{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atct38o_s3ZB"
      },
      "source": [
        "# Sentiment Analysis with ParsBERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9Nvlm0tAwGc"
      },
      "source": [
        "## The NVIDIA System Management Interface (nvidia-smi) is a command line utility, based on top of the NVIDIA Management Library (NVML), intended to aid in the management and monitoring of NVIDIA GPU devices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9HbUK_disBly",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75afd754-35ec-4cce-fe11-e5f588b8d70a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jun 14 18:30:41 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   69C    P8    12W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZ7ugLdoA9-7"
      },
      "source": [
        "## Install & import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iB2TDd3asGTx"
      },
      "outputs": [],
      "source": [
        "# Import required packages (If You Need Any More Packages, You Can Add them HERE.)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import os\n",
        "import re\n",
        "import collections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnGajnQGQIIX"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8Au1yJ8bMzj",
        "outputId": "4f5dc7ee-0f64-4564-c324-89697fcd0cc0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data1 = pd.read_csv('/content/drive/MyDrive/project-3/taghche_5000.csv', encoding='utf-8')\n",
        "data1.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FmbHKTl0u0vE",
        "outputId": "9189ac67-c6b2-4ee2-e030-79ced5e4700f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         date                                            comment  \\\n",
              "0  1395/11/14  اسم کتاب   No one writes to the Colonel\\nترجمش...   \n",
              "1  1395/11/14  طاقچه عزیز،نام کتاب\"کسی به سرهنگ نامه نمینویسد...   \n",
              "2  1394/06/06  بنظرم این اثر مارکز خیلی از صد سال تنهایی که ب...   \n",
              "3  1393/09/02  به نظر کتاب خوبی میومد اما من از ترجمش خوشم نی...   \n",
              "4  1393/06/29                                      کتاب خوبی است   \n",
              "\n",
              "                            bookname  rate  bookID  like  \n",
              "0  سرهنگ کسی ندارد برایش نامه بنویسد     0       3     2  \n",
              "1  سرهنگ کسی ندارد برایش نامه بنویسد     5       3     2  \n",
              "2  سرهنگ کسی ندارد برایش نامه بنویسد     5       3     0  \n",
              "3  سرهنگ کسی ندارد برایش نامه بنویسد     2       3     0  \n",
              "4  سرهنگ کسی ندارد برایش نامه بنویسد     3       3     0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fc26447d-a896-4e35-b4ad-a789db91f29c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>comment</th>\n",
              "      <th>bookname</th>\n",
              "      <th>rate</th>\n",
              "      <th>bookID</th>\n",
              "      <th>like</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1395/11/14</td>\n",
              "      <td>اسم کتاب   No one writes to the Colonel\\nترجمش...</td>\n",
              "      <td>سرهنگ کسی ندارد برایش نامه بنویسد</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1395/11/14</td>\n",
              "      <td>طاقچه عزیز،نام کتاب\"کسی به سرهنگ نامه نمینویسد...</td>\n",
              "      <td>سرهنگ کسی ندارد برایش نامه بنویسد</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1394/06/06</td>\n",
              "      <td>بنظرم این اثر مارکز خیلی از صد سال تنهایی که ب...</td>\n",
              "      <td>سرهنگ کسی ندارد برایش نامه بنویسد</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1393/09/02</td>\n",
              "      <td>به نظر کتاب خوبی میومد اما من از ترجمش خوشم نی...</td>\n",
              "      <td>سرهنگ کسی ندارد برایش نامه بنویسد</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1393/06/29</td>\n",
              "      <td>کتاب خوبی است</td>\n",
              "      <td>سرهنگ کسی ندارد برایش نامه بنویسد</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc26447d-a896-4e35-b4ad-a789db91f29c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fc26447d-a896-4e35-b4ad-a789db91f29c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fc26447d-a896-4e35-b4ad-a789db91f29c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCTKvthyQlOG"
      },
      "source": [
        "### Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DNx25HZyQI8H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "7b541e63-0974-4198-ca31-eb32162d793a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             comment  rate\n",
              "0  اسم کتاب   No one writes to the Colonel\\nترجمش...     0\n",
              "1  طاقچه عزیز،نام کتاب\"کسی به سرهنگ نامه نمینویسد...     5\n",
              "2  بنظرم این اثر مارکز خیلی از صد سال تنهایی که ب...     5\n",
              "3  به نظر کتاب خوبی میومد اما من از ترجمش خوشم نی...     2\n",
              "4                                      کتاب خوبی است     3"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c4b397c5-58e4-46ee-be1b-0494fce2fb7a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>اسم کتاب   No one writes to the Colonel\\nترجمش...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>طاقچه عزیز،نام کتاب\"کسی به سرهنگ نامه نمینویسد...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>بنظرم این اثر مارکز خیلی از صد سال تنهایی که ب...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>به نظر کتاب خوبی میومد اما من از ترجمش خوشم نی...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>کتاب خوبی است</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c4b397c5-58e4-46ee-be1b-0494fce2fb7a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c4b397c5-58e4-46ee-be1b-0494fce2fb7a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c4b397c5-58e4-46ee-be1b-0494fce2fb7a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/project-3/taghche_5000.csv', encoding='utf-8')\n",
        "data = data[['comment', 'rate']]\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YjjHSjyeQvqb"
      },
      "outputs": [],
      "source": [
        "# handle some conflicts with the dataset structure\n",
        "# you can find a reliable solution, for the sake of the simplicity\n",
        "# I just remove these bad combinations!\n",
        "data['rate'] = data['rate'].apply(lambda r: r if r < 6 else None)\n",
        "\n",
        "data = data.dropna(subset=['rate'])\n",
        "data = data.dropna(subset=['comment'])\n",
        "data = data.drop_duplicates(subset=['comment'], keep='first')\n",
        "data = data.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWmMbGFCQ1Rf"
      },
      "source": [
        "### Normalization / Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMn63nr5RCz2"
      },
      "source": [
        "**<font color=red> For simplicity, Transform the rate in a range of 0.0 to 5.0 to a binary form of negative (0) or positive (1) with a threshold. If the rate is less than 3.0, it labeled as negative otherwise specified as positive.</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OlqXeDLwLWx5"
      },
      "outputs": [],
      "source": [
        "##############################################################################################\n",
        "#                                       Your Code                                            #\n",
        "##############################################################################################"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = data[\"comment\"]\n",
        "import re\n",
        "\n",
        "pattern = re.compile('\\S*@\\S*\\s?')\n",
        "cleaning = []\n",
        "# pattern.sub('', s) \n",
        "# print(text) # with emoji\n",
        "def remove_emojis(data):\n",
        "    emoj = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "        u\"\\U0001f926-\\U0001f937\"\n",
        "        u\"\\U00010000-\\U0010ffff\"\n",
        "        u\"\\u2640-\\u2642\" \n",
        "        u\"\\u2600-\\u2B55\"\n",
        "        u\"\\u200d\"\n",
        "        u\"\\u23cf\"\n",
        "        u\"\\u23e9\"\n",
        "        u\"\\u231a\"\n",
        "        u\"\\ufe0f\"  # dingbats\n",
        "        u\"\\u3030\"\n",
        "                      \"]+\", re.UNICODE)\n",
        "    return re.sub(emoj, '', data)\n",
        "\n",
        "for item in text:\n",
        "    # print(item)\n",
        "    ss = remove_emojis(item)\n",
        "    print(item)\n",
        "    # s3 = pattern.sub('', s3) \n",
        "    print(ss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_E115NPJiI40",
        "outputId": "360a1851-47e4-4ca7-feed-5e528b58173f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "واقعاً احسنت بر آقای سرشار.. عالی بود.. خداقوت.\n",
            "واقعاً احسنت بر آقای سرشار.. عالی بود.. خداقوت.\n",
            "فوق العاده بود.\n",
            "یک کتاب خوندنی...\n",
            "برای من که مثل یک لیوان آب خنک تو تشنگی تابستون بود،،،همونقدر گوارا...\n",
            "نمی دونم برای بقیه هم اینطور بوده یا نه،ولی تصور من از پیامبر یه مرد با لباس عربی یک دست سفید بود،یک فرد مقدس،خیلی نسبت بهشون حس محبت نداشتم،بیشتر حالت احترام و تقدس...\n",
            "ولی با خوندن این کتاب پیامبر برای من یک شخصیت انسان گونه(جدای از اون حالت تقدس و فرشته مانند) پیدا کردند،شخصیتی که مثل همه آدما یه سری نیاز ها دارن،یه سری دغدغه ها دارن...\n",
            "حسی که کتاب از پیامبر و خانواده و اطرافیانشون ایجاد کرد به هیچ وجه با فیلم «محمد رسول الله(ص)» برای من ایجاد نشد،و اون حجم از اتفاقات ماورایی فیلم هم در کتاب نبود.\n",
            "کتاب از قبل از تولد پیامبر و از زندگی عبدالمطب پدربزرگ پیامبر آغاز میشه و تا زمان مبعث پیامبر پیش میره،نثر کتاب به زبان فارسی کهنه(ولی کاملاً قابل فهم و بسیار شیرین),گاهی اتفاق ها از زبان نویسنده است گاهی از زبان اطرافیان پیامبر،گاهی هم روند داستان ضمن مکالمه ها پیش می‌ره.\n",
            "اصلأ با کتاب احساس خستگی نکردم.\n",
            "برای معرفی پیامبر به نوجوان ها خیلی مناسبه.\n",
            "و کلا گزینه خوبیه برای هدیه دادن.\n",
            "از نویسنده محترم کتاب بسیار تشکر می کنم(اگه یه روز حضوری ببینمشون حتما حضوری هم تشکر خواهم کرد) و امیدوارم در آینده آثار بیشتری از ایشون ببینم.\n",
            "فوق العاده بود.\n",
            "یک کتاب خوندنی...\n",
            "برای من که مثل یک لیوان آب خنک تو تشنگی تابستون بود،،،همونقدر گوارا...\n",
            "نمی دونم برای بقیه هم اینطور بوده یا نه،ولی تصور من از پیامبر یه مرد با لباس عربی یک دست سفید بود،یک فرد مقدس،خیلی نسبت بهشون حس محبت نداشتم،بیشتر حالت احترام و تقدس...\n",
            "ولی با خوندن این کتاب پیامبر برای من یک شخصیت انسان گونه(جدای از اون حالت تقدس و فرشته مانند) پیدا کردند،شخصیتی که مثل همه آدما یه سری نیاز ها دارن،یه سری دغدغه ها دارن...\n",
            "حسی که کتاب از پیامبر و خانواده و اطرافیانشون ایجاد کرد به هیچ وجه با فیلم «محمد رسول الله(ص)» برای من ایجاد نشد،و اون حجم از اتفاقات ماورایی فیلم هم در کتاب نبود.\n",
            "کتاب از قبل از تولد پیامبر و از زندگی عبدالمطب پدربزرگ پیامبر آغاز میشه و تا زمان مبعث پیامبر پیش میره،نثر کتاب به زبان فارسی کهنه(ولی کاملاً قابل فهم و بسیار شیرین),گاهی اتفاق ها از زبان نویسنده است گاهی از زبان اطرافیان پیامبر،گاهی هم روند داستان ضمن مکالمه ها پیش می‌ره.\n",
            "اصلأ با کتاب احساس خستگی نکردم.\n",
            "برای معرفی پیامبر به نوجوان ها خیلی مناسبه.\n",
            "و کلا گزینه خوبیه برای هدیه دادن.\n",
            "از نویسنده محترم کتاب بسیار تشکر می کنم(اگه یه روز حضوری ببینمشون حتما حضوری هم تشکر خواهم کرد) و امیدوارم در آینده آثار بیشتری از ایشون ببینم.\n",
            "سخت خوان بود\n",
            "ولی خوب بود\n",
            "سخت خوان بود\n",
            "ولی خوب بود\n",
            "نسخه چاپی کتاب رو خوندم. واقعا دلنشین و دلپذیر بود\n",
            "نسخه چاپی کتاب رو خوندم. واقعا دلنشین و دلپذیر بود\n",
            "بدون شک یکی از بهترین رمان های فارسی ست...\n",
            "برای امتحان نمونه کتاب رو بخونین\n",
            "بدون شک یکی از بهترین رمان های فارسی ست...\n",
            "برای امتحان نمونه کتاب رو بخونین\n",
            "کتاب بسیار زیبا که با متن دلنشین وقایع دقیق تاریخی رو بیان کرده.\n",
            "واقعا ارزش چند بار خواندن رو داره.\n",
            "کتاب بسیار زیبا که با متن دلنشین وقایع دقیق تاریخی رو بیان کرده.\n",
            "واقعا ارزش چند بار خواندن رو داره.\n",
            "💎احادیثی از حضرت محمد صلی الله علیه و آله و سلم :\n",
            "\n",
            "🔸به یکدیگر هدیه دهید تا دوستی تان افزون شود .\n",
            "\n",
            "🔹حیا ، جز نیکی به بار نمی آورد .\n",
            "\n",
            "🔸بهترینِ شما کسی است که به خیرش امید می رود و از شرّش ایمنی هست .\n",
            "\n",
            "🔹پارسایی در دنیا ، مایه آسایش دل و تن است .\n",
            "\n",
            "🔸نیک بخت ، آن است که از [سرنوشت] دیگران پند بگیرد .  \n",
            "\n",
            "🔹آسان گرفتن ، مایه سودمندی است و سخت گرفتن ، سبب شوربختی .  \n",
            "\n",
            "🔸در جستجوی روزیِ حلال بودن ، جهاد است .  \n",
            "\n",
            "🔹خوشا آن که کسبش پاک ، نهانش بسامان و آشکارش نیک باشد و شرّ خود را از مردم ، باز دارد !  \n",
            " \n",
            "🔸خداوند ، رحمت نمی آوَرَد بر کسی که به مردم ، رحم نمی کند .  \n",
            "\n",
            "🔹ایمان بنده راست نشود ، مگر آن که دلش راست شود ، و دلش راست نشود ، مگر آن که زبانش راست شود .  \n",
            "\n",
            "🔸خدا را سپاس نمی گزارد ، آن که سپاسگزار مردم نباشد .  \n",
            "\n",
            "🔹بنده ایمان نمی آورَد ، مگر آن که نیکی ای را که برای خود دوست دارد ، برای برادرش نیز دوست داشته باشد .  \n",
            " \n",
            "🔸از ما نیست آن که خدا میدان روزی اش را فراخ کرده باشد و او بر خانواده اش تنگ گیرد .  \n",
            "\n",
            "🔹آن که خواهان خیر باشد ، زیان نمی بیند ، و آن که مشورت کند ، پشیمان نمی شود .  \n",
            "\n",
            "🔸  حکایت شما   ای مردم  همانند سپاهی است که ابتدای آن رفته و ندای کوچ در آن، سر داده شده است . پس ، چه زود آخر آن سپاه به اوّلش می رسد! به خدا سوگند ، دنیا در برابر آخرت ، جز به مانند یک نَفَس (جهش)  خرگوشی نیست . بکوشید ، بکوشید ای بندگان خدا  و از خداوند ، پروردگارتان ، کمک بجویید.  \n",
            "\n",
            "🔹خداوند به چیزی برتر از شناخت عالمانه دین ، عبادت نشد.\n",
            "\n",
            "\n",
            ".\n",
            "احادیثی از حضرت محمد صلی الله علیه و آله و سلم :\n",
            "\n",
            "به یکدیگر هدیه دهید تا دوستی تان افزون شود .\n",
            "\n",
            "حیا ، جز نیکی به بار نمی آورد .\n",
            "\n",
            "بهترینِ شما کسی است که به خیرش امید می رود و از شرّش ایمنی هست .\n",
            "\n",
            "پارسایی در دنیا ، مایه آسایش دل و تن است .\n",
            "\n",
            "نیک بخت ، آن است که از [سرنوشت] دیگران پند بگیرد .  \n",
            "\n",
            "آسان گرفتن ، مایه سودمندی است و سخت گرفتن ، سبب شوربختی .  \n",
            "\n",
            "در جستجوی روزیِ حلال بودن ، جهاد است .  \n",
            "\n",
            "خوشا آن که کسبش پاک ، نهانش بسامان و آشکارش نیک باشد و شرّ خود را از مردم ، باز دارد !  \n",
            " \n",
            "خداوند ، رحمت نمی آوَرَد بر کسی که به مردم ، رحم نمی کند .  \n",
            "\n",
            "ایمان بنده راست نشود ، مگر آن که دلش راست شود ، و دلش راست نشود ، مگر آن که زبانش راست شود .  \n",
            "\n",
            "خدا را سپاس نمی گزارد ، آن که سپاسگزار مردم نباشد .  \n",
            "\n",
            "بنده ایمان نمی آورَد ، مگر آن که نیکی ای را که برای خود دوست دارد ، برای برادرش نیز دوست داشته باشد .  \n",
            " \n",
            "از ما نیست آن که خدا میدان روزی اش را فراخ کرده باشد و او بر خانواده اش تنگ گیرد .  \n",
            "\n",
            "آن که خواهان خیر باشد ، زیان نمی بیند ، و آن که مشورت کند ، پشیمان نمی شود .  \n",
            "\n",
            "  حکایت شما   ای مردم  همانند سپاهی است که ابتدای آن رفته و ندای کوچ در آن، سر داده شده است . پس ، چه زود آخر آن سپاه به اوّلش می رسد! به خدا سوگند ، دنیا در برابر آخرت ، جز به مانند یک نَفَس (جهش)  خرگوشی نیست . بکوشید ، بکوشید ای بندگان خدا  و از خداوند ، پروردگارتان ، کمک بجویید.  \n",
            "\n",
            "خداوند به چیزی برتر از شناخت عالمانه دین ، عبادت نشد.\n",
            "\n",
            "\n",
            ".\n",
            "بهترین کتابی که خواندم.\n",
            "بهترین کتابی که خواندم.\n",
            "عالی بود....حتما بخونید.\n",
            "عالی بود....حتما بخونید.\n",
            "سلام،عالی بود لذت بردم جزو بهترین کتابهایی بود که تابحال خوندم،خدا نویسنده را خیر بده\n",
            "سلام،عالی بود لذت بردم جزو بهترین کتابهایی بود که تابحال خوندم،خدا نویسنده را خیر بده\n",
            "این کتاب به چند زبان مثل عربی، ترکی استامبولی، انگلیسی ترجمه شده، و خیلی خوبه که همچین کتابی رو میتونیم به زبان اصلیش بخونیم\n",
            "این کتاب به چند زبان مثل عربی، ترکی استامبولی، انگلیسی ترجمه شده، و خیلی خوبه که همچین کتابی رو میتونیم به زبان اصلیش بخونیم\n",
            "کتاب نثر جالبی داره طوری که گاهی فضاسازی اون باعث میشه احساس کنم در حال تماشای فیلم آنک آن یتیم نظر کرده هستم یا حتی گاهی اوقات خودم رو در زمان کتاب تصور کنم.\n",
            "کتاب نثر جالبی داره طوری که گاهی فضاسازی اون باعث میشه احساس کنم در حال تماشای فیلم آنک آن یتیم نظر کرده هستم یا حتی گاهی اوقات خودم رو در زمان کتاب تصور کنم.\n",
            "و آنها را که داستان نویس نمی دانم بروند ۴۰ بار از داستان گدا ساعدی مشق کنند. سخنرانی جوانمرگی در نثر معاصر فارسی هوشنگ گلشیری در انجمن داستان نویسان آلمان و ایران\n",
            "و آنها را که داستان نویس نمی دانم بروند ۴۰ بار از داستان گدا ساعدی مشق کنند. سخنرانی جوانمرگی در نثر معاصر فارسی هوشنگ گلشیری در انجمن داستان نویسان آلمان و ایران\n",
            "ولش کن اینو گَدایه\n",
            "ولش کن اینو گَدایه\n",
            "سلام من سال هاست بیکار و‌ بی پولم کلی هم کتاب کسب و کار خریدم به امید کار و پول اما هیچ فایده نداره واقعا داغون و خیلی شدم هیچ کسم کمکم نکرده کاش کمی پول داشتم وضعیتم این طوری نمی موند آخرش نمیدونم چه بلای سرم میاد در حد مرگ و جنون اذیتم کردن پیشنهاد و توصیه تون چیه ؟\n",
            "سلام من سال هاست بیکار و‌ بی پولم کلی هم کتاب کسب و کار خریدم به امید کار و پول اما هیچ فایده نداره واقعا داغون و خیلی شدم هیچ کسم کمکم نکرده کاش کمی پول داشتم وضعیتم این طوری نمی موند آخرش نمیدونم چه بلای سرم میاد در حد مرگ و جنون اذیتم کردن پیشنهاد و توصیه تون چیه ؟\n",
            "اونا گداین شهلا\n",
            "اونا گداین شهلا\n",
            "گاهی اوقات به نقطه ای میرسی که جز گول زدن خودت گزینه دیگری نداری،مجبوری یه جوری خودتو آروم کنی که دلت نترکه،مجبوری به خودت بقبولونی گدایی ثواب داره...\n",
            "گاهی اوقات به نقطه ای میرسی که جز گول زدن خودت گزینه دیگری نداری،مجبوری یه جوری خودتو آروم کنی که دلت نترکه،مجبوری به خودت بقبولونی گدایی ثواب داره...\n",
            "اون گدایه\n",
            "اون گدایه\n",
            "کتابای ساعدی همیشه گیراست و ادم و میبره تو فضای داستان\n",
            "کتابای ساعدی همیشه گیراست و ادم و میبره تو فضای داستان\n",
            "خوندن این داستان پیشنهاد میشه.\n",
            "خوندن این داستان پیشنهاد میشه.\n",
            "خیلی غم انگیز بود\n",
            "ومتاسفانه واقعیت داره و خیلی تلخه.اینکه یه عمر با خون دل زحمت بکشی و بچه بزرگ کنی و آخرشم هیچی به هیچی.هر کی بره دنبال زندگی خودش....\n",
            "خیلی غم انگیز بود\n",
            "ومتاسفانه واقعیت داره و خیلی تلخه.اینکه یه عمر با خون دل زحمت بکشی و بچه بزرگ کنی و آخرشم هیچی به هیچی.هر کی بره دنبال زندگی خودش....\n",
            "چی میشه که وقتی بچه ها بزرگ میشن، پدرومادر تو چشمشون کوچیک و یا حتی بی ارزش میشه،\n",
            "بی توجهی، بی احترامی،و...\n",
            "امیدوارم نه پدر مادری محتاج فرزندش باشه، نه فرزندی فراموش کار ِ پدرومادرش.\n",
            "چی میشه که وقتی بچه ها بزرگ میشن، پدرومادر تو چشمشون کوچیک و یا حتی بی ارزش میشه،\n",
            "بی توجهی، بی احترامی،و...\n",
            "امیدوارم نه پدر مادری محتاج فرزندش باشه، نه فرزندی فراموش کار ِ پدرومادرش.\n",
            "عجیب و غیر قابل درک\n",
            "عجیب و غیر قابل درک\n",
            "بنظرم بد نبود داستان در زمان خودش ملموس تر بوده قطعا\n",
            "بنظرم بد نبود داستان در زمان خودش ملموس تر بوده قطعا\n",
            "پیرزنه خیلی مظلوم بود بچه هاش فقط منتظربودن بمیره ماترکشو تقسیم کنن اما برداشت من ازثواب داشتن گداییش این بود که ...خانوم بزرگ قصدو نیتش این بود که با گدایی به اونهایی که میخوان صدقه بهش بدن یه ثوابی برسه چون صدقه دادن تواسلام خیلی ثواب داره شاید نویسنده به دنبال این بوده که درعین نشان دادن مظلومیت خانوم بزرگ اونو شخصیتی نشان بده که نون به نرخ روز میخوره مثل خیلی ازآدمایی که همین الانشم تو جامعه مون کم نیستند یعنی یه جورایی واسه نون خوردن خودش از اعتقادات مردم سؤء استفاده میکرد و تکدی گری رو با این استدلالش که ثواب داره توجیه میکرد ...\n",
            "پیرزنه خیلی مظلوم بود بچه هاش فقط منتظربودن بمیره ماترکشو تقسیم کنن اما برداشت من ازثواب داشتن گداییش این بود که ...خانوم بزرگ قصدو نیتش این بود که با گدایی به اونهایی که میخوان صدقه بهش بدن یه ثوابی برسه چون صدقه دادن تواسلام خیلی ثواب داره شاید نویسنده به دنبال این بوده که درعین نشان دادن مظلومیت خانوم بزرگ اونو شخصیتی نشان بده که نون به نرخ روز میخوره مثل خیلی ازآدمایی که همین الانشم تو جامعه مون کم نیستند یعنی یه جورایی واسه نون خوردن خودش از اعتقادات مردم سؤء استفاده میکرد و تکدی گری رو با این استدلالش که ثواب داره توجیه میکرد ...\n",
            "چقدر غمگین!!! واقعا گریم گرفت...\n",
            "چقدر غمگین!!! واقعا گریم گرفت...\n",
            "کتاب خیلی پیچیده ای نبود..خیلی من رو تحت تاثیر قرار نداد..ولی وقتی بیوگرافی دکتر رو خوندم نتونستم از یک خط کتاب بگذرم..و میگم که پیرزن به حقش رسید..با تشکر از طاقچه\n",
            "کتاب خیلی پیچیده ای نبود..خیلی من رو تحت تاثیر قرار نداد..ولی وقتی بیوگرافی دکتر رو خوندم نتونستم از یک خط کتاب بگذرم..و میگم که پیرزن به حقش رسید..با تشکر از طاقچه\n",
            "بااین تعداد از فرزند ولی بازم مجبور باشی گدایی کنی ؛\n",
            "بچه هایی که انگار حریص مالن و حتی چشم به بقچه مادرشون دارن .\n",
            "جایگاه و ارزش مادر هم مثل اینکه تعریفی نداشت براشون..\n",
            "بااین تعداد از فرزند ولی بازم مجبور باشی گدایی کنی ؛\n",
            "بچه هایی که انگار حریص مالن و حتی چشم به بقچه مادرشون دارن .\n",
            "جایگاه و ارزش مادر هم مثل اینکه تعریفی نداشت براشون..\n",
            "خیلی ناراحت کننده است😔\n",
            "خیلی ناراحت کننده است\n",
            "عالی بود بی نظیر بود واقعا دست نویسنده درد نکنه\n",
            "عالی بود بی نظیر بود واقعا دست نویسنده درد نکنه\n",
            "گدایی برای سادات حرام است. شاید نویسنده پیدا کردن دلیل مخالفت بچه ها رو به عهده خواننده گذاشته.\n",
            "گدایی برای سادات حرام است. شاید نویسنده پیدا کردن دلیل مخالفت بچه ها رو به عهده خواننده گذاشته.\n",
            "داستان گیرای خوبی داشت ولی اصلاً نتونستم درکش کنم یعنی که چی گدایی ثواب داره !\n",
            "داستان گیرای خوبی داشت ولی اصلاً نتونستم درکش کنم یعنی که چی گدایی ثواب داره !\n",
            "کاش این قصه واقعی نباشد...\n",
            "کاش هیچ \"سید خانم\"ی نباشد.\n",
            "حتی خواندن داستانش هم سخت است،چه برسد به...\n",
            "کاش این قصه واقعی نباشد...\n",
            "کاش هیچ \"سید خانم\"ی نباشد.\n",
            "حتی خواندن داستانش هم سخت است،چه برسد به...\n",
            "خیلی غمگین بود😔\n",
            "خیلی غمگین بود\n",
            "به شدت ترسیدم، این همه بی وفایی به مادر واقعا وحشتناکه.\n",
            "به شدت ترسیدم، این همه بی وفایی به مادر واقعا وحشتناکه.\n",
            "خیلی غم انگیز بود و تاثیر گذار😢😢\n",
            "خیلی غم انگیز بود و تاثیر گذار\n",
            "سلام یه مدتی به من تحمت میزدن از بچه های اداره .همه نوع تهمتی که لایق خودشون بود به من میگفتن .بعداز مدتها گذشت در طرشت کوچه میرزمانی پلاک 14باغی بود داخلش تعمیرگاه بود افرادی که بسیار عشق چشم تو چشم داشتن با ماموران میان داخل باغ که یکسریع معتاد ومصرف کننده بگیرن وهمون طرف که چشم درچشم خیلی دوست داره با مامورها میاد یعنی اون مامورها رو میاره خودشم میشنه به مصرف با زر ورق افراد دستگیر میشن ومیان بیرون از که برن سیوارماشین بشن چشم درچشم ازاد میشه ولی باقی افراد میبرن بعد به دیگرون میگن ادم فروش اهنگ شادمهر عقیلی ادم فروش اهنگ قشنگیه\n",
            "سلام یه مدتی به من تحمت میزدن از بچه های اداره .همه نوع تهمتی که لایق خودشون بود به من میگفتن .بعداز مدتها گذشت در طرشت کوچه میرزمانی پلاک 14باغی بود داخلش تعمیرگاه بود افرادی که بسیار عشق چشم تو چشم داشتن با ماموران میان داخل باغ که یکسریع معتاد ومصرف کننده بگیرن وهمون طرف که چشم درچشم خیلی دوست داره با مامورها میاد یعنی اون مامورها رو میاره خودشم میشنه به مصرف با زر ورق افراد دستگیر میشن ومیان بیرون از که برن سیوارماشین بشن چشم درچشم ازاد میشه ولی باقی افراد میبرن بعد به دیگرون میگن ادم فروش اهنگ شادمهر عقیلی ادم فروش اهنگ قشنگیه\n",
            "ارزش خوندن نداره!\n",
            "ارزش خوندن نداره!\n",
            "اگر این داستان روایت مصائب پیری و بی عدالتی در حق زنان باشه من درکش می‌کنم.\n",
            "اما داستان پر بود از نمادهایی که من نتونستم درک کنم..\n",
            "مثلاً ثواب گدایی بلاخص که در جای پرت و تاریک باشه..\n",
            "حیوانی که خاک زمین رو لیس میزد...\n",
            "شمایل حضرت و....\n",
            "داستان گیرا بود ولی نمیتونم بگم خوب بود چون از داستان‌هایی که ابهام آلود باشن لذت نمی‌برم\n",
            "اگر این داستان روایت مصائب پیری و بی عدالتی در حق زنان باشه من درکش می‌کنم.\n",
            "اما داستان پر بود از نمادهایی که من نتونستم درک کنم..\n",
            "مثلاً ثواب گدایی بلاخص که در جای پرت و تاریک باشه..\n",
            "حیوانی که خاک زمین رو لیس میزد...\n",
            "شمایل حضرت و....\n",
            "داستان گیرا بود ولی نمیتونم بگم خوب بود چون از داستان‌هایی که ابهام آلود باشن لذت نمی‌برم\n",
            "عالی بود\n",
            "واقعا اون پیرزن چقد بیچاره بود. چه بچه های بی احساسی😢\n",
            "عالی بود\n",
            "واقعا اون پیرزن چقد بیچاره بود. چه بچه های بی احساسی\n",
            "خیلی پر درد و غمگین....\n",
            "خیلی پر درد و غمگین....\n",
            "خیلی زیبا توصیف شده بود و بسیاااااااااار غم انگیز بود...دل آدم رو به درد میاره\n",
            "خیلی زیبا توصیف شده بود و بسیاااااااااار غم انگیز بود...دل آدم رو به درد میاره\n",
            "واقعا عالی بود\n",
            "فقط من نفهمیدم چرا گدایی ثواب داشت از نظرش!\n",
            "چقدر تلخ بود..دلم سوخت\n",
            "واقعا عالی بود\n",
            "فقط من نفهمیدم چرا گدایی ثواب داشت از نظرش!\n",
            "چقدر تلخ بود..دلم سوخت\n",
            "داستان به خوبی تعریف شده، توصیف ها عالی هستن ولی موضوع داستان عصبیم کرد، آخه چرا باید یکی خوشش بیاد گدایی کنه\n",
            "داستان به خوبی تعریف شده، توصیف ها عالی هستن ولی موضوع داستان عصبیم کرد، آخه چرا باید یکی خوشش بیاد گدایی کنه\n",
            "به نظرم (فقط در حد یه نظر) آشفتگی داستان و پرش شخصیتی باعث میشد آشفتگی اوضاع پیرزن و مشوش بودن ذهنش و اینکه هر لحظه از یکی می ترسه ملموس تر بشه و قابل تصور تر باشه. در کل به نظرم زیبا بود.\n",
            "به نظرم (فقط در حد یه نظر) آشفتگی داستان و پرش شخصیتی باعث میشد آشفتگی اوضاع پیرزن و مشوش بودن ذهنش و اینکه هر لحظه از یکی می ترسه ملموس تر بشه و قابل تصور تر باشه. در کل به نظرم زیبا بود.\n",
            "واقعا گریه ام گرفت\n",
            "واقعا گریه ام گرفت\n",
            "بنظر من همه اثار دکتر ساعدی با ارزش وخواندنی است هرکسی که اثار دکتر را بخونه بنظرم وقتش بیهوده نگذشته است ارزش خوندن داره ،روحش شاد\n",
            "بنظر من همه اثار دکتر ساعدی با ارزش وخواندنی است هرکسی که اثار دکتر را بخونه بنظرم وقتش بیهوده نگذشته است ارزش خوندن داره ،روحش شاد\n",
            "اصلا خوشم نیومد پیرزنه از گدایی خوشش میومد 😑\n",
            "اصلا خوشم نیومد پیرزنه از گدایی خوشش میومد \n",
            "che dardnak\n",
            "che dardnak\n",
            "فقط میتونم بگم امیدوارم در آینده همچین فرزندی واسه پدر و مادرم نباشم\n",
            "فقط میتونم بگم امیدوارم در آینده همچین فرزندی واسه پدر و مادرم نباشم\n",
            "خیلی عالی بود و غم انگیز\n",
            "خیلی عالی بود و غم انگیز\n",
            "من صوتیشو گوش کردم.. خیلی غمگین بود و دلم برای پیرزنه میسوخت.. توصیف هاش خیلی خوب بودن و آدم تمام اون ها رو راحت تصور میکرد..\n",
            "من صوتیشو گوش کردم.. خیلی غمگین بود و دلم برای پیرزنه میسوخت.. توصیف هاش خیلی خوب بودن و آدم تمام اون ها رو راحت تصور میکرد..\n",
            "خیلی غم انگیز اما واقعی ...\n",
            "خیلی غم انگیز اما واقعی ...\n",
            "قشنگ بود و خیلی غمگین\n",
            "قشنگ بود و خیلی غمگین\n",
            "قشنگ اما ناراحت کننده تلخ اما واقعی\n",
            "قشنگ اما ناراحت کننده تلخ اما واقعی\n",
            "تامل برانگیز زیباااااا ❤️❤️❤️\n",
            "تامل برانگیز زیباااااا \n",
            "جذاب،غم انگیز،تاثیر گذار و ...\n",
            "اشک آدمو درمیاره.. غریبی این پیرزن...\n",
            "جذاب،غم انگیز،تاثیر گذار و ...\n",
            "اشک آدمو درمیاره.. غریبی این پیرزن...\n",
            "غم انگیز , زیبا , تاثیرگذار\n",
            "غم انگیز , زیبا , تاثیرگذار\n",
            "بسیار غمگین و اقراق آمیز\n",
            "بسیار غمگین و اقراق آمیز\n",
            "خیلی قشنگ بود .\n",
            "خیلی قشنگ بود .\n",
            "قشنگ بود...\n",
            "قشنگ بود...\n",
            "به نظر من جدا از رابطه مادر و فرزند و بی وفایی بچه هاش بیشتر نشون دهنده موقعیت زن توی جامعه اس درون زمان وقتی که مادر اجازه نداره وسایل خودشو استفاده کنه و فقط باید جایی بمونه تا وقتی مرد تقسیم بشه . وقتی شوهر زنی میمیره اون هیچ پشتوانه ای نداره و دخترش از ترس شوهرش فقط باید توی خونه زار بزنه و قدرت هیچ حمایتی از مادرشو نداره\n",
            "به نظر من جدا از رابطه مادر و فرزند و بی وفایی بچه هاش بیشتر نشون دهنده موقعیت زن توی جامعه اس درون زمان وقتی که مادر اجازه نداره وسایل خودشو استفاده کنه و فقط باید جایی بمونه تا وقتی مرد تقسیم بشه . وقتی شوهر زنی میمیره اون هیچ پشتوانه ای نداره و دخترش از ترس شوهرش فقط باید توی خونه زار بزنه و قدرت هیچ حمایتی از مادرشو نداره\n",
            "منکه خوشم نیومد...راوی که خود گداس بنظر خوب عاقله  همه چی رو میفهمه اما به دلگی عادت کرده و نمیتونه دست از گدایی برداره....این موجود اینقد توانایی داره میتونس تو خونه دیگران کار کنه  وشرافتمندانه زندگی کنه و بچه هاش هم بیشتر هواشو داشتن اما آبرو برا  بچه هاش نذاشته بود واسه  همین بچه ها ازش دوری میکردن.\n",
            "منکه خوشم نیومد...راوی که خود گداس بنظر خوب عاقله  همه چی رو میفهمه اما به دلگی عادت کرده و نمیتونه دست از گدایی برداره....این موجود اینقد توانایی داره میتونس تو خونه دیگران کار کنه  وشرافتمندانه زندگی کنه و بچه هاش هم بیشتر هواشو داشتن اما آبرو برا  بچه هاش نذاشته بود واسه  همین بچه ها ازش دوری میکردن.\n",
            "به نظرم  حکایت پیری و بچه های بی انصاف رو خیلی خوب بیان کرد. به نظرتان بچه های ما با ما چطور رفتار میکنند ؟\n",
            "به نظرم  حکایت پیری و بچه های بی انصاف رو خیلی خوب بیان کرد. به نظرتان بچه های ما با ما چطور رفتار میکنند ؟\n",
            "خیلی عالی بود . ما باید قدر مادرامونو بدونیم . اون پیرزن بچه زیاد داشت اما خیلی تنها بود و جز بقچه و شمایلش دیگه چیزی نداشت . هر جمله ی این کتاب ، درسی است برای همه ی ما که احترام این فرشته ی مهربان رو نگه داریم . باید سعی کنیم که هم احترام مادر رو نگه داریم و هم عین پروانه دورش بچرخیم که خدایی نکرده حساس تنهایی نکنه .\n",
            "خیلی عالی بود . ما باید قدر مادرامونو بدونیم . اون پیرزن بچه زیاد داشت اما خیلی تنها بود و جز بقچه و شمایلش دیگه چیزی نداشت . هر جمله ی این کتاب ، درسی است برای همه ی ما که احترام این فرشته ی مهربان رو نگه داریم . باید سعی کنیم که هم احترام مادر رو نگه داریم و هم عین پروانه دورش بچرخیم که خدایی نکرده حساس تنهایی نکنه .\n",
            "یه خورده بیش از حد خیالی نبود؟ انقدر بدم پیدا میشه\n",
            "یه خورده بیش از حد خیالی نبود؟ انقدر بدم پیدا میشه\n",
            "😢😢😢😢😢😢😢😢😢😢😢😢😢😢😢\n",
            "قدر مادرامونو بدونیم\n",
            "😢😢😢😢😢😢\n",
            "\n",
            "قدر مادرامونو بدونیم\n",
            "\n",
            "خیلی غم انگیز ...\n",
            "هر سطر این کتاب رو که می خونی، چه مادرت در قید حیات باشه، چه از دستش داده باشی، یادش میفتی و میگی باهاش بد کردم :(\n",
            "خیلی غم انگیز ...\n",
            "هر سطر این کتاب رو که می خونی، چه مادرت در قید حیات باشه، چه از دستش داده باشی، یادش میفتی و میگی باهاش بد کردم :(\n",
            "سلام\n",
            "سلام\n",
            "عالی بود.\n",
            "عالی بود.\n",
            "قصه از درد و رنج و محنت طبقات محروم و آسیب دیده است (فضای حزن آلود حاکم بر این داستان، منو یاد بی سرپرستان ' قدسی نصیری' انداخت). قصه از جهل و نادانی مردمان، از بی اعتنایی فرزندان نسبت به مادره که نیاز به آوردن مثال و مصداق نداره و در جای جای داستان به چشم میخوره، از بی اعتنایی مردمان نسبت به هم مثلا جایی که پیرزن روضه میخونه و گریه میکنه، مردم دورش حلقه میزنن و به جای کمک یا حداقل تاثر، به پیرزن  میخندن! بی اعتنایی نسبت به رنج کشیدگان و دردمندان مثلا  جایی که پیرزن کفش هاشو گم میکنه و کسی نیست که بپرسه پابرهنه چطور راه میری؟!  از منفعت طلبی در هر شرایطی مثلا جایی که امینه در آن هیرو ویری زار زار گریه میکنه که چرا چیزی بهش نرسیده! یا پیرمرد جلوی در گداخانه، که نصف کته و پیاز پیرزن رو برمیداره. \n",
            " و من به شخصه علاقه زیادی به این طرز روایت از جامعه و واقع بینی موجود در اون -حداقل بخشی از جامعه- دارم، به تلنگری که نویسنده به طور ماهرانه ای در قالب یک داستان به ظاهر ساده به مردم و خوانندگان داستانش میزنه.\n",
            "به نظر من، در این داستان پیرزن نماد و نماینده ای میشه تا همه جا سرک بکشه و این دردها رو روایت کنه. پیرزن بهانه ای میشه تا با او به شهر، ده، حرم، گورستان و گداخانه و... بریم و با افراد مختلفی که با پیرزن روبرو میشن آشنا بشیم.\n",
            "\n",
            "برخی از منتقدین \"گدا\" رو با اصول مکتب فلسفی اگزیستانسیالیسم (تقدم وجود بر ماهیت) و مفاهیم مرتبط با اون مانند آزادی، آوارگی، دلهره و نوستالژی مورد بررسی قرار دادن که مطالعه ش خالی از لطف نیست.\n",
            "\n",
            "از طاقچه هم ممنونم.\n",
            "قصه از درد و رنج و محنت طبقات محروم و آسیب دیده است (فضای حزن آلود حاکم بر این داستان، منو یاد بی سرپرستان ' قدسی نصیری' انداخت). قصه از جهل و نادانی مردمان، از بی اعتنایی فرزندان نسبت به مادره که نیاز به آوردن مثال و مصداق نداره و در جای جای داستان به چشم میخوره، از بی اعتنایی مردمان نسبت به هم مثلا جایی که پیرزن روضه میخونه و گریه میکنه، مردم دورش حلقه میزنن و به جای کمک یا حداقل تاثر، به پیرزن  میخندن! بی اعتنایی نسبت به رنج کشیدگان و دردمندان مثلا  جایی که پیرزن کفش هاشو گم میکنه و کسی نیست که بپرسه پابرهنه چطور راه میری؟!  از منفعت طلبی در هر شرایطی مثلا جایی که امینه در آن هیرو ویری زار زار گریه میکنه که چرا چیزی بهش نرسیده! یا پیرمرد جلوی در گداخانه، که نصف کته و پیاز پیرزن رو برمیداره. \n",
            " و من به شخصه علاقه زیادی به این طرز روایت از جامعه و واقع بینی موجود در اون -حداقل بخشی از جامعه- دارم، به تلنگری که نویسنده به طور ماهرانه ای در قالب یک داستان به ظاهر ساده به مردم و خوانندگان داستانش میزنه.\n",
            "به نظر من، در این داستان پیرزن نماد و نماینده ای میشه تا همه جا سرک بکشه و این دردها رو روایت کنه. پیرزن بهانه ای میشه تا با او به شهر، ده، حرم، گورستان و گداخانه و... بریم و با افراد مختلفی که با پیرزن روبرو میشن آشنا بشیم.\n",
            "\n",
            "برخی از منتقدین \"گدا\" رو با اصول مکتب فلسفی اگزیستانسیالیسم (تقدم وجود بر ماهیت) و مفاهیم مرتبط با اون مانند آزادی، آوارگی، دلهره و نوستالژی مورد بررسی قرار دادن که مطالعه ش خالی از لطف نیست.\n",
            "\n",
            "از طاقچه هم ممنونم.\n",
            "بدک نبود\n",
            "بدک نبود\n",
            "غمگین بود 😔\n",
            "تهش کاش بهتر تموم میشد\n",
            "غمگین بود \n",
            "تهش کاش بهتر تموم میشد\n",
            "تا اومدم بفهمم چی به چیه تموم شد! 😑\n",
            "تا اومدم بفهمم چی به چیه تموم شد! \n",
            "عالی بودلذت بردم😊\n",
            "عالی بودلذت بردم\n",
            "چرا آخرش این طور شد؟ 😒\n",
            "چرا آخرش این طور شد؟ \n",
            "غم انگیز...\n",
            "یعنی اون دوره مردها اینطوری زناشون رو به مادرشون ترجیح میدادن؟؟!\n",
            "غم انگیز...\n",
            "یعنی اون دوره مردها اینطوری زناشون رو به مادرشون ترجیح میدادن؟؟!\n",
            "نامفهوم.بد.بی محتوا.پایان باز مثل قصه های اصغر فرهادی\n",
            "نامفهوم.بد.بی محتوا.پایان باز مثل قصه های اصغر فرهادی\n",
            "اصلا یه جوری بود؛ نه سر داشت نه ته\n",
            "اصلا یه جوری بود؛ نه سر داشت نه ته\n",
            "خوب بود و البته ناراحت کننده...\n",
            "خوب بود و البته ناراحت کننده...\n",
            "کجاش خوب بود\n",
            "کجاش خوب بود\n",
            "خوبه من خوشم اومد ولی برای کوچیکا درکش نمیکنن\n",
            "خوبه من خوشم اومد ولی برای کوچیکا درکش نمیکنن\n",
            "خووووب\n",
            "خووووب\n",
            "خیلی کتاب خوبی بود\n",
            "خیلی کتاب خوبی بود\n",
            "بسیار کار خوبی بود اما میشه گفت کار جدیدی تو اون دوره نبوده و دارای اشکالات زیادی هست اما نکته اصلی داستان راوی هستش که به قلم استاد ساعدی بسیار روان و ساده نگاشته و روایت شده و کار آسانی نبوده وهمینطور برای تمام سنین جذاب و آموزنده ست  قصه ی داستان هم زخم خوبی به خواننده میزنه و احساسات اونو تا حدی جریهه دار میکنه اما انتهای داستان میتونست به طرز بهتری به اتمام برسه در کل یه کار خوب دیگه از دکتر ساعدی خوندم و خوشحالم ...\n",
            "بسیار کار خوبی بود اما میشه گفت کار جدیدی تو اون دوره نبوده و دارای اشکالات زیادی هست اما نکته اصلی داستان راوی هستش که به قلم استاد ساعدی بسیار روان و ساده نگاشته و روایت شده و کار آسانی نبوده وهمینطور برای تمام سنین جذاب و آموزنده ست  قصه ی داستان هم زخم خوبی به خواننده میزنه و احساسات اونو تا حدی جریهه دار میکنه اما انتهای داستان میتونست به طرز بهتری به اتمام برسه در کل یه کار خوب دیگه از دکتر ساعدی خوندم و خوشحالم ...\n",
            "واسه سن ۱۸سال کتاب مناسبیه؟!\n",
            "واسه سن ۱۸سال کتاب مناسبیه؟!\n",
            "واقعا ما انسانا داریم کجا میریم اینم شد زندگی من کلی ادم میشناسم که مث این خانم با بدبختی دارن زندگی میکننترو خدا بیاید به مادر پدرامون احترام بزاریم محبت کنیم چی میشه اونا بودن که یه عمری با خون دل ما رو بزرگ کردم \n",
            "\n",
            "وبلوالدین احسانا و السلام نامه تمام\n",
            "واقعا ما انسانا داریم کجا میریم اینم شد زندگی من کلی ادم میشناسم که مث این خانم با بدبختی دارن زندگی میکننترو خدا بیاید به مادر پدرامون احترام بزاریم محبت کنیم چی میشه اونا بودن که یه عمری با خون دل ما رو بزرگ کردم \n",
            "\n",
            "وبلوالدین احسانا و السلام نامه تمام\n",
            "خوب بود!!!!\n",
            "خوب بود!!!!\n",
            "قشنگ بود ؟؟؟؟؟؟\n",
            "قشنگ بود ؟؟؟؟؟؟\n",
            "داغونم کرد\n",
            "داغونم کرد\n",
            "سلام این کتاب جزو مسابقه هست یانه ؟؟\n",
            "سلام این کتاب جزو مسابقه هست یانه ؟؟\n",
            "واااااقعا زیبا بود. کسانی که از داستان خوششون نیومد باید بیشتر مطالعه کنن و نقد داستان ها رو هم بخونن تا نسبت به سبک های نویسندگی عمیق تر بشن.\n",
            "واااااقعا زیبا بود. کسانی که از داستان خوششون نیومد باید بیشتر مطالعه کنن و نقد داستان ها رو هم بخونن تا نسبت به سبک های نویسندگی عمیق تر بشن.\n",
            "بنیانگذار واقعی ریالیسم جادویی ایشون هستند\n",
            "مدفون در کنار قبر صادق هدایت\n",
            "بنیانگذار واقعی ریالیسم جادویی ایشون هستند\n",
            "مدفون در کنار قبر صادق هدایت\n",
            "وقتی که میخوندمش یجوری میشدم سردو بی روح...زندگی اینجور ادما اصن معلوم نیس چطور تموم میشه مثه اخر خود داستان.¡!\n",
            "وقتی که میخوندمش یجوری میشدم سردو بی روح...زندگی اینجور ادما اصن معلوم نیس چطور تموم میشه مثه اخر خود داستان.¡!\n",
            "خیلی بیخود بود خیلیییی\n",
            "خیلی بیخود بود خیلیییی\n",
            "کوتاه و خیلی دردناک و غم انگیز. داستان مادرایی که همه ی عمر و توانشونو صرف بچه هاشون میکنن ولی اونطوری که شایستش هستن باهاشون برخورد نمیشه و توسط همون بچه ها بی رحمانه طرد میشن.\n",
            "کوتاه و خیلی دردناک و غم انگیز. داستان مادرایی که همه ی عمر و توانشونو صرف بچه هاشون میکنن ولی اونطوری که شایستش هستن باهاشون برخورد نمیشه و توسط همون بچه ها بی رحمانه طرد میشن.\n",
            "هیشکی درکش نکرد،کسی ک عمرشو برای درک اونا گذاشت....\n",
            "چرا مادرا تا لحه آخر راعات بچه هارو میکنن...😢\n",
            "هیشکی درکش نکرد،کسی ک عمرشو برای درک اونا گذاشت....\n",
            "چرا مادرا تا لحه آخر راعات بچه هارو میکنن...\n",
            "موضوعش که احترام به والدین بود قابل احترامه ولی خود داستان افتضاح بود ، این با این داستانا معروف شده ؟ عجبا\n",
            "موضوعش که احترام به والدین بود قابل احترامه ولی خود داستان افتضاح بود ، این با این داستانا معروف شده ؟ عجبا\n",
            "غمگین و کوتاه\n",
            "غمگین و کوتاه\n",
            "قدر پدر و مادر هامون رو بدونیم وقتی  که هستند . وقتی که رفتند چه فایده گریه و زاری\n",
            "قدر پدر و مادر هامون رو بدونیم وقتی  که هستند . وقتی که رفتند چه فایده گریه و زاری\n",
            "غم انگیز بود و ارزش خواندن داشت\n",
            "غم انگیز بود و ارزش خواندن داشت\n",
            "داستان خوبیه.  موضوعش یه پیرزن گداست اما مضمونش در ارتباط با والدینه\n",
            "داستان خوبیه.  موضوعش یه پیرزن گداست اما مضمونش در ارتباط با والدینه\n",
            "ﺧﻴﻠﻲ ﺑﺪ ﺑﻮﺩ!  اﺻﻼ ﭼﻲ ﻣﻴﺨﻮاﺳﺖ ﺑﮕﻪ!  ﻃﺎﻗﭽﻪ ﺑﻴﺸﺘﺮ ﺩﻗﺖ ﻛﻦ.  ﻣﺮﺳﻲ اﻩ\n",
            "  !  ا  ا !     .   ا\n",
            "حرکت یکنواخت در روایت داستان و بیان درست احساسات طوری که شخصیت کاملا پرداخته می شود و حرکات او کاملا نشان از یک شخصیت واحد دارد و ضد ونقیض نیست. نمی دانم چرا مرا به خانه سالمندان برد به یاد سالمندانی که داستان های گوناگونشان زیباست مانند چین و چروک های مواج چهره شان و چه دردناک است اشک هایی که در این خطوط می لغزد هنگامی که از گذشته می گویند و گاهی بعضی هاشان حرف نمی زنند مثل پیرزن قصه فقط تاب می آورند تا پر بکشند\n",
            "حرکت یکنواخت در روایت داستان و بیان درست احساسات طوری که شخصیت کاملا پرداخته می شود و حرکات او کاملا نشان از یک شخصیت واحد دارد و ضد ونقیض نیست. نمی دانم چرا مرا به خانه سالمندان برد به یاد سالمندانی که داستان های گوناگونشان زیباست مانند چین و چروک های مواج چهره شان و چه دردناک است اشک هایی که در این خطوط می لغزد هنگامی که از گذشته می گویند و گاهی بعضی هاشان حرف نمی زنند مثل پیرزن قصه فقط تاب می آورند تا پر بکشند\n",
            "نظرات خیلی توجه منو جلب کرد\n",
            "درحالی که ینفر راضی بود نفر بعدی گفت مزخرف\n",
            "داستان یه تخیل یا یه نوشته ساده نبود\n",
            "داستانی ک خوندین واقعیتی ایه ک توی جامعه از نمونه اش به راحتی پیدا میشه(بجز گدانماها)\n",
            "اگ هرکسی هوای پدر و مادر خودش رو داشته باشه ...\n",
            "نظرات خیلی توجه منو جلب کرد\n",
            "درحالی که ینفر راضی بود نفر بعدی گفت مزخرف\n",
            "داستان یه تخیل یا یه نوشته ساده نبود\n",
            "داستانی ک خوندین واقعیتی ایه ک توی جامعه از نمونه اش به راحتی پیدا میشه(بجز گدانماها)\n",
            "اگ هرکسی هوای پدر و مادر خودش رو داشته باشه ...\n",
            "زیبااماغم انگیز درکل خوبه.\n",
            "زیبااماغم انگیز درکل خوبه.\n",
            "قشنگ بود،ارزش یه بار خوندن را به نظر من داره.\n",
            "قشنگ بود،ارزش یه بار خوندن را به نظر من داره.\n",
            "با سلام و خسته نباشید.\n",
            "ضمن تشکر از قرار دادن این قبیل کتاب های تاریخی خصوصا تاریخ معاصر،نمونه کتاب را دانلود کردم و مطالعه نمودم.همه چیز عالی بود به جز برخی اشتباهات تایپی که امیدوارم به زودی مرتفع گردد.\n",
            "موفق باشید.\n",
            "با سلام و خسته نباشید.\n",
            "ضمن تشکر از قرار دادن این قبیل کتاب های تاریخی خصوصا تاریخ معاصر،نمونه کتاب را دانلود کردم و مطالعه نمودم.همه چیز عالی بود به جز برخی اشتباهات تایپی که امیدوارم به زودی مرتفع گردد.\n",
            "موفق باشید.\n",
            "خیلی عالیه واقعأ ازتون ممنونم\n",
            "خیلی عالیه واقعأ ازتون ممنونم\n",
            "به نظر من اصل مطلب در کتاب ادا نشده است! اسامی خیلی از فرمانده ها و معاونان دلاور اون روزها و رشادت هاشان ذکر نشده! و اون چند نفری هم که ذکر شده خیلی سرسری ازش گذشته شده!\n",
            "به نظر من اصل مطلب در کتاب ادا نشده است! اسامی خیلی از فرمانده ها و معاونان دلاور اون روزها و رشادت هاشان ذکر نشده! و اون چند نفری هم که ذکر شده خیلی سرسری ازش گذشته شده!\n",
            "کتاب مصاحبه ایست که با شهید صیاد شیرازی در باره ی آزادسازی خرمشهر صورت گرفته و اشاره به این موضوع که سخت ترین عملیات ها مربوط به عبور از رودخانه میشود که در عملیات بیت المقدس هم همین اتفاق افتاد و عبور از کارون و کرخه و ...و ساختن پل های شناور برای عبور لژستیک و نیروها کار بسیار طاقت فرسایی بود که با همت و عزم نیروهای ارتش و سپاه این کار سخت ممکن شد ومنجر به آزاد سازی خرمشهر شد تقریبا به اواسط کتاب که میرسیم هیجان برای رسیدن به این اتفاق تاریخی در خواننده رخ میده بخصوص وقتی که خلبان هلی کوپتر برای بررسی اوضاع و تعداد اسرا فریاد میزنه که چقدر اسیر عراقی ! با امداد خداوند 14500اسیر بدست نیروهای ما به اسارت در می آیند در حالیکه تعداد نیروهای خودی بسیار کمتر بودند هیچوقت صحنه های اسارت آنها را که از تلویزیون نمایش داده می شد را فراموش نمیکنم واقعا اگر میخواستند با دست خالی هم میتونستن بر نیروهای ما غالب بشوند اما خواست خداوند بر یاری ما قرار داشت و خونین شهر به آغوش وطن باز گشت.\n",
            "کتاب مصاحبه ایست که با شهید صیاد شیرازی در باره ی آزادسازی خرمشهر صورت گرفته و اشاره به این موضوع که سخت ترین عملیات ها مربوط به عبور از رودخانه میشود که در عملیات بیت المقدس هم همین اتفاق افتاد و عبور از کارون و کرخه و ...و ساختن پل های شناور برای عبور لژستیک و نیروها کار بسیار طاقت فرسایی بود که با همت و عزم نیروهای ارتش و سپاه این کار سخت ممکن شد ومنجر به آزاد سازی خرمشهر شد تقریبا به اواسط کتاب که میرسیم هیجان برای رسیدن به این اتفاق تاریخی در خواننده رخ میده بخصوص وقتی که خلبان هلی کوپتر برای بررسی اوضاع و تعداد اسرا فریاد میزنه که چقدر اسیر عراقی ! با امداد خداوند 14500اسیر بدست نیروهای ما به اسارت در می آیند در حالیکه تعداد نیروهای خودی بسیار کمتر بودند هیچوقت صحنه های اسارت آنها را که از تلویزیون نمایش داده می شد را فراموش نمیکنم واقعا اگر میخواستند با دست خالی هم میتونستن بر نیروهای ما غالب بشوند اما خواست خداوند بر یاری ما قرار داشت و خونین شهر به آغوش وطن باز گشت.\n",
            "سلام کتاب خوبی است. ممنون\n",
            "سلام کتاب خوبی است. ممنون\n",
            "بسیار زیبا و سرشار از نکات زیبا و معانے عمیق\n",
            "بسیار زیبا و سرشار از نکات زیبا و معانے عمیق\n",
            "کتاب خوبی بود اما من کوری رو ترجیح میدم تقریبا داستان یکیه\n",
            "کتاب خوبی بود اما من کوری رو ترجیح میدم تقریبا داستان یکیه\n",
            "هنوز تمومش نکردم اما در کل جالبه\n",
            "هنوز تمومش نکردم اما در کل جالبه\n",
            "من نمیتونم دریافتش کنم روی نمونه یا گزینه پایین ک میزنم مینویسه ارتباط برقرار نشد\n",
            "من نمیتونم دریافتش کنم روی نمونه یا گزینه پایین ک میزنم مینویسه ارتباط برقرار نشد\n",
            "جلال آل احمد در غرب زدگی گفته منظور کامو از طاعون ماشینیسم است\n",
            "جلال آل احمد در غرب زدگی گفته منظور کامو از طاعون ماشینیسم است\n",
            "کتاب بسیار خوبی بود.واقعا عالی بود.ممنون از طاقچه.\n",
            "کتاب بسیار خوبی بود.واقعا عالی بود.ممنون از طاقچه.\n",
            "تعداد کتابهارو بیشتر کنید\n",
            "تعداد کتابهارو بیشتر کنید\n",
            "مناسب منتقدان و نویسندگان به همراه اندیش ‌هایی در باب رئالیسم\n",
            "مناسب منتقدان و نویسندگان به همراه اندیش ‌هایی در باب رئالیسم\n",
            "کتاب خوبی هست و ترجمه خوبی هم داره. نکات جالبی داره که میتونه تو بهتر شدن کیفیت زندگی تاثیر مثبت بذاره. 👌\n",
            "کتاب خوبی هست و ترجمه خوبی هم داره. نکات جالبی داره که میتونه تو بهتر شدن کیفیت زندگی تاثیر مثبت بذاره. \n",
            "من این کتابو دارم و بارها با دقت خوندم.عالیه\n",
            "من این کتابو دارم و بارها با دقت خوندم.عالیه\n",
            "این کتاب رو 7 ماه پیش خوندم و عالی بود. و واقعا درسته عشق به هرچیزی اون رو خلق میکنه.\n",
            "این کتاب رو 7 ماه پیش خوندم و عالی بود. و واقعا درسته عشق به هرچیزی اون رو خلق میکنه.\n",
            "چی بگم والا ن خب ن بد\n",
            "چی بگم والا ن خب ن بد\n",
            "ابتدا باید نقاط ضعف وقوت خود را پیدا کرد و بعدموضوعات پیشنهادی کتاب را تمرینی برای ذهن  قرار داد تا  در ذهن  نهادینه شود. کتاب مفیدی بود.\n",
            "ابتدا باید نقاط ضعف وقوت خود را پیدا کرد و بعدموضوعات پیشنهادی کتاب را تمرینی برای ذهن  قرار داد تا  در ذهن  نهادینه شود. کتاب مفیدی بود.\n",
            "عالیه ،متشکرم\n",
            "عالیه ،متشکرم\n",
            "به نسبت کتابهای دیگر این نویسنده ، جذابتر است.\n",
            "ولی به اندازه ای که از اون تعریف شده بود منو جذب نکرد.\n",
            "به نسبت کتابهای دیگر این نویسنده ، جذابتر است.\n",
            "ولی به اندازه ای که از اون تعریف شده بود منو جذب نکرد.\n",
            "واقعا زیبا بود...ولی آدمی همیشه فراموش کار هست . امیدوارم همه به حدیث خویشتن برسن و با اون زندگی کنن.\n",
            "واقعا زیبا بود...ولی آدمی همیشه فراموش کار هست . امیدوارم همه به حدیث خویشتن برسن و با اون زندگی کنن.\n",
            "یه رمان مشابه کیمیاگر میخوام متاسفاته اینو خوندم وگرنه باز همینو میخوندم\n",
            "یه رمان مشابه کیمیاگر میخوام متاسفاته اینو خوندم وگرنه باز همینو میخوندم\n",
            "این کتاب رمان هست یانه\n",
            "این کتاب رمان هست یانه\n",
            "سلام. من این کتاب رو قبلا خوندم. خیلی قشنگه. احتمالا ترجمش خوب نبوده که جذب نشدین. البته باید عرفان دوست داشته باشین تا جذب بشین.\n",
            "سلام. من این کتاب رو قبلا خوندم. خیلی قشنگه. احتمالا ترجمش خوب نبوده که جذب نشدین. البته باید عرفان دوست داشته باشین تا جذب بشین.\n",
            "من نتونستم تمومش کنم😒 موضوعش بد نبود ولی اصلا جذبم نکرد ، شایدم ترجمش جالب نبود😩\n",
            "من نتونستم تمومش کنم موضوعش بد نبود ولی اصلا جذبم نکرد ، شایدم ترجمش جالب نبود\n",
            "کی کد عضویت داره لطفا به من هم بده\n",
            "کی کد عضویت داره لطفا به من هم بده\n",
            "فوق العاده است ❤️\n",
            "فوق العاده است \n",
            "زمانی که خوندمش پراز حسهای خوب شدم\n",
            "زمانی که خوندمش پراز حسهای خوب شدم\n",
            "کتاب های پائولو همیشه گیرایی خاصی برام داشت و داره.بعد از خوندن چندتا از کتاب هاش ناخودآگاه دنبال نشانه میگردی تو دنیای اطراف و زندگی ات ولی نمیدونم چرا کتاب خیانت اش رو حذف کردند از طاقچه\n",
            "کتاب های پائولو همیشه گیرایی خاصی برام داشت و داره.بعد از خوندن چندتا از کتاب هاش ناخودآگاه دنبال نشانه میگردی تو دنیای اطراف و زندگی ات ولی نمیدونم چرا کتاب خیانت اش رو حذف کردند از طاقچه\n",
            "با اعتماد به نظرات خوندم و از ماجراش خوشمان آمد :) مطمئنا هرکسی یه گنجی داره که بش نرسیده و موانعی جلوشونو گرفته که دل کندن ازشون سخته مثل خانواده،درامد،عشق،جایگاه اجتماعی ولی حتما میشه با ی سرنخایی رشد کرد و بهشون رسید... وسطاشم جمله های قشنگی دیدم.پیشنهاد میشه\n",
            "با اعتماد به نظرات خوندم و از ماجراش خوشمان آمد :) مطمئنا هرکسی یه گنجی داره که بش نرسیده و موانعی جلوشونو گرفته که دل کندن ازشون سخته مثل خانواده،درامد،عشق،جایگاه اجتماعی ولی حتما میشه با ی سرنخایی رشد کرد و بهشون رسید... وسطاشم جمله های قشنگی دیدم.پیشنهاد میشه\n",
            "آخرین اخبار\n",
            "شنبه ۲ آذر ۱۳۹۸ - ۱۴:۴۹ GMT 11:19\n",
            "شنبه / ۲ آذر ۱۳۹۸ / ۱۴:۲۶ دسته‌بندی: ارتباطات و فناوری اطلاعات کد خبر: 98090200823 خبرنگار : 71088\n",
            "اینترنت خانگی از دقایقی دیگر وصل می‌شود\n",
            "اینترنت\n",
            "اینترنت خانگی تهران و کلانشهرهای کشور تا دقایقی دیگر برقرار می‌شود.\n",
            "یک منبع آگاه در وزارت ارتباطات در گفت‌وگو با ایسنا تایید کرد که با دریافت مجوزهای لازم، اینترنت خانگی تهران و تعداد زیادی از کلانشهرهای کشور تا دقایقی دیگر برقرار خواهد شد.\n",
            "اینترنت خانگی چند استان برقرار شد\n",
            "بررسی‌های ایسنا نشان می‌دهد روز گذشته اینترنت خانگی در چند استان کشور برقرار شده است.\n",
            "گزارش واصله از خبرنگاران ایسنا در استان‌های خراسان شمالی، خراسان جنوبی، گلستان، سمنان، یزد، همدان، چهارمحال و بختیاری، اردبیل، زنجان و ایلام حاکی از برقراری اینترنت‌های خانگی در این استان‌هاست.\n",
            "امروز همچنین یکی از رسانه‌های داخلی اعلام کرد که اینترنت همراه نیز احتمالا تا صبح فردا یکشنبه ۳ آذر وصل می‌شود.\n",
            "ایسنا در تلاش است در خصوص این موضوع اطلاعات بیشتری کسب کند.\n",
            "آخرین اخبار\n",
            "شنبه ۲ آذر ۱۳۹۸ - ۱۴:۴۹ GMT 11:19\n",
            "شنبه / ۲ آذر ۱۳۹۸ / ۱۴:۲۶ دسته‌بندی: ارتباطات و فناوری اطلاعات کد خبر: 98090200823 خبرنگار : 71088\n",
            "اینترنت خانگی از دقایقی دیگر وصل می‌شود\n",
            "اینترنت\n",
            "اینترنت خانگی تهران و کلانشهرهای کشور تا دقایقی دیگر برقرار می‌شود.\n",
            "یک منبع آگاه در وزارت ارتباطات در گفت‌وگو با ایسنا تایید کرد که با دریافت مجوزهای لازم، اینترنت خانگی تهران و تعداد زیادی از کلانشهرهای کشور تا دقایقی دیگر برقرار خواهد شد.\n",
            "اینترنت خانگی چند استان برقرار شد\n",
            "بررسی‌های ایسنا نشان می‌دهد روز گذشته اینترنت خانگی در چند استان کشور برقرار شده است.\n",
            "گزارش واصله از خبرنگاران ایسنا در استان‌های خراسان شمالی، خراسان جنوبی، گلستان، سمنان، یزد، همدان، چهارمحال و بختیاری، اردبیل، زنجان و ایلام حاکی از برقراری اینترنت‌های خانگی در این استان‌هاست.\n",
            "امروز همچنین یکی از رسانه‌های داخلی اعلام کرد که اینترنت همراه نیز احتمالا تا صبح فردا یکشنبه ۳ آذر وصل می‌شود.\n",
            "ایسنا در تلاش است در خصوص این موضوع اطلاعات بیشتری کسب کند.\n",
            "کتاب خوبی بود.\n",
            "بنظرم ما کتاب. میخونیم که چیزهای جدید از انسان ها وفرهنگ وکشورهای دیگه یادبگیریم وبتونیم باهم مقایسه کنیم وبعد نتیجه گیری کنیم.شخصی گفته بودن که این کتاب فلانه وپائولو اینجور.\n",
            "ما کتاب رو میخونیم وفکر میکنیم نه اینکه همشو قبول داشته باشیم.\n",
            "نتیجه ای که من ازاین کتاب گرفتم اینه که بایداصل خودمونو نادیده نگیرم.\n",
            "کتاب خوبی بود.\n",
            "بنظرم ما کتاب. میخونیم که چیزهای جدید از انسان ها وفرهنگ وکشورهای دیگه یادبگیریم وبتونیم باهم مقایسه کنیم وبعد نتیجه گیری کنیم.شخصی گفته بودن که این کتاب فلانه وپائولو اینجور.\n",
            "ما کتاب رو میخونیم وفکر میکنیم نه اینکه همشو قبول داشته باشیم.\n",
            "نتیجه ای که من ازاین کتاب گرفتم اینه که بایداصل خودمونو نادیده نگیرم.\n",
            "من خوده کتاب و دارم و خوندم واقعا یکی از بهترین کتاباییه ک میشه خوند\n",
            "من خوده کتاب و دارم و خوندم واقعا یکی از بهترین کتاباییه ک میشه خوند\n",
            "دوستان نت مخابرات تو تهران کسی وصل شده؟؟؟؟؟\n",
            "دوستان نت مخابرات تو تهران کسی وصل شده؟؟؟؟؟\n",
            "رمانی بسیار تاثیر گذار\n",
            "رمانی بسیار تاثیر گذار\n",
            "این کتاب باعث بوجود اومدن انسانی دیگه میشه در همه خوانندگان\n",
            "این کتاب باعث بوجود اومدن انسانی دیگه میشه در همه خوانندگان\n",
            "دارم می میرم از بی نتی خدااااایا تا کی آخه😭😭😭\n",
            "دارم می میرم از بی نتی خدااااایا تا کی آخه\n",
            "من صوتیشو قبلا گوش دادم خیلی لذت بردم واقعا عالیه\n",
            "من صوتیشو قبلا گوش دادم خیلی لذت بردم واقعا عالیه\n",
            "بهترییییییییییییییییینه و بس\n",
            "باید عمیق و با حوصله بخونیدش ،سرسری ازش نگذرید\n",
            "فوق العادست به معنای واقعی کلمه\n",
            "بهترییییییییییییییییینه و بس\n",
            "باید عمیق و با حوصله بخونیدش ،سرسری ازش نگذرید\n",
            "فوق العادست به معنای واقعی کلمه\n",
            "با همه سختی ها و مشکلات به راهت ادامه بده تا به آرزو و خواسته ات برسی.\n",
            "به نظرم خیلی تاتیر داره برای روش زندگی، مخصوصا برای نوجوان ها.\n",
            "با همه سختی ها و مشکلات به راهت ادامه بده تا به آرزو و خواسته ات برسی.\n",
            "به نظرم خیلی تاتیر داره برای روش زندگی، مخصوصا برای نوجوان ها.\n",
            "اولش که میخونی جذبت میکنه اما هر چی میره جلوتر حس میکنی خبری از اون پیام های مثبت نیست و حتی یه سری نکات اشتباه هم داره و میشه گفت محتوای کاملا شعاری داره.\n",
            "ازینکه از مسلمان ها و اسلام هم صحبت شد در این کتاب خیلی خوشم نیومد به نکات مثبتی اشاره نشده بود.\n",
            "اولش که میخونی جذبت میکنه اما هر چی میره جلوتر حس میکنی خبری از اون پیام های مثبت نیست و حتی یه سری نکات اشتباه هم داره و میشه گفت محتوای کاملا شعاری داره.\n",
            "ازینکه از مسلمان ها و اسلام هم صحبت شد در این کتاب خیلی خوشم نیومد به نکات مثبتی اشاره نشده بود.\n",
            "من صوتیش رو گوش دادم با صدای محسن نامجوی عزیز عالییییییییی\n",
            "من صوتیش رو گوش دادم با صدای محسن نامجوی عزیز عالییییییییی\n",
            "عالی بود به معنای واقعی کلمه.\n",
            "عالی بود به معنای واقعی کلمه.\n",
            "اولا کتاب رو با ترجمه آرش حجازی بخونید. دوما در نظر اول کتاب بسیار پر مغز و عالی به نظر میاد که شما رو مجبور میکنه ساعت ها به اون فکر کنید ولی با کمی تامل متوجه میشید که موضوعاتی در کتاب گفته شده که نقدهای جدی به آن وارده.\n",
            "اولا کتاب رو با ترجمه آرش حجازی بخونید. دوما در نظر اول کتاب بسیار پر مغز و عالی به نظر میاد که شما رو مجبور میکنه ساعت ها به اون فکر کنید ولی با کمی تامل متوجه میشید که موضوعاتی در کتاب گفته شده که نقدهای جدی به آن وارده.\n",
            "توصیه میکنم نسخه صوتی این کتاب با صدای نامجو رو گوش بدید. اجرای عالی داره همراه با پس زمینه های صوتی زیبا.\n",
            "توصیه میکنم نسخه صوتی این کتاب با صدای نامجو رو گوش بدید. اجرای عالی داره همراه با پس زمینه های صوتی زیبا.\n",
            "من این کتاب رو دارم\n",
            "خیلی خوب بود\n",
            "توش میشه نکته مهم زیادی پیدا کرد واسه زندگی\n",
            "بخونینش...\n",
            "من این کتاب رو دارم\n",
            "خیلی خوب بود\n",
            "توش میشه نکته مهم زیادی پیدا کرد واسه زندگی\n",
            "بخونینش...\n",
            "این کتاب یه کپی از دفتر ششم مولوی هست.\n",
            "این کتاب یه کپی از دفتر ششم مولوی هست.\n",
            "کتاب خوبیه حتما بخونینش\n",
            "کتاب خوبیه حتما بخونینش\n",
            "من صوتی این کتاب رو گوش دادم.کلا خیلی از کتابای پائولو کوئلیو خوشم نمیاد ولی این یکی عالی بود واقعا با لذت گوش دادم میشه گفت یه روش زندگیه\n",
            "من صوتی این کتاب رو گوش دادم.کلا خیلی از کتابای پائولو کوئلیو خوشم نمیاد ولی این یکی عالی بود واقعا با لذت گوش دادم میشه گفت یه روش زندگیه\n",
            "بهترین کتابی که تا حالا خوندم سالی یکبار باید خونده بشه به شخصه منو عاشق صحرا و ماجراجویی کرد :)\n",
            "بهترین ترجمه هم متعلق به آقای آرش حجازی هست ان شاالله اکثر اونایی که درک خوبی از کتاب داشتن افسانه شخصی شون رو جستجو کنن و موفق باشن :)\n",
            "بهترین کتابی که تا حالا خوندم سالی یکبار باید خونده بشه به شخصه منو عاشق صحرا و ماجراجویی کرد :)\n",
            "بهترین ترجمه هم متعلق به آقای آرش حجازی هست ان شاالله اکثر اونایی که درک خوبی از کتاب داشتن افسانه شخصی شون رو جستجو کنن و موفق باشن :)\n",
            "زندگی و نشانه ها\n",
            "بدنبال نشانه ها رفتن یک چیزه و درک درست از نشانه ها یک چیز دیگر\n",
            "زندگی و نشانه ها\n",
            "بدنبال نشانه ها رفتن یک چیزه و درک درست از نشانه ها یک چیز دیگر\n",
            "جالب نبود... .\n",
            "جالب نبود... .\n",
            "کلا نوشته های پائولو کوئیلو سلیقه من نیست اما نسخه صوتی کیمیاگر رو گوش دادم و واقعا دوستش داشتم. جز کتابهایی هست که پیشنهاد میکنم در خوندنش شک نکنید. هم معنی و مفهوم عمیقی داره و هم خیلی خلاقانه روایت شده. پیشنهاد میکنم نسخه صوتی با صدای محسن نامجو رو گوش کنید.\n",
            "کلا نوشته های پائولو کوئیلو سلیقه من نیست اما نسخه صوتی کیمیاگر رو گوش دادم و واقعا دوستش داشتم. جز کتابهایی هست که پیشنهاد میکنم در خوندنش شک نکنید. هم معنی و مفهوم عمیقی داره و هم خیلی خلاقانه روایت شده. پیشنهاد میکنم نسخه صوتی با صدای محسن نامجو رو گوش کنید.\n",
            "در مدت کمتر از یک روز تمامش کردم،زیبا بود،به آدم انگیزه میده\n",
            "در مدت کمتر از یک روز تمامش کردم،زیبا بود،به آدم انگیزه میده\n",
            "بسیارکتاب آ مو زنده ای بود\n",
            "بسیارکتاب آ مو زنده ای بود\n",
            "عالی بود📚🍃🙂\n",
            "عالی بود\n",
            "جا داره یکبار دیگه هم بخونمش\n",
            "جا داره یکبار دیگه هم بخونمش\n",
            "خب درسته پنج تومن پولی نیس ولی ینی چی که نسخه الکترونیک و چاپیش قیمتش یکی باشه؟\n",
            "خب درسته پنج تومن پولی نیس ولی ینی چی که نسخه الکترونیک و چاپیش قیمتش یکی باشه؟\n",
            "عالییییی خیلی قشنگ و اموزنده واقعا درک بالایی میخواد فهمیدن این کتاب\n",
            "عالییییی خیلی قشنگ و اموزنده واقعا درک بالایی میخواد فهمیدن این کتاب\n",
            "واقعا کسل کننده اس بزور تا صفحه ی ۱۵۰ خوندم نمیدونم چرا انقد این کتاب معروف و پرفروش بوده!!! یا ترجمه مشکل داره یا خود کتاب مدلش اینه ک خوشم نیومد\n",
            "واقعا کسل کننده اس بزور تا صفحه ی ۱۵۰ خوندم نمیدونم چرا انقد این کتاب معروف و پرفروش بوده!!! یا ترجمه مشکل داره یا خود کتاب مدلش اینه ک خوشم نیومد\n",
            "من این کتاب رو راهنمایی بودم شروع کردم به خوندن\n",
            "انقدر بدم اومد ولش کردم 😐\n",
            "و هنوز هم نفهمیدم چرا اینهمه معروفه و طرفدار داره؟!\n",
            "نمیدونم سن مناسبی نبود یا ترجمه بد بود، ولی دیگه دوست نداشتم سمتش برم!\n",
            "من این کتاب رو راهنمایی بودم شروع کردم به خوندن\n",
            "انقدر بدم اومد ولش کردم \n",
            "و هنوز هم نفهمیدم چرا اینهمه معروفه و طرفدار داره؟!\n",
            "نمیدونم سن مناسبی نبود یا ترجمه بد بود، ولی دیگه دوست نداشتم سمتش برم!\n",
            "چیزی که من از این کتاب فهمیدم اینه که وقتی به دنبال ارزو ها نریم یه ادم مرده به حساب میایم فرقی نمیکنه هدفمون چقدر خطرناک باشه و حتی جونمون هم به خطر بندازه در هر صورت باید دنبال چیزی که میخوایم باشیم. داستان در طول کتاب به خوبی گفته شده و جای ابهامی نمیزاره ولی اخر کتاب واقعا عالی تموم میشه اصلا انتظار همچین پایانی رو نداشتم.\n",
            "چیزی که من از این کتاب فهمیدم اینه که وقتی به دنبال ارزو ها نریم یه ادم مرده به حساب میایم فرقی نمیکنه هدفمون چقدر خطرناک باشه و حتی جونمون هم به خطر بندازه در هر صورت باید دنبال چیزی که میخوایم باشیم. داستان در طول کتاب به خوبی گفته شده و جای ابهامی نمیزاره ولی اخر کتاب واقعا عالی تموم میشه اصلا انتظار همچین پایانی رو نداشتم.\n",
            "من این کتاب رو از روی فایل pdf خوندم که نه نام ناشر داشت و نه مترجم. کتاب از نظر روایی زیبا نوشته شده بود. تونست یکی مثل من رو که نسبت به کتابهای عرفانی و معنوی موضع دارم رو راحت به دنبال خودش بکشه. از پائولو کوییلو خوشم نمی اومد بخاطر توصیفی که دیگران از کاراش داشتن. میگفتن درباره عرفان مینویسه. اینکه خودم رو مجبور به خوندن یکی از آثارش کنم برام چالش برانگیز بود. اما از کتابش لذت بردم. احتمالا باز هم از کاراش خواهم خوند.\n",
            "کتابش من رو یاد کتاب \"شب آتشین\" اثر \"اریک امانوئل اشمیت\" انداخت. یه جورایی حال و هوای اون رو داشت.\n",
            "من این کتاب رو از روی فایل pdf خوندم که نه نام ناشر داشت و نه مترجم. کتاب از نظر روایی زیبا نوشته شده بود. تونست یکی مثل من رو که نسبت به کتابهای عرفانی و معنوی موضع دارم رو راحت به دنبال خودش بکشه. از پائولو کوییلو خوشم نمی اومد بخاطر توصیفی که دیگران از کاراش داشتن. میگفتن درباره عرفان مینویسه. اینکه خودم رو مجبور به خوندن یکی از آثارش کنم برام چالش برانگیز بود. اما از کتابش لذت بردم. احتمالا باز هم از کاراش خواهم خوند.\n",
            "کتابش من رو یاد کتاب \"شب آتشین\" اثر \"اریک امانوئل اشمیت\" انداخت. یه جورایی حال و هوای اون رو داشت.\n",
            "کتاب دل نواز ولی در مباحثی وارد میشه که ریشه در مسیحیت دارن گاهن\n",
            "کتاب دل نواز ولی در مباحثی وارد میشه که ریشه در مسیحیت دارن گاهن\n",
            "خیلی دوستش داشتم ولی وقتی فهمیدم کتاب ی مشکلاتی داره قلبم شکست💔\n",
            "خیلی دوستش داشتم ولی وقتی فهمیدم کتاب ی مشکلاتی داره قلبم شکست\n",
            "من که چیزی از این کتاب دستگیرم نشد، دوستان برداشت خودشان را بفرمایند استفاده کنیم\n",
            "من که چیزی از این کتاب دستگیرم نشد، دوستان برداشت خودشان را بفرمایند استفاده کنیم\n",
            "البته که باید با دید باز مذهبی خونده بشه ، چون ممکنه اعتقادات تخریب بشه ، ولی در عین حال کتابیه که موضوع اصلیش یعنی بازگشت به خود ، مهم تر از فرعیاتش هست .\n",
            "در ضمن برگرفته از یکی از اشعار مثنوی معنوی جناب مولانا ست . چیز جدیدی نیست ، و اینکه مولاناخداوندگار توی چند بیت این رو روایت کرده ، ایشون اومده کشش داده فقط ...\n",
            "البته که باید با دید باز مذهبی خونده بشه ، چون ممکنه اعتقادات تخریب بشه ، ولی در عین حال کتابیه که موضوع اصلیش یعنی بازگشت به خود ، مهم تر از فرعیاتش هست .\n",
            "در ضمن برگرفته از یکی از اشعار مثنوی معنوی جناب مولانا ست . چیز جدیدی نیست ، و اینکه مولاناخداوندگار توی چند بیت این رو روایت کرده ، ایشون اومده کشش داده فقط ...\n",
            "عالی بود و انسان را به اصل انسانیت و پیدا کردن گوهر خودش راهنمایی میکنه و خیلی استادانه مرحله مرحله آدم را میبره تا به مقصود که همانا گنج درون انسان است میرسی فقط میشه گفت خود پائولو جادوگر است\n",
            "عالی بود و انسان را به اصل انسانیت و پیدا کردن گوهر خودش راهنمایی میکنه و خیلی استادانه مرحله مرحله آدم را میبره تا به مقصود که همانا گنج درون انسان است میرسی فقط میشه گفت خود پائولو جادوگر است\n",
            "کتاب فوق العاده زیبایی است.\n",
            "من نمیدانم که فرق میان کتاب خوب و بد چیست؟\n",
            "هر کتابی با یک فکر و اندیشه خاصی نوشته می‌شود و سال های مختلف را دربر می‌گیرد تا کامل گردد اما ما وقت خود را صرف نمیکنیم تا با همان حس که کتاب نوشته گردیده، بخوانیم. کتاب را باید با عشق خواند همان طور که ایجاب می‌کند باید آن حس را برای خود ایجاد کرد.\n",
            "کتاب فوق العاده زیبایی است.\n",
            "من نمیدانم که فرق میان کتاب خوب و بد چیست؟\n",
            "هر کتابی با یک فکر و اندیشه خاصی نوشته می‌شود و سال های مختلف را دربر می‌گیرد تا کامل گردد اما ما وقت خود را صرف نمیکنیم تا با همان حس که کتاب نوشته گردیده، بخوانیم. کتاب را باید با عشق خواند همان طور که ایجاب می‌کند باید آن حس را برای خود ایجاد کرد.\n",
            "خیلی شیرینه. آدم واقعا لذت میبره از خوندنش\n",
            "خیلی شیرینه. آدم واقعا لذت میبره از خوندنش\n",
            "کتاب کیمیاگر یکی از جذاب ترین کتابایی بود که تاحالا خوندم میشه گفت یه حالت انگیزشی داشت.\n",
            "داستان چوپانی که به دنبال حدیث خویش میره به دنبال رویایی که در ذهن داره و برخلاف خیلی از اطرافیانش که بخاطر فراهم کردن نیاز های اساسی زندگی شون میل رسیدن به آرزوهاشون رو درخود سرکوب کردن حاضر نیست ازشون دست بکشه کیمیاگر یعنی کسی که میتونه ماهیت چیزی رو تغییر بده یا چیز جدیدی رو خلق کنه و این کتاب بهمون نشون میده که هرکدوم از ما کیمیاگر زندگی خودمون هستیم البته پائولو در این کتاب به خوبی سختی های مسیر رو نشون داده و ثابت کرده که رسیدن به رویاها بدون پرداخت هزینه ممکن نیست گرچه زندگی نکردن در مسیر رویاها هم خودش هزینه ای رو دربرداره.\n",
            "این کتاب بهمون میگه هرکسی توی این دنیا یه گنج داره گنجی که میتونه نسبت بهش بیتفاوت باشه رهاش کنه و یه زندگی معمولی رو داشته باشه مثل خیلی از دور و وریامون یا اینکه نه بره دنبال گنجش گنجی که به قول نویسنده فقط مخصوص خودشه کاری که اون فرد براش ساخته شده و اگه با تموم وجودش اون رو طلب کنه کائنات به تکاپو میفتن تا اون رو به خواسته اش برسونن البته این کتاب یه نکته جالب دیگه هم داره و اون اینکه ما نعمت هایی زیادی داریم که قدرشون رو نمی دونیم فرصت هایی که با بیتفاوتی از کنارشون میگذریم در واقع ما هر آنچه که نیاز داریم در وجودمون داریم اما یادمون میره و ازش غافلیم البته بنظرم ضعف کوچولوی کتاب این بود که نویسنده یه سری جاها از حوادث سریع عبور کرده بود و خیلی بهشون نپرداخته بود ولی بقیه اش عالی بود\n",
            "خلاصه اینکه این کتاب پر از حرف و نکته است و سیر داستانی جذابی هم داره پس از دستش ندین دوستان😉\n",
            "کتاب کیمیاگر یکی از جذاب ترین کتابایی بود که تاحالا خوندم میشه گفت یه حالت انگیزشی داشت.\n",
            "داستان چوپانی که به دنبال حدیث خویش میره به دنبال رویایی که در ذهن داره و برخلاف خیلی از اطرافیانش که بخاطر فراهم کردن نیاز های اساسی زندگی شون میل رسیدن به آرزوهاشون رو درخود سرکوب کردن حاضر نیست ازشون دست بکشه کیمیاگر یعنی کسی که میتونه ماهیت چیزی رو تغییر بده یا چیز جدیدی رو خلق کنه و این کتاب بهمون نشون میده که هرکدوم از ما کیمیاگر زندگی خودمون هستیم البته پائولو در این کتاب به خوبی سختی های مسیر رو نشون داده و ثابت کرده که رسیدن به رویاها بدون پرداخت هزینه ممکن نیست گرچه زندگی نکردن در مسیر رویاها هم خودش هزینه ای رو دربرداره.\n",
            "این کتاب بهمون میگه هرکسی توی این دنیا یه گنج داره گنجی که میتونه نسبت بهش بیتفاوت باشه رهاش کنه و یه زندگی معمولی رو داشته باشه مثل خیلی از دور و وریامون یا اینکه نه بره دنبال گنجش گنجی که به قول نویسنده فقط مخصوص خودشه کاری که اون فرد براش ساخته شده و اگه با تموم وجودش اون رو طلب کنه کائنات به تکاپو میفتن تا اون رو به خواسته اش برسونن البته این کتاب یه نکته جالب دیگه هم داره و اون اینکه ما نعمت هایی زیادی داریم که قدرشون رو نمی دونیم فرصت هایی که با بیتفاوتی از کنارشون میگذریم در واقع ما هر آنچه که نیاز داریم در وجودمون داریم اما یادمون میره و ازش غافلیم البته بنظرم ضعف کوچولوی کتاب این بود که نویسنده یه سری جاها از حوادث سریع عبور کرده بود و خیلی بهشون نپرداخته بود ولی بقیه اش عالی بود\n",
            "خلاصه اینکه این کتاب پر از حرف و نکته است و سیر داستانی جذابی هم داره پس از دستش ندین دوستان\n",
            "نسخه چاپی رو خوندم واقعا عالیه. نظر ثبت میکنم که دوستانی که بخش کتابگردی رو نگاه میکنن به خوندن این کتاب قشنگ دعوت کنم.\n",
            "نسخه چاپی رو خوندم واقعا عالیه. نظر ثبت میکنم که دوستانی که بخش کتابگردی رو نگاه میکنن به خوندن این کتاب قشنگ دعوت کنم.\n",
            "عالی بود واقعا لذت بردم\n",
            "عالی بود واقعا لذت بردم\n",
            "این کتاب واقعا عالی بود\n",
            "کمک میکنه شاید ما هم بتونیم حدیث خویش رو پیدا کنیم\n",
            "و....\n",
            "من واقعا نمیفهمم چطور چند نفر یه ستاره دادن؟مگه داریم؟😶\n",
            "این کتاب واقعا عالی بود\n",
            "کمک میکنه شاید ما هم بتونیم حدیث خویش رو پیدا کنیم\n",
            "و....\n",
            "من واقعا نمیفهمم چطور چند نفر یه ستاره دادن؟مگه داریم؟\n",
            "پائولو عالیه مثل همیشه عالییییییی\n",
            "پائولو عالیه مثل همیشه عالییییییی\n",
            "قطعا باید از رادیو تشکر کنم که سبب آشنایی شد چون قسمتی از این کتاب رو از رادیو و در راه منزل شنیدم و همون موقع شیفته کتاب شدم،،\n",
            "کتاب عمیقیه، زیباست، این از اندک کتابهایی بود که نسخه صوتی ش رو تهیه کردم و موقع خواب گوش میکردم\n",
            "قطعا باید از رادیو تشکر کنم که سبب آشنایی شد چون قسمتی از این کتاب رو از رادیو و در راه منزل شنیدم و همون موقع شیفته کتاب شدم،،\n",
            "کتاب عمیقیه، زیباست، این از اندک کتابهایی بود که نسخه صوتی ش رو تهیه کردم و موقع خواب گوش میکردم\n",
            "بیشتراز۱۰۰جلد کتاب مطالعه کردم هیچ کدوم واسم کیمیاگر نشد.این کتاب باید هر۳ماه یک مرتبه خوند پر از درس و اندرز\n",
            "بیشتراز۱۰۰جلد کتاب مطالعه کردم هیچ کدوم واسم کیمیاگر نشد.این کتاب باید هر۳ماه یک مرتبه خوند پر از درس و اندرز\n",
            "من خوندمش اما معنی خیلی از حرف هایی که میزد و نفهمیدم احساس می کنم باید دوباره برگردم از اول بخونم و بیشتر دربارش فکر کنم\n",
            "من خوندمش اما معنی خیلی از حرف هایی که میزد و نفهمیدم احساس می کنم باید دوباره برگردم از اول بخونم و بیشتر دربارش فکر کنم\n",
            "این کتاب اصلا یک کتاب معمولی نیست خیلی فرق داره به نظر من این ی کتاب فوق العاده اس عاااااشق این کتابم\n",
            "این کتاب اصلا یک کتاب معمولی نیست خیلی فرق داره به نظر من این ی کتاب فوق العاده اس عاااااشق این کتابم\n",
            "تاثیر خاصی تو زندگیم نداشت فقط قشنگ بود ورویای ودرضمن دزدی از مولانا،بخوتید ادبیاتتون تفویت شه وسرگرمیه\n",
            "تاثیر خاصی تو زندگیم نداشت فقط قشنگ بود ورویای ودرضمن دزدی از مولانا،بخوتید ادبیاتتون تفویت شه وسرگرمیه\n",
            "کتاب بسیار زیبا،تک تک جملاتش با معنا و مفهوم،بسیار فلسفی\n",
            "بی خود نیست که جزو کتاب های مطرح جهانه\n",
            "کتاب بسیار زیبا،تک تک جملاتش با معنا و مفهوم،بسیار فلسفی\n",
            "بی خود نیست که جزو کتاب های مطرح جهانه\n",
            "سرکاری\n",
            "سرکاری\n",
            "فوق العااااااااده\n",
            "تا الان هیچ کتابی رو دستش نزده\n",
            "هر کسی هم قدرت درک مطالبش نداره\n",
            "فوق العااااااااده\n",
            "تا الان هیچ کتابی رو دستش نزده\n",
            "هر کسی هم قدرت درک مطالبش نداره\n",
            "هرچی از زیبایی این کتاب بگم، کم گفتم. واقعا که فوق‌العاده هستش💛\n",
            "هرچی از زیبایی این کتاب بگم، کم گفتم. واقعا که فوق‌العاده هستش\n",
            "کتاب کیمیا گر یه کتاب خوب و درست حسابی.حتما بخونید.\n",
            "کتاب کیمیا گر یه کتاب خوب و درست حسابی.حتما بخونید.\n",
            "از جمله کتابایی که خوندنش رو به همه توصیه میکنم. کتاب کم نظیری هست، بسیار جذاب و پندآمیز. برای من که از تمام کتابای پائولو کوئیلو جالب تر بود.\n",
            "از جمله کتابایی که خوندنش رو به همه توصیه میکنم. کتاب کم نظیری هست، بسیار جذاب و پندآمیز. برای من که از تمام کتابای پائولو کوئیلو جالب تر بود.\n",
            "کتاب خوبی بود.البته من چاپیشو خوندم.لب مطلب اینه که می خواد بگه همه چیز به خودت و به درونت بستگی داره.هر چیزی که برای رسیدن به هر هدفی بخوای توی خودت هست.همین!☺\n",
            "کتاب خوبی بود.البته من چاپیشو خوندم.لب مطلب اینه که می خواد بگه همه چیز به خودت و به درونت بستگی داره.هر چیزی که برای رسیدن به هر هدفی بخوای توی خودت هست.همین!\n",
            "کتابی سنگین و سرشار از نماد های گوناگون\n",
            "برای درک کامل این کتاب باید در فلسفه مطالعه گسترده داشته باشید\n",
            "کتابی سنگین و سرشار از نماد های گوناگون\n",
            "برای درک کامل این کتاب باید در فلسفه مطالعه گسترده داشته باشید\n",
            "جالب بود. درسهای زیادی ازش گرفتم\n",
            "جالب بود. درسهای زیادی ازش گرفتم\n",
            "امتیاز: ۳.۵\n",
            "ژانر: ادبی\n",
            "من کتاب رو با ترجمه فرزانه فرزاد خوندم که ترجمه متوسطی بود. داستانی نمادین و انگیزشی درمورد اینکه انسان باید به ندای دلش توجه کنه. اثر از درس‌ها و پند‌های مختلف پره که در عین حال تامل‌برانگیز و انگیزشی هست. نویسنده با تعداد معدودی شخصیت مخاطب رو به سفری میبره که تجربیات خوبی رو میتونه به ارمغان بیاره. سرعت روند داستان خوبه و نثر کتاب هم کارش رو انجام میده. یکبار خوندن این اثر ضرری به کسی نمیزنه.\n",
            "امتیاز: ۳.۵\n",
            "ژانر: ادبی\n",
            "من کتاب رو با ترجمه فرزانه فرزاد خوندم که ترجمه متوسطی بود. داستانی نمادین و انگیزشی درمورد اینکه انسان باید به ندای دلش توجه کنه. اثر از درس‌ها و پند‌های مختلف پره که در عین حال تامل‌برانگیز و انگیزشی هست. نویسنده با تعداد معدودی شخصیت مخاطب رو به سفری میبره که تجربیات خوبی رو میتونه به ارمغان بیاره. سرعت روند داستان خوبه و نثر کتاب هم کارش رو انجام میده. یکبار خوندن این اثر ضرری به کسی نمیزنه.\n",
            "کتاب خوب بود البته هر سلیقه ای را در بر نمی گرفت من خودم عاشق داستان های پرهیاهویی هستم که به صورتی حرفه ای و ادبی نوشته شدن و البته مملو از ماجرا و اتفاقات جدید هستند.\n",
            "اما من به عنوان یک کتاب خوان هیچ وقت نمیتونم به یک کتاب حتی اگر خیلی بد باشه یا نویسندش مورد علاقه من نباشه نمره بدی بدم و هر اثری از نظر من احترام و ویژگی خاص خودش رو داره.👍😊\n",
            "کتاب خوب بود البته هر سلیقه ای را در بر نمی گرفت من خودم عاشق داستان های پرهیاهویی هستم که به صورتی حرفه ای و ادبی نوشته شدن و البته مملو از ماجرا و اتفاقات جدید هستند.\n",
            "اما من به عنوان یک کتاب خوان هیچ وقت نمیتونم به یک کتاب حتی اگر خیلی بد باشه یا نویسندش مورد علاقه من نباشه نمره بدی بدم و هر اثری از نظر من احترام و ویژگی خاص خودش رو داره.\n",
            "مدت ها بود می خواستم این کتاب رو بخونم ولی اصلا نظرم رو جلب نکرد.\n",
            "مدت ها بود می خواستم این کتاب رو بخونم ولی اصلا نظرم رو جلب نکرد.\n",
            "کوئیلو یه آدم فرقه گراست،تو این اثرش هم پر از نماد ها و اعداد فراماسونری هستش،هدف نهایی این کتاب این هستش که،اسلام را ناچیز و ضعیف و افراطی و بد جلوه بده،مسیحیت رو دینی از بین رفته و فراماسونری و فرقه گرایی رو خوب و کامل و کمک کننده برای ادامه ی زندگی جلوه بده،حواستون باشه چی میخونید،من خودم بعد خوندن این کتاب،۱۲ صفحه نقدش رو نوشتم،کلی مطلب دیگه هستش که طول میکشه گفتنش،نقدش رو حتما بخونید تا دچار شستشویه مغزی نشید،فقط داستانه سطحی رو نبینید،روزهاتون به کام،شب هاتون پر از آرامش.\n",
            "کوئیلو یه آدم فرقه گراست،تو این اثرش هم پر از نماد ها و اعداد فراماسونری هستش،هدف نهایی این کتاب این هستش که،اسلام را ناچیز و ضعیف و افراطی و بد جلوه بده،مسیحیت رو دینی از بین رفته و فراماسونری و فرقه گرایی رو خوب و کامل و کمک کننده برای ادامه ی زندگی جلوه بده،حواستون باشه چی میخونید،من خودم بعد خوندن این کتاب،۱۲ صفحه نقدش رو نوشتم،کلی مطلب دیگه هستش که طول میکشه گفتنش،نقدش رو حتما بخونید تا دچار شستشویه مغزی نشید،فقط داستانه سطحی رو نبینید،روزهاتون به کام،شب هاتون پر از آرامش.\n",
            "بسیار ضعیف بود.و در عین حال به صورت کاملا پنهانی به تخریب دین اسلام پرداخته بود.\n",
            "قبلا شنیده بودم نوشته های پائلو کوئلو مشکل داره\n",
            "بسیار ضعیف بود.و در عین حال به صورت کاملا پنهانی به تخریب دین اسلام پرداخته بود.\n",
            "قبلا شنیده بودم نوشته های پائلو کوئلو مشکل داره\n",
            "حیف وقتم\n",
            "واقعا کتاب چرندی بود\n",
            "حیف وقتم\n",
            "واقعا کتاب چرندی بود\n",
            "تقربیا مثل شازده کوچولو بود،من ک خیلی لذت بردم!\n",
            "تقربیا مثل شازده کوچولو بود،من ک خیلی لذت بردم!\n",
            "تا قبل این کتاب علاقمند به خواندن کتاب نبودم\n",
            "اما کیماگر‌ واقعا جذبم کرد.راحت میشد آدم خودشو جای شخصیت اصلی قرار بده و از خوندنش لذت ببره.\n",
            "اگر‌ کتابهای ناب دیگر میشناسید خواهشا به من پیشنهاد بدید\n",
            "تا قبل این کتاب علاقمند به خواندن کتاب نبودم\n",
            "اما کیماگر‌ واقعا جذبم کرد.راحت میشد آدم خودشو جای شخصیت اصلی قرار بده و از خوندنش لذت ببره.\n",
            "اگر‌ کتابهای ناب دیگر میشناسید خواهشا به من پیشنهاد بدید\n",
            "واقعا این کتاب رو توصیه میکنم. من که از خوندنش لذت بردم.\n",
            "واقعا این کتاب رو توصیه میکنم. من که از خوندنش لذت بردم.\n",
            "عالییییییییییییییی بود\n",
            "عالییییییییییییییی بود\n",
            "چقدری زیبا بود لذت بردم از خوندنش حتما بخونیددد\n",
            "چقدری زیبا بود لذت بردم از خوندنش حتما بخونیددد\n",
            "حتما بخونید عالیه\n",
            "حتما بخونید عالیه\n",
            "یک بار خوندن این کتاب اصلا نمیتونه عمق مطلب رو براتون عدا کنه پیشنهاد میشه چند بار که شده این کتاب رو با حوصله بخونید تا زیبایی و عمیقی این اثر رو درک کنید\n",
            "یک بار خوندن این کتاب اصلا نمیتونه عمق مطلب رو براتون عدا کنه پیشنهاد میشه چند بار که شده این کتاب رو با حوصله بخونید تا زیبایی و عمیقی این اثر رو درک کنید\n",
            "بینظیر💛🧡💜❤️👍🏽\n",
            "بینظیر\n",
            "خوندن این کتابو به همه پیشنهاد میکنم، عالی و تاثیرگذار\n",
            "خوندن این کتابو به همه پیشنهاد میکنم، عالی و تاثیرگذار\n",
            "عالی بود همین\n",
            "عالی بود همین\n",
            "من اصلا از خوندن این کتاب لذت نبردم و واقعا متعجبم چطور اینقدر از این کتاب تعریف میکنن نویسنده خیلی تلاش کرده بود که معناگرایانه بنوییه ولی متاسفانه موفق نبوده و اونقدرا هم که بقیه میگن شما رو به فکر وا میداره این طور نیست\n",
            "من اصلا از خوندن این کتاب لذت نبردم و واقعا متعجبم چطور اینقدر از این کتاب تعریف میکنن نویسنده خیلی تلاش کرده بود که معناگرایانه بنوییه ولی متاسفانه موفق نبوده و اونقدرا هم که بقیه میگن شما رو به فکر وا میداره این طور نیست\n",
            "من کتاب صوتیشو بیشتر دوست داشتم\n",
            "من کتاب صوتیشو بیشتر دوست داشتم\n",
            "هر چیزی که آدم از یه داستان میتونه انتظار داشته باشه تو این کتاب پیدا میشه .کتابی که سرشار از جمله هایی که آدم رو به فکر فرو میبره سرشار از عشق و روحیه و پند...\n",
            "هر چیزی که آدم از یه داستان میتونه انتظار داشته باشه تو این کتاب پیدا میشه .کتابی که سرشار از جمله هایی که آدم رو به فکر فرو میبره سرشار از عشق و روحیه و پند...\n",
            "قلبم درد گرفته از این فضای فرهنگی مسموم نظرات دوستان رو خوندم بر چه اساسی نظر میدید؟ بنده حقیر از دنیا بی خبر رو هم راهنمایی کنید...\n",
            "تا اونجا که من میدونم پائولو کوئیلو نویسنده فراماسونری(شیطان پرست) است دوستان نقد پژوهشگر شهریار زر شناس رو درباری پائولو کوئیلو و اثارش رو تو اپارت ببینید/ یا کمی تو اینترنت درباره این نویسنده مبتذل تحقیق کنید.\n",
            "قلبم درد گرفته از این فضای فرهنگی مسموم نظرات دوستان رو خوندم بر چه اساسی نظر میدید؟ بنده حقیر از دنیا بی خبر رو هم راهنمایی کنید...\n",
            "تا اونجا که من میدونم پائولو کوئیلو نویسنده فراماسونری(شیطان پرست) است دوستان نقد پژوهشگر شهریار زر شناس رو درباری پائولو کوئیلو و اثارش رو تو اپارت ببینید/ یا کمی تو اینترنت درباره این نویسنده مبتذل تحقیق کنید.\n",
            "خلوتی کو؟ که خیالات تو آنجا ببرم...\n",
            "دیده بر بندم و دل را به تماشا ببرم...\n",
            "خلوتی کو؟ که خیالات تو آنجا ببرم...\n",
            "دیده بر بندم و دل را به تماشا ببرم...\n",
            "خدایی کتابش فوووق العادست\n",
            "خدایی کتابش فوووق العادست\n",
            "کتاب جالبیه\n",
            "البته بستگی به ذاءقه خواننده داره\n",
            "باید خاص پسند و متفکر و عنق نگر باشی که درکش کنی و گرنه برات لذتی نداره\n",
            "توصیه میکنم زمانی بخونیدش که واقعا طالب خوندن باشین نه صرفا واسه وقت پر کردن\n",
            "دیگر کتابهای نویسنده هم ارزش خوندن داره\n",
            "کتاب جالبیه\n",
            "البته بستگی به ذاءقه خواننده داره\n",
            "باید خاص پسند و متفکر و عنق نگر باشی که درکش کنی و گرنه برات لذتی نداره\n",
            "توصیه میکنم زمانی بخونیدش که واقعا طالب خوندن باشین نه صرفا واسه وقت پر کردن\n",
            "دیگر کتابهای نویسنده هم ارزش خوندن داره\n",
            "یعنی کتابی از این بهترم هست؟ عالی بود.\n",
            "یعنی کتابی از این بهترم هست؟ عالی بود.\n",
            "این کتاب یه شاهکاربه تمام معناست\n",
            "این کتاب یه شاهکاربه تمام معناست\n",
            "کتاب عالییه.حتما بخرینش ارزششو داره.مخصوصا بعضی جاهاش که یه چیزای آموزشی خوبی میگه.در کل کتاب قشنگیه.\n",
            "کتاب عالییه.حتما بخرینش ارزششو داره.مخصوصا بعضی جاهاش که یه چیزای آموزشی خوبی میگه.در کل کتاب قشنگیه.\n",
            "این کتاب باعث میشه حتی برای لحظه ای هم که شده به رویاها و ارزوها مون فکر کنیم و اینکه هیچ وقت برای محقق کردنشون دیر نیست و باید به نشانه ها ایمان داشته باشیم شاید با قدم برداشتن در مسیر افسانه شخصیمون ناخواسته باعث شیم افراد دیگری در مسیر ارزوهاشون قرار بگیرند و اینکه هیچ نیروی در جهان از بین نمیره و تنها در چرخش است پس رفتار ما بر جهان پیرامونمون قطعا تاثیر گذاره . جز بهترین کتاب هایی بود که خوندم و قطعا دوباره به سراغش میرم . و....\n",
            "بیرون ز تو نیست انچه در عالم هست ازخود بطلب هر انچه خواهی که تویی\n",
            "این کتاب باعث میشه حتی برای لحظه ای هم که شده به رویاها و ارزوها مون فکر کنیم و اینکه هیچ وقت برای محقق کردنشون دیر نیست و باید به نشانه ها ایمان داشته باشیم شاید با قدم برداشتن در مسیر افسانه شخصیمون ناخواسته باعث شیم افراد دیگری در مسیر ارزوهاشون قرار بگیرند و اینکه هیچ نیروی در جهان از بین نمیره و تنها در چرخش است پس رفتار ما بر جهان پیرامونمون قطعا تاثیر گذاره . جز بهترین کتاب هایی بود که خوندم و قطعا دوباره به سراغش میرم . و....\n",
            "بیرون ز تو نیست انچه در عالم هست ازخود بطلب هر انچه خواهی که تویی\n",
            "عاشقین ادبیات نباید از این کتاب بگذرن 😍\n",
            "عاشقین ادبیات نباید از این کتاب بگذرن \n",
            "سلام...به این جمله دقت کنید:\n",
            "ناتانائیل !باید تو در خویشتن،تمام کتابها را بسوزانی...\n",
            "کاربرانی که آمادگی روحی و روانی دارند که به این جمله جامه عمل بپوشانیم و در نوشته هایمان،از دل خود بنویسیم،بدون هیچ اطلاعات کتابی،اینجا اعلام آمادگی کنند...🙂⚘\n",
            "سلام...به این جمله دقت کنید:\n",
            "ناتانائیل !باید تو در خویشتن،تمام کتابها را بسوزانی...\n",
            "کاربرانی که آمادگی روحی و روانی دارند که به این جمله جامه عمل بپوشانیم و در نوشته هایمان،از دل خود بنویسیم،بدون هیچ اطلاعات کتابی،اینجا اعلام آمادگی کنند...\n",
            "شگفتا!ناتانائیل تو خدارا در تملک داری و خود از آن بی خبر بوده ای...\n",
            "ناتانائیل،تنها خداست که نمیتوان در انتظارش بود،در انتظار خدا بودن،ناتانائیل،یعنی در نیافتن اینکه اورا هم اکنون در وجود خود داری....❤❤\n",
            "ترجمه مهستی بحرینی👆\n",
            "شگفتا!ناتانائیل تو خدارا در تملک داری و خود از آن بی خبر بوده ای...\n",
            "ناتانائیل،تنها خداست که نمیتوان در انتظارش بود،در انتظار خدا بودن،ناتانائیل،یعنی در نیافتن اینکه اورا هم اکنون در وجود خود داری....\n",
            "ترجمه مهستی بحرینی\n",
            "اصلا ترجمش خوب نیست‌\n",
            "اصلا ترجمش خوب نیست‌\n",
            "ی جورایی خوبه،، بهتر از اینم هست :/\n",
            "ی جورایی خوبه،، بهتر از اینم هست :/\n",
            "ناتانیل ای کاش عظمت در نگاه تو باشد نه در چیزیی که به ان می نگریی\n",
            "سهراب;من نمیدانم که چرا میگویند اسب حیوان نحیبی است کبوتر زیباست و چرا در قفس هیچ کسی کرکس نیست گل شبدر چه کم از لاله قرمز دارد.....چشم ها را باید شست جور دیگر باید دید\n",
            "ناتانیل ای کاش عظمت در نگاه تو باشد نه در چیزیی که به ان می نگریی\n",
            "سهراب;من نمیدانم که چرا میگویند اسب حیوان نحیبی است کبوتر زیباست و چرا در قفس هیچ کسی کرکس نیست گل شبدر چه کم از لاله قرمز دارد.....چشم ها را باید شست جور دیگر باید دید\n",
            "زیباست...\n",
            "زیباست...\n",
            "درک عمیق می خواهد و فهمی عظیم و روحیه ای لطیف! عالی❤\n",
            "درک عمیق می خواهد و فهمی عظیم و روحیه ای لطیف! عالی\n",
            "\"کاش کتابم به تو بیاموزد که بیش تر از این کتاب به خود بپردازی... و سپس بیش تر از خود به دیگر چیزها\"\n",
            "📚مائده های زمینی/آندره ژید\n",
            "خیلی لطیف بود مثل نسیمی که صورت آدمو نوازش می کنه.\n",
            "من با ترجمه ی خانم بحرینی خوندم ولی به نظرم ترجمه ی آقای داریوش پرویز ادبی تر و زیباتره.\n",
            "\"کاش کتابم به تو بیاموزد که بیش تر از این کتاب به خود بپردازی... و سپس بیش تر از خود به دیگر چیزها\"\n",
            "مائده های زمینی/آندره ژید\n",
            "خیلی لطیف بود مثل نسیمی که صورت آدمو نوازش می کنه.\n",
            "من با ترجمه ی خانم بحرینی خوندم ولی به نظرم ترجمه ی آقای داریوش پرویز ادبی تر و زیباتره.\n",
            "تو دبیرستان هم داشتیم. یادش بخیر\n",
            "تو دبیرستان هم داشتیم. یادش بخیر\n",
            "کتاب به نفس خودش فوق العادس...اما ترجمه یکم لنگ میزنه...\n",
            "کتاب به نفس خودش فوق العادس...اما ترجمه یکم لنگ میزنه...\n",
            "کتاب است که باید خوانده شود .ودر ک شود بسیار عالی است وزبان از توصیف این اثر ناتوان است.\"اگر روح کسی ارزش چیزی را دارد دلیل بر این است که بیش از دیگران سوخته است\"\n",
            "کتاب است که باید خوانده شود .ودر ک شود بسیار عالی است وزبان از توصیف این اثر ناتوان است.\"اگر روح کسی ارزش چیزی را دارد دلیل بر این است که بیش از دیگران سوخته است\"\n",
            "\"ناتانائیل، عظمت خدا باید در چشمان تو باشد،نه در آنچه به آن می نگری.\"\n",
            "\"ناتانائیل، عظمت خدا باید در چشمان تو باشد،نه در آنچه به آن می نگری.\"\n",
            "کتاب بسیار خوبی است. \n",
            "اگرچه در قرن  ۱۹ میلادی نوشته شده است  اما دکتر شریعتی در بعضی آثارش از ما ئده  های زمینی یاد کرده است.\n",
            "کتاب بسیار خوبی است. \n",
            "اگرچه در قرن  ۱۹ میلادی نوشته شده است  اما دکتر شریعتی در بعضی آثارش از ما ئده  های زمینی یاد کرده است.\n",
            "کتاب خوبیه برای کسایی که دختر دارن...ولی بیشتر بر مبنای تجربیات شخصیه نویسندست...نمیشه صد در صد نظرات رو تایید کرد\n",
            "کتاب خوبیه برای کسایی که دختر دارن...ولی بیشتر بر مبنای تجربیات شخصیه نویسندست...نمیشه صد در صد نظرات رو تایید کرد\n",
            "این کتاب خیلی عالی بود، لحظه‌های طنز همراه با لحظه‌های غم‌انگیز با قهرمان‌های کوچیکی که خیلی راحت میشد باهاشون ارتباط برقرار کرد. همین که ببینی چند تا نوجوون که خیلی متفاوت از ما نیستن میتونن اینقدر بزرگ بشن و به همه ثابت کنن که بچه نیستن بلکه رزمنده‌ان...\n",
            "این کتاب خیلی عالی بود، لحظه‌های طنز همراه با لحظه‌های غم‌انگیز با قهرمان‌های کوچیکی که خیلی راحت میشد باهاشون ارتباط برقرار کرد. همین که ببینی چند تا نوجوون که خیلی متفاوت از ما نیستن میتونن اینقدر بزرگ بشن و به همه ثابت کنن که بچه نیستن بلکه رزمنده‌ان...\n",
            "فوق العادہ بعد\n",
            "❤❤👏👏\n",
            "فوق العادہ بعد\n",
            "\n",
            "عالی بود:')\n",
            "عالی بود:')\n",
            "خواندن این گونه کتاب ها درسِ زندگی به آدم میده، ارزش ها و اهداف نسل های گذشته رو یادآوری می کنه و نمی گذاره هویت و فرهنگ و گذشته مان را فراموش کنیم... عالی بود..\n",
            "خواندن این گونه کتاب ها درسِ زندگی به آدم میده، ارزش ها و اهداف نسل های گذشته رو یادآوری می کنه و نمی گذاره هویت و فرهنگ و گذشته مان را فراموش کنیم... عالی بود..\n",
            "فیلمش دانشگاه پخش کرد و واقعا جذاب بود...یکی از همون اسرا هم استاد دانشگاهمونه و از تجربیاتش تو اون شرایط برامون گفت\n",
            "فیلمش دانشگاه پخش کرد و واقعا جذاب بود...یکی از همون اسرا هم استاد دانشگاهمونه و از تجربیاتش تو اون شرایط برامون گفت\n",
            "لطفا این کتاب رو در کتابخانه همگانی بذارید\n",
            "لطفا این کتاب رو در کتابخانه همگانی بذارید\n",
            "چندوقت پیش این کتاب رو خوندم وحالا که فکرمیکنم‌میبینم‌، قصه‌آن هنوز به خوبی یادم هست . دلیلش‌به‌نظرم‌‌جذابیت‌وگیرایی‌قصه‌است‌که‌ خواننده‌راهمراه‌خودمی‌کندویابه‌زبان‌دیگر‌خواننده‌باآن‌زندگی‌میکند.ودرآخر:خداوند به‌‌ رزمندگان شجاع کشورم ازجمله این بیست وسه نفر بسیجی‌قهرمان‌عاقبت بخیری عطا کند انشاءالله.\n",
            "چندوقت پیش این کتاب رو خوندم وحالا که فکرمیکنم‌میبینم‌، قصه‌آن هنوز به خوبی یادم هست . دلیلش‌به‌نظرم‌‌جذابیت‌وگیرایی‌قصه‌است‌که‌ خواننده‌راهمراه‌خودمی‌کندویابه‌زبان‌دیگر‌خواننده‌باآن‌زندگی‌میکند.ودرآخر:خداوند به‌‌ رزمندگان شجاع کشورم ازجمله این بیست وسه نفر بسیجی‌قهرمان‌عاقبت بخیری عطا کند انشاءالله.\n",
            "کتاب خیلی‌ قشنگ و‌ جالبی بود که بعثی ها ۲۳ تن از اسرای ایرانی نوجوون را ازشون استفاده تبلیغاتی میکنن ولی اونا مانع میشن و دست به کارایی مثه اعتصاب و... میزنن.\n",
            "کتاب خیلی‌ قشنگ و‌ جالبی بود که بعثی ها ۲۳ تن از اسرای ایرانی نوجوون را ازشون استفاده تبلیغاتی میکنن ولی اونا مانع میشن و دست به کارایی مثه اعتصاب و... میزنن.\n",
            "بسیار عالی و خوب\n",
            "بنظرم بخوبی فضای سخت اسارت رو به تصویر کشیده این کتاب .\n",
            "مخصوصا قسمت آخر کتاب که اوج داستانه\n",
            "بسیار عالی و خوب\n",
            "بنظرم بخوبی فضای سخت اسارت رو به تصویر کشیده این کتاب .\n",
            "مخصوصا قسمت آخر کتاب که اوج داستانه\n",
            "روایت کوتاه اما در عین حال کامل و شیرین؛ با ادبیات و نگارش عالی. خدا قوت و لعنت به صدام و پیروان جدید عربستانی اش\n",
            "روایت کوتاه اما در عین حال کامل و شیرین؛ با ادبیات و نگارش عالی. خدا قوت و لعنت به صدام و پیروان جدید عربستانی اش\n",
            "خیلی خوب ❤\n",
            "خیلی خوب \n",
            "روایتی تلخ با قلمی شیرین\n",
            "روایتی تلخ با قلمی شیرین\n",
            "سلام من کتاب ملاصالح از اسرای ابرانی رو هم خوندم جالبه این آقا هم از این نوجوان های اسیر میگن که چطور صدام ازشون استفاده ابزاری کرد\n",
            "سلام من کتاب ملاصالح از اسرای ابرانی رو هم خوندم جالبه این آقا هم از این نوجوان های اسیر میگن که چطور صدام ازشون استفاده ابزاری کرد\n",
            "بیست وسه نوجوان ایرانی بعد از اسارت در جنگ، مورد سواستفاده تبلیغاتی صدام قرار میگیرند. صدام قصد داشت با القای این فضا که این نوجوانان با اختیار خودشان به جبهه نیامده اند، رسانه ها را بر علیه ایران و انقلاب اسلامی بسیج کند. اما این شیرمردها برای جلوگیری از ایجاد فضای منفی علیه کشور و انقلاب، کاری بزرگ کردند که شرحش در کتاب آمده است. .\n",
            "در سال هشتاد و هشت، دو نانجیب به بهانه تقلب در انتخابات، علاوه بر تضعیف قدرت کشور، هجمه ی رسانه ای بزرگی علیه کشور به وجود آوردند. چقدر اون دوتا کوچولو بودند و چقدر این بیست و سه نفر بزرگ\n",
            "به نظرم با حذف مسائل کم اهمیت، حجم کتاب خیلی میتونست از این کمتر باشه.\n",
            "بیست وسه نوجوان ایرانی بعد از اسارت در جنگ، مورد سواستفاده تبلیغاتی صدام قرار میگیرند. صدام قصد داشت با القای این فضا که این نوجوانان با اختیار خودشان به جبهه نیامده اند، رسانه ها را بر علیه ایران و انقلاب اسلامی بسیج کند. اما این شیرمردها برای جلوگیری از ایجاد فضای منفی علیه کشور و انقلاب، کاری بزرگ کردند که شرحش در کتاب آمده است. .\n",
            "در سال هشتاد و هشت، دو نانجیب به بهانه تقلب در انتخابات، علاوه بر تضعیف قدرت کشور، هجمه ی رسانه ای بزرگی علیه کشور به وجود آوردند. چقدر اون دوتا کوچولو بودند و چقدر این بیست و سه نفر بزرگ\n",
            "به نظرم با حذف مسائل کم اهمیت، حجم کتاب خیلی میتونست از این کمتر باشه.\n",
            "عالی و جذاب\n",
            "لعنت به جنگ\n",
            "عالی و جذاب\n",
            "لعنت به جنگ\n",
            "چند سال پیش خوندمش زیبا و غرور آفرین بود\n",
            "داستان زندگی مترجمی که تو زندان کنار این بیست و سه نفر بود هم به اسم «ملاصالح» نوشته شده بخونید و لذت ببرید\n",
            "چند سال پیش خوندمش زیبا و غرور آفرین بود\n",
            "داستان زندگی مترجمی که تو زندان کنار این بیست و سه نفر بود هم به اسم «ملاصالح» نوشته شده بخونید و لذت ببرید\n",
            "کتاب عالی بود\n",
            "واقعا نویسنده مهارت زیادی در تصویر سازی و توصیف اتفاقات داشت خیلی قشنگ بود\n",
            "کتاب عالی بود\n",
            "واقعا نویسنده مهارت زیادی در تصویر سازی و توصیف اتفاقات داشت خیلی قشنگ بود\n",
            "عالی بود. واقعاً از بهترین آثار در زمینه اسارت آزادگان میهن اسلامی مون بود.....\n",
            "عالی بود. واقعاً از بهترین آثار در زمینه اسارت آزادگان میهن اسلامی مون بود.....\n",
            "کتاب نخرید قرار فیلمش بیاد\n",
            "کتاب نخرید قرار فیلمش بیاد\n",
            "عالی بود اراده استقامت و ایمان این افراد نسبت به سن کم شان فوق العاده بالا بود این از شاخصه های زمان دفاع مقدس است که رزمندگان برخلاف جثه نحیف شان شجاع، دلیر و نترسند و با دست خالی و سن کم تنها با ایمان که بهترین سلاح است به دل میدان میزنند کاش امروز هم از این نوجوان های شانزده ساله بیشتر پیدا بشود.\n",
            "عالی بود اراده استقامت و ایمان این افراد نسبت به سن کم شان فوق العاده بالا بود این از شاخصه های زمان دفاع مقدس است که رزمندگان برخلاف جثه نحیف شان شجاع، دلیر و نترسند و با دست خالی و سن کم تنها با ایمان که بهترین سلاح است به دل میدان میزنند کاش امروز هم از این نوجوان های شانزده ساله بیشتر پیدا بشود.\n",
            "خداییش باحال بود\n",
            "توصیه میکنم حتما بخونید\n",
            "خداییش باحال بود\n",
            "توصیه میکنم حتما بخونید\n",
            "امروز گفتند فیلمش رو میخوان بسازن 😀\n",
            "امیدوارم خوب پیش بره و عالی بسازن ...موفق باشند😁خیلی خوشحال شدم...😀😀😀\n",
            "امروز گفتند فیلمش رو میخوان بسازن \n",
            "امیدوارم خوب پیش بره و عالی بسازن ...موفق باشندخیلی خوشحال شدم...\n",
            "خیلی خوبه حتما بخونیدش\n",
            "👌👌👌👌\n",
            "خیلی خوبه حتما بخونیدش\n",
            "\n",
            "این کتاب یک کتاب فوق العاده ست. متن کتاب بسیار روان و دلنشین و داستان خیلی جذابه. به طوری که من این کتاب رو اصلا نتونستم زمین بذارم و همه ش تو ذهنم به این فکر میکردم که قراره چه اتفاقی برای این بزرگ مردها بیفته. و البته بعضی جا هاش هم بسیار درد ناک و غم انگیز بود و تلنگری برای من و امثال من که بفهمیم چه زحمت هایی برای حفظ ایران و انقلاب کشیده شده و به راحتی به این زحمات پشت نکنیم و سختی هایی که بعضا پیش میاد رو تحمل کنیم تا حداقل بخشی از دین خودمون رو به این عزیزان ادا کنیم و بدانیم که \" اِنَّ مَع العُسر یُسراً\"\n",
            "این کتاب یک کتاب فوق العاده ست. متن کتاب بسیار روان و دلنشین و داستان خیلی جذابه. به طوری که من این کتاب رو اصلا نتونستم زمین بذارم و همه ش تو ذهنم به این فکر میکردم که قراره چه اتفاقی برای این بزرگ مردها بیفته. و البته بعضی جا هاش هم بسیار درد ناک و غم انگیز بود و تلنگری برای من و امثال من که بفهمیم چه زحمت هایی برای حفظ ایران و انقلاب کشیده شده و به راحتی به این زحمات پشت نکنیم و سختی هایی که بعضا پیش میاد رو تحمل کنیم تا حداقل بخشی از دین خودمون رو به این عزیزان ادا کنیم و بدانیم که \" اِنَّ مَع العُسر یُسراً\"\n",
            "عالیه،حتما در سیر مطالعاتی قرارش بدید،تلخی اسارت به همراه چاشنی طنز\n",
            "عالیه،حتما در سیر مطالعاتی قرارش بدید،تلخی اسارت به همراه چاشنی طنز\n",
            "کتاب عالی هست.حتما بخونید\n",
            "کتاب عالی هست.حتما بخونید\n",
            "متن روان و زیبایی دارد بسیار لازم برای همه سنین\n",
            "متن روان و زیبایی دارد بسیار لازم برای همه سنین\n",
            "کتاب مفید و تاثیرگذاری بود، خواندن اون رو به همه نوجوانان وطنم توصیه می کنم\n",
            "کتاب مفید و تاثیرگذاری بود، خواندن اون رو به همه نوجوانان وطنم توصیه می کنم\n",
            "خاطرات بسیار جالب توجه و مفیدی داره خوندن این کتاب را به نسل جوان توصیه میکنم\n",
            "خاطرات بسیار جالب توجه و مفیدی داره خوندن این کتاب را به نسل جوان توصیه میکنم\n",
            "کتابی فوق العاده زیبا و متنی روان و گیرا حتما توصیه میکنم این کتاب مطالعه کنید و از خاطرات یک اثر جنگی لذت ببرید\n",
            "کتابی فوق العاده زیبا و متنی روان و گیرا حتما توصیه میکنم این کتاب مطالعه کنید و از خاطرات یک اثر جنگی لذت ببرید\n",
            "این هزینه برای کتاب الکترونیک کمی زیاده.اگه امکانش باشه با مبلغ کمتری بذارین که افراد بیشتری استفاده کنند.\n",
            "این هزینه برای کتاب الکترونیک کمی زیاده.اگه امکانش باشه با مبلغ کمتری بذارین که افراد بیشتری استفاده کنند.\n",
            "خدا رو شکر خوندم و خوب بود مخصوصا روحیه عجیب اسرای نوجوان مؤمن ایرانی...\n",
            "خدا رو شکر خوندم و خوب بود مخصوصا روحیه عجیب اسرای نوجوان مؤمن ایرانی...\n",
            "من خوشم نیومد\n",
            "\n",
            "من خوشم نیومد\n",
            "\n",
            "‍ 🔸ماه رمضان\n",
            "\n",
            "اولین روزه را گرفتیم ؛ با سختی بسیار. تشنگی کشنده و طاقت سوز بود ، اما به هر حال با صدای شلیک توپ افطار همه چیز تمام شد و روزمان را باز کردیم. در عراق ، اعلام موعد افطار نه با اذان که با شلیک توپ است، روزهای اول رمضان تا این توپ بخواهد شلیک بشود جان ما به لب می رسید!\n",
            "پیرمرد عرب روزه نمی گرفت؛ اما بیشتر از ما برای فرا رسیدن موعد افطار لحظه شماری می کرد. هر روز ، سه ساعت مانده به شلیک توپ افطار ، شمارش معکوس را شروع می کرد و به منصور می گفت: \" منصور ، سه ساعت دیگه.\"\n",
            "من بی اعلام پیرمرد هم می دانستم کی وقت اذان می شود. شعاع آفتاب که از پنجره زندان می افتاد روی دیوار ، تا برسد کنار در زندان ، مسیری دو ساعته را طی می کرد. وقتی آنجا ، در آخرین ایستگاه خود ، کاملا بی رنگ می شد، از پشت پنجره صدای شلیک توپ افطار به گوش می رسید.\n",
            "\n",
            "📚آن بیست و سه نفر ، احمد یوسف زاده\n",
            "#دفاع_مقدس\n",
            " ماه رمضان\n",
            "\n",
            "اولین روزه را گرفتیم ؛ با سختی بسیار. تشنگی کشنده و طاقت سوز بود ، اما به هر حال با صدای شلیک توپ افطار همه چیز تمام شد و روزمان را باز کردیم. در عراق ، اعلام موعد افطار نه با اذان که با شلیک توپ است، روزهای اول رمضان تا این توپ بخواهد شلیک بشود جان ما به لب می رسید!\n",
            "پیرمرد عرب روزه نمی گرفت؛ اما بیشتر از ما برای فرا رسیدن موعد افطار لحظه شماری می کرد. هر روز ، سه ساعت مانده به شلیک توپ افطار ، شمارش معکوس را شروع می کرد و به منصور می گفت: \" منصور ، سه ساعت دیگه.\"\n",
            "من بی اعلام پیرمرد هم می دانستم کی وقت اذان می شود. شعاع آفتاب که از پنجره زندان می افتاد روی دیوار ، تا برسد کنار در زندان ، مسیری دو ساعته را طی می کرد. وقتی آنجا ، در آخرین ایستگاه خود ، کاملا بی رنگ می شد، از پشت پنجره صدای شلیک توپ افطار به گوش می رسید.\n",
            "\n",
            "آن بیست و سه نفر ، احمد یوسف زاده\n",
            "#دفاع_مقدس\n",
            "خیلی جذاب و عالی... به همگی پیشنهاد میشه. \n",
            "خیلی جذاب و عالی... به همگی پیشنهاد میشه. \n",
            "کتاب قشنگی بود\n",
            "کتاب قشنگی بود\n",
            "نمونه اش که جالب بود\n",
            "نمونه اش که جالب بود\n",
            "یقینا چشیدن طعم تلخ اسارت جز برای آنانکه این جام بلا را عاشقانه سر کشیدند میسر نیست. در این کتاب می خوانیم چگونه فرزندان نوجوان روح الله کبیر به جهانیان نشان دادند که مرگ در راه رسیدن به آرمان هایشان به طفلی نوپا می ماند که تحت اراده ایشان است.\n",
            "ممکنه کتاب برای کسی که چون ماهی در آب قدرنعمت آزادی و بهای آن را نمی داند ممل و کسل کننده باشد اما کافیه سری به کشورهای همسایه من جمله عراق زد تا با سطر سطر این کتاب بتوان نفس کشید.\n",
            "نویسنده محترم جدای از دو ماجرای دیدار با صدام لعین و اعتصاب غذا باقی کتاب ساده و بی پیرایه به زندگی روزمره این چند قهرمان نوجوان و دنیای نوجوانی توأم با اسارتشان پرداخته است که خواندن کتاب برای نوجوانان نسل حاضر ممکن می کند.\n",
            "باشد تا فرزندان این مرز و بوم قدر لحظه لحظه آزادی و عزتشان را بدانند.\n",
            "یقینا چشیدن طعم تلخ اسارت جز برای آنانکه این جام بلا را عاشقانه سر کشیدند میسر نیست. در این کتاب می خوانیم چگونه فرزندان نوجوان روح الله کبیر به جهانیان نشان دادند که مرگ در راه رسیدن به آرمان هایشان به طفلی نوپا می ماند که تحت اراده ایشان است.\n",
            "ممکنه کتاب برای کسی که چون ماهی در آب قدرنعمت آزادی و بهای آن را نمی داند ممل و کسل کننده باشد اما کافیه سری به کشورهای همسایه من جمله عراق زد تا با سطر سطر این کتاب بتوان نفس کشید.\n",
            "نویسنده محترم جدای از دو ماجرای دیدار با صدام لعین و اعتصاب غذا باقی کتاب ساده و بی پیرایه به زندگی روزمره این چند قهرمان نوجوان و دنیای نوجوانی توأم با اسارتشان پرداخته است که خواندن کتاب برای نوجوانان نسل حاضر ممکن می کند.\n",
            "باشد تا فرزندان این مرز و بوم قدر لحظه لحظه آزادی و عزتشان را بدانند.\n",
            "خوب عالی خیلی خوب\n",
            "خوب عالی خیلی خوب\n",
            "کتاب رو برای بار دوم و با اطلاعات کاملتری از اسارت خوندم و این بار بیش از پیش لذت بردم.بارها و بارها خودم رو به جای\" آن بیست و سه نفر \"گذاشتم و با اونها سختی جنگ و اسارت رو چشیدم.مطمئنم هربار که این کتاب رو بخونم هرگز برام کهنه نمیشه.علی الخصوص لحظات بودن کنار \"ملا صالح قاری\"\n",
            "کتاب رو برای بار دوم و با اطلاعات کاملتری از اسارت خوندم و این بار بیش از پیش لذت بردم.بارها و بارها خودم رو به جای\" آن بیست و سه نفر \"گذاشتم و با اونها سختی جنگ و اسارت رو چشیدم.مطمئنم هربار که این کتاب رو بخونم هرگز برام کهنه نمیشه.علی الخصوص لحظات بودن کنار \"ملا صالح قاری\"\n",
            "عالیه و اتفاقاتش خیلی  متفاوته.\n",
            "عالیه و اتفاقاتش خیلی  متفاوته.\n",
            "بچه ها این کتاب و بخرم . ازش جوندن داره یا نه!!!\n",
            "بچه ها این کتاب و بخرم . ازش جوندن داره یا نه!!!\n",
            "وای خیلی کتاب قشنگیه من کتاب چاپیشو دارم\n",
            "وای خیلی کتاب قشنگیه من کتاب چاپیشو دارم\n",
            "کتاب قشنگیه ، پیشنهاد میشه\n",
            "کتاب قشنگیه ، پیشنهاد میشه\n",
            "خیلی عالی بود فقط چرا نصفه بود.\n",
            "خیلی عالی بود فقط چرا نصفه بود.\n",
            "من کتابش رو خوندم...خیلی خیلی زیباست...\n",
            "منتظر کتاب دومش هستم...ادامه داره دیگه؟!؟!\n",
            "من کتابش رو خوندم...خیلی خیلی زیباست...\n",
            "منتظر کتاب دومش هستم...ادامه داره دیگه؟!؟!\n",
            "خیلی زیبا بود هم گریه داشت و هم خنده علی الخصوص ملا صالح قاری....\n",
            "خیلی زیبا بود هم گریه داشت و هم خنده علی الخصوص ملا صالح قاری....\n",
            "من دوسش داشتم واقعا\n",
            "خصوصا ک تو برنامه ماه عسل یک توضیح خوبی در موردش دادند و از اون ببعد دنبال کتابش بودم.\n",
            "شرح روان و زیبایی داشت.\n",
            "باید اول از  استقامت همه بچه های جنگ و بعد از نویسنده کتاب تشکر کرد \n",
            "★★★★★\n",
            "من دوسش داشتم واقعا\n",
            "خصوصا ک تو برنامه ماه عسل یک توضیح خوبی در موردش دادند و از اون ببعد دنبال کتابش بودم.\n",
            "شرح روان و زیبایی داشت.\n",
            "باید اول از  استقامت همه بچه های جنگ و بعد از نویسنده کتاب تشکر کرد \n",
            "\n",
            "من به تازگی مجموعه کتابهای آقای دکتر مهدی خدامیان آرانی رو خوندم .توصیه میکنم هرکس  به زندگی امامان و پیامبر رحمت در قالب داستان علاقه داره این کتابها رو حتما بخونه...\n",
            "من به تازگی مجموعه کتابهای آقای دکتر مهدی خدامیان آرانی رو خوندم .توصیه میکنم هرکس  به زندگی امامان و پیامبر رحمت در قالب داستان علاقه داره این کتابها رو حتما بخونه...\n",
            "aallii\n",
            "aallii\n",
            "واقعا صادقانه بود\n",
            "واقعا صادقانه بود\n",
            "خوبه ولی حیف که مدت کوتاهی رو شرح میده\n",
            "خوبه ولی حیف که مدت کوتاهی رو شرح میده\n",
            "خیلی جالب بود. حیف که داستان یک مدت کوتاهی از این عزیزان بود.\n",
            "\n",
            "یک نکته جالب هم فلش بک به گذشته و دیارش بود.\n",
            "\n",
            "انتقادی که دارم.....البته چون راوی نمی خواد ریا بشه زیاد از زندان استخبارات و انواع شکنحه های وحشتناک آنجا نمی گه...زندان استخبارات مخوف ترین زندان صدام بود که راوی زیاد به وحشتناکی آن نپرداخت. البته من تحربه نکردم :) ولی مطالعه کردم در این باره :)\n",
            "خیلی جالب بود. حیف که داستان یک مدت کوتاهی از این عزیزان بود.\n",
            "\n",
            "یک نکته جالب هم فلش بک به گذشته و دیارش بود.\n",
            "\n",
            "انتقادی که دارم.....البته چون راوی نمی خواد ریا بشه زیاد از زندان استخبارات و انواع شکنحه های وحشتناک آنجا نمی گه...زندان استخبارات مخوف ترین زندان صدام بود که راوی زیاد به وحشتناکی آن نپرداخت. البته من تحربه نکردم :) ولی مطالعه کردم در این باره :)\n",
            "عااااالی. این کتاب رو به هیچ وجه از دست ندهید\n",
            "عااااالی. این کتاب رو به هیچ وجه از دست ندهید\n",
            "عالی بود ولی کاش یه کم طولانی تر بود و جزعیات بیشتری داشت\n",
            "عالی بود ولی کاش یه کم طولانی تر بود و جزعیات بیشتری داشت\n",
            "واقعا دست مریزاد. ممنون\n",
            "واقعا دست مریزاد. ممنون\n",
            "بسیارعالی بودان شاءالله خداحفظشون کنه توصیه میکنم حتماجوانهای عزیزبخونند.\n",
            "من خودم 14 سالم بودباکلی گرفتاری رفتم برای دفاع ازوطن وجانبازشدم باتمام وجوداین رویدادرودربخشهای ایران درک میکنم ولی تصورسختیهای این عزیزان دراسارت درکش سخته.\n",
            "بسیارعالی بودان شاءالله خداحفظشون کنه توصیه میکنم حتماجوانهای عزیزبخونند.\n",
            "من خودم 14 سالم بودباکلی گرفتاری رفتم برای دفاع ازوطن وجانبازشدم باتمام وجوداین رویدادرودربخشهای ایران درک میکنم ولی تصورسختیهای این عزیزان دراسارت درکش سخته.\n",
            "اینو لطفا بذارید برا تخفیف آخر هفته\n",
            "اینو لطفا بذارید برا تخفیف آخر هفته\n",
            "همون که در برنامه ماه  عسل94 هم دعوتشون کردن و ماجراشون تعریف کردن.\n",
            "همون که در برنامه ماه  عسل94 هم دعوتشون کردن و ماجراشون تعریف کردن.\n",
            "واقعا عالی بود\n",
            "توصیه میکنم حتما بخونید\n",
            "واقعا عالی بود\n",
            "توصیه میکنم حتما بخونید\n",
            "سلام \n",
            "واقعا کتاب مفید وآموزنده ای هست\n",
            "پیشنهاد میکنم بخونید\n",
            "سلام \n",
            "واقعا کتاب مفید وآموزنده ای هست\n",
            "پیشنهاد میکنم بخونید\n",
            "خیلی جالبه درس گرفتم خیلی\n",
            "خیلی جالبه درس گرفتم خیلی\n",
            "بار اول ارور می داد برای باز  شدن ولی بعد عالی بود\n",
            "بار اول ارور می داد برای باز  شدن ولی بعد عالی بود\n",
            "بسیار خوب بود علی نوری\n",
            "بسیار خوب بود علی نوری\n",
            "عالی بود. ممنون ازتخفیف نمایشگاهی\n",
            "عالی بود. ممنون ازتخفیف نمایشگاهی\n",
            "منو یاد مایک تایسون میندازه که به خاطر کبوترش قهرمان جهان شد\n",
            "منو یاد مایک تایسون میندازه که به خاطر کبوترش قهرمان جهان شد\n",
            "رومن گاری که خودش زمانی جزو نمایندگان فرانسه در سازمان ملل بوده، این کتاب رو بااسم مستعار و با کنایه به سیاستهای سازمان ملل و جو حاکمه بر سیاست بین الملل در زمان خودش مینویسه.که خیلی از این مسائل در حال حلضر هم وجود داره. مسائلی که مطرح میکنه میتونه با تغییر نامها به موضوعات مختلفی در زمانهای مختلف و حوزه های مختلفی هم تعمیم پیدا کنه. مثال مورد علاقه من که در کتاب مطرح شده gentleman agreement که به مواضع متضاد شوروی و آنریکا میگه یعنی هر طرفی موضعگیری کنه، طرف مقابل لازم نیست تامل کنه، باید بلافاصله موضع مخالف بگیره! این مسئله در فضاهای دوقطبی سیاسی و ایدئولوژیک و حتی منازعات یک جمع دوستانه نیز قابل مشاهده است که رومن گاری خیلی جالب اونو مطرح کرده.\n",
            "رومن گاری که خودش زمانی جزو نمایندگان فرانسه در سازمان ملل بوده، این کتاب رو بااسم مستعار و با کنایه به سیاستهای سازمان ملل و جو حاکمه بر سیاست بین الملل در زمان خودش مینویسه.که خیلی از این مسائل در حال حلضر هم وجود داره. مسائلی که مطرح میکنه میتونه با تغییر نامها به موضوعات مختلفی در زمانهای مختلف و حوزه های مختلفی هم تعمیم پیدا کنه. مثال مورد علاقه من که در کتاب مطرح شده gentleman agreement که به مواضع متضاد شوروی و آنریکا میگه یعنی هر طرفی موضعگیری کنه، طرف مقابل لازم نیست تامل کنه، باید بلافاصله موضع مخالف بگیره! این مسئله در فضاهای دوقطبی سیاسی و ایدئولوژیک و حتی منازعات یک جمع دوستانه نیز قابل مشاهده است که رومن گاری خیلی جالب اونو مطرح کرده.\n",
            "با توجه به حجم کم این کتاب ، خواندنش خالی از لطف نیست.\n",
            "با توجه به حجم کم این کتاب ، خواندنش خالی از لطف نیست.\n",
            "ترجمه  روان وخوبی داشت. اما خود داستان خوب شروع شده بود ولی از اواسط آن دچار شعار زدگی کلیشه ای شده بود بهر حال نویسنده معروفی  بود\n",
            "ترجمه  روان وخوبی داشت. اما خود داستان خوب شروع شده بود ولی از اواسط آن دچار شعار زدگی کلیشه ای شده بود بهر حال نویسنده معروفی  بود\n",
            "خوشمان آمد، خوب بود!\n",
            "خوشمان آمد، خوب بود!\n",
            "واقعا دمتون گرم عالیییی\n",
            "واقعا دمتون گرم عالیییی\n",
            "ثالث و طاقچه، ممنون از  هر دوی شما\n",
            "ثالث و طاقچه، ممنون از  هر دوی شما\n",
            "خیلی مزخرف بود\n",
            "خیلی مزخرف بود\n",
            "کتاب بدی نیست. ولی تعداد صفحات آن ۵ صفحه است که در مشخصات کتاب ۲۴ صفحه ذکر شده است.\n",
            "کتاب بدی نیست. ولی تعداد صفحات آن ۵ صفحه است که در مشخصات کتاب ۲۴ صفحه ذکر شده است.\n",
            "برای این کتاب انقدر ترجمه زیاده که آدم نمی‌دونه کدوم رو بخونه!!!\n",
            "برای این کتاب انقدر ترجمه زیاده که آدم نمی‌دونه کدوم رو بخونه!!!\n",
            "کتاب راز بیش از آن که در فضای حیات متعالی و زندگی معنوی و الهی باشد در فضای زیست حیوانی و ترغیب خوانندگان به دنیا گرایی شدید تر و انسان محوری عمیق تر است. شاهد این گفته هم این است که راندا برن بعد از یک دوره سختی و فروپاشی وضعیت مالی و اقتصادی، کتابی را از دخترش می گیرد که مطالعه کند و این کتاب و محتوای این کتاب با هدف پول دار شدن بیشتر به رشته تحریر در آمده است. این کتاب که توسط والاس واتلز به نام «علم پول دار شدن» نوشته شده است؛ خمیر مایه افکار راندا برن واقع شده است و وی در کتاب هایش چندین بار از اثر گذاری این کتاب بر اندیشه روندا بایرن و مبانی فکری اش نام می برد که بینش جدیدی به وی داده است.\n",
            "متاسفانه بعضی به غلط روندا بایرن را یک معلم معنویت و مروج دین و مذهب می شمارند و افکارش را افکار متعالی قلمداد می کنند؛ در حالی که افکار و اندیشه های راندا برن اصولا هیچ ارتباطی با عالم معنا و تمرینات روحی ندارد و اساسا وی یکی از عَلَم داران دنیازدگی و دنیاگرایی است و ایده‌های وی بر مبنای انسان محوری بنا شده است نه خدا محوری.\n",
            "این مطلب از توضیحات مندرج در سایت کتابراه گذاشته شد.\n",
            "کتاب راز بیش از آن که در فضای حیات متعالی و زندگی معنوی و الهی باشد در فضای زیست حیوانی و ترغیب خوانندگان به دنیا گرایی شدید تر و انسان محوری عمیق تر است. شاهد این گفته هم این است که راندا برن بعد از یک دوره سختی و فروپاشی وضعیت مالی و اقتصادی، کتابی را از دخترش می گیرد که مطالعه کند و این کتاب و محتوای این کتاب با هدف پول دار شدن بیشتر به رشته تحریر در آمده است. این کتاب که توسط والاس واتلز به نام «علم پول دار شدن» نوشته شده است؛ خمیر مایه افکار راندا برن واقع شده است و وی در کتاب هایش چندین بار از اثر گذاری این کتاب بر اندیشه روندا بایرن و مبانی فکری اش نام می برد که بینش جدیدی به وی داده است.\n",
            "متاسفانه بعضی به غلط روندا بایرن را یک معلم معنویت و مروج دین و مذهب می شمارند و افکارش را افکار متعالی قلمداد می کنند؛ در حالی که افکار و اندیشه های راندا برن اصولا هیچ ارتباطی با عالم معنا و تمرینات روحی ندارد و اساسا وی یکی از عَلَم داران دنیازدگی و دنیاگرایی است و ایده‌های وی بر مبنای انسان محوری بنا شده است نه خدا محوری.\n",
            "این مطلب از توضیحات مندرج در سایت کتابراه گذاشته شد.\n",
            "یعنی الان من عکس مازراتی 2017 با قیمت چند میلیارد رو به دیوار بزنم بدست میارمش! من ده سال کار کنم و چیزی هم نخورم بازم فکر نکنم تابلوی کائنات کاری بکنه که صاحب این ماشین بشم. توی مدیریت یه کلمه هست به اسم امکان پذیری یعنی اگر پیش زمینه های یک موضوع موجود نباشه اون طرح در ابتدا یا در ادامه با شکست روبرو میشه. البته تمرکز روی یک موضوع که از نظر منطقی ممکن باشه و تلاش لازم برای رسیدنش میتونه موثر باشه.\n",
            "یعنی الان من عکس مازراتی 2017 با قیمت چند میلیارد رو به دیوار بزنم بدست میارمش! من ده سال کار کنم و چیزی هم نخورم بازم فکر نکنم تابلوی کائنات کاری بکنه که صاحب این ماشین بشم. توی مدیریت یه کلمه هست به اسم امکان پذیری یعنی اگر پیش زمینه های یک موضوع موجود نباشه اون طرح در ابتدا یا در ادامه با شکست روبرو میشه. البته تمرکز روی یک موضوع که از نظر منطقی ممکن باشه و تلاش لازم برای رسیدنش میتونه موثر باشه.\n",
            "من اصلا نمیتونم باور کنم همچین چیزی رو\n",
            "من اصلا نمیتونم باور کنم همچین چیزی رو\n",
            "عالی چندتا از نسخه های چاپیه رازو دارم...جالبیش اینجاس واقعن عمل میکنه 😄\n",
            "عالی چندتا از نسخه های چاپیه رازو دارم...جالبیش اینجاس واقعن عمل میکنه \n",
            "خیلی عالی!\n",
            "خیلی عالی!\n",
            "مزخرف ترین کتابی که خوندم\n",
            "مزخرف ترین کتابی که خوندم\n",
            "چرت و پرته بیشتر مطالبش...انگار ک خدا رو نادیده گرفته\n",
            "چرت و پرته بیشتر مطالبش...انگار ک خدا رو نادیده گرفته\n",
            "فوق العاده اس،متشکرم\n",
            "فوق العاده اس،متشکرم\n",
            "عالیه! \n",
            "واقعا مجله خوندن توی آیپد لذت داره :)\n",
            "عالیه! \n",
            "واقعا مجله خوندن توی آیپد لذت داره :)\n",
            "شاهکارمحض. سه بار خواندم و هنوز سیر نشدم\n",
            "شاهکارمحض. سه بار خواندم و هنوز سیر نشدم\n",
            "یکی از بهترین کتابایی یود که تا حالا خوندم.\n",
            "اگه کسی از شما خوشش نیاد میتونه اعتراض کنه این مشکل شما نیست. پس از متفاوت بودن نترسید خودتون باشید و کاری رو که دوست دارید انجام بدید ولی مانند افراد عاقل یهش عمل کنید و سعی کنید به کسی آسیب نزنید. تو آزادی و تو این دنیا هستی که کارایی رو که دوست داری انجام بدی پس رویایی که تو سرته رو دنبال کن نذار اطرافیانت تو رو پشیمون کنن، داستان ادوارد رو فراموش نکن پسری که از رفتن به دنبال چیزی که خانواده‌اش ازش انتظار داشتن خودداری کرد و سعی کرد یه دنبال رویاش بره ولی خانواده ش ترجیح دادن اون تو تیمارستان بستری باشه تا اینکه کاری رو انجام بده که دوست داره. و ورونیکا دختری که زندگی ش یعد از دنبال نکردن آرزوهاش یه قدری یکنواخت بود که تصمیم گرفت بمیره، به این که دیگران راجع بهت چه فکری خواهند کرد اهمیت نده از متفاوت بودن نترس . برای عاقل بودن اول باید دیوانه باشی، دنبال آرزوهات برو تو نیازی نداری زندگیتو برای کسی توضیح بدی این زندگیه توست. اجازه نده زندگیت به پوچی بگذره و برای رسیدن به رویاها و آرزوهات تمام تلاشتو بکن.\n",
            "\"آگاهی از مرگ ما را تشویق میکند شدیدتر زندگی کنیم\" پس نهایت استفاده رو از هر روزت ببر و جوری زندگی کن که انگار فردا نخواهی بود.\n",
            "یکی از بهترین کتابایی یود که تا حالا خوندم.\n",
            "اگه کسی از شما خوشش نیاد میتونه اعتراض کنه این مشکل شما نیست. پس از متفاوت بودن نترسید خودتون باشید و کاری رو که دوست دارید انجام بدید ولی مانند افراد عاقل یهش عمل کنید و سعی کنید به کسی آسیب نزنید. تو آزادی و تو این دنیا هستی که کارایی رو که دوست داری انجام بدی پس رویایی که تو سرته رو دنبال کن نذار اطرافیانت تو رو پشیمون کنن، داستان ادوارد رو فراموش نکن پسری که از رفتن به دنبال چیزی که خانواده‌اش ازش انتظار داشتن خودداری کرد و سعی کرد یه دنبال رویاش بره ولی خانواده ش ترجیح دادن اون تو تیمارستان بستری باشه تا اینکه کاری رو انجام بده که دوست داره. و ورونیکا دختری که زندگی ش یعد از دنبال نکردن آرزوهاش یه قدری یکنواخت بود که تصمیم گرفت بمیره، به این که دیگران راجع بهت چه فکری خواهند کرد اهمیت نده از متفاوت بودن نترس . برای عاقل بودن اول باید دیوانه باشی، دنبال آرزوهات برو تو نیازی نداری زندگیتو برای کسی توضیح بدی این زندگیه توست. اجازه نده زندگیت به پوچی بگذره و برای رسیدن به رویاها و آرزوهات تمام تلاشتو بکن.\n",
            "\"آگاهی از مرگ ما را تشویق میکند شدیدتر زندگی کنیم\" پس نهایت استفاده رو از هر روزت ببر و جوری زندگی کن که انگار فردا نخواهی بود.\n",
            "بسی جذااااب\n",
            "بسی جذااااب\n",
            "این کتابو حتما بخونید.حتما حتما حتما .❤\n",
            "اینقدر عالی بود و خوب نوشته شده بود که فقط باید بخونی تا متوجه بشی\n",
            "این کتابو حتما بخونید.حتما حتما حتما .\n",
            "اینقدر عالی بود و خوب نوشته شده بود که فقط باید بخونی تا متوجه بشی\n",
            "این کتاب را باید کسایی بخونن که افسردگی دارن یا اینکه سوال های بنیادی از زندگی دارن ... در اصل باید شرایط روحیت با شرایط کتاب سازگار باشه...\n",
            "این کتاب را باید کسایی بخونن که افسردگی دارن یا اینکه سوال های بنیادی از زندگی دارن ... در اصل باید شرایط روحیت با شرایط کتاب سازگار باشه...\n",
            "این کتاب اثره یک انسانه شاهکار و کم نظیره.\n",
            "با خوندنش یاد گرفتم هر روز ک چشمامو باز میکنم بدونم ک امروز یه هدیه جدیده ک نصیبم شده.\n",
            "یاد گرفتم ک من یه دیوونه ام. پس خودم رو در لباس انسان هایه عاقل جا میدم تا روزی نرسه ک این مردم خطره متفاوت بودنه منو به روم بکشن.\n",
            "این کتاب اثره یک انسانه شاهکار و کم نظیره.\n",
            "با خوندنش یاد گرفتم هر روز ک چشمامو باز میکنم بدونم ک امروز یه هدیه جدیده ک نصیبم شده.\n",
            "یاد گرفتم ک من یه دیوونه ام. پس خودم رو در لباس انسان هایه عاقل جا میدم تا روزی نرسه ک این مردم خطره متفاوت بودنه منو به روم بکشن.\n",
            "ترجمه ی دیگه ای نخوندم ولی به نظر من این ترجمه بسیار خوب بود. نثر ادبی رو خیلی‌ها نمیپسندن و احتمالا به همین علت میگن ترجمه بد بوده و به نظرشون باید احترام گذاشت اما اگر خوب فکر کنیم درک میکنیم که باید یه فرقی بین لحن این کتاب و مثلا هری پاتر باشه. انصاف داشته باشیم. البته ایرادات تایپی و نگارشی زیاد بود و این مشکل به وفور در کتاب‌های طاقچه دیده میشه. بارها هم گفتیم ولی کی شده که به پیشنهادات کاربران اهمیت داده بشه که این بار دوم باشه.\n",
            "ترجمه ی دیگه ای نخوندم ولی به نظر من این ترجمه بسیار خوب بود. نثر ادبی رو خیلی‌ها نمیپسندن و احتمالا به همین علت میگن ترجمه بد بوده و به نظرشون باید احترام گذاشت اما اگر خوب فکر کنیم درک میکنیم که باید یه فرقی بین لحن این کتاب و مثلا هری پاتر باشه. انصاف داشته باشیم. البته ایرادات تایپی و نگارشی زیاد بود و این مشکل به وفور در کتاب‌های طاقچه دیده میشه. بارها هم گفتیم ولی کی شده که به پیشنهادات کاربران اهمیت داده بشه که این بار دوم باشه.\n",
            "ترجمه فوق العاده افتضاح بود،باعث شد کتاب رو از نصفه ول کنم\n",
            "ترجمه فوق العاده افتضاح بود،باعث شد کتاب رو از نصفه ول کنم\n",
            "مسائلی رو جواب میده این کتاب که اگر تا یه جاهایی برای خودتون توی زندگی واقعیتون تجربه نکرده باشین یا حداقل سوال نشده باشه واستون درکش نمیکنین\n",
            "مسائلی رو جواب میده این کتاب که اگر تا یه جاهایی برای خودتون توی زندگی واقعیتون تجربه نکرده باشین یا حداقل سوال نشده باشه واستون درکش نمیکنین\n",
            "از مزخرف ترن کتاب هایی بود که خوندم\n",
            "حیف وقت\n",
            "از مزخرف ترن کتاب هایی بود که خوندم\n",
            "حیف وقت\n",
            "چند سال قبل این کتاب رو خوندم و به شکل عجیبی قسمت های زیادیش رو هنوز یادمه . حس این رو دارم که شخصیت کتاب تبدیل شده به قسمتی از شخصیت خودم\n",
            "داستان فوق العاده قشنگیه با پایان خیلی زیبا ⁦☺️⁩\n",
            "چند سال قبل این کتاب رو خوندم و به شکل عجیبی قسمت های زیادیش رو هنوز یادمه . حس این رو دارم که شخصیت کتاب تبدیل شده به قسمتی از شخصیت خودم\n",
            "داستان فوق العاده قشنگیه با پایان خیلی زیبا ⁦⁩\n",
            "کتاب محتوای روانشناسی داره و سعی میکند در خلال تاریک ترین شرایط یک انگیزه برای زندگی ایجاد کند.در عین حال از انسانهای شرور و خودخواهی صحبت می کند که همچنان از دیوانه ها سو استفاده میکنند و به عنوان ابزار آزمایشیشون برای رسیدن به نتایج روانشناسی استفاده می کنند .\n",
            "وقتی این کتاب و خوندم تونستم ارتباطی بین این کتاب دارالمجانین جمالزاده پیدا کنم .\n",
            "امیدوارم از خوندنش لذت ببرین .\n",
            "کتاب محتوای روانشناسی داره و سعی میکند در خلال تاریک ترین شرایط یک انگیزه برای زندگی ایجاد کند.در عین حال از انسانهای شرور و خودخواهی صحبت می کند که همچنان از دیوانه ها سو استفاده میکنند و به عنوان ابزار آزمایشیشون برای رسیدن به نتایج روانشناسی استفاده می کنند .\n",
            "وقتی این کتاب و خوندم تونستم ارتباطی بین این کتاب دارالمجانین جمالزاده پیدا کنم .\n",
            "امیدوارم از خوندنش لذت ببرین .\n",
            "یکی از بهترین کتاب هایی که خوندم ، البته با ترجمه ی آقای حجازی\n",
            "یکی از بهترین کتاب هایی که خوندم ، البته با ترجمه ی آقای حجازی\n",
            "این کتاب یکی از بهترین و زیبا ترین کتاب هایی بود که خوندم\n",
            "این کتاب یکی از بهترین و زیبا ترین کتاب هایی بود که خوندم\n",
            "نمی دونم چرا از کتاب های پائولو کوئیلو زود خسته میشم با اینکه دوست دارم کتاب های معروفش بخرم ولی می ترسم پشیمون بشم\n",
            "نمی دونم چرا از کتاب های پائولو کوئیلو زود خسته میشم با اینکه دوست دارم کتاب های معروفش بخرم ولی می ترسم پشیمون بشم\n",
            "من چند سال پیش خوندمش خیلی کشش داشت یادمه تا سحر بیدار بودم و تموم کردم آخرشم یه حس خیلی خوبی داشتم انگار یه انگیزه و امید حس زندگی داره آخرش\n",
            "اون صبح منم از نور آفتاب لذت بردم به هر حال حس خوبی از این کتاب یادم مونده .\n",
            "من چند سال پیش خوندمش خیلی کشش داشت یادمه تا سحر بیدار بودم و تموم کردم آخرشم یه حس خیلی خوبی داشتم انگار یه انگیزه و امید حس زندگی داره آخرش\n",
            "اون صبح منم از نور آفتاب لذت بردم به هر حال حس خوبی از این کتاب یادم مونده .\n",
            "من این کتابو با ترجمه آرش حجازی خوندم و لذت بردم.. قلم این نویسنده رو دوست دارم مهمتر از قلمش دیدگاهشه که من میپسندم..خیلی از ما آدما ممکنه تو زندگی به یه پوچی برسیم.مثل شخصیت داستان.. اما اتفاقات اطرافش باعث شد دیدگاهش به زندگی عوض شه.. اگه بخوایم به دنیای خودمون نسبتش بدیم به این نتیجه میرسیم که باید بهتر اطرافو ببینیم و قضاوت کنیم..\n",
            "من این کتابو با ترجمه آرش حجازی خوندم و لذت بردم.. قلم این نویسنده رو دوست دارم مهمتر از قلمش دیدگاهشه که من میپسندم..خیلی از ما آدما ممکنه تو زندگی به یه پوچی برسیم.مثل شخصیت داستان.. اما اتفاقات اطرافش باعث شد دیدگاهش به زندگی عوض شه.. اگه بخوایم به دنیای خودمون نسبتش بدیم به این نتیجه میرسیم که باید بهتر اطرافو ببینیم و قضاوت کنیم..\n",
            "خیلی مزخرف بود .\n",
            "خیلی مزخرف بود .\n",
            "داستان جالبی داره کلا کتابای آقای کوئلیو رو دوست دارم البته با ترجمه آرش حجازی👌🌷\n",
            "داستان جالبی داره کلا کتابای آقای کوئلیو رو دوست دارم البته با ترجمه آرش حجازی\n",
            "با ترجمه آرش حجازی خوانده بودم. فضای تیمارستان و رنج های روحی و... فضای تلخی است. کتاب های بهتر از این کم نیستند.\n",
            "با ترجمه آرش حجازی خوانده بودم. فضای تیمارستان و رنج های روحی و... فضای تلخی است. کتاب های بهتر از این کم نیستند.\n",
            "تازه شروع کردم ب خوندنش ولی درکل کتاب جالبی هستش و بسیار شیرین چون از خوندنش خسته نمیشم\n",
            "کلا اینطور کتابای پرمحتوا رو دوست دارم.بخصوص ک اکثر کتابای اقای پائولو بی نظیرن مثل کیمیاگر\n",
            "ارزش خوندن داره😊\n",
            "تازه شروع کردم ب خوندنش ولی درکل کتاب جالبی هستش و بسیار شیرین چون از خوندنش خسته نمیشم\n",
            "کلا اینطور کتابای پرمحتوا رو دوست دارم.بخصوص ک اکثر کتابای اقای پائولو بی نظیرن مثل کیمیاگر\n",
            "ارزش خوندن داره\n",
            "فقط ترجمه آرش حجازی\n",
            "فقط ترجمه آرش حجازی\n",
            "کتاب خوبی بود سوالات بنیادی خوبی می پرسید و فرد رو به چالش می کشوند فقط مقداری در بخش دوم کتاب داستان هایی رو زیاد کش میداد که باعث می شد فرد خواننده خسته بشه و به نظر من نیازی به این مقدار زیاده گویی در رابطه با موضوعی جانبی در داستان نیست.\n",
            "ولی در کل کتاب خوبی بود ارزش خوندن رو داشت.\n",
            "و یه ذره هم ترجمه جای کار داشت چون روان روان نبود.\n",
            "کتاب خوبی بود سوالات بنیادی خوبی می پرسید و فرد رو به چالش می کشوند فقط مقداری در بخش دوم کتاب داستان هایی رو زیاد کش میداد که باعث می شد فرد خواننده خسته بشه و به نظر من نیازی به این مقدار زیاده گویی در رابطه با موضوعی جانبی در داستان نیست.\n",
            "ولی در کل کتاب خوبی بود ارزش خوندن رو داشت.\n",
            "و یه ذره هم ترجمه جای کار داشت چون روان روان نبود.\n",
            "خط داستانی کتاب گم و گنگ بوده و پیام نهایی کتاب مبهمه.\n",
            "درباره محتوا باید گفت نویسنده درباره علل بیماریهای روانی به نظریه سرکوب امیال درونی معتقده. مصداق این باور رو میشه تو عشق ورونیکا به ادوارد و خودارضایی دیوانه وار در حالت برهنه در مقابل ادوارد و تاثیر مثبت این اقدام در روحیه ورونیکا اشاره کرد، اقدامی که بنوعی نقطه عطف تحولات روحی ورونیکاست. اقدامی که نمود تمام خواهش های فروخورده ورونیکاست. در داستان مشخص نیست علت بهبود ورونیکا اشنایی با مفهوم مرگ و اغتنام فرصت کوتاه زندگیس یا تاثیر صحبت های زدکا و ماریا مبنی بر رها کردن استانداردهای روتین زندگی و روی اوردن به امیال درونی سرکوب شده. در مجموع کتاب حرف نو و بدیعی نداشت.\n",
            "خط داستانی کتاب گم و گنگ بوده و پیام نهایی کتاب مبهمه.\n",
            "درباره محتوا باید گفت نویسنده درباره علل بیماریهای روانی به نظریه سرکوب امیال درونی معتقده. مصداق این باور رو میشه تو عشق ورونیکا به ادوارد و خودارضایی دیوانه وار در حالت برهنه در مقابل ادوارد و تاثیر مثبت این اقدام در روحیه ورونیکا اشاره کرد، اقدامی که بنوعی نقطه عطف تحولات روحی ورونیکاست. اقدامی که نمود تمام خواهش های فروخورده ورونیکاست. در داستان مشخص نیست علت بهبود ورونیکا اشنایی با مفهوم مرگ و اغتنام فرصت کوتاه زندگیس یا تاثیر صحبت های زدکا و ماریا مبنی بر رها کردن استانداردهای روتین زندگی و روی اوردن به امیال درونی سرکوب شده. در مجموع کتاب حرف نو و بدیعی نداشت.\n",
            "خیلی عالی بود واقعا آخر داستان خیلی غافلگیرم کرد مثل کیمیا گر زیبا بود👏👏\n",
            "خیلی عالی بود واقعا آخر داستان خیلی غافلگیرم کرد مثل کیمیا گر زیبا بود\n",
            "داستان درمورد دختری به نام ورونیکاست که احساس میکنه زندگیش دچار پوچی و روزمرگی شده و دلیلی برای ادامه ی زندگی نداره. به همین دلیل هم با خوردن قرص خودکشی میکنه اما نمی میره. به یک بیمارستان روانی منتقل میشه و گفته میشه به علت داروهایی که مصرف کرده، قلبش ضعیف شده و به زودی میمیره. اما توی روزهایی که در پیش داره، در بیمارستان روانی، انگیزه ها و دلایل جدیدی برای ادامه ی زندگی پیدا میکنه..\n",
            "راستش کتاب نسبتا خوبی بود اما من پایانش رو نپسندیدم.متاسفانه از اینکه هر مدل داستانی رو به نوعی با مسئله ی عشق درگیر میکنن،  اصلا خوشم نمیاد.\n",
            "داستان درمورد دختری به نام ورونیکاست که احساس میکنه زندگیش دچار پوچی و روزمرگی شده و دلیلی برای ادامه ی زندگی نداره. به همین دلیل هم با خوردن قرص خودکشی میکنه اما نمی میره. به یک بیمارستان روانی منتقل میشه و گفته میشه به علت داروهایی که مصرف کرده، قلبش ضعیف شده و به زودی میمیره. اما توی روزهایی که در پیش داره، در بیمارستان روانی، انگیزه ها و دلایل جدیدی برای ادامه ی زندگی پیدا میکنه..\n",
            "راستش کتاب نسبتا خوبی بود اما من پایانش رو نپسندیدم.متاسفانه از اینکه هر مدل داستانی رو به نوعی با مسئله ی عشق درگیر میکنن،  اصلا خوشم نمیاد.\n",
            "سال گذشته این کتاب رو مطالعه کردم . واقعا بی نظیر بود . پایان داستان آدم غافلگیر میشه .\n",
            "سال گذشته این کتاب رو مطالعه کردم . واقعا بی نظیر بود . پایان داستان آدم غافلگیر میشه .\n",
            "بعضی نویسنده ها بعد از اینکه اسمی در کردن شروع به نوشتن اراجیف میکنن...\n",
            "بعضی نویسنده ها بعد از اینکه اسمی در کردن شروع به نوشتن اراجیف میکنن...\n",
            "این کتاب عالیه ولی منم همیشه ترجیح میدم کتابهای پائولو رو با ترجمه آرش حجازی بخونم...\n",
            "این کتاب عالیه ولی منم همیشه ترجیح میدم کتابهای پائولو رو با ترجمه آرش حجازی بخونم...\n",
            "این کتاب خیلی عالیه. فوق العاده محشر . کلا آثار پائلو کوئیلو بی نظیرن. واقعا شخص روشن فکر و آشنا با ادبیات هستند. روایت یه دختر افسرده و سیر شده از زندگی که توی تیمارستان طی اتفاقاتی باعث میشه دوباره به زندگی برگرده. البته من با ترجمه آقای آرش حجازی خوندم.بهتون پیشنهاد میکنم از دستش ندید.\n",
            "این کتاب خیلی عالیه. فوق العاده محشر . کلا آثار پائلو کوئیلو بی نظیرن. واقعا شخص روشن فکر و آشنا با ادبیات هستند. روایت یه دختر افسرده و سیر شده از زندگی که توی تیمارستان طی اتفاقاتی باعث میشه دوباره به زندگی برگرده. البته من با ترجمه آقای آرش حجازی خوندم.بهتون پیشنهاد میکنم از دستش ندید.\n",
            "یکی از بهترین کتابهایی که خوندم و خیلی تحت تاثیر قرار گرفتم. توصیفات داستان بسیار عالی و گسترده هست\n",
            "یکی از بهترین کتابهایی که خوندم و خیلی تحت تاثیر قرار گرفتم. توصیفات داستان بسیار عالی و گسترده هست\n",
            "جناب پسرخانده سلام علیکم\n",
            "من اصلا نظری نمیبینم از خودم روی این کتاب! اما کتاب خوبی است و ب خاندنش میارزد و نیز باید بگم ک برنده تنهاست هم کتاب ارزنده ای است.\n",
            "جناب پسرخانده سلام علیکم\n",
            "من اصلا نظری نمیبینم از خودم روی این کتاب! اما کتاب خوبی است و ب خاندنش میارزد و نیز باید بگم ک برنده تنهاست هم کتاب ارزنده ای است.\n",
            "عالی هست این کتاب. پر از مسایل ریزی که  خیلی زیبا توصیف شده اند\n",
            "عالی هست این کتاب. پر از مسایل ریزی که  خیلی زیبا توصیف شده اند\n",
            "fogholadas\n",
            "fogholadas\n",
            "خداوکیلی صفر ستاره وحید ؟ انصافه ؟\n",
            "خداوکیلی صفر ستاره وحید ؟ انصافه ؟\n",
            "ممنون هستم از اهل دل، خدا خیرت بده\n",
            "ممنون هستم از اهل دل، خدا خیرت بده\n",
            "اجازه بدید من جای برادر وحید جواب بدم، برنده تنهاست خوب میباشد در حد 4ستاره :-)\n",
            "اجازه بدید من جای برادر وحید جواب بدم، برنده تنهاست خوب میباشد در حد 4ستاره :-)\n",
            "آقای وحید\n",
            "سلام علیکم\n",
            "یعنی شما همه کتب بائولو کوئیلو خوانده اید؟احسنت\n",
            "نظرتان درباره برنده تنهاست چیست؟\n",
            "آقای وحید\n",
            "سلام علیکم\n",
            "یعنی شما همه کتب بائولو کوئیلو خوانده اید؟احسنت\n",
            "نظرتان درباره برنده تنهاست چیست؟\n",
            "واقعا عالیه کتابش\n",
            "واقعا عالیه کتابش\n",
            "ب نظرم کوءیلو بعد از کیمیاگر کتاب هاش متوسط اند تا برنده تنها ست،\n",
            "ب نظرم کوءیلو بعد از کیمیاگر کتاب هاش متوسط اند تا برنده تنها ست،\n",
            "با احترام \n",
            "کتاب بسیار خوبی  در در مباحث روابط اجتماعی  و  روش شناسی های مردم نگارانه  یا اتنو متدلوژی است.\n",
            "با احترام \n",
            "کتاب بسیار خوبی  در در مباحث روابط اجتماعی  و  روش شناسی های مردم نگارانه  یا اتنو متدلوژی است.\n",
            "چه قدر گرانه\n",
            "تازه کاغذی هم مصرف نشده که پول اونو بدیم، واقعا بعضی قیمتها رو پایین تر کنید\n",
            "چه قدر گرانه\n",
            "تازه کاغذی هم مصرف نشده که پول اونو بدیم، واقعا بعضی قیمتها رو پایین تر کنید\n",
            "بسیار عالی. شخصیتها خیلی خوب طعنه به مدلهای واقعیشون میزنن. داستان بیان میکنه که چطوری یه ایده صادقانه میتونه دچار چالشای جدی و سو استفاده های بدی بشه\n",
            "بسیار عالی. شخصیتها خیلی خوب طعنه به مدلهای واقعیشون میزنن. داستان بیان میکنه که چطوری یه ایده صادقانه میتونه دچار چالشای جدی و سو استفاده های بدی بشه\n",
            "بسیار خوشحال کننده است که حق ناشر محفوظ است. اما کاش کمی قیمت ها به دلیل چاپ مجازی شان تعدیل شود. در انگلیسی مثلا کتاب 120 پوندی در چاپ دیجیتال نهایتا 20 دلار قیمت میخورد یعنی یک ششم. به نظرم با این رقم ها صرفه با خرید خود کتابهاست چون خوانش را راحت تر میکند.\n",
            "البته این طرح تخفیف هفته چیز خوبی است\n",
            "بسیار خوشحال کننده است که حق ناشر محفوظ است. اما کاش کمی قیمت ها به دلیل چاپ مجازی شان تعدیل شود. در انگلیسی مثلا کتاب 120 پوندی در چاپ دیجیتال نهایتا 20 دلار قیمت میخورد یعنی یک ششم. به نظرم با این رقم ها صرفه با خرید خود کتابهاست چون خوانش را راحت تر میکند.\n",
            "البته این طرح تخفیف هفته چیز خوبی است\n",
            "رومن گاری تنها نویسنده ی فرانسوی ایه که دوبار جایزه گنکور رو برده\n",
            "مثل همیشه عالی\n",
            "رومن گاری تنها نویسنده ی فرانسوی ایه که دوبار جایزه گنکور رو برده\n",
            "مثل همیشه عالی\n",
            "واقعا خیلی خوبه ممنون طاقچه آدم موقع خوندن غرق داستان کتاب میشه واقعا قشنگه\n",
            "واقعا خیلی خوبه ممنون طاقچه آدم موقع خوندن غرق داستان کتاب میشه واقعا قشنگه\n",
            "واقعا خوبه کتاب خیلی عالیه ممنون طاقچه.\n",
            "واقعا خوبه کتاب خیلی عالیه ممنون طاقچه.\n",
            "جایزه کنگور به بهترین کتاب داستانی منتشر شده در سال داده میشه، واقعاً خوشحال کننده است که این کتاب به فارسی ترجمه شده  و نشر ثالث اون رو منتشر کرده.\n",
            "با خوندنش واقعاً پی برده میشه که این کتاب به طور شایسته ای انتخاب شده، من موقع خوندن کتاب دقیقاً غرق در فضای ساخته شده در کتاب می شدم\n",
            "جایزه کنگور به بهترین کتاب داستانی منتشر شده در سال داده میشه، واقعاً خوشحال کننده است که این کتاب به فارسی ترجمه شده  و نشر ثالث اون رو منتشر کرده.\n",
            "با خوندنش واقعاً پی برده میشه که این کتاب به طور شایسته ای انتخاب شده، من موقع خوندن کتاب دقیقاً غرق در فضای ساخته شده در کتاب می شدم\n",
            "این طرح تخفیف کتاب هفته عالیه\n",
            "لطفا ادامه بدیدش\n",
            "این طرح تخفیف کتاب هفته عالیه\n",
            "لطفا ادامه بدیدش\n",
            "طاقچه جان, کتاب های جدیدت عالین, کتاب بیشتر بگذار, در ضمن رومن گاری رو عشق است وبس!\n",
            "طاقچه جان, کتاب های جدیدت عالین, کتاب بیشتر بگذار, در ضمن رومن گاری رو عشق است وبس!\n",
            "واقعا کتاب جالبیه. مقدمه اش رو که خوندم تشویق شدم  شعرهاش رو بخونم. و شعر اولش «رب اعلم» واقعا جالب بود. و بقیه شعرهاش هم خیلی سلیس گفته شدند. پیشنهاد می کنم حتما بخونید\n",
            "واقعا کتاب جالبیه. مقدمه اش رو که خوندم تشویق شدم  شعرهاش رو بخونم. و شعر اولش «رب اعلم» واقعا جالب بود. و بقیه شعرهاش هم خیلی سلیس گفته شدند. پیشنهاد می کنم حتما بخونید\n",
            "توصیه میکنم بخونیدش\n",
            "توصیه میکنم بخونیدش\n",
            "کتاب خیلی خوبیه.توصیه میکنم بخونید.البته  با ترجمه آرش حجازی با عنوان زرم آور نور خیلی بهتره...💟\n",
            "کتاب خیلی خوبیه.توصیه میکنم بخونید.البته  با ترجمه آرش حجازی با عنوان زرم آور نور خیلی بهتره...\n",
            "شروور\n",
            "شروور\n",
            "مرور گذرا و گاه نادرست بر اندیشه‌های فلسفی که باعث ایجاد سوء برداشت در خواننده ناآگاه می‌شود.\n",
            "مرور گذرا و گاه نادرست بر اندیشه‌های فلسفی که باعث ایجاد سوء برداشت در خواننده ناآگاه می‌شود.\n",
            "اطلاعات خیلی کلی و بعضا نادرست\n",
            "اطلاعات خیلی کلی و بعضا نادرست\n",
            "یکی از بهترین ضمیمه ها ی روزنامه ها ی کشور که هر یکشنبه منتشر می‌شود.\n",
            "یکی از بهترین ضمیمه ها ی روزنامه ها ی کشور که هر یکشنبه منتشر می‌شود.\n",
            "فکر میکردم کتاب راهنمای گام به گام برای رسیدن به یک زن موفق باشه ولی صرفا چیزی نبود جز جملات الهام بخش و انرژی دهنده، البته تقصیر خودمه که بدون خوندن نمونه کتاب دانلودش کردم\n",
            "ولی باز به هرحال خیلی ام بد نبود\n",
            "فکر میکردم کتاب راهنمای گام به گام برای رسیدن به یک زن موفق باشه ولی صرفا چیزی نبود جز جملات الهام بخش و انرژی دهنده، البته تقصیر خودمه که بدون خوندن نمونه کتاب دانلودش کردم\n",
            "ولی باز به هرحال خیلی ام بد نبود\n",
            "♥زنان برجسته چه کسی آن ها را تماشا کند و چه نکند، خودشان را مطمئن و برجسته در نظر میگیرند.\n",
            "♥تعهد بدهید که عالی و بی نظیر باشید.\n",
            "♥با خودتان به عنوان فردی که همواره در اولویت قرار دارد رفتار کنید.\n",
            "♥به گونه ای حرفه ای لباس بپوشید، تصوری از قدرت و شایستگی ایجاد کنید.\n",
            "♥خودتان را تا سطح خوب بودن محدود نکنید. معیار هایتان را تا حد عالی بودن بالا ببرید و در این مسیر هیچ مصالحه ای نکنید.\n",
            "♥آینده متعلق به افراد شایسته است.\n",
            "♥فرمول موفقیت: کمی زودتر کار را شروع کنید، کمی سخت تر کار کنید، کمی بیشتر در محل کار بمانید.\n",
            "---> باید اینا رو با طلا بنویسم بذارم جلو چشم خودم.\n",
            "زنان برجسته چه کسی آن ها را تماشا کند و چه نکند، خودشان را مطمئن و برجسته در نظر میگیرند.\n",
            "تعهد بدهید که عالی و بی نظیر باشید.\n",
            "با خودتان به عنوان فردی که همواره در اولویت قرار دارد رفتار کنید.\n",
            "به گونه ای حرفه ای لباس بپوشید، تصوری از قدرت و شایستگی ایجاد کنید.\n",
            "خودتان را تا سطح خوب بودن محدود نکنید. معیار هایتان را تا حد عالی بودن بالا ببرید و در این مسیر هیچ مصالحه ای نکنید.\n",
            "آینده متعلق به افراد شایسته است.\n",
            "فرمول موفقیت: کمی زودتر کار را شروع کنید، کمی سخت تر کار کنید، کمی بیشتر در محل کار بمانید.\n",
            "---> باید اینا رو با طلا بنویسم بذارم جلو چشم خودم.\n",
            "در تعداد انگشت شماری از جملات این کتاب  به زن اشاره شده بود که اون هم انقدر کلی بود که نمی شه گفت تنها در مورد زن ها صدق می کنه. اگر به من بگن برایان تریسی کتابی به نام \"زن موفق\" نداره و این جملات مجموعه ای از جمله های گفته شده در کتاب های دیگر ایشونه که توسط این دو نفر (اسامی مترجم ها) جمع آوری شده، حتما باور می کنم. به نظر من کتاب خوبی نبود.\n",
            "در تعداد انگشت شماری از جملات این کتاب  به زن اشاره شده بود که اون هم انقدر کلی بود که نمی شه گفت تنها در مورد زن ها صدق می کنه. اگر به من بگن برایان تریسی کتابی به نام \"زن موفق\" نداره و این جملات مجموعه ای از جمله های گفته شده در کتاب های دیگر ایشونه که توسط این دو نفر (اسامی مترجم ها) جمع آوری شده، حتما باور می کنم. به نظر من کتاب خوبی نبود.\n",
            "خوب بود\n",
            "من دنبال کتاب \"زن کامل\" هستم از \"مارابل مورگان\"\n",
            "ممنون میشم اگ برام در نظر داشته باشیدش.\n",
            "کتاب خیلی خوبیه گویا\n",
            "خوب بود\n",
            "من دنبال کتاب \"زن کامل\" هستم از \"مارابل مورگان\"\n",
            "ممنون میشم اگ برام در نظر داشته باشیدش.\n",
            "کتاب خیلی خوبیه گویا\n",
            "@نسا\n",
            "نسخه‌ی کاغذی کتاب ۸۲ صفحه است. نسخه‌ی ePUB کتاب توی گوشی شما شده ۴۴ صفحه. الان اگه قلم کتاب رو بزرگ‌تر کنید تعداد صفحات بیشتر می‌شه. کوچکش هم بکنید تعداد صفحات کمتر می‌شه.\n",
            "@نسا\n",
            "نسخه‌ی کاغذی کتاب ۸۲ صفحه است. نسخه‌ی ePUB کتاب توی گوشی شما شده ۴۴ صفحه. الان اگه قلم کتاب رو بزرگ‌تر کنید تعداد صفحات بیشتر می‌شه. کوچکش هم بکنید تعداد صفحات کمتر می‌شه.\n",
            "نوشته  ۸۲ صفحه در صورتی که ۴۴صفحه بیشتر نیست!!!!؛!!\n",
            "نوشته  ۸۲ صفحه در صورتی که ۴۴صفحه بیشتر نیست!!!!؛!!\n",
            "متن خیلی جالبی داره. لذت بردم\n",
            "متن خیلی جالبی داره. لذت بردم\n",
            "عالی بود من واقعا دوست داشتم این کتابو\n",
            "عالی بود من واقعا دوست داشتم این کتابو\n",
            "ترجمه به شدت ضعیفه کتاب خوبیه . ویرگول نداره کتاب اذیت میکنه\n",
            "ترجمه به شدت ضعیفه کتاب خوبیه . ویرگول نداره کتاب اذیت میکنه\n",
            "کتاب بسیار راهگشایی برای درک روانکاوی است با کمترین اطلاعات در مورد روانکاوی باز هم چیز های بسیار مفیدی دستگیرتون میشه، چون سخنرانی های فروید بوده و لحن فروید در اون ها ساده و جذابه، بخش دومش هم که کلا یک مکالمه ی خیالی بین فروید و یک قاضی هست که فروید در اون از روانکاوی توسط غیر پزشکان دفاع میکنه که اون هم به اندازه ی بخش اول مفیده\n",
            "کتاب بسیار راهگشایی برای درک روانکاوی است با کمترین اطلاعات در مورد روانکاوی باز هم چیز های بسیار مفیدی دستگیرتون میشه، چون سخنرانی های فروید بوده و لحن فروید در اون ها ساده و جذابه، بخش دومش هم که کلا یک مکالمه ی خیالی بین فروید و یک قاضی هست که فروید در اون از روانکاوی توسط غیر پزشکان دفاع میکنه که اون هم به اندازه ی بخش اول مفیده\n",
            "آیا این کتاب آموزش روانکاوی میده میخواستم یکی از کتاب های فروید رو معرفی کنین که اموزش روانکاویش تو اون کتاب باشه\n",
            "آیا این کتاب آموزش روانکاوی میده میخواستم یکی از کتاب های فروید رو معرفی کنین که اموزش روانکاویش تو اون کتاب باشه\n",
            "برای مطالعه کارهای نویسندگانی که پیچیده صحبت می کنند بهترین روش اینه که اول نقدها و تفسیرهای نویسندگان دیگه رو در مورد اون نویسنده بخونیم بعد سراغ متن اصلی بریم، مثلا برای فهمیدن فروید یک متفکر به اسم اریک برن هست که تقسیم بندی فروید از نهاد، من و من برتر رو با مثال و با زبان ساده آورده که با خوندن اون میشه پی به تفکرات فروید پی برد.\n",
            "برای مطالعه کارهای نویسندگانی که پیچیده صحبت می کنند بهترین روش اینه که اول نقدها و تفسیرهای نویسندگان دیگه رو در مورد اون نویسنده بخونیم بعد سراغ متن اصلی بریم، مثلا برای فهمیدن فروید یک متفکر به اسم اریک برن هست که تقسیم بندی فروید از نهاد، من و من برتر رو با مثال و با زبان ساده آورده که با خوندن اون میشه پی به تفکرات فروید پی برد.\n",
            "کتاب های فروید کتاب های سنگینی هستند که من به شخصه چون در حوضه روانکاوی قسمتی از فروید و قسمتی از یونگ مطالعه کردم به همه پیشنهاد نمیکنم،کتابی نیست که کسی ببینه خوشش بیاد و بخونه و بعد تمام،چون  اول به اشتباه فکر میکنه روانکاو شده:) و ٢.احتمال داره چیزی متوجه نشه،پس به کسانی که به این شاخه علاقه دارند خوندن کتابهای فروید رو پیشنهاد میکنم\n",
            "کتاب های فروید کتاب های سنگینی هستند که من به شخصه چون در حوضه روانکاوی قسمتی از فروید و قسمتی از یونگ مطالعه کردم به همه پیشنهاد نمیکنم،کتابی نیست که کسی ببینه خوشش بیاد و بخونه و بعد تمام،چون  اول به اشتباه فکر میکنه روانکاو شده:) و ٢.احتمال داره چیزی متوجه نشه،پس به کسانی که به این شاخه علاقه دارند خوندن کتابهای فروید رو پیشنهاد میکنم\n",
            "کتابی عالی از جهت شروع نگرش در باره علم روانکاوی \n",
            "کتابی عالی از جهت شروع نگرش در باره علم روانکاوی \n",
            "کارآمد و متحول کننده شدیدا توصیه میکنم\n",
            "کارآمد و متحول کننده شدیدا توصیه میکنم\n",
            "❤❤❤\n",
            "کد تخفیف ۵۰ درصد\n",
            "Y98MACRCUNYJ2\n",
            "\n",
            "کد تخفیف ۵۰ درصد\n",
            "Y98MACRCUNYJ2\n",
            "لطفا اثاره ایشون رو کامل کنید\n",
            "لطفا اثاره ایشون رو کامل کنید\n",
            "ترجمه احمدپوری به بوکوفسکی روح میده.از بوتیما باز هم شعر بزارید مخصوصا کتاب تازه حافظ موسوی\n",
            "ترجمه احمدپوری به بوکوفسکی روح میده.از بوتیما باز هم شعر بزارید مخصوصا کتاب تازه حافظ موسوی\n",
            "بوکفسکی نفس من\n",
            "بوکفسکی نفس من\n",
            "عوض کردنِ مدامِ کانالای تلویزیون !\n",
            "قیافه هایی رُ می بینی که هیچ کدوم واقعی نیستن !\n",
            "با یه وحشتِ واقعی شاخ به شاخی !\n",
            "بجنب !\n",
            "بجنب !\n",
            "بیشتر !\n",
            "کمتر !\n",
            "صورتا بهت فرمون می دن !\n",
            "اونا رُ با چی پر کردن ؟\n",
            "چه جوری جا شدن تو اون شیشه ؟\n",
            "کی چپوندنتشون اون تو ؟\n",
            "چیزی نیست ؟\n",
            "تو این دنیا\n",
            "این دنیا...\n",
            "اینا مردمِ من نیستن\n",
            "مردمای من کجا رفتن ؟\n",
            "\n",
            "\n",
            "عوض کردنِ مدامِ کانالای تلویزیون !\n",
            "قیافه هایی رُ می بینی که هیچ کدوم واقعی نیستن !\n",
            "با یه وحشتِ واقعی شاخ به شاخی !\n",
            "بجنب !\n",
            "بجنب !\n",
            "بیشتر !\n",
            "کمتر !\n",
            "صورتا بهت فرمون می دن !\n",
            "اونا رُ با چی پر کردن ؟\n",
            "چه جوری جا شدن تو اون شیشه ؟\n",
            "کی چپوندنتشون اون تو ؟\n",
            "چیزی نیست ؟\n",
            "تو این دنیا\n",
            "این دنیا...\n",
            "اینا مردمِ من نیستن\n",
            "مردمای من کجا رفتن ؟\n",
            "\n",
            "\n",
            "سلام .شهید محمدابراهیم همت شخصیت مهربون و احساساتی و خصوصا خالصی دارن ...و از خصوصیات بارزشون خلوص در نیت ،عمل و گفتاره .\n",
            "ب قول خودشون همه چی، همه چی، همه چی خواست خدا باشه ک اگه این جور شد پیروزیم و شکست معنا نداره برای ما .\n",
            "کل کتاب، خاطرات کوتاه کوتاه از ایشون داره .و درباره تولدشون هم حاج حسین یکتا ،اسفند امسال تو شلمچه صحبت عجیبی کردن .\n",
            "سلام .شهید محمدابراهیم همت شخصیت مهربون و احساساتی و خصوصا خالصی دارن ...و از خصوصیات بارزشون خلوص در نیت ،عمل و گفتاره .\n",
            "ب قول خودشون همه چی، همه چی، همه چی خواست خدا باشه ک اگه این جور شد پیروزیم و شکست معنا نداره برای ما .\n",
            "کل کتاب، خاطرات کوتاه کوتاه از ایشون داره .و درباره تولدشون هم حاج حسین یکتا ،اسفند امسال تو شلمچه صحبت عجیبی کردن .\n",
            "شهید همت یک اسطوره ی واقعی هستن...\n",
            "شهید همت یک اسطوره ی واقعی هستن...\n",
            "سرزمین گوجه های سبز و موجود کنید\n",
            "لطفن\n",
            "سرزمین گوجه های سبز و موجود کنید\n",
            "لطفن\n",
            "هرتا مولر را با صبوری و آرامش بخوانید. لذت می برید.\n",
            "هرتا مولر را با صبوری و آرامش بخوانید. لذت می برید.\n",
            "خوب نیست\n",
            "خوب نیست\n",
            "خیلی خوشم نیومد،\n",
            "خیلی خوشم نیومد،\n",
            "ترجمه ی این کتاب خیلی خوبه.با این که فراتر از خط سیر یک رمانه و بیشتر میخواد حرف هاشو بیان کنه  خواندنش مثل بقیه رمان های مولر لذت بخشه\n",
            "ترجمه ی این کتاب خیلی خوبه.با این که فراتر از خط سیر یک رمانه و بیشتر میخواد حرف هاشو بیان کنه  خواندنش مثل بقیه رمان های مولر لذت بخشه\n",
            "طاقچه داره روز به روز بهتر میشه, طاقچه فراتر از یک اپ خواهد شد, طاقچه به همه سلیقه ها احترام میگذاره و این خیلی مهمه\n",
            "طاقچه داره روز به روز بهتر میشه, طاقچه فراتر از یک اپ خواهد شد, طاقچه به همه سلیقه ها احترام میگذاره و این خیلی مهمه\n",
            "مرسی به طاقچه و نشر بوتیمار با انتشار این کتاب خوب\n",
            "مرسی به طاقچه و نشر بوتیمار با انتشار این کتاب خوب\n",
            "واقعا ممنون\n",
            "واقعا ممنون\n",
            "Y986STYXCWS2Rکد 30 درصدی\n",
            "Y986STYXCWS2Rکد 30 درصدی\n",
            "من این کتابو تو دوره ی رایگانی گرفتم ولی الان که طاقچه رو پاک و نصب کردم میگه باید پرداخت کنی!!چرااا؟؟؟؟\n",
            "من این کتابو تو دوره ی رایگانی گرفتم ولی الان که طاقچه رو پاک و نصب کردم میگه باید پرداخت کنی!!چرااا؟؟؟؟\n",
            "چرا قماربازو دوس دارن؟!\n",
            "چرا قماربازو دوس دارن؟!\n",
            "کتابی که وقتی شروع کردم رها نکردم با داستان گویی عالی\n",
            "کتابی که وقتی شروع کردم رها نکردم با داستان گویی عالی\n",
            "مجذوب این کتاب شدم\n",
            "مجذوب این کتاب شدم\n",
            "ترجمه کتاب واقعا ضعیفه اما انقدر داستان کتاب جذابه که من توی سه روز، کتاب رو تموم کردم . اوایل کتاب با ترجمش خیلی مشکل داشتم اما کم کم عادت کردم و تونستم جمله و کلمه صحیح رو حدس بزنم ☺️\n",
            "ترجمه کتاب واقعا ضعیفه اما انقدر داستان کتاب جذابه که من توی سه روز، کتاب رو تموم کردم . اوایل کتاب با ترجمش خیلی مشکل داشتم اما کم کم عادت کردم و تونستم جمله و کلمه صحیح رو حدس بزنم \n",
            "\"خنک آن قماربازی که بباخت آنچه بودش\n",
            "بنماند هیچش الا هوس قمار دیگر\"\n",
            "رمان قوی با ترجمه ای ضعیف و گنگ مانند سیگار بدون نیکوتینه . اثر بخشی یک اثر در ترجمه ، دقت در انتقال مفاهیم و سهولت در درک و فهم خوانندست نه پیچیدگی های ادبی و گردنه های ابهام و ایهام .\n",
            "\"خنک آن قماربازی که بباخت آنچه بودش\n",
            "بنماند هیچش الا هوس قمار دیگر\"\n",
            "رمان قوی با ترجمه ای ضعیف و گنگ مانند سیگار بدون نیکوتینه . اثر بخشی یک اثر در ترجمه ، دقت در انتقال مفاهیم و سهولت در درک و فهم خوانندست نه پیچیدگی های ادبی و گردنه های ابهام و ایهام .\n",
            "سخت ولی خوب\n",
            "سخت ولی خوب\n",
            "ینی این بود آرمان های انقلاب واسه مطالعه😉 این چه ترجمه ایه واسه کتابای رایگان آخه😔\n",
            "ینی این بود آرمان های انقلاب واسه مطالعه این چه ترجمه ایه واسه کتابای رایگان آخه\n",
            "ترجمه پیچیده.....باید تمرکز بالایی داشته باشی تا بتونی داستان رو درک کنی\n",
            "ترجمه پیچیده.....باید تمرکز بالایی داشته باشی تا بتونی داستان رو درک کنی\n",
            "خوب بود. با اینکه متن روانی نداشت ولی واقعا به نظرم توصیفات داستایفسکی خیلی خوب بود.\n",
            "خوب بود. با اینکه متن روانی نداشت ولی واقعا به نظرم توصیفات داستایفسکی خیلی خوب بود.\n",
            "والا بعنوان کسی که زیاد حرفه ای مطالعه نمیکنه و ندارم اصلا نتونستم باهاش ارتباط برقرار کنم و تا کلی صفحه هم پیش رفتم ولی چیزی متوجه نشدم...و بی خیال شدم.😑😑\n",
            "والا بعنوان کسی که زیاد حرفه ای مطالعه نمیکنه و ندارم اصلا نتونستم باهاش ارتباط برقرار کنم و تا کلی صفحه هم پیش رفتم ولی چیزی متوجه نشدم...و بی خیال شدم.\n",
            "ترجمه گیج و گنگ است وسطای کتاب از مطالعه منصرف شدم\n",
            "ترجمه گیج و گنگ است وسطای کتاب از مطالعه منصرف شدم\n",
            "به خود کتاب 5 ستاره میدم، ترجمه آل احمد رو گنگ و پیچیده بود و از کتابخانه ترجمه صالح حسینی گرفتم خوندم کلا کتاب عالی بودش\n",
            "به خود کتاب 5 ستاره میدم، ترجمه آل احمد رو گنگ و پیچیده بود و از کتابخانه ترجمه صالح حسینی گرفتم خوندم کلا کتاب عالی بودش\n",
            "با اینکه ظاهرا نگارش کتاب با عجله صورت گرفته، اما داستایوفسکی شخصیت پردازی ها و توصیف حالات روانی و احساسی رو خیلی عالی انجام داده و میشه خیلی خوب موقعیت ها رو تخیل کرد. برخی دوستان نسبت به این ترجمه ابراز ناراضایتی کردن. از نظر من ترجمه هم مشکلی نداشت و فکر میکنم بخاطر سبک قلم نویسنده کمی بنظر دشوار یا غیرروان میاد. و زیاد ربطی به مترجم نداره. اما بهرحال سلیقه ای هس..\n",
            "با اینکه ظاهرا نگارش کتاب با عجله صورت گرفته، اما داستایوفسکی شخصیت پردازی ها و توصیف حالات روانی و احساسی رو خیلی عالی انجام داده و میشه خیلی خوب موقعیت ها رو تخیل کرد. برخی دوستان نسبت به این ترجمه ابراز ناراضایتی کردن. از نظر من ترجمه هم مشکلی نداشت و فکر میکنم بخاطر سبک قلم نویسنده کمی بنظر دشوار یا غیرروان میاد. و زیاد ربطی به مترجم نداره. اما بهرحال سلیقه ای هس..\n",
            "علی الرغم آنکه شنیده بودم که فئودور داستایوفسکی داستان نویسی با سبکی پوج گرایانه است\n",
            "در انتهای این اثر عجیب و به یاد ماندنی در یافتم که داستایوفسکی نگاه مثبتی به زندگی داشت\n",
            "به این جمله توجه کنید\n",
            "باید از میان مردگان برخیزم\n",
            "یا جائی که فقط یک فلورین در جیب آلکسی ایوانوویچ مانده بود و او با جرات به خرج دادن و قمار کردن صد و هفتاد فلورین به دست آورد و تصمیم گرفت که از فردا از میان مردگان برخیزد\n",
            "علی الرغم آنکه شنیده بودم که فئودور داستایوفسکی داستان نویسی با سبکی پوج گرایانه است\n",
            "در انتهای این اثر عجیب و به یاد ماندنی در یافتم که داستایوفسکی نگاه مثبتی به زندگی داشت\n",
            "به این جمله توجه کنید\n",
            "باید از میان مردگان برخیزم\n",
            "یا جائی که فقط یک فلورین در جیب آلکسی ایوانوویچ مانده بود و او با جرات به خرج دادن و قمار کردن صد و هفتاد فلورین به دست آورد و تصمیم گرفت که از فردا از میان مردگان برخیزد\n",
            "من ترجمه سروش حبیبی و خریدم نمیدونم این ترجمه خوبه یا مال من\n",
            "من ترجمه سروش حبیبی و خریدم نمیدونم این ترجمه خوبه یا مال من\n",
            "ترجمه ش مزخرفه\n",
            "ترجمه ش مزخرفه\n",
            "عالیه ای کاش صوتیش هم رایگان بود\n",
            "عالیه ای کاش صوتیش هم رایگان بود\n",
            "جالب و قابل تامل 👌\n",
            "نویسنده حرص و طمع ، غرور و خودخواهی ، رذالت و پستی و عشق رو در سایه یِ بی حسی با طعم گس به تصویر کشیده...ویژگی های انسانی خاص رو به ملیت های گوناگون نسبت داده که به نظرم میشه اونا رو تو هر آدمی دید...شخصیت تاریکِ شخصیت اصلی داستان رو بی نقاب به تصویر کشیده و خواننده رو با عمق اعتیاد الکسی به قمار ، شهوتش برای بدست آوردن پول و در عین حال عدم تمایلش نسبت به پول رو و اینکه چجوری تویِ دور باطلی از قمار زندگیش رو میگذرونه نشون میده...\n",
            "جالب و قابل تامل \n",
            "نویسنده حرص و طمع ، غرور و خودخواهی ، رذالت و پستی و عشق رو در سایه یِ بی حسی با طعم گس به تصویر کشیده...ویژگی های انسانی خاص رو به ملیت های گوناگون نسبت داده که به نظرم میشه اونا رو تو هر آدمی دید...شخصیت تاریکِ شخصیت اصلی داستان رو بی نقاب به تصویر کشیده و خواننده رو با عمق اعتیاد الکسی به قمار ، شهوتش برای بدست آوردن پول و در عین حال عدم تمایلش نسبت به پول رو و اینکه چجوری تویِ دور باطلی از قمار زندگیش رو میگذرونه نشون میده...\n",
            "دوستان میشه بگین که طاقچه همه کتاب هارو خلاصه میکنه میذاره یا کامل هم هست؟\n",
            "دوستان میشه بگین که طاقچه همه کتاب هارو خلاصه میکنه میذاره یا کامل هم هست؟\n",
            "اگه هنوز کتابو نخوندین نظر منو نگاه نکنین..\n",
            "نمیدونم چه علتی داره که جوری که قمار رو توصیف کرده بود باعث میشد منم مثل شخصیت اصلی فکر کنم.. جوری که آخر داستان که میگه نه دیگه قمار نمیکنم مطمئنم که این کار رو انجام میده که واقعا انجام میده و جالب این جاست که وقتی خودم رو جاش میذارم هم فکر میکنم منم همین کار رو انجام میدم.. حالا این ممکنه از ضعف شخصیت خودم باشه یا انقدر نویسنده خوب آدم رو با الکسی همراه کرده که قدم به قدم باهاش به فنا رفتم..\n",
            "در ضمن الکسی خیلی نسبت به اطرافیانش با حرص صحبت میکرد و فکر میکرد که از همه بهتره و کار خودش آخر به جاهای بدتری رسید..\n",
            "متاسفانه عشقش به پولینا هم نه تنها نتونست نجاتش بده که بدتر اون رو فرو برد.. حتی آخرش هم سر عقل نیمد بنده خدا\n",
            "( باید بگم پولینام مقصر بود چرا انقد باهاش بد رفتار میکرد؟ )\n",
            "حس میکنم مادربزرگ هم نقش بزرگی توی تغییرات الکسی داشت انگار اون ولع رو بهش انتقال داد..\n",
            "فکر دیگه ای که دارم اینه که این مشکوک بودن به همه و دید بدی که به همه داشت هم باعث شد دوست هایی مثل آستلی هم ازش دور بشن..\n",
            "در کل انگار تمام راه ها رو از خودش گرفت\n",
            "چیزی که درک نکردم پاریس رفتن با بلانش بود که حقیقتا نفهمیدم واسه هوس بود یا عقده چیزی رو داشت یا نمیتونست پول داشتن رو تحمل کنه یا هزار تا چیز دیگه که واقعا واقعا نفهمیدمش.. انگار این تیکه از شخصیتش جدا بود.. خوشحال میشم اگه کسی توضیحی داره بگه\n",
            "اگه هنوز کتابو نخوندین نظر منو نگاه نکنین..\n",
            "نمیدونم چه علتی داره که جوری که قمار رو توصیف کرده بود باعث میشد منم مثل شخصیت اصلی فکر کنم.. جوری که آخر داستان که میگه نه دیگه قمار نمیکنم مطمئنم که این کار رو انجام میده که واقعا انجام میده و جالب این جاست که وقتی خودم رو جاش میذارم هم فکر میکنم منم همین کار رو انجام میدم.. حالا این ممکنه از ضعف شخصیت خودم باشه یا انقدر نویسنده خوب آدم رو با الکسی همراه کرده که قدم به قدم باهاش به فنا رفتم..\n",
            "در ضمن الکسی خیلی نسبت به اطرافیانش با حرص صحبت میکرد و فکر میکرد که از همه بهتره و کار خودش آخر به جاهای بدتری رسید..\n",
            "متاسفانه عشقش به پولینا هم نه تنها نتونست نجاتش بده که بدتر اون رو فرو برد.. حتی آخرش هم سر عقل نیمد بنده خدا\n",
            "( باید بگم پولینام مقصر بود چرا انقد باهاش بد رفتار میکرد؟ )\n",
            "حس میکنم مادربزرگ هم نقش بزرگی توی تغییرات الکسی داشت انگار اون ولع رو بهش انتقال داد..\n",
            "فکر دیگه ای که دارم اینه که این مشکوک بودن به همه و دید بدی که به همه داشت هم باعث شد دوست هایی مثل آستلی هم ازش دور بشن..\n",
            "در کل انگار تمام راه ها رو از خودش گرفت\n",
            "چیزی که درک نکردم پاریس رفتن با بلانش بود که حقیقتا نفهمیدم واسه هوس بود یا عقده چیزی رو داشت یا نمیتونست پول داشتن رو تحمل کنه یا هزار تا چیز دیگه که واقعا واقعا نفهمیدمش.. انگار این تیکه از شخصیتش جدا بود.. خوشحال میشم اگه کسی توضیحی داره بگه\n",
            "با اینکه نویسنده زمان کمی برای نوشتن این کتاب گذاشته است اما رمان خوبی از کار درآمده و شخصیت‌ها با ملیت‌های مختلف را به خوبی در کنار هم گنجانده است.\n",
            "نویسنده از معلم روسی ای می‌نویسد که اعتیاد به قمار او و زندگی‌اش را به سمت پوچی هدایت می‌کند.\n",
            "با اینکه نویسنده زمان کمی برای نوشتن این کتاب گذاشته است اما رمان خوبی از کار درآمده و شخصیت‌ها با ملیت‌های مختلف را به خوبی در کنار هم گنجانده است.\n",
            "نویسنده از معلم روسی ای می‌نویسد که اعتیاد به قمار او و زندگی‌اش را به سمت پوچی هدایت می‌کند.\n",
            "اوایل کتاب کند پیش میره تا زمانی که مادربزرگ میاد و هیجان خاص خودش رو به داستان میده. یه موردی که کم دیدم دوستان راجب کتاب بگن این بود که نویسنده خیلی خوب از حس و حال قمار کردن به مخاطب توضیح میده جوری که آدم خودشو تو اون شرایط حس میکنه و اگر تا الان این کار رو نکرده میتونه از سرنوشت شخصیت ها بفهمه که چه سرانجامی رو دنبال داره.\n",
            "اوایل کتاب کند پیش میره تا زمانی که مادربزرگ میاد و هیجان خاص خودش رو به داستان میده. یه موردی که کم دیدم دوستان راجب کتاب بگن این بود که نویسنده خیلی خوب از حس و حال قمار کردن به مخاطب توضیح میده جوری که آدم خودشو تو اون شرایط حس میکنه و اگر تا الان این کار رو نکرده میتونه از سرنوشت شخصیت ها بفهمه که چه سرانجامی رو دنبال داره.\n",
            "سلام دوستان یک سوال داشتم من تازه عضو طاقچه شدم میخواستم ببینم چجوری میشه به فلان صفحه ی مورد نظر رفت؟؟؟؟\n",
            "سلام دوستان یک سوال داشتم من تازه عضو طاقچه شدم میخواستم ببینم چجوری میشه به فلان صفحه ی مورد نظر رفت؟؟؟؟\n",
            "جالب بود! ابتداش به کندی پیش میرفت اما در ادامه جذابیت بیشتری پیدا کرد!\n",
            "عشق بی چون و چرای الکسی ایوانوویچ به پولینا عجیب بود! حالت بین عشق و تنفر که هم میتونست جونشو واسش بده و هم جونشو ازش بگیره! اخر کتاب و نگاه الکسی به پولینا و دگریو هم قابل تامل بود !\n",
            "جالب بود! ابتداش به کندی پیش میرفت اما در ادامه جذابیت بیشتری پیدا کرد!\n",
            "عشق بی چون و چرای الکسی ایوانوویچ به پولینا عجیب بود! حالت بین عشق و تنفر که هم میتونست جونشو واسش بده و هم جونشو ازش بگیره! اخر کتاب و نگاه الکسی به پولینا و دگریو هم قابل تامل بود !\n",
            "درود و سپاس بیکران عالی بود عالی\n",
            "درود و سپاس بیکران عالی بود عالی\n",
            "برا شروع خوب بود ...\n",
            "برا شروع خوب بود ...\n",
            "خیلی زیبا بود 👌 کاملا قابل درک بود که عشق به پولینا باعث شد راوی قمار باز بشه چیزی به جز پولینا براش اهمیت نداشت\n",
            "خیلی زیبا بود  کاملا قابل درک بود که عشق به پولینا باعث شد راوی قمار باز بشه چیزی به جز پولینا براش اهمیت نداشت\n",
            "داستان به کندی پیش میره و تقریبا تا قبل از ورود مادربزرگ، به علت کندی احتمال رها کردن کتاب وجود داره.\n",
            "ولی بعد از ورود مادربزرگ بسیار جذاب میشه.\n",
            "داستان به کندی پیش میره و تقریبا تا قبل از ورود مادربزرگ، به علت کندی احتمال رها کردن کتاب وجود داره.\n",
            "ولی بعد از ورود مادربزرگ بسیار جذاب میشه.\n",
            "این کتاب ها که روزای عادی هم رایگان هستند. لطفا آخر هفته ها چند تا از کتاب هایی که رایگان نیستند رو رایگان کنید!\n",
            "این کتاب ها که روزای عادی هم رایگان هستند. لطفا آخر هفته ها چند تا از کتاب هایی که رایگان نیستند رو رایگان کنید!\n",
            "کتاب خیلی خوبی بود و حرص و ولع آدمی زاد رو به خوبی توصیف می کرد ولی یک ستاره نمی دم چون تعصب ملیتی داشت\n",
            "کتاب خیلی خوبی بود و حرص و ولع آدمی زاد رو به خوبی توصیف می کرد ولی یک ستاره نمی دم چون تعصب ملیتی داشت\n",
            "اوایل، داستان بسیار کند پیش میرفت و ترجمه هم کار رو سخت تر میکرد. داستان از فصل 14 به بعد برای من جذاب تر شد. پیشنهاد میکنم اگر تونستید ترجمه های دیگر رو بخونید. در کل کتاب خوبیه ولی قطعا جزو شاهکارهای داستایوفسکی نیست. اگر میخواید داستایوفسکی رو بهتر بشناسید، جنایت و مکافات یا برادران کارامازوف روبخونید...\n",
            "اوایل، داستان بسیار کند پیش میرفت و ترجمه هم کار رو سخت تر میکرد. داستان از فصل 14 به بعد برای من جذاب تر شد. پیشنهاد میکنم اگر تونستید ترجمه های دیگر رو بخونید. در کل کتاب خوبیه ولی قطعا جزو شاهکارهای داستایوفسکی نیست. اگر میخواید داستایوفسکی رو بهتر بشناسید، جنایت و مکافات یا برادران کارامازوف روبخونید...\n",
            "نسبت به شهرت کتاب و نام نویسنده اونقدر داستان برام جذاب نبود ترجمه هم کارو سخت تر کرده بود\n",
            "نسبت به شهرت کتاب و نام نویسنده اونقدر داستان برام جذاب نبود ترجمه هم کارو سخت تر کرده بود\n",
            "به نظرم تا لحظه ورود مادربزرگ، داستان مقداری واسم کسل کننده بود حتی مواقعی که قهرمان داستان با شور و شعف زایدالوصفی با ژنرال و اطرافیانش بحث می کرد به نظرم تلاش مذبوحان نویسنده برای هیجان انگیز کردن جو داستان بوده ، بعد از ورود مادربزرگ داستان اوج گرفت.دلم واسه قهرمان داستان می سوخت به دلیل اعتیاد به قمار از اون بدتر تو چطور دلت اومد با اون همه پول با خانم بلانش بری پاریس؟! پولت رو الکی حیف و میل کنی !! ترجمه روان نبود البته نمیشه خرده گرفت چون در اون دوره این جور نثری معمول بوده\n",
            "به نظرم تا لحظه ورود مادربزرگ، داستان مقداری واسم کسل کننده بود حتی مواقعی که قهرمان داستان با شور و شعف زایدالوصفی با ژنرال و اطرافیانش بحث می کرد به نظرم تلاش مذبوحان نویسنده برای هیجان انگیز کردن جو داستان بوده ، بعد از ورود مادربزرگ داستان اوج گرفت.دلم واسه قهرمان داستان می سوخت به دلیل اعتیاد به قمار از اون بدتر تو چطور دلت اومد با اون همه پول با خانم بلانش بری پاریس؟! پولت رو الکی حیف و میل کنی !! ترجمه روان نبود البته نمیشه خرده گرفت چون در اون دوره این جور نثری معمول بوده\n",
            "رمان زیبایی بود وحالات و روحیات کاراکتر اصلی داستان رو به زیبایی بیان کرده بود\n",
            "رمان زیبایی بود وحالات و روحیات کاراکتر اصلی داستان رو به زیبایی بیان کرده بود\n",
            "نثرش به نظرم سخت و کمی پیچیده بود. کسی ترجمه روان تر سراغ داره ؟\n",
            "نثرش به نظرم سخت و کمی پیچیده بود. کسی ترجمه روان تر سراغ داره ؟\n",
            "خیلی عالی بود...ذهن رو درگیر میکنه و وادار میکنه که با روای ک همون آلکسی ایوانکوویچ هست جدال کنید گاها همراهش باشید و آخر سر هم یه دور دیگه از اول داستان رو شروع کنید...یجورایی وسوسه انگیز برای قمار کردن ولی در همون حال خواننده رو بازمیداره از هر نوع حرکتی...عشق پولینا و آلکسی ایوانکوویچ رو هم بنوعی خاص ترسیم میکنه ک داستان رو از بعد عاشقانه بیشتر پیچیده میکنه...\n",
            "خیلی عالی بود...ذهن رو درگیر میکنه و وادار میکنه که با روای ک همون آلکسی ایوانکوویچ هست جدال کنید گاها همراهش باشید و آخر سر هم یه دور دیگه از اول داستان رو شروع کنید...یجورایی وسوسه انگیز برای قمار کردن ولی در همون حال خواننده رو بازمیداره از هر نوع حرکتی...عشق پولینا و آلکسی ایوانکوویچ رو هم بنوعی خاص ترسیم میکنه ک داستان رو از بعد عاشقانه بیشتر پیچیده میکنه...\n",
            "ترجمه سروش حبیبی روان تر هست\n",
            "ترجمه سروش حبیبی روان تر هست\n",
            "ببخشید شخصیت عمه خانم بود یا مادر بزرگ؟\n",
            "و پولینا خواهر زن ژنرال بود یا دختر خواندش\n",
            "البته من صفحه ی ۷ هستم\n",
            "ببخشید شخصیت عمه خانم بود یا مادر بزرگ؟\n",
            "و پولینا خواهر زن ژنرال بود یا دختر خواندش\n",
            "البته من صفحه ی ۷ هستم\n",
            "رومان خیلی قوی هست آدمو حزب میکنه\n",
            "رومان خیلی قوی هست آدمو حزب میکنه\n",
            "کتاب خوبی بود و کلا میخواد بگه قمار بده و نابودگر زندگیه ولی به نظرم تو بیان خورده چیز ها زیاده روی شده بود .... کاش متن یکم روان تر بود و پیشنهاد من اینه که اول برین تو ویکیپدیا با اسامی داستان اشنا بشین و بعد کارتون خیلی راحت میشه 😊\n",
            "کتاب خوبی بود و کلا میخواد بگه قمار بده و نابودگر زندگیه ولی به نظرم تو بیان خورده چیز ها زیاده روی شده بود .... کاش متن یکم روان تر بود و پیشنهاد من اینه که اول برین تو ویکیپدیا با اسامی داستان اشنا بشین و بعد کارتون خیلی راحت میشه \n",
            "درگیر شدن با اسامی داستان باعث میشه از مفهوم و بیان کلی دور بشیم. قبل از شروع به خواندن کتاب حتما خلاصه ای از آن بخونید😆\n",
            "درگیر شدن با اسامی داستان باعث میشه از مفهوم و بیان کلی دور بشیم. قبل از شروع به خواندن کتاب حتما خلاصه ای از آن بخونید\n",
            "یعنی با این ترجمه... سکوت کنم بهتره😶\n",
            "یعنی با این ترجمه... سکوت کنم بهتره\n",
            "واقعا بهتر نیست ی ترمجه ی روان تر هم زده بشه ؟\n",
            "واقعا بهتر نیست ی ترمجه ی روان تر هم زده بشه ؟\n",
            "عالیه.\n",
            "باید بگم که رذیلت های اخلاقی رو خیلی خوب به تصویر می کشه.حسش می کنی.هم وسوسه رو و هم زشتی اش رو. که یکی اش هم قماره\n",
            "یکی از دوستان رمان خوندم گفت دوست داشتنی ترین کتاب داستایوفسکیه\n",
            "ولی به نظرم همزمان یه کتاب دیگه که نشون دهنده فضیلت های اخلاقی هست رو بخونید که زندگی با این شخصیت های منفی تاثیر بد زیادی تو روحیه تون نذاره\n",
            "من همزمان کتاب «چمران، مردی برای تمام فصول» رو می خوندم\n",
            "عالیه.\n",
            "باید بگم که رذیلت های اخلاقی رو خیلی خوب به تصویر می کشه.حسش می کنی.هم وسوسه رو و هم زشتی اش رو. که یکی اش هم قماره\n",
            "یکی از دوستان رمان خوندم گفت دوست داشتنی ترین کتاب داستایوفسکیه\n",
            "ولی به نظرم همزمان یه کتاب دیگه که نشون دهنده فضیلت های اخلاقی هست رو بخونید که زندگی با این شخصیت های منفی تاثیر بد زیادی تو روحیه تون نذاره\n",
            "من همزمان کتاب «چمران، مردی برای تمام فصول» رو می خوندم\n",
            "کتاب های این نویسنده قلق داره خوندنش\n",
            "۱: زیاد در گیر اسمها نشید\n",
            "( روسا اسمای پیچیده ای دارن)\n",
            "۲:شخصیت های داستان عموما روح تاریکی دارن\n",
            "(یعنی شخصیت پردازیاش وسواس داشته تو پرداختن به اونا)\n",
            "۳:هر مدتی یه نفس عمیق بکشید و محیط و عوض کنید چون واقعا دیوانه نشد افسردتونم نکنه حتما فکرتونو مشغول میکنه\n",
            "۴:از حجم زیاد داستان نترسید خیلی تو پرداخت داستانی زیاده روی کرده\n",
            "(چهار صفحه میخونی تازه داشته حالت درونیه طرفو تو ضیح میداده\n",
            "خلاصه سخت نگیرید و حال کنید باش.😋\n",
            "کتاب های این نویسنده قلق داره خوندنش\n",
            "۱: زیاد در گیر اسمها نشید\n",
            "( روسا اسمای پیچیده ای دارن)\n",
            "۲:شخصیت های داستان عموما روح تاریکی دارن\n",
            "(یعنی شخصیت پردازیاش وسواس داشته تو پرداختن به اونا)\n",
            "۳:هر مدتی یه نفس عمیق بکشید و محیط و عوض کنید چون واقعا دیوانه نشد افسردتونم نکنه حتما فکرتونو مشغول میکنه\n",
            "۴:از حجم زیاد داستان نترسید خیلی تو پرداخت داستانی زیاده روی کرده\n",
            "(چهار صفحه میخونی تازه داشته حالت درونیه طرفو تو ضیح میداده\n",
            "خلاصه سخت نگیرید و حال کنید باش.\n",
            "این کتاب چطوره؟لطفا نظرتونوبگید.ارزش خوندن داره؟\n",
            "این کتاب چطوره؟لطفا نظرتونوبگید.ارزش خوندن داره؟\n",
            "وای خیلی سختمه این کتابو ادامه بدم هی بر میگردم عقب.\n",
            "وای خیلی سختمه این کتابو ادامه بدم هی بر میگردم عقب.\n",
            "لطفا یه کتاب خوب معرفی کنید تازه سمفونی مردگان رو تموم کردم از تو بحرش در بیام\n",
            "لطفا یه کتاب خوب معرفی کنید تازه سمفونی مردگان رو تموم کردم از تو بحرش در بیام\n",
            "ترجمه های استاد آل احمد که شیواست\n",
            "منتها اول داستان چون با تعداد زیادی اسامی ناشناس روبرو میشی ترغیب به ادامه مطالعه صورت نمی گیره\n",
            "ترجمه های استاد آل احمد که شیواست\n",
            "منتها اول داستان چون با تعداد زیادی اسامی ناشناس روبرو میشی ترغیب به ادامه مطالعه صورت نمی گیره\n",
            "😥\n",
            "یه پیشنهاد به عزیزانی که میخواهند این کتاب را بخوانند ، این کتاب تا انتهای فصل ۴ که حدود ۸۴ صفحه میشود ، گنگ و کسل کننده است ، این ۴ فصل را بدون تامل و با سرعت بخوانید و از فصل ۵ به بعد داستان روان میشود و دلچسب جوری که دلتان نمیخواهد رهایش کنید ،،، و در انتها میتوانید این ۴ فصل اول را دوباره بخوانید تا گنگ بودن آن از بین برود ، در این چهار فصل اصلا معلوم نیست که راوی دقیقا کیست ، مرد است یا زن ؟ و افراد دیگر هم گنگ هستند ولی از فصل ۵ به بعد همه چی روشن میشود ،،،\n",
            "شخصیت های داستان\n",
            "۱- الکسی ایوانوویچ : شخصیت اصلی و راوی داستان( آموزگار دو بچه ژنرال که کم از یک خدمتکار ندارد😥 ارزش معلم در نگاه روس ها ظاهرا خیلی پایین است)\n",
            "۲- پولینا : دختر خوانده ژنرال که معشوقه الکسی هستش\n",
            "۳- ژنرال : مردی روس تبار که خودباخته و مال باخته است\n",
            "۴- مادمازل بلانش : 😠 زنی فرصت طلب و خوش گذران که .....\n",
            "۵- دگریو یا همان مردک فرانسوی: کسی که ژنرال به او مقروض است و اسیر او ۶- بابوشکا : خاله ژنرال که خیلی ثروتمند است و همه بی صبرانه منتظر مرگش هستند تا ارثی ......\n",
            "۷- مستر آستلی : مرد انگلیسی .\n",
            ".\n",
            ".\n",
            "کتابیست عالی در وصف قمار ، که چه بلاییست خانمان سوز که به راحتی میتواند نه تنها خانواده ای را بلکه جامعه ای را متلاشی کند\n",
            "\n",
            "یه پیشنهاد به عزیزانی که میخواهند این کتاب را بخوانند ، این کتاب تا انتهای فصل ۴ که حدود ۸۴ صفحه میشود ، گنگ و کسل کننده است ، این ۴ فصل را بدون تامل و با سرعت بخوانید و از فصل ۵ به بعد داستان روان میشود و دلچسب جوری که دلتان نمیخواهد رهایش کنید ،،، و در انتها میتوانید این ۴ فصل اول را دوباره بخوانید تا گنگ بودن آن از بین برود ، در این چهار فصل اصلا معلوم نیست که راوی دقیقا کیست ، مرد است یا زن ؟ و افراد دیگر هم گنگ هستند ولی از فصل ۵ به بعد همه چی روشن میشود ،،،\n",
            "شخصیت های داستان\n",
            "۱- الکسی ایوانوویچ : شخصیت اصلی و راوی داستان( آموزگار دو بچه ژنرال که کم از یک خدمتکار ندارد ارزش معلم در نگاه روس ها ظاهرا خیلی پایین است)\n",
            "۲- پولینا : دختر خوانده ژنرال که معشوقه الکسی هستش\n",
            "۳- ژنرال : مردی روس تبار که خودباخته و مال باخته است\n",
            "۴- مادمازل بلانش :  زنی فرصت طلب و خوش گذران که .....\n",
            "۵- دگریو یا همان مردک فرانسوی: کسی که ژنرال به او مقروض است و اسیر او ۶- بابوشکا : خاله ژنرال که خیلی ثروتمند است و همه بی صبرانه منتظر مرگش هستند تا ارثی ......\n",
            "۷- مستر آستلی : مرد انگلیسی .\n",
            ".\n",
            ".\n",
            "کتابیست عالی در وصف قمار ، که چه بلاییست خانمان سوز که به راحتی میتواند نه تنها خانواده ای را بلکه جامعه ای را متلاشی کند\n",
            "احترام زیادی برای آقای داستایوفسکی قائلم اما نتونستم زیاد با این کتابشون ارتباط برقرار کنم سعی می کنم یک باره دیگه این کتاب رو مطالعه کنم\n",
            "احترام زیادی برای آقای داستایوفسکی قائلم اما نتونستم زیاد با این کتابشون ارتباط برقرار کنم سعی می کنم یک باره دیگه این کتاب رو مطالعه کنم\n",
            "یادمه تو دبیرستان خوندم و به معلم ادبیاتمون دادم بخونند که هدف نویسنده رو بفهمم! فرصت نکردند بخونند و هنوز هم قمارباز از کتاب هاییه که خیلی نفهمیدمش.\n",
            "یادمه تو دبیرستان خوندم و به معلم ادبیاتمون دادم بخونند که هدف نویسنده رو بفهمم! فرصت نکردند بخونند و هنوز هم قمارباز از کتاب هاییه که خیلی نفهمیدمش.\n",
            "نمیدونم چرا حس میکنم که انگار داره تو شخصیت دگریو که یه فرانسویه(از اون به عنوان یه فرانسوی حیله گر و مکار یاد میکنه) اغراق میکنه ؟\n",
            "نمیدونم چرا حس میکنم که انگار داره تو شخصیت دگریو که یه فرانسویه(از اون به عنوان یه فرانسوی حیله گر و مکار یاد میکنه) اغراق میکنه ؟\n",
            "سلام من این رمان رو خوندم ولی به نظرم زیاد جذاب نبود فقط اطلاعات خوبی درباره ملتهای مختلف کسب کردم مثل ملت روسیه یا فرانسه یاانگلیس\n",
            "سلام من این رمان رو خوندم ولی به نظرم زیاد جذاب نبود فقط اطلاعات خوبی درباره ملتهای مختلف کسب کردم مثل ملت روسیه یا فرانسه یاانگلیس\n",
            "بنظرم کتابهای روسی خیلی کسل کننده هستند و تحملش برای من سخته واقعا\n",
            "بنظرم کتابهای روسی خیلی کسل کننده هستند و تحملش برای من سخته واقعا\n",
            "به نظر من عالیه\n",
            "به نظر من عالیه\n",
            "سلام. آیا کسی میدونه کتابهایی ک نشون میکنیم کجا میره دقیقا.?\n",
            "سلام. آیا کسی میدونه کتابهایی ک نشون میکنیم کجا میره دقیقا.?\n",
            "آقا تو رو خدا یکی بگه چطوری میشه هدیه داد تو رو خداااا\n",
            "دوم این که آیا میشه بدون سیم کارت از طاقچه استفاده کرد؟خ\n",
            "آقا تو رو خدا یکی بگه چطوری میشه هدیه داد تو رو خداااا\n",
            "دوم این که آیا میشه بدون سیم کارت از طاقچه استفاده کرد؟خ\n",
            "Mehdi Tamadon Rastegar\n",
            "درباره انسانهای حریص است که خاک گور طمع آنها را کم کند.خوب شخصیت پردازی کرده است.\n",
            "Mehdi Tamadon Rastegar\n",
            "درباره انسانهای حریص است که خاک گور طمع آنها را کم کند.خوب شخصیت پردازی کرده است.\n",
            "خیلی خوب شخصیت پردازی میکنه\n",
            "خیلی خوب شخصیت پردازی میکنه\n",
            "عالی👌\n",
            "شخصیت پردازی که حرف نداشت\n",
            "عالی\n",
            "شخصیت پردازی که حرف نداشت\n",
            "ممنون از ناشر که این نوسخه رو رایگان گذاشت\n",
            "ممنون از ناشر که این نوسخه رو رایگان گذاشت\n",
            "زیادجذاب نبود\n",
            "زیادجذاب نبود\n",
            "ببخشید یه کتاب خوب به من معرفی می کنید ؟؟؟\n",
            "ببخشید یه کتاب خوب به من معرفی می کنید ؟؟؟\n",
            "به نظر من جذاب بود\n",
            "به نظر من جذاب بود\n",
            "تقریبا تا نیمه ی کتاب جذاب نبود، بعد از اون هم کشش زیادی نداشت.\n",
            "تقریبا تا نیمه ی کتاب جذاب نبود، بعد از اون هم کشش زیادی نداشت.\n",
            "کجای حافظه گوشی میتونم به کتاب دسترسی داشته باشم ؟ می‌خوام تبدیل کنم بفرستم روی کتابخوان کیندل ام\n",
            "کجای حافظه گوشی میتونم به کتاب دسترسی داشته باشم ؟ می‌خوام تبدیل کنم بفرستم روی کتابخوان کیندل ام\n",
            "کتاب جذابی بود چون تا اواسط کتاب شخص اول مشخص نبود کمی گیج کننده بود ولی در کل خوب بود\n",
            "کتاب جذابی بود چون تا اواسط کتاب شخص اول مشخص نبود کمی گیج کننده بود ولی در کل خوب بود\n",
            "خود کتاب داستان جذابی نداشت و ترجمه جلال کار رو بدتر کرده بود\n",
            "خود کتاب داستان جذابی نداشت و ترجمه جلال کار رو بدتر کرده بود\n",
            "یه جاهاییش خوب بود ، ولی خسته کننده بود ، جذابیتش خیلی کم بود .\n",
            "یه جاهاییش خوب بود ، ولی خسته کننده بود ، جذابیتش خیلی کم بود .\n",
            "پایانی عجیب ، حسی عجیب و عشقی عجیب کتابی که به هر کس میتواند موقعیت زمانی را که داستایفسکی خواستار تلقینش به مخاطب بوده را منتقل کند.\n",
            "ولی امان از ترجمه ی جلال آل احمد :|\n",
            "پایانی عجیب ، حسی عجیب و عشقی عجیب کتابی که به هر کس میتواند موقعیت زمانی را که داستایفسکی خواستار تلقینش به مخاطب بوده را منتقل کند.\n",
            "ولی امان از ترجمه ی جلال آل احمد :|\n",
            "آثار نویسنده های روسی فوق العاده اس\n",
            "آثار نویسنده های روسی فوق العاده اس\n",
            "اگه میشه در ریپلای این پیام در مورد پایانش نظر بدین. ممنون🙏\n",
            "اگه میشه در ریپلای این پیام در مورد پایانش نظر بدین. ممنون\n",
            "💣💣💣 خطر لو رفتن 💣💣💣\n",
            "آلکسی ایوانویچ معلم سرخانه ی بچه های ژنرال است، و به صورتی بسیار ناگهانی عاشق پولینا دخترخوانده ی ژنرال می شود.\n",
            "آلکسی ایوانویچ با حرف پولینا شروع به قمار می کند و در لجن فرو می رود و هربار حریص تر از بار قبل می شود.\n",
            "آلکسی در آخر تصمیم می گیرد به خاطر پولینا قمار را کنار بگذارد امادر سطور پایانی نویسنده شوک بسیار بزرگی بر مخاطب وارد می کند.\n",
            "💣💣💣💣💣\n",
            "برخلاف شروع بسیار کسل کننده ی داستان به نظرم جمع بندی و پایان بسیار خوبی داشت به طوری که خواننده بسیار غافل گیر می شد.\n",
            "عشق آلکسی به پولینا بسیار عجیب و غیر قابل باور به نظر می آمد.\n",
            "نثر کتاب روان نبود که قطعا ترجمه در آن دخیل است و شاید یکی از علل کسل کننده بودن اوایل رمان همین باشد.\n",
            "در کل خوب بود خوشحالم یک کتاب روسی باعث شد من یاد آیه ی قرآن بیفتم.\n",
            "\"از تو درباره ی شراب و قمار می پرسند بگو در آنها گناه وضرر بزرگی وجود دارد و منافع نیز برای مردم در بردارند ولی ضرر آنها بیشتر از نفعشان است\" بقره ۲۱۹\n",
            " خطر لو رفتن \n",
            "آلکسی ایوانویچ معلم سرخانه ی بچه های ژنرال است، و به صورتی بسیار ناگهانی عاشق پولینا دخترخوانده ی ژنرال می شود.\n",
            "آلکسی ایوانویچ با حرف پولینا شروع به قمار می کند و در لجن فرو می رود و هربار حریص تر از بار قبل می شود.\n",
            "آلکسی در آخر تصمیم می گیرد به خاطر پولینا قمار را کنار بگذارد امادر سطور پایانی نویسنده شوک بسیار بزرگی بر مخاطب وارد می کند.\n",
            "\n",
            "برخلاف شروع بسیار کسل کننده ی داستان به نظرم جمع بندی و پایان بسیار خوبی داشت به طوری که خواننده بسیار غافل گیر می شد.\n",
            "عشق آلکسی به پولینا بسیار عجیب و غیر قابل باور به نظر می آمد.\n",
            "نثر کتاب روان نبود که قطعا ترجمه در آن دخیل است و شاید یکی از علل کسل کننده بودن اوایل رمان همین باشد.\n",
            "در کل خوب بود خوشحالم یک کتاب روسی باعث شد من یاد آیه ی قرآن بیفتم.\n",
            "\"از تو درباره ی شراب و قمار می پرسند بگو در آنها گناه وضرر بزرگی وجود دارد و منافع نیز برای مردم در بردارند ولی ضرر آنها بیشتر از نفعشان است\" بقره ۲۱۹\n",
            "قشنگه ریتمش سریعه هرچیم بگذره جذاب تر میشه پیشنهاد میشود !\n",
            "قشنگه ریتمش سریعه هرچیم بگذره جذاب تر میشه پیشنهاد میشود !\n",
            "خوب بود اوایل داستان جذاب نبود کم کم جذابیت داستان زیاد شد و قسمت اخر داستان رو نویسنده زود جمع کرد\n",
            "خوب بود اوایل داستان جذاب نبود کم کم جذابیت داستان زیاد شد و قسمت اخر داستان رو نویسنده زود جمع کرد\n",
            "جذاب بود مرسی\n",
            "جذاب بود مرسی\n",
            "خوب بود ولی چون داستایوفسکی این کتابو با عجله نوشته (اگه دقت کنین اشاره شده) نگارش معمولی داشت ولی در کل بد نبود\n",
            "خوب بود ولی چون داستایوفسکی این کتابو با عجله نوشته (اگه دقت کنین اشاره شده) نگارش معمولی داشت ولی در کل بد نبود\n",
            "ریسک پذیریمو بالا برد👍\n",
            "ریسک پذیریمو بالا برد\n",
            "زیبا بود و البته اموزنده\n",
            "زیبا بود و البته اموزنده\n",
            "خوندم و بسیار جذاب و شیرین بود علی الخصوص که داستان واقعیه خود نویسندست\n",
            "خوندم و بسیار جذاب و شیرین بود علی الخصوص که داستان واقعیه خود نویسندست\n",
            "تازه شروع کردم بخونمش ۱۰ صفحه اول رو خوندم فعلا چیزی ازش نفهمیدم خخخخ مثل ابتدای سریالهای ایرانی هست تا میخواد راه بیفته کمی طول میکشه درواقع داره تاتی تاتی میکنه خخخخ\n",
            "تازه شروع کردم بخونمش ۱۰ صفحه اول رو خوندم فعلا چیزی ازش نفهمیدم خخخخ مثل ابتدای سریالهای ایرانی هست تا میخواد راه بیفته کمی طول میکشه درواقع داره تاتی تاتی میکنه خخخخ\n",
            "چه داستانی، توصیه میکنم حتما بخونید . اولش رو طاقت بیارین ، دیگه دوست نخواهید داشت تموم بشه . ترجمه عالی . همه چی عالی خیلی خوبه این کتاب\n",
            "چه داستانی، توصیه میکنم حتما بخونید . اولش رو طاقت بیارین ، دیگه دوست نخواهید داشت تموم بشه . ترجمه عالی . همه چی عالی خیلی خوبه این کتاب\n",
            "اوایل داستان یکم کند پیش میره ولی بعدش خوب میشه ونزدیک به پایان داستان که همش دوست داشتم ببینم چی میشه ، پنجاه صفحه اخر و یک جا خوندم و کلی لذت بردم.. ترجمه هم خوب بود من لذت بردم درکل...ممنون از طاقچه\n",
            "اوایل داستان یکم کند پیش میره ولی بعدش خوب میشه ونزدیک به پایان داستان که همش دوست داشتم ببینم چی میشه ، پنجاه صفحه اخر و یک جا خوندم و کلی لذت بردم.. ترجمه هم خوب بود من لذت بردم درکل...ممنون از طاقچه\n",
            "برای من جذاب نبود😞\n",
            "برای من جذاب نبود\n",
            "این کتاب رو سال گذشته خوندم و لذت بردم ، بسیار زیبا و خواندنی\n",
            "این کتاب رو سال گذشته خوندم و لذت بردم ، بسیار زیبا و خواندنی\n",
            "بسیار عالی و زبیاست...\n",
            "بسیار عالی و زبیاست...\n",
            "کسل کننده بود\n",
            "کسل کننده بود\n",
            "ترجمه این اثر اصلا جالب نیست\n",
            "ترجمه این اثر اصلا جالب نیست\n",
            "تا حالا ازش کتاب نخوندم، از اشتاین بک و هوگو و همینگوی کتاب هایی خوانده ام اما از روسیه هیچ نخوانده ام.\n",
            "تا حالا ازش کتاب نخوندم، از اشتاین بک و هوگو و همینگوی کتاب هایی خوانده ام اما از روسیه هیچ نخوانده ام.\n",
            "داستایوفسکی درحدیه که میشه پرستیدش!لعنتی❤\n",
            "داستایوفسکی درحدیه که میشه پرستیدش!لعنتی\n",
            "شاهکاره این کتاب در نهایت سادگی چنان مشکل فجیعی رو در زندگی آدم مطرح میکنه. واقعا کتاب ساده و عمیقیه👌\n",
            "شاهکاره این کتاب در نهایت سادگی چنان مشکل فجیعی رو در زندگی آدم مطرح میکنه. واقعا کتاب ساده و عمیقیه\n",
            "هر کتابی از مهم ترین بخش هایش اول داستانه اما واقعا اول داستان بسیار کسل کننده و گنگه . از خوندن بقیه داستان ادم رو منصرف میکنه\n",
            "هر کتابی از مهم ترین بخش هایش اول داستانه اما واقعا اول داستان بسیار کسل کننده و گنگه . از خوندن بقیه داستان ادم رو منصرف میکنه\n",
            "طاقچه دمت گرم با این تخفیف نمایشگاهی \n",
            "عالیییییییی\n",
            "طاقچه دمت گرم با این تخفیف نمایشگاهی \n",
            "عالیییییییی\n",
            "عالی ، اما فقط برای یکبار خوندن\n",
            "عالی ، اما فقط برای یکبار خوندن\n",
            "کتاباشو خیلیدوست دارم. بخصوص محاکمه این نویسنده رو\n",
            "کتاباشو خیلیدوست دارم. بخصوص محاکمه این نویسنده رو\n",
            "نمیدونم چرا حس میکنم یه چیزی تو کتابای داستایوفسکی کمه  شاید نتیجه گیری نهایی اخرشون نمیدونم به چی میرسیم\n",
            "نمیدونم چرا حس میکنم یه چیزی تو کتابای داستایوفسکی کمه  شاید نتیجه گیری نهایی اخرشون نمیدونم به چی میرسیم\n",
            "داستا یوبسکی حرف نداره . من که خوشم اومد .\n",
            "داستا یوبسکی حرف نداره . من که خوشم اومد .\n",
            "کتاب خیلی خوبی بود\n",
            "دقیقا همینطوره\n",
            "باید توی گروهها و حزبهای سیاسی بود تا گند و کثافتشون رو ببینی\n",
            "باید بینشان بود تا ببینی اعمال و رفتار رهبران چقدر با گفتارشون فرق میکنه\n",
            "برای کسب قدرت تن به هر رذالتی میدهند\n",
            "کتاب خیلی خوبی بود\n",
            "دقیقا همینطوره\n",
            "باید توی گروهها و حزبهای سیاسی بود تا گند و کثافتشون رو ببینی\n",
            "باید بینشان بود تا ببینی اعمال و رفتار رهبران چقدر با گفتارشون فرق میکنه\n",
            "برای کسب قدرت تن به هر رذالتی میدهند\n",
            "این کتاب یه نمایشنامه ی سیاسی هست .\n",
            "اوایلش هوگو خیلی حرف میزد حوصله ام رو سر میبرد ومنم بعضی جمله ها رو نخونده ردمیکردم.\n",
            "اگه سیاست رو دوست دارین. بخونیدش\n",
            "این کتاب یه نمایشنامه ی سیاسی هست .\n",
            "اوایلش هوگو خیلی حرف میزد حوصله ام رو سر میبرد ومنم بعضی جمله ها رو نخونده ردمیکردم.\n",
            "اگه سیاست رو دوست دارین. بخونیدش\n",
            "نفسگیر و زیبا. شخصیت پردازی فوق العاده. هرکدوم از شخصیت های اصلی این نمایشنامه میتونن نماینده ی تام تیپ های مختلف سیاسی تو زمان های مختلف باشن. سارتر به خوبی تونسته به مخاطب نشون بده که هوده رر و هوگو دو وجه یک انسان سردرگم بین افراط و تفریط هستن که در نهایت هر دو به نحوی شکست خورده اند؛ یکی با کشته شدن توسط اونیکی، اونیکی با کشتن اینیکی! فکر کنم سارتر میخواست بگه که باید هورر و هوگو با هم ترکیب میشدن تا چیز درستی از آب درمی اومد! صفحات آخر کتاب، بحثهای نهایی هوگو و اولگا فوق العاده ست! خوددرگیری انسان رو به خوبی ... به خوبی نه، فوق العاده نشون میده! من شیفته ش شدم. فقط اشتباهات تایپی زیاده.\n",
            "نفسگیر و زیبا. شخصیت پردازی فوق العاده. هرکدوم از شخصیت های اصلی این نمایشنامه میتونن نماینده ی تام تیپ های مختلف سیاسی تو زمان های مختلف باشن. سارتر به خوبی تونسته به مخاطب نشون بده که هوده رر و هوگو دو وجه یک انسان سردرگم بین افراط و تفریط هستن که در نهایت هر دو به نحوی شکست خورده اند؛ یکی با کشته شدن توسط اونیکی، اونیکی با کشتن اینیکی! فکر کنم سارتر میخواست بگه که باید هورر و هوگو با هم ترکیب میشدن تا چیز درستی از آب درمی اومد! صفحات آخر کتاب، بحثهای نهایی هوگو و اولگا فوق العاده ست! خوددرگیری انسان رو به خوبی ... به خوبی نه، فوق العاده نشون میده! من شیفته ش شدم. فقط اشتباهات تایپی زیاده.\n",
            "نمایشنامه خیلی خوبیه، شخصیت اصلی یک ایده‌آل گرا هست و مشکلات اونو در دنیای واقعی نشون میده!\n",
            "ترجمه یک خرده مشکل داشت و یکم بعضی جاها گنگ بود ولی در کل خوب بودش.\n",
            "نمایشنامه خیلی خوبیه، شخصیت اصلی یک ایده‌آل گرا هست و مشکلات اونو در دنیای واقعی نشون میده!\n",
            "ترجمه یک خرده مشکل داشت و یکم بعضی جاها گنگ بود ولی در کل خوب بودش.\n",
            "فوق العاده بود👍\n",
            "فوق العاده بود\n",
            "چون یکم سیاسی بود من زیاد دوس نداشتم😐ولیکن ژسیکا رو بیشتر از اولگا دوست داشتم😅\n",
            "چون یکم سیاسی بود من زیاد دوس نداشتمولیکن ژسیکا رو بیشتر از اولگا دوست داشتم\n",
            "«هوگو در این گیر و دار دلبسته‌ی همسر هوده‌رر می‌شود» خلاصه‌ی غلط!\n",
            "خود نمایشنامه هم زیاد باب طبع من نبود. البته ایده جالبی بود، اما بخشی از دیالوگ‌ها رو دوست نداشتم، و همینطور ترجمه یکدست و روان نبود، با دوگانگی زبانی.\n",
            "«هوگو در این گیر و دار دلبسته‌ی همسر هوده‌رر می‌شود» خلاصه‌ی غلط!\n",
            "خود نمایشنامه هم زیاد باب طبع من نبود. البته ایده جالبی بود، اما بخشی از دیالوگ‌ها رو دوست نداشتم، و همینطور ترجمه یکدست و روان نبود، با دوگانگی زبانی.\n",
            "نمایش نامه بسیار جالبی است که در مورد سیاست و احزاب سیاسیت، کتاب راجع به فردی ست که به یک حزب سیاسی بسیار معتقد است و برای آن بسیار تلاش میکند و به زندان میرود و.... ولی بعدا متوجه میشود آرمان های حزب کاملا تغییر کرده و...، کتاب کاملا به پیچیدگی و غیرقابل پیش بینی بودن سیاست اشاره دارد، بنظر من خیلی خوب و جالب و آموزنده بود\n",
            "نمایش نامه بسیار جالبی است که در مورد سیاست و احزاب سیاسیت، کتاب راجع به فردی ست که به یک حزب سیاسی بسیار معتقد است و برای آن بسیار تلاش میکند و به زندان میرود و.... ولی بعدا متوجه میشود آرمان های حزب کاملا تغییر کرده و...، کتاب کاملا به پیچیدگی و غیرقابل پیش بینی بودن سیاست اشاره دارد، بنظر من خیلی خوب و جالب و آموزنده بود\n",
            "چجوری میشه ذخیره اش کرد و توو کامپیوتر خوندش ؟؟؟؟\n",
            "چجوری میشه ذخیره اش کرد و توو کامپیوتر خوندش ؟؟؟؟\n",
            "واقعا عالیه، ایشالا تا انتها همینطوری باشه.\n",
            "واقعا عالیه، ایشالا تا انتها همینطوری باشه.\n",
            "نمیدونم چرا من ژسیکا رو بیشتر از اولگا دوس دارم 😐\n",
            "نمیدونم چرا من ژسیکا رو بیشتر از اولگا دوس دارم \n",
            "تا وسط داستان خسته کننده بود اما بعد عالی بود ارزش خوندن داره واقعا\n",
            "تا وسط داستان خسته کننده بود اما بعد عالی بود ارزش خوندن داره واقعا\n",
            "بنظر من چنتا نکته رو میشه از این کتاب برداشت کرد ونویسنده بهش اشاره کرده:\n",
            "۱.نویسنده در تلاشه تا اهداف احزاب رو نشون بده که مدام در حال تغییرن و خیلی ازونها به هدف اولیشون پایبند نیستن.\n",
            "۲.کشتن برای قدرت خیلی توی سیاست مرسومه\n",
            "۳.قدرت انسان ها رو عوض میکنه....اونها حاضرن برای قدرت دروغ بگن آدم بکشن ....اعمالی که توی هر دین و مذهبی نکوهش شده\n",
            "درکل خیلی نکات میشه از کتاب درآورد.\n",
            "راجع به خود نمایش نامه از لحاظ غیرقابل پیش بینی بودن خیلی عالیه و همین باعث بالا اومدنش شده تا حدودی....\n",
            "اما در کل زیاد از داستانش خوشم نیومد\n",
            "بنظر من چنتا نکته رو میشه از این کتاب برداشت کرد ونویسنده بهش اشاره کرده:\n",
            "۱.نویسنده در تلاشه تا اهداف احزاب رو نشون بده که مدام در حال تغییرن و خیلی ازونها به هدف اولیشون پایبند نیستن.\n",
            "۲.کشتن برای قدرت خیلی توی سیاست مرسومه\n",
            "۳.قدرت انسان ها رو عوض میکنه....اونها حاضرن برای قدرت دروغ بگن آدم بکشن ....اعمالی که توی هر دین و مذهبی نکوهش شده\n",
            "درکل خیلی نکات میشه از کتاب درآورد.\n",
            "راجع به خود نمایش نامه از لحاظ غیرقابل پیش بینی بودن خیلی عالیه و همین باعث بالا اومدنش شده تا حدودی....\n",
            "اما در کل زیاد از داستانش خوشم نیومد\n",
            "یکی از بهترین نمایشنامه های دنیاست .اتود فردا تمرین تائاتر منم هست😊\n",
            "یکی از بهترین نمایشنامه های دنیاست .اتود فردا تمرین تائاتر منم هست\n",
            "وای بهترین کتابی هست ک خوندم و دوس دارم بارها بخونمش یه سبک جدیدی داشت و خیلی درس بزرگی میده با خوندن این کتاب بود ک فهمیدم واقعا کتاب خوندن باعث میشه تجربه هات زیاد بشه . هر چی بگم کم گفتم .حتما بخونید اما نه به عنوان اولین کتاب ک متوجه بشید چقدر با بقیه کتابا فرق داره وچقد متفاوت\n",
            "وای بهترین کتابی هست ک خوندم و دوس دارم بارها بخونمش یه سبک جدیدی داشت و خیلی درس بزرگی میده با خوندن این کتاب بود ک فهمیدم واقعا کتاب خوندن باعث میشه تجربه هات زیاد بشه . هر چی بگم کم گفتم .حتما بخونید اما نه به عنوان اولین کتاب ک متوجه بشید چقدر با بقیه کتابا فرق داره وچقد متفاوت\n",
            "بسیار زیبا وقوی نوشته شده حتما بخونیدش\n",
            "بسیار زیبا وقوی نوشته شده حتما بخونیدش\n",
            "این نمایشنامه مثل یک چاقوی دو لبه برای افرادی است که می خواهند مبارزه با حکومت یا سیستم ناکارآمدی را آغاز کنند از یک طرف ( منفی) افراد حقیقت جو با تطبیق رویدادهای نمایشنامه با وضعیت سیاسی اجتماعی روزگار خود ممکن است از عضویت و فعالیت در تشکیلات و یا حتی یک تجمع مسالمت آمیز خودداری کنند و مایوسانه همه مبارزات را از ابتدا شکست خورده تلقی کنند ( البته در دنیای واقعی انسان ها معمولا میوه مبارزات خود را می چینند که اگر اینگونه نبود هنوز برده داری در دنیا رواج داشت و حکومت آپارتاید در آفریقای جنوبی جولان میداد و زنان اروپا و آمریکا حق رای نداشتند و....)\n",
            "از طرف دیگر ( مثبت) به آزادیخواهان می آموزد که هرگز در تلاش های صادقانه خود، وجدان و اخلاقیات خود را فدای اسامی و شهرت سازمان یا حزب یا تشکیلاتی که عضویت آن را داوطلبانه پذیرفته اند، نکنند. مبارزان راه آزادی همواره باید مراقب باشند در تلاش برای درمان بیماری های سیاسی و اجتماعی حاکم بر جامعه ، خود بیمار نگردند!\n",
            "این نمایشنامه مثل یک چاقوی دو لبه برای افرادی است که می خواهند مبارزه با حکومت یا سیستم ناکارآمدی را آغاز کنند از یک طرف ( منفی) افراد حقیقت جو با تطبیق رویدادهای نمایشنامه با وضعیت سیاسی اجتماعی روزگار خود ممکن است از عضویت و فعالیت در تشکیلات و یا حتی یک تجمع مسالمت آمیز خودداری کنند و مایوسانه همه مبارزات را از ابتدا شکست خورده تلقی کنند ( البته در دنیای واقعی انسان ها معمولا میوه مبارزات خود را می چینند که اگر اینگونه نبود هنوز برده داری در دنیا رواج داشت و حکومت آپارتاید در آفریقای جنوبی جولان میداد و زنان اروپا و آمریکا حق رای نداشتند و....)\n",
            "از طرف دیگر ( مثبت) به آزادیخواهان می آموزد که هرگز در تلاش های صادقانه خود، وجدان و اخلاقیات خود را فدای اسامی و شهرت سازمان یا حزب یا تشکیلاتی که عضویت آن را داوطلبانه پذیرفته اند، نکنند. مبارزان راه آزادی همواره باید مراقب باشند در تلاش برای درمان بیماری های سیاسی و اجتماعی حاکم بر جامعه ، خود بیمار نگردند!\n",
            "واقعا لذت بخش بود\n",
            "برای منی که عقاید سیاسی و علاقه به سیاست دارم\n",
            "واقعا لذت بخش بود\n",
            "برای منی که عقاید سیاسی و علاقه به سیاست دارم\n",
            "کتابش خیلی خوب بود همین طور ترجمه ش\n",
            "کتابش خیلی خوب بود همین طور ترجمه ش\n",
            "بسیار نمایشنامه ی گیرا و جذابی بود ، من هم مانند هوگو از رفتار و منش و البته عقائد نه چندان جالب هوده رر خوشم آمده و از افرادی مانند لویی که نماد انسانهایی خشکه مقدس که فقط نظر خود را قبول دارند و مصلحت اندیشی را مختص خود میدانند متنفر و بیزارم .\n",
            "هوگو قربانی زود باوری و اعتماد های بیجای خود شد .\n",
            "و چه جالب است که بسیاری از آرمان ها و عقائد و افکار حزبشان قرابت خاصی با حزب توده و سازمان مجاهدین دارد ، دقیقا همچین تشکیلاتی را با همان اهداف در تاریخ کشور خودمان داشته ایم و شک ندارم که در هر انقلابی در دنیا همچین تشکیلاتی با همان رویکردها وجود داشته است و خواهد داشت چون سناریو نویس قهاری پشت این جریان ها وجود دارد و او کسی نیست جز ابلیس ، که تمام تلاش خود را میکند تا انسان را از انسانیتش دور کند به هر نحوی که شده ،\n",
            "بسیار نمایشنامه ی گیرا و جذابی بود ، من هم مانند هوگو از رفتار و منش و البته عقائد نه چندان جالب هوده رر خوشم آمده و از افرادی مانند لویی که نماد انسانهایی خشکه مقدس که فقط نظر خود را قبول دارند و مصلحت اندیشی را مختص خود میدانند متنفر و بیزارم .\n",
            "هوگو قربانی زود باوری و اعتماد های بیجای خود شد .\n",
            "و چه جالب است که بسیاری از آرمان ها و عقائد و افکار حزبشان قرابت خاصی با حزب توده و سازمان مجاهدین دارد ، دقیقا همچین تشکیلاتی را با همان اهداف در تاریخ کشور خودمان داشته ایم و شک ندارم که در هر انقلابی در دنیا همچین تشکیلاتی با همان رویکردها وجود داشته است و خواهد داشت چون سناریو نویس قهاری پشت این جریان ها وجود دارد و او کسی نیست جز ابلیس ، که تمام تلاش خود را میکند تا انسان را از انسانیتش دور کند به هر نحوی که شده ،\n",
            "سیاست با وجود کثیف بودنش از خود گذشتگی می خواد ،فرمان قتل از طرف یک سیاست مدار شاید جلوی یک قتل عام رو بگیره ، ولی ما فقط اون قتل رو می بینیم ...به نظر من سیاست ابزار ،مهم هدف که اگه درست باشه اون ابزار هم موجه جلوه می کنه و البته بالعکس ...\n",
            "سیاست با وجود کثیف بودنش از خود گذشتگی می خواد ،فرمان قتل از طرف یک سیاست مدار شاید جلوی یک قتل عام رو بگیره ، ولی ما فقط اون قتل رو می بینیم ...به نظر من سیاست ابزار ،مهم هدف که اگه درست باشه اون ابزار هم موجه جلوه می کنه و البته بالعکس ...\n",
            "20 به کتاب ،20 به نویسنده و 20 هم به طرح روی جلد ،جلال هم که جای خود داره ،مخلص کلام شیر مادرت حلالت با کتابی ک نوشتی\n",
            "20 به کتاب ،20 به نویسنده و 20 هم به طرح روی جلد ،جلال هم که جای خود داره ،مخلص کلام شیر مادرت حلالت با کتابی ک نوشتی\n",
            "از این کتابهاست که نمیشه زمینش گذاشت. جالب بود.\n",
            "از این کتابهاست که نمیشه زمینش گذاشت. جالب بود.\n",
            "شاهکار.مرسی آقای ساتر\n",
            "شاهکار.مرسی آقای ساتر\n",
            "همه دعواها الکی است و به خاطر قدرت است و هر وقت برای رسیدن به قدرت نیاز به مصالحه باشد همه تفکرات سیاسی با هم قهوه می خورند و به راحتی حرف می زنند .ژان پل سارتر\n",
            "همه دعواها الکی است و به خاطر قدرت است و هر وقت برای رسیدن به قدرت نیاز به مصالحه باشد همه تفکرات سیاسی با هم قهوه می خورند و به راحتی حرف می زنند .ژان پل سارتر\n",
            "سلام من میخام کتاب به صورت چاپی بخرم باید چکار کنم؟\n",
            "سلام من میخام کتاب به صورت چاپی بخرم باید چکار کنم؟\n",
            "khob bvdsh\n",
            "khob bvdsh\n",
            "بسیار زیبا بود\n",
            "بسیار زیبا بود\n",
            "چرا نظرات کتاب به خاطر لی لا باز نمیشه مال همه اینجوره یا فقط مال من باز نمیشه\n",
            "چرا نظرات کتاب به خاطر لی لا باز نمیشه مال همه اینجوره یا فقط مال من باز نمیشه\n",
            "متن و مفهوم عالیه. ترجمه میتونست روان تر باشه. در کل خیلی خوبه\n",
            "متن و مفهوم عالیه. ترجمه میتونست روان تر باشه. در کل خیلی خوبه\n",
            "عالی بود ، ترجمه ش هم خیلی خوب و بدون مشکل . پیشنهاد میدم بخونید.\n",
            "عالی بود ، ترجمه ش هم خیلی خوب و بدون مشکل . پیشنهاد میدم بخونید.\n",
            "خیلی چهره مهمی از سیاست رو به تصویر کشیده. بنظرم بزرگترین نقطه مشترک همه ی سیاست هارو به عالی ترین شکل ممکن بیان کرده. لذت بردم.\n",
            "خیلی چهره مهمی از سیاست رو به تصویر کشیده. بنظرم بزرگترین نقطه مشترک همه ی سیاست هارو به عالی ترین شکل ممکن بیان کرده. لذت بردم.\n",
            "عالی، سیاسی و فلسفی و دراماتیک\n",
            "عالی، سیاسی و فلسفی و دراماتیک\n",
            "داستان جالبیه. خوشم اومد. شروعش خوبه. آدمو کنجکاو به ادامه داستان میکنه. به خاطر برگشت به عقبش.\n",
            "گاهی نا اینطوری رفتار می‌کنیم. بعد از زمانی، آرمان‌های ما تغییر می‌کنند.\n",
            "زمان همه چیز را تغییر می‌دهد.\n",
            "داستان جالبیه. خوشم اومد. شروعش خوبه. آدمو کنجکاو به ادامه داستان میکنه. به خاطر برگشت به عقبش.\n",
            "گاهی نا اینطوری رفتار می‌کنیم. بعد از زمانی، آرمان‌های ما تغییر می‌کنند.\n",
            "زمان همه چیز را تغییر می‌دهد.\n",
            "واقعا رمان زیبایی هست.به همه دوستان توصیه میکنم بخونن\n",
            "واقعا رمان زیبایی هست.به همه دوستان توصیه میکنم بخونن\n",
            "یه تئاتر که از این داستان اقتباس شده بود دیده بودم قبلا، داستان به مراتب گیراتر بود غیر از پایان گنگش\n",
            "یه تئاتر که از این داستان اقتباس شده بود دیده بودم قبلا، داستان به مراتب گیراتر بود غیر از پایان گنگش\n",
            "خیلب خوب بود مخصوصا اگه فیلمشو بسازن البته که خیلی سانسور خواهد داشت😂ولی داستانش جالب بود بخونید دوستان\n",
            "خیلب خوب بود مخصوصا اگه فیلمشو بسازن البته که خیلی سانسور خواهد داشتولی داستانش جالب بود بخونید دوستان\n",
            "⭐🌟⭐🌟⭐\n",
            "\n",
            "عاااالی بود .\n",
            "فوق العاده تلخی عمیقی داشت. هوگو تنهایی عمیقی را تجربه کرد\n",
            "عاااالی بود .\n",
            "فوق العاده تلخی عمیقی داشت. هوگو تنهایی عمیقی را تجربه کرد\n",
            "کتاب بسیار خوبی است . و فکر می کنم که از چند نظر حائز اهمیت است ‌. اول از نظر ادبی و بخصوص ادبیات نمایشی اثر مهمی است که در بسیاری از کشور ها این اثر به روی صحنه رفته . و از نظر ایدئولوژی و فلسفه اگزیستانسیالیتی که اصول مهم بیان شده در این فلسفه در این کتاب به دفعات ذکر شده از قبیل : وضعیت اولیه ( تولد - خانواده ) ، آزادی، انتخاب ، مسئولیت انسان ، دلهره ناشی از آزادی . همچنین این اثر از جنایت و مکافات داستایوفسکی و شخصیت اول آن هم بسیار بهره برده . و این در حالی است که داستایوفسکی رو هم از اولین اگزیستانسیالیتی ها می دونند.\n",
            "و دیگر از نظر تاریخی و بیان پیچیدگی جامعه سیاسی آن زمان فرانسه ، اتحاد حزب کمونیست فرانسه با احزاب لیبرال و سلطنت طلب و غیره . سارتر در این کتاب سیاست های محافظه کارانه حزب کمونیست فرانسه را نقد می کند و کمونیست ایده الش را در شخصیت هوگو معرفی می کند.\n",
            "کتاب بسیار خوبی است . و فکر می کنم که از چند نظر حائز اهمیت است ‌. اول از نظر ادبی و بخصوص ادبیات نمایشی اثر مهمی است که در بسیاری از کشور ها این اثر به روی صحنه رفته . و از نظر ایدئولوژی و فلسفه اگزیستانسیالیتی که اصول مهم بیان شده در این فلسفه در این کتاب به دفعات ذکر شده از قبیل : وضعیت اولیه ( تولد - خانواده ) ، آزادی، انتخاب ، مسئولیت انسان ، دلهره ناشی از آزادی . همچنین این اثر از جنایت و مکافات داستایوفسکی و شخصیت اول آن هم بسیار بهره برده . و این در حالی است که داستایوفسکی رو هم از اولین اگزیستانسیالیتی ها می دونند.\n",
            "و دیگر از نظر تاریخی و بیان پیچیدگی جامعه سیاسی آن زمان فرانسه ، اتحاد حزب کمونیست فرانسه با احزاب لیبرال و سلطنت طلب و غیره . سارتر در این کتاب سیاست های محافظه کارانه حزب کمونیست فرانسه را نقد می کند و کمونیست ایده الش را در شخصیت هوگو معرفی می کند.\n",
            "واقعا عالییی بود از بهترین هایی که خونده بودم👌👌👌👌\n",
            "واقعا عالییی بود از بهترین هایی که خونده بودم\n",
            "عالی........فقط لطفا کسانی بخونن که به پختگی لازم رسیدن👍👍🌹\n",
            "عالی........فقط لطفا کسانی بخونن که به پختگی لازم رسیدن\n",
            "من این کتاب و نخونده از لیست کتابام پاک میکنم.با وجود همچین کامنت هایی ازالان میتونم بفهمم که دراخر این کتاب باعث درگیری ذهنی درونم میشه پس نمیخونمش.من میخوام یه کتابی بخونم که بهم ارامش بده ولی به نظر میاد این کتاب ازاون کتابا نیست.من از سیاست متنفرم\n",
            "من این کتاب و نخونده از لیست کتابام پاک میکنم.با وجود همچین کامنت هایی ازالان میتونم بفهمم که دراخر این کتاب باعث درگیری ذهنی درونم میشه پس نمیخونمش.من میخوام یه کتابی بخونم که بهم ارامش بده ولی به نظر میاد این کتاب ازاون کتابا نیست.من از سیاست متنفرم\n",
            "خوب بود ولی صفحه ١٣ سفید بود!\n",
            "خوب بود ولی صفحه ١٣ سفید بود!\n",
            "خواهشا همه چیزو به دین وصل نکنین / نظرات هر کتابی رو نگاه میکتم باید واژه دین رو ببینم حتما ؟!\n",
            "خواهشا همه چیزو به دین وصل نکنین / نظرات هر کتابی رو نگاه میکتم باید واژه دین رو ببینم حتما ؟!\n",
            "ایشون یک بی دین بودن ؟؟؟\n",
            "ایشون یک بی دین بودن ؟؟؟\n",
            "خوب بود دوست داشتم.\n",
            "خوب بود دوست داشتم.\n",
            "چی بگم والا\n",
            "چی بگم والا\n",
            "به درک عمیقی از سیاست رسیده بوده\n",
            "به درک عمیقی از سیاست رسیده بوده\n",
            "مث واقعیت بود سیاست کثیف وخائنه.هرکی واردش شد دستاش الوده میشه\n",
            "مث واقعیت بود سیاست کثیف وخائنه.هرکی واردش شد دستاش الوده میشه\n",
            "فوق العاده بود و واقعا ازش لذت بردم، ترجمه هم روان و عالی\n",
            "سپاسگزارم طاقچه\n",
            "فوق العاده بود و واقعا ازش لذت بردم، ترجمه هم روان و عالی\n",
            "سپاسگزارم طاقچه\n",
            "فوق العاده بود، داستان کشش بسیار بالایی داشت. شدیدا پیشنهاد میشه. امیدوارم یک روز بتونم تئاتر این نمایشنامه رو ببینم\n",
            "فوق العاده بود، داستان کشش بسیار بالایی داشت. شدیدا پیشنهاد میشه. امیدوارم یک روز بتونم تئاتر این نمایشنامه رو ببینم\n",
            "تا اینجایی که میخونم جالب و جذاب بود برام(بیشتر از نصفشو خوندم)\n",
            "تا اینجایی که میخونم جالب و جذاب بود برام(بیشتر از نصفشو خوندم)\n",
            "نمیگم فوق العاده بود اما ارزش خوندن رو داشت.. هیجان انگیز و تا حدودی غیرقابل پیش بینی بود و داستان کاملا متفاوت روایت شده بود\n",
            "نمیگم فوق العاده بود اما ارزش خوندن رو داشت.. هیجان انگیز و تا حدودی غیرقابل پیش بینی بود و داستان کاملا متفاوت روایت شده بود\n",
            "هر چی از داستان میگذره زیباتر میشه. عالی بود\n",
            "هر چی از داستان میگذره زیباتر میشه. عالی بود\n",
            "یه رمان فوق العاده مربوط به حوادث داخلی حزب چپ در زمان جنگ جهانی دوم.\n",
            "ترجمه جلال هم لذت بخشه.\n",
            "پیشنهاد میکنم حتما بخونید. مخصوصا این که ژان پل سارتر فیلسوف بزرگ اگزیستانسیالیست فرانسوی اینو نوشته که در کودکی جنگ جهانی اول رو دیده و در بزرگسالی جنگ دوم رو!\n",
            "یه رمان فوق العاده مربوط به حوادث داخلی حزب چپ در زمان جنگ جهانی دوم.\n",
            "ترجمه جلال هم لذت بخشه.\n",
            "پیشنهاد میکنم حتما بخونید. مخصوصا این که ژان پل سارتر فیلسوف بزرگ اگزیستانسیالیست فرانسوی اینو نوشته که در کودکی جنگ جهانی اول رو دیده و در بزرگسالی جنگ دوم رو!\n",
            "بسیار جالب و تامل برانگیز\n",
            "بسیار جالب و تامل برانگیز\n",
            "من خوشم نیومد از این کتاب\n",
            "من خوشم نیومد از این کتاب\n",
            "از خوندنش خیلی لذت بردم. عمیق، و در عین حال جذاب و پرکشش بود.\n",
            "از خوندنش خیلی لذت بردم. عمیق، و در عین حال جذاب و پرکشش بود.\n",
            "خشبختی چیست؟ جانانه زیستن با تمام بدبختی ها.بنظرم چارلی چاپلین\n",
            "خشبختی چیست؟ جانانه زیستن با تمام بدبختی ها.بنظرم چارلی چاپلین\n",
            "مفید بود\n",
            "مفید بود\n",
            "«اگه فلج مادرزادبه دنیا بیای وقهرمان دوی المپیک نشی صددرصد خودت مقصری»\n",
            "ژان پل سارتر\n",
            "«اگه فلج مادرزادبه دنیا بیای وقهرمان دوی المپیک نشی صددرصد خودت مقصری»\n",
            "ژان پل سارتر\n",
            "به غیر از قسمت هایی که کلمه های  قلمبه سلمبه سیاسی داشت بقیش خوب بود، من فک کردم ژسیکا و هوگو با هم تصمیم گرفتن و نقشه کشیدن که این جوری هوده رر رو بکشن،  بعد دیدم اشتباه کردم\n",
            "به غیر از قسمت هایی که کلمه های  قلمبه سلمبه سیاسی داشت بقیش خوب بود، من فک کردم ژسیکا و هوگو با هم تصمیم گرفتن و نقشه کشیدن که این جوری هوده رر رو بکشن،  بعد دیدم اشتباه کردم\n",
            "خیلی باحالین! هر کس قسمت جزییات را راجع به کتاب نوشته،باید بهش جایزه خنگ ترین خواننده تعلق بگیره.اخه لامصب کجا ژسیکا زن رهبر حزب بود که بعد هوگو عاشقش شده باشه!!! باهوش،نابغه، دانشمند ،استاد،فرزانه،سرمایه علمی و دانشگاهی ، ژسیکا همسر خود هوگو بود از همون اول نمایشنامه!!!!!!!!!!\n",
            "خیلی باحالین! هر کس قسمت جزییات را راجع به کتاب نوشته،باید بهش جایزه خنگ ترین خواننده تعلق بگیره.اخه لامصب کجا ژسیکا زن رهبر حزب بود که بعد هوگو عاشقش شده باشه!!! باهوش،نابغه، دانشمند ،استاد،فرزانه،سرمایه علمی و دانشگاهی ، ژسیکا همسر خود هوگو بود از همون اول نمایشنامه!!!!!!!!!!\n",
            "بهتر از عالی بود :)\n",
            "بهتر از عالی بود :)\n",
            "لطفآ نمیاشنامه ی روسپی بزرگوار اثر ژان پل سارتر رو هم در بخش رایگان بذارید.خیلی کوتاه و کمیاب و قشنگه\n",
            "لطفآ نمیاشنامه ی روسپی بزرگوار اثر ژان پل سارتر رو هم در بخش رایگان بذارید.خیلی کوتاه و کمیاب و قشنگه\n",
            "عالی بود لذت بردم\n",
            "عالی بود لذت بردم\n",
            "نمایش نامه ی عالی بود خیلی خوب مفهوم قدرت در سیاست ، خیانت ،صداقت و اعتماد رو میرسونه \n",
            "نمایش نامه ی عالی بود خیلی خوب مفهوم قدرت در سیاست ، خیانت ،صداقت و اعتماد رو میرسونه \n",
            "قشنگ بود خیلی دوست داشتنی بود\n",
            "قشنگ بود خیلی دوست داشتنی بود\n",
            "خیلی خوب بود نمایش نامه فوق العاده ایه ،\n",
            "سیاسی بودنش تو سن کم ازدواج کردن حس دوس نداشتن خیانت بهش  و در اخر قتل داستان غم انگیزه ای هست.\n",
            "ولی در کل باید دختره هم میکشت بهتر بود بنظرم هه\n",
            "خیلی خوب بود نمایش نامه فوق العاده ایه ،\n",
            "سیاسی بودنش تو سن کم ازدواج کردن حس دوس نداشتن خیانت بهش  و در اخر قتل داستان غم انگیزه ای هست.\n",
            "ولی در کل باید دختره هم میکشت بهتر بود بنظرم هه\n",
            "خوب بود . رنج و درد و فریب و مکر رو در جامعه  رو نشان میدهد . اکثرا وقتی به قدرت که می رسند فراموش می کنند هدف های پاک رو . و جامعه رو به تخدیر می کشانند.\n",
            "خوب بود . رنج و درد و فریب و مکر رو در جامعه  رو نشان میدهد . اکثرا وقتی به قدرت که می رسند فراموش می کنند هدف های پاک رو . و جامعه رو به تخدیر می کشانند.\n",
            "شما خیلی خوبید ممنون حرف ندارین😁\n",
            "شما خیلی خوبید ممنون حرف ندارین\n",
            "بی نظیر بود.تا دیر وقت بیدار موندم و تمومش کردم.\n",
            "بی نظیر بود.تا دیر وقت بیدار موندم و تمومش کردم.\n",
            "خوب....\n",
            "خوب....\n",
            "ﺗﺎ ﻭﻗﺘﻲ ﺑﻪ ﮔﺬﺷﺘﻪ ﺭﺟﻮﻉ ﻧﻤﻴﻜﻨﻪ ﺧﻴﻠﻲ ﻛﺴﻞ ﻛﻨﻨﺪﺳﺖ ( اﻟﺒﺘﻪ ﺷﺎﻳﺪ ﻓﻘﻄ ﺑﺮا ﻣﻦ ﻛﻪ اﺯ ﻛﻠﻤﺎﺕ ﻗﻠﻤﺒﻪ ﺳﻴﺎﺳﻲ ﭼﻴﺰﻱ ﻧﻤﻴﺪﻭﻧﻢ)  ﻭﻟﻲ ﺑﻌﺪﺵ ﺧﻴﻠﻲ ﺧﻮﺏ ﻣﻴﺸﻪ.  ﺩﻭﺳﺖ ﺩاﺷﺘﻢ.\n",
            "ﻃﺎﻗﭽﻪ اﺯﺕ ﻣﻤﻨﻮﻧﻢ ﺧﻴﻠﻲ ﻭﻗت  ﺑﻮﺩ ﻛﺘﺎﺏ ﻧﺨﻮﻧﺪﻩ ﺑﻮﺩﻡ !\n",
            "         ( ا   ا   ا     )      .   ا.\n",
            " ا   ت      !\n",
            "کتاب فوووق العاده!  طرز فکرش کاملا ذهن رو درگیر میکنه و آدم رو دنبال خودش میکشونه. ولی کاش تو خلاصه کتاب داستان رو لو ندید! خوشبختانه من خودم خلاصه رو بعد خوندن کتاب دیدم.\n",
            "کتاب فوووق العاده!  طرز فکرش کاملا ذهن رو درگیر میکنه و آدم رو دنبال خودش میکشونه. ولی کاش تو خلاصه کتاب داستان رو لو ندید! خوشبختانه من خودم خلاصه رو بعد خوندن کتاب دیدم.\n",
            "عااالی.مرسی.\n",
            "عااالی.مرسی.\n",
            "واقعا قشنگ بود .مرسی طاقچه\n",
            "واقعا قشنگ بود .مرسی طاقچه\n",
            "چرا  تو توضیحات میگه که \" هوگو دلبسته همسر هودرر میشود\" ؟؟؟؟!!! 😕\n",
            "چرا  تو توضیحات میگه که \" هوگو دلبسته همسر هودرر میشود\" ؟؟؟؟!!! \n",
            "ممنون که رایگان کردید\n",
            "\n",
            "ممنون که رایگان کردید\n",
            "\n",
            "پنج ستاره اول برای کتاب\n",
            "پنج ستاره دوم واسه انتشارات جامی که کتاب رو رایگان قرار داده\n",
            "پنج ستاره اول برای کتاب\n",
            "پنج ستاره دوم واسه انتشارات جامی که کتاب رو رایگان قرار داده\n",
            "ممنون که رایگان بود  و تا صبح بیدار موندم برای خوندنش و لذت بردم\n",
            "ممنون که رایگان بود  و تا صبح بیدار موندم برای خوندنش و لذت بردم\n",
            "خیلی کوتاه بود\n",
            "سیاسی و روحیه جنگجویی \n",
            "درکل من خوشم نیومد\n",
            "خیلی کوتاه بود\n",
            "سیاسی و روحیه جنگجویی \n",
            "درکل من خوشم نیومد\n",
            "خواندن ش بسیار برایم لذت بخش بود!\n",
            "خواندن ش بسیار برایم لذت بخش بود!\n",
            "خیلی زیبا بود\n",
            "خیلی زیبا بود\n",
            "بسیار بسیار عالی بود ، ممنون\n",
            "بسیار بسیار عالی بود ، ممنون\n",
            "ارزش خوندنو داشت تا الان ک پنج صبحه یه سره خوندمش نتونستم ولش کنم ممنونم ازتون \n",
            "ارزش خوندنو داشت تا الان ک پنج صبحه یه سره خوندمش نتونستم ولش کنم ممنونم ازتون \n",
            "با سلام، ممنونم از نوع ویرایش و ایجاد سهولت در خواندن\n",
            "با سلام، ممنونم از نوع ویرایش و ایجاد سهولت در خواندن\n",
            "jaleb va gooyaye jameaye emroozi\n",
            "jaleb va gooyaye jameaye emroozi\n",
            "بسیار لذت بردم از خواندن کتاب \n",
            "ممنون از زحماتتون\n",
            "بسیار لذت بردم از خواندن کتاب \n",
            "ممنون از زحماتتون\n",
            "خواندیم و لذت بردیم..عالی بود. \n",
            "خواندیم و لذت بردیم..عالی بود. \n",
            "نشریه بسیار وزین و دوست داشتنی‌ایه.\n",
            "نشریه بسیار وزین و دوست داشتنی‌ایه.\n",
            "دو گروه عمده در برخورد با ی همچین نظریه ها و کتابایی هست.\n",
            "اولی روشنفکر نماها که همه زورشونو میزنن به چیزایی ایمان بیارن که توش خبری از دین و این حرفا و اسلام نباشه، ولی به هر حال ی روش معنوی برای زندگی به دست بده. برای همین کلا تاییدش میکنن\n",
            "دومی مومنا و دین دارا که چون هیچ کجای این کتابا اسم خدا نیست استنباط میکنن، کتاب داره میگه کارایی که خدا میکنه، مثلا حاجت میده، تحت تسلط کامل خوده انسانه که یعنی خداییم وجود نداره. برا همین کلا ردش میکنن.\n",
            "حالا بیاید بشینیم یکم نگا کنیم، اولا اگه به خدای به اون بزرگیت ایمان داری و فک میکنی سازو کار جهان اونقدر سادست که تو درکش کنی و چیزیو رد یا اثبات کنی، ول معطلی، هیچیم از اون اعتقاداتت نفهمیدی.\n",
            "اگه هم جزو دسته اولی که، برا من بگو دقیقا توجه و تمرکز کزدن روی ی چیزی، و هی فکرشو کردن، با دعا کردن و خواستنش چه فرقی داره؟ \n",
            "از لحاظ عرفانی جفتتون دارید ی چیزو میگید، :)))) جفتتونم باهم دعواتونه\n",
            "دو گروه عمده در برخورد با ی همچین نظریه ها و کتابایی هست.\n",
            "اولی روشنفکر نماها که همه زورشونو میزنن به چیزایی ایمان بیارن که توش خبری از دین و این حرفا و اسلام نباشه، ولی به هر حال ی روش معنوی برای زندگی به دست بده. برای همین کلا تاییدش میکنن\n",
            "دومی مومنا و دین دارا که چون هیچ کجای این کتابا اسم خدا نیست استنباط میکنن، کتاب داره میگه کارایی که خدا میکنه، مثلا حاجت میده، تحت تسلط کامل خوده انسانه که یعنی خداییم وجود نداره. برا همین کلا ردش میکنن.\n",
            "حالا بیاید بشینیم یکم نگا کنیم، اولا اگه به خدای به اون بزرگیت ایمان داری و فک میکنی سازو کار جهان اونقدر سادست که تو درکش کنی و چیزیو رد یا اثبات کنی، ول معطلی، هیچیم از اون اعتقاداتت نفهمیدی.\n",
            "اگه هم جزو دسته اولی که، برا من بگو دقیقا توجه و تمرکز کزدن روی ی چیزی، و هی فکرشو کردن، با دعا کردن و خواستنش چه فرقی داره؟ \n",
            "از لحاظ عرفانی جفتتون دارید ی چیزو میگید، :)))) جفتتونم باهم دعواتونه\n",
            "نویسندش مایکل جکسونه😨😨😨😨😨😨😨\n",
            "نویسندش مایکل جکسونه\n",
            "قانون جذب دروغه محضه....\n",
            "قانون جذب دروغه محضه....\n",
            "سلام، ممنون از ارایه کتابهای مفیدتون، این کتاب فوق العاده بود و خیلی از نکات ریز رو در مورد قانون جذب که در کتابهای دیگه اشاره نشده، بیان میکنه\n",
            "سلام، ممنون از ارایه کتابهای مفیدتون، این کتاب فوق العاده بود و خیلی از نکات ریز رو در مورد قانون جذب که در کتابهای دیگه اشاره نشده، بیان میکنه\n",
            "مطالب مفیدی داشت ممنون\n",
            "مطالب مفیدی داشت ممنون\n",
            "اولین کتابی بود که از \"مارتین سلیگمن\" مطالعه کردم.\n",
            "جناب سلیگمن اولین کسی است که به طور رسمی از\" روانشناسی مثبت\" می گوید و شاخه ی جدیدی به عنوان \"روانشناسی مثبت \" را به علم روانشناسی اضافه کرده است.\n",
            "مطالب کتاب کاربردی است.\n",
            "چند تست تشخیص افسردگی و روشهای مقابله با افسردگی را مطرح کرده است که به نظرم کارگشا بود.\n",
            "در کنار تمام اینها نباید از ترجمه غافل شد، ترجمه ی خوبی داشت.\n",
            "جدای از مطالب کتاب برای درمان افسردگی،نباید از رژیم غذایی مناسب و دمنوشهای موثر برای ایجاد آرامش و شادی و نشاط غفلت کرد.\n",
            "اولین کتابی بود که از \"مارتین سلیگمن\" مطالعه کردم.\n",
            "جناب سلیگمن اولین کسی است که به طور رسمی از\" روانشناسی مثبت\" می گوید و شاخه ی جدیدی به عنوان \"روانشناسی مثبت \" را به علم روانشناسی اضافه کرده است.\n",
            "مطالب کتاب کاربردی است.\n",
            "چند تست تشخیص افسردگی و روشهای مقابله با افسردگی را مطرح کرده است که به نظرم کارگشا بود.\n",
            "در کنار تمام اینها نباید از ترجمه غافل شد، ترجمه ی خوبی داشت.\n",
            "جدای از مطالب کتاب برای درمان افسردگی،نباید از رژیم غذایی مناسب و دمنوشهای موثر برای ایجاد آرامش و شادی و نشاط غفلت کرد.\n",
            "سلام\n",
            "قیمت کتاب را ٣٠٠٠ تومان زده است ولی وقتی میخواهید کتاب را بخرید قیمت ١٢۵٠٠ را نشان میدهد!\n",
            "سلام\n",
            "قیمت کتاب را ٣٠٠٠ تومان زده است ولی وقتی میخواهید کتاب را بخرید قیمت ١٢۵٠٠ را نشان میدهد!\n",
            "برای من خیلی کاربردی بود شاید چون در شرایطی خوندم که بهش نیاز داشتم . مثال های زیاد کتاب باعث میشه اصل حرف کتاب برای آدم جا بیفته و من از بعد خوندن این کتاب واقعا تونستم به خیلی از بدبینی هام غلبه کنم و کمتر به باورهای اشتباهم اجازه ی عرض اندام بدم☺ گویا کتاب خلاصه شده ست ولی به نظرم بازم خیلی تکرار داره پیشنهاد میکنم حین مطالعه نکته برداری کنید\n",
            "برای من خیلی کاربردی بود شاید چون در شرایطی خوندم که بهش نیاز داشتم . مثال های زیاد کتاب باعث میشه اصل حرف کتاب برای آدم جا بیفته و من از بعد خوندن این کتاب واقعا تونستم به خیلی از بدبینی هام غلبه کنم و کمتر به باورهای اشتباهم اجازه ی عرض اندام بدم گویا کتاب خلاصه شده ست ولی به نظرم بازم خیلی تکرار داره پیشنهاد میکنم حین مطالعه نکته برداری کنید\n",
            "متاسفانه حتی نمیشه گفت این کتاب ترجمه بدی داره. چرا که به هیچ عنوان به متن نسخه اصلی وفا دار نبوده و بیشتر شبیه به نت برداری و جزوه نویسی از کتاب اصلی ست. به راحتی میشه نسخه انگلیسی سمپل کتاب رو از گوگل playbook بگیرید - که مجانی هم هست - و مقایسه کنید. من فصل اول این کتاب رو خوندم و گذاشتم زمین و نظری در مورد بقیه فصل‌ها ندارم.\n",
            "متاسفانه حتی نمیشه گفت این کتاب ترجمه بدی داره. چرا که به هیچ عنوان به متن نسخه اصلی وفا دار نبوده و بیشتر شبیه به نت برداری و جزوه نویسی از کتاب اصلی ست. به راحتی میشه نسخه انگلیسی سمپل کتاب رو از گوگل playbook بگیرید - که مجانی هم هست - و مقایسه کنید. من فصل اول این کتاب رو خوندم و گذاشتم زمین و نظری در مورد بقیه فصل‌ها ندارم.\n",
            "کتاب روان نبود ولی در عین حال نکات جالبی هم درونش بود تا صفحه صد\n",
            "از صفحه صد به بعد امیدوار کننده و راه حل برای مبارزه با خودتون میده که عالیه\n",
            "👏👌✌️\n",
            "کتاب روان نبود ولی در عین حال نکات جالبی هم درونش بود تا صفحه صد\n",
            "از صفحه صد به بعد امیدوار کننده و راه حل برای مبارزه با خودتون میده که عالیه\n",
            "\n",
            "در مجموع کتابی کاربردی با راهکارهای عملیه. اما هم خلاصه شده و هم اشکالات نگارشی و حتی املایی داره.\n",
            "در مجموع کتابی کاربردی با راهکارهای عملیه. اما هم خلاصه شده و هم اشکالات نگارشی و حتی املایی داره.\n",
            "کتاب خوبی بود مخصوصا بخش سوم که راهکارهای عملی ارائه داده بود. چون خلاصه است مطالب کمی گنگ هستن و خوب برای خواننده جا نمیفته\n",
            "راهکارها نیاز به تمرین داره تا تبدیل به عادت بشن\n",
            "کتاب خوبی بود مخصوصا بخش سوم که راهکارهای عملی ارائه داده بود. چون خلاصه است مطالب کمی گنگ هستن و خوب برای خواننده جا نمیفته\n",
            "راهکارها نیاز به تمرین داره تا تبدیل به عادت بشن\n",
            "چرا کتاب شادمانی درونی از این نویسنده رو نمیزارید ؟\n",
            "چرا کتاب شادمانی درونی از این نویسنده رو نمیزارید ؟\n",
            "برا زندگیم خوندم فقط!\n",
            "کاش ۵ ، ۶ سال زودتر خونده بودم\n",
            "ای کاش کتابهای دیگش رو هم بزارن\n",
            "برا زندگیم خوندم فقط!\n",
            "کاش ۵ ، ۶ سال زودتر خونده بودم\n",
            "ای کاش کتابهای دیگش رو هم بزارن\n",
            "نسخه چاپی شو دارم، عالیه\n",
            "نسخه چاپی شو دارم، عالیه\n",
            "فکر میکنم کتابی با فضای جدید و حرفهای جدید به خوانندگان .تقدیم کردم؛ و خواندن آن خالی از لطف نیست\n",
            "فکر میکنم کتابی با فضای جدید و حرفهای جدید به خوانندگان .تقدیم کردم؛ و خواندن آن خالی از لطف نیست\n",
            "خیلی خوشم نیومد، ب نظرم بیشتر ب درد کسایی میخوره ک بخوان ی مروری بر تاریخ ادبیات معاصر داشته باشند.\n",
            "خیلی خوشم نیومد، ب نظرم بیشتر ب درد کسایی میخوره ک بخوان ی مروری بر تاریخ ادبیات معاصر داشته باشند.\n",
            "کاش کتابارو فروشی هم داشتین\n",
            "کاش کتابارو فروشی هم داشتین\n",
            "برخلاف عنوان به شدت مجذوب کننده این کتاب از نظر من چیز زیادی برای گفتن ندارد\n",
            "برخلاف عنوان به شدت مجذوب کننده این کتاب از نظر من چیز زیادی برای گفتن ندارد\n",
            "ترجمه روون نبود..من نسخه چاپی همین ترجمه و انتشارات رو خوندم..نوشته های پائولو مطمئنا زیباست ولی کاش هر مترجمی هم نخواد هر قلمی رو ترجمه کنه.\n",
            "ترجمه روون نبود..من نسخه چاپی همین ترجمه و انتشارات رو خوندم..نوشته های پائولو مطمئنا زیباست ولی کاش هر مترجمی هم نخواد هر قلمی رو ترجمه کنه.\n",
            "همیشه سعی میکنم از خوندن کتابای تربیتی با نویسنده فارسی دوری کنم.و حیف که اینبار وفادار نبودم و حدود دوساعت از وقتمو هدر دادم.\n",
            "به امیدی که مطلب بدرد بخوری که تو کتابای اونور ندیده باشم ،ببینم.\n",
            "هیچی.\n",
            "به نویسنده ها تویه میکنم اینقدر به دنبال تعاریف کلمه ها و توصیفات اضافی نرن.و راهکار بدن.\n",
            "افتضاح\n",
            "همیشه سعی میکنم از خوندن کتابای تربیتی با نویسنده فارسی دوری کنم.و حیف که اینبار وفادار نبودم و حدود دوساعت از وقتمو هدر دادم.\n",
            "به امیدی که مطلب بدرد بخوری که تو کتابای اونور ندیده باشم ،ببینم.\n",
            "هیچی.\n",
            "به نویسنده ها تویه میکنم اینقدر به دنبال تعاریف کلمه ها و توصیفات اضافی نرن.و راهکار بدن.\n",
            "افتضاح\n",
            "خیلی خوبهههه\n",
            "خیلی خوبهههه\n",
            "نوشته‌هایِ گیرایِ این شماره :\n",
            "۱.لشکرکشی ایران برای رهایی یمن (تاریخچه حضور نظامی ایران در یمن)\n",
            "۲.به خاطر داریم و حق می‌طلبیم ( صدسالگی نسل‌کشی ارمنی‌ها توسط عثمانی )\n",
            "نوشته‌هایِ گیرایِ این شماره :\n",
            "۱.لشکرکشی ایران برای رهایی یمن (تاریخچه حضور نظامی ایران در یمن)\n",
            "۲.به خاطر داریم و حق می‌طلبیم ( صدسالگی نسل‌کشی ارمنی‌ها توسط عثمانی )\n",
            "کتابی کم حجم اما ارزشمند که برای شروع فرآیند خودیاری به تمام سنین توصیه میشه\n",
            "کتابی کم حجم اما ارزشمند که برای شروع فرآیند خودیاری به تمام سنین توصیه میشه\n",
            "واسه من فقط ۲۱ صفحه اش اومده یعنی سه فصلش چرا ایا همین مقدار هست یا اگر نیست چیکار کنم؟\n",
            "واسه من فقط ۲۱ صفحه اش اومده یعنی سه فصلش چرا ایا همین مقدار هست یا اگر نیست چیکار کنم؟\n",
            "این که ۴۸ صفحه س! \n",
            "پس بقیه ش  چی میشه؟\n",
            "این که ۴۸ صفحه س! \n",
            "پس بقیه ش  چی میشه؟\n",
            "مختصر و مفید \n",
            "عالی👌\n",
            "مختصر و مفید \n",
            "عالی\n",
            "واقعا برای نوجوانان کتاب خوبیه،\n",
            "نگاه من رو به خانوادم و زندگیم عوض کرد..\n",
            "الان واقعا شادم و از زندگی راضی\n",
            "واقعا برای نوجوانان کتاب خوبیه،\n",
            "نگاه من رو به خانوادم و زندگیم عوض کرد..\n",
            "الان واقعا شادم و از زندگی راضی\n",
            "بسیار بسیار زیبا و دلنشین است .نادین گوردیمر عالی است.اوواقعا توانست احساس مرا نسبت به این کتاب بیرون بکشد وباعث شود تا کتاب را بیش از دوبار بخوانم.وبرخی از قسمت هایش ملکه ی ذهنم شود💞مرحبا\n",
            "بسیار بسیار زیبا و دلنشین است .نادین گوردیمر عالی است.اوواقعا توانست احساس مرا نسبت به این کتاب بیرون بکشد وباعث شود تا کتاب را بیش از دوبار بخوانم.وبرخی از قسمت هایش ملکه ی ذهنم شودمرحبا\n",
            "ﻣﻤﻨﻮﻥ ﻛﺘﺎﺏ ﺧﻮﺑﻴﻪ ﺑﺎ ﻗﻴﻤﺖ ﻣﻨﺎﺳﺐ.ﻫﻨﻮﺯ ﻛﻞ ﻛﺘﺎﺏ ﺭﻭ ﻧﺨﻮﻧﺪﻡ ﻭﻟﻲ ﺑﺎ ﻧﻴﻢ ﻧﮕﺎﻫﻲ ﺑﻪ ﻣﻘﺪﻣﺎﺕ ﻣﺘﻮﺟﻪ ﺷﺪﻡ ﺩﻗﻴﻘﺎ ﺑﻪ ﻣﺴﺎﻟﻪ ی ﭘﻴﺸﺮﻓﺖ ﺗﺤﺼﻴﻠﻲ ﻧﮕﺎﻩ ﻋﻠﻤﻲ و ﻋﻤﻠﻲ ﺷﺪﻩ.ﺑﺎ ﺗﺸﻜﺮ.(ﺭاﺩ)\n",
            "     .                ی     و  . .(ا)\n",
            "به نظرم ترجمه بهتری میتوانست داشته باشد و البته مجموعا برای شروع کتاب خوبی است.\n",
            "به نظرم ترجمه بهتری میتوانست داشته باشد و البته مجموعا برای شروع کتاب خوبی است.\n",
            "درود بر کوروش بزرگ\n",
            "درود بر کوروش بزرگ\n",
            "اصولا دلیل این همه صحبت راجع به کوروش بزرگ اینه که چشم امثال شما ها در بیاد جناب\n",
            "اصولا دلیل این همه صحبت راجع به کوروش بزرگ اینه که چشم امثال شما ها در بیاد جناب\n",
            "تاریخ و کورش جولانگاه همه شده ، هر کس از راه می رسد برای خالی نبودن عریضه کتابی می سازد ، یکی معمار ، یکی مانند مولف این کتاب حشره شناس\n",
            "تاریخ و کورش جولانگاه همه شده ، هر کس از راه می رسد برای خالی نبودن عریضه کتابی می سازد ، یکی معمار ، یکی مانند مولف این کتاب حشره شناس\n",
            "یعنی ایران قبل کوروش تاریخ نداشته. تا جایی که میدونیم تمدنهای خیلی قدیمی تری در ایران وجود داشتند و درست نیست که تاریخ ایران رو 2500 ساله بیان کنیم. اگه اشتباه نکنم ویکیپدیا هم که قدیمی ترین کشور جهان رو ایران نامبرده تاریخ تاسیس کشور درایران رو پنج هزار سال بیان کرده.\n",
            "یعنی ایران قبل کوروش تاریخ نداشته. تا جایی که میدونیم تمدنهای خیلی قدیمی تری در ایران وجود داشتند و درست نیست که تاریخ ایران رو 2500 ساله بیان کنیم. اگه اشتباه نکنم ویکیپدیا هم که قدیمی ترین کشور جهان رو ایران نامبرده تاریخ تاسیس کشور درایران رو پنج هزار سال بیان کرده.\n",
            "برام جالبه بدونم دلیل برخی از افراد از حمایتهای نابه جا از کوروش چیه؟؟!!!!\n",
            "برام جالبه بدونم دلیل برخی از افراد از حمایتهای نابه جا از کوروش چیه؟؟!!!!\n",
            "کوروش کبیر \n",
            "\n",
            "کوروش از بزرگترین  پادشاهانی است که نه  تنها  تاریخ \n",
            "بلکه  جهان  به نام او افتخار می کند. \n",
            "او تنها  بنیاد  و  بنیانگذار  یک امپراطوری  معظم در جهان \n",
            "نیست  که نام او  را پر  آوازه کرده  است ، بلکه او \n",
            "بنیاد گذار  منشوری است  که  تاریخ  و جهانیان به  آن \n",
            "افتخار می کنند.!! \n",
            "\n",
            "در تاریخ  نام  پادشاهان  همراه با  ظلم  و ستم  و غارت  و چپاول است.  اما  نام کوروش  همراه با  عدالت  و  قانون   و  مدارا است. \n",
            "آنچه امروز  با  نام   ( مدارا )   و    tolerance  در فلسفه‌ سیاسی جهان  مورد  توجه  و تحلیل  متفکران  قرار گرفته  است  ، \n",
            "پدیده ای است  که  در  ۵۰۰  سال  قبل از  میلاد  کوروش  در \n",
            "بین النهرین  و نسبت  به  بابلیان  و  معتقدات  آنها  انجام. \n",
            "\n",
            "کوروش  کبیر تنها  پادشاهی است  که در کتب مقدس \n",
            "لقب منجی  و  رهایی بخش پیدا کرده است.!! \n",
            "او  کسی است  که  قدرت  خویش را  در آزادی  قوم  یهود \n",
            "در بین النهرین و  بابل  بکار گرفت  و  این  قوم  را  از یوغ \n",
            "بردگی  بابلیان نجات  داد  و به  آنها کرامت بخشید.  به همین \n",
            "خاطر بخشی از  کتاب  مقدس  عهد  عتیق به او اختصاص \n",
            "یافته  و از او بعنوان  رهایی بخش یاد کرده است. \n",
            "او  نه تنها  یهود یان را در  رفتن  به سرزمین  خویش آزاد\n",
            " گذاشت  بلکه به آنها در ساختن معابدشان کمک نمود. \n",
            "و اقامت  بزرگان  و پیامبران  بنی اسراییل  از جمله  حضرت \n",
            "دانیال  پیامبر و  ۲۰ نفر دیگر از پیامبر ان  آنان در ایران  \n",
            "بدون  ارتباط  با  رفتار و اخلاق  عالی انسانی او نیست!! \n",
            "\n",
            "بی جهت نیست  که  استاد  ابوالکلام  آزاد  وزیر معارف زمان \n",
            "گاندی  و  مفسر قرآن  مجید  در تفسیر  خود  ، تحقیقاتش را تا بدانجا ادامه میدهد  که  با  صراحت   بنویسد  که  به  احتمال \n",
            "زیاد  ( ذوالقرنین )  همان  کوروش  دوم   امپراطور  \n",
            "هخامنشیان است  .!! \n",
            "و مجموعه  دیدگاهی استاد ابوالکلام آزاد  در کتاب به نام \n",
            "ذوالقرنین توسط استاد باستانی پاریزی ترجمه  و چاپ\n",
            "شده است. \n",
            "به هرحال! \n",
            "ذوالقرنین چه کوروش باشد چه  نباشد ،  کوروش پادشاهی بزرگ و بیمانند است  که  تاریخ  جهان  و جهانیان  به او و  \n",
            "خدمات او افتخار می کنند. \n",
            "اما  این  افتخار نباید  ما  دچار افراط گرایی کاذب  و باستان \n",
            "گرایی بدون  آگاهی نماید.!! \n",
            "والسلام\n",
            "کوروش کبیر \n",
            "\n",
            "کوروش از بزرگترین  پادشاهانی است که نه  تنها  تاریخ \n",
            "بلکه  جهان  به نام او افتخار می کند. \n",
            "او تنها  بنیاد  و  بنیانگذار  یک امپراطوری  معظم در جهان \n",
            "نیست  که نام او  را پر  آوازه کرده  است ، بلکه او \n",
            "بنیاد گذار  منشوری است  که  تاریخ  و جهانیان به  آن \n",
            "افتخار می کنند.!! \n",
            "\n",
            "در تاریخ  نام  پادشاهان  همراه با  ظلم  و ستم  و غارت  و چپاول است.  اما  نام کوروش  همراه با  عدالت  و  قانون   و  مدارا است. \n",
            "آنچه امروز  با  نام   ( مدارا )   و    tolerance  در فلسفه‌ سیاسی جهان  مورد  توجه  و تحلیل  متفکران  قرار گرفته  است  ، \n",
            "پدیده ای است  که  در  ۵۰۰  سال  قبل از  میلاد  کوروش  در \n",
            "بین النهرین  و نسبت  به  بابلیان  و  معتقدات  آنها  انجام. \n",
            "\n",
            "کوروش  کبیر تنها  پادشاهی است  که در کتب مقدس \n",
            "لقب منجی  و  رهایی بخش پیدا کرده است.!! \n",
            "او  کسی است  که  قدرت  خویش را  در آزادی  قوم  یهود \n",
            "در بین النهرین و  بابل  بکار گرفت  و  این  قوم  را  از یوغ \n",
            "بردگی  بابلیان نجات  داد  و به  آنها کرامت بخشید.  به همین \n",
            "خاطر بخشی از  کتاب  مقدس  عهد  عتیق به او اختصاص \n",
            "یافته  و از او بعنوان  رهایی بخش یاد کرده است. \n",
            "او  نه تنها  یهود یان را در  رفتن  به سرزمین  خویش آزاد\n",
            " گذاشت  بلکه به آنها در ساختن معابدشان کمک نمود. \n",
            "و اقامت  بزرگان  و پیامبران  بنی اسراییل  از جمله  حضرت \n",
            "دانیال  پیامبر و  ۲۰ نفر دیگر از پیامبر ان  آنان در ایران  \n",
            "بدون  ارتباط  با  رفتار و اخلاق  عالی انسانی او نیست!! \n",
            "\n",
            "بی جهت نیست  که  استاد  ابوالکلام  آزاد  وزیر معارف زمان \n",
            "گاندی  و  مفسر قرآن  مجید  در تفسیر  خود  ، تحقیقاتش را تا بدانجا ادامه میدهد  که  با  صراحت   بنویسد  که  به  احتمال \n",
            "زیاد  ( ذوالقرنین )  همان  کوروش  دوم   امپراطور  \n",
            "هخامنشیان است  .!! \n",
            "و مجموعه  دیدگاهی استاد ابوالکلام آزاد  در کتاب به نام \n",
            "ذوالقرنین توسط استاد باستانی پاریزی ترجمه  و چاپ\n",
            "شده است. \n",
            "به هرحال! \n",
            "ذوالقرنین چه کوروش باشد چه  نباشد ،  کوروش پادشاهی بزرگ و بیمانند است  که  تاریخ  جهان  و جهانیان  به او و  \n",
            "خدمات او افتخار می کنند. \n",
            "اما  این  افتخار نباید  ما  دچار افراط گرایی کاذب  و باستان \n",
            "گرایی بدون  آگاهی نماید.!! \n",
            "والسلام\n",
            "افتضاح بود\n",
            "افتضاح بود\n",
            "کتاب عالی بود. متن فوق العاده و روان و قابل درک برای همه\n",
            "\n",
            "کتاب عالی بود. متن فوق العاده و روان و قابل درک برای همه\n",
            "\n",
            "کتاب خوبی باید باشد\n",
            "کتاب خوبی باید باشد\n",
            "با سپاس از نویسنده محترم جناب دکتر وکیلی  و   پایگاه‌ فرهنگی طاقچه\n",
            "با سپاس از نویسنده محترم جناب دکتر وکیلی  و   پایگاه‌ فرهنگی طاقچه\n",
            "عرض ادب و احترام \n",
            "خیلی به  دنبال  کتاب  و نوشته ای بودم که به بررسی تاریخی  ( ترانه )  و ترانه سرایی در ایران پرداخته باشد. \n",
            "اگرچه در باره ی تاریخ موسیقی و موسیقی دانان بزرگ آثار بسیار گرانبهایی در ادبیات فارسی وجود دارد و یا در ضمن کتاب های ادبی  یا  انواع ادبی  اشاره ای به\n",
            "  ( ترانه ) نیز  شده  باشد. \n",
            "اما  در این کتاب ارجمند ،  موضوع ( ترانه )  به صورت واحد  مورد بررسی  و کنکاش قرار گرفته  و ترانه سرایی را تا دوران قبل از اسلام و  بزرگانی همچون ( باربد و نکیسا )  ادامه داده است. اگرچه موسیقی تاریخی به  قدمت انسان و تاریخ دارد.\n",
            "عرض ادب و احترام \n",
            "خیلی به  دنبال  کتاب  و نوشته ای بودم که به بررسی تاریخی  ( ترانه )  و ترانه سرایی در ایران پرداخته باشد. \n",
            "اگرچه در باره ی تاریخ موسیقی و موسیقی دانان بزرگ آثار بسیار گرانبهایی در ادبیات فارسی وجود دارد و یا در ضمن کتاب های ادبی  یا  انواع ادبی  اشاره ای به\n",
            "  ( ترانه ) نیز  شده  باشد. \n",
            "اما  در این کتاب ارجمند ،  موضوع ( ترانه )  به صورت واحد  مورد بررسی  و کنکاش قرار گرفته  و ترانه سرایی را تا دوران قبل از اسلام و  بزرگانی همچون ( باربد و نکیسا )  ادامه داده است. اگرچه موسیقی تاریخی به  قدمت انسان و تاریخ دارد.\n",
            "پایان دردناکی داره که هیج وقت فراموشش نکردم❤\n",
            "پایان دردناکی داره که هیج وقت فراموشش نکردم\n",
            "کتاب فوووووق العاده ای بود به نظر من ترجمش هم بسیار خوب وقدیمیه فقط اخرش خیلی غم انگیز بود که من همینشو دوست داشتم\n",
            "کتاب فوووووق العاده ای بود به نظر من ترجمش هم بسیار خوب وقدیمیه فقط اخرش خیلی غم انگیز بود که من همینشو دوست داشتم\n",
            "چرانمیشه خریدش؟؟؟\n",
            "چرانمیشه خریدش؟؟؟\n",
            "5:30صبح الان تمومش کردم درمورد کتاب هرچیزی که بگم حق مطلب ادا نشده.ی عاشقانه ب معنی واقعیه کلمه .ب نظرم کتابیه ک باید هرکسی بخوندش و اصلا لازمه ک خونده بشه هرچند این کتاب واقعا ب جایگاهش نرسید.\n",
            "بخونید و لذت ببرید\n",
            "5:30صبح الان تمومش کردم درمورد کتاب هرچیزی که بگم حق مطلب ادا نشده.ی عاشقانه ب معنی واقعیه کلمه .ب نظرم کتابیه ک باید هرکسی بخوندش و اصلا لازمه ک خونده بشه هرچند این کتاب واقعا ب جایگاهش نرسید.\n",
            "بخونید و لذت ببرید\n",
            "خیلی داستان زیبایی بود واقعا لذت بردم.\n",
            "خیلی داستان زیبایی بود واقعا لذت بردم.\n",
            "زیباست و البته کمی کسل کننده\n",
            "زیباست و البته کمی کسل کننده\n",
            "عااالیه من ک خیلی دوسش دارم..\n",
            "عااالیه من ک خیلی دوسش دارم..\n",
            "عالیه،فوق العاده\n",
            "عالیه،فوق العاده\n",
            "خوب بود، ممنون از پیشنهادتون...\n",
            "خوب بود، ممنون از پیشنهادتون...\n",
            "سلام دوستان برای خرید نسخه چاپی کدوم انتشارات تهران داره؟\n",
            "سلام دوستان برای خرید نسخه چاپی کدوم انتشارات تهران داره؟\n",
            "واقعا عالی بود آدم مجذوبش میشه\n",
            "من از کتاب های رمان فانتزی خیلی خوشم میاد اگه کسی کتابی اینجوری خونده لطفا بگین منم بخونم\n",
            "❤🖤\n",
            "واقعا عالی بود آدم مجذوبش میشه\n",
            "من از کتاب های رمان فانتزی خیلی خوشم میاد اگه کسی کتابی اینجوری خونده لطفا بگین منم بخونم\n",
            "\n",
            "این کتاب فوق العاده است. نویسنده این کتاب کلمات و جملات و داستان را جوری با ظرافت طراحی کرده است که هر خواننده ای را میخ کوب کتابش می کند\n",
            "این کتاب فوق العاده است. نویسنده این کتاب کلمات و جملات و داستان را جوری با ظرافت طراحی کرده است که هر خواننده ای را میخ کوب کتابش می کند\n",
            "من واقعا کتابشو خیلی بیشتر توصیه میکنم تا فیلمش چون تو کتاب علاوه بر جریان جذابی که به خوبی به تصویر کشیده شده دیالوگای ناب و بی نظیری داره که ادمو ساعت ها به فکر فرو میبره\n",
            "من واقعا کتابشو خیلی بیشتر توصیه میکنم تا فیلمش چون تو کتاب علاوه بر جریان جذابی که به خوبی به تصویر کشیده شده دیالوگای ناب و بی نظیری داره که ادمو ساعت ها به فکر فرو میبره\n",
            "فیلمش عالیه\n",
            "واقعن دنیا به دایورجنت ها نیاز داره\n",
            "فیلمش عالیه\n",
            "واقعن دنیا به دایورجنت ها نیاز داره\n",
            "من پنج ساله که روزانه دو کتاب میخوانم\n",
            "این اولین کتابی بود که گریه ام را در اورد و قلبم را مچاله کرد.\n",
            "افرادی که طاقتش را ندارند، جلد اخر را نخونن\n",
            "من پنج ساله که روزانه دو کتاب میخوانم\n",
            "این اولین کتابی بود که گریه ام را در اورد و قلبم را مچاله کرد.\n",
            "افرادی که طاقتش را ندارند، جلد اخر را نخونن\n",
            "فیلمشم قشنگه\n",
            "فیلمشم قشنگه\n",
            "کتابشو نخوندم اما فیلمشو دیدم و قشنگ بود\n",
            "کتابشو نخوندم اما فیلمشو دیدم و قشنگ بود\n",
            "عالی بود\n",
            "اصلا از خوندنش پشیمون نبستم با اینکه امتحان دارم و هیچی نخوندم ولی باز راضیم که وقتمو برای هم چین کتابی گذاشتم\n",
            "ترجمه ش روان و خوب بود\n",
            "در کل فضای داستان و روندش و ترجمه اش همه برام خوب و قابل قبول بود و از خوندن کتاب نهااااایت لذت رو بردم\n",
            "پیشنهاد میشه👌👌👌\n",
            "عالی بود\n",
            "اصلا از خوندنش پشیمون نبستم با اینکه امتحان دارم و هیچی نخوندم ولی باز راضیم که وقتمو برای هم چین کتابی گذاشتم\n",
            "ترجمه ش روان و خوب بود\n",
            "در کل فضای داستان و روندش و ترجمه اش همه برام خوب و قابل قبول بود و از خوندن کتاب نهااااایت لذت رو بردم\n",
            "پیشنهاد میشه\n",
            "با اینکه وفتی فیلمش رو دیدم و متوجه شدم براساس کتابه مدام فکر میکردم کتابش باید چفدر فوق‌العاده تر باشه، تو ذوقم خورد و فیلم رو بیشتر دوست داشتم\n",
            "کتاب خوبی بود و کلا ایده اصلی داستان واقعاااااا جالبه اما نمیدونم چون فیلم رو خیلی دوست داشتم کتاب به نظرم اون اندازه قوی نبود یا اگر فیلم رو نمیدیدم هم همین نظر رو داشتم\n",
            "فضای کتاب خیلی تینیجری تر و احساساتی تر و شخصیت تریس خیلیییی ضعیف تر بود\n",
            "بهرحال بهش پنج میدم چون ایده کتاب رو به شدت دوست داشتم و با تمام این تفاسیر ارزش خوندن رو داشت و اگر کتابش نبود از دیدن فیلمی به این قشنگی محروم بودیم\n",
            "با اینکه وفتی فیلمش رو دیدم و متوجه شدم براساس کتابه مدام فکر میکردم کتابش باید چفدر فوق‌العاده تر باشه، تو ذوقم خورد و فیلم رو بیشتر دوست داشتم\n",
            "کتاب خوبی بود و کلا ایده اصلی داستان واقعاااااا جالبه اما نمیدونم چون فیلم رو خیلی دوست داشتم کتاب به نظرم اون اندازه قوی نبود یا اگر فیلم رو نمیدیدم هم همین نظر رو داشتم\n",
            "فضای کتاب خیلی تینیجری تر و احساساتی تر و شخصیت تریس خیلیییی ضعیف تر بود\n",
            "بهرحال بهش پنج میدم چون ایده کتاب رو به شدت دوست داشتم و با تمام این تفاسیر ارزش خوندن رو داشت و اگر کتابش نبود از دیدن فیلمی به این قشنگی محروم بودیم\n",
            "خیلی کتاب خوبی بود با اینکه فانتزی بود اما خیلی چیزا میشد ازش یاد گرفت\n",
            "خیلی کتاب خوبی بود با اینکه فانتزی بود اما خیلی چیزا میشد ازش یاد گرفت\n",
            "کتاب تخیلی خیلی قشنگی بود، نویسنده قلم خوبی داشته و مترجم هم عالی ترجمه کرده.. دوستش داشتم و حتما دو جلد بعدی رو هم میخونم ان شاالله\n",
            "کتاب تخیلی خیلی قشنگی بود، نویسنده قلم خوبی داشته و مترجم هم عالی ترجمه کرده.. دوستش داشتم و حتما دو جلد بعدی رو هم میخونم ان شاالله\n",
            "خوب بود ، شاید هر کدام از بخش های شهر نمادی از بخش های وجود انسان باشند ، یا جامعه ، باید بیشتر در موردش فکر کنم ، اگر به رمانهای تخیلی علاقه دارید خوبه ،\n",
            "خوب بود ، شاید هر کدام از بخش های شهر نمادی از بخش های وجود انسان باشند ، یا جامعه ، باید بیشتر در موردش فکر کنم ، اگر به رمانهای تخیلی علاقه دارید خوبه ،\n",
            "خیلی خوب حس تجسم رو در خواننده ایجاد میکنه توصیف های دقیق و داستان جذابی داره البته اگه فیلمشو قبلا دیدین فکر نکنم زیاد براتون جذاب باشه...🙂😇\n",
            "خیلی خوب حس تجسم رو در خواننده ایجاد میکنه توصیف های دقیق و داستان جذابی داره البته اگه فیلمشو قبلا دیدین فکر نکنم زیاد براتون جذاب باشه...\n",
            "اگه مثل فیلمش باشه باید قشنگ باشع\n",
            "اگه مثل فیلمش باشه باید قشنگ باشع\n",
            "کتابی بود تخیلی البته من فکرمیکنم اگه همینطور پیش بریم دنیا به همون سمت میره.. فکرمیکنم نوجوانها خوششون بیاد و دوسش داشته باشن.. منم فقط همین کتاب رو خوندم شنیدم دو بخش دیگه هم داره.. کتاب جوری بود که بلافاصله و بی وقفه نمیرم سراغ بخش های بعدی ولی اگه کتاب خوب دیگه ایی پیدا نکردم یه روز میرم میخونمش🙄😊\n",
            "کتابی بود تخیلی البته من فکرمیکنم اگه همینطور پیش بریم دنیا به همون سمت میره.. فکرمیکنم نوجوانها خوششون بیاد و دوسش داشته باشن.. منم فقط همین کتاب رو خوندم شنیدم دو بخش دیگه هم داره.. کتاب جوری بود که بلافاصله و بی وقفه نمیرم سراغ بخش های بعدی ولی اگه کتاب خوب دیگه ایی پیدا نکردم یه روز میرم میخونمش\n",
            "به نظرم محشر بود من تا چند روز به خاطر آخر کتاب جلد سوم افسرده بودم.😢😭\n",
            "به نظرم محشر بود من تا چند روز به خاطر آخر کتاب جلد سوم افسرده بودم.\n",
            "خیلی معمولی\n",
            "خیلی معمولی\n",
            "عالی و پر از هیجان\n",
            "عالی و پر از هیجان\n",
            "جذاب و پر هیجان 🙆\n",
            "جذاب و پر هیجان \n",
            "خیلی دوسداشتنی بود و پر از هیجان.. در طول رمان ضربان قلبم بالا بود و کلی هیجان داشتم.. الان میخوام برم فیلمش رو ببینم😍\n",
            "خیلی دوسداشتنی بود و پر از هیجان.. در طول رمان ضربان قلبم بالا بود و کلی هیجان داشتم.. الان میخوام برم فیلمش رو ببینم\n",
            "خیلی جذاب بود، یک سره نشستم سرش و از اونها بود که آدم مشتاق بود بقیش رو بخونه، با فیلمش هم یه جاهایی متفاوت بود، هر دوش خوبه البته اما توصیه من اینه که اول کتابشو بخونین بعد اگه دوس داشتید فیلمو ببینین\n",
            "خیلی جذاب بود، یک سره نشستم سرش و از اونها بود که آدم مشتاق بود بقیش رو بخونه، با فیلمش هم یه جاهایی متفاوت بود، هر دوش خوبه البته اما توصیه من اینه که اول کتابشو بخونین بعد اگه دوس داشتید فیلمو ببینین\n",
            "این کتاب بیشتر یک کتاب علمی تخیلی مخصوص نوجوان ها و جوان ها شناخته شده اما اگه عمیق بهش نگاه بشه ؛ کتاب جالبیه. وجود فرقه های مختلف ؛ و اینکه هرکس پس از انتخاب فرقه ی خود ... بدون هیچ فکری ... کارها و روش های فرقه ی انتخابی رو انجام میده و ... حالا یک نفر که میاد تغییر ایجاد کنه میشه سنت شکن ... داستان جالبیه ... البته من فقط جلد یک رو خوندم چون فیلمشو که دیدم قسمت های دیگه خیلی فانتزی شده بود و من خوشم نیومد و برای همین به مطالعه همینجلد قناعت کردم.\n",
            "این کتاب بیشتر یک کتاب علمی تخیلی مخصوص نوجوان ها و جوان ها شناخته شده اما اگه عمیق بهش نگاه بشه ؛ کتاب جالبیه. وجود فرقه های مختلف ؛ و اینکه هرکس پس از انتخاب فرقه ی خود ... بدون هیچ فکری ... کارها و روش های فرقه ی انتخابی رو انجام میده و ... حالا یک نفر که میاد تغییر ایجاد کنه میشه سنت شکن ... داستان جالبیه ... البته من فقط جلد یک رو خوندم چون فیلمشو که دیدم قسمت های دیگه خیلی فانتزی شده بود و من خوشم نیومد و برای همین به مطالعه همینجلد قناعت کردم.\n",
            "تو فاز خوندن ی کتابه فانتزیم ی کتاب فانتزی خوب پیشنهاد بدین (ولی جان مادرتون هری پاتر پیشنهاد ندین😂)\n",
            "تو فاز خوندن ی کتابه فانتزیم ی کتاب فانتزی خوب پیشنهاد بدین (ولی جان مادرتون هری پاتر پیشنهاد ندین)\n",
            "خوب بود من فکر کنم فیلم این کتاب رو هم قبلا دیدم درسته ؟\n",
            "خوب بود من فکر کنم فیلم این کتاب رو هم قبلا دیدم درسته ؟\n",
            "خیلی زیباست فیلمش هم موجوده\n",
            "خیلی زیباست فیلمش هم موجوده\n",
            "فارغ از شباهت های این داستان به مجموعه های علمی تخیلی مشابه، فکرمی کنم برای دوستداران مجموعه های فانتزی، با هرسن و سالی، جذاب و خواندنی باشه.\n",
            "فارغ از شباهت های این داستان به مجموعه های علمی تخیلی مشابه، فکرمی کنم برای دوستداران مجموعه های فانتزی، با هرسن و سالی، جذاب و خواندنی باشه.\n",
            "این کتاب منو یاد دوران نوجوانیم میندازه پر از هیجانات مختص به اون سن\n",
            "برای کسایی که کتابایی تو سبک هیجانی تخیلی دوست دارند کتاب خوبیه\n",
            "من این کتابو دوستداشتم فارغ از سن و سالم\n",
            "نکته اینکه شاید اوایل کتاب زیاد جذاب نباشه اما بعدش روند متفاوتی رو پیش میگیره\n",
            "این کتاب منو یاد دوران نوجوانیم میندازه پر از هیجانات مختص به اون سن\n",
            "برای کسایی که کتابایی تو سبک هیجانی تخیلی دوست دارند کتاب خوبیه\n",
            "من این کتابو دوستداشتم فارغ از سن و سالم\n",
            "نکته اینکه شاید اوایل کتاب زیاد جذاب نباشه اما بعدش روند متفاوتی رو پیش میگیره\n",
            "فوق العاده خوب و جذاب! همین :) حتما اگه وقت کردید حتی شده نمونه اش رو هم بخونید چون واقعا از اون داستان هایی که شدیدا شمارو درگیر خودش میکنه و خیلی حرف ها پشت اتفاقاتش هست.\n",
            "فوق العاده خوب و جذاب! همین :) حتما اگه وقت کردید حتی شده نمونه اش رو هم بخونید چون واقعا از اون داستان هایی که شدیدا شمارو درگیر خودش میکنه و خیلی حرف ها پشت اتفاقاتش هست.\n",
            "خیلی خوشم اومد و داستانش هم خیلی جالبه ، فضاسازیش یه جاهایی خیلی قوی میشه و ادم رو با خودش همراه میکنه . توی این سبک کتاب ، این از کتاب های مورد علاقه ام بود اگر کسی کتاب جالب و خوندنی دیگه ای تو این سبک میشناسه لطفا بگه ما هم استفاده کنیم . خیلی ممنون 😊☺\n",
            "خیلی خوشم اومد و داستانش هم خیلی جالبه ، فضاسازیش یه جاهایی خیلی قوی میشه و ادم رو با خودش همراه میکنه . توی این سبک کتاب ، این از کتاب های مورد علاقه ام بود اگر کسی کتاب جالب و خوندنی دیگه ای تو این سبک میشناسه لطفا بگه ما هم استفاده کنیم . خیلی ممنون \n",
            "هم فیلمش هم کتابش خیلی خوووبه حتما بخونید یا فیلمشو نگاه کنید😍😍\n",
            "هم فیلمش هم کتابش خیلی خوووبه حتما بخونید یا فیلمشو نگاه کنید\n",
            "چه خوب که این همه کتاب رایگان کردید\n",
            "چه خوب که این همه کتاب رایگان کردید\n",
            "فیلمش عالیه کتابش هم قطعا عالی باید باشه. ممنون بابت عیدی\n",
            "فیلمش عالیه کتابش هم قطعا عالی باید باشه. ممنون بابت عیدی\n",
            "مرسی طاقچه عزیز برای کتاب های با ارزشی که عیدی دادید🌸🌸🌸🙏🏻🙏🏻\n",
            "مرسی طاقچه عزیز برای کتاب های با ارزشی که عیدی دادید\n",
            "دست مریزاد طاقچه .دمتون گرم... 12 کتاب رایگان احسنت\n",
            "دست مریزاد طاقچه .دمتون گرم... 12 کتاب رایگان احسنت\n",
            "سلام طاقچه به نظرم رایگان کردن یک جلد از یک کتاب سه جلدی بیشتر برای اینه که مارو به خرید دو کتاب دیگه تشویق کنی و این عیدی به حساب نمیاد اگر واقعا قصد عیدی دادن دارید هر سه کتاب رو رایگان کنید.\n",
            "سلام طاقچه به نظرم رایگان کردن یک جلد از یک کتاب سه جلدی بیشتر برای اینه که مارو به خرید دو کتاب دیگه تشویق کنی و این عیدی به حساب نمیاد اگر واقعا قصد عیدی دادن دارید هر سه کتاب رو رایگان کنید.\n",
            "فیلمش عالیه کتابش هم خیلی عالیه از کفت میره نخونی داستانش هیجانیه\n",
            "فیلمش عالیه کتابش هم خیلی عالیه از کفت میره نخونی داستانش هیجانیه\n",
            "کتاب و نمیدونم ولی عاشق فیلمش هستم\n",
            "کتاب و نمیدونم ولی عاشق فیلمش هستم\n",
            "جالب نیود\n",
            "جالب نیود\n",
            "من این کتاب رو در قالب اسم divergent خوندم ولی ترجمه ای که در نمونش دیدم ترجمه ی خوبی بود\n",
            "من این کتاب رو در قالب اسم divergent خوندم ولی ترجمه ای که در نمونش دیدم ترجمه ی خوبی بود\n",
            "فیلمش رو هم ساختن همون divergent معروف\n",
            "فیلمش رو هم ساختن همون divergent معروف\n",
            "به نظرم کتاب خوب و جالبی بود ولی کمی دور از واقعیت بود. نویسنده کمی در مورد قدرت و شجاعت و خاص بودن بئاتریس اغراق کرده بود.\n",
            "به نظرم کتاب خوب و جالبی بود ولی کمی دور از واقعیت بود. نویسنده کمی در مورد قدرت و شجاعت و خاص بودن بئاتریس اغراق کرده بود.\n",
            "بسیار مشتاقم که این کتاب رو مطالعه کنم اما در حال حاضر هم وقتش رو ندارم هم اینکه کلی کتاب مطالعه نکرده روی دستم باقی مونده.\n",
            "بسیار مشتاقم که این کتاب رو مطالعه کنم اما در حال حاضر هم وقتش رو ندارم هم اینکه کلی کتاب مطالعه نکرده روی دستم باقی مونده.\n",
            "اول فکر کردم شبیه ۱۹۸۴هستش، ولی خیلی ضعیف تر از اون بود..🙂\n",
            "اول فکر کردم شبیه ۱۹۸۴هستش، ولی خیلی ضعیف تر از اون بود..\n",
            "ترجمه ی کتاب عالی بود 🌟\n",
            "ترجمه ی کتاب عالی بود \n",
            "واقعا عالی بود.. \n",
            "نمیتونستم دست از خوندنش بردارم اصلا..\n",
            "واقعا عالی بود.. \n",
            "نمیتونستم دست از خوندنش بردارم اصلا..\n",
            "آقای احسان صفایی اگه کتاب اصلی رو خونده باشید نویسنده (ورونیکا راف) توی صفحه توضیحات، عنوان کتاب رو کاملا تشریح کرده.  توی توضیحاتش اومده:  توی این کتابdivergent به کسی میگن که نوع دیگه ای از زندگی رو در پیش میگیره و از مسیر عادی منحرف میشه بنابراین \"سنت شکن\" ترجمه به جا و عالی بود. \n",
            "آقای احسان صفایی اگه کتاب اصلی رو خونده باشید نویسنده (ورونیکا راف) توی صفحه توضیحات، عنوان کتاب رو کاملا تشریح کرده.  توی توضیحاتش اومده:  توی این کتابdivergent به کسی میگن که نوع دیگه ای از زندگی رو در پیش میگیره و از مسیر عادی منحرف میشه بنابراین \"سنت شکن\" ترجمه به جا و عالی بود. \n",
            "اسم اصلی کتاب divergent هست\n",
            "یعنی بی نظیر \n",
            "به نظرم سنت شکن اشتباهه.\n",
            "ولی کتاب خیلی خوبیه.\n",
            "سبک نوشتن فرق داره بخصوص جلد آخر.\n",
            "حتما بخونید.\n",
            "اسم اصلی کتاب divergent هست\n",
            "یعنی بی نظیر \n",
            "به نظرم سنت شکن اشتباهه.\n",
            "ولی کتاب خیلی خوبیه.\n",
            "سبک نوشتن فرق داره بخصوص جلد آخر.\n",
            "حتما بخونید.\n",
            "همه ی جلد هاش فوق العاده بود من پارسال خوندم. موضوعش همون قدر ک  کتاب های هری پاتر جدید بود اینم جدیده\n",
            "همه ی جلد هاش فوق العاده بود من پارسال خوندم. موضوعش همون قدر ک  کتاب های هری پاتر جدید بود اینم جدیده\n",
            "عاشق این کتاب ها و فیلمش هستم...انگلیسیش هم عاااالیه...عاشق بازیگرانش هم هستم...\n",
            "عاشق این کتاب ها و فیلمش هستم...انگلیسیش هم عاااالیه...عاشق بازیگرانش هم هستم...\n",
            "حرف نداره\n",
            "حرف نداره\n",
            "تو  این سبک کتابای دیگه هم هست؟؟\n",
            "کتاب عالی بود\n",
            "تو  این سبک کتابای دیگه هم هست؟؟\n",
            "کتاب عالی بود\n",
            "عالی بود!ترجمه هم حرف نداشت!٥ ستاره ی ٥ستاره!!\n",
            "عالی بود!ترجمه هم حرف نداشت!٥ ستاره ی ٥ستاره!!\n",
            "خیلی عالی بود. ترجمه ی خیلی خوبی هم داشت و سریع جلو میرفت.\n",
            "خیلی عالی بود. ترجمه ی خیلی خوبی هم داشت و سریع جلو میرفت.\n",
            "بسیار خوب بود و ترجمه بسیار عالی داشت. خیلی سریع جلو میرفت.\n",
            "بسیار خوب بود و ترجمه بسیار عالی داشت. خیلی سریع جلو میرفت.\n",
            "٥  فصل اول خیلی خوب و هیجان انگیز بود ولی بعدش یکم کند شد اما  ٩ فصل آخرش عالی بود.\n",
            "کلا  ٣٩ فصله.\n",
            "ترجمه خوب و روانی داشت.\n",
            "در کل کتاب خوبی بود.\n",
            "٥  فصل اول خیلی خوب و هیجان انگیز بود ولی بعدش یکم کند شد اما  ٩ فصل آخرش عالی بود.\n",
            "کلا  ٣٩ فصله.\n",
            "ترجمه خوب و روانی داشت.\n",
            "در کل کتاب خوبی بود.\n",
            "ترجمه اش عالی بود. کتاب رو توی یک روز تموم کردم👌👌👌\n",
            "ترجمه اش عالی بود. کتاب رو توی یک روز تموم کردم\n",
            "به نظر من کتاب فوق العاده ای بود.\n",
            "به نظر من کتاب فوق العاده ای بود.\n",
            "کتاب خوبیست. تصویر سازی بسیار قوی و روان. فضای فانتزی جذاب و پرشوری داره. واقعا لذت بردم. سپاسگزارم.\n",
            "کتاب خوبیست. تصویر سازی بسیار قوی و روان. فضای فانتزی جذاب و پرشوری داره. واقعا لذت بردم. سپاسگزارم.\n",
            "کتاب جذابیه و خواننده رو به دنبال کردن کتاب ترغیب می کنه.\n",
            "کتاب جذابیه و خواننده رو به دنبال کردن کتاب ترغیب می کنه.\n",
            "کتاب بسیار قشنگیه واقعا برای کسایی که از کتاب و سبک عطش مبارزه خوششون میاد پیشنهاد میشههه ... \n",
            "طاقچه اگه کتابهای معروف جهان تو سبک فانتزی مثل ارباب حلقه ها . هری پاتر . نارنیا هم بذاری خییلی خوبه\n",
            "کتاب بسیار قشنگیه واقعا برای کسایی که از کتاب و سبک عطش مبارزه خوششون میاد پیشنهاد میشههه ... \n",
            "طاقچه اگه کتابهای معروف جهان تو سبک فانتزی مثل ارباب حلقه ها . هری پاتر . نارنیا هم بذاری خییلی خوبه\n",
            "این کتاب یک سه گانست یعنی دنباله داره و نام این سه گانه:1_سنت شکن2_شورشی3_هم پیمان\n",
            "که از روی دو کتاب اول فیلم هم ساخته شده و اخری هم ساخته خواهد شد که فیلمی که کتاب دوم ساختن در حال حاظر تو سینما ها در حال اکران\n",
            "این کتاب یک سه گانست یعنی دنباله داره و نام این سه گانه:1_سنت شکن2_شورشی3_هم پیمان\n",
            "که از روی دو کتاب اول فیلم هم ساخته شده و اخری هم ساخته خواهد شد که فیلمی که کتاب دوم ساختن در حال حاظر تو سینما ها در حال اکران\n",
            "ب نظرم شروع خیلی خوبی داشت اما در ادامه افت کردش، ب هر حال از خاندنش پشیمان نیستم.\n",
            "ب نظرم شروع خیلی خوبی داشت اما در ادامه افت کردش، ب هر حال از خاندنش پشیمان نیستم.\n",
            "علی رغم بعضی غلط های املایی، فوق العاده بود. هم داستان و هم ترجمه\n",
            "علی رغم بعضی غلط های املایی، فوق العاده بود. هم داستان و هم ترجمه\n",
            "خیلی جالبه  و یکسره میشه از اول تا آخرش رو خوند ، منتها یه کمی زیادی فانتزی و غیر واقعیه !\n",
            "خیلی جالبه  و یکسره میشه از اول تا آخرش رو خوند ، منتها یه کمی زیادی فانتزی و غیر واقعیه !\n",
            "خیلی خوب بود فقط کاش برای جلد دو و سه هم تخفیف میذاشتید...\n",
            "خیلی خوب بود فقط کاش برای جلد دو و سه هم تخفیف میذاشتید...\n",
            "خوب آقا خووووووب ....\n",
            "خوب آقا خووووووب ....\n",
            "عالیه ممنون فقط اگه می تونید کتاب های دونده هزار تو و نغمه یخ و اتش (game of thranth) رو هم بزارید ممنون میشم\n",
            "عالیه ممنون فقط اگه می تونید کتاب های دونده هزار تو و نغمه یخ و اتش (game of thranth) رو هم بزارید ممنون میشم\n",
            "ممنون طاقچه. عالیه\n",
            "ممنون طاقچه. عالیه\n",
            "واقعا عالیههههه......\n",
            "واقعا عالیههههه......\n",
            "افتتاحیه کتاب آنقدر خوب بود ک نتوانستم نیایم و پنج ستاره را ندهم!\n",
            "افتتاحیه کتاب آنقدر خوب بود ک نتوانستم نیایم و پنج ستاره را ندهم!\n",
            "من فیلمهای هر سه گانه رو دیدم و عالی بود.\n",
            "من فیلمهای هر سه گانه رو دیدم و عالی بود.\n",
            "این هم قشنگ بود.\n",
            "کتاب اول رو دوستان میگن قشنگ تر بود و من فکر میکنم علتش اینه که تقریبا همون ویژگی های عجیبی که تو کتاب اول مطرح شده بود این جا تکرار می شد، نه که نویسنده حرف جدیدی برای گفتن نداشته باشه ولی با همون ویژگی ها و اخلاق ها داستان رو جلو برده. چیزی بهشون اضافه نکرده. و اینکه از لحاظ تایپی کمی ایراد داشت که خب مسلما خواننده ترجیح میده وقتی تو اوج داستان هست چشمش گیر نکنه بین کلمات تا اونا رو حدس بزنه یا مرتب کنه\n",
            "این هم قشنگ بود.\n",
            "کتاب اول رو دوستان میگن قشنگ تر بود و من فکر میکنم علتش اینه که تقریبا همون ویژگی های عجیبی که تو کتاب اول مطرح شده بود این جا تکرار می شد، نه که نویسنده حرف جدیدی برای گفتن نداشته باشه ولی با همون ویژگی ها و اخلاق ها داستان رو جلو برده. چیزی بهشون اضافه نکرده. و اینکه از لحاظ تایپی کمی ایراد داشت که خب مسلما خواننده ترجیح میده وقتی تو اوج داستان هست چشمش گیر نکنه بین کلمات تا اونا رو حدس بزنه یا مرتب کنه\n",
            "جلد دوم علاوه بر داشتن یسری اشتباهات تایپی ، از نظر موضوع و اتفاقات داستان سطح پایین تری از جلد اول داره .\n",
            "ولی در مجموع این یه سه گانه موضوع جالبی داره و جذابه 👌\n",
            "جلد دوم علاوه بر داشتن یسری اشتباهات تایپی ، از نظر موضوع و اتفاقات داستان سطح پایین تری از جلد اول داره .\n",
            "ولی در مجموع این یه سه گانه موضوع جالبی داره و جذابه \n",
            "جلد اول از هر نظر خوب بود اما جلد دوم پر از اشتباهات تایپیه .\n",
            "جلد اول از هر نظر خوب بود اما جلد دوم پر از اشتباهات تایپیه .\n",
            "مزخرف،\n",
            "مزخرف،\n",
            "من نمونه را خواندم ولی وقتی کتاب را خریدم متن حذف شده علتش چیه؟\n",
            "من نمونه را خواندم ولی وقتی کتاب را خریدم متن حذف شده علتش چیه؟\n",
            "ترجمه هر  کتاب از کتاب های سه گانه بسیار روان میباشد. بسیار لذت بردم... خسته نباشید خانم مترجم... 💜🍀\n",
            "ترجمه هر  کتاب از کتاب های سه گانه بسیار روان میباشد. بسیار لذت بردم... خسته نباشید خانم مترجم... \n",
            "عالی بود!از اون کتاب هایی که آدم از خوندنش لذت میبره و با شخصیت های به راحتی داستان ارتباط برقرار میکنه!💗\n",
            "عالی بود!از اون کتاب هایی که آدم از خوندنش لذت میبره و با شخصیت های به راحتی داستان ارتباط برقرار میکنه!\n",
            "لذتبخش بود.\n",
            "لذتبخش بود.\n",
            "من کتاب اصلی شو هم خوندم. باید بگم ترجمه اش محشره. روند داستان هم خیلی جذابه.👌🏻کلا وقتی شروع به خوندن این سه گانه میکنی دیگه نمیتونی کتاب رو زمین بذاری.\n",
            "من کتاب اصلی شو هم خوندم. باید بگم ترجمه اش محشره. روند داستان هم خیلی جذابه.کلا وقتی شروع به خوندن این سه گانه میکنی دیگه نمیتونی کتاب رو زمین بذاری.\n",
            "کاربر هادی ، ممنون که گفتی ...راستش من هم پیمان رو سرچ کردم اومد که نیست !حالا توی بخش رمانهای خارجی پیداش کردم ...هنوز نخوندم ...امیدوارم خوب باشه !\n",
            "کاربر هادی ، ممنون که گفتی ...راستش من هم پیمان رو سرچ کردم اومد که نیست !حالا توی بخش رمانهای خارجی پیداش کردم ...هنوز نخوندم ...امیدوارم خوب باشه !\n",
            "کاربر 4552 !! طاقچه هم پیمان رو هم داره...همین انتشارات نوروز هنر منتشرش کرده\n",
            "کاربر 4552 !! طاقچه هم پیمان رو هم داره...همین انتشارات نوروز هنر منتشرش کرده\n",
            "نمیشه گفت که خواندنش وقت تلف کردنه ...کاملا سرگرم کننده اس...نسبت به جلد اول هم چندان افت کیفیت نداشت ولی میشه گفت تا حدودی گیج کننده بود و میشد که اینطور نباشه ...جلد سوم رو از کجا تهیه کنیم ؟ طاقچه که نداره ...اصلا هم پیمان ترجمه شده ؟!\n",
            "نمیشه گفت که خواندنش وقت تلف کردنه ...کاملا سرگرم کننده اس...نسبت به جلد اول هم چندان افت کیفیت نداشت ولی میشه گفت تا حدودی گیج کننده بود و میشد که اینطور نباشه ...جلد سوم رو از کجا تهیه کنیم ؟ طاقچه که نداره ...اصلا هم پیمان ترجمه شده ؟!\n",
            "با وحید موافقم.....جلد یکش قوی تر بود....اما با این حال ارزش خوندن رو. داره...😎\n",
            "با وحید موافقم.....جلد یکش قوی تر بود....اما با این حال ارزش خوندن رو. داره...\n",
            "راستش ب نظرم نسبت ب جلد قبلی ب طور آشکاری هالیوودی تر شده، و بعضی جاهاش خیلی آبکی ه، اما در مجموع هنوز ارزش خوندن رو داره، جالبه ک اصولا در اکثر تیرولوژی ها قسمت دوم از اولی ضعیف تر میشه حالا باید ببینم جلد سوم ش در چ حده :-D\n",
            "راستش ب نظرم نسبت ب جلد قبلی ب طور آشکاری هالیوودی تر شده، و بعضی جاهاش خیلی آبکی ه، اما در مجموع هنوز ارزش خوندن رو داره، جالبه ک اصولا در اکثر تیرولوژی ها قسمت دوم از اولی ضعیف تر میشه حالا باید ببینم جلد سوم ش در چ حده :-D\n",
            "این کتاب فوق العاده بود.\n",
            "این کتاب فوق العاده بود.\n",
            "عالیه اگه می شه کتاب های برتر و جدید دنیا رو بزاری مثل نغمه یخ و آتش یا کتاب های دیگه ای که برنده جایزه شدن ممنون\n",
            "عالیه اگه می شه کتاب های برتر و جدید دنیا رو بزاری مثل نغمه یخ و آتش یا کتاب های دیگه ای که برنده جایزه شدن ممنون\n",
            "خیلی پایان بدی داشت بنظرم نویسنده میتونست یه پایان خیلیی قشنگتر براش بنویسه بعد از خوندن ۳جلد کتاب یهو کلا پوکر میشی😐😑\n",
            "خیلی پایان بدی داشت بنظرم نویسنده میتونست یه پایان خیلیی قشنگتر براش بنویسه بعد از خوندن ۳جلد کتاب یهو کلا پوکر میشی\n",
            "قشنگ بود، یعنی به یکبار خوندنش می ارزید ، هر چند وسطاش خیلی خسته کننده میشد و پایانش هم خیلی تلخ بود، حس میکنم فیلمش باید قشنگ تر باشه\n",
            "قشنگ بود، یعنی به یکبار خوندنش می ارزید ، هر چند وسطاش خیلی خسته کننده میشد و پایانش هم خیلی تلخ بود، حس میکنم فیلمش باید قشنگ تر باشه\n",
            "اخههه چرا انقد پایانش بد بود\n",
            "اخههه چرا انقد پایانش بد بود\n",
            "این کتاب های سه گانه رو نخوندم فیلمش دیدم که خیلی خیلی قشنگ بود مخصوصا قسمت سومش که از یک و دو قشنگ تر بود در کل نبوغ نویسنده فراتر از فوق العاده بود.\n",
            "این کتاب های سه گانه رو نخوندم فیلمش دیدم که خیلی خیلی قشنگ بود مخصوصا قسمت سومش که از یک و دو قشنگ تر بود در کل نبوغ نویسنده فراتر از فوق العاده بود.\n",
            "و بلاخره پایان این سه گانه😊\n",
            "جلد سوم فراز و نشیب و هیجان داره ،اما کشش کمی داره وحتی چندتا فصلو نخوندم تا زودتر به پایانش برسه !\n",
            "پایان تلخی داره ؛اما در مجموع این سه کتاب میتونن اموزنده هم باشن✌\n",
            "و بلاخره پایان این سه گانه\n",
            "جلد سوم فراز و نشیب و هیجان داره ،اما کشش کمی داره وحتی چندتا فصلو نخوندم تا زودتر به پایانش برسه !\n",
            "پایان تلخی داره ؛اما در مجموع این سه کتاب میتونن اموزنده هم باشن\n",
            "تو سه روز این سه گانه رو خوندم.امروز روز سومه و من اونقدری شوکه شدم که نمیدونم نبوغ نویسنده رو تحسین کنم یا فحشش بدم.جزو فانتزی هاییه که به آدم درس زندگی میده\n",
            "تو سه روز این سه گانه رو خوندم.امروز روز سومه و من اونقدری شوکه شدم که نمیدونم نبوغ نویسنده رو تحسین کنم یا فحشش بدم.جزو فانتزی هاییه که به آدم درس زندگی میده\n",
            "اخر این کتاب چی شد مگه؟\n",
            "اخه من فیلمش رو دیدم پایان خاصی نداشت\n",
            "اخر این کتاب چی شد مگه؟\n",
            "اخه من فیلمش رو دیدم پایان خاصی نداشت\n",
            "هر سه کتاب عالی بودن ولی پایانش خیلی شوکه کننده کننده بود چند روز لازمه که پایان داستان رو هضم کنم\n",
            "هر سه کتاب عالی بودن ولی پایانش خیلی شوکه کننده کننده بود چند روز لازمه که پایان داستان رو هضم کنم\n",
            "عالی بود واسه همه توصیه میکنم\n",
            "عالی بود واسه همه توصیه میکنم\n",
            "یکی از بهترین کتابای عمرم بود\n",
            "به نظرم نویسنده از دید واقعا جالبی به زندگی و انسان ها نگاه کرده بود\n",
            "هر کدوم از شخصیت ها نمادی از انسان های اطرافمون بودن\n",
            "من خودم واقعا دید فلسفی نسبت به همه چیز برای همین این کتاب برای من پنجره ای به یک دنیای جدید بود که هیچ وقت تا این حد بهش دقت نکرده بودم\n",
            "پایان کتاب... خیلی زیبا اما شوکه اور بود\n",
            "من خودم یک هفته طول کشید تا به حالت نرمال برگردم اما بازم ارزش خوندن رو داشت طوری که میخوام بازم این کتابو بار ها و بار بخونم\n",
            "و راستی میشه لطفا جلد چهارمش رو هم بذارید نسبت بهش احساس نیاز دارم\n",
            "ممنون\n",
            "یکی از بهترین کتابای عمرم بود\n",
            "به نظرم نویسنده از دید واقعا جالبی به زندگی و انسان ها نگاه کرده بود\n",
            "هر کدوم از شخصیت ها نمادی از انسان های اطرافمون بودن\n",
            "من خودم واقعا دید فلسفی نسبت به همه چیز برای همین این کتاب برای من پنجره ای به یک دنیای جدید بود که هیچ وقت تا این حد بهش دقت نکرده بودم\n",
            "پایان کتاب... خیلی زیبا اما شوکه اور بود\n",
            "من خودم یک هفته طول کشید تا به حالت نرمال برگردم اما بازم ارزش خوندن رو داشت طوری که میخوام بازم این کتابو بار ها و بار بخونم\n",
            "و راستی میشه لطفا جلد چهارمش رو هم بذارید نسبت بهش احساس نیاز دارم\n",
            "ممنون\n",
            "یه کتاب دیگه ام هست که میشه چهارمین کتاب اسمش four از زبان توبایس گفته میشه ودر باره اونه نمی دونم چرا بعد از حدود ٤ سال هنوز کسکی ترجمه اش نکرده\n",
            "خیلیامون توبایسو دوست داریم و می خوایم درباره اش بیشتر بدونیم\n",
            "یه کتاب دیگه ام هست که میشه چهارمین کتاب اسمش four از زبان توبایس گفته میشه ودر باره اونه نمی دونم چرا بعد از حدود ٤ سال هنوز کسکی ترجمه اش نکرده\n",
            "خیلیامون توبایسو دوست داریم و می خوایم درباره اش بیشتر بدونیم\n",
            "عالیه این کتاب\n",
            "عالیه این کتاب\n",
            "عالی بود ... پایان لوسی نداشت ... فانتزی جدید و جذابی بود\n",
            "عالی بود ... پایان لوسی نداشت ... فانتزی جدید و جذابی بود\n",
            "چطور میتونم جایی غیر از طاقچه باز کنم کتابو؟ یعنی چطور انتقال بدم خارج از طاقچه\n",
            "چطور میتونم جایی غیر از طاقچه باز کنم کتابو؟ یعنی چطور انتقال بدم خارج از طاقچه\n",
            "جلد چهارم این کتاب ترجمه شده؟ \n",
            "اگر جلد چهارمم دارین ، لطفا بزارین\n",
            "جلد چهارم این کتاب ترجمه شده؟ \n",
            "اگر جلد چهارمم دارین ، لطفا بزارین\n",
            "فوق العادس این کتاب ولی پایانش خیلی برای من دلچسب نبود ،واقعا شوکه شدم...\n",
            "فوق العادس این کتاب ولی پایانش خیلی برای من دلچسب نبود ،واقعا شوکه شدم...\n",
            "کتاب بسیار جذابی بود با ترجمه بسیار روان...\n",
            "کتاب بسیار جذابی بود با ترجمه بسیار روان...\n",
            "عالی عالی عالی 👍👍👍از اینکه پایان لوسی نداشت لذت بردم.\n",
            "عالی عالی عالی از اینکه پایان لوسی نداشت لذت بردم.\n",
            "بسیار لذت بردم. خوندنش رو حتما حتما توصیه میکنم.\n",
            "بسیار لذت بردم. خوندنش رو حتما حتما توصیه میکنم.\n",
            "خیلی عالی بود ، البته قسمت اول از همه بهتر بود...\n",
            "پایانش هم شوک شدم...\n",
            "خیلی عالی بود ، البته قسمت اول از همه بهتر بود...\n",
            "پایانش هم شوک شدم...\n",
            "ب نظرم نویسنده در سه تا کتاب سیر نزولی را طی کرده، نصف این کتاب زیادی بود و میتونست حذف شه، کل سه کتاب را باید در همان اولی خلاصه میکرد.\n",
            "ب نظرم نویسنده در سه تا کتاب سیر نزولی را طی کرده، نصف این کتاب زیادی بود و میتونست حذف شه، کل سه کتاب را باید در همان اولی خلاصه میکرد.\n",
            "چی بگم ؟ ... تصورات قبلی ام رو بهم ریخت ... بهتر بود این جلد رو نمی خوندم ...الان دقیقا حس کسی رو دارم که فریب داده شده !..\n",
            "چی بگم ؟ ... تصورات قبلی ام رو بهم ریخت ... بهتر بود این جلد رو نمی خوندم ...الان دقیقا حس کسی رو دارم که فریب داده شده !..\n",
            "عالی بود 👍👌👍👍👍\n",
            "عالی بود \n",
            "عالیه لطفا کتاب های دیگر که ترجمه ای هست و برای رنج جوان و نوجوان است رو بیشتر بزارید\n",
            "عالیه لطفا کتاب های دیگر که ترجمه ای هست و برای رنج جوان و نوجوان است رو بیشتر بزارید\n",
            "بینظیر\n",
            "بینظیر\n",
            "کتابی که علمیه نباید اینقد ارایه ادبی و توصیف و اینا داشته باشه😒😐😐😐\n",
            "اصن دلم نیومد ادامش بدم\n",
            "مطالب تکراری و بنظرم پیش پا افتاده!\n",
            "بعنوان ی کتاب انگیزشی بدک نیس! ولی اونقدرا هم خوب نیس!\n",
            "البته از حق نگذریم سرفصلای جالبی داشت و چیزای خوبی رو برای بررسی کردن در نظر گرفته بود اما خیلی بهشون نپرداخت و زود از روشون رد شد و کاربردی نبود و انگار انشا نوشته با موضوع فلان!!!\n",
            "و تو انشا برای خوشگل شدن باید ی کم اطلاعات رو تو ی سری جملات قشنگ قشنگ کنار هم بچینی تا نمره بگیری 😐\n",
            "کتابی که علمیه نباید اینقد ارایه ادبی و توصیف و اینا داشته باشه\n",
            "اصن دلم نیومد ادامش بدم\n",
            "مطالب تکراری و بنظرم پیش پا افتاده!\n",
            "بعنوان ی کتاب انگیزشی بدک نیس! ولی اونقدرا هم خوب نیس!\n",
            "البته از حق نگذریم سرفصلای جالبی داشت و چیزای خوبی رو برای بررسی کردن در نظر گرفته بود اما خیلی بهشون نپرداخت و زود از روشون رد شد و کاربردی نبود و انگار انشا نوشته با موضوع فلان!!!\n",
            "و تو انشا برای خوشگل شدن باید ی کم اطلاعات رو تو ی سری جملات قشنگ قشنگ کنار هم بچینی تا نمره بگیری \n",
            "یکی از واقعا ضعیف ترین کتاب هایی که خوندم،اصلا کتاب نمیشد گفت،نصیحت بود،فقط جملات معمولی و مثبت نوشته شده؛ و راجب یک جمله کلی توضیح داده،یک ستاره به اجبار میدم،به نظرم ارزش یک بار خوندن رو با تردید میشه بهش داد،\n",
            "یکی از واقعا ضعیف ترین کتاب هایی که خوندم،اصلا کتاب نمیشد گفت،نصیحت بود،فقط جملات معمولی و مثبت نوشته شده؛ و راجب یک جمله کلی توضیح داده،یک ستاره به اجبار میدم،به نظرم ارزش یک بار خوندن رو با تردید میشه بهش داد،\n",
            "بسیار عالی👍👍\n",
            "بسیار عالی\n",
            "خیلی خوبه اگه کسی میخواد تغییر کنه بهش اگاهی میده و یه جورایی محرکشه...موفق باشید عزیزان\n",
            "خیلی خوبه اگه کسی میخواد تغییر کنه بهش اگاهی میده و یه جورایی محرکشه...موفق باشید عزیزان\n",
            "\"کجاوه\"روایتی از سختی ها و رنج ها و واقعیت زندگی ترکمن هاست.از چهار داستان تشکیل شده است; با همان نثر روان و لطیف و با همان نکته سنجی ها ی مخصوصِ\"یوسف قوجق\".\n",
            "اما...ریتم کند و یکنواخت داستانها حوصله را سر میبرد.قبل تر کتابِ دیگری از این نویسنده خوانده بودم به نام \"لالو\";و موقع خواندن کجاوه انگار داشتم دوباره لالو میخواندم,از نظر من غیر از داستان پایانی بقیه کتاب هیچ حرف جدیدی برای گفتن نداشت;محتوای تکراری!\n",
            "¤¤¤\n",
            "دو ستاره;فقط به خاطر پایان بندیِ داستانِ آخر,که برای من بسیار دل نشین بود.\n",
            "\"کجاوه\"روایتی از سختی ها و رنج ها و واقعیت زندگی ترکمن هاست.از چهار داستان تشکیل شده است; با همان نثر روان و لطیف و با همان نکته سنجی ها ی مخصوصِ\"یوسف قوجق\".\n",
            "اما...ریتم کند و یکنواخت داستانها حوصله را سر میبرد.قبل تر کتابِ دیگری از این نویسنده خوانده بودم به نام \"لالو\";و موقع خواندن کجاوه انگار داشتم دوباره لالو میخواندم,از نظر من غیر از داستان پایانی بقیه کتاب هیچ حرف جدیدی برای گفتن نداشت;محتوای تکراری!\n",
            "¤¤¤\n",
            "دو ستاره;فقط به خاطر پایان بندیِ داستانِ آخر,که برای من بسیار دل نشین بود.\n",
            "تو کتابفروشی های اینترنتی قیمتش 1900 برین چک کنین.از تاقچه انتظار نداشتم\n",
            "تو کتابفروشی های اینترنتی قیمتش 1900 برین چک کنین.از تاقچه انتظار نداشتم\n",
            "تقریبا 5،6سال پیش خوندمش عالیه\n",
            "البته کتاب من ترجمه مهرداد فیروزبخت ، انتشارات رشده...ترجمه روون و خوبی داره\n",
            "تقریبا 5،6سال پیش خوندمش عالیه\n",
            "البته کتاب من ترجمه مهرداد فیروزبخت ، انتشارات رشده...ترجمه روون و خوبی داره\n",
            "در توضیحات کتاب نوشته شده ۱۳۶صفحه و وقتی خریدم ۸۷صفحه البته این بار دومه یعنی کتاب قبلی هم که خریدم همین وضعیت رو داشت؟؟؟؟!!!!!\n",
            "این مسله را در کتاب راه ، فیدیبو یا فرا کتاب یا.... نداشتم\n",
            "به جای نگرانی خرید نمی کنم\n",
            "در توضیحات کتاب نوشته شده ۱۳۶صفحه و وقتی خریدم ۸۷صفحه البته این بار دومه یعنی کتاب قبلی هم که خریدم همین وضعیت رو داشت؟؟؟؟!!!!!\n",
            "این مسله را در کتاب راه ، فیدیبو یا فرا کتاب یا.... نداشتم\n",
            "به جای نگرانی خرید نمی کنم\n",
            "واقعا کتاب خوبیه. من توصیه اش میکنم. نکته مثبتش اینه که مباحثی که یک نویسنده آمریکایی نوشته رو \"ایرانیزه\" کرده. یعنی طوری که با فرهنگ ایرانی میخونه و این به فهم بیش تر مطلب خیلی کمک میکنه. کاش افراد دیگری هم بودن تا کتاب های دیگه ی روانشناسی موفقیت رو \"ایرانیزه\" کنن. چون فرهنگ ما جامعه ما و شرایط زندگی ما با اون ها خیلی متفاوته .\n",
            "واقعا کتاب خوبیه. من توصیه اش میکنم. نکته مثبتش اینه که مباحثی که یک نویسنده آمریکایی نوشته رو \"ایرانیزه\" کرده. یعنی طوری که با فرهنگ ایرانی میخونه و این به فهم بیش تر مطلب خیلی کمک میکنه. کاش افراد دیگری هم بودن تا کتاب های دیگه ی روانشناسی موفقیت رو \"ایرانیزه\" کنن. چون فرهنگ ما جامعه ما و شرایط زندگی ما با اون ها خیلی متفاوته .\n",
            "انقدر کتابش غلط تایپی و ویراستی داره که وسط کار بیخیالش شدم. میرم توی اپ های دیگه پیداش کنم!\n",
            "انقدر کتابش غلط تایپی و ویراستی داره که وسط کار بیخیالش شدم. میرم توی اپ های دیگه پیداش کنم!\n",
            "تقریبا همون کتاب نمیگذارم کسی اعصابم را بهم بریزد به نگارش فارسی و مناسب با فرهنگ ایرانی که البته خیلی نکات کاربردی زیادی نداشت\n",
            "تقریبا همون کتاب نمیگذارم کسی اعصابم را بهم بریزد به نگارش فارسی و مناسب با فرهنگ ایرانی که البته خیلی نکات کاربردی زیادی نداشت\n",
            "یه کتاب مفید\n",
            "یه کتاب مفید\n",
            "کتاب خیلی خوبیه ، اکثر ناراحتی های ما به خاطر باورهای غیرمنطقیمونه ، مثلا انتظار داریم همه مارو دوست داشته باشند و تایید کنند ولی عقل میگه که چنین چیزی ممکن نیست.\n",
            "عقل نعمت خیلی بزرگیه ولی اکثر آدمها عاقلانه زندگی نمی کنن و اسیر تمایلاتشونن، مثلا شیفته یه مقام و منصب میشن و به خاطر رسیدن بهش حتی ممکنه خوشبختی و آرامششون رو هم فدا کنن.\n",
            "کتاب خیلی خوبیه ، اکثر ناراحتی های ما به خاطر باورهای غیرمنطقیمونه ، مثلا انتظار داریم همه مارو دوست داشته باشند و تایید کنند ولی عقل میگه که چنین چیزی ممکن نیست.\n",
            "عقل نعمت خیلی بزرگیه ولی اکثر آدمها عاقلانه زندگی نمی کنن و اسیر تمایلاتشونن، مثلا شیفته یه مقام و منصب میشن و به خاطر رسیدن بهش حتی ممکنه خوشبختی و آرامششون رو هم فدا کنن.\n",
            "فوق العاده،بازنویسی شده برای جامعه ی ایرانی.\n",
            "اگه بتونید بخونیدش،حتی نمونه رو،خیلی زیاد مفیده براتون.\n",
            "فوق العاده،بازنویسی شده برای جامعه ی ایرانی.\n",
            "اگه بتونید بخونیدش،حتی نمونه رو،خیلی زیاد مفیده براتون.\n",
            "این کتاب را خواهرم که روانشناس هست بهم معرفی کرده کتاب خوبی هست ، مطمئن باشید ارزش خوندن را داره\n",
            "این کتاب را خواهرم که روانشناس هست بهم معرفی کرده کتاب خوبی هست ، مطمئن باشید ارزش خوندن را داره\n",
            "این کتاب رو شدیدا توصیه میکنم خصوصا اگر طالب آرامش در زندگیتون هستین و اطرافیانتون شما رو دلگیر میکنند. وقتی تموم میشه آدم میگه کاش سالها پیش خونده بودمش.\n",
            "این کتاب رو شدیدا توصیه میکنم خصوصا اگر طالب آرامش در زندگیتون هستین و اطرافیانتون شما رو دلگیر میکنند. وقتی تموم میشه آدم میگه کاش سالها پیش خونده بودمش.\n",
            "کتاب بسیار کاربردی میباشد.\n",
            "کتاب بسیار کاربردی میباشد.\n",
            "خوندن این کتاب برای همه افراد ضروریه. نگاهتون رو به مشکلات خصوصا مشکلات رابطه ای عوض می کنه. باید ها و نبایدها رو زیر سوال می بره. خلاصه بگم اگر  واقعا دنبال آرامش هستین ابن یکی از کتاب هاییه که حتما باید بخونبن\n",
            "خوندن این کتاب برای همه افراد ضروریه. نگاهتون رو به مشکلات خصوصا مشکلات رابطه ای عوض می کنه. باید ها و نبایدها رو زیر سوال می بره. خلاصه بگم اگر  واقعا دنبال آرامش هستین ابن یکی از کتاب هاییه که حتما باید بخونبن\n",
            "کتابی با جزییات دقیق برای اصلاح طرز فکر بویژه با برگردان رامین کریمی که این روزا به چهره معروف روانشناسی کشور تبدیل شده\n",
            "کتابی با جزییات دقیق برای اصلاح طرز فکر بویژه با برگردان رامین کریمی که این روزا به چهره معروف روانشناسی کشور تبدیل شده\n",
            "مریی طاقچه\n",
            "مریی طاقچه\n",
            "امیرعباس هویدا مردی دانشمند با تحصیلات عالیه و انسانی راستین بود که تمام عمر برای پیشرفت و ارتقای میهنش تلاش کرد و در پایان نیز پس از آنکه حاضر نشد از کشور بگریزد به دست مزدوری عاری از انسانیت در دادگاهی فرمایشی به قتل رسید.\n",
            "امیرعباس هویدا مردی دانشمند با تحصیلات عالیه و انسانی راستین بود که تمام عمر برای پیشرفت و ارتقای میهنش تلاش کرد و در پایان نیز پس از آنکه حاضر نشد از کشور بگریزد به دست مزدوری عاری از انسانیت در دادگاهی فرمایشی به قتل رسید.\n",
            "نه الان فقر و چپاول نیست و مملکت گل و بلبل است\n",
            "نه الان فقر و چپاول نیست و مملکت گل و بلبل است\n",
            "هویدا یک فراماسون بود و در دوره صدارت او ایران به عرصه تاخت و تاز لژهای رنگارنگ فراماسونری بدل شد. نام هویدا به دوران\" ثبات\"سلطنت محمدرضا پهلوی گره خورده است و سالهای صدارت او اوج فساد و تباهی و یکه تازی شاه محسوب میشود. در دوران هویداست که پیوندهای نهان و عیان دربار پهلوی با محافل قدرتمند و چپاولگر غرب و صهیونیسم جهانی به مستحکم ترین شکل خود رسید و شاه مغرور در عرصه بین المللی بمثابه یک دیکتاتور بلند پرواز و در منطقه به عنوان استوارترین دوست غرب ظاهر شد.و در کشوری که فقر و تباهی آن را به کام انحطاط کشیده بود متفرعنانه فرا رسیدن دروازه های تمدن بزرگ را صلا میداد. در این دوران هویدا در افکار عمومی مردم ایران به عنوان چهره ای مسلوب الاختیار و نمونه ای کامل از نخست وزیری چاکرمنش و فاقد شخصیت ثبت شد؛نخست وزیری که با حضور او شاه می توانست جلوه فروشی کند خود را به مثابه قدرتی مطلقه ،بر فراز قانون اساسی مشروطه ،نمایش دهد. \n",
            "امیرعباس هویدا از نظر برادرش فریدون هویدا سپر بلای شاه شد که شاه هنگام فرار با آن که امکان بردن او و نعمت الله نصیری و دیگر سران حکومتی را داشت (که 18 آبان 57به دستور شاه دستگیر شده بودند)اما آنان را برای نجات خود رها کرد و این چنین شد که چند ماه بعد و در تاریخ 18 فروردین57 حکم اعدام او اجرا و امیرعباس هویدا تیرباران شد.\n",
            "هویدا یک فراماسون بود و در دوره صدارت او ایران به عرصه تاخت و تاز لژهای رنگارنگ فراماسونری بدل شد. نام هویدا به دوران\" ثبات\"سلطنت محمدرضا پهلوی گره خورده است و سالهای صدارت او اوج فساد و تباهی و یکه تازی شاه محسوب میشود. در دوران هویداست که پیوندهای نهان و عیان دربار پهلوی با محافل قدرتمند و چپاولگر غرب و صهیونیسم جهانی به مستحکم ترین شکل خود رسید و شاه مغرور در عرصه بین المللی بمثابه یک دیکتاتور بلند پرواز و در منطقه به عنوان استوارترین دوست غرب ظاهر شد.و در کشوری که فقر و تباهی آن را به کام انحطاط کشیده بود متفرعنانه فرا رسیدن دروازه های تمدن بزرگ را صلا میداد. در این دوران هویدا در افکار عمومی مردم ایران به عنوان چهره ای مسلوب الاختیار و نمونه ای کامل از نخست وزیری چاکرمنش و فاقد شخصیت ثبت شد؛نخست وزیری که با حضور او شاه می توانست جلوه فروشی کند خود را به مثابه قدرتی مطلقه ،بر فراز قانون اساسی مشروطه ،نمایش دهد. \n",
            "امیرعباس هویدا از نظر برادرش فریدون هویدا سپر بلای شاه شد که شاه هنگام فرار با آن که امکان بردن او و نعمت الله نصیری و دیگر سران حکومتی را داشت (که 18 آبان 57به دستور شاه دستگیر شده بودند)اما آنان را برای نجات خود رها کرد و این چنین شد که چند ماه بعد و در تاریخ 18 فروردین57 حکم اعدام او اجرا و امیرعباس هویدا تیرباران شد.\n",
            "دروغ خدمت هویدا بی سابقه بو\n",
            "دروغ خدمت هویدا بی سابقه بو\n",
            "به نظر خوب میاد\n",
            "به نظر خوب میاد\n",
            "من چاپیشو تا الان و این شماره  خریدم.یک مجله فوق العاااااده\n",
            "من چاپیشو تا الان و این شماره  خریدم.یک مجله فوق العاااااده\n",
            "کتابی جامع با منابعی معتبر است.\n",
            "کتابی جامع با منابعی معتبر است.\n",
            "کتاب خیلی خیلی خوبیهههه\n",
            "کتاب خیلی خیلی خوبیهههه\n",
            "کتاب جالب و سرشار از مطالب مفید و با سندیت هم نوشته شده است.\n",
            "کتاب جالب و سرشار از مطالب مفید و با سندیت هم نوشته شده است.\n",
            "شاهنامه یک کتاب تاریخی به معنای علم تاریخی که اکنون می شناسیم نیست. شاهنامه مجموعه ای منظوم از روایت های تاریخی، داستانی و اسطوره ای است. از همین رو نیامدن نام کورش در شاهنامه به معنای نبود این چهره تاریخی نیست. دوم اینکه اسناد تاریخی و باستان شناسی روشن و دقیقی، فرمانروایی هخامنشیان و کورش بزرگ را تایید می کند. مانند سنگ نگاره بیستون و لوح حقوق بشر منشور کورش بزرگ. در یک سده اخیر، کاوش های باستان شناسی جدید، رشد دانش باستان شناسی و پژوهش های دانشگاهی گسترده، زمینه را برای شناخت بهتر و بیشتر ایران باستان فراهم کرده است. به همین سبب، ما در این دوره زمانی، شاهد شکوفایی انتشار محتوا در این حوزه هستیم.\n",
            "شاهنامه یک کتاب تاریخی به معنای علم تاریخی که اکنون می شناسیم نیست. شاهنامه مجموعه ای منظوم از روایت های تاریخی، داستانی و اسطوره ای است. از همین رو نیامدن نام کورش در شاهنامه به معنای نبود این چهره تاریخی نیست. دوم اینکه اسناد تاریخی و باستان شناسی روشن و دقیقی، فرمانروایی هخامنشیان و کورش بزرگ را تایید می کند. مانند سنگ نگاره بیستون و لوح حقوق بشر منشور کورش بزرگ. در یک سده اخیر، کاوش های باستان شناسی جدید، رشد دانش باستان شناسی و پژوهش های دانشگاهی گسترده، زمینه را برای شناخت بهتر و بیشتر ایران باستان فراهم کرده است. به همین سبب، ما در این دوره زمانی، شاهد شکوفایی انتشار محتوا در این حوزه هستیم.\n",
            "چرا قبل از ورود استعمارگران انگلیسی نامی از کوروش نبوده. حتی در کتاب شاهنامه نیز اسمی از او اورده نشده.\n",
            "چرا تمام منابع از زبان یونانی است؟\n",
            "چرا قبل از ورود استعمارگران انگلیسی نامی از کوروش نبوده. حتی در کتاب شاهنامه نیز اسمی از او اورده نشده.\n",
            "چرا تمام منابع از زبان یونانی است؟\n",
            "کتابی نسبتا مفید هست\n",
            "کتابی نسبتا مفید هست\n",
            "کتاب خوبیه فعلا دارم از خوندنش لذت میبرم و اطلاعات خوبی میگیرم ازش\n",
            "کتاب خوبیه فعلا دارم از خوندنش لذت میبرم و اطلاعات خوبی میگیرم ازش\n",
            "سایه ای از بهرام بیضایی\n",
            "سایه ای از بهرام بیضایی\n",
            "تشکرات فراوان\n",
            "تشکرات فراوان\n",
            "کتاب عالی هست ولی حیف علیرغم زحمت زیاد آقای سمی ترجمه سخت فهمی هست .\n",
            "کتاب عالی هست ولی حیف علیرغم زحمت زیاد آقای سمی ترجمه سخت فهمی هست .\n",
            "کتاب عالی حرف نداره بکت ولی حیف که ترجمه سمی افتضاحه.\n",
            "کتاب عالی حرف نداره بکت ولی حیف که ترجمه سمی افتضاحه.\n",
            "کتاب فوق العاده جالبیه . من که خوشم اومد .\n",
            "کتاب فوق العاده جالبیه . من که خوشم اومد .\n",
            "عالی. ممنون از نشر ثالث و طاقچه\n",
            "عالی. ممنون از نشر ثالث و طاقچه\n",
            "با این شماره عاشق روشن شدم\n",
            "با این شماره عاشق روشن شدم\n",
            "جمع آوری اسناد مهم ساواک در مورد هر شخص و این کتاب هم بهرام آریانا و چه کسی بهتر از او واقعا\n",
            "عاالی بود\n",
            "جمع آوری اسناد مهم ساواک در مورد هر شخص و این کتاب هم بهرام آریانا و چه کسی بهتر از او واقعا\n",
            "عاالی بود\n",
            "گاهی اوقات از کنجکاوی اسناد ساواک رو با چشمام می بلعیدم! گاهی هم به توهم های موجود در متن می خندیدم.... خلاصه اینکه پند اخلاقی: یک طرفه نباید به قاضی رفت\n",
            "\n",
            "اگر کسی گفت \"شنبه\" ای که ساواک برای آریانا تعیین کرده بوده کی بود، ١٠ تا لغت ناب عراقی یادش میدم\n",
            "گاهی اوقات از کنجکاوی اسناد ساواک رو با چشمام می بلعیدم! گاهی هم به توهم های موجود در متن می خندیدم.... خلاصه اینکه پند اخلاقی: یک طرفه نباید به قاضی رفت\n",
            "\n",
            "اگر کسی گفت \"شنبه\" ای که ساواک برای آریانا تعیین کرده بوده کی بود، ١٠ تا لغت ناب عراقی یادش میدم\n",
            "میدونید کدوم ترجمه این کتاب از همه بهتره؟\n",
            "میدونید کدوم ترجمه این کتاب از همه بهتره؟\n",
            "یک اثر واقعا تاثیر گذار.\n",
            "یک اثر واقعا تاثیر گذار.\n",
            "۲۰ درصدی\n",
            "SB98KDP96ZD42A\n",
            "۲۰ درصدی\n",
            "SB98KDP96ZD42A\n",
            "SB98J7WNHN8RGX\n",
            "کد تخفیف ۳۰ درصدی،\n",
            "SB98J7WNHN8RGX\n",
            "کد تخفیف ۳۰ درصدی،\n",
            "من نسخه فیزیکی این کتاب رو با ترجمه مهدی علوی در دوران سربازی خوندم .\n",
            "باری کسانی که به رمان های تاریخی علاقه دارن این کتاب یک نعمت بزرگه . اتفاقات از تقریبا اوایل جمهوری فرانسه شروع میشه شرایط اجتماعی و سیاسی دوران خودش رو به خوبی توصیف میکنه . به زیبایی ناپلئون رو به مخاطب معرفی میکنه و کتاب تا سقوط ناپلئون ادامه داره\n",
            "من نسخه فیزیکی این کتاب رو با ترجمه مهدی علوی در دوران سربازی خوندم .\n",
            "باری کسانی که به رمان های تاریخی علاقه دارن این کتاب یک نعمت بزرگه . اتفاقات از تقریبا اوایل جمهوری فرانسه شروع میشه شرایط اجتماعی و سیاسی دوران خودش رو به خوبی توصیف میکنه . به زیبایی ناپلئون رو به مخاطب معرفی میکنه و کتاب تا سقوط ناپلئون ادامه داره\n",
            "اخه هنوز نتونستم کتابو بخونم😔😔😔SB98MPXVP3CBTZ\n",
            "اخه هنوز نتونستم کتابو بخونمSB98MPXVP3CBTZ\n",
            "من این کتاب رو از نشر افق گرفتم ولی متاسفانه هنوز فرصت نکردم بخونم. تاریخ فرانسه رو دوست دارم کتاب ماری آنتوانت رو خوندم باید بگم کتاب قشنگی بود هم کمی احساسی بود و هم اطلاعات تاریخی آدم رو بالا می بره.\n",
            "من این کتاب رو از نشر افق گرفتم ولی متاسفانه هنوز فرصت نکردم بخونم. تاریخ فرانسه رو دوست دارم کتاب ماری آنتوانت رو خوندم باید بگم کتاب قشنگی بود هم کمی احساسی بود و هم اطلاعات تاریخی آدم رو بالا می بره.\n",
            "من نسخه چاپی رو خوندم . راستش داستان رو دوست نداشتم و آخرا واقعا داشت از دزیره بدم میومد\n",
            "من نسخه چاپی رو خوندم . راستش داستان رو دوست نداشتم و آخرا واقعا داشت از دزیره بدم میومد\n",
            "فکر نمی‌کنم هیچ وقت می‌رفتم سراغ تاریخ فرانسهرولی این کتاب با داستان جدابش بخشی از تاریخ فرانسه رو هم به خواننده یاد می‌ده. واقعا ارزش خوندن چندین باره رو داره\n",
            "فکر نمی‌کنم هیچ وقت می‌رفتم سراغ تاریخ فرانسهرولی این کتاب با داستان جدابش بخشی از تاریخ فرانسه رو هم به خواننده یاد می‌ده. واقعا ارزش خوندن چندین باره رو داره\n",
            "در عین داستانی و سرگرم کنندگی،اطلاعات تاریخی جالبی هم در اختیار میذاره\n",
            "در عین داستانی و سرگرم کنندگی،اطلاعات تاریخی جالبی هم در اختیار میذاره\n",
            "کتاب زیبایی البته بعضی جاها از دست دزیره خیلی حرص میخوری و اینکه زیاد از جنگ تعریف میکنه\n",
            "کتاب زیبایی البته بعضی جاها از دست دزیره خیلی حرص میخوری و اینکه زیاد از جنگ تعریف میکنه\n",
            "واقعا کتاب خوبی بود لذت بردم\n",
            "واقعا کتاب خوبی بود لذت بردم\n",
            "توصیف جنگ زیاد داره.\n",
            "به نظرم فیلمش نتونسته ابهت ناپلئون رو خوب به چشم بیاره.\n",
            "توصیف جنگ زیاد داره.\n",
            "به نظرم فیلمش نتونسته ابهت ناپلئون رو خوب به چشم بیاره.\n",
            "عالی بود🍃🍃🦋🦋🦋🌹🌹🌻🍃\n",
            "عالی بود\n",
            "عاااالی بود\n",
            "عاااالی بود\n",
            "کتاب بسیار خوبی بود و به نظرم دزیره تا اونجا که میتونست سعی کرد که عادلانه و بی طرف تاریخ رو روایت کنه؛ تنها چیزی که موقع خوندن کتاب منو ازار میداد، وطن فروشی ژان باتیست بود که بخاطر پادشاه شدن و پیشی گرفتن از ناپلئون به کشور خودش خیانت کرد، به نظرم ناپلئون با اینکه دیکتاتور بود و بیش از حد طمع قدرت داشت ولی به مراتب بهتر از ژان باتیست بود\n",
            "کتاب بسیار خوبی بود و به نظرم دزیره تا اونجا که میتونست سعی کرد که عادلانه و بی طرف تاریخ رو روایت کنه؛ تنها چیزی که موقع خوندن کتاب منو ازار میداد، وطن فروشی ژان باتیست بود که بخاطر پادشاه شدن و پیشی گرفتن از ناپلئون به کشور خودش خیانت کرد، به نظرم ناپلئون با اینکه دیکتاتور بود و بیش از حد طمع قدرت داشت ولی به مراتب بهتر از ژان باتیست بود\n",
            "من نسخه چاپیش رو خوندم با این که خیلی سانسور داشت اما عالی بود\n",
            "من نسخه چاپیش رو خوندم با این که خیلی سانسور داشت اما عالی بود\n",
            "کتابی که دلت نمیخواد بذاریش زمین...معرکه است😍\n",
            "کتابی که دلت نمیخواد بذاریش زمین...معرکه است\n",
            "صد بار هم این کتابو بخونی بازم کمه خیلیییییییییی زیباست😘😘😘😘😘😘\n",
            "صد بار هم این کتابو بخونی بازم کمه خیلیییییییییی زیباست\n",
            "چرا اینقدر گرونه؟؟\n",
            "چرا اینقدر گرونه؟؟\n",
            "😭😭😭وقتی این کتابو تموم کردم به شدت غمگین شدممم جوری ک دلم میخواست زار زار گریه کنم.....دوستان اگر حسب حالی به این صورت وجود داره یا کتاب تاریخی که ادغام شده با عشق.هست معرفی کنید به شدتت مشتاقم ک برم سراغش\n",
            "وقتی این کتابو تموم کردم به شدت غمگین شدممم جوری ک دلم میخواست زار زار گریه کنم.....دوستان اگر حسب حالی به این صورت وجود داره یا کتاب تاریخی که ادغام شده با عشق.هست معرفی کنید به شدتت مشتاقم ک برم سراغش\n",
            "به نظر من کتاب بسیار کم نظیری است .با اینکه چند سال قبل این کتاب را خوانده بودم، ولی وقتی در طاقچه دیدم خیلی خوشحال شدم و از خواندنش لذت فراوان بردم .\n",
            "به نظر من کتاب بسیار کم نظیری است .با اینکه چند سال قبل این کتاب را خوانده بودم، ولی وقتی در طاقچه دیدم خیلی خوشحال شدم و از خواندنش لذت فراوان بردم .\n",
            "چی بگم از این کتاب آخه😍\n",
            "اگه به ادبیات کلاسیک وزندگی نامه ها علاقه داری باید نسخه چاپیش روبخری ک همیشه توکتابخونت باشه ،البته ب مترجمش هم دقت کن هرچقدر قدیمی ترباشه بهتر کمترحذفیات داره !\n",
            "سه سال پیش خوندمش و باهاش زندگی کردم این کتاب ازروی دفترخاطرات عشق اول ناپلئون نوشته شده از 14سالگی تازمانی ک ملکه سوئد میشه و قلم نویسنده هم با گذشت زمان تغییر میکنه انگار ک شماهم بااین کتاب بزرگ میشید\n",
            "من نسخه چاپیش رو خوندم ک 700 صفحه بود ولی انقدر جذاب بودک نمی تونستم بزارم زمین وچندروزه تمومش کردم\n",
            "فقط چندتا توصیه اگه چیزی درمورد تاریخ فرانسه نمی دونید یه سرچ کوچیک درموردش کنیدچون در غیراین صورت براتون فقط یه عاشقانه کلاسیک هستش درحالی ک اوضاع اقتصادی و سیاسی اون دوران روهم به تصویر کشیده\n",
            "فیلمش رو هم نبینید ک اصلا با کتابش قابل مقایسه نیست\n",
            "یک ذره هم نتونسته به خوبی دزیره عاشق رو به تصویربکشه چون خیلی هم بازیگراش بدانتخاب شدن و هم اینکه خیلی از قسمت هایی ک تو کتاب هست توفیلم نیورده .\n",
            "خلاصه اینکه بخوانید و لذت ببرید😊👌🌸\n",
            "و در آخر یک سوال دارم ازکسایی ک این کتاب رو خوندند در انتهانوشته شده ک ناپلئون خاطراتش رودرتبعیدمی نوشته و درنت هم جایی خوندم ک این کتاب ظاهرا چاپ شده کسی اسمش رو میدونه؟\n",
            "چی بگم از این کتاب آخه\n",
            "اگه به ادبیات کلاسیک وزندگی نامه ها علاقه داری باید نسخه چاپیش روبخری ک همیشه توکتابخونت باشه ،البته ب مترجمش هم دقت کن هرچقدر قدیمی ترباشه بهتر کمترحذفیات داره !\n",
            "سه سال پیش خوندمش و باهاش زندگی کردم این کتاب ازروی دفترخاطرات عشق اول ناپلئون نوشته شده از 14سالگی تازمانی ک ملکه سوئد میشه و قلم نویسنده هم با گذشت زمان تغییر میکنه انگار ک شماهم بااین کتاب بزرگ میشید\n",
            "من نسخه چاپیش رو خوندم ک 700 صفحه بود ولی انقدر جذاب بودک نمی تونستم بزارم زمین وچندروزه تمومش کردم\n",
            "فقط چندتا توصیه اگه چیزی درمورد تاریخ فرانسه نمی دونید یه سرچ کوچیک درموردش کنیدچون در غیراین صورت براتون فقط یه عاشقانه کلاسیک هستش درحالی ک اوضاع اقتصادی و سیاسی اون دوران روهم به تصویر کشیده\n",
            "فیلمش رو هم نبینید ک اصلا با کتابش قابل مقایسه نیست\n",
            "یک ذره هم نتونسته به خوبی دزیره عاشق رو به تصویربکشه چون خیلی هم بازیگراش بدانتخاب شدن و هم اینکه خیلی از قسمت هایی ک تو کتاب هست توفیلم نیورده .\n",
            "خلاصه اینکه بخوانید و لذت ببرید\n",
            "و در آخر یک سوال دارم ازکسایی ک این کتاب رو خوندند در انتهانوشته شده ک ناپلئون خاطراتش رودرتبعیدمی نوشته و درنت هم جایی خوندم ک این کتاب ظاهرا چاپ شده کسی اسمش رو میدونه؟\n",
            "کتاب بسیار خوب و جذابی است، کتاب در مورد زندگی دزیره نامزد ناپلئون بناپارت است که هرگز با او ازدواج نمیکند و در آینده ملکه سوئد میشود، ولی اطلاعات خوبی راجع به ناپلئون و چگونگی به قدرت رسیدنش و شکست و تبعیدش میدهد. و نکته مثبت دیگرش این است که بسیار خوب و روان نوشته و ترجمه شده.\n",
            "کتاب بسیار خوب و جذابی است، کتاب در مورد زندگی دزیره نامزد ناپلئون بناپارت است که هرگز با او ازدواج نمیکند و در آینده ملکه سوئد میشود، ولی اطلاعات خوبی راجع به ناپلئون و چگونگی به قدرت رسیدنش و شکست و تبعیدش میدهد. و نکته مثبت دیگرش این است که بسیار خوب و روان نوشته و ترجمه شده.\n",
            "واقعا کتاب محشری بود ،خیلی خیلی قشنگ\n",
            "واقعا کتاب محشری بود ،خیلی خیلی قشنگ\n",
            "فوقالعاده ارزش خرید داره اگه امکانشو دارید و دنبال کتاب خوبید برا خرید بخرید اینو نگران نباشید\n",
            "فوقالعاده ارزش خرید داره اگه امکانشو دارید و دنبال کتاب خوبید برا خرید بخرید اینو نگران نباشید\n",
            "این کتاب چاپ چندم هست ؟ ، کسی میدونه چاپ اول اصلا گیر میاد یا نه ، کدوم ترجمه سانسور کمتری داره\n",
            "این کتاب چاپ چندم هست ؟ ، کسی میدونه چاپ اول اصلا گیر میاد یا نه ، کدوم ترجمه سانسور کمتری داره\n",
            "یکی از زیباترین کتابهایی که تا الان خوندم. واقعا عالی بود. عجب زندگی پر فراز و نشیبی داشت دزیره کلاری....\n",
            "یکی از زیباترین کتابهایی که تا الان خوندم. واقعا عالی بود. عجب زندگی پر فراز و نشیبی داشت دزیره کلاری....\n",
            "خوش به حالش چه زندگی پر ماجرایی داشته\n",
            "خوش به حالش چه زندگی پر ماجرایی داشته\n",
            "بسیار عالی...فوق العادست\n",
            "بسیار عالی...فوق العادست\n",
            "کتاب قشنگیه.شاید وقتی توی توضیحاتش خونده میشه که موضوعش تو حال و هوای جنگه یه ذره دلسرد کننده باشه اما اونقدر خوب با کلمات بازی شده که جای هیچ ایرادی نیست.من نسخه چاپیشو خوندم ب نظرم اگه از مشکل ترجمه تو انتشاراتی های مختلف بگذریم،کار نویسندش عالیههههه.\n",
            "کتاب قشنگیه.شاید وقتی توی توضیحاتش خونده میشه که موضوعش تو حال و هوای جنگه یه ذره دلسرد کننده باشه اما اونقدر خوب با کلمات بازی شده که جای هیچ ایرادی نیست.من نسخه چاپیشو خوندم ب نظرم اگه از مشکل ترجمه تو انتشاراتی های مختلف بگذریم،کار نویسندش عالیههههه.\n",
            "تصویر پردازی خیلی خوبی داشت. با اینکه ۵_۶ سال پیش خوندم ولی هنوز بعضی قسمت هاشو یادمه. کتابیه که حتما باید خوند.\n",
            "تصویر پردازی خیلی خوبی داشت. با اینکه ۵_۶ سال پیش خوندم ولی هنوز بعضی قسمت هاشو یادمه. کتابیه که حتما باید خوند.\n",
            "بهترین ترجمه ی این کتاب کدومه؟؟؟\n",
            "بهترین ترجمه ی این کتاب کدومه؟؟؟\n",
            "محشره این رمان...توصیه میکنم حتما بخونید\n",
            "محشره این رمان...توصیه میکنم حتما بخونید\n",
            "من نسخه چاپی رو با۵۰درصد تخفیف گرفتم۲۵تومن و بنظرم ارزشش خریدن داشت بسیار جالب هست توصیه میکنم چاپیشو بگیرد هم حس بهتری داره برا خوندن و هم میتونید به عزیزانتون بدید اونام ازین لذت بی نصیب نمونن\n",
            "من نسخه چاپی رو با۵۰درصد تخفیف گرفتم۲۵تومن و بنظرم ارزشش خریدن داشت بسیار جالب هست توصیه میکنم چاپیشو بگیرد هم حس بهتری داره برا خوندن و هم میتونید به عزیزانتون بدید اونام ازین لذت بی نصیب نمونن\n",
            "عالییییییی است\n",
            "عالییییییی است\n",
            "من نسخه چاپی رو با یک ترجمه دیگه خوندم. این ٥ ستاره رو هم به نویسنده می دم. جزو بهترین رمانهایی که در عمرم خوندم. عاشق ژان باتیست برنادوتم.\n",
            "من نسخه چاپی رو با یک ترجمه دیگه خوندم. این ٥ ستاره رو هم به نویسنده می دم. جزو بهترین رمانهایی که در عمرم خوندم. عاشق ژان باتیست برنادوتم.\n",
            "سلام نسخه چاپی چند جلد داره؟\n",
            "سلام نسخه چاپی چند جلد داره؟\n",
            "نسخه ی چاپیشو تازه شروه کردم کتاب قشنگیه\n",
            "نسخه ی چاپیشو تازه شروه کردم کتاب قشنگیه\n",
            "من با ترجمه ذبیح الله منصوری موندم به نظرم بهترین رمان تاریخ این کتاب هستش بدون شک\n",
            "من با ترجمه ذبیح الله منصوری موندم به نظرم بهترین رمان تاریخ این کتاب هستش بدون شک\n",
            "در خوب بودن کتاب شکی نیست.البته توجه هم داشته باشید که ''رمان'' لزوما براساس واقعیت نوشته نشده.این کتاب برگرفته از رویدادهای فرانسه و انقلاب فرانسه ست.اما درنوع خودش یک داستانه و هرداستانی میتونه مبالغه آمیز،تحریف شده یا به دور از واقعیت باشه.\n",
            "حتی کتاب های معتبر تاریخی هم بسیاری وقت ها چیزهایی از تاریخ رو در تاریکی قرار دادن.تکلیف این کتاب هم روشنه.اگر کمی قبل ار خوندنش سرچی در زمینه انقلاب فرانسه و اسامی افراد کتاب داشته باشید سردرگم نمی شید.\n",
            "بعدازخوندن هم فکر نکنید تاریخ دان شدید.نوشته های این کتاب نمیتونن منبع پژوهشی معتبری باشن：)))\n",
            "در خوب بودن کتاب شکی نیست.البته توجه هم داشته باشید که ''رمان'' لزوما براساس واقعیت نوشته نشده.این کتاب برگرفته از رویدادهای فرانسه و انقلاب فرانسه ست.اما درنوع خودش یک داستانه و هرداستانی میتونه مبالغه آمیز،تحریف شده یا به دور از واقعیت باشه.\n",
            "حتی کتاب های معتبر تاریخی هم بسیاری وقت ها چیزهایی از تاریخ رو در تاریکی قرار دادن.تکلیف این کتاب هم روشنه.اگر کمی قبل ار خوندنش سرچی در زمینه انقلاب فرانسه و اسامی افراد کتاب داشته باشید سردرگم نمی شید.\n",
            "بعدازخوندن هم فکر نکنید تاریخ دان شدید.نوشته های این کتاب نمیتونن منبع پژوهشی معتبری باشن)))\n",
            "فوق العاده بود.\n",
            "فوق العاده بود.\n",
            "صدتاستاره هم براش کمه من عااااااشق این کتاب شدم😍\n",
            "صدتاستاره هم براش کمه من عااااااشق این کتاب شدم\n",
            "ارزش خوندن داره\n",
            "ارزش خوندن داره\n",
            "یکی از بهترین کتابهایی بود که خوندم . دزیره در خلال توصیف عشق ناپلئون به او که البته هیچوقت منجر به ازدواج آنها نشد ، شرایط انقلاب فرانسه و چگونگی به قدرت رسیدن ناپلئون و برکناری او و بسیار مسائل دیگر رو که برای دانستنشون باید به کتابهای تاریخی رجوع کرد شرح داده و البته شاید تا این اندازه به درون زندگی ناپلئون در کتب تاریخی اشاره نشده باشه . خواندن این کتاب جذاب توصیه میشه البته اواسط کتاب ممکنه کمی از جذابیت آن کم بشه اما یقینا آنقدر کشش داره که تا آخرش پیش برید .\n",
            "یکی از بهترین کتابهایی بود که خوندم . دزیره در خلال توصیف عشق ناپلئون به او که البته هیچوقت منجر به ازدواج آنها نشد ، شرایط انقلاب فرانسه و چگونگی به قدرت رسیدن ناپلئون و برکناری او و بسیار مسائل دیگر رو که برای دانستنشون باید به کتابهای تاریخی رجوع کرد شرح داده و البته شاید تا این اندازه به درون زندگی ناپلئون در کتب تاریخی اشاره نشده باشه . خواندن این کتاب جذاب توصیه میشه البته اواسط کتاب ممکنه کمی از جذابیت آن کم بشه اما یقینا آنقدر کشش داره که تا آخرش پیش برید .\n",
            "خیلی کتاب خوبیه حتما بخونیدش\n",
            "خیلی کتاب خوبیه حتما بخونیدش\n",
            "میخاستم بگیرمش قیمتش ۷۵ تومن بود ولی مال یه انتشارات دیگه ایی بود\n",
            "میخاستم بگیرمش قیمتش ۷۵ تومن بود ولی مال یه انتشارات دیگه ایی بود\n",
            "واقعا قشنگ و زیبا بود من که وقتی کتاب تمام شد تا چند روز حالم گرفته بود \n",
            "البته همه ترجمه ها خوب نیستن و ارزش اثر رو پایین میارن مثل نشر افق\n",
            "واقعا قشنگ و زیبا بود من که وقتی کتاب تمام شد تا چند روز حالم گرفته بود \n",
            "البته همه ترجمه ها خوب نیستن و ارزش اثر رو پایین میارن مثل نشر افق\n",
            "حال و هوای فرانسه قرن هجدهم رو خیلی خوب منتقل میکنه .شخصیت دزیره واقعا بینظیره!دختری محکم و قوی که هیچ وقت اصالت خودشو فراموش نکرد.. من فقط کمی از این نسخه و ترجمه رو خوندم ولی به نظرم ترجمه آقای ایرج پزشکزاد جذاب تره..\n",
            "حال و هوای فرانسه قرن هجدهم رو خیلی خوب منتقل میکنه .شخصیت دزیره واقعا بینظیره!دختری محکم و قوی که هیچ وقت اصالت خودشو فراموش نکرد.. من فقط کمی از این نسخه و ترجمه رو خوندم ولی به نظرم ترجمه آقای ایرج پزشکزاد جذاب تره..\n",
            "بد نبود .\n",
            "بد نبود .\n",
            "ترجمش چیزی بیشتر از افتضاح بود 👎\n",
            "ترجمش چیزی بیشتر از افتضاح بود \n",
            "واقعا کتابه عالی بود....دلنشین و گویا و روان\n",
            "واقعا کتابه عالی بود....دلنشین و گویا و روان\n",
            "این کتاب چقدر زیباست .....\n",
            "این کتاب چقدر زیباست .....\n",
            "من عاشق این کتابم البته برام هنوز درکش سخته مخصوصا جاهای تاریخیش اما خیلی فوق العاده است حتما بخونین\n",
            "من عاشق این کتابم البته برام هنوز درکش سخته مخصوصا جاهای تاریخیش اما خیلی فوق العاده است حتما بخونین\n",
            "دزیره واقعا عالیه...\n",
            "من نسخه چاپیشو خوندم...\n",
            "واقعا دوسش دارم...\n",
            "....\n",
            "دزیره واقعا عالیه...\n",
            "من نسخه چاپیشو خوندم...\n",
            "واقعا دوسش دارم...\n",
            "....\n",
            "محشره...\n",
            "من امروز به عنوان یکی از کاربران \"طاقچه\" عزیز،خواستم از دوستان و کاربرانی که نقد های حرفه ای ،به اشتراک میگذارن ،صمیمانه تشکر کنم.بترتیب از :آقا سالار-آقا ی روح الله-آقا ی حجت-آقای ابوذر-فاطمه خانوم-هستی خانوم و کاربران دیگه ای با نام اعداد هستن و خودتون می تونید نقدهاشونو بخونید و لذت ببرید.خیلی از عزیزان احتمالا از قلم افتادن چون در حال حاضر حضور ذهن ندارم.با تشکر و سپاس از مدیریت و پرسنل محترم \"طاقچه\"\n",
            "محشره...\n",
            "من امروز به عنوان یکی از کاربران \"طاقچه\" عزیز،خواستم از دوستان و کاربرانی که نقد های حرفه ای ،به اشتراک میگذارن ،صمیمانه تشکر کنم.بترتیب از :آقا سالار-آقا ی روح الله-آقا ی حجت-آقای ابوذر-فاطمه خانوم-هستی خانوم و کاربران دیگه ای با نام اعداد هستن و خودتون می تونید نقدهاشونو بخونید و لذت ببرید.خیلی از عزیزان احتمالا از قلم افتادن چون در حال حاضر حضور ذهن ندارم.با تشکر و سپاس از مدیریت و پرسنل محترم \"طاقچه\"\n",
            "یکی از بهترین رمان هایی که خوندم\n",
            " از اونجایی که بر اساس واقعیته و تاریخی هم هست عاشقش شدم \n",
            "روانی و گیرایی ترجمه اثر هم از هر حیث خیلی خوب بود\n",
            "یکی از بهترین رمان هایی که خوندم\n",
            " از اونجایی که بر اساس واقعیته و تاریخی هم هست عاشقش شدم \n",
            "روانی و گیرایی ترجمه اثر هم از هر حیث خیلی خوب بود\n",
            "کتاب جذابیه. بعد تاریخیشم خوبه آدم تاریخش خوب میشه😀\n",
            "کتاب جذابیه. بعد تاریخیشم خوبه آدم تاریخش خوب میشه\n",
            "بهترین رمانی که توزندگیم خوندم فوق العاده 👌👌👌👌رمان خوناازدستش ندین\n",
            "بهترین رمانی که توزندگیم خوندم فوق العاده رمان خوناازدستش ندین\n",
            "من  این کتاب رو چند روز پیش شروع کردم  به نظرم یکی از بهترین کتابای تاریخیه که تلفیقی از رمان  و تاریخ هستش\n",
            "من  این کتاب رو چند روز پیش شروع کردم  به نظرم یکی از بهترین کتابای تاریخیه که تلفیقی از رمان  و تاریخ هستش\n",
            "بعضی از کتابا  رو بدون اینکه دوباره بخونی وقتی اسمشون رو میشنوی تمام متن کتاب مثل فیلم توی ذهنت مرور میشه.  دزیره برای من از همین نوعه\n",
            "بعضی از کتابا  رو بدون اینکه دوباره بخونی وقتی اسمشون رو میشنوی تمام متن کتاب مثل فیلم توی ذهنت مرور میشه.  دزیره برای من از همین نوعه\n",
            "اولین  و یکی از زیباترین رمان هایی که خوندم\n",
            "اولین  و یکی از زیباترین رمان هایی که خوندم\n",
            "این کتاب یکی از بهترین کتابهاییست که تاریخ و داستان رو در یک قالب به خواننده میدهد. ماجرای عشقی و فراز و نشیب های زندگی دزیره من رو درگیر خودش کرد و بسیار از متن کتاب لذت بردم. \n",
            "این کتاب یکی از بهترین کتابهاییست که تاریخ و داستان رو در یک قالب به خواننده میدهد. ماجرای عشقی و فراز و نشیب های زندگی دزیره من رو درگیر خودش کرد و بسیار از متن کتاب لذت بردم. \n",
            "مال نشر افق بهتره .اون ترجمه رو بخونیم\n",
            "مال نشر افق بهتره .اون ترجمه رو بخونیم\n",
            "عالی و بی نظیر بود نه کتاب بلکه خود دزیره تصور کنید یه زن دو مرد تو زندگیش قرار گرفتن که هر دو به سلطنت رسیدن!!\n",
            "این فقط تو قصه ها ممکنه اما دزیره واقعی بود.\n",
            "بخونید و از اون روی سکه ناپلئون بناپارت آگاه بشید.\n",
            "فوق العاده بود من خیلی لذت بردم.\n",
            "عالی و بی نظیر بود نه کتاب بلکه خود دزیره تصور کنید یه زن دو مرد تو زندگیش قرار گرفتن که هر دو به سلطنت رسیدن!!\n",
            "این فقط تو قصه ها ممکنه اما دزیره واقعی بود.\n",
            "بخونید و از اون روی سکه ناپلئون بناپارت آگاه بشید.\n",
            "فوق العاده بود من خیلی لذت بردم.\n",
            "من نسخه چاپی رو دارم. واقعا عالی و هیجان انگیزه. بخصوص اینکه داری از قسمتی از تاریخ مطلع میشی. بدترین قسمتش رها کردن همسرش برای چندین ساله بخاطر خانوادش به سوئد نمیره و همسر و فرزندش رو رها میکنه!!! دلم میخاست جای اون گریه میکردم\n",
            "من نسخه چاپی رو دارم. واقعا عالی و هیجان انگیزه. بخصوص اینکه داری از قسمتی از تاریخ مطلع میشی. بدترین قسمتش رها کردن همسرش برای چندین ساله بخاطر خانوادش به سوئد نمیره و همسر و فرزندش رو رها میکنه!!! دلم میخاست جای اون گریه میکردم\n",
            "سلام. این کتاب یک شاهکار بی نظیر ادبی و تاریخی ست . بخونید حتما\n",
            "سلام. این کتاب یک شاهکار بی نظیر ادبی و تاریخی ست . بخونید حتما\n",
            "بسیار زیبا بود.پیشنهاد میکنم بخونید\n",
            "بسیار زیبا بود.پیشنهاد میکنم بخونید\n",
            "بی نهایت زیبایک شاهکاربی نظیرادبی ترجمه اش هم خیلی خوبه ازدستش ندین دوستان😊\n",
            "بی نهایت زیبایک شاهکاربی نظیرادبی ترجمه اش هم خیلی خوبه ازدستش ندین دوستان\n",
            "کتاب خوبی بود .جذابیت خاصی داشت ولی یه اشکالی که داشت این بود ک بعضی قسمتاش بیش از اندازه به مسایل سیاسی و نظامی پر و بال داده بود و از اصل داستان دور میشد.این قسمتا یه خورده کسل کننده بود.ولی در کل خوندنش ارزش داره :)\n",
            "کتاب خوبی بود .جذابیت خاصی داشت ولی یه اشکالی که داشت این بود ک بعضی قسمتاش بیش از اندازه به مسایل سیاسی و نظامی پر و بال داده بود و از اصل داستان دور میشد.این قسمتا یه خورده کسل کننده بود.ولی در کل خوندنش ارزش داره :)\n",
            "این کتاب محشره فوق العاده است حتمابخونید ارزش خریدن وداره😍😍😍😍😍\n",
            "این کتاب محشره فوق العاده است حتمابخونید ارزش خریدن وداره\n",
            "کتاب دزیره تو کتابراه رایگانه\n",
            "کتاب دزیره تو کتابراه رایگانه\n",
            "هم کتاب و هم فیلمش عالیه...👍🌼🍀ممنون طاقچه\n",
            "هم کتاب و هم فیلمش عالیه...ممنون طاقچه\n",
            "کتاب فوق العاده ایه کسی تو این سبک می تونه کتابی معرفی کنه؟؟؟\n",
            "کتاب فوق العاده ایه کسی تو این سبک می تونه کتابی معرفی کنه؟؟؟\n",
            "این کتاب عالیه . مخصوصا این که واقعیه . نسخه ی چاپی اش 2 جلد هستش که حدود 900 تا 1000 صفحه است ولی ارزش خوندن رو داره و یا حتی بیش تر. اینکه ناپلئون با خیره سری این بلا ها رو سره خودش میاره اموزنده است و این که دزیره پای عشقش یعنی برنادوت میمیونه حتی با اینکه در کشور های جدا  زندگی میکردن هم تحسین بر انگیزه .\n",
            "این کتاب عالیه . مخصوصا این که واقعیه . نسخه ی چاپی اش 2 جلد هستش که حدود 900 تا 1000 صفحه است ولی ارزش خوندن رو داره و یا حتی بیش تر. اینکه ناپلئون با خیره سری این بلا ها رو سره خودش میاره اموزنده است و این که دزیره پای عشقش یعنی برنادوت میمیونه حتی با اینکه در کشور های جدا  زندگی میکردن هم تحسین بر انگیزه .\n",
            "کتاب عالیه. اینکه وقایع تاریخی رو از یه زاویه ی دیگه و از بعد عاطفی اونها ببینی واقعا جذابه. و اینکه ناپلئون بناپارت با اون درجه از قدرت و ثروت در جوانی توی چه فقر وحشتناکی دست و پا میزده و با تلاش خیلی زیاد به همچون جایگاهی رسیده حیرت انگیزه. از طرف دیگه اینکه زن ها با اینکه هرگز توی جنگ ها و لشکرکشی ها حضور نداشتن ولی در پشت صحنه به قدری نقش های پررنگی ایفا کردن که چه بسا سرنوشت کشورهارو بیش از جنگ تونستن تغییر بدن.\n",
            "کتاب عالیه. اینکه وقایع تاریخی رو از یه زاویه ی دیگه و از بعد عاطفی اونها ببینی واقعا جذابه. و اینکه ناپلئون بناپارت با اون درجه از قدرت و ثروت در جوانی توی چه فقر وحشتناکی دست و پا میزده و با تلاش خیلی زیاد به همچون جایگاهی رسیده حیرت انگیزه. از طرف دیگه اینکه زن ها با اینکه هرگز توی جنگ ها و لشکرکشی ها حضور نداشتن ولی در پشت صحنه به قدری نقش های پررنگی ایفا کردن که چه بسا سرنوشت کشورهارو بیش از جنگ تونستن تغییر بدن.\n",
            "کتاب خوب و تاثیر گذاری بود.\n",
            "ممنون.\n",
            "کتاب خوب و تاثیر گذاری بود.\n",
            "ممنون.\n",
            "دوستان در مورد قیمت کتابا بی انصافی نکنید دیگه.. \n",
            "قیمت ها واقعا معقول و مناسب ه.. \n",
            "میتونین برای اطمینان یک سر به برنامه های مشابه بزنین یا اینکه اول  از حجم کتاب ها و قیمت نسخه های چاپیشون مطلع بشید.. با تشکر :)\n",
            "دوستان در مورد قیمت کتابا بی انصافی نکنید دیگه.. \n",
            "قیمت ها واقعا معقول و مناسب ه.. \n",
            "میتونین برای اطمینان یک سر به برنامه های مشابه بزنین یا اینکه اول  از حجم کتاب ها و قیمت نسخه های چاپیشون مطلع بشید.. با تشکر :)\n",
            "قابل توجه برخی دوستان که میگن قیمت کتاب گرونه، این کتاب بیشتر از ٧٠٠ صفحه است و در اصل دو جلده و قیمت نسخه چاپیش ٣٠-٤٠ هزار تومنه، تو همین جا کتابای ٢٠٠-٣٠٠ صفحه ای هست که ٤٠٠٠-٥٠٠٠ تومن قیمتشونه و با توجه به این موضوع به نظرم قیمت کتاب معقول و منصفانه است، در ضمن کتابش فوق العادست، ترجمه خیلی خوبی هم داره، من که کلش رو ٣-٤ روزه تموم کردم، نخوندین از دستش ندین\n",
            "قابل توجه برخی دوستان که میگن قیمت کتاب گرونه، این کتاب بیشتر از ٧٠٠ صفحه است و در اصل دو جلده و قیمت نسخه چاپیش ٣٠-٤٠ هزار تومنه، تو همین جا کتابای ٢٠٠-٣٠٠ صفحه ای هست که ٤٠٠٠-٥٠٠٠ تومن قیمتشونه و با توجه به این موضوع به نظرم قیمت کتاب معقول و منصفانه است، در ضمن کتابش فوق العادست، ترجمه خیلی خوبی هم داره، من که کلش رو ٣-٤ روزه تموم کردم، نخوندین از دستش ندین\n",
            "من این کتاب رو خوندم فیلمش رو هم دیدم عالیه.میخواستم ی بار دیگه هم بخونم ولی خیلی گرونه ترجیح میدم به همون یکباری که خوندم اکتفا کنم\n",
            "من این کتاب رو خوندم فیلمش رو هم دیدم عالیه.میخواستم ی بار دیگه هم بخونم ولی خیلی گرونه ترجیح میدم به همون یکباری که خوندم اکتفا کنم\n",
            "خیلی گرونه ترجیح میدم نسخه اصلی بخرم\n",
            "خیلی گرونه ترجیح میدم نسخه اصلی بخرم\n",
            "یکم گرون نیست؟\n",
            "یکم گرون نیست؟\n",
            "من این کتاب رو خوندم البته با ترجمه پزشکزاد که فوق العاده بود\n",
            "من این کتاب رو خوندم البته با ترجمه پزشکزاد که فوق العاده بود\n",
            "عکس روی جلد باید خانم جین سیمونز باشه.\n",
            "عکس روی جلد باید خانم جین سیمونز باشه.\n",
            "دوستان کسی اطلاع داره که اسم خانومی که تصویر جلد این رمان هستش چیه؟\n",
            "دوستان کسی اطلاع داره که اسم خانومی که تصویر جلد این رمان هستش چیه؟\n",
            "من کتاب دزیره رودارم تا الان سه بار خوندمش.بی نظیره واینکه داستانش واقعیه بیشتر ادمو مجذوب میکنه.حتما بخونید.\n",
            "من کتاب دزیره رودارم تا الان سه بار خوندمش.بی نظیره واینکه داستانش واقعیه بیشتر ادمو مجذوب میکنه.حتما بخونید.\n",
            "بهترین کتابی که خوندم\n",
            "بهترین کتابی که خوندم\n",
            "عالی و فوق العاده 😍😍😍\n",
            "عالی و فوق العاده \n",
            "یکی از بهترررین کتابایی ک خوندم\n",
            "مرسی از مترجم کارش عالی بود\n",
            "\"هیچ چیز واقعی تر از هیچ نیست\"\n",
            "یکی از بهترررین کتابایی ک خوندم\n",
            "مرسی از مترجم کارش عالی بود\n",
            "\"هیچ چیز واقعی تر از هیچ نیست\"\n",
            "مالون می میرد عبارت است از یک گفتگوی درونیِ جستجوگرانه در اعماق روح و رفتار ، در واپسین لحظات زندگی با یک نیمچه آگاهی از زمان مرگ ... راوی تا حدودی غیرقابل اعتماد است ، شاید به دلیل ضعف در پذیرش و هضم موقعیت اش در زندگی. پوچ گراییِ این اثر که تا حدودی به اَبزورد می زند جز ملال و بیهودگی چیزی به خواننده ساطع نمی کند. همان ملالی که خودِ راوی هم بازگو می کند و از آن دم می زند و تاحدودی تسلیمش میشود. جهان راوی ، جهانی ست بی رنگ و بی هدف که نه دیگر شادی برایش اهمیت دارد و نه خشم. تنها به صرف گذران لحظاتش تصمیم به انجام کارهایی می گیرد تا با خودِ نشناخته اش کلنجار برود.\n",
            "مالون می میرد عبارت است از یک گفتگوی درونیِ جستجوگرانه در اعماق روح و رفتار ، در واپسین لحظات زندگی با یک نیمچه آگاهی از زمان مرگ ... راوی تا حدودی غیرقابل اعتماد است ، شاید به دلیل ضعف در پذیرش و هضم موقعیت اش در زندگی. پوچ گراییِ این اثر که تا حدودی به اَبزورد می زند جز ملال و بیهودگی چیزی به خواننده ساطع نمی کند. همان ملالی که خودِ راوی هم بازگو می کند و از آن دم می زند و تاحدودی تسلیمش میشود. جهان راوی ، جهانی ست بی رنگ و بی هدف که نه دیگر شادی برایش اهمیت دارد و نه خشم. تنها به صرف گذران لحظاتش تصمیم به انجام کارهایی می گیرد تا با خودِ نشناخته اش کلنجار برود.\n",
            "هیچ طوری قابل درک نبود.\n",
            "هیچ طوری قابل درک نبود.\n",
            "بهترین کتاب در سبک نهیلیسم\n",
            "بهترین کتاب در سبک نهیلیسم\n",
            "زیبا.جذاب.پرکشش و ترجمه خوب.\n",
            "زیبا.جذاب.پرکشش و ترجمه خوب.\n",
            "بکت شگفت آوره\n",
            "بکت شگفت آوره\n",
            "عالی، خیلی عالی، باز هم ممنون از همه شما\n",
            "عالی، خیلی عالی، باز هم ممنون از همه شما\n",
            "کتاب خیلی خوبی هست\n",
            "کتاب خیلی خوبی هست\n",
            "این ترجمه خوب نیست، ولی کلیت کتاب عالیه، یکی از متفاوت ترین ها و بهترین های دنیا بکته، همین محتوارو از نشر چشمه با عنوان ننامیدنی با ترجمه ی مهدی نوید تهیه کنید، که نقد و تعلیقات هم ضمیمش هست.\n",
            "این ترجمه خوب نیست، ولی کلیت کتاب عالیه، یکی از متفاوت ترین ها و بهترین های دنیا بکته، همین محتوارو از نشر چشمه با عنوان ننامیدنی با ترجمه ی مهدی نوید تهیه کنید، که نقد و تعلیقات هم ضمیمش هست.\n",
            "اگر قبل از این کیمیاگر رو خونده باشید این کتاب چیزی اضافه تر از اون نداره.‌‌..کیمیاگر تکمیل تر و فوق العادس\n",
            "اگر قبل از این کیمیاگر رو خونده باشید این کتاب چیزی اضافه تر از اون نداره.‌‌..کیمیاگر تکمیل تر و فوق العادس\n",
            "به سوال های خوبی جواب میداد سوالاتی ک تو زندگی هرگی یبار پیش اومده شاید ولی روند داستان جذب نکرد منو!\n",
            "کتاب کیمیاگرش خیلی جذاب تره\n",
            "به سوال های خوبی جواب میداد سوالاتی ک تو زندگی هرگی یبار پیش اومده شاید ولی روند داستان جذب نکرد منو!\n",
            "کتاب کیمیاگرش خیلی جذاب تره\n",
            "کتاب فوق العاده ای بود\n",
            "کتاب فوق العاده ای بود\n",
            "با این که موضوع کلی داستان تفاوت عمیقی با عقاید ما داره و اوایل کتاب کمی گیج کننده به نظر میرسه اما در آخر به من درس بزرگی داد چون بنظرم همه ی ما در رابطه با خدا یک جایی مثل ایلیا می‌شیم و امیدوارم که مثل اونم راه خودمون رو پیدا کنیم.\n",
            "با این که موضوع کلی داستان تفاوت عمیقی با عقاید ما داره و اوایل کتاب کمی گیج کننده به نظر میرسه اما در آخر به من درس بزرگی داد چون بنظرم همه ی ما در رابطه با خدا یک جایی مثل ایلیا می‌شیم و امیدوارم که مثل اونم راه خودمون رو پیدا کنیم.\n",
            "نثر خوب و داستان جذاب و ....واقعا به فکر فرو میبره ادمو! درسای بزرگی میده...خیلی خیلی حیلی خوبه!\n",
            "نثر خوب و داستان جذاب و ....واقعا به فکر فرو میبره ادمو! درسای بزرگی میده...خیلی خیلی حیلی خوبه!\n",
            "یکی از بهترین و پرمحتوا ترین کتاب هایی که تا به حال خواندم.\n",
            "یکی از بهترین و پرمحتوا ترین کتاب هایی که تا به حال خواندم.\n",
            "داستانی عرفانی و بسیار زیبا . هر چه از نوشته های این مرد تعریف شود ، باز هم کم است . مردی که بر تمام بعد های روحانی و فلسفی انسان ها مانور می دهد .\n",
            "داستانی عرفانی و بسیار زیبا . هر چه از نوشته های این مرد تعریف شود ، باز هم کم است . مردی که بر تمام بعد های روحانی و فلسفی انسان ها مانور می دهد .\n",
            "اگه درست ترجمه میشد شاید قشنگ تر بود در کل بدکی نبود\n",
            "اگه درست ترجمه میشد شاید قشنگ تر بود در کل بدکی نبود\n",
            "کتاب این گونه شروع می شود:\n",
            "چند کلمه توضیح:\n",
            "مترجم داستان را در دو خط لو می دهد:|\n",
            "آدم به عقل مترجم و ناشر شک می کنه!!!!\n",
            "کتاب این گونه شروع می شود:\n",
            "چند کلمه توضیح:\n",
            "مترجم داستان را در دو خط لو می دهد:|\n",
            "آدم به عقل مترجم و ناشر شک می کنه!!!!\n",
            "در حال خوندنشم 😊\n",
            "بازم میام طاقچه و کتابامو میخونم ولی مریم احمدی دلم برات تنگ میشه😂\n",
            "در حال خوندنشم \n",
            "بازم میام طاقچه و کتابامو میخونم ولی مریم احمدی دلم برات تنگ میشه\n",
            "آلبر کامو از قوی‌ترین نویسنده‌های اگزیستانسیالیسم هست؛ کسی که سارتر درباره بیگانه‌ش می‌نویسه اون بلده چجوری از صفت کار بکشه تا چیزی که در ذهنش هست رو به مخاطب‌ش نشون بده؛ سوءتفاهم هم مثل بیگانه و طاعون همان هدف‌های اگزیستانسیالیستی رو دنبال می‌کنه؛ قطعا درباره کامو نمیشه نظر خوب و بد داد چون از قوی‌ترین ها در این سبک بوده و هر بار که کتاب‌هاش رو بخونید چیز جدیدی در رابطه‌ با دنیای فانی یاد می‌گیرید.\n",
            "کتاب‌های کامو رو باید آهسته و با تأمل خوند؛ انقد آروم که بتونین تک‌تک صحنه‌هایی که توصیف می‌کنه رو توی ذهنتون بسازید و با داستان جلو ببرید.\n",
            "آلبر کامو از قوی‌ترین نویسنده‌های اگزیستانسیالیسم هست؛ کسی که سارتر درباره بیگانه‌ش می‌نویسه اون بلده چجوری از صفت کار بکشه تا چیزی که در ذهنش هست رو به مخاطب‌ش نشون بده؛ سوءتفاهم هم مثل بیگانه و طاعون همان هدف‌های اگزیستانسیالیستی رو دنبال می‌کنه؛ قطعا درباره کامو نمیشه نظر خوب و بد داد چون از قوی‌ترین ها در این سبک بوده و هر بار که کتاب‌هاش رو بخونید چیز جدیدی در رابطه‌ با دنیای فانی یاد می‌گیرید.\n",
            "کتاب‌های کامو رو باید آهسته و با تأمل خوند؛ انقد آروم که بتونین تک‌تک صحنه‌هایی که توصیف می‌کنه رو توی ذهنتون بسازید و با داستان جلو ببرید.\n",
            "چرا باید تو همون چند خط اول مقدمه داستان کامل اسپویل شه؟؟ دو صفحه ی اول رو خوندم بدون اینکه متوجه باشم مقدمه است. فکر کردم داستان شروع شده که یهو دیدم نوشته این خلاصه ی کل کتاب بود!! بعد ول کردم ادامه ی مقدمه رو رفتم داستان رو شروع کردم ولی دیگه هیچ جذابیتی واسم نداره چون میدونم چی میشه تهش..\n",
            "چرا باید تو همون چند خط اول مقدمه داستان کامل اسپویل شه؟؟ دو صفحه ی اول رو خوندم بدون اینکه متوجه باشم مقدمه است. فکر کردم داستان شروع شده که یهو دیدم نوشته این خلاصه ی کل کتاب بود!! بعد ول کردم ادامه ی مقدمه رو رفتم داستان رو شروع کردم ولی دیگه هیچ جذابیتی واسم نداره چون میدونم چی میشه تهش..\n",
            "ترجمه اصلا خوب نبود. کتاب کاملا خسته کننده و مزخرف بود.\n",
            "ترجمه اصلا خوب نبود. کتاب کاملا خسته کننده و مزخرف بود.\n",
            "اصلأ دوستش نداشتم😖اولین نمایشنامه ایی بود که خوندم و از هر چی نمایشنامه است متنفر شدم😒\n",
            "اصلأ ترجمه خوب نبود خیلـــــی بد بــود😖😞\n",
            "به سختی تمومش کردم\n",
            "اصلأ دوستش نداشتماولین نمایشنامه ایی بود که خوندم و از هر چی نمایشنامه است متنفر شدم\n",
            "اصلأ ترجمه خوب نبود خیلـــــی بد بــود\n",
            "به سختی تمومش کردم\n",
            "ترجمه ضعیف\n",
            "ترجمه ضعیف\n",
            "یه نمایشنامهٔ کوتاه که به نظر من برای شروع آثار کامو و آشنا شدن با قلمشون، تا حدودی مناسبه.\n",
            "ترجمه افتضاحه جوری که یه سری دیالوگ هارو بعد از چندبار خوندن بازهم نمیتونی بفهمی و مجبوری ازشون رد بشی.از جلال آل احمد انتظار یه ترجمه خوب رو داشتم.(البته اولین ترجمه ایه که از ایشون میخونم و نمیدونم بقیه اشون هم اینطورین یا نه.)\n",
            "یه ستاره که واسه ترجمه کم کردم یکی دیگه برای مقدمه:|\n",
            "توی مقدمه در یکی دو بند کل داستان رو لو میدن و لذت خوندن و شگفت زده شدن رو از ما میگیرن.مقدمه رو که خوندم دیگه هیجانی واسه خوندن نمایشنامه نداشتم.شما اگه خواستین بخونین مقدمه رو بزارین اخر سر.\n",
            "یه نمایشنامهٔ کوتاه که به نظر من برای شروع آثار کامو و آشنا شدن با قلمشون، تا حدودی مناسبه.\n",
            "ترجمه افتضاحه جوری که یه سری دیالوگ هارو بعد از چندبار خوندن بازهم نمیتونی بفهمی و مجبوری ازشون رد بشی.از جلال آل احمد انتظار یه ترجمه خوب رو داشتم.(البته اولین ترجمه ایه که از ایشون میخونم و نمیدونم بقیه اشون هم اینطورین یا نه.)\n",
            "یه ستاره که واسه ترجمه کم کردم یکی دیگه برای مقدمه:|\n",
            "توی مقدمه در یکی دو بند کل داستان رو لو میدن و لذت خوندن و شگفت زده شدن رو از ما میگیرن.مقدمه رو که خوندم دیگه هیجانی واسه خوندن نمایشنامه نداشتم.شما اگه خواستین بخونین مقدمه رو بزارین اخر سر.\n",
            "چرا در مقدمه باید داستان لو داده بشه؟!؟! اصلا درک نمیکنم :/\n",
            "ترجمه خیلی ایراد داشت. خیلییی از جملات و کلمات اصلا ارتباط معنایی نمیشد بینشون برقرار کرد!\n",
            "و البته من کامو رو درک نمیکنم.. این دیالوگای مارتا چی بود بعد از کشتن برادرش ؟!؟! بنظرم باید برم متن اصلی رو خودم بخونم. وقت تلف کردن بود\n",
            "چرا در مقدمه باید داستان لو داده بشه؟!؟! اصلا درک نمیکنم :/\n",
            "ترجمه خیلی ایراد داشت. خیلییی از جملات و کلمات اصلا ارتباط معنایی نمیشد بینشون برقرار کرد!\n",
            "و البته من کامو رو درک نمیکنم.. این دیالوگای مارتا چی بود بعد از کشتن برادرش ؟!؟! بنظرم باید برم متن اصلی رو خودم بخونم. وقت تلف کردن بود\n",
            "کلاسیک و خاص پسند با فضایی ابزورد و کافکایی\n",
            "ترجمه‌ای ملتهب، درگیر و دار امانتداری\n",
            "کلاسیک و خاص پسند با فضایی ابزورد و کافکایی\n",
            "ترجمه‌ای ملتهب، درگیر و دار امانتداری\n",
            "خوشم نیومد\n",
            "خوشم نیومد\n",
            "ترجمه خوبی نداشت اما باز هم نمیشه از قدرت کامو گذشت. اگه به ترجمه عادت کنید خیلی سریع جذب داستان می شید. مقدمه کتاب رو هم آخر بخونید بهتره به نظرم. حس و حال داستان به خصوص صفحات آخر طوری آدم رو غرق خودش می‌کنه که انگار تمام اتفاقات رو از نزدیک تماشا کرده.\n",
            "ترجمه خوبی نداشت اما باز هم نمیشه از قدرت کامو گذشت. اگه به ترجمه عادت کنید خیلی سریع جذب داستان می شید. مقدمه کتاب رو هم آخر بخونید بهتره به نظرم. حس و حال داستان به خصوص صفحات آخر طوری آدم رو غرق خودش می‌کنه که انگار تمام اتفاقات رو از نزدیک تماشا کرده.\n",
            "ترجمه افتضاح! حس میکنم اصلا نتونست اونطور که شاید و باید مفهوم رو بروسونه در ترجمش و داستان رو کاملا خراب کرده!\n",
            "اولش هم که تو مقدمه داستان رو لو میده! نمیدونم مشکل از ناشر بوده و یا فقط مترجم!\n",
            "ترجمه افتضاح! حس میکنم اصلا نتونست اونطور که شاید و باید مفهوم رو بروسونه در ترجمش و داستان رو کاملا خراب کرده!\n",
            "اولش هم که تو مقدمه داستان رو لو میده! نمیدونم مشکل از ناشر بوده و یا فقط مترجم!\n",
            "ااااااه مسخره بود از ۲خط اولشم معلوم بود@^_^@\n",
            "ااااااه مسخره بود از ۲خط اولشم معلوم بود@^_^@\n",
            "چند صفحه اول عین بعضی از صفحات کتاب بیگانه همین نویسندس که این اتفاقات و پیداکردن روزنامه در دوره محکومیت مرسو شخصیت داستان بیگانه است\n",
            "چند صفحه اول عین بعضی از صفحات کتاب بیگانه همین نویسندس که این اتفاقات و پیداکردن روزنامه در دوره محکومیت مرسو شخصیت داستان بیگانه است\n",
            "از محتوا و موضوع داستان خوشم اومد و تا مدتها ذهنم درگیرش بود ولی ی جاهایی انقد ترجمه وحشتناک بود ک اونجاهارو نمیخوندم.ی ستاره فقط ب محتوا\n",
            "از محتوا و موضوع داستان خوشم اومد و تا مدتها ذهنم درگیرش بود ولی ی جاهایی انقد ترجمه وحشتناک بود ک اونجاهارو نمیخوندم.ی ستاره فقط ب محتوا\n",
            "ترجمه همانطور که خود جلال هم گفته بود،کمی سخت بود اما لذت فهمیدنش جان ادم را تازه میکرد،موضوع داستان جدید بود ، حتما بخوانید\n",
            "ترجمه همانطور که خود جلال هم گفته بود،کمی سخت بود اما لذت فهمیدنش جان ادم را تازه میکرد،موضوع داستان جدید بود ، حتما بخوانید\n",
            "داستان جالب . نوشته ها خوب تا اخرم خوندم ولی نچسبید بهم . دلم میخاست صحنه قتلشو بهتر بازگو میکرد . چقدرم این دخترو مادر باهم بیخودی حرف میزدن 😄😁\n",
            "داستان جالب . نوشته ها خوب تا اخرم خوندم ولی نچسبید بهم . دلم میخاست صحنه قتلشو بهتر بازگو میکرد . چقدرم این دخترو مادر باهم بیخودی حرف میزدن \n",
            "یک نمایشنامه خوووب...\n",
            "یک نمایشنامه خوووب...\n",
            "نمایشنامه سنگینی بود، نه به خاطر وقایع و تعدد بازیگرهاش که اتفاقا همین چند نفر هم زیاد بودند!..داستان غم بسیاری همراه خودش داره، غمی که وقتی شرایط به انسان سخت بگیره زندگی چقدر پوچ و خطرناک میشه برای خودش و دیگران... و کلمات و فلسفه بافی شخصیتهاش هم هرچه تلاش کردند از اندوه و بار گناه داستان کم کنند نشد که نشد.\n",
            "خلاصه که ارزش خوندن داشت اما رد غمش تا مدتی قلب آدم رو مچاله میکنه.\n",
            "و منم مثل خیلی از دوستان کتابخون که یک کتاب رو از ب بسم الله تا تهش میخونیم با خوندن مقدمه کل داستانش برامون لو رفت، اما جالبه که باز هم به قدر کافی کشش داشت.\n",
            "اما قطعا توصیه ام اینه که مقدمه اش رو نخونید!\n",
            "نمایشنامه سنگینی بود، نه به خاطر وقایع و تعدد بازیگرهاش که اتفاقا همین چند نفر هم زیاد بودند!..داستان غم بسیاری همراه خودش داره، غمی که وقتی شرایط به انسان سخت بگیره زندگی چقدر پوچ و خطرناک میشه برای خودش و دیگران... و کلمات و فلسفه بافی شخصیتهاش هم هرچه تلاش کردند از اندوه و بار گناه داستان کم کنند نشد که نشد.\n",
            "خلاصه که ارزش خوندن داشت اما رد غمش تا مدتی قلب آدم رو مچاله میکنه.\n",
            "و منم مثل خیلی از دوستان کتابخون که یک کتاب رو از ب بسم الله تا تهش میخونیم با خوندن مقدمه کل داستانش برامون لو رفت، اما جالبه که باز هم به قدر کافی کشش داشت.\n",
            "اما قطعا توصیه ام اینه که مقدمه اش رو نخونید!\n",
            "داستان جالبی داشت.ولی در نهایت عکس العمل مادر رو درک نکردم(بعد از این که فهمید ژان پسرش بوده)،درسته که سال ها جنایت می کرده ولی از صحبت هاش معلوم بود که هنوز کمی احساس توی وجودش هست(برخلاف دخترش)،ولی بیش از اندازه سرد برخورد کرد بعد از اینکه متوجه شد ژان پسرشه.وبه نظرم این یک تناقض توی شخصیت مادر بود.و نکته دیگه این که کاش یه کم روان تر ترجمه میشد.به نظرم متن اصلی نمایشنامه رو بخونیم جالب تر باشه.ولی در کل خوب بود\n",
            "داستان جالبی داشت.ولی در نهایت عکس العمل مادر رو درک نکردم(بعد از این که فهمید ژان پسرش بوده)،درسته که سال ها جنایت می کرده ولی از صحبت هاش معلوم بود که هنوز کمی احساس توی وجودش هست(برخلاف دخترش)،ولی بیش از اندازه سرد برخورد کرد بعد از اینکه متوجه شد ژان پسرشه.وبه نظرم این یک تناقض توی شخصیت مادر بود.و نکته دیگه این که کاش یه کم روان تر ترجمه میشد.به نظرم متن اصلی نمایشنامه رو بخونیم جالب تر باشه.ولی در کل خوب بود\n",
            "خود مترجم دلیل این جور ترجمه کردنش رو گفته،ولی به نظرم اصلا خوب در نیومده.به نظرم اگه روون تر ترجمه میکرد بهتر از آب در میومد...\n",
            "خود مترجم دلیل این جور ترجمه کردنش رو گفته،ولی به نظرم اصلا خوب در نیومده.به نظرم اگه روون تر ترجمه میکرد بهتر از آب در میومد...\n",
            "عالی👌🏻\n",
            "عالی\n",
            "پیشنهاد میدم قبل از اینکه این کتاب رو بخونید اصلا کتاب بیگانه و پیشگفتار همین کتاب رو نخونید چون داستان کتاب لو می‌ره و براتون بی مزه میشه\n",
            "پیشنهاد میدم قبل از اینکه این کتاب رو بخونید اصلا کتاب بیگانه و پیشگفتار همین کتاب رو نخونید چون داستان کتاب لو می‌ره و براتون بی مزه میشه\n",
            "من تازه میخوام کتاب رو شروع کنم. چند کلمه توضیح جلال که من عاشق قلمش هستم، یه جورایی داستان رو اسپویل کرد به نظرم. حالا باید شروع کرد و دید خود اثر چیه! در کل توصیه میکنم توضیحات مترجم رو بعد از خوندن کتاب بخونید.\n",
            "من تازه میخوام کتاب رو شروع کنم. چند کلمه توضیح جلال که من عاشق قلمش هستم، یه جورایی داستان رو اسپویل کرد به نظرم. حالا باید شروع کرد و دید خود اثر چیه! در کل توصیه میکنم توضیحات مترجم رو بعد از خوندن کتاب بخونید.\n",
            "کاش مقدمه رو نمیخوندم تا اخر داستان این افسوس همرام بود ب عنوان ی داستان متفاوت و نمایشنامه خوب بود ولی بیان تصویر نداشت ولی کالیگولا عالی بود ازین نظر\n",
            "کاش مقدمه رو نمیخوندم تا اخر داستان این افسوس همرام بود ب عنوان ی داستان متفاوت و نمایشنامه خوب بود ولی بیان تصویر نداشت ولی کالیگولا عالی بود ازین نظر\n",
            "wow عالی بود\n",
            "wow عالی بود\n",
            "شاهکار بود\n",
            "شاهکار بود\n",
            "از خدای خودتان بخواهید که شما را همچون سنگ کند ( حرف های ناگفته ، سوء تفاهم ها ، قضاوت ها ، برهوت رابطه ، انزوا ، نبود عشق ) ، و در آخر مرگی پوچ\n",
            "از خدای خودتان بخواهید که شما را همچون سنگ کند ( حرف های ناگفته ، سوء تفاهم ها ، قضاوت ها ، برهوت رابطه ، انزوا ، نبود عشق ) ، و در آخر مرگی پوچ\n",
            "یه سوال\n",
            "چرا از این نمایشنامه دو تا هست؟؟\n",
            "بعد این رایگان و اون پولیه\n",
            "یعنی باهم فرق میکنن؟؟؟\n",
            "یه سوال\n",
            "چرا از این نمایشنامه دو تا هست؟؟\n",
            "بعد این رایگان و اون پولیه\n",
            "یعنی باهم فرق میکنن؟؟؟\n",
            "داستان خیلی خوبی داشت .کامو عالیه\n",
            "داستان خیلی خوبی داشت .کامو عالیه\n",
            "عاااااالی خیلی داستان جالبی داشتن\n",
            "عاااااالی خیلی داستان جالبی داشتن\n",
            "وای من ک خیلی دوست داشتم و احتیاج دارم یک بار دیگه بخونم چقدر ساده و متفاوت. دختر و مادر چقدر غریب بودند.\n",
            "وای من ک خیلی دوست داشتم و احتیاج دارم یک بار دیگه بخونم چقدر ساده و متفاوت. دختر و مادر چقدر غریب بودند.\n",
            "خوب بود 👏👏\n",
            "خوب بود \n",
            "اینکه بعضی از دوستان میگن کشش نداره دلیلش شاید اینه که رمان نیست...بعنوان یک نمایشنامه خوبه ولی کاش مقدمه رو نمیخوندم😔\n",
            "اینکه بعضی از دوستان میگن کشش نداره دلیلش شاید اینه که رمان نیست...بعنوان یک نمایشنامه خوبه ولی کاش مقدمه رو نمیخوندم\n",
            "آلبر کامو چهره‌ای متفکر است و در «سوء‌تفاهم» مانند دیگر آثار خود، تمام تلاش خویشتن را دارد تا خواننده را به تفکر وادارد. او نمایشی تکان‌دهنده خلق می‌کند و از دلِ ماجرای نمایش، انبوهی سوالات گوناگون پیش می‌کشد: خانواده و جایگاه آن را زیرِ سوال می‌برد. روابط انسانی و رویاهای بشری را زیرِ سوال می‌برد. خودِ بشر و خلقیات او را زیرِ سوال می‌برد و همه اینها نمایشنامه ای بسیار تکان دهنده می سازد ، درباره همه ما انسانها.\n",
            "آلبر کامو چهره‌ای متفکر است و در «سوء‌تفاهم» مانند دیگر آثار خود، تمام تلاش خویشتن را دارد تا خواننده را به تفکر وادارد. او نمایشی تکان‌دهنده خلق می‌کند و از دلِ ماجرای نمایش، انبوهی سوالات گوناگون پیش می‌کشد: خانواده و جایگاه آن را زیرِ سوال می‌برد. روابط انسانی و رویاهای بشری را زیرِ سوال می‌برد. خودِ بشر و خلقیات او را زیرِ سوال می‌برد و همه اینها نمایشنامه ای بسیار تکان دهنده می سازد ، درباره همه ما انسانها.\n",
            "من اولین کتابی که خوندم این کتاب بود که واقعا لذت بردم از خوندنش و باعث شد بیشتر کتابهای کامو رو بخونم و همچنین دیگر نویسندگان رو بهتون پیشنهاد میکنم حتما بخونین\n",
            "من اولین کتابی که خوندم این کتاب بود که واقعا لذت بردم از خوندنش و باعث شد بیشتر کتابهای کامو رو بخونم و همچنین دیگر نویسندگان رو بهتون پیشنهاد میکنم حتما بخونین\n",
            "دوستان برای مطالعه این کتاب توصیه میکنم مقدمه رو نخونید و به ناشر هم توصیه میکنم متن مترجم رو به عنوان مؤخره در کتاب بیاورند.\n",
            "دوستان برای مطالعه این کتاب توصیه میکنم مقدمه رو نخونید و به ناشر هم توصیه میکنم متن مترجم رو به عنوان مؤخره در کتاب بیاورند.\n",
            "عالی بود فقط پیشنهاد میشه مقدمش رو ابتدا نخونید چون داستان لو میره\n",
            "عالی بود فقط پیشنهاد میشه مقدمش رو ابتدا نخونید چون داستان لو میره\n",
            "نمایشنامه قوویی و جالبی هست با اینکه اصلا نمایشنامه دوست ندارم..\n",
            "نمایشنامه قوویی و جالبی هست با اینکه اصلا نمایشنامه دوست ندارم..\n",
            "کتاب فوق العاده ای هستش . فقط حیف که داستان توی مقدمه لو رفت و انگیره خواننده برای خواندن جزئیات رو گرفت.\n",
            "حواستون باشه مقدمه رو نخونید\n",
            "کتاب فوق العاده ای هستش . فقط حیف که داستان توی مقدمه لو رفت و انگیره خواننده برای خواندن جزئیات رو گرفت.\n",
            "حواستون باشه مقدمه رو نخونید\n",
            "عجب سو تفاهمی! اولین بار بود نمایشنامه میخوندم،بد نبود.\n",
            "عجب سو تفاهمی! اولین بار بود نمایشنامه میخوندم،بد نبود.\n",
            "قشنگ بود 💎\n",
            "قشنگ بود \n",
            "اولین کتابی بود که از این نویسنده میخوندم.کتاب وروایت مورد پسندم بود ولذت بردم\n",
            "اولین کتابی بود که از این نویسنده میخوندم.کتاب وروایت مورد پسندم بود ولذت بردم\n",
            "مقدمه غیر حرفه‌ای که تا آخر داستان رو در چند جمله لو داد.\n",
            "مقدمه غیر حرفه‌ای که تا آخر داستان رو در چند جمله لو داد.\n",
            "مقدمه را آخر کار بخوانید چون داستان کاملا لو میرود.\n",
            "مقدمه را آخر کار بخوانید چون داستان کاملا لو میرود.\n",
            "اولا : جلال ال احمد گل کاشته\n",
            "دوما : اونایی که اهل تئاتر هستند پیشنهاد میدم حتما بخونن\n",
            "سوما : در کل خوب بود ،\n",
            "اولا : جلال ال احمد گل کاشته\n",
            "دوما : اونایی که اهل تئاتر هستند پیشنهاد میدم حتما بخونن\n",
            "سوما : در کل خوب بود ،\n",
            "داستان هیچگونه جذابیتی نداره، من واقعا به زور تمومش کردم بعد 2ماه، چون رغبتی تو من ایجاد نمیکرد، اما نه به خاطر ترجمه جلال آل احمد، خود متن آلبرکامو ثقیل و به گونه ای قدیمی بود و سیر داستان هم کند و از جذابیتش به شدت کاسته بود...\n",
            "اما از جلال آل احمد بعید بود که کل داستانو تو مقدمه ش لو بده تحت عنوان تحلیل، آخه برادر من تحلیلتو بذار آخر کتاب\n",
            "حالا فک کنین یه همچین کتاب ناجذابی تهشم بدونین، دیگه چی میخواد کشش ایجاد کنه من نمیدونم! بزرگوار جلال آل احمد تیرخلاصو زد با این کارش، شایدم عمدا خلاصه شو اول گفته که وقتمون تلف نشه بیخودی کتابو بخونیم!!\n",
            "به هرحال اگه با تمام این حرفا بازم اصرار به خوندنش دارید پیشنهاد میکنم مقدمه رو آخر بخونید یا اصن نخونید، چه کاریه\n",
            "درضمن اون یه ستاره روهم از روی اجبار دادم!\n",
            "داستان هیچگونه جذابیتی نداره، من واقعا به زور تمومش کردم بعد 2ماه، چون رغبتی تو من ایجاد نمیکرد، اما نه به خاطر ترجمه جلال آل احمد، خود متن آلبرکامو ثقیل و به گونه ای قدیمی بود و سیر داستان هم کند و از جذابیتش به شدت کاسته بود...\n",
            "اما از جلال آل احمد بعید بود که کل داستانو تو مقدمه ش لو بده تحت عنوان تحلیل، آخه برادر من تحلیلتو بذار آخر کتاب\n",
            "حالا فک کنین یه همچین کتاب ناجذابی تهشم بدونین، دیگه چی میخواد کشش ایجاد کنه من نمیدونم! بزرگوار جلال آل احمد تیرخلاصو زد با این کارش، شایدم عمدا خلاصه شو اول گفته که وقتمون تلف نشه بیخودی کتابو بخونیم!!\n",
            "به هرحال اگه با تمام این حرفا بازم اصرار به خوندنش دارید پیشنهاد میکنم مقدمه رو آخر بخونید یا اصن نخونید، چه کاریه\n",
            "درضمن اون یه ستاره روهم از روی اجبار دادم!\n",
            "داستان غم‌انگیزی بود... درام خوبی بود ولی کشش قوی‌ای نداشت.\n",
            "داستان غم‌انگیزی بود... درام خوبی بود ولی کشش قوی‌ای نداشت.\n",
            "167 صفحه اس؟ حس میکنم ادامه داشته\n",
            "167 صفحه اس؟ حس میکنم ادامه داشته\n",
            "همچین عقیده ای در اون مکان و زمان نشانه ی پوچی خو مکان و زمان و فرهنگ آلبر کامو است. واقعا خیلی خوب تونسته غم داستان رو انتقال بده\n",
            "همچین عقیده ای در اون مکان و زمان نشانه ی پوچی خو مکان و زمان و فرهنگ آلبر کامو است. واقعا خیلی خوب تونسته غم داستان رو انتقال بده\n",
            "بسیار زیبا و دراماتیک\n",
            "بسیار زیبا و دراماتیک\n",
            "اولین کتابیه که از آلبرکامو میخونم... جذب نوع افکار و نوشته هاش شدم .... شکی ندارم کم کم اونو از نویسنده های مورد علاقه م میدونم.\n",
            "اولین کتابیه که از آلبرکامو میخونم... جذب نوع افکار و نوشته هاش شدم .... شکی ندارم کم کم اونو از نویسنده های مورد علاقه م میدونم.\n",
            "دوستان ترجمش خوبه؟؟\n",
            "دوستان ترجمش خوبه؟؟\n",
            "اولین کتابی ک بعد مدتها خوندم جالب بود ولی مقدمه درخاتمه خوانده شود..\n",
            "اولین کتابی ک بعد مدتها خوندم جالب بود ولی مقدمه درخاتمه خوانده شود..\n",
            "کتابی غمگین و تاثیر گذار،نباید تند رفت\n",
            "کتابی غمگین و تاثیر گذار،نباید تند رفت\n",
            "غمگین و زیبا:(\n",
            "غمگین و زیبا:(\n",
            "مرسی که گفتید مقدمه رو اول نخونید.نمایشنامه خوندن خیلی جذاب تره از این جهت که همه ی برداشت ها با خواننده است .\n",
            "مرسی که گفتید مقدمه رو اول نخونید.نمایشنامه خوندن خیلی جذاب تره از این جهت که همه ی برداشت ها با خواننده است .\n",
            "مقدمه رو اول نخونیدمتاسفانه یه کم از مقدمه رو خوندم که داستان و لو داد و کشش وهیجانش وازبین برد\n",
            "مقدمه رو اول نخونیدمتاسفانه یه کم از مقدمه رو خوندم که داستان و لو داد و کشش وهیجانش وازبین برد\n",
            "ناگفته نماند که سو تفاهم یک مشکل کلیشه ای در زندگی است که به شکل ها متنوع در صحنه نمایش زندگی برایمان رخ می دهد.\n",
            " این کتاب یک تراژدی بود در واقع یک صحنه ای بود که بیچارگی افرادی از جامعه را نشان میدهد که آلتی برای خوشحالی و احساس خوشبختی ندارند. متاسفانه یک مشکل بارز ان مقدمه بود ( جالب نبود ). \n",
            "نویسنده سعی کرد نشان دهد که راه حل حیات عشق به زیبایی ها است. می توان فهمید که نویسنده قصد داشت زندگی را سبک نشان دهد. \n",
            "در کل موضوع جالبی برای خواندن است.\n",
            "ناگفته نماند که سو تفاهم یک مشکل کلیشه ای در زندگی است که به شکل ها متنوع در صحنه نمایش زندگی برایمان رخ می دهد.\n",
            " این کتاب یک تراژدی بود در واقع یک صحنه ای بود که بیچارگی افرادی از جامعه را نشان میدهد که آلتی برای خوشحالی و احساس خوشبختی ندارند. متاسفانه یک مشکل بارز ان مقدمه بود ( جالب نبود ). \n",
            "نویسنده سعی کرد نشان دهد که راه حل حیات عشق به زیبایی ها است. می توان فهمید که نویسنده قصد داشت زندگی را سبک نشان دهد. \n",
            "در کل موضوع جالبی برای خواندن است.\n",
            "#مسئله بزرگی که باید \"عملا\" حل کرد:\n",
            "آیا میتوان خوشبخت و تنها بود؟\n",
            "(آلبر کامو). .\n",
            "باحال بودツ\n",
            "#مسئله بزرگی که باید \"عملا\" حل کرد:\n",
            "آیا میتوان خوشبخت و تنها بود؟\n",
            "(آلبر کامو). .\n",
            "باحال بود\n",
            "من نمیدونم  امتیاز این نمایشنامه چرا اینقدر پایینه ...\n",
            "از نظر من  که  بی نظیره\n",
            "من نمیدونم  امتیاز این نمایشنامه چرا اینقدر پایینه ...\n",
            "از نظر من  که  بی نظیره\n",
            "جالب بود و هیجانی.\n",
            "جالب بود و هیجانی.\n",
            "عالییییی\n",
            "عالییییی\n",
            "شخصیت پردازی های خوب و ایده جالب\n",
            "ترجمه روانی داره\n",
            "شخصیت پردازی های خوب و ایده جالب\n",
            "ترجمه روانی داره\n",
            "فقط میتونم بگم بد نبود\n",
            "نه عالی بود نه مزخرف، بدنبود\n",
            "فقط میتونم بگم بد نبود\n",
            "نه عالی بود نه مزخرف، بدنبود\n",
            "بنظرم عالی بود بخصوص نتیجش که دردناک تموم شد بهترش کرده بود.خیلی دوست داشتم پیشنهاد میکنم بخونید\n",
            "بنظرم عالی بود بخصوص نتیجش که دردناک تموم شد بهترش کرده بود.خیلی دوست داشتم پیشنهاد میکنم بخونید\n",
            "به نظر من اونقدر هام جالب نبود....\n",
            "فکر نمیکردم اینقدر بد تموم بشه \n",
            "کاملا هیجانی بود .امانتیجه اش مسخره بود\n",
            "به نظر من اونقدر هام جالب نبود....\n",
            "فکر نمیکردم اینقدر بد تموم بشه \n",
            "کاملا هیجانی بود .امانتیجه اش مسخره بود\n",
            "👍👌\n",
            "\n",
            "اولین نمایشنامه‌ای که تا الان خوندم. عالی\n",
            "اولین نمایشنامه‌ای که تا الان خوندم. عالی\n",
            "بنظر من نویسنده در این نمایشنامه بسیار در پی دنبال کردن ایده برتولت برشت در نمایشنامه استثنا و قاعده بود اگه اون نمایشنامه رو مطالعه کرده باشین خلاقیتی از نظر مفهوم نیز نمیشه بلکه بسیار هم ضعیف تر بیان شده. نویسنده در پی وارد کردن نقش عشق برای ربط استثنا به یک رخداد بوده که در حالت عادی کاملا دور از قاعده جامعه است. که به نظر من به خوبی جلوه نکرده. در کل مفهوم سوتفاهم که ناشی از برداشت ما انسانها و علم به قطعی بودن برداشت هامونه خوب بیان شده و بنظر من در این کار موفق ظاهر شده.\n",
            "بنظر من نویسنده در این نمایشنامه بسیار در پی دنبال کردن ایده برتولت برشت در نمایشنامه استثنا و قاعده بود اگه اون نمایشنامه رو مطالعه کرده باشین خلاقیتی از نظر مفهوم نیز نمیشه بلکه بسیار هم ضعیف تر بیان شده. نویسنده در پی وارد کردن نقش عشق برای ربط استثنا به یک رخداد بوده که در حالت عادی کاملا دور از قاعده جامعه است. که به نظر من به خوبی جلوه نکرده. در کل مفهوم سوتفاهم که ناشی از برداشت ما انسانها و علم به قطعی بودن برداشت هامونه خوب بیان شده و بنظر من در این کار موفق ظاهر شده.\n",
            "یک ایده بکر و جذاب که توسط لحن داستان و استفاده از کلمات غیرحسی قربانی میشود! و در نهایت حاصلش میشود یک اثر کاملا متوسط!!\n",
            "یک ایده بکر و جذاب که توسط لحن داستان و استفاده از کلمات غیرحسی قربانی میشود! و در نهایت حاصلش میشود یک اثر کاملا متوسط!!\n",
            "سوء تفاهم، اون هم چه سوء تفاهمی!\n",
            " در مورد نمایشنامه بیشتر از این دو کلمه چیزی نمیتونم بگم: غم انگیز و تکان دهنده.\n",
            "اما به جرات میشه گفت سوء تفاهم در زندگی همه ما اتفاق میوفته، حالا در ابعاد و اقسام مختلف، در رنگ ها و  اشکال متفاوت.\n",
            "در مورد ترجمه: زیادی تکلف داره.\n",
            "به نظرم انتخاب کلمه مناسب به طوری که تغییری در منظور نویسنده ایجاد نکنه و از طرفی در زبان مقصد (اینجا فارسی) هم جاافتاده باشه، از اصلی ترین وظایف یک مترجمه!\n",
            " به عنوان یک نمونه از هزاران:\n",
            "در جایی ژان میگه \"شما می توانستید تهیه سفر خود را ببینید\"\n",
            "در این جمله اگر به جای کلمه تهیه، تدارک جایگزین میشد، بهتر نبود؟!\n",
            "در مورد چند کلمه توضیح آقای جلال آل احمد: بهتر بود این قسمت رو بعد از نمایشنامه قرار بدید، طاقچه!\n",
            "سوء تفاهم، اون هم چه سوء تفاهمی!\n",
            " در مورد نمایشنامه بیشتر از این دو کلمه چیزی نمیتونم بگم: غم انگیز و تکان دهنده.\n",
            "اما به جرات میشه گفت سوء تفاهم در زندگی همه ما اتفاق میوفته، حالا در ابعاد و اقسام مختلف، در رنگ ها و  اشکال متفاوت.\n",
            "در مورد ترجمه: زیادی تکلف داره.\n",
            "به نظرم انتخاب کلمه مناسب به طوری که تغییری در منظور نویسنده ایجاد نکنه و از طرفی در زبان مقصد (اینجا فارسی) هم جاافتاده باشه، از اصلی ترین وظایف یک مترجمه!\n",
            " به عنوان یک نمونه از هزاران:\n",
            "در جایی ژان میگه \"شما می توانستید تهیه سفر خود را ببینید\"\n",
            "در این جمله اگر به جای کلمه تهیه، تدارک جایگزین میشد، بهتر نبود؟!\n",
            "در مورد چند کلمه توضیح آقای جلال آل احمد: بهتر بود این قسمت رو بعد از نمایشنامه قرار بدید، طاقچه!\n",
            "خیلی عالی و پر از غم بود\n",
            "و البته به نظر من مقدمه بیشتر هیجان به داستان هیجان داد.\n",
            "خیلی عالی و پر از غم بود\n",
            "و البته به نظر من مقدمه بیشتر هیجان به داستان هیجان داد.\n",
            "توصیه میکنم مقدمه این نمایشنامه حذف بشه یا خونده نشه‌. یک مقدمه ی خسته کننده و طولانی ک کل داستان رو لو داد و باعث شد اصل نمایشنامه رو کامل نخونم:/\n",
            "توصیه میکنم مقدمه این نمایشنامه حذف بشه یا خونده نشه‌. یک مقدمه ی خسته کننده و طولانی ک کل داستان رو لو داد و باعث شد اصل نمایشنامه رو کامل نخونم:/\n",
            "کاش ان مقدمه که لو رفتن کل داستان رو  به همرا داره نبود\n",
            "کاش ان مقدمه که لو رفتن کل داستان رو  به همرا داره نبود\n",
            "دیدار دوباره بعد از ۲۰ سال  ،کشتن یک آدم ،فهمیدن نسبت مفتول با خودشان،اعتراف به قتل و ... همه بدون هیجان!البته بیگانه آلبرکامو هم همین طور بود اما من بیگانه رو بیشتر پسندیدم.در ضمن خوندن مقدمه اشتباهه چون داستان را کامل لو می دهد.\n",
            "دیدار دوباره بعد از ۲۰ سال  ،کشتن یک آدم ،فهمیدن نسبت مفتول با خودشان،اعتراف به قتل و ... همه بدون هیجان!البته بیگانه آلبرکامو هم همین طور بود اما من بیگانه رو بیشتر پسندیدم.در ضمن خوندن مقدمه اشتباهه چون داستان را کامل لو می دهد.\n",
            "تقریبا میتونم بگم یه جیگولی خوف بود\n",
            "تقریبا میتونم بگم یه جیگولی خوف بود\n",
            "خوب بود البته برای افراد متفکر .به افراد باهوش توصیه میکنم بخونن\n",
            "خوب بود البته برای افراد متفکر .به افراد باهوش توصیه میکنم بخونن\n",
            "چرت  مطلق اینقدر مزخرف بود که به زور خواندمش گفتم عجیب کتاب کامو مجانی باشد\n",
            "چرت  مطلق اینقدر مزخرف بود که به زور خواندمش گفتم عجیب کتاب کامو مجانی باشد\n",
            "مرسی واقعا عالی بود\n",
            "مرسی واقعا عالی بود\n",
            "فاطمه محسن پور :مرسی واقعا عالی بود\n",
            "فاطمه محسن پور :مرسی واقعا عالی بود\n",
            "فوق العادست آثار کامو مخصوصا شاهکارش بیگانه\n",
            "فوق العادست آثار کامو مخصوصا شاهکارش بیگانه\n",
            "دومین اثری هستش که از کامو میخونم خوب بود\n",
            "دومین اثری هستش که از کامو میخونم خوب بود\n",
            "ترجمه زیاد خوب نبود \n",
            "اما اثر زیبایی بود. \n",
            "وقتی مادر فهمید پسرش رو کشته واقعا به ته خط رسید. چیزی که به ذهن من اومد این بود که چطور برای بقیه ی کسایی که کشته بود ارزش قائل نمیشد؟ مگه اونا خانواده نداشتن؟ حالا که به سر خودش اومده میره خودشو میکشه... \n",
            "از  این نگاه \"پوچ بودن زندگی\" هم که توی اثر بود اصلا خوشم نیومد. به هیچ وجه حس نزدیکی نمیکردم به این دیدگاه. نتیجه ای که من از خوندنش گرفتم انگار با بقیه فرق داره ولی من یاد کارما افتادم. اینکه هرکاری کنی نتیجش به سر خودت میاد. پس حواست به اعمالت باشه. خیلی جالب بود که طی تمام خطوطی که میخوندم اون دو تا زن داشتن نقشه ی قتل یکی از اعضای خانواده ی خودشون رو میکشیدن! \n",
            "ترجمه زیاد خوب نبود \n",
            "اما اثر زیبایی بود. \n",
            "وقتی مادر فهمید پسرش رو کشته واقعا به ته خط رسید. چیزی که به ذهن من اومد این بود که چطور برای بقیه ی کسایی که کشته بود ارزش قائل نمیشد؟ مگه اونا خانواده نداشتن؟ حالا که به سر خودش اومده میره خودشو میکشه... \n",
            "از  این نگاه \"پوچ بودن زندگی\" هم که توی اثر بود اصلا خوشم نیومد. به هیچ وجه حس نزدیکی نمیکردم به این دیدگاه. نتیجه ای که من از خوندنش گرفتم انگار با بقیه فرق داره ولی من یاد کارما افتادم. اینکه هرکاری کنی نتیجش به سر خودت میاد. پس حواست به اعمالت باشه. خیلی جالب بود که طی تمام خطوطی که میخوندم اون دو تا زن داشتن نقشه ی قتل یکی از اعضای خانواده ی خودشون رو میکشیدن! \n",
            "پیش گفتار مترجم افتضاح بود.تمام داستان تو چند صفحه تعریف میکنه و شوق خوندن و کنجکاوی تا پایان داستان از آدم میگیره.\n",
            "پیش گفتار مترجم افتضاح بود.تمام داستان تو چند صفحه تعریف میکنه و شوق خوندن و کنجکاوی تا پایان داستان از آدم میگیره.\n",
            "تلخ بود :(\n",
            "تلخ بود :(\n",
            "لذت بردم از مطالعه این کتاب همچون دیگر آثار کامو.\n",
            "لذت بردم از مطالعه این کتاب همچون دیگر آثار کامو.\n",
            "ممنون. عالی بود.\n",
            "ممنون. عالی بود.\n",
            "یک کار متوسط از کامو.  ارزش یک بار خواندن را دارد.\n",
            "یک کار متوسط از کامو.  ارزش یک بار خواندن را دارد.\n",
            "عاااالی\n",
            "عاااالی\n",
            "👏👏👏👏👍👍👍👍\n",
            "\n",
            "ممنون بلافاصله می زارینش تو طاقچه\n",
            "ممنون بلافاصله می زارینش تو طاقچه\n",
            "خیلی جالــــــب و پر مفهوم،\n",
            "البته فصل اول برای من جذابیت بیشتری داشت👍👍\n",
            "خیلی جالــــــب و پر مفهوم،\n",
            "البته فصل اول برای من جذابیت بیشتری داشت\n",
            "\"با کاروان حوله\"اثر امید مهدی نژاد ،کتابی است به ظاهر _وآن گونه که بر جلد کتاب نوشته شده_طنز؛ که در سه پرده و در دو میان پرده سعی میکند خنده را به لب خواننده کتابش بیاورد ولی در این کار چندان موفق نبوده است. در پرده اول_محفل انس_به قول نویسنده \"به شرح و تاویل چند شاهکار شعر و ترانه و غیره ی معاصر پرداخته ایم و بسته به حالمان در پروسه خلق اثر هنری شرکت جسته ایم.\"\n",
            "در میان پرده اول_همه چیز شناسی مرگ_آخرین دست نوشته پروفسور جان تراولتا را می بینید که پیش از مرگ در اختیار مترجم قرار داده است.\"در این متن پروفسور تراولتا با بهره گیری از پیشینه مطالعات فلسفی و عرفانی به دست آمده از سالها تحقیق و تفحص در ایران و هند و گینه، مهم ترین مسائل پیرامونی پدیده مرگ را مورد واکاری قرار میدهد\"\n",
            "از پرده دوم_فالنامه حافظ_(به قول نویسنده)میتوانید به عنوان فالنامه واقعی استفاده کنید زیرا اشعار حافظ به همراه شرح و تفسیر طنز آنها در این کتاب آمده است.\n",
            "در میان پرده دوم _یک انجمن ادبی_نویسنده از انجمن ادبی اثیرالدین اخسیکتی که در سال چهل و چهار تاسیس شده صحبت میکند.و در نهایت در پرده سوم_کتابسرا_نویسنده به معرفی بهترین کتابهای طنز پرداخته و برای هر کدام توضیح طنزی قرار داده است.\n",
            "به نظر من این کتاب به هیچ وجه نمی تواند در بین کتابهای طنز قرار گیرد زیرا نه نویسنده طنز پرداز خوبی است و نه تلاش او برای خلق صحنه های خنده دار مفید واقع شده است.\n",
            "یک ستاره برای ثبت نظر☆.\n",
            "***\n",
            "در بخشی از کتاب میخوانیم:\n",
            ".\n",
            ".\n",
            "😳با عرض پوزش به دلیل نبودن قسمت جذاب و طنزی در این کتاب از نوشتن این بخش از نظرم معذورم\n",
            "\"با کاروان حوله\"اثر امید مهدی نژاد ،کتابی است به ظاهر _وآن گونه که بر جلد کتاب نوشته شده_طنز؛ که در سه پرده و در دو میان پرده سعی میکند خنده را به لب خواننده کتابش بیاورد ولی در این کار چندان موفق نبوده است. در پرده اول_محفل انس_به قول نویسنده \"به شرح و تاویل چند شاهکار شعر و ترانه و غیره ی معاصر پرداخته ایم و بسته به حالمان در پروسه خلق اثر هنری شرکت جسته ایم.\"\n",
            "در میان پرده اول_همه چیز شناسی مرگ_آخرین دست نوشته پروفسور جان تراولتا را می بینید که پیش از مرگ در اختیار مترجم قرار داده است.\"در این متن پروفسور تراولتا با بهره گیری از پیشینه مطالعات فلسفی و عرفانی به دست آمده از سالها تحقیق و تفحص در ایران و هند و گینه، مهم ترین مسائل پیرامونی پدیده مرگ را مورد واکاری قرار میدهد\"\n",
            "از پرده دوم_فالنامه حافظ_(به قول نویسنده)میتوانید به عنوان فالنامه واقعی استفاده کنید زیرا اشعار حافظ به همراه شرح و تفسیر طنز آنها در این کتاب آمده است.\n",
            "در میان پرده دوم _یک انجمن ادبی_نویسنده از انجمن ادبی اثیرالدین اخسیکتی که در سال چهل و چهار تاسیس شده صحبت میکند.و در نهایت در پرده سوم_کتابسرا_نویسنده به معرفی بهترین کتابهای طنز پرداخته و برای هر کدام توضیح طنزی قرار داده است.\n",
            "به نظر من این کتاب به هیچ وجه نمی تواند در بین کتابهای طنز قرار گیرد زیرا نه نویسنده طنز پرداز خوبی است و نه تلاش او برای خلق صحنه های خنده دار مفید واقع شده است.\n",
            "یک ستاره برای ثبت نظر.\n",
            "***\n",
            "در بخشی از کتاب میخوانیم:\n",
            ".\n",
            ".\n",
            "با عرض پوزش به دلیل نبودن قسمت جذاب و طنزی در این کتاب از نوشتن این بخش از نظرم معذورم\n",
            "فصل فالنامه حافظ واقعا جالب بود!\n",
            "فصل فالنامه حافظ واقعا جالب بود!\n",
            "متوسط\n",
            "متوسط\n",
            "عالی.....\n",
            "دزفول قهرمان را بهتر بشناسید......\n",
            "شهری که اسوه ی مقاوت ایران است در روزگاری گه صدام (لعنت الله علیه) دستور حمله را با '' الف_دزفول آغاز می کرد!\n",
            "عالی.....\n",
            "دزفول قهرمان را بهتر بشناسید......\n",
            "شهری که اسوه ی مقاوت ایران است در روزگاری گه صدام (لعنت الله علیه) دستور حمله را با '' الف_دزفول آغاز می کرد!\n",
            "کتابی است که داستانهایش از ذهنیت حقیقی دور است و نوشته بر اساس ساختار موضوعیت نیست و تنها نکته مثبت آن گرمی و صمیمیت داستان است\n",
            "کتابی است که داستانهایش از ذهنیت حقیقی دور است و نوشته بر اساس ساختار موضوعیت نیست و تنها نکته مثبت آن گرمی و صمیمیت داستان است\n",
            "کتاب\"عکس پشه ای\"یازده داستان کوتاه درباره پسری هفت ساله به نام\"سعیدو\"است که در خوزستان زندگی میکند و مهم ترین علایق او ماهیگیری و قدم زدن در نخلستان است که در داستانهای کتاب به آن پرداخته می شود.\n",
            "برخلاف طبقه بندی کتابها در طاقچه-که این کتاب را جزو کتابهای نوجوان قرار داده است-این کتاب متعلق به گروه سنی'ج'یعنی سالهای پایانی دبستان(پنجم و ششم دبستان)است.\n",
            "یکی از مهم ترین نکات در کتابهای این رده سنی باید تصویرگری جذاب آنها باشد که متاسفانه در این کتاب این جذابیت وجود نداشت.نقطه ضعف دیگر این کتاب نیز پایان باز و نه چندان دل چسب کتاب بود.\n",
            "کتاب\"عکس پشه ای\"یازده داستان کوتاه درباره پسری هفت ساله به نام\"سعیدو\"است که در خوزستان زندگی میکند و مهم ترین علایق او ماهیگیری و قدم زدن در نخلستان است که در داستانهای کتاب به آن پرداخته می شود.\n",
            "برخلاف طبقه بندی کتابها در طاقچه-که این کتاب را جزو کتابهای نوجوان قرار داده است-این کتاب متعلق به گروه سنی'ج'یعنی سالهای پایانی دبستان(پنجم و ششم دبستان)است.\n",
            "یکی از مهم ترین نکات در کتابهای این رده سنی باید تصویرگری جذاب آنها باشد که متاسفانه در این کتاب این جذابیت وجود نداشت.نقطه ضعف دیگر این کتاب نیز پایان باز و نه چندان دل چسب کتاب بود.\n",
            "من خوشم نیومد کسل کننده بود\n",
            "من خوشم نیومد کسل کننده بود\n",
            "عالیه ، فقط دو تا از داستانا جذاب نبودن ، ترجمه هم رووونه\n",
            "عالیه ، فقط دو تا از داستانا جذاب نبودن ، ترجمه هم رووونه\n",
            "خسته کننده بود توضیحات بی مورد داشت و لحنشم مثل لحن پر شور ناطوردشت نبود\n",
            "خسته کننده بود توضیحات بی مورد داشت و لحنشم مثل لحن پر شور ناطوردشت نبود\n",
            "اولین کتابی بود که از سلینجر میخوندم خوشم نیومد\n",
            "اولین کتابی بود که از سلینجر میخوندم خوشم نیومد\n",
            "بسیار جالب بود\n",
            "بسیار جالب بود\n",
            "من که لذت بردم\n",
            "من که لذت بردم\n",
            "خیلی کتاب خوب و  قشنگیه\n",
            "خیلی کتاب خوب و  قشنگیه\n",
            "این کتاب را جایزه هم برده است. جایزه بهترین بازنویسی کانون پرورش.\n",
            "این کتاب را جایزه هم برده است. جایزه بهترین بازنویسی کانون پرورش.\n",
            "طاقچه مرسی که داستانهای خوبو مناسب بچه ها گذاشتی\n",
            "طاقچه مرسی که داستانهای خوبو مناسب بچه ها گذاشتی\n",
            "مجموعه کتابهای روزگاران عالین... عالی... ای کاش هزاران هزار از این خاطرات با همین قلم ثبت میشد\n",
            "همیشه تو کتابخونه‌ام هستن. هروقت برشون میدارم حتما یکی دوتا از خاطراتش رو میخونم... و البته هیچوقت موفق نمیشم به یکی دوتا بسنده کنم ؛)\n",
            "مجموعه کتابهای روزگاران عالین... عالی... ای کاش هزاران هزار از این خاطرات با همین قلم ثبت میشد\n",
            "همیشه تو کتابخونه‌ام هستن. هروقت برشون میدارم حتما یکی دوتا از خاطراتش رو میخونم... و البته هیچوقت موفق نمیشم به یکی دوتا بسنده کنم ؛)\n",
            "زیاد جالب نبود خیلی کوتاه بودند خاطرات.\n",
            "زیاد جالب نبود خیلی کوتاه بودند خاطرات.\n",
            "اگر فارسی بلد نبودم، برای خواندن این کتاب یاد می گرفتم؛ کتاب بسیار عالی است\n",
            "اگر فارسی بلد نبودم، برای خواندن این کتاب یاد می گرفتم؛ کتاب بسیار عالی است\n",
            "عجیبه وقتی میبینم کتابی به این خوبی هیچ کامنتی نداره \n",
            "این کتاب خیلی عالیه\n",
            "عجیبه وقتی میبینم کتابی به این خوبی هیچ کامنتی نداره \n",
            "این کتاب خیلی عالیه\n",
            "ممنون از خدمات شما\n",
            "ممنون از خدمات شما\n",
            "سلام ، چگونه میتونم کتاب را به صورت پی دی اف روی گوشی یا کاپیوتر داشته باشم ؟؟\n",
            "سلام ، چگونه میتونم کتاب را به صورت پی دی اف روی گوشی یا کاپیوتر داشته باشم ؟؟\n",
            "تفصیلش زیاده، باید حرف خودشو میزد دیگه چقد بقیه رو نقد کرده..\n",
            "تفصیلش زیاده، باید حرف خودشو میزد دیگه چقد بقیه رو نقد کرده..\n",
            "نشریه دارای محتوای بسیار خوبی می باشد با توجه به اینکه مانند سایر مجلات این حوزه دارای تبلیغات بی شماری نیست \n",
            "نشریه دارای محتوای بسیار خوبی می باشد با توجه به اینکه مانند سایر مجلات این حوزه دارای تبلیغات بی شماری نیست \n",
            "به نظر من مجله جالبی بود\n",
            "به نظر من مجله جالبی بود\n",
            "ولی به نظر من خیلی خوبه. این ماهنامه کاملا تخصصیه. شاید عکس نداشته باشه که کسی خوشش بیاد یا نه. چیزی که مهمه محتوای ماهنامه هست\n",
            "ولی به نظر من خیلی خوبه. این ماهنامه کاملا تخصصیه. شاید عکس نداشته باشه که کسی خوشش بیاد یا نه. چیزی که مهمه محتوای ماهنامه هست\n",
            "افتضاحه\n",
            "افتضاحه\n",
            "من خیلی از داستان هایش خوشم می اید\n",
            "من خیلی از داستان هایش خوشم می اید\n",
            "باسلام\n",
            "خیلی وقت بود که دنبال یک کتاب مفید، آموزنده برای قصه های هر شب پسرم می گشتم.\n",
            "وقتی چند روز قبل تو تلویزیون تیزر فیلم کارتونی کلیله و دمنه را دیدم، یاد بخشی از این کتاب تو دوره مدرسه افتادم. واسه همین دانلودش کردم و هر شب داریم از قصه هاش لذت می بریم.\n",
            "باتشکر\n",
            "باسلام\n",
            "خیلی وقت بود که دنبال یک کتاب مفید، آموزنده برای قصه های هر شب پسرم می گشتم.\n",
            "وقتی چند روز قبل تو تلویزیون تیزر فیلم کارتونی کلیله و دمنه را دیدم، یاد بخشی از این کتاب تو دوره مدرسه افتادم. واسه همین دانلودش کردم و هر شب داریم از قصه هاش لذت می بریم.\n",
            "باتشکر\n",
            "کتاب قشنگیه.\n",
            "حیوون های جنگل انگار هر کدومشون یک آدمن با روحیات مختلف:)\n",
            "کتاب قشنگیه.\n",
            "حیوون های جنگل انگار هر کدومشون یک آدمن با روحیات مختلف:)\n",
            "یکی از پر بار ترین داستان های ایرانی.. بعد دوستمون میگه قیمت زیاده به نسبت محتوی!!!\n",
            "یکی از پر بار ترین داستان های ایرانی.. بعد دوستمون میگه قیمت زیاده به نسبت محتوی!!!\n",
            "قشنگه اما قیمتش زیاده به نسبت محتواش\n",
            "قشنگه اما قیمتش زیاده به نسبت محتواش\n",
            "خوندنشون برای بچه ها عالیه\n",
            "خوندنشون برای بچه ها عالیه\n",
            "کتب یادگاران خیلی خوب هستید فقط یه بدی که دارند اینه که بعضی از خاطره ها رو نمیشه متوجه شد از زبان چه کسی هست.\n",
            "کتب یادگاران خیلی خوب هستید فقط یه بدی که دارند اینه که بعضی از خاطره ها رو نمیشه متوجه شد از زبان چه کسی هست.\n",
            "کتاب رو دوست داشتم چون نویسنده بی هیچ کلیشه ای و در قالب یک داستان نمادین با روایت جذاب و شخصیت پردازی قوی رنج های یک ملت رو بیان کرده بود خیلی خوب شخصیت ها رو به هم ربط داد و غافلگیری خوبی داشت در اواخر داستان در ضمن ترجمه خیلی خوب و روان بود\n",
            "کتاب رو دوست داشتم چون نویسنده بی هیچ کلیشه ای و در قالب یک داستان نمادین با روایت جذاب و شخصیت پردازی قوی رنج های یک ملت رو بیان کرده بود خیلی خوب شخصیت ها رو به هم ربط داد و غافلگیری خوبی داشت در اواخر داستان در ضمن ترجمه خیلی خوب و روان بود\n",
            "تنها کتابیه که هر سال میخونمش و حس خوبی بهم میده\n",
            "تنها کتابیه که هر سال میخونمش و حس خوبی بهم میده\n",
            "تنها کتابی که پنج سال از خوندنش گذشته و هنوووز برام جذابه\n",
            "تنها کتابی که پنج سال از خوندنش گذشته و هنوووز برام جذابه\n",
            "توجه: این، یک کتاب عادی نیست! آخرین انار دنیا، دنیایی از سمبل ها و استعاره هاست.. لطفا با احتیاط بخوانید. لطفا عمیق بخوانید.\n",
            "توجه: این، یک کتاب عادی نیست! آخرین انار دنیا، دنیایی از سمبل ها و استعاره هاست.. لطفا با احتیاط بخوانید. لطفا عمیق بخوانید.\n",
            "کتاب خیلی خیلی خوبی بود.\n",
            "موضوعاتی مثل جنگ،محرومیت،یتیمی و ....رو در قالب نماد های سریاس مانند و محمد دل شیشه ای و...نشون میده.خیلی کتاب خوبیه.\n",
            "من رو خیلی یاد کتاب بادبادک‌باز انداخت.اونم مثل همین کتاب خیلی خوبه\n",
            "کتاب خیلی خیلی خوبی بود.\n",
            "موضوعاتی مثل جنگ،محرومیت،یتیمی و ....رو در قالب نماد های سریاس مانند و محمد دل شیشه ای و...نشون میده.خیلی کتاب خوبیه.\n",
            "من رو خیلی یاد کتاب بادبادک‌باز انداخت.اونم مثل همین کتاب خیلی خوبه\n",
            "ممنون از بابت تخفیف🙏\n",
            "ممنون از بابت تخفیف\n",
            "کتاب رئالیسم جادویی بی نظری داره خواننده رو پا به پای خودش میان سلول انفرادی صخره هاو.. می کشونه\n",
            "مترجم(مریوان حلبچه ای) تسلط کاملی بر هر دو زبون داره و کاملا بر متن ترجمه سواره متاسفانه مترجم های دیگه نسبتا تحت الفظی ترجمه کردن بعید بدونم حتی خودشون هم بفهمن چی ترجمه کردن\n",
            "کتاب رئالیسم جادویی بی نظری داره خواننده رو پا به پای خودش میان سلول انفرادی صخره هاو.. می کشونه\n",
            "مترجم(مریوان حلبچه ای) تسلط کاملی بر هر دو زبون داره و کاملا بر متن ترجمه سواره متاسفانه مترجم های دیگه نسبتا تحت الفظی ترجمه کردن بعید بدونم حتی خودشون هم بفهمن چی ترجمه کردن\n",
            "به واسطه حضور چندین ساله‌م در استان کردستان و درک فرهنگ این قوم هنرمند و علاقه‌م به ادبیات و فرهنگ این خطه باید عرض کنم که به نظر من بختیار علی و شیرزاد حسن رو میشه جزء بهترین نویسنده‌های کرد زبان حساب کرد.\n",
            "همچنین با توجه به خوانش چندین ترجمه از کتابهای این عزیزان به قلم سایر مترجمین، باید بگم ترجمه‌های آقای نریوان حلبچه‌ای عالین.\n",
            "خوندن این کتاب و کتاب \"حصار و سگهای پدری\" از استاد شیرزاد حسن رو به شدت توصیه میکنم.\n",
            "به واسطه حضور چندین ساله‌م در استان کردستان و درک فرهنگ این قوم هنرمند و علاقه‌م به ادبیات و فرهنگ این خطه باید عرض کنم که به نظر من بختیار علی و شیرزاد حسن رو میشه جزء بهترین نویسنده‌های کرد زبان حساب کرد.\n",
            "همچنین با توجه به خوانش چندین ترجمه از کتابهای این عزیزان به قلم سایر مترجمین، باید بگم ترجمه‌های آقای نریوان حلبچه‌ای عالین.\n",
            "خوندن این کتاب و کتاب \"حصار و سگهای پدری\" از استاد شیرزاد حسن رو به شدت توصیه میکنم.\n",
            "درسته ارزش کتاب بالاست\n",
            "امایه خواهش دارم اونم اینه که کتابای رایگان بیشتری بزارید\n",
            "خعلی خعلی ممنون میشم😞\n",
            "متأسفانه پول نداشتم این کتابم بخرم ولی چکیده هایی ازمتنشو خوندم خعلی قشنگ بود\n",
            "وخیلی مشتاقم که این کتابو کامل بخونم😍\n",
            "درسته ارزش کتاب بالاست\n",
            "امایه خواهش دارم اونم اینه که کتابای رایگان بیشتری بزارید\n",
            "خعلی خعلی ممنون میشم\n",
            "متأسفانه پول نداشتم این کتابم بخرم ولی چکیده هایی ازمتنشو خوندم خعلی قشنگ بود\n",
            "وخیلی مشتاقم که این کتابو کامل بخونم\n",
            "شک نکنید این ترجمه بهترین است\n",
            "ترجمه آقای سنجابی مقدار زیادی حذفیات دارد\n",
            "شک نکنید این ترجمه بهترین است\n",
            "ترجمه آقای سنجابی مقدار زیادی حذفیات دارد\n",
            "چطوری باید سقارش بدم ک بفرستن واسم دم خونه؟\n",
            "چطوری باید سقارش بدم ک بفرستن واسم دم خونه؟\n",
            "به دوستانی که این کتاب رو نخوندن به شدت توصیه ش میکنم. عالی عالی عالی. 👍👍👍\n",
            "به دوستانی که این کتاب رو نخوندن به شدت توصیه ش میکنم. عالی عالی عالی. \n",
            "در بخش جزییات کتاب توضیحات خیلی خوبی در باب کتاب ذکر شده .\n",
            "در این کتاب نویسنده برای درک بهتر احوال درونی شخصیتهای داستان مثال های احساسی زیادی را روایت می کندکه نوعی شاعرانگی زیبا را خلق میکند\n",
            "بختیار علی با این کتاب مارا با عواقب جنگ _بویژه جنگ داخلی_ آشنا میکند.\n",
            "کتابی بشدت قوی؛ در ترسیم احساس ها\n",
            "در مذمت جنگ و جنگاوران در ستایش عشق\n",
            "در توصیف تنهایی\n",
            "در بخش جزییات کتاب توضیحات خیلی خوبی در باب کتاب ذکر شده .\n",
            "در این کتاب نویسنده برای درک بهتر احوال درونی شخصیتهای داستان مثال های احساسی زیادی را روایت می کندکه نوعی شاعرانگی زیبا را خلق میکند\n",
            "بختیار علی با این کتاب مارا با عواقب جنگ _بویژه جنگ داخلی_ آشنا میکند.\n",
            "کتابی بشدت قوی؛ در ترسیم احساس ها\n",
            "در مذمت جنگ و جنگاوران در ستایش عشق\n",
            "در توصیف تنهایی\n",
            "نثر و فضاسازی عالی.\n",
            "نثر و فضاسازی عالی.\n",
            "کودوم ترجمه و انتشارات بهتره واسه این کتاب؟؟\n",
            "کودوم ترجمه و انتشارات بهتره واسه این کتاب؟؟\n",
            "واقعا کتاب بی نظیری بود. بهترین رمانی بود که تا حالا خوندم\n",
            "واقعا کتاب بی نظیری بود. بهترین رمانی بود که تا حالا خوندم\n",
            "در طی یکی از جنگ های کردستان، دو دوست به نام های \"مظفر صبحدم\" و \"یعقوب صنوبر\" در آستانه ی دستگیری به وسیله ی دشمن قرار میگیرن. مظفر صبحدم فداکاری میکنه و تن به اسارت میده تا یعقوب صنوبر فرصت فرار پیدا کنه. و فقط از اون خواهش میکنه تا مراقب پسر تازه متولد شده و بی مادرش \"سریاس صبحدم\" باشه. مظفر صبحدم بیست و یک سال زندانی میشه و طی این سال ها اتفاقات و جنگ های متعددی رخ میده ،حزب اون ها پیروز میشه و یعقوب صنوبر به عنوان رهبر به قدرت میرسه. اما مظفر صبحدم بعد از آزادی متوجه میشه که همه چیز کاملا تغییر کرده و با تصورات اون متفاوته. بعد از آزادی تلاش میکنه تا پسرش رو پیدا کنه و این سرآغاز داستان ها و اتفاقات متعددیه که انتظارش رو میکشن. راز های متعددی که نیاز به رمزگشایی و کشف شدن دارن.\n",
            "\n",
            "کتاب در مذمت جنگ نوشته شده. اینکه جنگ ها با هر هدفی هم که انجام بشن، حاصلی جز تباهی، سیاهی، ویرانی، فقر، سوختگی و نابودی انسان های بی گناه ندارن. اگرچه موضوع جذابیه و البته این کتاب به شدت معروفه، من خیلی ازش لذت نبردم. بنظرم کتاب های خیلی جذاب تر و تکان دهنده تری هم در این زمینه و موضوع وجود دارن. بخصوص اینکه، با وجود قسمتای اسرارآمیز و تخیلی درون کتاب، انتظار پایان متفاوت تر و غیرقابل پیش بینی تری داشتم. البته کتاب پر از جملات نغز و پرمفهومیه که دقیق تر خوندنش میتونه باعث بشه مفاهیم عمیق تری از کتاب برداشت بشه.\n",
            "در طی یکی از جنگ های کردستان، دو دوست به نام های \"مظفر صبحدم\" و \"یعقوب صنوبر\" در آستانه ی دستگیری به وسیله ی دشمن قرار میگیرن. مظفر صبحدم فداکاری میکنه و تن به اسارت میده تا یعقوب صنوبر فرصت فرار پیدا کنه. و فقط از اون خواهش میکنه تا مراقب پسر تازه متولد شده و بی مادرش \"سریاس صبحدم\" باشه. مظفر صبحدم بیست و یک سال زندانی میشه و طی این سال ها اتفاقات و جنگ های متعددی رخ میده ،حزب اون ها پیروز میشه و یعقوب صنوبر به عنوان رهبر به قدرت میرسه. اما مظفر صبحدم بعد از آزادی متوجه میشه که همه چیز کاملا تغییر کرده و با تصورات اون متفاوته. بعد از آزادی تلاش میکنه تا پسرش رو پیدا کنه و این سرآغاز داستان ها و اتفاقات متعددیه که انتظارش رو میکشن. راز های متعددی که نیاز به رمزگشایی و کشف شدن دارن.\n",
            "\n",
            "کتاب در مذمت جنگ نوشته شده. اینکه جنگ ها با هر هدفی هم که انجام بشن، حاصلی جز تباهی، سیاهی، ویرانی، فقر، سوختگی و نابودی انسان های بی گناه ندارن. اگرچه موضوع جذابیه و البته این کتاب به شدت معروفه، من خیلی ازش لذت نبردم. بنظرم کتاب های خیلی جذاب تر و تکان دهنده تری هم در این زمینه و موضوع وجود دارن. بخصوص اینکه، با وجود قسمتای اسرارآمیز و تخیلی درون کتاب، انتظار پایان متفاوت تر و غیرقابل پیش بینی تری داشتم. البته کتاب پر از جملات نغز و پرمفهومیه که دقیق تر خوندنش میتونه باعث بشه مفاهیم عمیق تری از کتاب برداشت بشه.\n",
            "واقعا که لذت بردم\n",
            "واقعا که لذت بردم\n",
            "این کتاب عالیه من یبار خوندمش ولی باز دنبالش بودم ک بخونمش:)\n",
            "این کتاب عالیه من یبار خوندمش ولی باز دنبالش بودم ک بخونمش:)\n",
            "تعریف این کتابو زیاد شنیدم.ـ\n",
            "کاش رایگان بشه\n",
            "تعریف این کتابو زیاد شنیدم.ـ\n",
            "کاش رایگان بشه\n",
            "عالیه ...نسخه ی زبان اصلیش اگر باشه عالیه..لطفا بذارید\n",
            "عالیه ...نسخه ی زبان اصلیش اگر باشه عالیه..لطفا بذارید\n",
            "خیلی گران من نمیتونم بخرمش پولی ندارم لطفاً کمکم کنید تخفیف بدید\n",
            "خیلی گران من نمیتونم بخرمش پولی ندارم لطفاً کمکم کنید تخفیف بدید\n",
            "ولی ترجمه آرش سنجابی بهتره. یعنی عالیه.\n",
            "ولی ترجمه آرش سنجابی بهتره. یعنی عالیه.\n",
            "کتاب عالیه . ولی خیلی گرونه. امیدوارم تجدید نظری بشه . شیرکو بی که س پیشنهاد این کتابو کرده که حتما قبل از مرگ بخونید .\n",
            "کتاب عالیه . ولی خیلی گرونه. امیدوارم تجدید نظری بشه . شیرکو بی که س پیشنهاد این کتابو کرده که حتما قبل از مرگ بخونید .\n",
            "زیادی گرون نیست ؟\n",
            "زیادی گرون نیست ؟\n",
            "تعریف این کتاب رو خیلی شنیده بودم, دنبالش بودم بخرمش, خدارو شکر که اومد رو طاقچه\n",
            "تعریف این کتاب رو خیلی شنیده بودم, دنبالش بودم بخرمش, خدارو شکر که اومد رو طاقچه\n",
            "جملاتی از \"ساموئل بکت\" ،\n",
            "-هیج چیز بامزه تر از شاد بودن نیست.\n",
            "مطمئن باشید،بله،بله، شاد \"نبودن\"  مسخره ترین چیز دنیاست.\n",
            "\n",
            "-گاهی فقط باید لبخند بزنی و رد شوی.بگذار فکر کنند نفهمیدی.\n",
            "جملاتی از \"ساموئل بکت\" ،\n",
            "-هیج چیز بامزه تر از شاد بودن نیست.\n",
            "مطمئن باشید،بله،بله، شاد \"نبودن\"  مسخره ترین چیز دنیاست.\n",
            "\n",
            "-گاهی فقط باید لبخند بزنی و رد شوی.بگذار فکر کنند نفهمیدی.\n",
            "بکت واقعا خوبه\n",
            "بکت واقعا خوبه\n",
            "کتاب فوق العاده جالبیه .من که خوشم اومد. \n",
            "کتاب فوق العاده جالبیه .من که خوشم اومد. \n",
            "خوندنش حس خوبی بهم نداد و بعضی جاهاش خیلی تعجب کردم!\n",
            "خوندنش حس خوبی بهم نداد و بعضی جاهاش خیلی تعجب کردم!\n",
            "واقعاکتاب جالبی بود...کوتاه ولی پرمحتواولذت بخش😍😍\n",
            "شخصیت شهیدزین الدین تاحدودی دستم اومد یک انسان آروم مهربون باچشمان نافذوقلبی دریایی...\n",
            "خوندن این کتاب روبه همه توصیه میکنم\n",
            "شادی روح همه شهداصلوات\n",
            "واقعاکتاب جالبی بود...کوتاه ولی پرمحتواولذت بخش\n",
            "شخصیت شهیدزین الدین تاحدودی دستم اومد یک انسان آروم مهربون باچشمان نافذوقلبی دریایی...\n",
            "خوندن این کتاب روبه همه توصیه میکنم\n",
            "شادی روح همه شهداصلوات\n",
            "من ده جلد از مجموعه های نیمه ی پنهان ماه و آسمان و اینک شوکران رو خوندم. یکی از یکی بهترن\n",
            "من ده جلد از مجموعه های نیمه ی پنهان ماه و آسمان و اینک شوکران رو خوندم. یکی از یکی بهترن\n",
            "نسخه چاپی با epub یک قیمت!!!؟\n",
            "نسخه چاپی با epub یک قیمت!!!؟\n",
            "توصیه‌میکنم نیمه پنهان۱ چمران به روایت همسر شهید رو مطالعه کنید.\n",
            "توصیه‌میکنم نیمه پنهان۱ چمران به روایت همسر شهید رو مطالعه کنید.\n",
            "من این کتاب رو خوندم. دوست عزیزی که میگن چاخان هست متاسفانه بی راه نمیگن. چون فرد مصاحبه کننده با همسر شهید در مدت ثبت و ضبط خاطرات، با ناشر به مشکل بر میخوره و کار رو ول میکنه.  بعد یک نویسنده دیگه میاد و خاطرات رو تبدیل به کتاب میکنه درحالی که از همسر شهید کسب اجازه نشده بوده و یک مقدار حرف های غلط غلوط داخل در  روایت زندگی میشه... من این رو از فرد مورد وثوقی شنیدم چون خودم بعد از خوندن کتاب دپرس شدم و اصلا اعصابم به هم ریخت و شهید زین الدین رو دیگه دوست نداشتم. ولی بعدا فهمیدم بدترین کتابی که ممکن بود نوشته بشه از زبان یک همسر شهید،  همین بوده و هست!\n",
            "من این کتاب رو خوندم. دوست عزیزی که میگن چاخان هست متاسفانه بی راه نمیگن. چون فرد مصاحبه کننده با همسر شهید در مدت ثبت و ضبط خاطرات، با ناشر به مشکل بر میخوره و کار رو ول میکنه.  بعد یک نویسنده دیگه میاد و خاطرات رو تبدیل به کتاب میکنه درحالی که از همسر شهید کسب اجازه نشده بوده و یک مقدار حرف های غلط غلوط داخل در  روایت زندگی میشه... من این رو از فرد مورد وثوقی شنیدم چون خودم بعد از خوندن کتاب دپرس شدم و اصلا اعصابم به هم ریخت و شهید زین الدین رو دیگه دوست نداشتم. ولی بعدا فهمیدم بدترین کتابی که ممکن بود نوشته بشه از زبان یک همسر شهید،  همین بوده و هست!\n",
            "همش چاخانه\n",
            "همش چاخانه\n",
            "سلام ...عالیه عالیه...\n",
            "سلام ...عالیه عالیه...\n",
            "سلام اگه همیشه مجموعه نیمه پنهان ماه ازشماره 1 تاآخرین شماره اش روبزاریدچون واقعایه مجموعه یی نظیره\n",
            "سلام اگه همیشه مجموعه نیمه پنهان ماه ازشماره 1 تاآخرین شماره اش روبزاریدچون واقعایه مجموعه یی نظیره\n",
            "بسیار عالی\n",
            "لطفا بیشتر از  کتاب های نیمه ی پنهان ماه بگذارید\n",
            "بسیار عالی\n",
            "لطفا بیشتر از  کتاب های نیمه ی پنهان ماه بگذارید\n",
            "کتاب های نیمه پنهان ماه عالی هستن، ایکاش همه مجموعه شو بگذارید\n",
            "کتاب های نیمه پنهان ماه عالی هستن، ایکاش همه مجموعه شو بگذارید\n",
            "نوشته‌های گیرای این شماره :\n",
            "۱.تورانیان در گذر تاریخ (بحث بر سر اینکه مردم توران کجا زندگی می‌کردند و ترک نبوده اند. )\n",
            "۲.رازگشایی از استورهٔ اژدهای کَشَف‌رود.\n",
            "نوشته‌های گیرای این شماره :\n",
            "۱.تورانیان در گذر تاریخ (بحث بر سر اینکه مردم توران کجا زندگی می‌کردند و ترک نبوده اند. )\n",
            "۲.رازگشایی از استورهٔ اژدهای کَشَف‌رود.\n",
            "سپیده دانایی و دکتر محمود گلزاری یعنی فرشته های راهنمایی و فریاد حقیقت بدون پرده و دلسوز جوانها بوسه بر دستهای پر مهرتون و دوستان طاقچه که خوش سلیقگی کردن و سپیده رو به جمع طاقچه اوردن تا ما همیشه همراهشون باشیم\n",
            "سپیده دانایی و دکتر محمود گلزاری یعنی فرشته های راهنمایی و فریاد حقیقت بدون پرده و دلسوز جوانها بوسه بر دستهای پر مهرتون و دوستان طاقچه که خوش سلیقگی کردن و سپیده رو به جمع طاقچه اوردن تا ما همیشه همراهشون باشیم\n",
            "از  دکتر علی فیضی بابت مطالب خوبی که در این شماره نوشته اند متشکرم\n",
            "از  دکتر علی فیضی بابت مطالب خوبی که در این شماره نوشته اند متشکرم\n",
            "تولدت مبارک کلیک عالی هستی فقط جنگ ستارگان برای xbox 360 کی میاد ممنون\n",
            "تولدت مبارک کلیک عالی هستی فقط جنگ ستارگان برای xbox 360 کی میاد ممنون\n",
            "طاقچه بهترین برنامه ایراانیه\n",
            "خواهش کتاب های روانشناسیزتحصیلی و برنامه نویسی بزارید\n",
            "طاقچه بهترین برنامه ایراانیه\n",
            "خواهش کتاب های روانشناسیزتحصیلی و برنامه نویسی بزارید\n",
            "من این کتاب رو به صورت چاپی خریدم عالی بود ممنون❤\n",
            "من این کتاب رو به صورت چاپی خریدم عالی بود ممنون\n",
            "سلام لطفا رایگان کنید ممنون .😘من یک قسمت دیگر ی از این مجموعه خوندنم عالی بود  😆\n",
            "سلام لطفا رایگان کنید ممنون .من یک قسمت دیگر ی از این مجموعه خوندنم عالی بود  \n",
            "سلام بنظر من زیاد جالب نبود،  نثر این کتاب بدرد بچه های دبستانی میخوره، زیادی سادش کردید، آدم دوست داره داستان های سعدی رو با ادبیات خودش بخونه، اصلا لذت بخش نیست، من این کتابو فقط به افراد زیر ۱۵ سال توصیه میکنم\n",
            "سلام بنظر من زیاد جالب نبود،  نثر این کتاب بدرد بچه های دبستانی میخوره، زیادی سادش کردید، آدم دوست داره داستان های سعدی رو با ادبیات خودش بخونه، اصلا لذت بخش نیست، من این کتابو فقط به افراد زیر ۱۵ سال توصیه میکنم\n",
            "فرماندهی جوان و نابغه که جنگ مدیون استراتژی های او بود\n",
            "فرماندهی جوان و نابغه که جنگ مدیون استراتژی های او بود\n",
            "\"آوای سرباز\"زندگی نامه جانباز شیمیایی ,صادق روشنی است. با اینکه راوی میتوانست با توضیح و توصیف بیشتر وقایع و سختیهایی که خود و خانواده اش تحمل کرده اند و افزودن آلبوم تصاویر,کتاب را جذابتر کند;اما بازهم \"آوای سرباز\"زیباست.و نام کتاب هم بسیار هنرمندانه انتخاب شده است.\n",
            "□□□\n",
            "در بخشی از کتاب میخوانیم:\n",
            "\"...یک روز دوتا خانم به ملاقاتم آمدند.یکی شان دختر بچه نوجوانی بود و دیگری حدود چهل سال سن داشت.دخترخانم درحالی که خیره خیره به صورت تاول زده ام نگاه میکرد,گفت:\n",
            "صورت شما چی شده؟\n",
            "با لبخند گفتم:\n",
            "چیز خاصی نشده,یک مقدار شیمیایی خورده ام.\n",
            "دخترخانم پرسید:\n",
            "برای چی رفتید جبهه که اینجور مجروح شوید و حالا روی تخت بیمارستان باشید؟\n",
            "لبخند زدم و برای چندلحظه سکوت کردم.بعد گفتم:اگر من نمیرفتم پس چه کسی باید میرفت؟چه کسی باید از دین و کشور و ملت دفاع میکرد؟...\"\n",
            "(آوای سرباز/سید محمد میرموسوی/صفحه124-125از نسخه الکترونیکی)\n",
            "\"آوای سرباز\"زندگی نامه جانباز شیمیایی ,صادق روشنی است. با اینکه راوی میتوانست با توضیح و توصیف بیشتر وقایع و سختیهایی که خود و خانواده اش تحمل کرده اند و افزودن آلبوم تصاویر,کتاب را جذابتر کند;اما بازهم \"آوای سرباز\"زیباست.و نام کتاب هم بسیار هنرمندانه انتخاب شده است.\n",
            "\n",
            "در بخشی از کتاب میخوانیم:\n",
            "\"...یک روز دوتا خانم به ملاقاتم آمدند.یکی شان دختر بچه نوجوانی بود و دیگری حدود چهل سال سن داشت.دخترخانم درحالی که خیره خیره به صورت تاول زده ام نگاه میکرد,گفت:\n",
            "صورت شما چی شده؟\n",
            "با لبخند گفتم:\n",
            "چیز خاصی نشده,یک مقدار شیمیایی خورده ام.\n",
            "دخترخانم پرسید:\n",
            "برای چی رفتید جبهه که اینجور مجروح شوید و حالا روی تخت بیمارستان باشید؟\n",
            "لبخند زدم و برای چندلحظه سکوت کردم.بعد گفتم:اگر من نمیرفتم پس چه کسی باید میرفت؟چه کسی باید از دین و کشور و ملت دفاع میکرد؟...\"\n",
            "(آوای سرباز/سید محمد میرموسوی/صفحه124-125از نسخه الکترونیکی)\n",
            "من نسخه چاپـــــــــــی رو دارم\n",
            "به شــــــــــدت افتضـــــــــــــــــــــــــاح، و بـــــــــــی مـــــــــــــزه\n",
            "من نسخه چاپـــــــــــی رو دارم\n",
            "به شــــــــــدت افتضـــــــــــــــــــــــــاح، و بـــــــــــی مـــــــــــــزه\n",
            "فقط نمونه رو خوندم و خوشم نیومد، طنز بی مزه ای بود، در حد ی نویسنده نبود!\n",
            "فقط نمونه رو خوندم و خوشم نیومد، طنز بی مزه ای بود، در حد ی نویسنده نبود!\n",
            "۴۹داستان کوتاه برگزیده، در دوره های مختلف جشنواره طنز مکتوب.\n",
            "\n",
            "من از داستان های \"دموکراسی در همه جا، طلاق در اولین روز ازدواج ،  این و اون ، یک داستان تقدیمی\" و..خوشم اومد.اما بعضی از داستان ها هم اصلا خوب نبودند و نتونستم تمومشون کنم.\n",
            "در کل خیلی خوب نبود،میتونست بهترم باشه با توجه به اینکه بیان شده بود که آثار شاخص انتخاب شدن.\n",
            "۴۹داستان کوتاه برگزیده، در دوره های مختلف جشنواره طنز مکتوب.\n",
            "\n",
            "من از داستان های \"دموکراسی در همه جا، طلاق در اولین روز ازدواج ،  این و اون ، یک داستان تقدیمی\" و..خوشم اومد.اما بعضی از داستان ها هم اصلا خوب نبودند و نتونستم تمومشون کنم.\n",
            "در کل خیلی خوب نبود،میتونست بهترم باشه با توجه به اینکه بیان شده بود که آثار شاخص انتخاب شدن.\n",
            "من خوشم نیومد.طنز داستان هاش مث برنامه های طنز دهه هفتاد بود!\n",
            "من خوشم نیومد.طنز داستان هاش مث برنامه های طنز دهه هفتاد بود!\n",
            "من  نمونشو خوندم خوب بود\n",
            "ولی نمی ارزه،قیمتش زیاده\n",
            "من  نمونشو خوندم خوب بود\n",
            "ولی نمی ارزه،قیمتش زیاده\n",
            "خیلی وقت پیش این کتابو توی طاقچه خوندم،کتاب جذابی نیست،من خوشم نیومد.....البته این نظر منه .....\n",
            "خیلی وقت پیش این کتابو توی طاقچه خوندم،کتاب جذابی نیست،من خوشم نیومد.....البته این نظر منه .....\n",
            "معمولی بود\n",
            "معمولی بود\n",
            "داستان جالب داشت \n",
            "اما داستان بی مزه هم داشت\n",
            "داستان جالب داشت \n",
            "اما داستان بی مزه هم داشت\n",
            "کتاب خیلی خوبیه . من که خوشم اومد .\n",
            "کتاب خیلی خوبیه . من که خوشم اومد .\n",
            "کنار بیا مینا😄😂\n",
            "کنار بیا مینا\n",
            "یکی از بهترین های بوتیمار\n",
            "یکی از بهترین های بوتیمار\n",
            "عرض ادب.\n",
            "چیزهایی که دست کم می گیریم،انسانی دیگر برای به دست آوردنش ،با خدا راز و نیاز می کند.\n",
            "نادر.\n",
            "عرض ادب.\n",
            "چیزهایی که دست کم می گیریم،انسانی دیگر برای به دست آوردنش ،با خدا راز و نیاز می کند.\n",
            "نادر.\n",
            "خیلی بچه گونه....  واسه سن دبستانی ها خوبه... اما ممنون بابت زحمتی که کشیدید.  اگه میشه تو قسمت اطلاعات بیشتر،  واسه هر کتاب گروه سنی اش رو هم بذارین.  تشکر\n",
            "خیلی بچه گونه....  واسه سن دبستانی ها خوبه... اما ممنون بابت زحمتی که کشیدید.  اگه میشه تو قسمت اطلاعات بیشتر،  واسه هر کتاب گروه سنی اش رو هم بذارین.  تشکر\n",
            "داستان های مثنوی پر از حکمته.در این کتاب به زبان ساده این داستان ها بیان شده...بسیار کتاب خوبیه\n",
            "داستان های مثنوی پر از حکمته.در این کتاب به زبان ساده این داستان ها بیان شده...بسیار کتاب خوبیه\n",
            "خوبه 😕\n",
            "خوبه \n",
            "کتابهای« زبان بدن» رشد زیادی کرده و تقریبا به حالت اشباع رسیده که مشهورترین آنها هم مربوط به آلن پیز هست.منتهی یک موردی هم هست که ممکنه قضیه را پیچیده کنه و اون آگاهی همگانی از این سبک روانشناختی است که ممکنه منجر به مهندسی معکوس بشه ، یعنی فرد یک سری رفتارهای خاص و حساب شده را به طور آگاهانه در پیش بگیره تا شخصیتی از پیش خواسته و طراحی شده را در ذهن مخاطبش القاء کنه\n",
            "یا کتابهایی که درباره تأثیرات اجتماعی شخصیتی و داشتن نفوذ کلام یا داشتن شخصیت کاریزماتیک هستند و وضعیت را بگونه ای بغرنج میکنه اگه همه بخواهند بر همدیگه تأثیر بذارند ، خب در اینصورت چه کسی تأثیر می پذیره؟؟؟\n",
            "کتابهای« زبان بدن» رشد زیادی کرده و تقریبا به حالت اشباع رسیده که مشهورترین آنها هم مربوط به آلن پیز هست.منتهی یک موردی هم هست که ممکنه قضیه را پیچیده کنه و اون آگاهی همگانی از این سبک روانشناختی است که ممکنه منجر به مهندسی معکوس بشه ، یعنی فرد یک سری رفتارهای خاص و حساب شده را به طور آگاهانه در پیش بگیره تا شخصیتی از پیش خواسته و طراحی شده را در ذهن مخاطبش القاء کنه\n",
            "یا کتابهایی که درباره تأثیرات اجتماعی شخصیتی و داشتن نفوذ کلام یا داشتن شخصیت کاریزماتیک هستند و وضعیت را بگونه ای بغرنج میکنه اگه همه بخواهند بر همدیگه تأثیر بذارند ، خب در اینصورت چه کسی تأثیر می پذیره؟؟؟\n",
            "کتاب جذابی ه\n",
            "کتاب جذابی ه\n",
            "تا حد زیادی اشاره به بدیهیات و مواردی هست که همه ما تا به حال متوجه شدیم ولی مطمئنا خوندنش باعث تثبیت همین دانسته ها میشه و کابردشون رو پر رنگ تر میکنه.اگر مسئولین سایت کتاب هنر همیشه بر حق بودن هم رو سایت بذارن برای علاقه مندان چنین موضوع هایی بدون شک بسیار بسیار کتاب جالبی خواهد بود. \n",
            "تا حد زیادی اشاره به بدیهیات و مواردی هست که همه ما تا به حال متوجه شدیم ولی مطمئنا خوندنش باعث تثبیت همین دانسته ها میشه و کابردشون رو پر رنگ تر میکنه.اگر مسئولین سایت کتاب هنر همیشه بر حق بودن هم رو سایت بذارن برای علاقه مندان چنین موضوع هایی بدون شک بسیار بسیار کتاب جالبی خواهد بود. \n",
            "با ۱۰۰ خاطره ی کوتاه از اسارت جنگ همراه بشید.....\n",
            "تلخه حقیقتا! ...غربت و دوری ، شکنجه ، گرسنگی ، بیماری و جراحت ، نبود ابتدایی ترین امکانات....\n",
            "اما این وسط کدبانویی اسرای عزیزمون هم جالبه!\n",
            "..................\n",
            "هر آسایشگاه یک تکه زمین کوچک داشت که توش کشاورزی میکردند.سبزی میکاشتند ، کاهو و چیزهای دیگر.\n",
            "غذا درست میکردیم با سبزی...کم می آمد ،کاهو میریختیم! باز هم کم می آمد هر چیز سبزی که در آمده بود ، میریختیم توش!!\n",
            "😊😅\n",
            "پ.ن : یاد آشپزهای دانشگاه مون افتادم!\n",
            "با ۱۰۰ خاطره ی کوتاه از اسارت جنگ همراه بشید.....\n",
            "تلخه حقیقتا! ...غربت و دوری ، شکنجه ، گرسنگی ، بیماری و جراحت ، نبود ابتدایی ترین امکانات....\n",
            "اما این وسط کدبانویی اسرای عزیزمون هم جالبه!\n",
            "..................\n",
            "هر آسایشگاه یک تکه زمین کوچک داشت که توش کشاورزی میکردند.سبزی میکاشتند ، کاهو و چیزهای دیگر.\n",
            "غذا درست میکردیم با سبزی...کم می آمد ،کاهو میریختیم! باز هم کم می آمد هر چیز سبزی که در آمده بود ، میریختیم توش!!\n",
            "\n",
            "پ.ن : یاد آشپزهای دانشگاه مون افتادم!\n",
            "100خاطره کوتاه از اُسرا خاطراتی از صبر و مقاومت این عزیزان.\n",
            "گفته بود مترجم نمیخوام خودم دردم رو میگم\n",
            "شکم درد داشت دکتر به ش  گفته بود چته؟\n",
            "به شکمش اشاره کرده بود و گفته بود :\n",
            "\n",
            "\"فی قُلوبهم مَرَضا \" دکتر هم بهش گفته بود \" فَزادَهُمُ\n",
            "\n",
            " اللّهُ مَرَضا\n",
            " **************\n",
            "کُرد  بود گیوه می بافت چنان با دقت زیرپوش های نخی را می شکافت که می شد یک نخ بلند از این سر اردوگاه تا آن سر بعد نخ ها رو می پیچید دو روز طول میکشید بعد آنها را چهار لا میکرد .یک تکه سیم خاردار صاف می کرد و سرش را هم بر می گرداند می شد سوزن .\n",
            "\n",
            "دمپایی ها را پاره می کرد روی کَفِش گیوه می بافت این آخریها که می آمدیم خیلی ها بلد بودن گیوه ببافند.\n",
            "100خاطره کوتاه از اُسرا خاطراتی از صبر و مقاومت این عزیزان.\n",
            "گفته بود مترجم نمیخوام خودم دردم رو میگم\n",
            "شکم درد داشت دکتر به ش  گفته بود چته؟\n",
            "به شکمش اشاره کرده بود و گفته بود :\n",
            "\n",
            "\"فی قُلوبهم مَرَضا \" دکتر هم بهش گفته بود \" فَزادَهُمُ\n",
            "\n",
            " اللّهُ مَرَضا\n",
            " **************\n",
            "کُرد  بود گیوه می بافت چنان با دقت زیرپوش های نخی را می شکافت که می شد یک نخ بلند از این سر اردوگاه تا آن سر بعد نخ ها رو می پیچید دو روز طول میکشید بعد آنها را چهار لا میکرد .یک تکه سیم خاردار صاف می کرد و سرش را هم بر می گرداند می شد سوزن .\n",
            "\n",
            "دمپایی ها را پاره می کرد روی کَفِش گیوه می بافت این آخریها که می آمدیم خیلی ها بلد بودن گیوه ببافند.\n",
            "اصلن معلوم نیست که طرف کی هستن :)))\n",
            "اصلن معلوم نیست که طرف کی هستن :)))\n",
            "کاملا جهت دار مینویسند\n",
            "کاملا جهت دار مینویسند\n",
            "دوستان کتاب خوبیه بخرمش ؟؟\n",
            "دوستان کتاب خوبیه بخرمش ؟؟\n",
            "این کتاب واقعا عالیه\n",
            "این کتاب واقعا عالیه\n",
            "کتابه جالبی بود نسخه چاپیش رو حدود۲ماه پیش خوندم ولی حیف کم بود زود تموم شد😔\n",
            "کتابه جالبی بود نسخه چاپیش رو حدود۲ماه پیش خوندم ولی حیف کم بود زود تموم شد\n",
            "دید جالبی داشت\n",
            "دید جالبی داشت\n",
            "قشنگ بود ولی دو تا عیب داشت یکی اینکه کم بود دیگری اینه اونقدری ازش انتظار داشتم نبود\n",
            "قشنگ بود ولی دو تا عیب داشت یکی اینکه کم بود دیگری اینه اونقدری ازش انتظار داشتم نبود\n",
            "عالیه ولی کمی\n",
            "عالیه ولی کمی\n",
            "این کتاب عالیه من نسخه چاپیشو خوندم . از دفتر خاطرات الاغ خیییلی جالبه😍😍 واقعا عالیه ❤\n",
            "این کتاب عالیه من نسخه چاپیشو خوندم . از دفتر خاطرات الاغ خیییلی جالبه واقعا عالیه \n",
            "همان طور که از اسم کتاب مشخص است \"دفتر خاطرات حیوانات \"مجموعه خاطراتی از حیوانات است که بر روی پوست نارگیل نوشته شده و علیرضا غفاری در فرصت کوتاهی که به دست آورده بود با اصرار فراوان توانسته از هر دفتر خاطرات یکی را انتخاب و در این کتاب بیاورد.\n",
            "کتاب طنز جذابی است از زبان حیوانات و گاه نقدی بر زندگی انسانها با استفاده از جزییاتی که این کتاب را از سایر آثار طنز متفاوت کرده است.\n",
            "□□□\n",
            "\"از دفتر خاطرات یک روباه\n",
            "داستان فریب\n",
            "قصه باور است\n",
            "خروس نادان نیاز به نیرنگ ندارد!\n",
            "امروز برای سیر شدن\n",
            "باید راست بگویم\n",
            "گرسنه ام!\"(صفحه91)\n",
            "\"از دفتر خاطرات یک شامپانزه\n",
            "...امروز یکی از آدمها درحالی که کتاب قطوری را ورق میزد,اصرار داشت به دوست همراهش ثابت کند که با ما فامیل هستند و در یک جهش تاریخی دم خود را از دست داده اند!\n",
            "اما من به شدت این رابطه را تکذیب میکنم!\"(صفحه47)\n",
            "\"از دفتر خاطرات یک زنبور\n",
            "امروز ملکه بسیار عصبانی بود و برعکس عمویم بسیار خوشحال!این را وقتی فهمیدم که موقع عبور از مقابل ملکه به دستور او کمی توقف کرد,پاهایش را به هم مالید,نگاهی به چشمان خمار ملکه کرد و زیر لب گفت:ویزز...\"(صفحه19)\n",
            "همان طور که از اسم کتاب مشخص است \"دفتر خاطرات حیوانات \"مجموعه خاطراتی از حیوانات است که بر روی پوست نارگیل نوشته شده و علیرضا غفاری در فرصت کوتاهی که به دست آورده بود با اصرار فراوان توانسته از هر دفتر خاطرات یکی را انتخاب و در این کتاب بیاورد.\n",
            "کتاب طنز جذابی است از زبان حیوانات و گاه نقدی بر زندگی انسانها با استفاده از جزییاتی که این کتاب را از سایر آثار طنز متفاوت کرده است.\n",
            "\n",
            "\"از دفتر خاطرات یک روباه\n",
            "داستان فریب\n",
            "قصه باور است\n",
            "خروس نادان نیاز به نیرنگ ندارد!\n",
            "امروز برای سیر شدن\n",
            "باید راست بگویم\n",
            "گرسنه ام!\"(صفحه91)\n",
            "\"از دفتر خاطرات یک شامپانزه\n",
            "...امروز یکی از آدمها درحالی که کتاب قطوری را ورق میزد,اصرار داشت به دوست همراهش ثابت کند که با ما فامیل هستند و در یک جهش تاریخی دم خود را از دست داده اند!\n",
            "اما من به شدت این رابطه را تکذیب میکنم!\"(صفحه47)\n",
            "\"از دفتر خاطرات یک زنبور\n",
            "امروز ملکه بسیار عصبانی بود و برعکس عمویم بسیار خوشحال!این را وقتی فهمیدم که موقع عبور از مقابل ملکه به دستور او کمی توقف کرد,پاهایش را به هم مالید,نگاهی به چشمان خمار ملکه کرد و زیر لب گفت:ویزز...\"(صفحه19)\n",
            "باحاله 😂😂😂😂😂😂😂😂\n",
            "باحاله \n",
            "باحال بود\n",
            "باحال بود\n",
            "جالب و باحاله😏😏😏\n",
            "جالب و باحاله\n",
            "سلام \n",
            "اعلام برنده های مسابقه رو چرا همش عقب میندازید\n",
            "مسخره اش درآوردید\n",
            "سلام \n",
            "اعلام برنده های مسابقه رو چرا همش عقب میندازید\n",
            "مسخره اش درآوردید\n",
            "برای 96 صفحه قیمتش زیاده\n",
            "برای 96 صفحه قیمتش زیاده\n",
            "روحت شاد ای شهید بزرگوار  گذری کوتاه از زندگی این شهید در قالب خاطرات کوتاهی که دیگران از ایشان داشتند واقعاً  که انسان بزرگی بودند\n",
            "روحت شاد ای شهید بزرگوار  گذری کوتاه از زندگی این شهید در قالب خاطرات کوتاهی که دیگران از ایشان داشتند واقعاً  که انسان بزرگی بودند\n",
            "خیلی کتاب جالبیه\n",
            "ترجمه خیلی خوبی هم داره\n",
            "در  زبان فارسی در مورد تئاتر مستند کتاب خیلی خیلی کم هست و این قطعا یکی از بهترین هاست\n",
            "خیلی کتاب جالبیه\n",
            "ترجمه خیلی خوبی هم داره\n",
            "در  زبان فارسی در مورد تئاتر مستند کتاب خیلی خیلی کم هست و این قطعا یکی از بهترین هاست\n",
            "مجموعه گزارشی شاهکار از یک نابغه با ترجمه ای فوق العاده خوب. ممنون از مترجم\n",
            "مجموعه گزارشی شاهکار از یک نابغه با ترجمه ای فوق العاده خوب. ممنون از مترجم\n",
            "متاسفانه حتی این ترجمه هم خوب و روان نبود، همچنان ترجمه ی همین کتاب رو با عنوان ننامیدنی با ترجمه ی مهدی نوید پیشنهاد میکنم.\n",
            "متاسفانه حتی این ترجمه هم خوب و روان نبود، همچنان ترجمه ی همین کتاب رو با عنوان ننامیدنی با ترجمه ی مهدی نوید پیشنهاد میکنم.\n",
            "از دوستان کسی میدونه ترجمه سمی بهتره یا این؟\n",
            "از دوستان کسی میدونه ترجمه سمی بهتره یا این؟\n",
            "به قول خود نویسنده، آقای کاظمی، این کتاب با کتابهای «احمد احمد» و «خاطرات عزت شاهی» سه گانه ای را شکل می دهند که همپوشانی زیادی دارند. حدود ۱۲ سال پیش خاطرات احمد احمد را خواندم که اولین کتاب از خاطرات پیش از انقلاب بود (البته بعدش هم خاطرات مرضیه حدیده چی را خواندم).... ولی کتاب عزت شاهی چیز دیگری بود... این کتاب در بسیاری از بخش ها مشابه عزت شاهی است (چون در زندان می گذرد و عملا حوادث را مرور می کند و بیشتر روی شخصیت ها توضیح می دهد) ، اما اصلا وارد جزییات نمی شود و از این نظر هیجانی ندارد... مثلا می گوید من را یک هفته شکنحه کردند و هیچ توضیحی درباره نحوه ی اتفاقات نمی دهد.. اگر زیرنویس ها نبود کتاب خیلی بی مایه می شد... به هر حال من اگر بخواهم کتابی پرحجم برای مبارزات پیش از انقلاب و آشنایی با مجاهدین معرفی کنم، قطعا خاطرات عزت شاهی را ترجیح می دهم چون واقعا جذاب و دقیق و کامل نوشته شده است...البته نکات جدیدی هم داشت این کتاب ولی با فاصله زیاد، پایین تر از خاطرات عزت شاهی قرار میگیره در این سه گانه تاریخی البته هر سه این کتاب ها به عنوان کارهای آقای کاظمی جای تقدیر دارند... ایشان با پاورقی های دقیق و غیرحانبدارانه شان ، نتیجه کار را یک مطالعه علمی تاریخی کرده اند\n",
            "به قول خود نویسنده، آقای کاظمی، این کتاب با کتابهای «احمد احمد» و «خاطرات عزت شاهی» سه گانه ای را شکل می دهند که همپوشانی زیادی دارند. حدود ۱۲ سال پیش خاطرات احمد احمد را خواندم که اولین کتاب از خاطرات پیش از انقلاب بود (البته بعدش هم خاطرات مرضیه حدیده چی را خواندم).... ولی کتاب عزت شاهی چیز دیگری بود... این کتاب در بسیاری از بخش ها مشابه عزت شاهی است (چون در زندان می گذرد و عملا حوادث را مرور می کند و بیشتر روی شخصیت ها توضیح می دهد) ، اما اصلا وارد جزییات نمی شود و از این نظر هیجانی ندارد... مثلا می گوید من را یک هفته شکنحه کردند و هیچ توضیحی درباره نحوه ی اتفاقات نمی دهد.. اگر زیرنویس ها نبود کتاب خیلی بی مایه می شد... به هر حال من اگر بخواهم کتابی پرحجم برای مبارزات پیش از انقلاب و آشنایی با مجاهدین معرفی کنم، قطعا خاطرات عزت شاهی را ترجیح می دهم چون واقعا جذاب و دقیق و کامل نوشته شده است...البته نکات جدیدی هم داشت این کتاب ولی با فاصله زیاد، پایین تر از خاطرات عزت شاهی قرار میگیره در این سه گانه تاریخی البته هر سه این کتاب ها به عنوان کارهای آقای کاظمی جای تقدیر دارند... ایشان با پاورقی های دقیق و غیرحانبدارانه شان ، نتیجه کار را یک مطالعه علمی تاریخی کرده اند\n",
            "\"اگر حرکتی نباشد,و فقط سکوت و سکون;معنایش این نیست که آب از آب تکانی نمیخورد.حرکت در رفتن لازمه اش تکان و لرزش است;گاهی کند گاهی تند...معنای این هم فقط بی قراری نیست.بلکه مهم قرار است,و مهم تر بی قراری هایی که قرار می آفرینند...\"(صفحه381)\n",
            "¤¤¤\n",
            "\"سالهای بی قرار\"خاطرات جواد منصوری است.جوانی که سالهای سال با رژیم طاغوت مبارزه کرد و در این راه هم رنج زندان را چشید,هم تبعید را ;وهم درد و زخمهایی را که در شکنجه گاه ها بر جسم و روحش نشست...جواد منصوری یکی از آن جوانهایی است که تا اکنون پای اعتقاداتش ایستاده است. این کتاب خاطرات اوست که هنگام حضور در اسلام آباد به تحریر در آمده است و با توانمندی ها و دانسته های محسن کاظمی در تدوین آن به یک منبع موثق در مورد سازمانها و گروهکها,شخصیتها ,حکومتها و...بدل شده است.\n",
            "¤¤¤\n",
            "\"...من معتقدم هیچ نوشته و تصویری نمیتواند تمام آنچه را که در این مدت[ ِمبارزات انقلابی]گذشت,باتمام ابعاد آن بیان کند و نشان دهد.عقده های قرنها و نسلها گشوده شد,انتظار طولانی یک ملت به پایان رسید;هرچند من تا نیمه های شب[ ِبیست و دو بهمن]در خیابانها بودم و صحنه های فراموش ناشدنی زیادی دیدم,ولی بعید میدانم که قادر به نوشتن[همه] آنها باشم...\"(صفحه448)\n",
            "¤¤¤\n",
            "\"...معلومه که هرکی تو زندگیش به خاطر راهی که میره ,پاهاش خسته میشه,زخمی میشه;هر چی راه پرپیچ و خم تر,زخمها هم عمیق تر,بعضی زخمها با اینکه جاشون میمونه اما خوب میشند;بعضی زخمها با اینکه جاشون نمیمونه,ولی هیچ وقت خوب نمیشند...\"(صفحه215)\n",
            "\"...گاهی احساس میکنم پاهای دلم خسته شده اند!خسته ازروزگار و بدعهدی هاش...چه شبها و روزها که با این پاها دویدم;به این طرف...به آن طرف...;در مقصد و در میانه راه به هرکِه رسیدم فریاد کردم,نفس به نفسشان دادم,و جان گرفتم و رفتم.اما الان ایستاده ام تا خستگی پاهایم را درکنم و نفسی دوباره بگیرم تا...\"(صفحه165)\n",
            "\"اگر حرکتی نباشد,و فقط سکوت و سکون;معنایش این نیست که آب از آب تکانی نمیخورد.حرکت در رفتن لازمه اش تکان و لرزش است;گاهی کند گاهی تند...معنای این هم فقط بی قراری نیست.بلکه مهم قرار است,و مهم تر بی قراری هایی که قرار می آفرینند...\"(صفحه381)\n",
            "¤¤¤\n",
            "\"سالهای بی قرار\"خاطرات جواد منصوری است.جوانی که سالهای سال با رژیم طاغوت مبارزه کرد و در این راه هم رنج زندان را چشید,هم تبعید را ;وهم درد و زخمهایی را که در شکنجه گاه ها بر جسم و روحش نشست...جواد منصوری یکی از آن جوانهایی است که تا اکنون پای اعتقاداتش ایستاده است. این کتاب خاطرات اوست که هنگام حضور در اسلام آباد به تحریر در آمده است و با توانمندی ها و دانسته های محسن کاظمی در تدوین آن به یک منبع موثق در مورد سازمانها و گروهکها,شخصیتها ,حکومتها و...بدل شده است.\n",
            "¤¤¤\n",
            "\"...من معتقدم هیچ نوشته و تصویری نمیتواند تمام آنچه را که در این مدت[ ِمبارزات انقلابی]گذشت,باتمام ابعاد آن بیان کند و نشان دهد.عقده های قرنها و نسلها گشوده شد,انتظار طولانی یک ملت به پایان رسید;هرچند من تا نیمه های شب[ ِبیست و دو بهمن]در خیابانها بودم و صحنه های فراموش ناشدنی زیادی دیدم,ولی بعید میدانم که قادر به نوشتن[همه] آنها باشم...\"(صفحه448)\n",
            "¤¤¤\n",
            "\"...معلومه که هرکی تو زندگیش به خاطر راهی که میره ,پاهاش خسته میشه,زخمی میشه;هر چی راه پرپیچ و خم تر,زخمها هم عمیق تر,بعضی زخمها با اینکه جاشون میمونه اما خوب میشند;بعضی زخمها با اینکه جاشون نمیمونه,ولی هیچ وقت خوب نمیشند...\"(صفحه215)\n",
            "\"...گاهی احساس میکنم پاهای دلم خسته شده اند!خسته ازروزگار و بدعهدی هاش...چه شبها و روزها که با این پاها دویدم;به این طرف...به آن طرف...;در مقصد و در میانه راه به هرکِه رسیدم فریاد کردم,نفس به نفسشان دادم,و جان گرفتم و رفتم.اما الان ایستاده ام تا خستگی پاهایم را درکنم و نفسی دوباره بگیرم تا...\"(صفحه165)\n",
            "با سلام.از کتاب بسیار خوب شما منونم\n",
            "با سلام.از کتاب بسیار خوب شما منونم\n",
            "اصلا  آدم رو جذب نمیکنه زیادی بی سرو تهه داستانهاش من که چندتای اولش رو خوندم دیگه ادامه ندادم\n",
            "اصلا  آدم رو جذب نمیکنه زیادی بی سرو تهه داستانهاش من که چندتای اولش رو خوندم دیگه ادامه ندادم\n",
            "واقعا این کتاب چاپ شده با این همه الفاظ رکیک\n",
            "و داستانهای زشت و بی معنی\n",
            "و سیاست زده\n",
            "واقعا این کتاب چاپ شده با این همه الفاظ رکیک\n",
            "و داستانهای زشت و بی معنی\n",
            "و سیاست زده\n",
            "کتاب چندان قوی نیست و داستان هاش جذابیت ندارن\n",
            "کتاب چندان قوی نیست و داستان هاش جذابیت ندارن\n",
            "نقاط مثبت : از بی کاری بهتره\n",
            "نقاط منفی: می فهمید هر کتابی ارزش خوندن نداره...معنی غبطه خوردن از عمر را درک می کنید....داستان ها ته ندارند...بی ادبی هم توش هست\n",
            "نقاط مثبت : از بی کاری بهتره\n",
            "نقاط منفی: می فهمید هر کتابی ارزش خوندن نداره...معنی غبطه خوردن از عمر را درک می کنید....داستان ها ته ندارند...بی ادبی هم توش هست\n",
            "صفر از صد\n",
            "بی هدف \n",
            "\n",
            "کاملا بی استعداد در نویسندگی\n",
            "انشاء دوران دبستانم خوندنی تر از این کتابه\n",
            "صفر از صد\n",
            "بی هدف \n",
            "\n",
            "کاملا بی استعداد در نویسندگی\n",
            "انشاء دوران دبستانم خوندنی تر از این کتابه\n",
            "در ضمن قیمت کتاب هم خیلی خوووبه\n",
            "ممنون طاقچه و بوتیمار\n",
            "در ضمن قیمت کتاب هم خیلی خوووبه\n",
            "ممنون طاقچه و بوتیمار\n",
            "مجموع داستان عالی و کم نقص که تک تک داستان هاش خوندنیه .\n",
            "مهران ابادی اینده ی خیلی خوبی در ادبیات داستانی خواهد داشت\n",
            "مجموع داستان عالی و کم نقص که تک تک داستان هاش خوندنیه .\n",
            "مهران ابادی اینده ی خیلی خوبی در ادبیات داستانی خواهد داشت\n",
            "کتاب نثر شاعرانه ای دارد ... بسیار زیباست ... مانند خواندن یک شعر بلند \n",
            "فضای داستان شبیه روایت یک خواب بلند است ...\n",
            "کتاب نثر شاعرانه ای دارد ... بسیار زیباست ... مانند خواندن یک شعر بلند \n",
            "فضای داستان شبیه روایت یک خواب بلند است ...\n",
            "اگه میخواید رمان بخونید یا حتا یه داستان بلند یا کوتاه اصلن پیشنهاد نمیکنم.\n",
            "کلن هم اگه نخونید هیچی رو از دست ندادین.\n",
            "اگه میخواید رمان بخونید یا حتا یه داستان بلند یا کوتاه اصلن پیشنهاد نمیکنم.\n",
            "کلن هم اگه نخونید هیچی رو از دست ندادین.\n",
            "به به به عااااالیه  ممنون از طاقچه و ثالث\n",
            "از رمان ها و مجموعه شعرهای احمدرضا احمدی باز هم روی طاقچه بگذارید\n",
            "به به به عااااالیه  ممنون از طاقچه و ثالث\n",
            "از رمان ها و مجموعه شعرهای احمدرضا احمدی باز هم روی طاقچه بگذارید\n",
            "این عالیه !\n",
            "این عالیه !\n",
            "دکتر شروین وکیلی درس خوانده ی جامعه شناسی است و با تاریخ ایران نیز آشنایی دارد. \n",
            "او در این کتاب برای تحلیل تاریخ و هویت ملیت ایرانی نقطه عزیمت خود را بر اسطوره ی معجزه یونان باستان گذاشته است که چگونه خاستگاه و اساس تحلیل ملیت در جهان قرار گرفته است. \n",
            "بدون تردید کتاب بسیار ارزشمندی است و سطحی از تحلیل را در فراروی خواننده قرار میدهد.\n",
            "دکتر شروین وکیلی درس خوانده ی جامعه شناسی است و با تاریخ ایران نیز آشنایی دارد. \n",
            "او در این کتاب برای تحلیل تاریخ و هویت ملیت ایرانی نقطه عزیمت خود را بر اسطوره ی معجزه یونان باستان گذاشته است که چگونه خاستگاه و اساس تحلیل ملیت در جهان قرار گرفته است. \n",
            "بدون تردید کتاب بسیار ارزشمندی است و سطحی از تحلیل را در فراروی خواننده قرار میدهد.\n",
            "بهشان گفته بودند: شیمیایی که زدند، اگه ماسک نبود، اگه رودخانه‌ای، چاله ی آبی دوروبر بود، بپرید توی آب! شیمیایی توی آب بی اثر میشود.\n",
            "***\n",
            "صورتش، دستهایش تا آرنج و روی پاهاش تاول زده بود. با آب نهر وضو گرفته بود... 😊\n",
            "_____________________\n",
            "از صبح هرچی عراقیِ زخمی آوردند، دادیم او عمل کرد. شاکی شد، گفت:\n",
            "بهشتی هاش رو خودتون عمل میکنید، جهنمی هاش رو میدین به من؟! 😊 😊\n",
            "(منبع: کتاب پزشکان)\n",
            "_____________________\n",
            "کتاب شاملی صد خاطره‌ی کوتاه و شیرین اِز شهدا/جانبازان گرانقدرس که خیلی ساده و شیک و به دل نِشین بیان شده آ بیشترشم دست مایه ی طنز دارِد 😊\n",
            "انصافا پیشنهاد میکونم:)\n",
            "بهشان گفته بودند: شیمیایی که زدند، اگه ماسک نبود، اگه رودخانه‌ای، چاله ی آبی دوروبر بود، بپرید توی آب! شیمیایی توی آب بی اثر میشود.\n",
            "***\n",
            "صورتش، دستهایش تا آرنج و روی پاهاش تاول زده بود. با آب نهر وضو گرفته بود... \n",
            "_____________________\n",
            "از صبح هرچی عراقیِ زخمی آوردند، دادیم او عمل کرد. شاکی شد، گفت:\n",
            "بهشتی هاش رو خودتون عمل میکنید، جهنمی هاش رو میدین به من؟!  \n",
            "(منبع: کتاب پزشکان)\n",
            "_____________________\n",
            "کتاب شاملی صد خاطره‌ی کوتاه و شیرین اِز شهدا/جانبازان گرانقدرس که خیلی ساده و شیک و به دل نِشین بیان شده آ بیشترشم دست مایه ی طنز دارِد \n",
            "انصافا پیشنهاد میکونم:)\n",
            "با ترجمه ای الکن...\n",
            "با ترجمه ای الکن...\n",
            "داستانخوبی بود\n",
            "داستانخوبی بود\n",
            "فکر نمیکردم به این زودی ترجمه اخرین رمان مودیانو رو از طاقچه بتونم بخونم\n",
            "فضای داستانی مثل بقیه نوشته های مودیانو فوق العادست\n",
            "فکر نمیکردم به این زودی ترجمه اخرین رمان مودیانو رو از طاقچه بتونم بخونم\n",
            "فضای داستانی مثل بقیه نوشته های مودیانو فوق العادست\n",
            "من اصلا دوسش نداشتم !! موضوعش خاص نبود دقیقا جایزه رو ب کجاش دادن؟؟؟؟\n",
            "من اصلا دوسش نداشتم !! موضوعش خاص نبود دقیقا جایزه رو ب کجاش دادن؟؟؟؟\n",
            "این نمایشنامه چجوری این همه جایزه داشت؟ خیلی معمولی بود.\n",
            "ولی متن کشش داشت\n",
            "این نمایشنامه چجوری این همه جایزه داشت؟ خیلی معمولی بود.\n",
            "ولی متن کشش داشت\n",
            "تخفیف 10 درصد:\n",
            "SB9866ZC7FKYV5\n",
            "تخفیف 10 درصد:\n",
            "SB9866ZC7FKYV5\n",
            "مغول ها بخشی از تاریخ جهانی  و تاریخ ایران در قرن هفتم هجری هستند که تأثیر ات آنها بر تاریخ ایران دارای تفاسیر چندگانه ای است.\n",
            "آنها از یک طرف در زمان خوارزمشاهیان  به خاطر تحریک آنها  به خاک ایران هجوم آورده و مناطق شرقی ایران را  ویران ساختند. اما از سوی دیگر تحت تاثیر وزرای اندیشمند ایرانی خود  مسلمان شده و باعث خدمات فرهنگی ارزشمندی در ایران شدند.\n",
            "از مباحث بسیار مهم و اساسی در تاریخ و فرهنگ مغول  ها در تمدن اسلامی ، براندازی خلافت عظیم عباسی و پایان دادن به عصر شب های « هزار و یکشب » در شهر افسانه ای بغداد است. اگرچه  داستان های هزار و یکشب مربوط به عصر هارون الرشید است.\n",
            "\n",
            "در باره تاریخ مغول یا ایلخانان کتابهای ارزشمند زیادی نوشته شده یا تحقیقات فراوانی صورت گرفته است.\n",
            "از منابع ارزشمند در این باره میتوان به آثار ارزشمند زیر اشاره کرد:\n",
            "رنه گروسه : امپراطوری صحرانوردان\n",
            "اقبال آشتیانی : تاریخ مغول \n",
            "بارتلد : امپراطوری مغول و حکومت جغتایی\n",
            "یواخیم بارکهاوزن : امپراطوری زرد\n",
            "خانم شیرین بیانی : نظام اجتماعی مغول \n",
            "شریک امین : اصطلاحات دیوانی عصر مغول\n",
            "پروفسور اشپولر : تاریخ مغول ( کتاب حاضر )\n",
            "\n",
            "پروفسور اشپولر در این کتاب مانند کتاب  ارزشمند « ایران در قرون نخستین اسلامی » با دقت و روحیه علمی  و روش شناسی تاریخی به برآمدن مغول در ایران ، جایگاه و سرزمین ، نژاد  و ماهیت تاریخی  آنان در تاریخ مشرق زمین خاصه شرق نزدیک و شمال غرب کشور چین و جنوب استپ های  سیبری  پرداخته  و جایگاه تاریخی آنان را مورد بررسی قرار داده است.\n",
            "بدون تردید کتاب حاضر کتاب ارزشمندی است .\n",
            "\n",
            "همت نوری\n",
            "مغول ها بخشی از تاریخ جهانی  و تاریخ ایران در قرن هفتم هجری هستند که تأثیر ات آنها بر تاریخ ایران دارای تفاسیر چندگانه ای است.\n",
            "آنها از یک طرف در زمان خوارزمشاهیان  به خاطر تحریک آنها  به خاک ایران هجوم آورده و مناطق شرقی ایران را  ویران ساختند. اما از سوی دیگر تحت تاثیر وزرای اندیشمند ایرانی خود  مسلمان شده و باعث خدمات فرهنگی ارزشمندی در ایران شدند.\n",
            "از مباحث بسیار مهم و اساسی در تاریخ و فرهنگ مغول  ها در تمدن اسلامی ، براندازی خلافت عظیم عباسی و پایان دادن به عصر شب های « هزار و یکشب » در شهر افسانه ای بغداد است. اگرچه  داستان های هزار و یکشب مربوط به عصر هارون الرشید است.\n",
            "\n",
            "در باره تاریخ مغول یا ایلخانان کتابهای ارزشمند زیادی نوشته شده یا تحقیقات فراوانی صورت گرفته است.\n",
            "از منابع ارزشمند در این باره میتوان به آثار ارزشمند زیر اشاره کرد:\n",
            "رنه گروسه : امپراطوری صحرانوردان\n",
            "اقبال آشتیانی : تاریخ مغول \n",
            "بارتلد : امپراطوری مغول و حکومت جغتایی\n",
            "یواخیم بارکهاوزن : امپراطوری زرد\n",
            "خانم شیرین بیانی : نظام اجتماعی مغول \n",
            "شریک امین : اصطلاحات دیوانی عصر مغول\n",
            "پروفسور اشپولر : تاریخ مغول ( کتاب حاضر )\n",
            "\n",
            "پروفسور اشپولر در این کتاب مانند کتاب  ارزشمند « ایران در قرون نخستین اسلامی » با دقت و روحیه علمی  و روش شناسی تاریخی به برآمدن مغول در ایران ، جایگاه و سرزمین ، نژاد  و ماهیت تاریخی  آنان در تاریخ مشرق زمین خاصه شرق نزدیک و شمال غرب کشور چین و جنوب استپ های  سیبری  پرداخته  و جایگاه تاریخی آنان را مورد بررسی قرار داده است.\n",
            "بدون تردید کتاب حاضر کتاب ارزشمندی است .\n",
            "\n",
            "همت نوری\n",
            "رمانی بسیار زیبا و شاعرانه که بانگاهی خلاقانه جنگ و تاثیرات آن بر مردم را به تصویر کشیده است.\n",
            "\n",
            "...و چقدر دلگیر است شهر بی کبوتر.\n",
            "رمانی بسیار زیبا و شاعرانه که بانگاهی خلاقانه جنگ و تاثیرات آن بر مردم را به تصویر کشیده است.\n",
            "\n",
            "...و چقدر دلگیر است شهر بی کبوتر.\n",
            "واقعاً کتاب جالبیه . من می خواستم از تمامی کسانی که در ساخت برنامه طاقچه  نقشی داشته اند ، صمیمانه تشکر کنم . جداً برنامه فوق العاده جالبیه و مهم تر از آن که گام بزرگی در رشد و توسعه صنعت کتاب و کتابخوانی برداشته است .\n",
            "واقعاً کتاب جالبیه . من می خواستم از تمامی کسانی که در ساخت برنامه طاقچه  نقشی داشته اند ، صمیمانه تشکر کنم . جداً برنامه فوق العاده جالبیه و مهم تر از آن که گام بزرگی در رشد و توسعه صنعت کتاب و کتابخوانی برداشته است .\n",
            "کی خوندش؟\n",
            "بگید چجوریه ؟\n",
            "کی خوندش؟\n",
            "بگید چجوریه ؟\n",
            "اسم کتاب بامزه اس\n",
            "اسم کتاب بامزه اس\n",
            "چه گرونه؟؟؟؟😞😞😞\n",
            "چه گرونه؟؟؟؟\n",
            "قشنگه..\n",
            "قشنگه..\n",
            "دوست داشتم👌\n",
            "دوست داشتم\n",
            "ناجوانمردانه گرونه\n",
            "ناجوانمردانه گرونه\n",
            "میخوام کتاب رو دریافت کنم کلمه عبور میخواد قسمت پرداخت از کجا باید کلمه عبور رو پیدا کنم؟\n",
            "میخوام کتاب رو دریافت کنم کلمه عبور میخواد قسمت پرداخت از کجا باید کلمه عبور رو پیدا کنم؟\n",
            "وقتی یه چیزی از بکت رو شروع میکنی توقع نداری که جز شاهکار با چیز دیگه ای طرف باشی!! زنده بود میرفتم بغلش میکردم! \n",
            "وقتی یه چیزی از بکت رو شروع میکنی توقع نداری که جز شاهکار با چیز دیگه ای طرف باشی!! زنده بود میرفتم بغلش میکردم! \n",
            "طرح جلدش عالیه، حتی قشنگ‌تر از زبان اصلیش شده\n",
            "طرح جلدش عالیه، حتی قشنگ‌تر از زبان اصلیش شده\n",
            "عالی! چیز دیگری نمیشه گفت\n",
            "عالی! چیز دیگری نمیشه گفت\n",
            "من نمونه شو خوندم گاهی نثر خودمونی میشد و محاوره .بعضی جاها محاوره و کتابی 😑انگار انسجام نداشت .چقدم بد لفظ نوشته بودند .مثلا راجب شوهرش .حتی اگه این ادم واقعی نباشه نباید توکتاب اینقد راجب یه ادمی که باهاش زندگی کردی بد بگی میانه روی خوبه حتی تو داستان پردازی .خوب کتاب الگو میشه برای یه عده ادم ..میخواستم کتابو بخرم بخونم ولی ترجیح دادم.نخونم\n",
            "من نمونه شو خوندم گاهی نثر خودمونی میشد و محاوره .بعضی جاها محاوره و کتابی انگار انسجام نداشت .چقدم بد لفظ نوشته بودند .مثلا راجب شوهرش .حتی اگه این ادم واقعی نباشه نباید توکتاب اینقد راجب یه ادمی که باهاش زندگی کردی بد بگی میانه روی خوبه حتی تو داستان پردازی .خوب کتاب الگو میشه برای یه عده ادم ..میخواستم کتابو بخرم بخونم ولی ترجیح دادم.نخونم\n",
            "من نمونه رو خوندم، از موضوعش خوشم اومد و حتی از قلم نویسنده؛ ولی بدزبونی راوی یه کم اذیت کننده س.. مثل رمانای سایت 98یاست.. نتونستم راضی کنم خودمو که بخرمش\n",
            "من نمونه رو خوندم، از موضوعش خوشم اومد و حتی از قلم نویسنده؛ ولی بدزبونی راوی یه کم اذیت کننده س.. مثل رمانای سایت 98یاست.. نتونستم راضی کنم خودمو که بخرمش\n",
            "مزخرف ترین کتابی بود که تا حالا خوندم\n",
            "فقط یکی به من بگه این خانوم چند تا شوهر داشت و این دوقولوها مال کدوم شوهرش بودن\n",
            "بدترین تصویری که از یک زن ایرانی می شد به تصویر کشید\n",
            "مزخرف ترین کتابی بود که تا حالا خوندم\n",
            "فقط یکی به من بگه این خانوم چند تا شوهر داشت و این دوقولوها مال کدوم شوهرش بودن\n",
            "بدترین تصویری که از یک زن ایرانی می شد به تصویر کشید\n",
            "گویا نویسنده کتابش را بر اساس اسطوره زر وان نوشته ،در روایت اساطیری زر وان آمده زر وان هزار سال قربانی کرد و در انتظار پسری ماند زمان دراز قربانی و انتظار طولانی او را در باب تاثیر ایین (گماننده)) ساخت درست در همان لحظه گمانندی دو موجود در بطن او جان گرفت هرمزد به پاس قربانی کردن و انتظار اهریمن به سزای گمانندی و ناشکیبایی زر وان قسم یادکرد که اگر هر کدام زودتر پای به هستی بگذارد فرمانروایی جهان را به او میدهد البته اول هرمزد را می خواست وبرای او قربانی کرده بود و می پنداشت هرمزد زودتر از بطنش بیرون می آید ولی هرمزد چون نیک سرشت بود این را با برادرش در میان گذاشت و اهریمن زشت خوی با ترفند زودتر بیرون امد و زروان شاخه ای برسم به هرمزد داد و گفت تا الان من برای تو قربانی کردم بعد از این تو برای من قربانی کن این شد جنگ بین هرمزد و اهریمن آغاز شد . بنابراین در ایین باستان زروان را خاستگاه همه چیز می دانسته اند که همه چیز از او آغاز می شود در حالی که خود خاستگاه و آغازی ندارد . کتاب موضوع جالبی داشت البته نگارش ضعیفی داشت تکه کلامهای زشت و نامربوط چاله میدانی شخشیت زن کتاب ارزش کتاب رو پایین آورده و هم ارزش این اسطوره قدیمی را و تناسبی با هم ندارند.از نویسنده های خانم بیش از این انتظار نمی رود\n",
            "گویا نویسنده کتابش را بر اساس اسطوره زر وان نوشته ،در روایت اساطیری زر وان آمده زر وان هزار سال قربانی کرد و در انتظار پسری ماند زمان دراز قربانی و انتظار طولانی او را در باب تاثیر ایین (گماننده)) ساخت درست در همان لحظه گمانندی دو موجود در بطن او جان گرفت هرمزد به پاس قربانی کردن و انتظار اهریمن به سزای گمانندی و ناشکیبایی زر وان قسم یادکرد که اگر هر کدام زودتر پای به هستی بگذارد فرمانروایی جهان را به او میدهد البته اول هرمزد را می خواست وبرای او قربانی کرده بود و می پنداشت هرمزد زودتر از بطنش بیرون می آید ولی هرمزد چون نیک سرشت بود این را با برادرش در میان گذاشت و اهریمن زشت خوی با ترفند زودتر بیرون امد و زروان شاخه ای برسم به هرمزد داد و گفت تا الان من برای تو قربانی کردم بعد از این تو برای من قربانی کن این شد جنگ بین هرمزد و اهریمن آغاز شد . بنابراین در ایین باستان زروان را خاستگاه همه چیز می دانسته اند که همه چیز از او آغاز می شود در حالی که خود خاستگاه و آغازی ندارد . کتاب موضوع جالبی داشت البته نگارش ضعیفی داشت تکه کلامهای زشت و نامربوط چاله میدانی شخشیت زن کتاب ارزش کتاب رو پایین آورده و هم ارزش این اسطوره قدیمی را و تناسبی با هم ندارند.از نویسنده های خانم بیش از این انتظار نمی رود\n",
            "هنوز نخوندم به نظرم خیلی قشنگه خلاصشو خوندم👍\n",
            "هنوز نخوندم به نظرم خیلی قشنگه خلاصشو خوندم\n",
            "قشنگگگگ بود\n",
            "قشنگگگگ بود\n",
            "من هنوز نخوندم ولی همینجوریش از اسم داستان معلومه زیباست\n",
            "من هنوز نخوندم ولی همینجوریش از اسم داستان معلومه زیباست\n",
            "باسلام کتاب خیلی زیبایی بود واقعا جذاب وگیرا،گاهی گیج کننده میشدولی بازهم جذابیتش راداشت،تشکرازنویسنده گرامی\n",
            "باسلام کتاب خیلی زیبایی بود واقعا جذاب وگیرا،گاهی گیج کننده میشدولی بازهم جذابیتش راداشت،تشکرازنویسنده گرامی\n",
            "این کتاب فوق العاده ، به قدر روان و زیباست که تا تمومش رو نخونید اون رو زمین نمیزارید.\n",
            "این کتاب فوق العاده ، به قدر روان و زیباست که تا تمومش رو نخونید اون رو زمین نمیزارید.\n",
            "سپاس از خانم خرمی برای نگاشتن این کتاب. از خوندنش لذت بردم. کار زیبایی بود. \n",
            "سپاس از خانم خرمی برای نگاشتن این کتاب. از خوندنش لذت بردم. کار زیبایی بود. \n",
            "سلام دوستان عزیز\n",
            "انتشارات آفرینگان(ناشر تخصصی کودک و نوجوان) و انتشارات هیلا(ناشر تخصصی داستان و ادبیات) ازیر مجموعه‌های انتشارات ققنوس هستند که امور قبل از چاپ و توزیع آن در گروه انتشاراتی ققنوس صورت می‌گیرد.\n",
            "سلام دوستان عزیز\n",
            "انتشارات آفرینگان(ناشر تخصصی کودک و نوجوان) و انتشارات هیلا(ناشر تخصصی داستان و ادبیات) ازیر مجموعه‌های انتشارات ققنوس هستند که امور قبل از چاپ و توزیع آن در گروه انتشاراتی ققنوس صورت می‌گیرد.\n",
            "دوست عزیز انتشارات آفرینگان و انتشارات هیلا زیر مجموعه انتشارت ققنوس هستند\n",
            "تو صفحه درباره ما وبسایت ققنوس هم اینو توضیح داده\n",
            "دوست عزیز انتشارات آفرینگان و انتشارات هیلا زیر مجموعه انتشارت ققنوس هستند\n",
            "تو صفحه درباره ما وبسایت ققنوس هم اینو توضیح داده\n",
            "فقط مطمنید این کتاب مال ققنوس ؟\n",
            "رو جلدش که زده هیلا !!!\n",
            "تو سایت ققنوسم نیست اصلا...\n",
            "فقط مطمنید این کتاب مال ققنوس ؟\n",
            "رو جلدش که زده هیلا !!!\n",
            "تو سایت ققنوسم نیست اصلا...\n",
            "عالی\n",
            "😍😍🌷🌷😘😘🌹🌹\n",
            "عالی\n",
            "\n",
            "کاش طاقچه امکان هدیه دادن کتاب رو اضافه می‌کرد چون اولین چیزی که بعد از خوندن این کتاب به ذهنم می‌رسید این بود که به چند نفر حتما هدیه بدمش. عالی بود. امیدوارم از این نویسنده باز هم کتاب روی طاقچه قرار بدید.\n",
            "کاش طاقچه امکان هدیه دادن کتاب رو اضافه می‌کرد چون اولین چیزی که بعد از خوندن این کتاب به ذهنم می‌رسید این بود که به چند نفر حتما هدیه بدمش. عالی بود. امیدوارم از این نویسنده باز هم کتاب روی طاقچه قرار بدید.\n",
            "کتاب جالبیه . من که خوشم اومد .\n",
            "کتاب جالبیه . من که خوشم اومد .\n",
            "چه جالب.... ماهنامه ی نجومی که دنبالش میکنم روز تولد منم بوده! در مورد چگونگی تشکیل ماه و خورشیده...در مورد سفر یه سفینه به خورشید!\n",
            "اونموقع میدونستن یه روزی رو جلدشون میزنن امکان دارد در قمر انسلادوس سیاره ی زحل حیات وجود داشته باشد؟ یا اینکه جهانهای موازی میتونن واقعی باشن؟ یا اینکه جهان داره با سرعت غیریکنواخت منبسط میشه؟ اونموقع هیجکدوم از اینها وجود نداشته....\n",
            "چه جالب.... ماهنامه ی نجومی که دنبالش میکنم روز تولد منم بوده! در مورد چگونگی تشکیل ماه و خورشیده...در مورد سفر یه سفینه به خورشید!\n",
            "اونموقع میدونستن یه روزی رو جلدشون میزنن امکان دارد در قمر انسلادوس سیاره ی زحل حیات وجود داشته باشد؟ یا اینکه جهانهای موازی میتونن واقعی باشن؟ یا اینکه جهان داره با سرعت غیریکنواخت منبسط میشه؟ اونموقع هیجکدوم از اینها وجود نداشته....\n",
            "بسیار عالی بود آقای لاهوری کسی بودن که در وسط فساد نماز تهجد شون قضا نمی شد من واقعا از شعر های اشون لذت میبرم\n",
            "بسیار عالی بود آقای لاهوری کسی بودن که در وسط فساد نماز تهجد شون قضا نمی شد من واقعا از شعر های اشون لذت میبرم\n",
            "من عاشق شعر های اقبال لاهوری هستم بسیار عالی هستش\n",
            "من عاشق شعر های اقبال لاهوری هستم بسیار عالی هستش\n",
            "...سفالم را می او جام جم کرد,,,درون قطره ام پوشیده یم کرد خرد اندر سرم بتخانه ای ریخت,,,خلیل عشق دیرم را حرم کرد. درود بیکران به روح با عظمت شاعر متفکر,حکیم آزاده..شاعر انسانیت ومعنا علامه اقبال.\n",
            "...سفالم را می او جام جم کرد,,,درون قطره ام پوشیده یم کرد خرد اندر سرم بتخانه ای ریخت,,,خلیل عشق دیرم را حرم کرد. درود بیکران به روح با عظمت شاعر متفکر,حکیم آزاده..شاعر انسانیت ومعنا علامه اقبال.\n",
            "سلام وعرض ادب\n",
            "کتابی بسیار زیبا وحکیمانه.\n",
            "سلام وعرض ادب\n",
            "کتابی بسیار زیبا وحکیمانه.\n",
            "چه شعرهای حکیمانه ایی دارد این اقبال لاهوری....\n",
            "الحق که شعرهایش آینه ایی از ذهن متفکر و حکمت اندیش او هست\n",
            "وقتی شعرهایش را میخوانی گویی در کلاس حکمت و تامل نشسته ایی و چه نیک آموزگاری است این اقبال لاهوری.\n",
            "چه شعرهای حکیمانه ایی دارد این اقبال لاهوری....\n",
            "الحق که شعرهایش آینه ایی از ذهن متفکر و حکمت اندیش او هست\n",
            "وقتی شعرهایش را میخوانی گویی در کلاس حکمت و تامل نشسته ایی و چه نیک آموزگاری است این اقبال لاهوری.\n",
            "ای نظر بر حسن ترسا زاده ای\n",
            "ای ز راه کعبه دور افتاده ای \n",
            "طرح عشق انداز اندر جان خویش\n",
            "تازه کن با مصطفی پیمان خویش\n",
            "\n",
            "بسیار بسیار عالی.با تشکر از طاقچه\n",
            "ای نظر بر حسن ترسا زاده ای\n",
            "ای ز راه کعبه دور افتاده ای \n",
            "طرح عشق انداز اندر جان خویش\n",
            "تازه کن با مصطفی پیمان خویش\n",
            "\n",
            "بسیار بسیار عالی.با تشکر از طاقچه\n",
            "قطعا اشعار اقبال ارزش مرور را دارند، واقعا جا دارد ک از این حرکت تشکر ویژه ای شود، انشاءالله ک اشعار بقیه هم کمکم ب این شیوه منتشر شوند.\n",
            "قطعا اشعار اقبال ارزش مرور را دارند، واقعا جا دارد ک از این حرکت تشکر ویژه ای شود، انشاءالله ک اشعار بقیه هم کمکم ب این شیوه منتشر شوند.\n",
            "اسم کتاب دقیقا با حال و هوای داخلش همخوانی داره. خوندن این قصه ها به ما یادآوری میکنه در طول تاریخ چه چیزایی برای مردم ما ارزش به حساب میومده و مردم ما درست و غلط رو چطور معنی میکردن. قصه هاش به وضوح عامیانه ان ولی بعضی وقتا به خوبی خواننده رو جذب میکنن طوری که گذر زمان رو نمیفهمی\n",
            "اسم کتاب دقیقا با حال و هوای داخلش همخوانی داره. خوندن این قصه ها به ما یادآوری میکنه در طول تاریخ چه چیزایی برای مردم ما ارزش به حساب میومده و مردم ما درست و غلط رو چطور معنی میکردن. قصه هاش به وضوح عامیانه ان ولی بعضی وقتا به خوبی خواننده رو جذب میکنن طوری که گذر زمان رو نمیفهمی\n",
            "در داستان دوم جمله ای زیبا وجود دارد. ؛؛اگر شهدا به پیش خدا می روند چرا مادرشان برایشان گریه میکنند؛؛ جمله ای بسیار تامل برانگیز :-)\n",
            "در داستان دوم جمله ای زیبا وجود دارد. ؛؛اگر شهدا به پیش خدا می روند چرا مادرشان برایشان گریه میکنند؛؛ جمله ای بسیار تامل برانگیز :-)\n",
            "باسلام داستان جذاب وبسیارخواندنی بود،توصیه میکنم حتمابخونیدش\n",
            "باسلام داستان جذاب وبسیارخواندنی بود،توصیه میکنم حتمابخونیدش\n",
            "100خاطره ی کوتاه درباره ی شهید دکتر مصطفی چمران...\n",
            "خاطرات به گونه ای انتخاب شدن که همه جور احساسی رو میتونید باهاشون تجربه کنید:عشق،احساس،غم،اندوه،لبخند و...\n",
            "خوندنش رو بعد از کتاب،چمران به روایت همسر شهید پیشنهاد میکنم😊\n",
            "بسیار لذت بخشه...\n",
            "100خاطره ی کوتاه درباره ی شهید دکتر مصطفی چمران...\n",
            "خاطرات به گونه ای انتخاب شدن که همه جور احساسی رو میتونید باهاشون تجربه کنید:عشق،احساس،غم،اندوه،لبخند و...\n",
            "خوندنش رو بعد از کتاب،چمران به روایت همسر شهید پیشنهاد میکنم\n",
            "بسیار لذت بخشه...\n",
            "از اون کتابهاییه که در حین مرور برهه‌ای از تاریخ دفاع مقدس در اثنای آن عاشقانه ای هم درجریانه‌. قشنگه .زندگی همیشه جریان داره!\n",
            "از اون کتابهاییه که در حین مرور برهه‌ای از تاریخ دفاع مقدس در اثنای آن عاشقانه ای هم درجریانه‌. قشنگه .زندگی همیشه جریان داره!\n",
            "چند سال پیش خونده بودمش.یکی از اون کتابهایی هست که در خاطرم میماند.عالی بود\n",
            "چند سال پیش خونده بودمش.یکی از اون کتابهایی هست که در خاطرم میماند.عالی بود\n",
            "من امروز تمومش کردم خیلی آخرش غم انگیز بود 😭😭\n",
            "من امروز تمومش کردم خیلی آخرش غم انگیز بود \n",
            "من متوجه نشدم اخرش\n",
            "جشمش کی خوب شد؟\n",
            "داستان با چشمم شروع شد اما بعد محو شد؟؟؟\n",
            "واسم ی معما شده ک چشمم چی شد بلاخره؟؟\n",
            "در کل کتاب خیلی قشنگی بود\n",
            "توصیه میکنم بخونینش\n",
            "من متوجه نشدم اخرش\n",
            "جشمش کی خوب شد؟\n",
            "داستان با چشمم شروع شد اما بعد محو شد؟؟؟\n",
            "واسم ی معما شده ک چشمم چی شد بلاخره؟؟\n",
            "در کل کتاب خیلی قشنگی بود\n",
            "توصیه میکنم بخونینش\n",
            "کتاب بسیار جالبی است و مخلوطی از دفاع مقدس و عاشقانه ای جالب به همراه  سختی های مسیر:\n",
            "که عشق اول نمود آسان ولی افتاد مشکلها\n",
            "کتاب بسیار جالبی است و مخلوطی از دفاع مقدس و عاشقانه ای جالب به همراه  سختی های مسیر:\n",
            "که عشق اول نمود آسان ولی افتاد مشکلها\n",
            "یک داستان واقعی و به شدت عاشقانه با پایانی بسیار تامل برانگیز.\n",
            "در جاهایی از کتاب می خوانیم که چگونه زندانی و زندانبان از جفای روزگار،  دست در گردن هم انداخته و گریه میکنند، کسانی که روزی به خون هم تشنه بودند، چگونه در اغوش یکدیگر گریه میکنند و تنها یک چیز در این میان واضح است: \n",
            "نفرین بر جنگ و درگیری و نفرین بر قدرت طلبی های سیاسی، که چگونه انسانهای عادی و بیگناه را به بدبختی و فلاکت و در به دری میکشاند.\n",
            "این کتاب بسیار روی من تاثیر گذاشت. خواندنش را به هر انسان حق طلب و ژرف اندیش توصیه میکنم.\n",
            "یک داستان واقعی و به شدت عاشقانه با پایانی بسیار تامل برانگیز.\n",
            "در جاهایی از کتاب می خوانیم که چگونه زندانی و زندانبان از جفای روزگار،  دست در گردن هم انداخته و گریه میکنند، کسانی که روزی به خون هم تشنه بودند، چگونه در اغوش یکدیگر گریه میکنند و تنها یک چیز در این میان واضح است: \n",
            "نفرین بر جنگ و درگیری و نفرین بر قدرت طلبی های سیاسی، که چگونه انسانهای عادی و بیگناه را به بدبختی و فلاکت و در به دری میکشاند.\n",
            "این کتاب بسیار روی من تاثیر گذاشت. خواندنش را به هر انسان حق طلب و ژرف اندیش توصیه میکنم.\n",
            "عالی،داستان خیلی خوبس داره.من نسخه چاپی رو دوسه سال پیش خوندم\n",
            "عالی،داستان خیلی خوبس داره.من نسخه چاپی رو دوسه سال پیش خوندم\n",
            "توپ توپ.اصلا نمیتونستم کتابو بذارم زمین.یه ماجرای عشقی تو دل اسارت.دمت گرم کیانوش جون!\n",
            "آقای گلزار راغب،الان دیدم یه کتاب دیگه هم نوشتید.بازم کتاب بنویسین.\n",
            "توپ توپ.اصلا نمیتونستم کتابو بذارم زمین.یه ماجرای عشقی تو دل اسارت.دمت گرم کیانوش جون!\n",
            "آقای گلزار راغب،الان دیدم یه کتاب دیگه هم نوشتید.بازم کتاب بنویسین.\n",
            "این کتاب زیباست ارزش کتاب خوندنش را دارد\n",
            "این کتاب زیباست ارزش کتاب خوندنش را دارد\n",
            "\"نخواهمت داشت تا فراموشت نکنم \" آخه اینم شد حرف!\n",
            "\"نخواهمت داشت تا فراموشت نکنم \" آخه اینم شد حرف!\n",
            "این کتاب عالیه، داستان اسارتی که منجر به عشقی سوزنده و نافرجام میشه. توصیه میشود خواندش\n",
            "این کتاب عالیه، داستان اسارتی که منجر به عشقی سوزنده و نافرجام میشه. توصیه میشود خواندش\n",
            "من خیلی نگران زخم چشم کیانوش بودم،ولی هیچی راجع بهش نگفت،یکی دو تا اشتباه هم داشت ،مثلا حسن مراد با برادرش شهید شده بود ولی میگه موقع آزادی اومد استقبالم و....\n",
            "من خیلی نگران زخم چشم کیانوش بودم،ولی هیچی راجع بهش نگفت،یکی دو تا اشتباه هم داشت ،مثلا حسن مراد با برادرش شهید شده بود ولی میگه موقع آزادی اومد استقبالم و....\n",
            "این چیه؟ عصرهای کریسکان چیه؟😮 یه خاطره دو کتاب؟! کسی هر دو رو خونده؟\n",
            "این چیه؟ عصرهای کریسکان چیه؟ یه خاطره دو کتاب؟! کسی هر دو رو خونده؟\n",
            "این کتاب رو به دوستان توصیه میکنم، فضای عاشقانه ترکیب شده با حال هوای جنگ و اسارت در این داستان خیلی جذاب و زیباست.\n",
            "این کتاب رو به دوستان توصیه میکنم، فضای عاشقانه ترکیب شده با حال هوای جنگ و اسارت در این داستان خیلی جذاب و زیباست.\n",
            "بله آقای وحید\n",
            "تازه آدم میفهمه چقدر فیلم هست که باید ساخته بشه... البته به نظر حضرتت یکمقدار چالش قومی قبیله ای ایجاد نمیکنه؟\n",
            "بله آقای وحید\n",
            "تازه آدم میفهمه چقدر فیلم هست که باید ساخته بشه... البته به نظر حضرتت یکمقدار چالش قومی قبیله ای ایجاد نمیکنه؟\n",
            "من کتاب درباره جنگ خیلی خوندم، اما انصافا این خیلی خوب و خاص بود و خیلی هم جا داره حتی تبدیل ب فیلم بشه،\n",
            "من کتاب درباره جنگ خیلی خوندم، اما انصافا این خیلی خوب و خاص بود و خیلی هم جا داره حتی تبدیل ب فیلم بشه،\n",
            "بله آقای ابوذر\n",
            "واقعا همینطوره\n",
            "بله آقای ابوذر\n",
            "واقعا همینطوره\n",
            "عالی،پیشنهاد میکنم بخونین.\n",
            "عالی،پیشنهاد میکنم بخونین.\n",
            "باسلام\n",
            "واقعا  کتاب خوبیه\n",
            "باسلام\n",
            "واقعا  کتاب خوبیه\n",
            "واقعا قبل از خوندن کتاب فکر نمی‌کردم با چنین اثر گیرایی مواجه بشم. داستان فقط روایت ساده‌ی یه رزمنده از دوران جبهه یا اسارت نیست. نویسنده بدون قضاوت کردن و فقط با ذکر خرده داستان‌های واقعی، خواننده رو به درک واقع‌گرایانه ای از  دغدغه‌ها و روحیات اجتماع در سال‌های اول انقلاب می‌رسونه. مضاف بر این خوانده درگیر عواطف شخصی شخصیت‌ها هم می‌شه که از این حیث تنه به تنه داستان‌های پرتب‌وتاب هالیوودی می‌زنه، با این تفاوت که خواننده می‌دونه با روایتی حقیقی طرف هست، نه یک افسانه.\n",
            "واقعا قبل از خوندن کتاب فکر نمی‌کردم با چنین اثر گیرایی مواجه بشم. داستان فقط روایت ساده‌ی یه رزمنده از دوران جبهه یا اسارت نیست. نویسنده بدون قضاوت کردن و فقط با ذکر خرده داستان‌های واقعی، خواننده رو به درک واقع‌گرایانه ای از  دغدغه‌ها و روحیات اجتماع در سال‌های اول انقلاب می‌رسونه. مضاف بر این خوانده درگیر عواطف شخصی شخصیت‌ها هم می‌شه که از این حیث تنه به تنه داستان‌های پرتب‌وتاب هالیوودی می‌زنه، با این تفاوت که خواننده می‌دونه با روایتی حقیقی طرف هست، نه یک افسانه.\n",
            "کتاب خوبی، آدم آخرش درگیر میمونه بازم...\n",
            "کتاب خوبی، آدم آخرش درگیر میمونه بازم...\n",
            "این کتاب از زبان کومه له به راحتی مرام مائوئیسم را تخریب کرده است \n",
            "در حالی که کشور پهناور چین مرام مائو را پذیرفته است\n",
            "ولی من هم با نظر شنام درباره کومه له موافق هستم\n",
            "این کتاب از زبان کومه له به راحتی مرام مائوئیسم را تخریب کرده است \n",
            "در حالی که کشور پهناور چین مرام مائو را پذیرفته است\n",
            "ولی من هم با نظر شنام درباره کومه له موافق هستم\n",
            "کتاب؛ فوق العاده ست، البته از نظر نگارشی و نوع ثبت و روایت شاید مشکلاتی داشته باشه، ولی روند کتاب اینقدر گیراست که این چیزها زیاد تاثیر نداره.\n",
            "با اینکه کتاب تموم شده ولی ولع من برای این کتاب تمام نشده\n",
            "کتاب؛ فوق العاده ست، البته از نظر نگارشی و نوع ثبت و روایت شاید مشکلاتی داشته باشه، ولی روند کتاب اینقدر گیراست که این چیزها زیاد تاثیر نداره.\n",
            "با اینکه کتاب تموم شده ولی ولع من برای این کتاب تمام نشده\n",
            "کتاب خوبیست\n",
            "\n",
            "کتاب أنیق؛ أللی یهتم بتعریف ما جری فی کوردستان إیرانی و مشددین یسمی ب\"کومه له\" فعلیه هالکتاب و أفضل لإخواننا المعاودین أن یهیئوه للآخرین بالغة العربیة\n",
            "و منی السلام و شکو ماکو\n",
            "کتاب خوبیست\n",
            "\n",
            "کتاب أنیق؛ أللی یهتم بتعریف ما جری فی کوردستان إیرانی و مشددین یسمی ب\"کومه له\" فعلیه هالکتاب و أفضل لإخواننا المعاودین أن یهیئوه للآخرین بالغة العربیة\n",
            "و منی السلام و شکو ماکو\n",
            "بد نبود\n",
            "عالی هم نبود😈\n",
            "بد نبود\n",
            "عالی هم نبود\n",
            "اسم کتاب جالب است و حتی عکسش و خود این باعث می شود که خواننده جذب شود\n",
            "اسم کتاب جالب است و حتی عکسش و خود این باعث می شود که خواننده جذب شود\n",
            "ممنون از طاقچه کار ارزشمندی انجام داد...\n",
            "ممنون از طاقچه کار ارزشمندی انجام داد...\n",
            "ممنون که رایگان بود.استفاده کردم ;-))\n",
            "ممنون که رایگان بود.استفاده کردم ;-))\n",
            "من ندیدم مجله رو ولی از روی جلدش و عناوین میشه گفت مجله نفتی ضعیف بنظر میاد که سعی در مجیز گویی دارد\n",
            "من ندیدم مجله رو ولی از روی جلدش و عناوین میشه گفت مجله نفتی ضعیف بنظر میاد که سعی در مجیز گویی دارد\n",
            "با سلام بسیار عالی و مناسب \n",
            "\n",
            "با سلام بسیار عالی و مناسب \n",
            "\n",
            "واقعا همش درسته خیلی این مجله خوبه واقعا درسته خیلی پول ها خرج میکنن\n",
            "واقعا همش درسته خیلی این مجله خوبه واقعا درسته خیلی پول ها خرج میکنن\n",
            "بعد تحقیقاتی مثل من متوجه میشین که آینده نداره__ ممنون\n",
            "بعد تحقیقاتی مثل من متوجه میشین که آینده نداره__ ممنون\n",
            "دوستان هرمی باز اینجا جمع شدن، امیدوارم جیبمون رو خالی نکنند. طرف شمارشو هم گذشته تا زیرشاخه جمع کنه😊\n",
            "دوستان هرمی باز اینجا جمع شدن، امیدوارم جیبمون رو خالی نکنند. طرف شمارشو هم گذشته تا زیرشاخه جمع کنه\n",
            "من دان کردم واقعا عالیه\n",
            "البته اگه بخواهید یکی از بهترینها باشید \n",
            "\n",
            "من دان کردم واقعا عالیه\n",
            "البته اگه بخواهید یکی از بهترینها باشید \n",
            "\n",
            "کتاب خوبی هست، با خوندنش نکته برداری کردم.اینجوری آدم میفهمه چه شرکتی کارش درسته و اینکه چطوری پیشرفت کنه.خدایارتان.\n",
            "کتاب خوبی هست، با خوندنش نکته برداری کردم.اینجوری آدم میفهمه چه شرکتی کارش درسته و اینکه چطوری پیشرفت کنه.خدایارتان.\n",
            "بازاریابی چند سطحی (mlm )یک استراتژی بازاریابی فروش مستقیم است که در آن بازاریاب علاوه بر پاداشی که بابت فروش مستقیم محصول دریافت می کند بابت فروش افرادی که توسط او استخدام شده اند نیز درآمدکسب میکند.افرادی که توسط بازاریاب استخدام شده اند زیر مجموعه او نامیده میشوند و شخص بازاریاب بابت فروشی که زیر مجموعه های او داشته اند نیز پاداش دریافت میکند.این زیر مجموعه ها میتوانند تا چند سطح نیز ادامه داشته باشند. فرد بازاریاب با داشتن زیر مجموعه های بیشتر میتواند سود بیشتری کسب کند.\n",
            "میتوان از شرکت \"بادران گستران\"بعنوان یکی از قدرتمندترین و اولین شرکت های این حوزه نام برد که با  مجوز  وزارت صنعت ,معدن وتجارت در ایران فعالیت میکند.\n",
            "بازاریابی چند سطحی (mlm )یک استراتژی بازاریابی فروش مستقیم است که در آن بازاریاب علاوه بر پاداشی که بابت فروش مستقیم محصول دریافت می کند بابت فروش افرادی که توسط او استخدام شده اند نیز درآمدکسب میکند.افرادی که توسط بازاریاب استخدام شده اند زیر مجموعه او نامیده میشوند و شخص بازاریاب بابت فروشی که زیر مجموعه های او داشته اند نیز پاداش دریافت میکند.این زیر مجموعه ها میتوانند تا چند سطح نیز ادامه داشته باشند. فرد بازاریاب با داشتن زیر مجموعه های بیشتر میتواند سود بیشتری کسب کند.\n",
            "میتوان از شرکت \"بادران گستران\"بعنوان یکی از قدرتمندترین و اولین شرکت های این حوزه نام برد که با  مجوز  وزارت صنعت ,معدن وتجارت در ایران فعالیت میکند.\n",
            "خوب نبود\n",
            "خوب نبود\n",
            "خوب نبود...\n",
            "خوب نبود...\n",
            "یه چیز جالب بگم: اگه دقت کنید روی سر مجسمه حضرت موسی که روی کتاب هست، دو تا شاخ وجود داره. سازنده مجسمه کلمه karnayim که هم معنی درخشش و نورانی رو میده و هم معنی شاخ رو میده رو شاخ فهمیده.نوشته بوده که پرتو های نور از سر او می تابیده اون فکر کرده نوشته شاخ در سر داشته😂😂😂\n",
            "یه چیز جالب بگم: اگه دقت کنید روی سر مجسمه حضرت موسی که روی کتاب هست، دو تا شاخ وجود داره. سازنده مجسمه کلمه karnayim که هم معنی درخشش و نورانی رو میده و هم معنی شاخ رو میده رو شاخ فهمیده.نوشته بوده که پرتو های نور از سر او می تابیده اون فکر کرده نوشته شاخ در سر داشته\n",
            "دروغگوهای متقلب\n",
            "دروغگوهای متقلب\n",
            "چه با نمکه عنوان این کتاب😄\n",
            "دور از جون این جمع,واقعا بعضیا اینجورین😱😂\n",
            "چه با نمکه عنوان این کتاب\n",
            "دور از جون این جمع,واقعا بعضیا اینجورین\n",
            "خیلی دوست داشتم این کتابو.نویسنده نثر روان و خوبی داره.شخصیت پردازی هاش هم قشنگ بود.مخصوصا داستان اول رو خیلی دوست داشتم.توصیه میکنم بخوتید.\n",
            "خیلی دوست داشتم این کتابو.نویسنده نثر روان و خوبی داره.شخصیت پردازی هاش هم قشنگ بود.مخصوصا داستان اول رو خیلی دوست داشتم.توصیه میکنم بخوتید.\n",
            "چقدر هی گفته \"است\"\n",
            "چقدر هی گفته \"است\"\n",
            "فوق العاده زیبا و شنیدنی\n",
            "فوق العاده زیبا و شنیدنی\n",
            "خیلی زیبا و تاثیرگذار. ممنون بابت همچین کتابی.\n",
            "خیلی زیبا و تاثیرگذار. ممنون بابت همچین کتابی.\n",
            "مجموعه چاپیش 70 تومنه:/\n",
            "مجموعه چاپیش 70 تومنه:/\n",
            "کتاب خوبی بود از خواندنش لذت بردم\n",
            "کتاب خوبی بود از خواندنش لذت بردم\n",
            "کتاب فوق العاده ای هست\n",
            "توصییه میکنم حتما بخونید تا چگونگی خوشبختی با حداقل چیز ها رو لمس کنید\n",
            "عالی بود عالی بود\n",
            "کتاب فوق العاده ای هست\n",
            "توصییه میکنم حتما بخونید تا چگونگی خوشبختی با حداقل چیز ها رو لمس کنید\n",
            "عالی بود عالی بود\n",
            "کاش تمام کتاب های نیمه  پنهان ماه رو بگذارید توی طاقچه. خیلی خوبن :)\n",
            "کاش تمام کتاب های نیمه  پنهان ماه رو بگذارید توی طاقچه. خیلی خوبن :)\n",
            "وای شهید تجلایی عالین ، کتاب واقعا ارزشمندیه\n",
            "وای شهید تجلایی عالین ، کتاب واقعا ارزشمندیه\n",
            "کتابهای نیمه پنهان ماه کتابهای بسیار خوبیست...\n",
            "کتابهای نیمه پنهان ماه کتابهای بسیار خوبیست...\n",
            "با سلام وآرزوی موفقیت. لطفا سال نشر کتاب را هم بنویسید. از ابتکار ارزنده ی شما سپاسگزارم.\n",
            "با سلام وآرزوی موفقیت. لطفا سال نشر کتاب را هم بنویسید. از ابتکار ارزنده ی شما سپاسگزارم.\n",
            "مرسی نشر جامی\n",
            "مرسی نشر جامی\n",
            "باسلام لطفا کتاب هایی که محتوای خوب و جالبی دارند رو لطفا رایگان هم بذارین چون من نمی تونم از کتا ب هایی که پولی هستن استفاده کنم چون معمولا کتا بهای پیشنهادی طاقچه پولی هستن. باتشکر\n",
            "باسلام لطفا کتاب هایی که محتوای خوب و جالبی دارند رو لطفا رایگان هم بذارین چون من نمی تونم از کتا ب هایی که پولی هستن استفاده کنم چون معمولا کتا بهای پیشنهادی طاقچه پولی هستن. باتشکر\n",
            "دمتون گرم خیلی حال کردم. امیدوارم سایر کتابهای شاملو رو هم بزارید\n",
            "دمتون گرم خیلی حال کردم. امیدوارم سایر کتابهای شاملو رو هم بزارید\n",
            "ای وای! ای وای من! عالیه این کتاب! ممنونم از شما و  مروارید\n",
            "ای وای! ای وای من! عالیه این کتاب! ممنونم از شما و  مروارید\n",
            "چرا کامنت منو پاک می‌کنید؟ واقعن بعضی‌ها پیدا می‌شن که این مذخرفاتو بخونن؟\n",
            "چرا کامنت منو پاک می‌کنید؟ واقعن بعضی‌ها پیدا می‌شن که این مذخرفاتو بخونن؟\n",
            "چقدر زیاده گویی😐😣\n",
            "خوب شد نمونه شعر رو هم اورده بود که مطمن بشم این زیاده گویی نامفید از متن اصلی نبوده\n",
            "چرا آخه\n",
            "یک داستان یک صفحه ای رو در بدترین حالت بیست صفحه کرده که هنگام خوندن خوابت بگیره☹\n",
            "چقدر زیاده گویی\n",
            "خوب شد نمونه شعر رو هم اورده بود که مطمن بشم این زیاده گویی نامفید از متن اصلی نبوده\n",
            "چرا آخه\n",
            "یک داستان یک صفحه ای رو در بدترین حالت بیست صفحه کرده که هنگام خوندن خوابت بگیره\n",
            "قبلا دبیر ادبیاتمون برامون قصه شو گفته بود. الانم که خوندم خیلی باحال بود. حتما بخونبن. خیلیییییییی ارزش خوندن دارههههههه\n",
            "قبلا دبیر ادبیاتمون برامون قصه شو گفته بود. الانم که خوندم خیلی باحال بود. حتما بخونبن. خیلیییییییی ارزش خوندن دارههههههه\n",
            "هرکس این کتابو نخونده و بمیره به مرگ جاهلیت مرده،ترجمش هم به دست کسی بوده که نمیشه مثالی براش آورد\n",
            "هرکس این کتابو نخونده و بمیره به مرگ جاهلیت مرده،ترجمش هم به دست کسی بوده که نمیشه مثالی براش آورد\n",
            "کتاب بسیار مفیدی هستش\n",
            "کتاب بسیار مفیدی هستش\n",
            "نحوه استدلال سقراط زیبا بود.\n",
            "نحوه استدلال سقراط زیبا بود.\n",
            "عشق زیبا نیست ولی به دنبال زیبایی است...\n",
            "من از این کتاب یاد گرفتم که :\n",
            "عشقی که در آن نتوان به خاطر عشق از عشق گذشت ، عشق نیست ؛ عشق یعنی به خاطر عشق از عشق ها بگذریم....\n",
            "عشق زیبا نیست ولی به دنبال زیبایی است...\n",
            "من از این کتاب یاد گرفتم که :\n",
            "عشقی که در آن نتوان به خاطر عشق از عشق گذشت ، عشق نیست ؛ عشق یعنی به خاطر عشق از عشق ها بگذریم....\n",
            "از کتاب‌های کلاسیک که هر که در رشته‌های علوم انسانی تحصیل و مطالعه می‌کند، بایدش بخواند.\n",
            "از کتاب‌های کلاسیک که هر که در رشته‌های علوم انسانی تحصیل و مطالعه می‌کند، بایدش بخواند.\n",
            "من این کتاب رو نسخه چاپیش رو خوندم.\n",
            "یه کتاب فلسفی داستانی...\n",
            "جالبه ولی خسته کنندس.\n",
            "من این کتاب رو نسخه چاپیش رو خوندم.\n",
            "یه کتاب فلسفی داستانی...\n",
            "جالبه ولی خسته کنندس.\n",
            "رشتم تجربی بود و برای کنکور انسانی شرکت کردم.الان خدارو هزار مرتبه شکر میکنم که میتونم آثار فلسفی و منطقی رو با همون مقدمات دبیرستان بفهمم و استفاده کنم.\n",
            "به نظرم برید کتاب فلسفه و منطق انسانی رو بگیرید و بخونید واقعا مفید و کاربردیه.\n",
            "کاملا متوجه مغلطه ها میشید و دیگه به راحتی حرف کسیرو نمیپذیرید مگه اینکه به راستیتش پی ببرید\n",
            "رشتم تجربی بود و برای کنکور انسانی شرکت کردم.الان خدارو هزار مرتبه شکر میکنم که میتونم آثار فلسفی و منطقی رو با همون مقدمات دبیرستان بفهمم و استفاده کنم.\n",
            "به نظرم برید کتاب فلسفه و منطق انسانی رو بگیرید و بخونید واقعا مفید و کاربردیه.\n",
            "کاملا متوجه مغلطه ها میشید و دیگه به راحتی حرف کسیرو نمیپذیرید مگه اینکه به راستیتش پی ببرید\n",
            "جز زیباترین کتاب هایی که خوندم با ارزش با متنی راحت وقابل فهم در مورد عشق\n",
            "احسنت به سقراط\n",
            "جز زیباترین کتاب هایی که خوندم با ارزش با متنی راحت وقابل فهم در مورد عشق\n",
            "احسنت به سقراط\n",
            "خیلی سخته فهمیدنش ..\n",
            "یکم تخصصیِ\n",
            "خیلی سخته فهمیدنش ..\n",
            "یکم تخصصیِ\n",
            "سلام. این کتاب اولین پنجره ی نابی بود که به دنیای عشق باز شد برایم\n",
            "سلام. این کتاب اولین پنجره ی نابی بود که به دنیای عشق باز شد برایم\n",
            "واقعا با اختلاف 200 تا تک تومنی چرا باید به جای خرید نسخه چاپی، دانلودش کرد؟!..این روش قیمت گذاری بی معنیه!!!\n",
            "واقعا با اختلاف 200 تا تک تومنی چرا باید به جای خرید نسخه چاپی، دانلودش کرد؟!..این روش قیمت گذاری بی معنیه!!!\n",
            "تعداد صفحات کتاب رو نوشتید 144 ، در صورتی که در فایل46 صفحه بیشتر نیست. در توضحات نوشتید کتاب روایتی از عشق است که افلاطون و بزرگان یونان آن را روایت می کنند. در صورتی که از همین 46 صفحه اکثرا توضیحاتیست از زندگینامه و کارهای افلاطون و دیگر بزرگان یونان...\n",
            "تعداد صفحات کتاب رو نوشتید 144 ، در صورتی که در فایل46 صفحه بیشتر نیست. در توضحات نوشتید کتاب روایتی از عشق است که افلاطون و بزرگان یونان آن را روایت می کنند. در صورتی که از همین 46 صفحه اکثرا توضیحاتیست از زندگینامه و کارهای افلاطون و دیگر بزرگان یونان...\n",
            "کتاب خوب و جالبی بود.\n",
            "کتاب خوب و جالبی بود.\n",
            "فوق العاده است.افلاطون رو باید ستود.\n",
            "فوق العاده است.افلاطون رو باید ستود.\n",
            "آخه چ کاریه با این قیمت خب نسخه چاپی میخرم چشمامم اذیت نمیکنم فرقش ۲۰۰ خخخ\n",
            "آخه چ کاریه با این قیمت خب نسخه چاپی میخرم چشمامم اذیت نمیکنم فرقش ۲۰۰ خخخ\n",
            "بار اول به دلم ننشست ولی بار دوم نشست وبیرون نرفت,  سخنان سقراط در تعریف عشق وجد آور هستند\n",
            "بار اول به دلم ننشست ولی بار دوم نشست وبیرون نرفت,  سخنان سقراط در تعریف عشق وجد آور هستند\n",
            "خیلی کتاب خوب و جالبی بود.\n",
            "خیلی کتاب خوب و جالبی بود.\n",
            "با سلام\n",
            "این کتاب واقعا کتاب بسیار تاثیر گذاری هست بر طریقه ی نگاه فیلسوفان و عارفان سرزمین خودمان و حتی بو علی سینا ی بزرگ هم از طرز تفکر افلاطون درباره ی عشق در کتاب فلسفی خودش استفاده کرده است و کاملا واضح است که این طرز فکر و اندیشه در ادبیات فارسی هم نمود پیدا کرده است .\n",
            "خواندن این کتاب به شدت توصیه می شود.\n",
            "با سلام\n",
            "این کتاب واقعا کتاب بسیار تاثیر گذاری هست بر طریقه ی نگاه فیلسوفان و عارفان سرزمین خودمان و حتی بو علی سینا ی بزرگ هم از طرز تفکر افلاطون درباره ی عشق در کتاب فلسفی خودش استفاده کرده است و کاملا واضح است که این طرز فکر و اندیشه در ادبیات فارسی هم نمود پیدا کرده است .\n",
            "خواندن این کتاب به شدت توصیه می شود.\n",
            "سلام\n",
            "لطفا صفحه مشخصات کتاب رو داخل کتاب الکترونیکی قرار بدید! سال چاپ و ناشر و مترجم و ...\n",
            "سلام\n",
            "لطفا صفحه مشخصات کتاب رو داخل کتاب الکترونیکی قرار بدید! سال چاپ و ناشر و مترجم و ...\n",
            "\"گزینش ادبیات آمریکای لاتین به این دلیل بود که دیدم این نویسندگان سبک و حرفی تازه دارند و درعین‌حال شاعرانگی سبک و سخن بعضی‌هاشان مثل فوئنتس یا آستوریاس و روئاباستوس مرا شیفته کرد. از طرف دیگر  دهه 1970 به بعد غیر از استثنائات معدود، راستش چیز دندان‌گیری در ادبیات غرب (به معنای اروپای غربی و ایالات متحده) نمی‌یافتم و هنوز هم نمی‌یابم.\"عبدا.. کوثری\n",
            "از مترجم به خاطر ترجمه عالی از انتشارات و طاقچه متشکرم. بولانیو محبوبترین نویسنده خارجی من هست و واقعا لذت بردم.\n",
            "\"گزینش ادبیات آمریکای لاتین به این دلیل بود که دیدم این نویسندگان سبک و حرفی تازه دارند و درعین‌حال شاعرانگی سبک و سخن بعضی‌هاشان مثل فوئنتس یا آستوریاس و روئاباستوس مرا شیفته کرد. از طرف دیگر  دهه 1970 به بعد غیر از استثنائات معدود، راستش چیز دندان‌گیری در ادبیات غرب (به معنای اروپای غربی و ایالات متحده) نمی‌یافتم و هنوز هم نمی‌یابم.\"عبدا.. کوثری\n",
            "از مترجم به خاطر ترجمه عالی از انتشارات و طاقچه متشکرم. بولانیو محبوبترین نویسنده خارجی من هست و واقعا لذت بردم.\n",
            "نمیدونم چرا این کتابا مجوز میگیرن. اولا چیزی جز دروغ نبود. دوما اصلا هیچ معنا و فایده ای نداشت بدترین رمانی بود که تا الآن خونده بودم.\n",
            "نمیدونم چرا این کتابا مجوز میگیرن. اولا چیزی جز دروغ نبود. دوما اصلا هیچ معنا و فایده ای نداشت بدترین رمانی بود که تا الآن خونده بودم.\n",
            "هیچ فرقی نداره کتابهای فونتس با چه ترتیبی خونده میشه !  همیشه مطمینم که کتاب بعدی یک شاهکار دیگه ست که حتی از اینم بهتره!!! عالی. ممنون.\n",
            "هیچ فرقی نداره کتابهای فونتس با چه ترتیبی خونده میشه !  همیشه مطمینم که کتاب بعدی یک شاهکار دیگه ست که حتی از اینم بهتره!!! عالی. ممنون.\n",
            "خیلی گرونه بابا، هشت هزار تومن!!! لطفا تخفیف بیشتری بذارید. ممنون\n",
            "خیلی گرونه بابا، هشت هزار تومن!!! لطفا تخفیف بیشتری بذارید. ممنون\n",
            "بینهایت مزخرف و حوصله سر بر\n",
            "بینهایت مزخرف و حوصله سر بر\n",
            "کتاب خیلی حوصله سر بر و به درد نخوریه؛ اصلا ارزش خوندن نداره\n",
            "کتاب خیلی حوصله سر بر و به درد نخوریه؛ اصلا ارزش خوندن نداره\n",
            "به نظرم نثر نویسنده و نگاهش به مهاجران هندی در  امریکا بسیار عالی است و البته ترجمه هم بسیار خوب است. دو داستان اول البته تصویر تلخی داشتند و شاید این تلخی در حوصله ی هر کسی نگنجد.\n",
            "به نظرم نثر نویسنده و نگاهش به مهاجران هندی در  امریکا بسیار عالی است و البته ترجمه هم بسیار خوب است. دو داستان اول البته تصویر تلخی داشتند و شاید این تلخی در حوصله ی هر کسی نگنجد.\n",
            "آقای هومن ج  هر دو کتاب ترجمه ای از کتاب Unaccustomed earth هستن \n",
            "آقای هومن ج  هر دو کتاب ترجمه ای از کتاب Unaccustomed earth هستن \n",
            "این زمین نا آشنا همون خاک غریب نیست که از انتشارات ماهی چاپ شده ؟\n",
            "این زمین نا آشنا همون خاک غریب نیست که از انتشارات ماهی چاپ شده ؟\n",
            "فکر میکردم کتابای خوب قرار نیست تو این طرح بیاد ، ولی با این کتاب ثابت کردید از این خبرا نیست، این که عاااالیه (البته از کتابای قبلی خبر ندارم چون تازه نصب کردم طاقچه رو)\n",
            "فکر میکردم کتابای خوب قرار نیست تو این طرح بیاد ، ولی با این کتاب ثابت کردید از این خبرا نیست، این که عاااالیه (البته از کتابای قبلی خبر ندارم چون تازه نصب کردم طاقچه رو)\n",
            "عجب کتابی پسر!!!؟ ینی این ٥٠ درصد تخفیف بهترین تخفیف بوده تا الان. طاقچه مادر، الهی خیر از جوونیت ببینی کپلم. \n",
            "عجب کتابی پسر!!!؟ ینی این ٥٠ درصد تخفیف بهترین تخفیف بوده تا الان. طاقچه مادر، الهی خیر از جوونیت ببینی کپلم. \n",
            "من داستان «هما و کاشیک » را دوست داشتم.\n",
            "سرنوشت یا نتیجه اعمال ما  !!!\n",
            "من داستان «هما و کاشیک » را دوست داشتم.\n",
            "سرنوشت یا نتیجه اعمال ما  !!!\n",
            "هنوز اوایل کتابم...تا اینجاش که جذاب بود. ممنون از تخفیف : )\n",
            "هنوز اوایل کتابم...تا اینجاش که جذاب بود. ممنون از تخفیف : )\n",
            "یک مجموعه داستان بی نظیر... از بزرگ ترین نویسندگان ژاپن... ژاپن را در این کتاب با بزرگ ترین نویسندگانش همسفر شوید... یکی از بهترین مجموعه داستان های سالهای اخیر.... عالی... واقعن عالی\n",
            "یک مجموعه داستان بی نظیر... از بزرگ ترین نویسندگان ژاپن... ژاپن را در این کتاب با بزرگ ترین نویسندگانش همسفر شوید... یکی از بهترین مجموعه داستان های سالهای اخیر.... عالی... واقعن عالی\n",
            "شایعه و نقش زنان\n",
            "گفته می شود که زنان برای شایعه پراکنی آمادگی دارند؛ و نیز فرض بر این است که روشنفکران همواره درباره شایعات مقاومت می کنند.\n",
            "سخن گفتن درباره زنان و شایعه، انسان را در معرض خطر اتهام تبعیض و غلطیدن در ورطه ی زن ستیزی، قرار می دهد. با این حال، حقیقت این است که در فرهنگ مردمی، رابطه ای بین زنان و شایعه وجود دارد. در این جا اگر نتوانیم به انگیزه ها بپردازیم، به ریشه می توانیم.\n",
            "کلمه ی « Commerage » به معنی «پچ پچ» یا غیبت در مورد زندگی خصوصی آشنایان و در و همسایه، از واژه ی Commater لاتین به معنای مادر خوانده آمده است. کلمه ی انگلیسی gossip نیز به همان معنا، ریشه ی مشابهی دارد و از god_sib به معنای مادر خوانده می آید.\n",
            "( در فارسی نیز با استفاده از اصطلاح «حرف های خاله زنکی» به این نوع حرف ها هویتی زنانه داده ایم. )\n",
            "احتمالاً، انحرافی که در مفهوم کلمه ایجاد شده است، از آن جا نشأت می گیرد که رابطه نزدیک و گرم با مادر خوانده ی فرزندان ( یا با خاله ی فرزندان )، باعث می شد مادران خود را مجاز بدانند که با آنان پیرامون احساسات خود درباره ی افرادِ محیط شان، سخن بگویند. متخصصان ریشه شناسی لغات انگلیسی توضیح داده اند که این انحراف ناشی از بحث هایی بوده است که زنان، هنگام گردهمایی در خانه یکی از اقوام، که در آن نوزادی متولد می شده است، مطرح می کرده اند. حتی اگر این توضیحِ ریشه شناختی صحیح باشد، نمی تواند برای بار منفی ای که این عبارت به خود گرفته توضیحی بدهد. نباید فراموش کرد که رواج این نوع حرف ها در میان زنان، در عین حال نشان روشنی از همبستگی آنان است زیرا سخن با دیگران گفته می شود نه با خود. آیا جوامع پدر سالار از این همبستگی ناخرسند بوده اند که چنین نامی بر آن گذاشته اند؟ در حقیقت آنان زنان را از کلیه فعالیت های عمومی حذف کرده بودند و زنان هیچ حق رسمی برای بحث پیرامون امور شهر خود را نداشتند لذا، از طریق این نوع حرف ها، آن چه را که مردان بر آن ها تحریم کرده بودند، به دست می آوردند و نه تنها درباره ی کار و کسب شهر، بلکه درباره ی مسایل خوشایند آن ( خلاف کاری ها، جنایات و غیره ) نیز صحبت می کردند. از آن جا که از زندگی عمومی محروم شده بودند، زندگی خصوصی را عمومی کردند. ممکن است از این جا عادت دراز مدتی در زنان پدید آمده باشد و به شایعه خو گرفته باشند. اما در هر صورت علتِ اصلی، انزوای تحمیلی بوده است. مورن متوجه شد که در شایعه تجارت بردگان سفید در شهر اورلئان، در سال 1969، مردان شایعه را نپذیرفتند، و نتیجه گرفت که این ناباوری، ناشی از تجربه مردان است. گرایش مردان به جست و جوی شواهد بیش تر برای پذیرفتن یک شایعه ناشی از آزادی ای است که در فعالیت های خود در شهر، از آن بهره مندند، تا نتیجه ی یک روحیه منتقدانه و تحلیل گر.\n",
            "منبع:\n",
            "کتاب: شایعه، ژان نوئل کاپفرر، خداداد موقّر، چاپ اول، 1380\n",
            "شایعه و نقش زنان\n",
            "گفته می شود که زنان برای شایعه پراکنی آمادگی دارند؛ و نیز فرض بر این است که روشنفکران همواره درباره شایعات مقاومت می کنند.\n",
            "سخن گفتن درباره زنان و شایعه، انسان را در معرض خطر اتهام تبعیض و غلطیدن در ورطه ی زن ستیزی، قرار می دهد. با این حال، حقیقت این است که در فرهنگ مردمی، رابطه ای بین زنان و شایعه وجود دارد. در این جا اگر نتوانیم به انگیزه ها بپردازیم، به ریشه می توانیم.\n",
            "کلمه ی « Commerage » به معنی «پچ پچ» یا غیبت در مورد زندگی خصوصی آشنایان و در و همسایه، از واژه ی Commater لاتین به معنای مادر خوانده آمده است. کلمه ی انگلیسی gossip نیز به همان معنا، ریشه ی مشابهی دارد و از god_sib به معنای مادر خوانده می آید.\n",
            "( در فارسی نیز با استفاده از اصطلاح «حرف های خاله زنکی» به این نوع حرف ها هویتی زنانه داده ایم. )\n",
            "احتمالاً، انحرافی که در مفهوم کلمه ایجاد شده است، از آن جا نشأت می گیرد که رابطه نزدیک و گرم با مادر خوانده ی فرزندان ( یا با خاله ی فرزندان )، باعث می شد مادران خود را مجاز بدانند که با آنان پیرامون احساسات خود درباره ی افرادِ محیط شان، سخن بگویند. متخصصان ریشه شناسی لغات انگلیسی توضیح داده اند که این انحراف ناشی از بحث هایی بوده است که زنان، هنگام گردهمایی در خانه یکی از اقوام، که در آن نوزادی متولد می شده است، مطرح می کرده اند. حتی اگر این توضیحِ ریشه شناختی صحیح باشد، نمی تواند برای بار منفی ای که این عبارت به خود گرفته توضیحی بدهد. نباید فراموش کرد که رواج این نوع حرف ها در میان زنان، در عین حال نشان روشنی از همبستگی آنان است زیرا سخن با دیگران گفته می شود نه با خود. آیا جوامع پدر سالار از این همبستگی ناخرسند بوده اند که چنین نامی بر آن گذاشته اند؟ در حقیقت آنان زنان را از کلیه فعالیت های عمومی حذف کرده بودند و زنان هیچ حق رسمی برای بحث پیرامون امور شهر خود را نداشتند لذا، از طریق این نوع حرف ها، آن چه را که مردان بر آن ها تحریم کرده بودند، به دست می آوردند و نه تنها درباره ی کار و کسب شهر، بلکه درباره ی مسایل خوشایند آن ( خلاف کاری ها، جنایات و غیره ) نیز صحبت می کردند. از آن جا که از زندگی عمومی محروم شده بودند، زندگی خصوصی را عمومی کردند. ممکن است از این جا عادت دراز مدتی در زنان پدید آمده باشد و به شایعه خو گرفته باشند. اما در هر صورت علتِ اصلی، انزوای تحمیلی بوده است. مورن متوجه شد که در شایعه تجارت بردگان سفید در شهر اورلئان، در سال 1969، مردان شایعه را نپذیرفتند، و نتیجه گرفت که این ناباوری، ناشی از تجربه مردان است. گرایش مردان به جست و جوی شواهد بیش تر برای پذیرفتن یک شایعه ناشی از آزادی ای است که در فعالیت های خود در شهر، از آن بهره مندند، تا نتیجه ی یک روحیه منتقدانه و تحلیل گر.\n",
            "منبع:\n",
            "کتاب: شایعه، ژان نوئل کاپفرر، خداداد موقّر، چاپ اول، 1380\n",
            "نقش شایعه پراکنی و ظرف شستن در طول عمر زنان\n",
            "خانم استفانی براون از دانشگاه میشیگان ، راجع به اثرات مثبت «ظرف شستن خانم‌ها با هم» و «گپ زدن و شایعه‌پردازی بی‌خطر» بر روی «افزایش طول عمر خانم‌ها» مطالعه ای کرده و مقاله ای ارائه داده که خلاصه ای از اون را از سایت استاد محمدرضا شعبانعلی اینجا میزارم.\n",
            "– اینکه «کمک کردن به دیگران» و «انجام رفتارهایی که حس دوستی و نزدیکی ما به اطرافیان را تقویت می‌کند» موجب ترشح بیشتر پروژسترون می‌شود.\n",
            "– اینکه یکی از خاصیت‌های مثبت شایعه پردازی و شایعه پراکنی در کنار اثرات منفی آن، ایجاد «احساس دوستی» و «پیوند بیشتر» بین شنونده و گوینده‌ی شایعه است که این «احساس نزدیکی و پیوند» ترشح هورمون پروژسترون را افزایش داده و موجب کاهش «اضطراب و استرس» در زنان می‌گردد.\n",
            "– اینکه بحث کردن روی شایعه‌ها و پشت سر دیگران، در مورد زنان می‌تواند موجب طول عمر شود اما در مورد مردان، چنین اثری ندارد و حتی موجب افزایش استرس و اضطراب می‌شود. به دلیل اینکه بر خلاف زنان، که تعریف یک خبر (به قول ما خاله زنکی)‌ بیشتر از اصل خبر به معنای اعلام دوستی با طرف مقابل است (آنقدر دوستت دارم که الان به تو یک خبر خیلی جالب راجع به فلانی می‌گویم!) در مورد مردان، تعریف شایعه – خصوصاً در محیط کار – عموماً بخشی ازرفتارهای سیاسی است که برای طرف مقابل یک معنا دارد: «بدبخت! ببین چه خبرهایی را دارم که تو نداری! من خیلی مهم تر و مطلع‌تر از تو هستم!». به همین دلیل مردها در شایعه پراکنی از «طول عمر خود» هزینه می‌کنند!\n",
            "نقش شایعه پراکنی و ظرف شستن در طول عمر زنان\n",
            "خانم استفانی براون از دانشگاه میشیگان ، راجع به اثرات مثبت «ظرف شستن خانم‌ها با هم» و «گپ زدن و شایعه‌پردازی بی‌خطر» بر روی «افزایش طول عمر خانم‌ها» مطالعه ای کرده و مقاله ای ارائه داده که خلاصه ای از اون را از سایت استاد محمدرضا شعبانعلی اینجا میزارم.\n",
            "– اینکه «کمک کردن به دیگران» و «انجام رفتارهایی که حس دوستی و نزدیکی ما به اطرافیان را تقویت می‌کند» موجب ترشح بیشتر پروژسترون می‌شود.\n",
            "– اینکه یکی از خاصیت‌های مثبت شایعه پردازی و شایعه پراکنی در کنار اثرات منفی آن، ایجاد «احساس دوستی» و «پیوند بیشتر» بین شنونده و گوینده‌ی شایعه است که این «احساس نزدیکی و پیوند» ترشح هورمون پروژسترون را افزایش داده و موجب کاهش «اضطراب و استرس» در زنان می‌گردد.\n",
            "– اینکه بحث کردن روی شایعه‌ها و پشت سر دیگران، در مورد زنان می‌تواند موجب طول عمر شود اما در مورد مردان، چنین اثری ندارد و حتی موجب افزایش استرس و اضطراب می‌شود. به دلیل اینکه بر خلاف زنان، که تعریف یک خبر (به قول ما خاله زنکی)‌ بیشتر از اصل خبر به معنای اعلام دوستی با طرف مقابل است (آنقدر دوستت دارم که الان به تو یک خبر خیلی جالب راجع به فلانی می‌گویم!) در مورد مردان، تعریف شایعه – خصوصاً در محیط کار – عموماً بخشی ازرفتارهای سیاسی است که برای طرف مقابل یک معنا دارد: «بدبخت! ببین چه خبرهایی را دارم که تو نداری! من خیلی مهم تر و مطلع‌تر از تو هستم!». به همین دلیل مردها در شایعه پراکنی از «طول عمر خود» هزینه می‌کنند!\n",
            "قشنگ\n",
            "قشنگ\n",
            "در این کتاب خصوصیات یک معلم به عنوان یک انسان و نه فقط چرخ دنده ای در ماشین آموزشی نگاه می شود و به کوچکترین مشکلاتی که ممکن است در طول عمر تدریس خود با آن مواجه شود می پردازد و راه های مختلفی برای رهایی از آن ها ذکر می کند.\n",
            "•\n",
            "من خودم صرفا نه به خاطر اینکه به معلمی علاقه داشته باشم این کتاب رو خوندم بلکه بخاطر اینکه بتونم به مشکلاتی که در سر راه این شغل قرار داره پی ببرم و با دید وسیع تری به نقد معلمان خودم بپردازم😁😄😁\n",
            "به امید تغییر اساسی و مثبت در نظام آموزش و پرورش امون🙂🌷\n",
            "در این کتاب خصوصیات یک معلم به عنوان یک انسان و نه فقط چرخ دنده ای در ماشین آموزشی نگاه می شود و به کوچکترین مشکلاتی که ممکن است در طول عمر تدریس خود با آن مواجه شود می پردازد و راه های مختلفی برای رهایی از آن ها ذکر می کند.\n",
            "•\n",
            "من خودم صرفا نه به خاطر اینکه به معلمی علاقه داشته باشم این کتاب رو خوندم بلکه بخاطر اینکه بتونم به مشکلاتی که در سر راه این شغل قرار داره پی ببرم و با دید وسیع تری به نقد معلمان خودم بپردازم\n",
            "به امید تغییر اساسی و مثبت در نظام آموزش و پرورش امون\n",
            "آیا برای دانش آموزان نیز کتاب گران بهایی است؟؟!!!\n",
            "آیا برای دانش آموزان نیز کتاب گران بهایی است؟؟!!!\n",
            "برای معلمان کتاب ارزشمندی است\n",
            "برای معلمان کتاب ارزشمندی است\n",
            "پیتر کری عالیه...\n",
            "پیتر کری عالیه...\n",
            "وقتی یاد طوطی یکی از راویان رمان می افتم، دلم می خواست در رکاب الکسی دو توکویل باشم. رمانی عالی با ترجمه ای خوب. از نویسنده ای بزرگ. زنده باد پیتر کری.\n",
            "وقتی یاد طوطی یکی از راویان رمان می افتم، دلم می خواست در رکاب الکسی دو توکویل باشم. رمانی عالی با ترجمه ای خوب. از نویسنده ای بزرگ. زنده باد پیتر کری.\n",
            "فکر می کنم نویسنده یی است که همین دو سه سال آینده به ش نوبل بدهند...\n",
            "جای خوش وقتی است که نویسنده یی که دو تا بوکر در کارنامه ادبی ش داره هم بالاخره به فارسی ترجمه شده...\n",
            "پیتر کری دیر  امد به ایران، اما خوش امد... پیتر کری به قول پل آستر، خدای قصه گویی است...\n",
            "فکر می کنم نویسنده یی است که همین دو سه سال آینده به ش نوبل بدهند...\n",
            "جای خوش وقتی است که نویسنده یی که دو تا بوکر در کارنامه ادبی ش داره هم بالاخره به فارسی ترجمه شده...\n",
            "پیتر کری دیر  امد به ایران، اما خوش امد... پیتر کری به قول پل آستر، خدای قصه گویی است...\n",
            "پیتر کری عالی است.... نثرش عالی... قصه ش عالی... نویسنده یی به این بزرگی که متاسفانه سالها مغفول مانده بود در ایران... خوشبختانه حالا پیتر کری را داریم و لذت خوانش ان را هم حالا داریم.... تبریک به خودمان\n",
            "پیتر کری عالی است.... نثرش عالی... قصه ش عالی... نویسنده یی به این بزرگی که متاسفانه سالها مغفول مانده بود در ایران... خوشبختانه حالا پیتر کری را داریم و لذت خوانش ان را هم حالا داریم.... تبریک به خودمان\n",
            "از امیدهای اصلی نوبل\n",
            "از امیدهای اصلی نوبل\n",
            "طاقچه, هر روز بهتر از دیروز\n",
            "ممنون طاقچه\n",
            "کتابهای منزوی رو هم بیارین لطفا\n",
            "طاقچه, هر روز بهتر از دیروز\n",
            "ممنون طاقچه\n",
            "کتابهای منزوی رو هم بیارین لطفا\n",
            "عالیه لطفا جلد پشت مجله هم بزارید ممنون میشم&\n",
            "عالیه لطفا جلد پشت مجله هم بزارید ممنون میشم&\n",
            "دکتر منصوری فوق العاده س، این کارش خدمت به نجوم کشور بوده و هست\n",
            "دکتر منصوری فوق العاده س، این کارش خدمت به نجوم کشور بوده و هست\n",
            "عالیه.\n",
            "عالیه.\n",
            "خیلی ممنون، ولی اگه تقسیم بندی به صورت جزء به جزء هم داشت بهتر میشد.\n",
            "خیلی ممنون، ولی اگه تقسیم بندی به صورت جزء به جزء هم داشت بهتر میشد.\n",
            "ازانتشار قرآن واقعا ممنونم خیلی باارزشه ولی ای کاش میشد فایلهای پی دی اف مجانی رو کپی کرد که برای همیشه داشته باشیم\n",
            "ازانتشار قرآن واقعا ممنونم خیلی باارزشه ولی ای کاش میشد فایلهای پی دی اف مجانی رو کپی کرد که برای همیشه داشته باشیم\n",
            "نسبت به بقیه بهتره\n",
            "نسبت به بقیه بهتره\n",
            "😍الهم عجل لولیک الفرج 😘\n",
            "الهم عجل لولیک الفرج \n",
            "واقعا قشنگ بود\n",
            "واقعا قشنگ بود\n",
            "جانم فدای قرآن\n",
            "جانم فدای قرآن\n",
            "باید هنگام مطالعه وضو داشت؟\n",
            "باید هنگام مطالعه وضو داشت؟\n",
            "جان من فدای قرآن\n",
            "جان من فدای قرآن\n",
            "از همین نویسنده در طاقچه سه کتاب دیگر منتشر شده اما اسم تی هارو اکر به‌گونه دیگری نوشته شده که امیدوارم ویرایش بشه.\n",
            "از همین نویسنده در طاقچه سه کتاب دیگر منتشر شده اما اسم تی هارو اکر به‌گونه دیگری نوشته شده که امیدوارم ویرایش بشه.\n",
            "به نظرم بیشتر تبلغ همایش هاشه.\n",
            "کتاب برتری خفیف یا هفت عادت مردمان موفق یا شادی حقیقی کاربردی تر هستند.\n",
            "به نظرم بیشتر تبلغ همایش هاشه.\n",
            "کتاب برتری خفیف یا هفت عادت مردمان موفق یا شادی حقیقی کاربردی تر هستند.\n",
            "حس خوبی به آدم میده، هنوز تمومش نکردم\n",
            "کسایی که خوندن تونستن پول در بیارن؟!\n",
            "حس خوبی به آدم میده، هنوز تمومش نکردم\n",
            "کسایی که خوندن تونستن پول در بیارن؟!\n",
            "اگر در ابتدای مسیر موفقیت هستید و تا بحال کتابی نخوندید، خوندنش برای ۱ بار خالی از لطف نیست. ولی اگر کتاب های بهتری خوندید با نخوندنش چیزی است دست نمیدید.\n",
            "اگر در ابتدای مسیر موفقیت هستید و تا بحال کتابی نخوندید، خوندنش برای ۱ بار خالی از لطف نیست. ولی اگر کتاب های بهتری خوندید با نخوندنش چیزی است دست نمیدید.\n",
            "کتابی که هر کس حداقل یک بار باید بخونتش.و قطعا در زمینه های دیگه هم کمک کنندس\n",
            "کتابی که هر کس حداقل یک بار باید بخونتش.و قطعا در زمینه های دیگه هم کمک کنندس\n",
            "بخونین بد نیس حداقل امیدواری توش هست\n",
            "بخونین بد نیس حداقل امیدواری توش هست\n",
            "کتاب بدی نبود ولی اگه « پدر پولدار پدر بیپول »رو خونده باشین دقیقا انگار داشت حرفای اونو نشخوار میکرد به علاوه اینکه هی تبلیغ سمینارها و همایشهای خودشو میکرد که این کارش اصلا جالب نبود و حرص آدمو درمیاورد. ولی حرف های جدید و جالبی هم برای گفتن داشت.\n",
            "کتاب بدی نبود ولی اگه « پدر پولدار پدر بیپول »رو خونده باشین دقیقا انگار داشت حرفای اونو نشخوار میکرد به علاوه اینکه هی تبلیغ سمینارها و همایشهای خودشو میکرد که این کارش اصلا جالب نبود و حرص آدمو درمیاورد. ولی حرف های جدید و جالبی هم برای گفتن داشت.\n",
            "به نظر من کتاب بدی نیست و ارزش یکبار خوندن داره، شاید توی ثروت کمک نکنه، اما می تونه در موارد دیگه زندگی به درد ادم بخوره ✋\n",
            "به نظر من کتاب بدی نیست و ارزش یکبار خوندن داره، شاید توی ثروت کمک نکنه، اما می تونه در موارد دیگه زندگی به درد ادم بخوره \n",
            "کتاب خیلی خوب و کاربردی هست. من کاملا راضی بودم\n",
            "کتاب خیلی خوب و کاربردی هست. من کاملا راضی بودم\n",
            "برای کسی که با جملات تاکیدی حال نمیکنه و خسته ست از کتابایی مثل قانون توانگری کاترین پاندر که آخرش هم راه حل درست و حسابی و قابل اعتماد دستگیر آدم نمیشه، خیلی کتاب خوبیه و خوندن چندین باره ش توصیه ی منه :)\n",
            "متشکر\n",
            "برای کسی که با جملات تاکیدی حال نمیکنه و خسته ست از کتابایی مثل قانون توانگری کاترین پاندر که آخرش هم راه حل درست و حسابی و قابل اعتماد دستگیر آدم نمیشه، خیلی کتاب خوبیه و خوندن چندین باره ش توصیه ی منه :)\n",
            "متشکر\n",
            "عالیه. بسیار عالی. حتما بخونین\n",
            "عالیه. بسیار عالی. حتما بخونین\n",
            "افرین خوشم اومدکتاب خوبی بود\n",
            "افرین خوشم اومدکتاب خوبی بود\n",
            "بی نظیر ، کاملا در رویه زندگی من تاثیر مثبت داشت.\n",
            "بی نظیر ، کاملا در رویه زندگی من تاثیر مثبت داشت.\n",
            "نکته دیگه هم اینه که ارزش مادیات رو تو آدم بالا میبره و انسان رو از معنویات دور میکنه. و از انسان یه موجود حریص و پول دوست میسازه.\n",
            "نکته دیگه هم اینه که ارزش مادیات رو تو آدم بالا میبره و انسان رو از معنویات دور میکنه. و از انسان یه موجود حریص و پول دوست میسازه.\n",
            "اکثر کتابهای موفقیت به خصوص این کتاب حس خودخواهی و زیاده طلبی ذو در آدم ایجاد میکنند. آرزوهایی رو هم درون انسان ایجاد میکنند ولی چون واقعی نشان نمیدهند دنیا را با نرسیدن به آرزوهایش افسرده میشود. انسان نمیفهمد که این دنیا بیشتر آرزوها محقق نمیشوند و نباید به آنها دل بست.\n",
            "اکثر کتابهای موفقیت به خصوص این کتاب حس خودخواهی و زیاده طلبی ذو در آدم ایجاد میکنند. آرزوهایی رو هم درون انسان ایجاد میکنند ولی چون واقعی نشان نمیدهند دنیا را با نرسیدن به آرزوهایش افسرده میشود. انسان نمیفهمد که این دنیا بیشتر آرزوها محقق نمیشوند و نباید به آنها دل بست.\n",
            "واقعا کتاب خوبیه\n",
            "واقعا کتاب خوبیه\n",
            "یعنی کتاب رو بگیرم؟؟؟؟\n",
            "یعنی کتاب رو بگیرم؟؟؟؟\n",
            "من کتابهای زیادی در زمینه موفقیت کاری مطالعه کردم میتونم بدون شک بگم قویترین و تاثیر گذارترین کتابی که خوندم بود و زمینه فکری من رو راجب کارم و خودم تغییر داد  و از  زمانی که دست به اجرای فایلهای مالیش تو زندگیم زدم تو ی مدت خیلی کمی متوجه تاثیر حیرت انگیزش شدم \n",
            "پیشنهاد میکنم حتی اگه احساس میکنید موفقید بازم این کتاب ارزشمندو از دست ندید\n",
            " با تشکر از طاقچه\n",
            "من کتابهای زیادی در زمینه موفقیت کاری مطالعه کردم میتونم بدون شک بگم قویترین و تاثیر گذارترین کتابی که خوندم بود و زمینه فکری من رو راجب کارم و خودم تغییر داد  و از  زمانی که دست به اجرای فایلهای مالیش تو زندگیم زدم تو ی مدت خیلی کمی متوجه تاثیر حیرت انگیزش شدم \n",
            "پیشنهاد میکنم حتی اگه احساس میکنید موفقید بازم این کتاب ارزشمندو از دست ندید\n",
            " با تشکر از طاقچه\n",
            "فوق العاده....\n",
            "فوق العاده....\n",
            "به تمام دوستایی که توی مسابقه ی کتابخونی برنده نشدن پیشنهاد می کنم حتما این کتاب رو بخونن شاید اینجوری دست از سر رامبد عزیز بردارن\n",
            "به تمام دوستایی که توی مسابقه ی کتابخونی برنده نشدن پیشنهاد می کنم حتما این کتاب رو بخونن شاید اینجوری دست از سر رامبد عزیز بردارن\n",
            "یکی به من بگه کتاب خوبی بود یا عالی بود؟من به کتابای روانشناسی موفقیت علاقه دارم نمیدونم بخرم\n",
            "یکی به من بگه کتاب خوبی بود یا عالی بود؟من به کتابای روانشناسی موفقیت علاقه دارم نمیدونم بخرم\n",
            "واااا\n",
            "پولشو میزارم تو جیبم به جای خریدن کتاب کم، کم میلیونر میشم\n",
            "والاااا\n",
            "واااا\n",
            "پولشو میزارم تو جیبم به جای خریدن کتاب کم، کم میلیونر میشم\n",
            "والاااا\n",
            "بزنید واسش دس قشنکرم کتاب خوبی بود\n",
            "بزنید واسش دس قشنکرم کتاب خوبی بود\n",
            "کتابی پر از جملات مثبت فقط.  کاملا معمولی. تبلیغ سمینارهای میلیوتر شدن. دریک کلمه ارزش صرف وقت گرانبها رو ندارد\n",
            "کتابی پر از جملات مثبت فقط.  کاملا معمولی. تبلیغ سمینارهای میلیوتر شدن. دریک کلمه ارزش صرف وقت گرانبها رو ندارد\n",
            "کتاب خیلی عالی هست از نظر محتوا ولی ...\n",
            "چیزی که اهمیت خیلی بالایی داره عمل کردن به راهکارها و عبارت های تاکیدی کتاب هست .\n",
            "اینکه هر روز اول صبح و هر شب قبل از خواب تکرار کنیم و بگیم : من یک ذهن ملیونر دارم .\n",
            "و گرنه خواندن کتاب که راحت ترین کار هستش .\n",
            "راه ثروت و ثروتمند شدن سخته.\n",
            "کتاب خیلی عالی هست از نظر محتوا ولی ...\n",
            "چیزی که اهمیت خیلی بالایی داره عمل کردن به راهکارها و عبارت های تاکیدی کتاب هست .\n",
            "اینکه هر روز اول صبح و هر شب قبل از خواب تکرار کنیم و بگیم : من یک ذهن ملیونر دارم .\n",
            "و گرنه خواندن کتاب که راحت ترین کار هستش .\n",
            "راه ثروت و ثروتمند شدن سخته.\n",
            "بهترین کتابیه که توعمرم خوندم ممنون هارو عزیز وممنون طاقچه\n",
            "بهترین کتابیه که توعمرم خوندم ممنون هارو عزیز وممنون طاقچه\n",
            "با سلام.خدمت همه دست اندرکاران طاقچه.بسیار ممنون از قیمتهای منصفانه و همچنین تخفیف های عالی که بابت نمایشگاه کتاب قرار دادید.خواستم تشکر کرده باشم واینکه به همین راه با قدرت ادامه بدید. و با گذشت زمان. قیمتا بالا نره.این کتابم عالیه.\n",
            "با سلام.خدمت همه دست اندرکاران طاقچه.بسیار ممنون از قیمتهای منصفانه و همچنین تخفیف های عالی که بابت نمایشگاه کتاب قرار دادید.خواستم تشکر کرده باشم واینکه به همین راه با قدرت ادامه بدید. و با گذشت زمان. قیمتا بالا نره.این کتابم عالیه.\n",
            "من تازه کتاب رو دانلود کردمولی مقدمه اش منو مشتاق خوندن کرد. امیدوارم زندگی من و دوستان دچار تغییرات خوشایندی بشه\n",
            "من تازه کتاب رو دانلود کردمولی مقدمه اش منو مشتاق خوندن کرد. امیدوارم زندگی من و دوستان دچار تغییرات خوشایندی بشه\n",
            "فوقالعاده عالی!\n",
            "فوقالعاده عالی!\n",
            "همه کتابو تعریف کردن ولی یکی نگفت که با عمل بهش تاثیری داشته براش؟؟؟؟؟\n",
            "همه کتابو تعریف کردن ولی یکی نگفت که با عمل بهش تاثیری داشته براش؟؟؟؟؟\n",
            "شدیدا توصیه میشه :)\n",
            "شدیدا توصیه میشه :)\n",
            "کتاب عالی بود.ولی اگه میشه کتابهای بیشتری بذارید.\n",
            "کتاب عالی بود.ولی اگه میشه کتابهای بیشتری بذارید.\n",
            "کتاب فوق العاده کاربردی. هر صفحه اش جا تفکر داره.  ارزش خوندن داره.\n",
            "کتاب فوق العاده کاربردی. هر صفحه اش جا تفکر داره.  ارزش خوندن داره.\n",
            "اگه قرار باشه آدم یه کتابو درست تو زندگیش بخونه همین کتابه.هر صفحه میخونی کنجکاو میشی بیشتر بری جلو.فوق العادس\n",
            "اگه قرار باشه آدم یه کتابو درست تو زندگیش بخونه همین کتابه.هر صفحه میخونی کنجکاو میشی بیشتر بری جلو.فوق العادس\n",
            "خیلی راهکارهای موثری ارائه میده خیلی کتاب ثاثیر گذار و خوبیه.....از این کتابها بیشتر بذار طاقچه جان\n",
            "خیلی راهکارهای موثری ارائه میده خیلی کتاب ثاثیر گذار و خوبیه.....از این کتابها بیشتر بذار طاقچه جان\n",
            "این کتابو که میخونی میبینی تقریبا همه خصوصیات روحی انسانهای فقیرو داری و تازه میفهمی که اشتباهاتت چیه. به واقع که برای کسب ثر ت و موفقیت باید ذهنیتشو داشت. ممنون از طاقچه این کتاب تاثیر زیا دی رو من داشته\n",
            "این کتابو که میخونی میبینی تقریبا همه خصوصیات روحی انسانهای فقیرو داری و تازه میفهمی که اشتباهاتت چیه. به واقع که برای کسب ثر ت و موفقیت باید ذهنیتشو داشت. ممنون از طاقچه این کتاب تاثیر زیا دی رو من داشته\n",
            "کاش قابلیت بوک مارک کردن صفحات رو هم اضافه کنید. گاهی آدم نیاز داره صفحات خاصی رو مرور کنه.\n",
            "کاش قابلیت بوک مارک کردن صفحات رو هم اضافه کنید. گاهی آدم نیاز داره صفحات خاصی رو مرور کنه.\n",
            "بهزاد جان\n",
            "اگه آدم  ندونه چطور فکر کنه\n",
            "چطوری مغزشو بکتر بندازه و تلاش کنه؟\n",
            "خیلیا هستن که هم تلاش میکنن هم فکرشون کار میکنه\n",
            "ولی همیشه هشتشون گرو نه‌شونه!!!\n",
            "وبعضیا هم برعکس اینن.\n",
            "پس به ذهنیت و طرز فکر آدما مربوطه و این کتاب هم همینو میخواد برتمون روشن کنه.\n",
            "بهزاد جان\n",
            "اگه آدم  ندونه چطور فکر کنه\n",
            "چطوری مغزشو بکتر بندازه و تلاش کنه؟\n",
            "خیلیا هستن که هم تلاش میکنن هم فکرشون کار میکنه\n",
            "ولی همیشه هشتشون گرو نه‌شونه!!!\n",
            "وبعضیا هم برعکس اینن.\n",
            "پس به ذهنیت و طرز فکر آدما مربوطه و این کتاب هم همینو میخواد برتمون روشن کنه.\n",
            "عزیزم نمی خواد واسه اینجور مساءل کتاب بخونی . فقط مغزتو به کار بنداز و تلاشتو بکن. همین .\n",
            "عزیزم نمی خواد واسه اینجور مساءل کتاب بخونی . فقط مغزتو به کار بنداز و تلاشتو بکن. همین .\n",
            "سلام ممنون بابت بذنامه خوب و کتاب خوبتون من وقتی می خوام کتابو بخونم ازیه صفحه ای ببعد از کتاب خارج میشه لطفا رسیدگی کنن ممنون ه\n",
            "سلام ممنون بابت بذنامه خوب و کتاب خوبتون من وقتی می خوام کتابو بخونم ازیه صفحه ای ببعد از کتاب خارج میشه لطفا رسیدگی کنن ممنون ه\n",
            "این کتاب میخواد بگه که فقر مادی از فقر ذهن و فکر آدمه.\n",
            "این کتاب میخواد بگه که فقر مادی از فقر ذهن و فکر آدمه.\n",
            "به نظرماین کتاب  بسیار خوب توانسته احساسات و حالات تمام فقیران و ثروتمندان را بیان کنه و نظرات اشتباه رو به چالش بکشه\n",
            "به نظرماین کتاب  بسیار خوب توانسته احساسات و حالات تمام فقیران و ثروتمندان را بیان کنه و نظرات اشتباه رو به چالش بکشه\n",
            "این کتاب فوقالعادست و  پیشنهاد میکنم از دستش ندید!\n",
            "این کتاب فوقالعادست و  پیشنهاد میکنم از دستش ندید!\n",
            "با تشکر از برنامه طاقچه بابت ارائه نسخه الکترونیکی این کتاب جذاب \n",
            "و سلام به همه کسانی که قصد تحول در زندگی را دارند!\n",
            "اگر تا به امروز به این نتیجه رسیده‌اید که زندگی شما همینه که در حال حاضر وجود داره، پس خواندن این کتاب را به شما پیشنهاد می کنم. \n",
            "با آرزوی کتاب خوان شدن برای همه!\n",
            "با تشکر از برنامه طاقچه بابت ارائه نسخه الکترونیکی این کتاب جذاب \n",
            "و سلام به همه کسانی که قصد تحول در زندگی را دارند!\n",
            "اگر تا به امروز به این نتیجه رسیده‌اید که زندگی شما همینه که در حال حاضر وجود داره، پس خواندن این کتاب را به شما پیشنهاد می کنم. \n",
            "با آرزوی کتاب خوان شدن برای همه!\n",
            "این کتاب فوق العادس . بی نهایت انگیزه میده . طرز فکرم متحول شد.\n",
            "این کتاب فوق العادس . بی نهایت انگیزه میده . طرز فکرم متحول شد.\n",
            "من نسخه چاپی رو دارم، اینقدکه ازش خوشم اومد ازاینجاهم خریدم تاهمیشه همرام باشه. طاقچه جون اگه کتابهای خانم دبی فورد هم بذاری ممنون میشم :)\n",
            "من نسخه چاپی رو دارم، اینقدکه ازش خوشم اومد ازاینجاهم خریدم تاهمیشه همرام باشه. طاقچه جون اگه کتابهای خانم دبی فورد هم بذاری ممنون میشم :)\n",
            "به نظرم خیلی کتاب جالبی بود، مخصوصاً اون بخشی که درباره ذهنیت حرف میزد و این که با چه ذهنیت هایی بزرگ می شیم که مانغ پیشرفت ما می شن!\n",
            "به نظرم خیلی کتاب جالبی بود، مخصوصاً اون بخشی که درباره ذهنیت حرف میزد و این که با چه ذهنیت هایی بزرگ می شیم که مانغ پیشرفت ما می شن!\n",
            "عالیه با آرزوی موفقیت واسه خودم و اونایی که این کتابو میخونن\n",
            "عالیه با آرزوی موفقیت واسه خودم و اونایی که این کتابو میخونن\n",
            "کتاب خیلی خوبیه\n",
            "مرسی طاقچه\n",
            "کتاب خیلی خوبیه\n",
            "مرسی طاقچه\n",
            "عالی بود..کاش جلد دوم و سومشم بزارید..کتاب آناتومی پی دی اف نیس واقعا که همه جا بتونیم دنبالمون داشته باشیم😔\n",
            "عالی بود..کاش جلد دوم و سومشم بزارید..کتاب آناتومی پی دی اف نیس واقعا که همه جا بتونیم دنبالمون داشته باشیم\n",
            "لطفا آناتومی گری بذارید\n",
            "لطفا آناتومی گری بذارید\n",
            "کتاب اسنل کتاب خوبیه ، من قبلا گری خوندم . تصاویر گری بهتره اما اسنل همونطور که از اسم‌اش معلومه بیشتر به مباحث بالینی پرداخته.\n",
            "پ.ن:متاسفانه تعداد کتب آموزش پزشکی طاقچه خیلی کمه!\n",
            "کتاب اسنل کتاب خوبیه ، من قبلا گری خوندم . تصاویر گری بهتره اما اسنل همونطور که از اسم‌اش معلومه بیشتر به مباحث بالینی پرداخته.\n",
            "پ.ن:متاسفانه تعداد کتب آموزش پزشکی طاقچه خیلی کمه!\n",
            "واقعا کتاب ضعیفی در زمینه آناتومی هستش\n",
            "واقعا کتاب ضعیفی در زمینه آناتومی هستش\n",
            "لطفاً طاقچه رو از نظر کتابای پزشکی تقویت کنید، حیفه همچین برنامه ای کتابای محدودی در این زمینه ارائه بده، ممنون \n",
            "لطفاً طاقچه رو از نظر کتابای پزشکی تقویت کنید، حیفه همچین برنامه ای کتابای محدودی در این زمینه ارائه بده، ممنون \n",
            "لطفا سایر جلدهای این کتاب را هم بزارید \n",
            "کتاب بری و کهن هم بزارید منابع اصلی پزشکی و پیراپزشکیتون خیلی کم و نامعتبر هستند لطفا در این زمینه طاقچه را تقویت کنید\n",
            "لطفا سایر جلدهای این کتاب را هم بزارید \n",
            "کتاب بری و کهن هم بزارید منابع اصلی پزشکی و پیراپزشکیتون خیلی کم و نامعتبر هستند لطفا در این زمینه طاقچه را تقویت کنید\n",
            "سلام من کتاب آناتومی اسنل رو خریدم اما pdf  آن توی گوشیم ذخیره نشده\n",
            "لطفا راهنماییم کنید\n",
            "سلام من کتاب آناتومی اسنل رو خریدم اما pdf  آن توی گوشیم ذخیره نشده\n",
            "لطفا راهنماییم کنید\n",
            "نیازمند شدید جلدهای دیگه ایم لطفا هر چه سریعتر با تشکر \n",
            "نیازمند شدید جلدهای دیگه ایم لطفا هر چه سریعتر با تشکر \n",
            "سلام ببخشید من دانلود کردم و خریدم هم این کتابو هم کتاب پرستاربیهوشی جلد اول اما متاسفانه تو گوشیم ویروس کشی کردم انگار اطلاعات برنامه طاقچه هم پرید دوباره نصب کردم الان کتابا نیستن و زده که باید بخرم . یعنی تو حساب کاربری من ثبت نمیشه چ کتابایی خریدم ؟ بصورت پی دی افم که تو گوشی سیو نمیشه خارج از برنامه . لطفا راهنمایی کنید .ممنون\n",
            "سلام ببخشید من دانلود کردم و خریدم هم این کتابو هم کتاب پرستاربیهوشی جلد اول اما متاسفانه تو گوشیم ویروس کشی کردم انگار اطلاعات برنامه طاقچه هم پرید دوباره نصب کردم الان کتابا نیستن و زده که باید بخرم . یعنی تو حساب کاربری من ثبت نمیشه چ کتابایی خریدم ؟ بصورت پی دی افم که تو گوشی سیو نمیشه خارج از برنامه . لطفا راهنمایی کنید .ممنون\n",
            "سلام من خریدم دانلودم کردم اما تو گوشیم نیستش که بخام زمان افلاین بخونمش ؟ اگه میشه راهنمایی کنید\n",
            "سلام من خریدم دانلودم کردم اما تو گوشیم نیستش که بخام زمان افلاین بخونمش ؟ اگه میشه راهنمایی کنید\n",
            "بقیه جلد هاشم بیارید دگ لطفا\n",
            "بقیه جلد هاشم بیارید دگ لطفا\n",
            "نمیدونم داستان ها بی معنی و مفهوم بود یا من چیزی ازشون نفهمیدم، کلا دوتاشو بیشتر نتونستم بخونم حالم بد شد\n",
            "نمیدونم داستان ها بی معنی و مفهوم بود یا من چیزی ازشون نفهمیدم، کلا دوتاشو بیشتر نتونستم بخونم حالم بد شد\n",
            "پر از نوستالژی دردناک بود و تصاویر شاعرانه زیبا این مجموعه شعر کوتاه رو حتما مطالعه کنید طاقچه جان در قسمت ت ضیحات تعداد صفحات به اشتباه نوشته شده ست . با سپاس\n",
            "پر از نوستالژی دردناک بود و تصاویر شاعرانه زیبا این مجموعه شعر کوتاه رو حتما مطالعه کنید طاقچه جان در قسمت ت ضیحات تعداد صفحات به اشتباه نوشته شده ست . با سپاس\n",
            "من دنبال کتاب مبتدی و قابل درک فلسفی در مورد هستی بودم کتاب مناسبی برام نبود\n",
            "من دنبال کتاب مبتدی و قابل درک فلسفی در مورد هستی بودم کتاب مناسبی برام نبود\n",
            "ترجمه روان موضوع بکر متن اعجاب انگیز این کتاب  را حواندنی کرده است روح احمد شاملو شاد\n",
            "ترجمه روان موضوع بکر متن اعجاب انگیز این کتاب  را حواندنی کرده است روح احمد شاملو شاد\n",
            "زنده یاد پرویز خسروانی با تاسیس تاج جای خودش رو تا ابد در قلب نصف جمعیت ایران باز کرد ...روحت شاد ای بزرگمرد .....مطمئنم که تایید نمیکنید\n",
            "زنده یاد پرویز خسروانی با تاسیس تاج جای خودش رو تا ابد در قلب نصف جمعیت ایران باز کرد ...روحت شاد ای بزرگمرد .....مطمئنم که تایید نمیکنید\n",
            "🌸🌸🌸مسابقه کتاب خوانی تفسیر سوره حمد در اپلیکیشن شهید مطهری\n",
            "کتاب آشنایی با قرآن جلد دوم از شهید مطهری🌸🌸🌸\n",
            "مسابقه کتاب خوانی تفسیر سوره حمد در اپلیکیشن شهید مطهری\n",
            "کتاب آشنایی با قرآن جلد دوم از شهید مطهری\n",
            "چرا پی دی افه؟\n",
            "مفاتیح که نیس\n",
            "نهج البلاغه که نیس\n",
            "قرآنم که نیس\n",
            "...\n",
            "چرا پی دی افه؟\n",
            "مفاتیح که نیس\n",
            "نهج البلاغه که نیس\n",
            "قرآنم که نیس\n",
            "...\n",
            "ممنون عالیه\n",
            "ممنون عالیه\n",
            "چندمین ماه رمضون به صورت پیاپیه؟؟؟ که انقد گرفتار بودم...\n",
            "بازم نتونستم تمومش کنم\n",
            "می‌دونم به فهم و رسوخ در دل و این حرفاس، به خوندنِ طوطی‌وار و تموم کردنِ همین‌جوری نیس؛ اما دلم می‌خواس تمومش کنم😔\n",
            "چندمین ماه رمضون به صورت پیاپیه؟؟؟ که انقد گرفتار بودم...\n",
            "بازم نتونستم تمومش کنم\n",
            "می‌دونم به فهم و رسوخ در دل و این حرفاس، به خوندنِ طوطی‌وار و تموم کردنِ همین‌جوری نیس؛ اما دلم می‌خواس تمومش کنم\n",
            "کاش همون صفحه ای که میخواستیم میموند و خودش به سوره های بعدی نمیرفت\n",
            "کاش همون صفحه ای که میخواستیم میموند و خودش به سوره های بعدی نمیرفت\n",
            "پی دی اف چرته، اصن نمیشه خوند! ی ستاره هم زیاده\n",
            "پی دی اف چرته، اصن نمیشه خوند! ی ستاره هم زیاده\n",
            "اعراب برخی آیات شکال داشت بعضی حروف اعرابشان جا افتاده بود\n",
            "خط اول تمام آیات اعرابش نمایش داده نمی‌شد امیدوارم این مشکلات رو رفع بفرمایید\n",
            "اعراب برخی آیات شکال داشت بعضی حروف اعرابشان جا افتاده بود\n",
            "خط اول تمام آیات اعرابش نمایش داده نمی‌شد امیدوارم این مشکلات رو رفع بفرمایید\n",
            "طیب الکتب\n",
            "طیب الکتب\n",
            "بنام حضرت دوست...بسیار زیبا و جالبه . طاقچه ممنونتم♥\n",
            "چه کتابی میتواند برتر از کتابی باشد که نویسنده اش خداست\n",
            ".\n",
            "یا علی 👋\n",
            "بنام حضرت دوست...بسیار زیبا و جالبه . طاقچه ممنونتم\n",
            "چه کتابی میتواند برتر از کتابی باشد که نویسنده اش خداست\n",
            ".\n",
            "یا علی \n",
            "با سلام خدمت همه دست اندر کاران فرهنگ و ادب کتاب فوق متاسفانه در برخی کلمات فاقد اعراب بوده و ممکن است در قرائت ناصحیح معانی متفاوتی پیدا می کند. لذا از عزیزان خواهشمندم نسبت به اصلاح pdfموجود پرداخته سپس در دسترس عموم قرار دهید. با تشکر ومن الله التوفیق\n",
            "با سلام خدمت همه دست اندر کاران فرهنگ و ادب کتاب فوق متاسفانه در برخی کلمات فاقد اعراب بوده و ممکن است در قرائت ناصحیح معانی متفاوتی پیدا می کند. لذا از عزیزان خواهشمندم نسبت به اصلاح pdfموجود پرداخته سپس در دسترس عموم قرار دهید. با تشکر ومن الله التوفیق\n",
            "قرآن ثقل اکبره و عترت ثقل اصغر؛ فراموش نکنیم و جای بزرگ‌تر و کوچیک‌تر رو جابه‌جا نکنیم...\n",
            "قرآن ثقل اکبره و عترت ثقل اصغر؛ فراموش نکنیم و جای بزرگ‌تر و کوچیک‌تر رو جابه‌جا نکنیم...\n",
            "سه ستاره میدم چون پی دی افه خیلی سخته خوندش. والا ترجمه آقای فولاوند که خیلی خووبه. من با ترجمه مکارم٬بهرام پور٬انصاریان یه مقایسه در حد خودم (خعلی ابتدایی) کردم و اینو بهتر دیدم.\n",
            "ترجمه فولاوند بین تحت الفظی و محتواییه ٬وفاداری بیشتری نسبت به متن و همچنین ساختار آیه ها داره. نه مثل تحت الفظی بی معنیه و نه مثل محتوایی (ترجمه مکارم) مملو از پرانتز و برداشت مترجمه. یه ترجمه قران دیگه هم از آقای محمد علی کوشا امسال بالاخره منتشر میشه که از همه اینها بهتره!\n",
            "سه ستاره میدم چون پی دی افه خیلی سخته خوندش. والا ترجمه آقای فولاوند که خیلی خووبه. من با ترجمه مکارم٬بهرام پور٬انصاریان یه مقایسه در حد خودم (خعلی ابتدایی) کردم و اینو بهتر دیدم.\n",
            "ترجمه فولاوند بین تحت الفظی و محتواییه ٬وفاداری بیشتری نسبت به متن و همچنین ساختار آیه ها داره. نه مثل تحت الفظی بی معنیه و نه مثل محتوایی (ترجمه مکارم) مملو از پرانتز و برداشت مترجمه. یه ترجمه قران دیگه هم از آقای محمد علی کوشا امسال بالاخره منتشر میشه که از همه اینها بهتره!\n",
            "حُرِّمَتْ عَلَیْکُمُ الْمَیْتَةُ وَالدَّمُ وَلَحْمُ الْخِنْزِیرِ وَمَا أُهِلَّ لِغَیْرِ اللَّهِ بِهِ وَالْمُنْخَنِقَةُ وَالْمَوْقُوذَةُ وَالْمُتَرَدِّیَةُ وَالنَّطِیحَةُ وَمَا أَکَلَ السَّبُعُ إِلَّا مَا ذَکَّیْتُمْ وَمَا ذُبِحَ عَلَی النُّصُبِ وَأَنْ تَسْتَقْسِمُوا بِالْأَزْلَامِ ۚ ذَٰلِکُمْ فِسْقٌ ۗ الْیَوْمَ یَئِسَ الَّذِینَ کَفَرُوا مِنْ دِینِکُمْ فَلَا تَخْشَوْهُمْ وَاخْشَوْنِ ۚ الْیَوْمَ أَکْمَلْتُ لَکُمْ دِینَکُمْ وَأَتْمَمْتُ عَلَیْکُمْ نِعْمَتِی وَرَضِیتُ لَکُمُ الْإِسْلَامَ دِینًا ۚ فَمَنِ اضْطُرَّ فِی مَخْمَصَةٍ غَیْرَ مُتَجَانِفٍ لِإِثْمٍ ۙ فَإِنَّ اللَّهَ غَفُورٌ رَحِیمٌ\n",
            "عاشق آن پیامی هستم که خداوند در دل این آیه پنهان کرده است. مومنین را نوید می دهد به کامل کردن دین و ناامیدی کافران... سلام بر امیرالمومنین، سلام بر فرزندش مهدی و سلام بر شیعیانش که وارثان زمین خواهند بود و نابود کننده کافران...\n",
            "حُرِّمَتْ عَلَیْکُمُ الْمَیْتَةُ وَالدَّمُ وَلَحْمُ الْخِنْزِیرِ وَمَا أُهِلَّ لِغَیْرِ اللَّهِ بِهِ وَالْمُنْخَنِقَةُ وَالْمَوْقُوذَةُ وَالْمُتَرَدِّیَةُ وَالنَّطِیحَةُ وَمَا أَکَلَ السَّبُعُ إِلَّا مَا ذَکَّیْتُمْ وَمَا ذُبِحَ عَلَی النُّصُبِ وَأَنْ تَسْتَقْسِمُوا بِالْأَزْلَامِ ۚ ذَٰلِکُمْ فِسْقٌ ۗ الْیَوْمَ یَئِسَ الَّذِینَ کَفَرُوا مِنْ دِینِکُمْ فَلَا تَخْشَوْهُمْ وَاخْشَوْنِ ۚ الْیَوْمَ أَکْمَلْتُ لَکُمْ دِینَکُمْ وَأَتْمَمْتُ عَلَیْکُمْ نِعْمَتِی وَرَضِیتُ لَکُمُ الْإِسْلَامَ دِینًا ۚ فَمَنِ اضْطُرَّ فِی مَخْمَصَةٍ غَیْرَ مُتَجَانِفٍ لِإِثْمٍ ۙ فَإِنَّ اللَّهَ غَفُورٌ رَحِیمٌ\n",
            "عاشق آن پیامی هستم که خداوند در دل این آیه پنهان کرده است. مومنین را نوید می دهد به کامل کردن دین و ناامیدی کافران... سلام بر امیرالمومنین، سلام بر فرزندش مهدی و سلام بر شیعیانش که وارثان زمین خواهند بود و نابود کننده کافران...\n",
            "و قطعا برای شما در زمین قدرت عمل و وسایل معیشت قرار دادیم ...!\n",
            "اما خیلی کم شکرگذاری میکنید ...!\n",
            "اعراف /١٠ اگه تو همین آیه تنها فکر کنید زندگیتون رو ١٨٠ درجه تغییر میدین\n",
            "و قطعا برای شما در زمین قدرت عمل و وسایل معیشت قرار دادیم ...!\n",
            "اما خیلی کم شکرگذاری میکنید ...!\n",
            "اعراف /١٠ اگه تو همین آیه تنها فکر کنید زندگیتون رو ١٨٠ درجه تغییر میدین\n",
            "حافظه زیادی میخواد\n",
            "حافظه زیادی میخواد\n",
            "کاش پی دی اف نبود ، خواستم بخونم اصن نمی شد\n",
            "کاش پی دی اف نبود ، خواستم بخونم اصن نمی شد\n",
            "\"لَقَد خَلَقَنا الانسانَ فی کَبَد\"\n",
            "*همانا انسان را در رنج آفریدیم\n",
            "خدا ما رو نجات بده از بی دردی...\n",
            "وقتی بی درد شدیم باید بترسیم از خودمون، که از مقام انسانیت پایین نیومده باشیم\n",
            "و خدا کنه، خدا! به ما دردای قشنگ بده، نه دردای کوچیک و بی ارزش...\n",
            "\"لَقَد خَلَقَنا الانسانَ فی کَبَد\"\n",
            "*همانا انسان را در رنج آفریدیم\n",
            "خدا ما رو نجات بده از بی دردی...\n",
            "وقتی بی درد شدیم باید بترسیم از خودمون، که از مقام انسانیت پایین نیومده باشیم\n",
            "و خدا کنه، خدا! به ما دردای قشنگ بده، نه دردای کوچیک و بی ارزش...\n",
            "نماز روزه هاتون قبول باشه همگی...\n",
            "عجب ماهی... عجب حال و هوایی ☺️\n",
            "نماز روزه هاتون قبول باشه همگی...\n",
            "عجب ماهی... عجب حال و هوایی \n",
            "نسخه epub قرآن کریم از لینک زیر قابل دریافت است.\n",
            "______________________________\n",
            ".\n",
            ".\n",
            "https://taaghche.ir/book/2679\n",
            "نسخه epub قرآن کریم از لینک زیر قابل دریافت است.\n",
            "______________________________\n",
            ".\n",
            ".\n",
            "https://taaghche.ir/book/2679\n",
            "همه ی کتاب های عالی رو داره حافظ سهدی قران شاهنامه همشم رایگانه\n",
            "همه ی کتاب های عالی رو داره حافظ سهدی قران شاهنامه همشم رایگانه\n",
            "قرآن، عمیق ترین و رازآلود ترین کتاب جهانه. وای به حال امثال من، که واسه خوندن کتاب های دیگه مشتاقن و نسبت به قرآن، بی رغبت ...\n",
            "قرآن، عمیق ترین و رازآلود ترین کتاب جهانه. وای به حال امثال من، که واسه خوندن کتاب های دیگه مشتاقن و نسبت به قرآن، بی رغبت ...\n",
            "کاش غریب ترین کتاب از غربت بیرون بیاد\n",
            "کاش غریب ترین کتاب از غربت بیرون بیاد\n",
            "very good\n",
            "very good\n",
            "دست آقای فولادوند دردنکنه با ترجمه بسار خوبش واقعا خیلی خیلی عالیه پنج ستاره کمه واسه این کتاب با ارزش\n",
            "دست آقای فولادوند دردنکنه با ترجمه بسار خوبش واقعا خیلی خیلی عالیه پنج ستاره کمه واسه این کتاب با ارزش\n",
            "بهترین ترجمه ای که تا حالا دیدم!\n",
            "بهترین ترجمه ای که تا حالا دیدم!\n",
            "راهی که برای ذلت ما دشمن انتخاب کرده است، بهترین راهنمای است تا برای عزت خویش انتخاب کنیم.\n",
            "بازگشتن درست از همان راه که او مارا برده است.\n",
            "باز آوردن قرآن از قبرستان به شهر، تلاوت آن از این پس برای زندگان! و فرود آوردن قرآن از بالای رف و گشودنش در پیش روی درس.\n",
            "قرآن را نتوانستند نابود کنند بستند و کتاب را یک شی متبرک کردند.\n",
            "آن را دوباره کتاب کنیم وکتابِ خواندن! که قرآن یعنی کتابِ خواندن...\n",
            "حج/دکتر علی شریعتی\n",
            "راهی که برای ذلت ما دشمن انتخاب کرده است، بهترین راهنمای است تا برای عزت خویش انتخاب کنیم.\n",
            "بازگشتن درست از همان راه که او مارا برده است.\n",
            "باز آوردن قرآن از قبرستان به شهر، تلاوت آن از این پس برای زندگان! و فرود آوردن قرآن از بالای رف و گشودنش در پیش روی درس.\n",
            "قرآن را نتوانستند نابود کنند بستند و کتاب را یک شی متبرک کردند.\n",
            "آن را دوباره کتاب کنیم وکتابِ خواندن! که قرآن یعنی کتابِ خواندن...\n",
            "حج/دکتر علی شریعتی\n",
            "عید فطر را پیشاپیش به تمام روزداران تبریک می گویم\n",
            "التماس دعا\n",
            "عید فطر را پیشاپیش به تمام روزداران تبریک می گویم\n",
            "التماس دعا\n",
            "قرآن‌های الکتریکی و هوشمند عالی است \n",
            "همه جا با خودمان داریم \n",
            "واقعا عاللللللی است\n",
            "قرآن‌های الکتریکی و هوشمند عالی است \n",
            "همه جا با خودمان داریم \n",
            "واقعا عاللللللی است\n",
            "ابن اسحاق کندی، فیلسوفی عراقی بود که در نیمه قرن سوم هجری و همزمان با عصر امام حسن عسکری(علیه السلام) می زیست. او به توهّم تناقض و اختلاف در آیات قرآن، مشغول جمع ‌آوری آیاتی شد. وی آن‌ها را به صورت رساله تدوین کرد. چون امام حسن عسکری(علیه السلام) توسّط یکی از شاگردان او از این مطلب آگاه شد، فرمود: آیا نمی توانید استادتان را از این کار منصرف کنید. در ادامه حضرت به یکی از شاگردان ابن اسحاق کندی فرمود: «برو و از استادت بپرس: آیا امکان دارد روزی خداوند بگوید که من از آیات قرآن، هدفی غیر از آنچه تو فهمیدی داشتم؟ چنانچه پذیرفت، بگو: پس چگونه مدّعی تناقض بین آیات قرآن هستی؟». شاگرد در خدمت استاد، همین مطالب را بازگو کرد. او که از این استدلال شگفت زده شده بود، آتشی افروخت و دست نوشته ‌هایش را در آن افکند.\n",
            "\n",
            "منبع:پایگاه اطلاع رسانی دفتر حضرت آیت الله مکارم شیرازی/قسمت کتاب و مقالات/بخش مقالات/مقاله \"گمان تناقض در قرآن\"\n",
            "ابن اسحاق کندی، فیلسوفی عراقی بود که در نیمه قرن سوم هجری و همزمان با عصر امام حسن عسکری(علیه السلام) می زیست. او به توهّم تناقض و اختلاف در آیات قرآن، مشغول جمع ‌آوری آیاتی شد. وی آن‌ها را به صورت رساله تدوین کرد. چون امام حسن عسکری(علیه السلام) توسّط یکی از شاگردان او از این مطلب آگاه شد، فرمود: آیا نمی توانید استادتان را از این کار منصرف کنید. در ادامه حضرت به یکی از شاگردان ابن اسحاق کندی فرمود: «برو و از استادت بپرس: آیا امکان دارد روزی خداوند بگوید که من از آیات قرآن، هدفی غیر از آنچه تو فهمیدی داشتم؟ چنانچه پذیرفت، بگو: پس چگونه مدّعی تناقض بین آیات قرآن هستی؟». شاگرد در خدمت استاد، همین مطالب را بازگو کرد. او که از این استدلال شگفت زده شده بود، آتشی افروخت و دست نوشته ‌هایش را در آن افکند.\n",
            "\n",
            "منبع:پایگاه اطلاع رسانی دفتر حضرت آیت الله مکارم شیرازی/قسمت کتاب و مقالات/بخش مقالات/مقاله \"گمان تناقض در قرآن\"\n",
            "خیلی خوب است😉\n",
            "خیلی خوب است\n",
            "خوبه ولی جای یک نسخه epub از قرآن در ایران و طاقچه خالیه\n",
            "خوبه ولی جای یک نسخه epub از قرآن در ایران و طاقچه خالیه\n",
            "برای اینکه شلوغکاری نشه ، نظر چند دانشمند یا ادیب رو که از کتاب در حدیث دیگران ، نوشتم رو در پاسخ های این نظر قرار میدم.\n",
            "برای اینکه شلوغکاری نشه ، نظر چند دانشمند یا ادیب رو که از کتاب در حدیث دیگران ، نوشتم رو در پاسخ های این نظر قرار میدم.\n",
            "دکتر عبدالکریم سروش(نواندیش دینی) بر این باور است که قرآن علمی نیست.\n",
            "او معتقد است که نسبت دادن قرآن به  علم به بازی حریف تن دادن است.\n",
            "و نتیجه ای جز شکست ندارد.\n",
            "\n",
            "دکتر سروش در کتاب علم چیست؟ فلسفه چیست؟\n",
            "اینطور میگه؛\n",
            "《و چه اندوه بار و رنج آور است که می بینیم کسانی مقلدانه و عامیانه به دفاع از علمی بودن اسلام و ایمان برخواسته اند.\n",
            "و در غایت خامی و ساده لوحی تن به افسون رقیب داده اند.》\n",
            "دکتر عبدالکریم سروش(نواندیش دینی) بر این باور است که قرآن علمی نیست.\n",
            "او معتقد است که نسبت دادن قرآن به  علم به بازی حریف تن دادن است.\n",
            "و نتیجه ای جز شکست ندارد.\n",
            "\n",
            "دکتر سروش در کتاب علم چیست؟ فلسفه چیست؟\n",
            "اینطور میگه؛\n",
            "و چه اندوه بار و رنج آور است که می بینیم کسانی مقلدانه و عامیانه به دفاع از علمی بودن اسلام و ایمان برخواسته اند.\n",
            "و در غایت خامی و ساده لوحی تن به افسون رقیب داده اند.\n",
            "راه فطرت\n",
            "\n",
            "راه واقعی برای انسان در مسیر زندگی همان است که آفرینش ویژه‌ وی به سوی آن دعوت می کند و مقرراتی را در زندگی فردی و اجتماعی خود باید به کار بندد که طبیعت یک انسان فطری (طبیعی) به سوی آنها هدایت می‌کند نه انسانهایی که به هوا و هوس آلوده و در برابر عواطف و احساسات اسیر دست بسته می باشد.\n",
            "\n",
            "مقتضای دین فطری این است که تجهیزات وجودی انسان الغا نشود و حق هر یک از آنها ادا شود و جهازات مختلف و متضاد مانند قوای گوناگون عاطفی و احساسی که در  وی به ودیعه گذارده شده تعدیل شده به هرکدام از آنها تا اندازه ای که مزاحم حال دیگران نشود رخصت عمل داده شود.\n",
            "و بالاخره در وجود انسان عقل حکومت کند نه خواست نفس و نه غلبه عاطفه و احساس .\n",
            "\n",
            "📚قرآن در اسلام ، علامه طباطبایی، سیدهادی خسرو شاهی\n",
            "راه فطرت\n",
            "\n",
            "راه واقعی برای انسان در مسیر زندگی همان است که آفرینش ویژه‌ وی به سوی آن دعوت می کند و مقرراتی را در زندگی فردی و اجتماعی خود باید به کار بندد که طبیعت یک انسان فطری (طبیعی) به سوی آنها هدایت می‌کند نه انسانهایی که به هوا و هوس آلوده و در برابر عواطف و احساسات اسیر دست بسته می باشد.\n",
            "\n",
            "مقتضای دین فطری این است که تجهیزات وجودی انسان الغا نشود و حق هر یک از آنها ادا شود و جهازات مختلف و متضاد مانند قوای گوناگون عاطفی و احساسی که در  وی به ودیعه گذارده شده تعدیل شده به هرکدام از آنها تا اندازه ای که مزاحم حال دیگران نشود رخصت عمل داده شود.\n",
            "و بالاخره در وجود انسان عقل حکومت کند نه خواست نفس و نه غلبه عاطفه و احساس .\n",
            "\n",
            "قرآن در اسلام ، علامه طباطبایی، سیدهادی خسرو شاهی\n",
            "سلام بر همه عزیزان\n",
            "\n",
            "ماجرای اتصال دریاها چیست؟\n",
            "\n",
            "چند وقت پیش جناب روح الله یک کلیپ رو برای من فرستاد که به عنوان معجزه قرآن مطرح شده.\n",
            "\n",
            "متاسفانه از اونجایی که قبلا هم گفتم بسیاری از عزیزان دنبال علم نیستن، دلشون به شبه علم خوشه\n",
            "از راه های شناسایی شبه علم همین نشر کلیپ های جنجالیه.\n",
            "\n",
            "خب در ادامه میخوام به این موضوع بپردازم که آیا واقعا همچین چیزی هست؟؟\n",
            "\n",
            "آیا واقعا گفته این عزیزان صحت داره؟؟؟\n",
            "\n",
            "من مطالبی رو عنوان میکنم صرفا جهت روشنگری\n",
            "هرکدوم از عزیزان هم اشکالی در گفته های من پیدا کردن بگن.\n",
            "\n",
            "\n",
            "\n",
            "چند سالی است عکس و فیلم‌هایی در شبکه‌های اجتماعی به طرز باورنکردنی منتشر می‌شود که ادعا می‌کند تصاویری از برخورد دو دریای بالتیک و دریای شمال به یکدیگر است و آب این دو دریا با یکدیگر ترکیب نمی‌شود و طبق معمول هم عده‌ای که کارشان ربط دادن انواع مسائلی است که حداقل ۱۰٪ با هم شباهت دارند کمر همت بستند و با زور و ضرب این رویداد طبیعی را به معجزات و آیات قرآن مرتبط کرده‌اند! متنی که به همراه این عکس منتشر می‌شود مضمونی اینچنینی دارد:\n",
            "«در شمالی ترین شهر دانمارک می توان یک نشانه قرآنی را دید. در شهر توریستی اسکاگن این زیبایی را می توان در سجیه دید. جایی که دریای بالتیک و دریای شمالی بهم می پیوندند. دو دریای مختلف با هم یکی نمی شوند و بنابرین این پدیده زیبا بوجود می آید و این همان چیزی است که در قرآن آمده است.» و پس از آن آیات زیر را از قرآن در ارتباط با این رویداد بیان می‌کنند:\n",
            "سلام بر همه عزیزان\n",
            "\n",
            "ماجرای اتصال دریاها چیست؟\n",
            "\n",
            "چند وقت پیش جناب روح الله یک کلیپ رو برای من فرستاد که به عنوان معجزه قرآن مطرح شده.\n",
            "\n",
            "متاسفانه از اونجایی که قبلا هم گفتم بسیاری از عزیزان دنبال علم نیستن، دلشون به شبه علم خوشه\n",
            "از راه های شناسایی شبه علم همین نشر کلیپ های جنجالیه.\n",
            "\n",
            "خب در ادامه میخوام به این موضوع بپردازم که آیا واقعا همچین چیزی هست؟؟\n",
            "\n",
            "آیا واقعا گفته این عزیزان صحت داره؟؟؟\n",
            "\n",
            "من مطالبی رو عنوان میکنم صرفا جهت روشنگری\n",
            "هرکدوم از عزیزان هم اشکالی در گفته های من پیدا کردن بگن.\n",
            "\n",
            "\n",
            "\n",
            "چند سالی است عکس و فیلم‌هایی در شبکه‌های اجتماعی به طرز باورنکردنی منتشر می‌شود که ادعا می‌کند تصاویری از برخورد دو دریای بالتیک و دریای شمال به یکدیگر است و آب این دو دریا با یکدیگر ترکیب نمی‌شود و طبق معمول هم عده‌ای که کارشان ربط دادن انواع مسائلی است که حداقل ۱۰٪ با هم شباهت دارند کمر همت بستند و با زور و ضرب این رویداد طبیعی را به معجزات و آیات قرآن مرتبط کرده‌اند! متنی که به همراه این عکس منتشر می‌شود مضمونی اینچنینی دارد:\n",
            "«در شمالی ترین شهر دانمارک می توان یک نشانه قرآنی را دید. در شهر توریستی اسکاگن این زیبایی را می توان در سجیه دید. جایی که دریای بالتیک و دریای شمالی بهم می پیوندند. دو دریای مختلف با هم یکی نمی شوند و بنابرین این پدیده زیبا بوجود می آید و این همان چیزی است که در قرآن آمده است.» و پس از آن آیات زیر را از قرآن در ارتباط با این رویداد بیان می‌کنند:\n",
            "دوستان نظرتون چیه یه گروه بزنیم برای تبادل نظرات \n",
            "دوستان نظرتون چیه یه گروه بزنیم برای تبادل نظرات \n",
            "‍ ✅ارنست رنان (فرانسوی):\n",
            "\n",
            "در کتابخانه شخصی من هزاران جلد کتاب سیاسی، اجتماعی، ادبی و... وجود دارد که همه آنها را بیشتر از یک بار مطالعه نکرده ام و چه بسا کتابهایی که فقط زینت کتابخانه من می باشند ولی یک جلد کتاب است که همیشه مونس من است و هر وقت خسته می شوم و می خواهم درهایی از معانی و کمال بر روی من باز شود آن را مطالعه می کنم و از مطالعه زیاد آن خسته و ملول نمی شوم. این کتاب، قرآن، کتاب آسمانی مسلمین است.\n",
            "\n",
            "\n",
            "\n",
            "📚حدیث دیگران، فرامرز میرشکار\n",
            "#قرآن_کریم\n",
            " ارنست رنان (فرانسوی):\n",
            "\n",
            "در کتابخانه شخصی من هزاران جلد کتاب سیاسی، اجتماعی، ادبی و... وجود دارد که همه آنها را بیشتر از یک بار مطالعه نکرده ام و چه بسا کتابهایی که فقط زینت کتابخانه من می باشند ولی یک جلد کتاب است که همیشه مونس من است و هر وقت خسته می شوم و می خواهم درهایی از معانی و کمال بر روی من باز شود آن را مطالعه می کنم و از مطالعه زیاد آن خسته و ملول نمی شوم. این کتاب، قرآن، کتاب آسمانی مسلمین است.\n",
            "\n",
            "\n",
            "\n",
            "حدیث دیگران، فرامرز میرشکار\n",
            "#قرآن_کریم\n",
            "در مجموعه کتابهای طاقچه ، کتاب « القران الکریم» با ترجمه آیت الله مکارم شیرازی هم هست که من در قسمت کتابهام دارم ولی در لیست درختی کتابها نیست اصلا قسمت جستجو هم نمیاره و حتی نظراتشم هم نمیاره.خودمم از طریق نظرات یکی از کاربران بطور غیرمستقیم وارد صفحه دانلودش شدم.انگار سیستم ادرسی دهی اون حذف شده😮\n",
            "در مجموعه کتابهای طاقچه ، کتاب « القران الکریم» با ترجمه آیت الله مکارم شیرازی هم هست که من در قسمت کتابهام دارم ولی در لیست درختی کتابها نیست اصلا قسمت جستجو هم نمیاره و حتی نظراتشم هم نمیاره.خودمم از طریق نظرات یکی از کاربران بطور غیرمستقیم وارد صفحه دانلودش شدم.انگار سیستم ادرسی دهی اون حذف شده\n",
            "قرآن یه کتاب آسمونی هس ک تا به امروز ما بیشتر درمان _راه و روش زندگی _عاقبت کارها همشو از این کتاب یاد گرفتیم من میخوام مهمون به این کتاب ارزش قاعل باشیم و ممنون از برنامه خوبتون😻\n",
            "قرآن یه کتاب آسمونی هس ک تا به امروز ما بیشتر درمان _راه و روش زندگی _عاقبت کارها همشو از این کتاب یاد گرفتیم من میخوام مهمون به این کتاب ارزش قاعل باشیم و ممنون از برنامه خوبتون\n",
            "\"...یونس ،تو نمی توانی معنای خداوند را در کنار بقیه ی معناهای زندگی ات بچینی.وقتی خداوند در معصومیت کودکان ،مثل برف زمستانی می درخشد تو کجایی یونس؟واقعا تو کجایی ؟شاید خداوند در هیچ جای دیگر هستی مثل معصومیت کودکی،خودش را این گونه آشکار نکرده باشد.من گاهی از شدت وضوح خداوند در کودکان ،پر از هراس می شوم و دل ام شروع می کند به تپیدن.دل ام آنقدر بلند بلند می تپد که بهت زده می دوم تا از لای انگشتان کودکان،خداوند را برگیرم.کجایی یونس؟صدای مرا می شنوی؟...\"\n",
            "(روی ماه خداوند را ببوس،مصطفی مستور،صفحه 111)\n",
            "\"...یونس ،تو نمی توانی معنای خداوند را در کنار بقیه ی معناهای زندگی ات بچینی.وقتی خداوند در معصومیت کودکان ،مثل برف زمستانی می درخشد تو کجایی یونس؟واقعا تو کجایی ؟شاید خداوند در هیچ جای دیگر هستی مثل معصومیت کودکی،خودش را این گونه آشکار نکرده باشد.من گاهی از شدت وضوح خداوند در کودکان ،پر از هراس می شوم و دل ام شروع می کند به تپیدن.دل ام آنقدر بلند بلند می تپد که بهت زده می دوم تا از لای انگشتان کودکان،خداوند را برگیرم.کجایی یونس؟صدای مرا می شنوی؟...\"\n",
            "(روی ماه خداوند را ببوس،مصطفی مستور،صفحه 111)\n",
            "إنّی تارکٌ فیکُمُ الثَّقَلَین، ما إن تَمَسَّکتُم بهما لَن تَضلّوا: کتابَ اللّه وَ عترَتی أهلَ بَیتی، فَإنَّهُما لَن یفتَرقا حَتّی یردا عَلَی الحَوضَ؛\n",
            "\n",
            "من در میان شما دو چیز گران بها به یادگار می گذارم. اگر به آن دو چنگ زنید، هرگز گمراه نمی شوید: کتاب خدا و عترتم، [یعنی] دودمانم. این دو از هم جدا نمی شوند تا در کنار حوض [کوثر] بر من واردشوند\n",
            "\"حدیث ثقلین\"\n",
            "إنّی تارکٌ فیکُمُ الثَّقَلَین، ما إن تَمَسَّکتُم بهما لَن تَضلّوا: کتابَ اللّه وَ عترَتی أهلَ بَیتی، فَإنَّهُما لَن یفتَرقا حَتّی یردا عَلَی الحَوضَ؛\n",
            "\n",
            "من در میان شما دو چیز گران بها به یادگار می گذارم. اگر به آن دو چنگ زنید، هرگز گمراه نمی شوید: کتاب خدا و عترتم، [یعنی] دودمانم. این دو از هم جدا نمی شوند تا در کنار حوض [کوثر] بر من واردشوند\n",
            "\"حدیث ثقلین\"\n",
            "میخواهند نور را با فوت خاموش کنند  ، اما نمیدانند که نور با فوت  خاموش نمیشود.\n",
            "میخواهند نور را با فوت خاموش کنند  ، اما نمیدانند که نور با فوت  خاموش نمیشود.\n",
            "برای روز مبادا، حاجی به مذهب هم معتقد بود. اگرچه با خودش می گفت: « کی از آن دنیا برگشته؟ اگر راست باشه! » و مثل عقاید سیاسیش به آن دنیا هم اعتقاد محکمی نداشت. مگر با پول نمی‌شد حج و نماز و روزه را خرید؟ پس هرکس پول داشت دو دنیا را داشت.\n",
            "\n",
            "حاجی آقا\n",
            "صادق هدایت\n",
            "برای روز مبادا، حاجی به مذهب هم معتقد بود. اگرچه با خودش می گفت: « کی از آن دنیا برگشته؟ اگر راست باشه! » و مثل عقاید سیاسیش به آن دنیا هم اعتقاد محکمی نداشت. مگر با پول نمی‌شد حج و نماز و روزه را خرید؟ پس هرکس پول داشت دو دنیا را داشت.\n",
            "\n",
            "حاجی آقا\n",
            "صادق هدایت\n",
            "خدایا بخدا خیلی خوبی\n",
            "خدایا بخدا خیلی خوبی\n",
            "الله اکبر\n",
            "الله اکبر\n",
            "🔸إنَّا عَرَضْنَا الْأَمَانَةَ عَلَی السَّمَاوَاتِ وَالْأَرْضِ وَالْجِبَالِ فَأَبَیْنَ أَن یَحْمِلْنَهَا وَأَشْفَقْنَ مِنْهَا وَحَمَلَهَا الْإِنسَانُ إِنَّهُ کَانَ ظَلُومًا جَهُولًا🔸 \n",
            "\n",
            "ﻳﻘﻴﻨﺎ ﻣﺎ ﺍﻣﺎﻧﺖرا ﺑﺮ ﺁﺳﻤﺎﻥ ﻫﺎ ﻭ ﺯﻣﻴﻦ ﻭ ﻛﻮﻩ ﻫﺎ ﻋﺮﺿﻪ ﻛﺮﺩﻳﻢ ﻭ ﺁﻧﻬﺎ ﺍﺯ ﺑﻪ ﻋﻬﺪﻩ ﮔﺮﻓﺘﻨﺶ [ ﺑﻪ ﺳﺒﺐ ﺍﻳﻨﻜﻪ ﺍﺳﺘﻌﺪﺍﺩﺵ ﺭﺍ ﻧﺪﺍﺷﺘﻨﺪ ] ﺍﻣﺘﻨﺎﻉ ﻭﺭﺯﻳﺪﻧﺪ ﻭ ﺍﺯ ﺁﻥ هراسیدند ، ﻭ ﺍﻧﺴﺎﻥ ﺁﻥ ﺭﺍ ﭘﺬﻳﺮﻓﺖ ﺑﻰ ﺗﺮﺩﻳﺪ ﺍﻭ [ﺩﺭ ﺣﻖ ﺧﻮﻳﺶ ] ﺳﺘﻤﻜﺎﺭ و ﻧﺎﺩﺍن ﺑﻮﺩ.(قدر این مقام عظیم را نشناخت.)\n",
            "\n",
            "احزاب ،۷۲\n",
            "\n",
            "🔹اشاره تلمیحی حافظ به این آیه در شعر زیر:\n",
            "\n",
            "دوش دیدم که ملایک در میخانه زدند\n",
            "گل آدم بسرشتند و به پیمانه زدند\n",
            "\n",
            "ساکنان حرم ستر و عفاف ملکوت\n",
            "با من راه نشین باده مستانه زدند\n",
            "\n",
            "🍃آسمان بار امانت نتوانست کشید\n",
            "قرعه کار به نام من دیوانه زدند🍃\n",
            "\n",
            "جنگ هفتاد و دو ملت همه را عذر بنه\n",
            "چون ندیدند حقیقت ره افسانه زدند\n",
            "\n",
            "شکر ایزد که میان من و او صلح افتاد\n",
            "صوفیان رقص کنان ساغر شکرانه زدند\n",
            "\n",
            "آتش آن نیست که از شعله او خندد شمع\n",
            "آتش آن است که در خرمن پروانه زدند\n",
            "\n",
            "کس چو حافظ نگشاد از رخ اندیشه نقاب\n",
            "تا سر زلف سخن را به قلم شانه زدند\n",
            "#قرآن_کریم\n",
            "إنَّا عَرَضْنَا الْأَمَانَةَ عَلَی السَّمَاوَاتِ وَالْأَرْضِ وَالْجِبَالِ فَأَبَیْنَ أَن یَحْمِلْنَهَا وَأَشْفَقْنَ مِنْهَا وَحَمَلَهَا الْإِنسَانُ إِنَّهُ کَانَ ظَلُومًا جَهُولًا \n",
            "\n",
            "  را                 [       ]      هراسیدند ،         [   ]  و ن .(قدر این مقام عظیم را نشناخت.)\n",
            "\n",
            "احزاب ،۷۲\n",
            "\n",
            "اشاره تلمیحی حافظ به این آیه در شعر زیر:\n",
            "\n",
            "دوش دیدم که ملایک در میخانه زدند\n",
            "گل آدم بسرشتند و به پیمانه زدند\n",
            "\n",
            "ساکنان حرم ستر و عفاف ملکوت\n",
            "با من راه نشین باده مستانه زدند\n",
            "\n",
            "آسمان بار امانت نتوانست کشید\n",
            "قرعه کار به نام من دیوانه زدند\n",
            "\n",
            "جنگ هفتاد و دو ملت همه را عذر بنه\n",
            "چون ندیدند حقیقت ره افسانه زدند\n",
            "\n",
            "شکر ایزد که میان من و او صلح افتاد\n",
            "صوفیان رقص کنان ساغر شکرانه زدند\n",
            "\n",
            "آتش آن نیست که از شعله او خندد شمع\n",
            "آتش آن است که در خرمن پروانه زدند\n",
            "\n",
            "کس چو حافظ نگشاد از رخ اندیشه نقاب\n",
            "تا سر زلف سخن را به قلم شانه زدند\n",
            "#قرآن_کریم\n",
            "اکثرا نمره پنج دادن! ولی چون من سر شوخی رو با خالق باز کردم پس یک میدم، چون صفر نداشت.\n",
            " رابطمون که شکر آب شده، از چه حسی به چه حسی رسیدم، چه ادعاهایی داشتم و حالا هزار تا سوال بی جواب، هزار تا شک و تردید، نه به تو، به خودم، دکتر فرهنگی میگه اگه بهت نامه بنویسیم جواب میدی، نامه نوشتم و گم شد، \n",
            "خیلی چیزهارو از دست دادم و اولیش خود تو بودی، به خیلی چیزها اعتقاد داشتم، همش به باد رفت، اولیش هم خودم بودم. \n",
            "حالت اون بالا خوبه، ما که خسته ایم و گمشده، از من که گذشت، بقیه رو فراموش نکن!\n",
            "اکثرا نمره پنج دادن! ولی چون من سر شوخی رو با خالق باز کردم پس یک میدم، چون صفر نداشت.\n",
            " رابطمون که شکر آب شده، از چه حسی به چه حسی رسیدم، چه ادعاهایی داشتم و حالا هزار تا سوال بی جواب، هزار تا شک و تردید، نه به تو، به خودم، دکتر فرهنگی میگه اگه بهت نامه بنویسیم جواب میدی، نامه نوشتم و گم شد، \n",
            "خیلی چیزهارو از دست دادم و اولیش خود تو بودی، به خیلی چیزها اعتقاد داشتم، همش به باد رفت، اولیش هم خودم بودم. \n",
            "حالت اون بالا خوبه، ما که خسته ایم و گمشده، از من که گذشت، بقیه رو فراموش نکن!\n",
            "🔸 لقَد خَلَقنا الانسانَ فی اَحسن تقویم \n",
            "\n",
            "\" ﺗﻘﻮﻳﻢ\" ﺑﻪ ﻣﻌﻨﻰ ﺩﺭ ﺁﻭﺭﺩﻥ ﭼﻴﺰﻯ ﺑﻪ ﺻﻮﺭﺕ ﻣﻨﺎﺳﺐ، ﻭ ﻧﻈﺎم ﻣﻌﺘﺪﻝ ﻭ ﻛﻴﻔﻴﺖ ﺷﺎﻳﺴﺘﻪ ﺍﺳﺖ، ﻭ ﮔﺴﺘﺮﺩﮔﻰ ﻣﻔﻬﻮم ﺁﻥ ﺍﺷﺎﺭﻩ ﺑﻪ ﺍﻳﻦ ﺍﺳﺖ ﻛﻪ ﺧﺪﺍﻭﻧﺪ ﺍﻧﺴﺎﻥ ﺭﺍ ﺍﺯ ﻫﺮ ﻧﻈﺮ ﻣﻮﺯﻭﻥ ﻭ ﺷﺎﻳﺴﺘﻪ ﺁﻓﺮﻳﺪ، ﻫﻢ ﺍﺯ ﻧﻈﺮ ﺟﺴﻤﻰ، ﻭ ﻫﻢ ﺍﺯ ﻧﻈﺮ ﺭﻭﺣﻰ ﻭ ﻋﻘﻠﻰ، ﭼﺮﺍ ﻛﻪ ﻫﺮ ﮔﻮﻧﻪ ﺍﺳﺘﻌﺪﺍﺩﻯ ﺭﺍ ﺩﺭ ﻭﺟﻮﺩ ﺍﻭ ﻗﺮﺍﺭ ﺩﺍﺩﻩ، ﻭ ﺍﻭ ﺭﺍ ﺑﺮﺍﻯ ﭘﻴﻤﻮﺩﻥ ﻗﻮﺱ ﺻﻌﻮﺩﻯ ﺑﺴﻴﺎﺭ ﻋﻈﻴﻤﻰ ﺁﻣﺎﺩﻩ ﺳﺎﺧﺘﻪ، ﻭ ﺑﺎ ﺍﻳﻨﻜﻪ ﺍﻧﺴﺎﻥ\" ﺟﺮم ﺻﻐﻴﺮﻯ\" ﺍﺳﺖ،\" ﻋﺎﻟﻢ ﻛﺒﻴﺮ\" ﺭﺍ ﺩﺭ ﺍﻭ ﺟﺎ ﺩﺍﺩﻩ ﻭ ﺁﻥ ﻗﺪﺭ ﺷﺎﻳﺴﺘﮕﻴﻬﺎ ﺑﻪ ﺍﻭ ﺑﺨﺸﻴﺪﻩ ﻛﻪ ﻟﺎﻳﻖ ﺧﻠﻌﺖ ﻭَ ﻟَﻘَﺪْ ﻛَﺮَّﻣْﻨﺎ ﺑَﻨِﻰ ﺁﺩَمَ\" ﻣﺎ ﻓﺮﺯﻧﺪﺍﻥ ﺁﺩم ﺭﺍ ﻛﺮﺍﻣﺖ ﻭ ﻋﻈﻤﺖ ﺑﺨﺸﻴﺪﻳﻢ (ﺳﻮﺭﻩ ﺍﺳﺮﺍء ﺁﻳﻪ 70) ﺷﺪﻩ ﺍﺳﺖ ﻫﻤﺎﻥ ﺍﻧﺴﺎﻧﻰ ﻛﻪ ﺑﻌﺪ ﺍﺯ ﺍﺗﻤﺎم ﺧﻠﻘﺘﺶ ﻣﻰ ﻓﺮﻣﺎﻳﺪ: ﻓَﺘَﺒﺎﺭَﻙَ ﺍﻟﻠَّﻪُ ﺃَﺣْﺴَﻦُ ﺍﻟْﺨﺎﻟِﻘِﻴﻦَ\" ﭘﺲ ﺑﺰﺭﮒ ﻭ ﭘﺮ ﺑﺮﻛﺖ ﺍﺳﺖ ﺧﺪﺍﻳﻰ ﻛﻪ ﺑﻬﺘﺮﻳﻦ ﺧﻠﻖ ﻛﻨﻨﺪﮔﺎﻥ ﺍﺳﺖ\"!\n",
            "\n",
            "\n",
            "\n",
            "📚تفسیر نمونه ذیل آیه ۴ سوره التین\n",
            "#قرآن \n",
            "🔸قدر خودتان را بدانید.\n",
            "\n",
            "🆔 @ 🍀🌼\n",
            " لقَد خَلَقنا الانسانَ فی اَحسن تقویم \n",
            "\n",
            "\" \"        ،  م     ،   م                ،    ،       ،           ،           ،    \" م \" ،\"  \"                َ ََْ ََّْ َِ َمَ\"   م      ( ء  70)        م   : ََََ َُّ ََُْ َِِْ\"            \"!\n",
            "\n",
            "\n",
            "\n",
            "تفسیر نمونه ذیل آیه ۴ سوره التین\n",
            "#قرآن \n",
            "قدر خودتان را بدانید.\n",
            "\n",
            " @ \n",
            "لغزشگاههای اندیشه از نظر قرآن \n",
            "\n",
            "\n",
            "قرآن مجید که دعوت به تفکر و نتیجه گیری فکری می‌کند و تفکر را عبادت‌ \n",
            "می‌شمارد و اصول عقاید را جز با تفکر منطقی ، صحیح نمی‌داند ، به یک مطلب‌ \n",
            "اساسی توجه کرده است و آن اینکه لغزشهای فکری بشر از کجا سرچشمه می‌گیرد \n",
            "و ریشه اصلی خطاها و گمراهیها در کجاست ؟\n",
            "\n",
            "🔸تکیه بر ظن و گمان بجای علم و یقین \n",
            "قرآن می‌گوید : \n",
            "اکثر مردم چنین‌اند که اگر بخواهی پیرو آنها باشی تو را از راه حق گمراه‌ \n",
            "می‌کنند ، برای اینکه تکیه شان بر ظن و گمان است و ( نه بر یقین ) ، تنها \n",
            "با حدس و تخمین کار می‌کنند  . \n",
            "قرآن کریم در آیات زیادی به شدت با پیروی از ظن و گمان مخالفت می‌کند \n",
            "و می‌گوید : مادامی که به چیزی علم و یقین حاصل نکرده‌ای آنرا دنبال مکن .\n",
            "\n",
            "🔸میلها و هواهای نفسانی \n",
            "انسان اگر بخواهد صحیح قضاوت کند باید در مورد مطلبی که می‌اندیشد کاملا \n",
            "بی طرفی خود را حفظ کند ، یعنی کوشش کند که حقیقت خواه باشد و خویشتن‌ \n",
            "را تسلیم دلیلها و مدارک نماید ، درست مانند یک قاضی که روی پرونده‌ای‌ \n",
            "مطالعه می‌کند ، باید نسبت به طرفین دعوا بی طرف باشد . \n",
            "انسان در تفکرات خود اگر بی طرفی خود را نسبت به نفی یا اثبات مطلبی‌ \n",
            "حفظ نکند و میل نفسانیش به یک طرف باشد ، خواه‌ناخواه و بدون آنکه‌ \n",
            "خودش متوجه شود عقربه فکرش به جانب میل و خواهش نفسانیش متمایل‌ \n",
            "می‌شود این است که قرآن هوای نفس را نیز مانند تکیه بر ظن و گمان یکی از \n",
            "عوامل لغزش می‌شمارد .\n",
            "\n",
            "🔸شتابزدگی \n",
            "هر قضاوت و اظهار نظری مقداری معین مدارک لازم دارد و تا مدارک به‌ \n",
            "قدر کافی در یک مساله جمع نشود هرگونه اظهار نظر ، شتابزدگی و موجب لغزش اندیشه است قرآن کریم مکرر به اندک بودن سرمایه‌ \n",
            "علمی بشر و کافی نبودنش برای برخی قضاوتهای بزرگ اشاره می‌کند و اظهار \n",
            "جزم را دور از احتیاط تلقی می‌نماید . \n",
            "\n",
            "🔸سنت گرائی و گذشته نگری \n",
            "انسان به حکم طبع اولی خود هنگامی که می‌بیند یک فکر و عقیده خاص مورد \n",
            "قبول نسلهای گذشته بوده است خودبخود بدون آنکه مجالی به اندیشه خود بدهد \n",
            "آن را می‌پذیرد قرآن یادآوری می‌کند که پذیرفته‌ها و باورهای گذشتگان را \n",
            "مادام که با معیار عقل نسنجیده‌اید نپذیرید ، در مقابل باورهای گذشتگان‌ \n",
            "استقلال فکری داشته باشید . \n",
            "\n",
            "🔸شخصیت گرائی \n",
            "یکی دیگر از موجبات لغزش اندیشه ، گرایش به شخصیتها است شخصیتهای‌ \n",
            "بزرگ تاریخی یا معاصر از نظر عظمتی که در نفوس دارند بر روی فکر و اندیشه و تصمیم و اراده دیگران اثر می‌گذارند و در حقیقت هم‌ \n",
            "فکر و هم اراده دیگران را تسخیر می‌کنند ، دیگران آنچنان می‌اندیشند که‌ \n",
            "آنها می‌اندیشند و آنچنان تصمیم می‌گیرند که آنها می‌گیرند ، دیگران در \n",
            "مقابل آنها استقلال فکر و اراده خود را از دست می‌دهند .\n",
            "\n",
            "📚انسان و ایمان ، شهید مطهری \n",
            "\n",
            "🆔 @\n",
            "لغزشگاههای اندیشه از نظر قرآن \n",
            "\n",
            "\n",
            "قرآن مجید که دعوت به تفکر و نتیجه گیری فکری می‌کند و تفکر را عبادت‌ \n",
            "می‌شمارد و اصول عقاید را جز با تفکر منطقی ، صحیح نمی‌داند ، به یک مطلب‌ \n",
            "اساسی توجه کرده است و آن اینکه لغزشهای فکری بشر از کجا سرچشمه می‌گیرد \n",
            "و ریشه اصلی خطاها و گمراهیها در کجاست ؟\n",
            "\n",
            "تکیه بر ظن و گمان بجای علم و یقین \n",
            "قرآن می‌گوید : \n",
            "اکثر مردم چنین‌اند که اگر بخواهی پیرو آنها باشی تو را از راه حق گمراه‌ \n",
            "می‌کنند ، برای اینکه تکیه شان بر ظن و گمان است و ( نه بر یقین ) ، تنها \n",
            "با حدس و تخمین کار می‌کنند  . \n",
            "قرآن کریم در آیات زیادی به شدت با پیروی از ظن و گمان مخالفت می‌کند \n",
            "و می‌گوید : مادامی که به چیزی علم و یقین حاصل نکرده‌ای آنرا دنبال مکن .\n",
            "\n",
            "میلها و هواهای نفسانی \n",
            "انسان اگر بخواهد صحیح قضاوت کند باید در مورد مطلبی که می‌اندیشد کاملا \n",
            "بی طرفی خود را حفظ کند ، یعنی کوشش کند که حقیقت خواه باشد و خویشتن‌ \n",
            "را تسلیم دلیلها و مدارک نماید ، درست مانند یک قاضی که روی پرونده‌ای‌ \n",
            "مطالعه می‌کند ، باید نسبت به طرفین دعوا بی طرف باشد . \n",
            "انسان در تفکرات خود اگر بی طرفی خود را نسبت به نفی یا اثبات مطلبی‌ \n",
            "حفظ نکند و میل نفسانیش به یک طرف باشد ، خواه‌ناخواه و بدون آنکه‌ \n",
            "خودش متوجه شود عقربه فکرش به جانب میل و خواهش نفسانیش متمایل‌ \n",
            "می‌شود این است که قرآن هوای نفس را نیز مانند تکیه بر ظن و گمان یکی از \n",
            "عوامل لغزش می‌شمارد .\n",
            "\n",
            "شتابزدگی \n",
            "هر قضاوت و اظهار نظری مقداری معین مدارک لازم دارد و تا مدارک به‌ \n",
            "قدر کافی در یک مساله جمع نشود هرگونه اظهار نظر ، شتابزدگی و موجب لغزش اندیشه است قرآن کریم مکرر به اندک بودن سرمایه‌ \n",
            "علمی بشر و کافی نبودنش برای برخی قضاوتهای بزرگ اشاره می‌کند و اظهار \n",
            "جزم را دور از احتیاط تلقی می‌نماید . \n",
            "\n",
            "سنت گرائی و گذشته نگری \n",
            "انسان به حکم طبع اولی خود هنگامی که می‌بیند یک فکر و عقیده خاص مورد \n",
            "قبول نسلهای گذشته بوده است خودبخود بدون آنکه مجالی به اندیشه خود بدهد \n",
            "آن را می‌پذیرد قرآن یادآوری می‌کند که پذیرفته‌ها و باورهای گذشتگان را \n",
            "مادام که با معیار عقل نسنجیده‌اید نپذیرید ، در مقابل باورهای گذشتگان‌ \n",
            "استقلال فکری داشته باشید . \n",
            "\n",
            "شخصیت گرائی \n",
            "یکی دیگر از موجبات لغزش اندیشه ، گرایش به شخصیتها است شخصیتهای‌ \n",
            "بزرگ تاریخی یا معاصر از نظر عظمتی که در نفوس دارند بر روی فکر و اندیشه و تصمیم و اراده دیگران اثر می‌گذارند و در حقیقت هم‌ \n",
            "فکر و هم اراده دیگران را تسخیر می‌کنند ، دیگران آنچنان می‌اندیشند که‌ \n",
            "آنها می‌اندیشند و آنچنان تصمیم می‌گیرند که آنها می‌گیرند ، دیگران در \n",
            "مقابل آنها استقلال فکر و اراده خود را از دست می‌دهند .\n",
            "\n",
            "انسان و ایمان ، شهید مطهری \n",
            "\n",
            " @\n",
            "خدایا! چقدر با تو بودن را دوست دارم!\n",
            "تمام لحظه هایی که با تو سپری می کنم؛\n",
            "آن دقائق کوتاهی که برای صحبت با تو می گذارم،\n",
            "حتی آن لحظه های سردرگم و پر از فکر و خیال را با تو دوست دارم\n",
            "خدای من!\n",
            "خواندمت پاسخم گفتی\n",
            "از تو خواستم عطایم کردی\n",
            "به سوی تو آمدم آغوش رحمت گشودی\n",
            "به تو تکیه کردم نجاتم دادی\n",
            "به تو پناه آوردم کفایتم کردی\n",
            "خدای من! \n",
            "دوست دارم ....دستانم را رها مکن.\n",
            "خدایا! چقدر با تو بودن را دوست دارم!\n",
            "تمام لحظه هایی که با تو سپری می کنم؛\n",
            "آن دقائق کوتاهی که برای صحبت با تو می گذارم،\n",
            "حتی آن لحظه های سردرگم و پر از فکر و خیال را با تو دوست دارم\n",
            "خدای من!\n",
            "خواندمت پاسخم گفتی\n",
            "از تو خواستم عطایم کردی\n",
            "به سوی تو آمدم آغوش رحمت گشودی\n",
            "به تو تکیه کردم نجاتم دادی\n",
            "به تو پناه آوردم کفایتم کردی\n",
            "خدای من! \n",
            "دوست دارم ....دستانم را رها مکن.\n",
            "شاه تمام کتاب های جهان 👑👑👑\n",
            "شاه تمام کتاب های جهان \n",
            "فقط خدا\n",
            "فقط خدا\n",
            "خیلی خوبه که اینطوری همه جا کتاب قرآن کریم با ترجمه همیشه همراهته و می تونی بهش یه نگاهی بندازی تا دلت تو دانشگاه ، اداره ، یا مواقعی که دلتنگ خدایی کلامشو بخونی تا آروم بشی و دوباره با این که شکست خوردی با قدرت پاشی و ادامه بدی ، از همکاران گرامی بسیار سپاس گزارم . یا علی .\n",
            "خیلی خوبه که اینطوری همه جا کتاب قرآن کریم با ترجمه همیشه همراهته و می تونی بهش یه نگاهی بندازی تا دلت تو دانشگاه ، اداره ، یا مواقعی که دلتنگ خدایی کلامشو بخونی تا آروم بشی و دوباره با این که شکست خوردی با قدرت پاشی و ادامه بدی ، از همکاران گرامی بسیار سپاس گزارم . یا علی .\n",
            "خوشحالم که طاقچه کتاب های خوبی رو مانند قرآن کریم و شاهنامه فردوسی رایگان در اختیار ما قرار می دهد\n",
            "خوشحالم که طاقچه کتاب های خوبی رو مانند قرآن کریم و شاهنامه فردوسی رایگان در اختیار ما قرار می دهد\n",
            "دوستان طاقچه درزمینه کتب مذهبی ، فکرمیکنم کم لطفی کردند تنوع زیادنیست، سایت مصاف کتاب هایی رو دراین زمینه به صورت رایگان قراردادند به علاقه مندان پیشنهاد میکنم به این سایت مراجعه کنید.\n",
            "دوستان طاقچه درزمینه کتب مذهبی ، فکرمیکنم کم لطفی کردند تنوع زیادنیست، سایت مصاف کتاب هایی رو دراین زمینه به صورت رایگان قراردادند به علاقه مندان پیشنهاد میکنم به این سایت مراجعه کنید.\n",
            "برای سلامتی آواری های فرشگاه پلاسکو تهران  و آتش نشانان  قهرمان کشورمون که جان خود را دادن ، بخونید قرآن و فاتحه و صوات.\n",
            "برای سلامتی آواری های فرشگاه پلاسکو تهران  و آتش نشانان  قهرمان کشورمون که جان خود را دادن ، بخونید قرآن و فاتحه و صوات.\n",
            "سلام.ختم آیه الکرسی گرفتیم برای آتش نشانان و هموطنانی که زیر آوار مانده اند.برای سلامت و زنده بودنشان.سهم شما دو تا.لطفا به دوستان خود بگویید،تا به نیت ۱۴ معصوم،خداوند نظر نماید.\n",
            "سلام.ختم آیه الکرسی گرفتیم برای آتش نشانان و هموطنانی که زیر آوار مانده اند.برای سلامت و زنده بودنشان.سهم شما دو تا.لطفا به دوستان خود بگویید،تا به نیت ۱۴ معصوم،خداوند نظر نماید.\n",
            "قرآن شاهکار بی مانند زبان عرب است و باید اعتراف کرد که جمال صوری آن با عظمت معنوی اش برابر است... .\n",
            "قرآن با سبک خاص خویش دارای مباحث مختلف و فواید متعدد است: هم سرود مذهبی است هم ستایش ایزدی؛ و هم متضمن اصول، قواعد و قوانین مدنی و جزایی است؛ هم بشیر و نذیر است و هم پندآموز و اندرزگوی؛ هم مؤمنان را به صراط مستقیم هدایت می کند و هم قصه و داستان و امثال و حکم بیان می کند... .\n",
            "در توصیف اهمیت این کتاب همین قدر کافی است که اعراب با وجود نفاق و عناد و لجاج زیاد که در سرشت آن قوم است و با وصف اینکه هنری به غیر از فصاحت و بلاغت و سخن سنجی نداشتند در پیش قرآن زانو بر زمین زدند، آن را کلام الهی دانسته و به ذیل ولای آن دست زدند.\n",
            "\n",
            "(بارتلمی سنت هیلر، محمد و قرآن، ص188-187)\n",
            "قرآن شاهکار بی مانند زبان عرب است و باید اعتراف کرد که جمال صوری آن با عظمت معنوی اش برابر است... .\n",
            "قرآن با سبک خاص خویش دارای مباحث مختلف و فواید متعدد است: هم سرود مذهبی است هم ستایش ایزدی؛ و هم متضمن اصول، قواعد و قوانین مدنی و جزایی است؛ هم بشیر و نذیر است و هم پندآموز و اندرزگوی؛ هم مؤمنان را به صراط مستقیم هدایت می کند و هم قصه و داستان و امثال و حکم بیان می کند... .\n",
            "در توصیف اهمیت این کتاب همین قدر کافی است که اعراب با وجود نفاق و عناد و لجاج زیاد که در سرشت آن قوم است و با وصف اینکه هنری به غیر از فصاحت و بلاغت و سخن سنجی نداشتند در پیش قرآن زانو بر زمین زدند، آن را کلام الهی دانسته و به ذیل ولای آن دست زدند.\n",
            "\n",
            "(بارتلمی سنت هیلر، محمد و قرآن، ص188-187)\n",
            "عااااللللللیییییییییی۳ببیببیب\n",
            "عااااللللللیییییییییی۳ببیببیب\n",
            "کاش جزها را هم مشخص میکرد. نمیدونم من پیدا نمیکنم یا مشخص نیست. کسی میتونه راهنماییم کنه؟؟\n",
            "کاش جزها را هم مشخص میکرد. نمیدونم من پیدا نمیکنم یا مشخص نیست. کسی میتونه راهنماییم کنه؟؟\n",
            "عالی\n",
            "\n",
            "عالی\n",
            "\n",
            "کلام خداارامبخش دل وجان\n",
            "کلام خداارامبخش دل وجان\n",
            "ترجمه مرحوم فولادوندازقرآن کریم بهترین ترجمه درزبان فارسی است.امیدوارم مطالعه کنیم وبهره ببریم.انشاالله.\n",
            "ترجمه مرحوم فولادوندازقرآن کریم بهترین ترجمه درزبان فارسی است.امیدوارم مطالعه کنیم وبهره ببریم.انشاالله.\n",
            "کلام خدا و عالی است\n",
            "کلام خدا و عالی است\n",
            "خودت گفتی بخوان \n",
            "میخوانمت \n",
            "اینک مرا دریاب \n",
            "به چشمانی ک میجوید تورا\n",
            "نوری عنایت کن ....\n",
            "و خدا همین نزدیکیست \n",
            "کنار من و تو و ما.......\n",
            "غافل از او،مشغولیم...650\n",
            "خودت گفتی بخوان \n",
            "میخوانمت \n",
            "اینک مرا دریاب \n",
            "به چشمانی ک میجوید تورا\n",
            "نوری عنایت کن ....\n",
            "و خدا همین نزدیکیست \n",
            "کنار من و تو و ما.......\n",
            "غافل از او،مشغولیم...650\n",
            "به نام خدایی که هرگز دغدغه از دست دادنش را ندارم..\n",
            "خداوند بلند مرتبه در آیه 103 سوره انعام میفرماید:\n",
            "چشم ها او را نمی بینند\n",
            "ولی او همه چشم ها را می بیند...\n",
            "\n",
            "سپاس طاقچه\n",
            "به نام خدایی که هرگز دغدغه از دست دادنش را ندارم..\n",
            "خداوند بلند مرتبه در آیه 103 سوره انعام میفرماید:\n",
            "چشم ها او را نمی بینند\n",
            "ولی او همه چشم ها را می بیند...\n",
            "\n",
            "سپاس طاقچه\n",
            "خوبه فقط آیه های سجده دار رو نگفته کدوم سجده دارن مث سوره انشقاق که سجده مستحب داره هیچ علامتی بالای آیه ش نذاشته\n",
            "خوبه فقط آیه های سجده دار رو نگفته کدوم سجده دارن مث سوره انشقاق که سجده مستحب داره هیچ علامتی بالای آیه ش نذاشته\n",
            "چی از قرآن کریم بهتر ؟؟؟؟\n",
            "چی از قرآن کریم بهتر ؟؟؟؟\n",
            "ترجمه الهی قمشه ای رو هم قرار بدید لطفا با تشکر\n",
            "ترجمه الهی قمشه ای رو هم قرار بدید لطفا با تشکر\n",
            "عاااال \n",
            "درپناه قران\n",
            "عاااال \n",
            "درپناه قران\n",
            "عالی(very good)\n",
            "عالی(very good)\n",
            "سپاس\n",
            "سپاس\n",
            "قران همیشه عالیست\n",
            "قران همیشه عالیست\n",
            "ممنون که رایگانه\n",
            "ممنون که رایگانه\n",
            "خیلی ممنون بابت رایگان گذاشتن قرآن\n",
            "خیلی ممنون بابت رایگان گذاشتن قرآن\n",
            "عالی بود\n",
            "و رایگان بودنش فوق العادش میکنه\n",
            "عالی بود\n",
            "و رایگان بودنش فوق العادش میکنه\n",
            "خیلی زیبا تشکر\n",
            "خیلی زیبا تشکر\n",
            "خیلی عالیه خیلی خیلی عالیه\n",
            "خیلی عالیه خیلی خیلی عالیه\n",
            "با سلام و تشکر . ترجمه  آقای الهی قمشه ای را هم بذارید.\n",
            "با سلام و تشکر . ترجمه  آقای الهی قمشه ای را هم بذارید.\n",
            "ممنون از برنامه خوبتون\n",
            "ممنون از برنامه خوبتون\n",
            "بنام نامی حضرت دوست \n",
            "\n",
            "نحن  نزلنا  الذکر \n",
            "\n",
            "استاد  محمد مهدی فولادوند  ( ره )  از  اساتید  علوم الهیات  و  قرآن  و از  مترجمان  کتاب خدا  و  کتب مقدس  دینی است. \n",
            "استاد فولادوند  غیر از ترجمه  قرآن  مجید  ، \n",
            "کتاب  نهج البلاغه \n",
            "صحیفه ی سجادیه \n",
            "دعای کمیل   را  به فارسی  ترجمه کرده  و ترجمه ی ایشان  از \n",
            "کتاب الله  مورد  توجه  قرآن  پژوهان   و  مترجمان  این  کتاب \n",
            "آسمانی قرار گرفته است. \n",
            "استاد  بهاءالدین  خرمشاهی که از  اساتید مسلم  زبان و ادبیات فارسی  و  ادبیات  عربی  و  از  بزرگان  حافظ  پژوهی  و  قرآن  پژوهی است  و  در  زمینه ی  علوم  قرانی دارای چندین اثر   \n",
            "فاخر  و  ارزشمند  است  می فرماید ：\n",
            "\n",
            "\"  بدون   اغراق ترجمه ی استاد  محمد مهدی فولادوند  از  قرآن مجید  از  بهترین  ترجمه  های  زبان  فارسی  است. \"\n",
            "ایشان  معتقد ند  که تسلط استاد فولادوند بر  زبان  عربی و فارسی  باعث شده  که  یک  نثر فاخری را مبنای  ترجمه خویش قرار دهند. \n",
            "ترجمه ای که   مبنای آن  زبان فارسی امروزی است. \n",
            "بطورکلی  ایشان این ترجمه  را   بسیار خوب  دانسته  به  گونه ای که  نه  در آن  افراط گرایی  زبان  فارسی  مشاهده  می شود \n",
            "و نه  ویژگی های  مفرط زبان عربی!! \n",
            "استاد خرمشاهی  این ترجمه را از آن  جهت  کم نظیر  می دانند که در  آن   سوره  های مکی  بصورت  آهنگین  ترجمه شده اند. \n",
            "\n",
            "استاد کوشا که از  اساتید   بنام   علوم قرانی  و از  منتقدین  ترجمه های  فارسی  کتاب  قرآن است  ، ترجمه استاد فولادوند \n",
            "از قرآن  را  جزء ترجمه هایی می داند که  دران  \n",
            "محتواگرایی  فدای  ترجمه ی  تحت الفظی نشده است!! \n",
            "\n",
            "نکته ی پایانی  شکر و سپاس بیکران  از خالق  لایزال  این \n",
            "معجزه ی خالده  و پیامبر  رحمتی است  که  در دوران رسالت \n",
            "خود  آن را بر امت  خواند  و برای جهانیان به یادگار گذاشت. \n",
            "\n",
            "و سپاس بیکران از پایگاه  فرهنگی طاقچه  که آنرا  به  کاربران \n",
            "فهیم خویش اهدا نمود. \n",
            "\n",
            "من الله  التوفیق\n",
            "بنام نامی حضرت دوست \n",
            "\n",
            "نحن  نزلنا  الذکر \n",
            "\n",
            "استاد  محمد مهدی فولادوند  ( ره )  از  اساتید  علوم الهیات  و  قرآن  و از  مترجمان  کتاب خدا  و  کتب مقدس  دینی است. \n",
            "استاد فولادوند  غیر از ترجمه  قرآن  مجید  ، \n",
            "کتاب  نهج البلاغه \n",
            "صحیفه ی سجادیه \n",
            "دعای کمیل   را  به فارسی  ترجمه کرده  و ترجمه ی ایشان  از \n",
            "کتاب الله  مورد  توجه  قرآن  پژوهان   و  مترجمان  این  کتاب \n",
            "آسمانی قرار گرفته است. \n",
            "استاد  بهاءالدین  خرمشاهی که از  اساتید مسلم  زبان و ادبیات فارسی  و  ادبیات  عربی  و  از  بزرگان  حافظ  پژوهی  و  قرآن  پژوهی است  و  در  زمینه ی  علوم  قرانی دارای چندین اثر   \n",
            "فاخر  و  ارزشمند  است  می فرماید \n",
            "\n",
            "\"  بدون   اغراق ترجمه ی استاد  محمد مهدی فولادوند  از  قرآن مجید  از  بهترین  ترجمه  های  زبان  فارسی  است. \"\n",
            "ایشان  معتقد ند  که تسلط استاد فولادوند بر  زبان  عربی و فارسی  باعث شده  که  یک  نثر فاخری را مبنای  ترجمه خویش قرار دهند. \n",
            "ترجمه ای که   مبنای آن  زبان فارسی امروزی است. \n",
            "بطورکلی  ایشان این ترجمه  را   بسیار خوب  دانسته  به  گونه ای که  نه  در آن  افراط گرایی  زبان  فارسی  مشاهده  می شود \n",
            "و نه  ویژگی های  مفرط زبان عربی!! \n",
            "استاد خرمشاهی  این ترجمه را از آن  جهت  کم نظیر  می دانند که در  آن   سوره  های مکی  بصورت  آهنگین  ترجمه شده اند. \n",
            "\n",
            "استاد کوشا که از  اساتید   بنام   علوم قرانی  و از  منتقدین  ترجمه های  فارسی  کتاب  قرآن است  ، ترجمه استاد فولادوند \n",
            "از قرآن  را  جزء ترجمه هایی می داند که  دران  \n",
            "محتواگرایی  فدای  ترجمه ی  تحت الفظی نشده است!! \n",
            "\n",
            "نکته ی پایانی  شکر و سپاس بیکران  از خالق  لایزال  این \n",
            "معجزه ی خالده  و پیامبر  رحمتی است  که  در دوران رسالت \n",
            "خود  آن را بر امت  خواند  و برای جهانیان به یادگار گذاشت. \n",
            "\n",
            "و سپاس بیکران از پایگاه  فرهنگی طاقچه  که آنرا  به  کاربران \n",
            "فهیم خویش اهدا نمود. \n",
            "\n",
            "من الله  التوفیق\n",
            "mamnon 🙏🙏\n",
            "mamnon \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCQfM5DmRGG-"
      },
      "source": [
        "**<font color=red> Cleaning is the final step in this section. Your cleaned method should be included these steps:</font>**\n",
        "\n",
        "**<font color=red>- fixing unicodes</font>**\n",
        "\n",
        "**<font color=red>- removing specials like a phone number, email, url, new lines, ...</font>**\n",
        "\n",
        "**<font color=red>- cleaning HTMLs</font>**\n",
        "\n",
        "**<font color=red>- normalizing</font>**\n",
        "\n",
        "**<font color=red>- removing emojis</font>**\n",
        "\n",
        "**<font color=red>- removing extra spaces, hashtags</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CRX3CZT6REFh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7107792-c8b7-4037-e37c-d665fd2f1687"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting hazm\n",
            "  Downloading hazm-0.7.0-py3-none-any.whl (316 kB)\n",
            "\u001b[K     |████████████████████████████████| 316 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting libwapiti>=0.2.1\n",
            "  Downloading libwapiti-0.2.1.tar.gz (233 kB)\n",
            "\u001b[K     |████████████████████████████████| 233 kB 46.4 MB/s \n",
            "\u001b[?25hCollecting nltk==3.3\n",
            "  Downloading nltk-3.3.0.zip (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 39.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.3->hazm) (1.15.0)\n",
            "Building wheels for collected packages: nltk, libwapiti\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.3-py3-none-any.whl size=1394489 sha256=129df1e822745e01ca10f82cd3bc071a1cacc8977fba53e4d5207830e9a87b18\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/fd/0c/d92302c876e5de87ebd7fc0979d82edb93e2d8d768bf71fac4\n",
            "  Building wheel for libwapiti (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libwapiti: filename=libwapiti-0.2.1-cp37-cp37m-linux_x86_64.whl size=154994 sha256=bcbc8399d5c96a95134805fda773a62dfd4530adf8f8df22026141964bdf8dcc\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/b2/5b/0fe4b8f5c0e65341e8ea7bb3f4a6ebabfe8b1ac31322392dbf\n",
            "Successfully built nltk libwapiti\n",
            "Installing collected packages: nltk, libwapiti, hazm\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.7\n",
            "    Uninstalling nltk-3.7:\n",
            "      Successfully uninstalled nltk-3.7\n",
            "Successfully installed hazm-0.7.0 libwapiti-0.2.1 nltk-3.3\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 86 kB 6.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 48.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 48.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 175 kB 10.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 235 kB 56.0 MB/s \n",
            "\u001b[?25h  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install hazm\n",
        "!pip install -q transformers\n",
        "!pip install -q hazm\n",
        "!pip install -q clean-text[gpl]\n",
        "\n",
        "import hazm\n",
        "from cleantext import clean\n",
        "\n",
        "def cleaning(text):\n",
        "    text = text.strip()\n",
        "\n",
        "    ##############################################################################################\n",
        "    #                                       Your Code                                            #\n",
        "    ##############################################################################################\n",
        "    # regular cleaning\n",
        "    text = clean(text,\n",
        "        fix_unicode=True,\n",
        "        to_ascii=False,\n",
        "        lower=True,\n",
        "        no_line_breaks=True,\n",
        "        no_urls=True,\n",
        "        no_emails=True,\n",
        "        no_phone_numbers=True,\n",
        "        no_numbers=False,\n",
        "        no_digits=False,\n",
        "        no_currency_symbols=True,\n",
        "        no_punct=False,\n",
        "        replace_with_url=\"\",\n",
        "        replace_with_email=\"\",\n",
        "        replace_with_phone_number=\"\",\n",
        "        replace_with_number=\"\",\n",
        "        replace_with_digit=\"0\",\n",
        "        replace_with_currency_symbol=\"\",\n",
        "    )\n",
        "\n",
        "    # cleaning htmls\n",
        "\n",
        "    cleanr = re.compile('<.*?>')\n",
        "    text = re.sub(cleanr, '', text)\n",
        "    \n",
        "    # normalizing\n",
        "\n",
        "\n",
        "    normalizer = hazm.Normalizer()\n",
        "    text = normalizer.normalize(text)\n",
        "    \n",
        "    # removing wierd patterns\n",
        "    wierd_pattern = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "        u\"\\U0001f926-\\U0001f937\"\n",
        "        u'\\U00010000-\\U0010ffff'\n",
        "        u\"\\u200d\"\n",
        "        u\"\\u2640-\\u2642\"\n",
        "        u\"\\u2600-\\u2B55\"\n",
        "        u\"\\u23cf\"\n",
        "        u\"\\u23e9\"\n",
        "        u\"\\u231a\"\n",
        "        u\"\\u3030\"\n",
        "        u\"\\ufe0f\"\n",
        "        u\"\\u2069\"\n",
        "        u\"\\u2066\"\n",
        "        # u\"\\u200c\"\n",
        "        u\"\\u2068\"\n",
        "        u\"\\u2067\"\n",
        "        \"]+\", flags=re.UNICODE)\n",
        "    \n",
        "    text = wierd_pattern.sub(r'', text)\n",
        "    \n",
        "    # removing extra spaces, hashtags\n",
        "    text = re.sub(\"#\", \"\", text)\n",
        "    text = re.sub(\"\\s+\", \" \", text)\n",
        "    \n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "681o2WMERHbJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# cleaning comments\n",
        "data['cleaned_comment'] = data['comment'].apply(cleaning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asSwiNKxPaAz"
      },
      "source": [
        "**<font color=red> Calculate the Length of Comments based on their Words</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ioFL5_1MQzIb"
      },
      "outputs": [],
      "source": [
        "##############################################################################################\n",
        "#                                       Your Code                                            #\n",
        "##############################################################################################\n",
        "data['cleaned_comment_len_by_words'] = data['cleaned_comment'].apply(lambda t: len(hazm.word_tokenize(t)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDwxjxkJPpyY"
      },
      "source": [
        "**<font color=red> Remove Comments with the Length of Fewer than 3 Words & More than 256 Words</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "kliWRX7-3U1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "0ae193c5-566b-45cb-8669-a1a3fdae8c68"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             comment  rate  \\\n",
              "0  اسم کتاب   No one writes to the Colonel\\nترجمش...     0   \n",
              "1  طاقچه عزیز،نام کتاب\"کسی به سرهنگ نامه نمینویسد...     5   \n",
              "2  بنظرم این اثر مارکز خیلی از صد سال تنهایی که ب...     5   \n",
              "3  به نظر کتاب خوبی میومد اما من از ترجمش خوشم نی...     2   \n",
              "4                                      کتاب خوبی است     3   \n",
              "\n",
              "                                     cleaned_comment  \\\n",
              "0  اسم کتاب no one writes to the colonel ترجمش می...   \n",
              "1  طاقچه عزیز، نام کتاب «کسی به سرهنگ نامه نمینوی...   \n",
              "2  بنظرم این اثر مارکز خیلی از صد سال تنهایی که ب...   \n",
              "3  به نظر کتاب خوبی میومد اما من از ترجمش خوشم نی...   \n",
              "4                                      کتاب خوبی است   \n",
              "\n",
              "   cleaned_comment_len_by_words  \n",
              "0                            47  \n",
              "1                            20  \n",
              "2                            45  \n",
              "3                            20  \n",
              "4                             3  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2cc5e470-cc20-4e4d-ab4e-acb6f46198f8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>rate</th>\n",
              "      <th>cleaned_comment</th>\n",
              "      <th>cleaned_comment_len_by_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>اسم کتاب   No one writes to the Colonel\\nترجمش...</td>\n",
              "      <td>0</td>\n",
              "      <td>اسم کتاب no one writes to the colonel ترجمش می...</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>طاقچه عزیز،نام کتاب\"کسی به سرهنگ نامه نمینویسد...</td>\n",
              "      <td>5</td>\n",
              "      <td>طاقچه عزیز، نام کتاب «کسی به سرهنگ نامه نمینوی...</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>بنظرم این اثر مارکز خیلی از صد سال تنهایی که ب...</td>\n",
              "      <td>5</td>\n",
              "      <td>بنظرم این اثر مارکز خیلی از صد سال تنهایی که ب...</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>به نظر کتاب خوبی میومد اما من از ترجمش خوشم نی...</td>\n",
              "      <td>2</td>\n",
              "      <td>به نظر کتاب خوبی میومد اما من از ترجمش خوشم نی...</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>کتاب خوبی است</td>\n",
              "      <td>3</td>\n",
              "      <td>کتاب خوبی است</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2cc5e470-cc20-4e4d-ab4e-acb6f46198f8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2cc5e470-cc20-4e4d-ab4e-acb6f46198f8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2cc5e470-cc20-4e4d-ab4e-acb6f46198f8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "##############################################################################################\n",
        "#                                       Your Code                                            #\n",
        "##############################################################################################\n",
        "minlim = 3\n",
        "maxlim = 256\n",
        "# remove comments with the length of fewer than three words\n",
        "data['cleaned_comment_len_by_words'] = data['cleaned_comment_len_by_words'].apply(lambda len_t: len_t if minlim < len_t <= maxlim else len_t)\n",
        "data = data.dropna(subset=['cleaned_comment_len_by_words'])\n",
        "data = data.reset_index(drop=True)\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rate_to_label(rate, threshold=3.0):\n",
        "    if rate <= threshold:\n",
        "        return \"0\"\n",
        "    else:\n",
        "        return \"1\"\n",
        "\n",
        "\n",
        "data['label'] = data['rate'].apply(lambda t: rate_to_label(t, 3.0))\n",
        "labels = list(sorted(data['label'].unique()))\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "xHjWUqk_GKGS",
        "outputId": "7a26c892-3a5e-4a7c-fa35-41a91e2306c1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             comment  rate  \\\n",
              "0  اسم کتاب   No one writes to the Colonel\\nترجمش...     0   \n",
              "1  طاقچه عزیز،نام کتاب\"کسی به سرهنگ نامه نمینویسد...     5   \n",
              "2  بنظرم این اثر مارکز خیلی از صد سال تنهایی که ب...     5   \n",
              "3  به نظر کتاب خوبی میومد اما من از ترجمش خوشم نی...     2   \n",
              "4                                      کتاب خوبی است     3   \n",
              "\n",
              "                                     cleaned_comment  \\\n",
              "0  اسم کتاب no one writes to the colonel ترجمش می...   \n",
              "1  طاقچه عزیز، نام کتاب «کسی به سرهنگ نامه نمینوی...   \n",
              "2  بنظرم این اثر مارکز خیلی از صد سال تنهایی که ب...   \n",
              "3  به نظر کتاب خوبی میومد اما من از ترجمش خوشم نی...   \n",
              "4                                      کتاب خوبی است   \n",
              "\n",
              "   cleaned_comment_len_by_words label  \n",
              "0                            47     0  \n",
              "1                            20     1  \n",
              "2                            45     1  \n",
              "3                            20     0  \n",
              "4                             3     0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6aba810a-1c83-4196-9c4f-668ee6e69c48\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>rate</th>\n",
              "      <th>cleaned_comment</th>\n",
              "      <th>cleaned_comment_len_by_words</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>اسم کتاب   No one writes to the Colonel\\nترجمش...</td>\n",
              "      <td>0</td>\n",
              "      <td>اسم کتاب no one writes to the colonel ترجمش می...</td>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>طاقچه عزیز،نام کتاب\"کسی به سرهنگ نامه نمینویسد...</td>\n",
              "      <td>5</td>\n",
              "      <td>طاقچه عزیز، نام کتاب «کسی به سرهنگ نامه نمینوی...</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>بنظرم این اثر مارکز خیلی از صد سال تنهایی که ب...</td>\n",
              "      <td>5</td>\n",
              "      <td>بنظرم این اثر مارکز خیلی از صد سال تنهایی که ب...</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>به نظر کتاب خوبی میومد اما من از ترجمش خوشم نی...</td>\n",
              "      <td>2</td>\n",
              "      <td>به نظر کتاب خوبی میومد اما من از ترجمش خوشم نی...</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>کتاب خوبی است</td>\n",
              "      <td>3</td>\n",
              "      <td>کتاب خوبی است</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6aba810a-1c83-4196-9c4f-668ee6e69c48')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6aba810a-1c83-4196-9c4f-668ee6e69c48 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6aba810a-1c83-4196-9c4f-668ee6e69c48');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "GlBnHyl0RIzx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "463facf6-4f63-4d4c-83e9-568945bb39a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             comment label\n",
              "0  اسم کتاب no one writes to the colonel ترجمش می...     0\n",
              "1  طاقچه عزیز، نام کتاب «کسی به سرهنگ نامه نمینوی...     1\n",
              "2  بنظرم این اثر مارکز خیلی از صد سال تنهایی که ب...     1\n",
              "3  به نظر کتاب خوبی میومد اما من از ترجمش خوشم نی...     0\n",
              "4                                      کتاب خوبی است     0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ab8c5224-0346-4be1-be4c-bf1b92ec17d8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>اسم کتاب no one writes to the colonel ترجمش می...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>طاقچه عزیز، نام کتاب «کسی به سرهنگ نامه نمینوی...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>بنظرم این اثر مارکز خیلی از صد سال تنهایی که ب...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>به نظر کتاب خوبی میومد اما من از ترجمش خوشم نی...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>کتاب خوبی است</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab8c5224-0346-4be1-be4c-bf1b92ec17d8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ab8c5224-0346-4be1-be4c-bf1b92ec17d8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ab8c5224-0346-4be1-be4c-bf1b92ec17d8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "data = data[['cleaned_comment', 'label']]\n",
        "data.columns = ['comment', 'label']\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ny0D77atzqWT"
      },
      "source": [
        "### Handling Unbalanced Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Q0yEPxd-tb-"
      },
      "source": [
        "**<font color=red> Because the Data is Unbalanced, You should Balance it. Before & After Balancing Data, You should Plot a Bar Chart of Distribution of label within comments [DATA]</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "8rhzPbMURPyK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "48803821-7eca-44f7-c8a6-d20e0e7d7368"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"397ebdae-3283-4836-91f6-e0fbafda3f3a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"397ebdae-3283-4836-91f6-e0fbafda3f3a\")) {                    Plotly.newPlot(                        \"397ebdae-3283-4836-91f6-e0fbafda3f3a\",                        [{\"text\":[\"1246\",\"3419\"],\"textposition\":\"auto\",\"x\":[\"0\",\"1\"],\"y\":[1246,3419],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Distribution of label within comments [DATA]\"},\"xaxis\":{\"title\":{\"text\":\"Label\"}},\"yaxis\":{\"title\":{\"text\":\"Frequency\"}},\"bargap\":0.2,\"bargroupgap\":0.2},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('397ebdae-3283-4836-91f6-e0fbafda3f3a');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "##############################################################################################\n",
        "#                                       Your Code                                            #\n",
        "##############################################################################################\n",
        "fig = go.Figure()\n",
        "\n",
        "groupby_label = data.groupby('label')['label'].count()\n",
        "\n",
        "fig.add_trace(go.Bar(\n",
        "    x=list(sorted(groupby_label.index)),\n",
        "    y=groupby_label.tolist(),\n",
        "    text=groupby_label.tolist(),\n",
        "    textposition='auto'\n",
        "))\n",
        "\n",
        "fig.update_layout(\n",
        "    title_text='Distribution of label within comments [DATA]',\n",
        "    xaxis_title_text='Label',\n",
        "    yaxis_title_text='Frequency',\n",
        "    bargap=0.2,\n",
        "    bargroupgap=0.2)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "negative_data = data[data['label'] == \"0\"]\n",
        "positive_data = data[data['label'] == \"1\"]\n",
        "\n",
        "cutting_point = min(len(negative_data), len(positive_data))\n",
        "\n",
        "if cutting_point <= len(negative_data):\n",
        "    negative_data = negative_data.sample(n=cutting_point).reset_index(drop=True)\n",
        "\n",
        "if cutting_point <= len(positive_data):\n",
        "    positive_data = positive_data.sample(n=cutting_point).reset_index(drop=True)\n",
        "\n",
        "new_data = pd.concat([negative_data, positive_data])\n",
        "new_data = new_data.sample(frac=1).reset_index(drop=True)\n",
        "new_data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwtZY3lHHoYm",
        "outputId": "674db289-00da-42c6-d4f2-d7e12b25ffaf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2492 entries, 0 to 2491\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   comment  2492 non-null   object\n",
            " 1   label    2492 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 39.1+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure()\n",
        "\n",
        "groupby_label = new_data.groupby('label')['label'].count()\n",
        "\n",
        "fig.add_trace(go.Bar(\n",
        "    x=list(sorted(groupby_label.index)),\n",
        "    y=groupby_label.tolist(),\n",
        "    text=groupby_label.tolist(),\n",
        "    textposition='auto'\n",
        "))\n",
        "\n",
        "fig.update_layout(\n",
        "    title_text='Distribution of label within comments [NEW DATA]',\n",
        "    xaxis_title_text='Label',\n",
        "    yaxis_title_text='Frequency',\n",
        "    bargap=0.2,\n",
        "    bargroupgap=0.2)\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "7N2l1DiRH6zm",
        "outputId": "76bc005d-1d14-4889-bf57-1dca8e1099ce"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"fe1c622d-d404-497e-9cda-1647361619f8\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"fe1c622d-d404-497e-9cda-1647361619f8\")) {                    Plotly.newPlot(                        \"fe1c622d-d404-497e-9cda-1647361619f8\",                        [{\"text\":[\"1246\",\"1246\"],\"textposition\":\"auto\",\"x\":[\"0\",\"1\"],\"y\":[1246,1246],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Distribution of label within comments [NEW DATA]\"},\"xaxis\":{\"title\":{\"text\":\"Label\"}},\"yaxis\":{\"title\":{\"text\":\"Frequency\"}},\"bargap\":0.2,\"bargroupgap\":0.2},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('fe1c622d-d404-497e-9cda-1647361619f8');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpLObddZROJm"
      },
      "source": [
        "## Train,Validation,Test split\n",
        "\n",
        "To achieve a globalized model, we need to split the cleaned dataset into train, valid, test sets due to size of the data. In this tutorial, I have considered a rate of **0.1** for both *valid*, *test* sets. For splitting, I use `train_test_split` provided by Sklearn package with stratifying on the label for preserving the distribution balance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "DR_4CTGERLyw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "561201c7-b2e9-45c8-e4c2-0947890438dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2017, 3)\n",
            "(225, 3)\n",
            "(250, 3)\n"
          ]
        }
      ],
      "source": [
        "new_data['label_id'] = new_data['label'].apply(lambda t: labels.index(t))\n",
        "\n",
        "train, test = train_test_split(new_data, test_size=0.1, random_state=1, stratify=new_data['label'])\n",
        "train, valid = train_test_split(train, test_size=0.1, random_state=1, stratify=train['label'])\n",
        "\n",
        "train = train.reset_index(drop=True)\n",
        "valid = valid.reset_index(drop=True)\n",
        "test = test.reset_index(drop=True)\n",
        "\n",
        "x_train, y_train = train['comment'].values.tolist(), train['label_id'].values.tolist()\n",
        "x_valid, y_valid = valid['comment'].values.tolist(), valid['label_id'].values.tolist()\n",
        "x_test, y_test = test['comment'].values.tolist(), test['label_id'].values.tolist()\n",
        "\n",
        "print(train.shape)\n",
        "print(valid.shape)\n",
        "print(test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17sghNPPRaOz"
      },
      "source": [
        "![BERT INPUTS](https://res.cloudinary.com/m3hrdadfi/image/upload/v1595158991/kaggle/bert_inputs_w8rith.png)\n",
        "\n",
        "As you may know, the BERT model input is a combination of 3 embeddings.\n",
        "- Token embeddings: WordPiece token vocabulary (WordPiece is another word segmentation algorithm, similar to BPE)\n",
        "- Segment embeddings: for pair sentences [A-B] marked as $E_A$ or $E_B$ mean that it belongs to the first sentence or the second one.\n",
        "- Position embeddings: specify the position of words in a sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mk-T5EvIRc6t"
      },
      "source": [
        "## PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "LjfRss-DR3fu"
      },
      "outputs": [],
      "source": [
        "# Import required packages (If You Need Any More Packages, You Can Add them HERE.)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SperdZDDWKxT"
      },
      "source": [
        "### Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "WFpUoggdpU3x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75f946fb-1b3c-4289-8005-6c3df4ea8cda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda:0\n",
            "CUDA is available!  Training on GPU ...\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'device: {device}')\n",
        "\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "mH38OJU0X7rd"
      },
      "outputs": [],
      "source": [
        "# general config\n",
        "MAX_LEN = 128\n",
        "TRAIN_BATCH_SIZE = 16\n",
        "VALID_BATCH_SIZE = 16\n",
        "TEST_BATCH_SIZE = 16\n",
        "\n",
        "EPOCHS = 10\n",
        "EEVERY_EPOCH = 1000\n",
        "LEARNING_RATE = 2e-5\n",
        "CLIP = 0.0\n",
        "\n",
        "OUTPUT_PATH = '/content/bert-fa-base-uncased-sentiment-taaghceh/pytorch_model.bin'\n",
        "\n",
        "os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "qK02AC0pYIPj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1b24033-8639-496d-e167-52a82567a438"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label2id: {'0': 0, '1': 1}\n",
            "id2label: {0: '0', 1: '1'}\n"
          ]
        }
      ],
      "source": [
        "# create a key finder based on label 2 id and id to label\n",
        "\n",
        "label2id = {label: i for i, label in enumerate(labels)}\n",
        "id2label = {v: k for k, v in label2id.items()}\n",
        "\n",
        "print(f'label2id: {label2id}')\n",
        "print(f'id2label: {id2label}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBjLAydrU8jN"
      },
      "source": [
        "**<font color=red> Setup the Tokenizer and Configuration</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "qGJRNBXFYOcx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637,
          "referenced_widgets": [
            "499f74de07764d43a4164df19b1a0ccf",
            "f125474f707f48a589eb3d21da4a95f2",
            "43eff8ce43dd4056b7898a22179aa812",
            "e6bc9ed89a274f88bdbf192d3e2eaddb",
            "04e5a3fce56b4ca09f3e2b3af8067623",
            "5a5bb13585944ef69718c9f3b7fad322",
            "c942290c8bd14ec6b8644a83504b2aa2",
            "12a3210bbb864414ae7cb9d3361351e3",
            "42cc91115efa47e6bf6121e1e1550731",
            "8a4d0d26defe40f5b06ee4f901289647",
            "bd891371cd304c81a62be55c2f388a6c",
            "3ff4ae5966814bc89dc823fdda0f7ce6",
            "1d8080f487384783a2aec63391331610",
            "09f8f12214bb4675800dbfee6cd2038c",
            "33ec7bccf44d40e195b90861f561bd4b",
            "b6da6ffdece54ea69fff9929fdf467ad",
            "bf2995046fad4709ac48cbcc42d1c394",
            "7d87c212aa1c48c3b666af39e794547c",
            "2939d19010ba4caeb56e973373bfc80f",
            "a61c30e0a3a64185939b9fa537355712",
            "36bc92e1736a48faa3174c5ba6994c10",
            "a44e0a294e7648fa995c326f66950342"
          ]
        },
        "outputId": "c4338e08-3f01-4471-8213-466307f68f89"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.14M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "499f74de07764d43a4164df19b1a0ccf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/440 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ff4ae5966814bc89dc823fdda0f7ce6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"0\",\n",
            "    \"1\": \"1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"0\": 0,\n",
            "    \"1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.19.4\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 100000\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "##############################################################################################\n",
        "#                                       Your Code                                            #\n",
        "##############################################################################################\n",
        "MODEL_NAME_OR_PATH = 'HooshvareLab/bert-fa-base-uncased'\n",
        "from transformers import BertConfig, BertTokenizer\n",
        "from transformers import BertModel\n",
        "\n",
        "from transformers import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME_OR_PATH)\n",
        "config = BertConfig.from_pretrained(\n",
        "    MODEL_NAME_OR_PATH, **{\n",
        "        'label2id': label2id,\n",
        "        'id2label': id2label,\n",
        "    })\n",
        "\n",
        "print(config.to_json_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr9L9N91gSpm"
      },
      "source": [
        "### Input Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pr8cRm9xiyKh"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "TaJBSSuMizgr"
      },
      "outputs": [],
      "source": [
        "class TaaghcheDataset(torch.utils.data.Dataset):\n",
        "    \"\"\" Create a PyTorch dataset for Taaghche. \"\"\"\n",
        "\n",
        "    def __init__(self, tokenizer, comments, targets=None, label_list=None, max_len=128):\n",
        "        self.comments = comments\n",
        "        self.targets = targets\n",
        "        self.has_target = isinstance(targets, list) or isinstance(targets, np.ndarray)\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "        \n",
        "        self.label_map = {label: i for i, label in enumerate(label_list)} if isinstance(label_list, list) else {}\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.comments)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        comment = str(self.comments[item])\n",
        "\n",
        "        if self.has_target:\n",
        "            target = self.label_map.get(str(self.targets[item]), str(self.targets[item]))\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            comment,\n",
        "            add_special_tokens=True,\n",
        "            truncation=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=True,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt')\n",
        "        \n",
        "        inputs = {\n",
        "            'comment': comment,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'token_type_ids': encoding['token_type_ids'].flatten(),\n",
        "        }\n",
        "\n",
        "        if self.has_target:\n",
        "            inputs['targets'] = torch.tensor(target, dtype=torch.long)\n",
        "        \n",
        "        return inputs\n",
        "\n",
        "\n",
        "def create_data_loader(x, y, tokenizer, max_len, batch_size, label_list):\n",
        "    dataset = TaaghcheDataset(\n",
        "        comments=x,\n",
        "        targets=y,\n",
        "        tokenizer=tokenizer,\n",
        "        max_len=max_len, \n",
        "        label_list=label_list)\n",
        "    \n",
        "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "JEcefj6fkZFl"
      },
      "outputs": [],
      "source": [
        "label_list = ['0', '1']\n",
        "train_data_loader = create_data_loader(train['comment'].to_numpy(), train['label'].to_numpy(), tokenizer, MAX_LEN, TRAIN_BATCH_SIZE, label_list)\n",
        "valid_data_loader = create_data_loader(valid['comment'].to_numpy(), valid['label'].to_numpy(), tokenizer, MAX_LEN, VALID_BATCH_SIZE, label_list)\n",
        "test_data_loader = create_data_loader(test['comment'].to_numpy(), None, tokenizer, MAX_LEN, TEST_BATCH_SIZE, label_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doP5OE1OWP38"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqhHjIUQYq3Y"
      },
      "source": [
        "**<font color=red> Complete forward function</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Mv75ARn_R_Dt"
      },
      "outputs": [],
      "source": [
        "class SentimentModel(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super(SentimentModel, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained(MODEL_NAME_OR_PATH)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
        "    \n",
        "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "        ##############################################################################################\n",
        "        #                                       Your Code                                            #\n",
        "        ##############################################################################################\n",
        "        # print(input_ids)\n",
        "        _, pooled_output = self.bert(\n",
        "            input_ids=input_ids, \n",
        "            attention_mask=attention_mask, \n",
        "            token_type_ids=token_type_ids, return_dict=False)\n",
        "        \n",
        "        print(type(pooled_output))\n",
        "        # pooled_output = torch.as_tensor(pooled_output)\n",
        "        # pooled_output = self.dropout(pooled_output)\n",
        "        print(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "VrObbZAdNTNl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a63f1666-3684-42ac-fd14-dc2c639d2956"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jun 14 18:33:23 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P8    11W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "import torch, gc\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "pt_model = None\n",
        "\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "7vzQGZGUmw3-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "1b37ce85d0ba4f74a75d65deb066614a",
            "999dd428264d447093b79a430cf006a9",
            "fa84b3deee9a449499955067e565cf48",
            "376d97cf555949e2847ba49c741aff5d",
            "1ee8ce0c6edd402f8b0d4a96fe8466e9",
            "d894ebbcafd14e2a957365a250eb6a54",
            "73f690b312e142a9ba59fff9adefc5b7",
            "1258cddfc7244ad8b472519a1518ed5c",
            "09839934638340d09ffaa0e1876b7656",
            "67b127d30cc843bf9274617c948e3d3f",
            "ad4641dc3143436cbdd6f64bfe65626a"
          ]
        },
        "outputId": "b603a1ce-c0bb-42e1-c5a8-4dd8ba974150"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/624M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b37ce85d0ba4f74a75d65deb066614a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at HooshvareLab/bert-fa-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pt_model <class '__main__.SentimentModel'>\n"
          ]
        }
      ],
      "source": [
        "pt_model = SentimentModel(config=config)\n",
        "pt_model = pt_model.to(device)\n",
        "\n",
        "print('pt_model', type(pt_model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFZQDfLlp0Sf"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f8_XjYbcdUv"
      },
      "source": [
        "**<font color=red> Complete functions</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "e044fZSfBoKe"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "def acc_and_f1(y_true, y_pred, average='weighted'):\n",
        "    # Define Accuracy and F1-score\n",
        "    ##############################################################################################\n",
        "    #                                       Your Code                                            #\n",
        "    ##############################################################################################\n",
        "    acc = (y_true == y_pred).mean()\n",
        "    f1 = f1_score(y_true=y_true, y_pred=y_pred, average=average)\n",
        "    return {\n",
        "        \"acc\": acc,\n",
        "        \"f1\": f1,\n",
        "    }\n",
        "\n",
        "def y_loss(y_true, y_pred, losses):\n",
        "    y_true = torch.stack(y_true).cpu().detach().numpy()\n",
        "    y_pred = torch.stack(y_pred).cpu().detach().numpy()\n",
        "    y = [y_true, y_pred]\n",
        "    loss = np.mean(losses)\n",
        "\n",
        "    return y, loss\n",
        "\n",
        "\n",
        "def eval_op(model, data_loader, loss_fn):\n",
        "    model.eval()\n",
        "\n",
        "    losses = []\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for dl in tqdm(data_loader, total=len(data_loader), desc=\"Evaluation... \"):\n",
        "\n",
        "            # Define input_ids, attention_mask, token_type_ids, targets\n",
        "            ##############################################################################################\n",
        "            #                                       Your Code                                            #\n",
        "            ##############################################################################################\n",
        "            input_ids = dl['input_ids']\n",
        "            attention_mask = dl['attention_mask']\n",
        "            token_type_ids = dl['token_type_ids']\n",
        "            targets = dl['targets']\n",
        "\n",
        "            # move tensors to GPU if CUDA is available\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            token_type_ids = token_type_ids.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            # compute predicted outputs by passing inputs to the model\n",
        "            ##############################################################################################\n",
        "            #                                       Your Code                                            #\n",
        "            ##############################################################################################\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                token_type_ids=token_type_ids)\n",
        "            \n",
        "            # convert output probabilities to predicted class\n",
        "            ##############################################################################################\n",
        "            #                                       Your Code                                            #\n",
        "            ##############################################################################################\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "            # calculate the batch loss\n",
        "            ##############################################################################################\n",
        "            #                                       Your Code                                            #\n",
        "            ##############################################################################################\n",
        "            loss = loss_fn(outputs, targets)\n",
        "\n",
        "            # accumulate all the losses\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            y_pred.extend(preds)\n",
        "            y_true.extend(targets)\n",
        "    \n",
        "    eval_y, eval_loss = y_loss(y_true, y_pred, losses)\n",
        "    return eval_y, eval_loss\n",
        "\n",
        "\n",
        "def train_op(model, \n",
        "             data_loader, \n",
        "             loss_fn, \n",
        "             optimizer, \n",
        "             scheduler, \n",
        "             step=0, \n",
        "             print_every_step=100, \n",
        "             eval=False,\n",
        "             eval_cb=None,\n",
        "             eval_loss_min=np.Inf,\n",
        "             eval_data_loader=None, \n",
        "             clip=0.0):\n",
        "    \n",
        "    model.train()\n",
        "\n",
        "    losses = []\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "\n",
        "    for dl in tqdm(data_loader, total=len(data_loader), desc=\"Training... \"):\n",
        "        step += 1\n",
        "\n",
        "        # Define input_ids, attention_mask, token_type_ids, targets\n",
        "        ##############################################################################################\n",
        "        #                                       Your Code                                            #\n",
        "        ##############################################################################################\n",
        "        input_ids = dl['input_ids']\n",
        "        attention_mask = dl['attention_mask']\n",
        "        token_type_ids = dl['token_type_ids']\n",
        "        targets = dl['targets']\n",
        "\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "        token_type_ids = token_type_ids.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        # clear the gradients of all optimized variables\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # compute predicted outputs by passing inputs to the model\n",
        "        ##############################################################################################\n",
        "        #                                       Your Code                                            #\n",
        "        ##############################################################################################\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids)\n",
        "        \n",
        "        # convert output probabilities to predicted class\n",
        "        ##############################################################################################\n",
        "        #                                       Your Code                                            #\n",
        "        ##############################################################################################\n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "        # calculate the batch loss\n",
        "        ##############################################################################################\n",
        "        #                                       Your Code                                            #\n",
        "        ##############################################################################################\n",
        "        loss = loss_fn(outputs, targets)\n",
        "\n",
        "        # accumulate all the losses\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        # compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        if clip > 0.0:\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip)\n",
        "\n",
        "        # perform optimization step\n",
        "        optimizer.step()\n",
        "\n",
        "        # perform scheduler step\n",
        "        scheduler.step()\n",
        "\n",
        "        y_pred.extend(preds)\n",
        "        y_true.extend(targets)\n",
        "\n",
        "        if eval:\n",
        "            train_y, train_loss = y_loss(y_true, y_pred, losses)\n",
        "            train_score = acc_and_f1(train_y[0], train_y[1], average='weighted')\n",
        "\n",
        "            if step % print_every_step == 0:\n",
        "                eval_y, eval_loss = eval_op(model, eval_data_loader, loss_fn)\n",
        "                eval_score = acc_and_f1(eval_y[0], eval_y[1], average='weighted')\n",
        "\n",
        "                if hasattr(eval_cb, '__call__'):\n",
        "                    eval_loss_min = eval_cb(model, step, train_score, train_loss, eval_score, eval_loss, eval_loss_min)\n",
        "\n",
        "    train_y, train_loss = y_loss(y_true, y_pred, losses)\n",
        "\n",
        "    return train_y, train_loss, step, eval_loss_min"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1vqogQgbCiH"
      },
      "source": [
        "**<font color=red> Define Optimizer, Scheduler & Loss Function</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTWrdialDAtN",
        "outputId": "9742cb36-ce32-4efe-df67-1e164bcb0c19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning:\n",
            "\n",
            "This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#######################################Your Code#############################################                                   \n",
        "optimizer = AdamW(pt_model.parameters(), lr=LEARNING_RATE, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()                                        \n",
        "##############################################################################################\n",
        "\n",
        "step = 0\n",
        "eval_loss_min = np.Inf\n",
        "history = collections.defaultdict(list)\n",
        "\n",
        "\n",
        "def eval_callback(epoch, epochs, output_path):\n",
        "    def eval_cb(model, step, train_score, train_loss, eval_score, eval_loss, eval_loss_min):\n",
        "        statement = ''\n",
        "        statement += 'Epoch: {}/{}...'.format(epoch, epochs)\n",
        "        statement += 'Step: {}...'.format(step)\n",
        "        \n",
        "        statement += 'Train Loss: {:.6f}...'.format(train_loss)\n",
        "        statement += 'Train Acc: {:.3f}...'.format(train_score['acc'])\n",
        "\n",
        "        statement += 'Valid Loss: {:.6f}...'.format(eval_loss)\n",
        "        statement += 'Valid Acc: {:.3f}...'.format(eval_score['acc'])\n",
        "\n",
        "        print(statement)\n",
        "\n",
        "        if eval_loss <= eval_loss_min:\n",
        "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "                eval_loss_min,\n",
        "                eval_loss))\n",
        "            \n",
        "            torch.save(model.state_dict(), output_path)\n",
        "            eval_loss_min = eval_loss\n",
        "        \n",
        "        return eval_loss_min\n",
        "\n",
        "    return eval_cb\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ph_-AxZkcvQ"
      },
      "source": [
        "**<font color=red> Complete Training & Plot Loss and Accuracy Diagram</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "7i42uhBMkbEy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "849a0c5397714e728f4a0feb8abcaf18",
            "a47c8af7a843479c8abd62902ab6ff1f",
            "9ba1f0d92cfb4520aebd5c2fb02c575d",
            "162d8d89f37e48b9ad775a6e88e66cca",
            "a456d87324ed4acd9f5c70f27719fa88",
            "a1c14ec7f1f74963a3d766611d3a615d",
            "a130a78d20434c2898297db8835ae3f0",
            "74e68e302692433eb0f3735b78adfeb4",
            "ed05b03884a942ccb7800218093cce49",
            "2b9c9c3bb07a4ca692149936f3c688ea",
            "51b0ffdbd4484d6db43405b57b042c50",
            "a5c90b77d0b442f380d7c3d183a5300c",
            "c2926082540d4dfc90cf557cf6db1144",
            "109267bf737e431884382b7d31fd7852",
            "8601eb8ad82545abaf747999a1a8f657",
            "ba841ab64e6f4c66ac56ea5a715a679d",
            "ff2338148b274857bc23c13145e0c906",
            "9a8013942fe24daf9b0e4df1f1f33981",
            "b1ca07b00b0446e2a553925a7950fe32",
            "bf09c769b2254724a902808b07eed392",
            "32ac88fd5ad942b19740d67d74915362",
            "2aadadb679b64dc7b951a63de7e0466f",
            "1f4f054c4ceb4eb4b22900a1439698fa",
            "a99a0c08e9db47d7990e7bcc00d83df6",
            "b53c5194051c4ff981d924ab0a3a8efc",
            "57bb996901ef458e94496afa5f16bbbb",
            "0c6081ba8ca6434d858b85fb6efd325a",
            "24a1ca4632b7490097060ed08b08cc99",
            "19bf4ef60dce4fbe93dffcb6bdc9a929",
            "659f3f0df94d46f6ac775ff04d21f84c",
            "f7fb1d381cff47ae8eee16df8d1208dd",
            "8f207df9a1384cf1ad4b36645946aa6e",
            "e96d3c3ed39d4897ad3a9d617a7bbe6a",
            "82592d0ddb6f4667848b15d4ddf63edb",
            "02ce970aebf74b179f170ff8c20b2bc1",
            "a5266057ae3342a0a9b3ac78a4f9c236",
            "c5061ba32c754d82a42c9fffaeef3b1a",
            "cc82c3ab83a34da3a89a672757bfb3d2",
            "edefb16f58bf44bfbd549e9696798074",
            "f47e3e38804e4555811860c0293e956a",
            "67840bd1888941f891211ea901ad00f5",
            "06955744027840e8bce23fea9c1c26ff",
            "dcbdc9cc99e14477ad7463d13a594a44",
            "1a002b68a0fc42e49f86d517175b421b",
            "893286436692404194cfef6c856cdc67",
            "eda97d34774b432d9204c3729f7e1d9a",
            "825a285ac309419f97b9a2bcef4f7751",
            "ce3fe39bef414eafab7d1a89280b0c86",
            "40ba3eb4005f4f80ab0529d13d2aeb2a",
            "17ac8f3fe5524703be485d2524772a14",
            "004e35587f8747acbaa4719545a49d5a",
            "5a4e3283bbf2426cb9ae5ea0db7a1f3a",
            "adc152c76b2841b185988d26eb7fd58b",
            "8eafef2060da49cbad827c9f1b072f5e",
            "6ef7e897435642dda7bc0ad1b71d9e12",
            "6d4d8827789e41f8be80a443f1a15bdf",
            "8fd982099f054498b548e70ba915952d",
            "6442cf2047d14730b6679df5acb66860",
            "a04497d7247b402f926ab46dedec7b45",
            "66f6ebb3a25143bcb40bc3ee9fa10c09",
            "580b60de18404ed3a6cb53bce4f8f710",
            "df24d290e37b41a4bb02a774cbd86697",
            "e2a50148d417445e859d6f184af3d560",
            "d54d3d1c36cb4d058d90f29fde59eced",
            "b91117a0c541458cbf5eb53c646f3a8b",
            "c7034328b49b4211a0f02a2211cbbda9",
            "270a2e26ad054a649f5169562e1326a5",
            "2a6b2cd2d54a4bc59a0da8a5bc629eea",
            "bb949fc263ff406cbfe018fcfdd37085",
            "89323f4b0f014299a98393ab07512664",
            "b2dc9a16147b4a28a5c90557119f7962",
            "b518b3e487db4191aac7a08f533cec28",
            "df334dc9cb7041388b1450d44e0618a2",
            "7f3a1158935745a8a9483afe4726546b",
            "905b216e2e584e1cb904ba72aa8a3477",
            "de357ed73f024a6a8971b0f3e266f9d0",
            "ed863aedc9f94162a64653b76f15450f",
            "9210640196204e76b9afb46e09bc612e",
            "7c64014fae4041ebbc3220d8f14e19c1",
            "5db0bae4bd0e4b49a6d492cdac896ebe",
            "689889ea9ee744bbade7c64ce451e1b6",
            "b350843193504592a810440cddd04c22",
            "871ab8105fd247a1ab25eda16976b5b1",
            "d4bb601e87d54588b920a1d6ada019af",
            "7ed7b6c303824311b481ae3d6b47f252",
            "4c786b8ae89a4cfdb949a77339d8048a",
            "73c8bb0f9b474300b6caf8db7627b3df",
            "008fcaf16170441db8d07fcad4f8f039",
            "0811f59155e945598ab2daf8db337ea5",
            "4bde0af3b5f2479f80374035ef7e945e",
            "17d4a00ab6934a35aa628aa059eea6e5",
            "68ece3a48eb84cfba024bdc49760582c",
            "7c137e0929d0476585ac3f2af2f3180b",
            "f4c799a68343416cbfbc57be1de6f8a4",
            "baee5ef17b8540cb9b67bd7adb737d5c",
            "f5a300352c7a44f0bcd173fe4b507862",
            "f7803fadc58e486a8457d2f238f16f98",
            "ba1f8ed4c2d748ad80233229b45d768e",
            "d22725e0be734a57af5fe276c88a4945",
            "9aed995118b443409667bc495b4e25df",
            "292ef6272db9499696072df7e307ea90",
            "07a0d2af5bff44f486dd2e3621184b67",
            "7a220e989fb64beca2d5abdecbb30c07",
            "132edba0bbdd49a686439c5c42668973",
            "9db67726b5054c0fa4bfeb168ad8cebf",
            "12477f9b808f44ae807ba8e35921b14f",
            "cd6e2f37e195447a9af47be38f9bd3d4",
            "16727ff7d8f649b59503d5b314cf84e8",
            "a8ee4f6383eb400197d522480a82c033",
            "5d28acfb8458487c986b4c9dc4d511d2",
            "02f80e5f64814c3082ae935a9072716c",
            "e693d92fe71742d09397264c4d99001b",
            "b8ec11b81aaa4247b30d6250a83ccc94",
            "d2d03889b7aa46888abdac0edc526ad4",
            "596bd130a9cf4693b6977d7bc4839af6",
            "96c5531de4764a05873f69da3847b853",
            "1c137234cdea4bd5a34b2cff9c5e1f47",
            "748c02a6382743e88f79ddea63b34c16",
            "17494a17b06547ddaa03d72ef8782044",
            "270f3ad8f39e4c1583546cbedd4644f1",
            "d887b730ae944f3bbaf310183d2bc40b",
            "86e0e04f92c34c38b98de2716e28e376",
            "1450abf5cd1549709badb72b0bac9728",
            "e2946ebcb3244438a391aba94cb44e21",
            "0adbf2ac679e45a0bda05b679d0e830c",
            "177cee6c3eda4b4eab4a2529cfdc7b7c",
            "5ff4520a721445cfaf5cc20fe279468d",
            "19bb820d169a4de1936e49e7f08df1a1",
            "79637fbcc5444cfd825373e0ee4780d5",
            "c9a8966752c94e1e909f77aa4425aeef",
            "5cc5c9813d80411fa37dff15005ecb6d",
            "a4c9df2b59f445cf8a4e5809c2b3a431",
            "d7f309d5689f49c39dbc1e9cd8f6d6a2",
            "bc12ea29b25646ef8a580244d08bddee",
            "70c8ae9dd3064c2098f0e60f8777f147",
            "ce3460e415dc4e64ab47124646438448",
            "f93eae4aed3b4761b65ad6e82512b5cf",
            "4bd127bfc7f04f0a8f5f22eaed5eb1fe",
            "b420d0c66c1b492a85b11cc48c655dcb",
            "47504834cd7f40fa95815e7db77c595a",
            "62d34ee221184081ba83758c7cf83168",
            "90a14ef808df4a6980416bdc0a061137",
            "efd6d60eb98b47d2a81a0599a316035d",
            "eb70fdbcdc9d4d36a8aa15a5047d5374",
            "097eb548449d407480c1d6a2bee7b729",
            "da0faebd99384bb19ac94167f625a43b",
            "5a3dc56a790a4768a1d4e106a1f7c230",
            "ccd0898d21c147dca8b93213f288ecbb",
            "b80fa8fa8b264cd09b72597bf9d40963",
            "657ca5ecd14d4b8c984c8ac1d628e827",
            "cea64c8c4b2f44919e653bb78d637478",
            "39ae8603d3a6414a987a669bf1e71d5d",
            "7a07341aa17841a7884cc2f77a229c73",
            "7fc9045d679d4187b005ba5e9f47c564",
            "c1b622bcbf364de69c9096d57f84dda8",
            "e06275da28e04b73a5b2a4d65f6ced24",
            "8eb45b00a6634c69ae88d3d5cf727ecf",
            "8a47a54439c64ef5bf8a1b32265ffde5",
            "670f02ea804446d984e0b1b060104cf2",
            "24cf6bdc462d43ed8cd930fec703c5ad",
            "23f5f89e1db0434e95c4e41643e5117c",
            "084d2597c7524dc786dfb87b858c4b82",
            "bcb1bb491e40493380fd038a9ef77401",
            "7a82aae66f2b4303a8a7405cbc96bdf5",
            "2ef6fdeeb916463b930433fda0f70ccc",
            "b701b766409f420f9e4ac66415582b78",
            "046f059594864439b2178641641e51e5",
            "0e605e2232bd4dd9b97367e2da30e923",
            "02631f3903bf4ece8764b84baf7ce838",
            "44cad2dff63543c88ee1d8e6ee8f4073",
            "4d95c58e9fd84a7c8c0bdbf91e5784b8",
            "ac77bddf75d44950b932c408535dc2a6",
            "28b51df6499d4bde8cecaa88d223c980",
            "bc33e0ded05d42978be7facb9a67d482",
            "907a5e1e362c4731857e10ee22b52c35",
            "cd1d10c42bb9446191e247c271fc9c17",
            "9f267748ea5d4da1917de0ceb1af462f",
            "82f505c824364c7c997c5bc5cf174183",
            "9c0363e2117245c9a22fb4de2f35e6db",
            "2616c8c2e7b24d6abe73144f07575842",
            "ac6c266425a24051a80c1a6a112a83da",
            "5e4b9c15d1dc44cf9290527e69983ae5",
            "e3f46ed90b4942759a68a499c18b6b97",
            "eb12f34dca574a1da206cf71d055785e",
            "e72082b305dc4ad7a794fb439cbd7fcd",
            "4e95fb3fd5c04c4f975be892a81b238f",
            "f6a07473f1e8475a8fae818c29f4ba08",
            "33403fd8abae4e149f34929ea89b70b0",
            "5a202287e0714bc49148cbf81739bb6f",
            "f08f3bc8fc234b809b02978b477f54cd",
            "091f3c7c1ce7486aacdef75f3c414725",
            "71ed124f595d482eb95d9ee172a29e39",
            "3d41d51bf67c46ffb50b443821473a1b",
            "e30d4bd707234b8b8ca501989e358b16",
            "d95a46f733264b428619021b72614002",
            "74b60563e7c742f7adb8487a409cb6d3",
            "7b2835053b7842cfa5e2dca6a8bf9726",
            "0bb9ff8bf78b4c89b371bf45ebf83753",
            "967af0dfa87e4eac911e6f0ab7415312",
            "f9dbc51c012f4708bfc4ba68621e2505",
            "b95e26d3560f433db8c77db9e1d27616",
            "40d5010dbed2473dbe7e0429b41b5461",
            "029183ecdc644903996e50d665ce198f",
            "1ad6d9c69a0b46e6b8e5876df0b26f81",
            "aa16ace50b74488d9559b0dba579ca4a",
            "96a851951e7c4e6e96dc9e10f99b6f22",
            "6ceb86f21f864739a0fa111259e41b7e",
            "7e6b0bd439894917b0d56c4b61733766",
            "5baf55b049bb4725aaced06f75e30136",
            "699381678de5446392cd7d2b13d3c83e",
            "c5b18a0216274ec3a8df4273d47d732f",
            "7f6f7e2499b84b8ca5456e2827a3e807",
            "af2bdf284b4c4a8aa950f64867445823",
            "b9a37eaa91984bb9ad78cda52cab0557",
            "2b136c6ff6204661a50531262017e0e4",
            "fef5fee962c64e358ec02dc84ad9e690",
            "1f5d9efbf78a495d8fd20a879bf344c5",
            "fb777dbe75334091a0477971da471c04",
            "19ac036ed63643509d0c2f337468860d",
            "9b471f92f09f4ee69b900ee0ba59170f",
            "f3243dfd90014c449a91e5e3826c00a0",
            "555bcd7ed31f4aa7951e6f6c4d987a30",
            "3e90e7ec33c34861837d8be88aebadd1",
            "6981b6c5ecee4c5fbae1bafe68d6ae45",
            "dbf683a521624767830719b3b9422220",
            "86edd78334fb44e69dd9028957d6b856",
            "5a9f098974fb494da092cc4e99e7fd63",
            "0bbdd0af72984ed285a3250ed217f558",
            "e1f76220efd04b2c81bd385b404c0752",
            "8e88156e2b0e460a84448b21a691e65a",
            "17d796277d014aca97f7b5ffcddbc01b",
            "aeebdb00c47c4e588897f4853757d9e5",
            "7bbe10ca6ad44295bcc215443725d29d",
            "320f2ab606874d3782b9e247049ec017",
            "dbe505d579f34f5f8cc1b1b6fb35562e",
            "c84ed20948244c48b74bba18edd4a7f4",
            "b21338a7b4544cd3a01e2ab686fc5ee4",
            "b852f703a61845efbe2df771a49eca88",
            "7598a304ccb94c42b623936c8f28769b",
            "2acd1337f8904501afda98640be3ffc5",
            "29d3f41ab12544efb7088dff79d3a732",
            "1210392c1a894b1ea96e22ab6339926a"
          ]
        },
        "outputId": "5604ec72-917f-4a10-9909-ef1487830354"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epochs... :   0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "849a0c5397714e728f4a0feb8abcaf18"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training... :   0%|          | 0/127 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5c90b77d0b442f380d7c3d183a5300c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0378,  1.0000,  0.0224,  ..., -0.3120, -0.1096, -0.4630],\n",
            "        [ 0.4726,  1.0000,  0.5462,  ..., -0.1145,  0.0859, -0.7667],\n",
            "        [ 0.7134,  1.0000,  0.6169,  ...,  0.3221,  0.0327, -0.6537],\n",
            "        ...,\n",
            "        [ 0.4668,  1.0000, -0.0116,  ..., -0.1864, -0.0823, -0.8706],\n",
            "        [ 0.6155,  1.0000,  0.1617,  ..., -0.0576, -0.0072, -0.6538],\n",
            "        [-0.0339,  0.9999, -0.5607,  ..., -0.7499, -0.1673, -0.3371]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 6.0703e-02,  9.9977e-01, -2.0738e-01,  ..., -7.6526e-01,\n",
            "          1.1743e-01,  6.8751e-02],\n",
            "        [ 2.2653e-01,  9.9998e-01,  1.5204e-01,  ...,  6.6082e-01,\n",
            "          5.6819e-02, -6.6635e-01],\n",
            "        [ 3.4060e-01,  9.9989e-01, -8.1676e-03,  ..., -6.3868e-01,\n",
            "          6.0675e-02, -7.6396e-01],\n",
            "        ...,\n",
            "        [ 4.6589e-01,  9.9783e-01,  1.9846e-01,  ...,  5.4770e-03,\n",
            "         -5.4221e-02, -3.9233e-01],\n",
            "        [ 3.8158e-01,  9.9990e-01, -3.7087e-01,  ..., -2.1707e-01,\n",
            "          1.7733e-01, -6.8158e-01],\n",
            "        [ 2.2851e-01,  9.9410e-01, -1.2848e-01,  ..., -9.5194e-04,\n",
            "         -1.3468e-01, -6.2531e-01]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4959,  0.9999, -0.3204,  ...,  0.1681,  0.5433, -0.4527],\n",
            "        [ 0.4814,  1.0000,  0.3843,  ...,  0.0489,  0.3095, -0.7338],\n",
            "        [ 0.6295,  1.0000,  0.3529,  ..., -0.0019,  0.8029, -0.7378],\n",
            "        ...,\n",
            "        [ 0.8114,  1.0000,  0.2029,  ...,  0.2179,  0.5092, -0.8935],\n",
            "        [-0.0582,  1.0000, -0.3519,  ..., -0.4924,  0.3296, -0.7391],\n",
            "        [ 0.2207,  1.0000,  0.6070,  ..., -0.1460,  0.6554, -0.6216]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7303,  1.0000, -0.0484,  ..., -0.2626,  0.7501, -0.8493],\n",
            "        [ 0.5513,  0.9966, -0.1923,  ..., -0.3049,  0.2445, -0.5728],\n",
            "        [ 0.6265,  1.0000,  0.0267,  ..., -0.6430,  0.6185, -0.7174],\n",
            "        ...,\n",
            "        [ 0.5173,  1.0000, -0.5009,  ..., -0.1048,  0.4627, -0.6883],\n",
            "        [ 0.5674,  1.0000,  0.0742,  ..., -0.4852,  0.4357, -0.4734],\n",
            "        [ 0.5789,  1.0000, -0.3646,  ..., -0.4650,  0.7704, -0.8670]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6494,  1.0000,  0.1329,  ...,  0.2531,  0.5672, -0.7917],\n",
            "        [ 0.8162,  1.0000, -0.1082,  ...,  0.6004,  0.8757, -0.8133],\n",
            "        [ 0.4427,  1.0000, -0.0236,  ..., -0.0053,  0.7127, -0.9304],\n",
            "        ...,\n",
            "        [ 0.4782,  1.0000, -0.0987,  ...,  0.3281,  0.4273, -0.6635],\n",
            "        [ 0.2708,  1.0000, -0.1802,  ..., -0.4829,  0.7275, -0.8943],\n",
            "        [ 0.2287,  1.0000, -0.1579,  ..., -0.5649,  0.8559, -0.8871]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0890,  0.9984,  0.7957,  ...,  0.0429, -0.5620, -0.5594],\n",
            "        [-0.4283,  1.0000,  0.6345,  ..., -0.1258, -0.0930, -0.4614],\n",
            "        [-0.1776,  1.0000,  0.3827,  ..., -0.1326,  0.0373, -0.6797],\n",
            "        ...,\n",
            "        [ 0.1811,  1.0000,  0.8557,  ..., -0.5862,  0.5157, -0.8395],\n",
            "        [-0.4784,  0.9999,  0.0739,  ...,  0.1794, -0.3136, -0.6908],\n",
            "        [ 0.0647,  1.0000,  0.5088,  ...,  0.3727,  0.5865, -0.9123]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1740,  1.0000,  0.7233,  ...,  0.1552, -0.0209, -0.5633],\n",
            "        [ 0.0296,  1.0000,  0.6138,  ...,  0.2327,  0.4792, -0.9435],\n",
            "        [ 0.1157,  1.0000,  0.5836,  ..., -0.3706,  0.1008, -0.9307],\n",
            "        ...,\n",
            "        [-0.4060,  1.0000,  0.3876,  ..., -0.1387, -0.0549, -0.7508],\n",
            "        [ 0.5901,  1.0000,  0.7908,  ...,  0.1279,  0.5974, -0.9052],\n",
            "        [ 0.2947,  1.0000,  0.3942,  ..., -0.1786,  0.0496, -0.7530]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3939,  1.0000, -0.0357,  ...,  0.2073, -0.4730, -0.6435],\n",
            "        [ 0.2837,  1.0000,  0.6471,  ..., -0.6779,  0.6256, -0.9632],\n",
            "        [ 0.4577,  1.0000,  0.6710,  ..., -0.4011,  0.1963, -0.8839],\n",
            "        ...,\n",
            "        [ 0.2771,  1.0000,  0.6185,  ..., -0.0158,  0.4666, -0.9177],\n",
            "        [ 0.3808,  1.0000,  0.8019,  ..., -0.1706,  0.5228, -0.9749],\n",
            "        [ 0.2640,  1.0000,  0.5848,  ..., -0.4338,  0.7203, -0.9374]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3895,  1.0000,  0.3455,  ..., -0.5425,  0.3255, -0.9512],\n",
            "        [-0.2479,  1.0000,  0.5296,  ..., -0.3897,  0.1635, -0.9335],\n",
            "        [ 0.3505,  1.0000,  0.2233,  ..., -0.6076,  0.1118, -0.9434],\n",
            "        ...,\n",
            "        [ 0.3049,  1.0000,  0.2010,  ..., -0.6318,  0.7311, -0.9405],\n",
            "        [ 0.5117,  1.0000,  0.3753,  ..., -0.7297,  0.6080, -0.9361],\n",
            "        [-0.1669,  1.0000, -0.5114,  ..., -0.3469, -0.0283, -0.7057]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5149,  1.0000,  0.3172,  ..., -0.8342,  0.3986, -0.9690],\n",
            "        [ 0.4866,  1.0000,  0.5321,  ..., -0.7143,  0.2085, -0.8727],\n",
            "        [ 0.6744,  1.0000,  0.5174,  ..., -0.2691,  0.7568, -0.9691],\n",
            "        ...,\n",
            "        [-0.5519,  1.0000,  0.6266,  ..., -0.8868, -0.1866, -0.8138],\n",
            "        [-0.1639,  1.0000,  0.1105,  ..., -0.9186,  0.2221, -0.9141],\n",
            "        [ 0.2173,  1.0000,  0.1339,  ..., -0.8108,  0.5010, -0.9527]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0644,  1.0000,  0.4457,  ..., -0.8752,  0.5837, -0.8620],\n",
            "        [ 0.3180,  1.0000,  0.6809,  ..., -0.8712,  0.5013, -0.9194],\n",
            "        [-0.0421,  1.0000,  0.6051,  ..., -0.8496,  0.1503, -0.9274],\n",
            "        ...,\n",
            "        [-0.2427,  1.0000,  0.7267,  ..., -0.8589, -0.1545, -0.8666],\n",
            "        [-0.1667,  1.0000,  0.4883,  ..., -0.9259, -0.1805, -0.8825],\n",
            "        [ 0.1668,  1.0000,  0.5607,  ..., -0.7594,  0.6640, -0.9646]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2366,  1.0000,  0.5454,  ..., -0.9488,  0.8181, -0.9127],\n",
            "        [-0.1426,  1.0000,  0.4186,  ..., -0.9416,  0.3411, -0.9310],\n",
            "        [ 0.4416,  1.0000,  0.7128,  ..., -0.8590,  0.4676, -0.9101],\n",
            "        ...,\n",
            "        [ 0.0123,  1.0000,  0.4595,  ..., -0.9061,  0.4147, -0.8883],\n",
            "        [-0.0679,  1.0000,  0.4529,  ..., -0.9353,  0.7008, -0.8964],\n",
            "        [ 0.3489,  1.0000,  0.6439,  ..., -0.9100,  0.7841, -0.9772]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6751,  1.0000,  0.7836,  ..., -0.9055,  0.8252, -0.9812],\n",
            "        [ 0.2573,  1.0000,  0.4390,  ..., -0.8899,  0.7642, -0.9739],\n",
            "        [ 0.3401,  1.0000,  0.6896,  ..., -0.9051,  0.6451, -0.9422],\n",
            "        ...,\n",
            "        [ 0.2910,  1.0000,  0.7666,  ..., -0.9159,  0.7216, -0.8926],\n",
            "        [ 0.1930,  1.0000,  0.2987,  ..., -0.9545,  0.5355, -0.9489],\n",
            "        [ 0.0611,  1.0000,  0.6432,  ..., -0.8396,  0.6341, -0.9724]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3084,  1.0000,  0.6559,  ..., -0.9437,  0.7859, -0.9602],\n",
            "        [-0.3023,  1.0000,  0.8232,  ..., -0.7433,  0.2849, -0.9140],\n",
            "        [ 0.3301,  1.0000,  0.6520,  ..., -0.9134,  0.8042, -0.9698],\n",
            "        ...,\n",
            "        [ 0.5854,  1.0000,  0.7125,  ..., -0.9251,  0.7895, -0.9632],\n",
            "        [ 0.3466,  1.0000,  0.6750,  ..., -0.9170,  0.8837, -0.9767],\n",
            "        [ 0.4331,  1.0000,  0.7651,  ..., -0.8786,  0.6188, -0.9887]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0980,  1.0000,  0.7805,  ..., -0.9224,  0.8168, -0.9788],\n",
            "        [ 0.1127,  1.0000,  0.7810,  ..., -0.9590,  0.8083, -0.9851],\n",
            "        [ 0.1658,  1.0000,  0.7951,  ..., -0.9286,  0.8125, -0.9770],\n",
            "        ...,\n",
            "        [ 0.6563,  1.0000,  0.8150,  ..., -0.8969,  0.8791, -0.9835],\n",
            "        [-0.4504,  1.0000,  0.7457,  ..., -0.9214,  0.5180, -0.8917],\n",
            "        [ 0.1671,  1.0000,  0.4884,  ..., -0.8313,  0.7684, -0.9738]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3784,  1.0000,  0.6702,  ..., -0.8969,  0.8385, -0.9848],\n",
            "        [ 0.5288,  1.0000,  0.8904,  ..., -0.8754,  0.8119, -0.9863],\n",
            "        [ 0.1020,  1.0000,  0.8656,  ..., -0.9031,  0.7217, -0.9564],\n",
            "        ...,\n",
            "        [ 0.5103,  1.0000,  0.6598,  ..., -0.9087,  0.8881, -0.9606],\n",
            "        [ 0.3383,  1.0000,  0.7387,  ..., -0.9524,  0.8477, -0.9792],\n",
            "        [-0.2842,  1.0000,  0.8162,  ..., -0.9231,  0.8515, -0.9710]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6956,  1.0000,  0.6545,  ..., -0.9161,  0.8595, -0.9732],\n",
            "        [-0.0476,  1.0000,  0.7962,  ..., -0.7716,  0.5234, -0.9347],\n",
            "        [ 0.3685,  1.0000,  0.9264,  ..., -0.9251,  0.8158, -0.9882],\n",
            "        ...,\n",
            "        [ 0.2908,  1.0000,  0.7348,  ..., -0.9104,  0.8425, -0.9605],\n",
            "        [ 0.0012,  1.0000,  0.7910,  ..., -0.9299,  0.8056, -0.9720],\n",
            "        [ 0.1754,  1.0000,  0.8682,  ..., -0.6726,  0.6700, -0.9382]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5011,  1.0000,  0.7191,  ..., -0.8783,  0.8796, -0.9868],\n",
            "        [ 0.2759,  1.0000,  0.9148,  ..., -0.9453,  0.6574, -0.9844],\n",
            "        [-0.0894,  1.0000,  0.9036,  ..., -0.8961,  0.7356, -0.9577],\n",
            "        ...,\n",
            "        [ 0.1974,  1.0000,  0.7199,  ..., -0.7732,  0.7519, -0.9736],\n",
            "        [ 0.3027,  1.0000,  0.8276,  ..., -0.8130,  0.7301, -0.9609],\n",
            "        [ 0.6142,  1.0000,  0.7664,  ..., -0.8908,  0.8637, -0.9918]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6615,  1.0000,  0.8103,  ..., -0.8517,  0.8635, -0.9873],\n",
            "        [ 0.5419,  1.0000,  0.8144,  ..., -0.9116,  0.9108, -0.9884],\n",
            "        [ 0.5831,  1.0000,  0.8816,  ..., -0.8553,  0.8652, -0.9831],\n",
            "        ...,\n",
            "        [ 0.2142,  1.0000,  0.8932,  ..., -0.8388,  0.8142, -0.9669],\n",
            "        [ 0.6202,  1.0000,  0.8543,  ..., -0.8124,  0.8824, -0.9873],\n",
            "        [ 0.3549,  1.0000,  0.8668,  ..., -0.9092,  0.8211, -0.9541]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7740,  1.0000,  0.7469,  ..., -0.8132,  0.9331, -0.9864],\n",
            "        [ 0.5953,  1.0000,  0.8259,  ..., -0.8819,  0.9165, -0.9878],\n",
            "        [ 0.4997,  1.0000,  0.8779,  ..., -0.8053,  0.8431, -0.9715],\n",
            "        ...,\n",
            "        [ 0.7010,  1.0000,  0.8181,  ..., -0.8834,  0.9288, -0.9954],\n",
            "        [ 0.5144,  1.0000,  0.8434,  ..., -0.8903,  0.9224, -0.9941],\n",
            "        [ 0.5134,  1.0000,  0.7047,  ..., -0.7924,  0.9384, -0.9852]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6262,  1.0000,  0.5760,  ..., -0.8596,  0.9240, -0.9866],\n",
            "        [ 0.5769,  1.0000,  0.8739,  ..., -0.9029,  0.9047, -0.9826],\n",
            "        [ 0.6525,  1.0000,  0.7769,  ..., -0.8826,  0.8628, -0.9878],\n",
            "        ...,\n",
            "        [ 0.5689,  1.0000,  0.8380,  ..., -0.9018,  0.9222, -0.9898],\n",
            "        [ 0.6573,  1.0000,  0.5025,  ..., -0.9384,  0.9251, -0.9850],\n",
            "        [ 0.0217,  1.0000,  0.9014,  ..., -0.6151,  0.8140, -0.9345]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7346,  1.0000,  0.8020,  ..., -0.8659,  0.9197, -0.9820],\n",
            "        [ 0.6691,  1.0000,  0.7230,  ..., -0.9074,  0.8710, -0.9923],\n",
            "        [ 0.6387,  1.0000,  0.8119,  ..., -0.9032,  0.8836, -0.9874],\n",
            "        ...,\n",
            "        [ 0.5316,  1.0000,  0.8193,  ..., -0.9485,  0.8356, -0.9852],\n",
            "        [ 0.6672,  1.0000,  0.8630,  ..., -0.8522,  0.8800, -0.9890],\n",
            "        [ 0.3984,  1.0000,  0.8084,  ..., -0.8827,  0.8225, -0.9829]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6131,  1.0000,  0.7692,  ..., -0.9455,  0.9042, -0.9859],\n",
            "        [ 0.4561,  1.0000,  0.8863,  ..., -0.9305,  0.8774, -0.9763],\n",
            "        [ 0.1153,  1.0000,  0.8286,  ..., -0.8428,  0.8115, -0.9616],\n",
            "        ...,\n",
            "        [ 0.4812,  1.0000,  0.6188,  ..., -0.8638,  0.9029, -0.9785],\n",
            "        [ 0.5269,  1.0000,  0.7298,  ..., -0.8193,  0.8904, -0.9839],\n",
            "        [ 0.4970,  1.0000,  0.8319,  ..., -0.9138,  0.8490, -0.9838]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4205,  1.0000,  0.8747,  ..., -0.9115,  0.8581, -0.9915],\n",
            "        [ 0.5577,  1.0000,  0.6775,  ..., -0.8918,  0.8682, -0.9867],\n",
            "        [ 0.1535,  1.0000,  0.9033,  ..., -0.6886,  0.6664, -0.9434],\n",
            "        ...,\n",
            "        [ 0.4603,  1.0000,  0.8538,  ..., -0.9006,  0.8051, -0.9873],\n",
            "        [ 0.4518,  1.0000,  0.8974,  ..., -0.9292,  0.8916, -0.9856],\n",
            "        [ 0.4088,  1.0000,  0.9254,  ..., -0.8872,  0.7655, -0.9839]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1686,  1.0000,  0.9166,  ..., -0.8836,  0.8104, -0.9422],\n",
            "        [ 0.4627,  1.0000,  0.8412,  ..., -0.9368,  0.8220, -0.9862],\n",
            "        [ 0.5248,  1.0000,  0.8308,  ..., -0.9473,  0.9082, -0.9832],\n",
            "        ...,\n",
            "        [ 0.3564,  1.0000,  0.9196,  ..., -0.9359,  0.8475, -0.9779],\n",
            "        [ 0.3760,  1.0000,  0.9142,  ..., -0.8949,  0.8930, -0.9800],\n",
            "        [ 0.1100,  1.0000,  0.9337,  ..., -0.9122,  0.6996, -0.9571]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2069,  1.0000,  0.9228,  ..., -0.9353,  0.7155, -0.9697],\n",
            "        [ 0.4139,  1.0000,  0.8963,  ..., -0.9503,  0.8617, -0.9853],\n",
            "        [ 0.1843,  1.0000,  0.8568,  ..., -0.9314,  0.8322, -0.9689],\n",
            "        ...,\n",
            "        [ 0.3260,  1.0000,  0.8334,  ..., -0.9546,  0.8406, -0.9874],\n",
            "        [ 0.1918,  1.0000,  0.8712,  ..., -0.9328,  0.8362, -0.9807],\n",
            "        [ 0.5824,  1.0000,  0.8818,  ..., -0.9177,  0.8008, -0.9899]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7680,  1.0000,  0.8022,  ..., -0.9184,  0.8985, -0.9820],\n",
            "        [ 0.3060,  1.0000,  0.9240,  ..., -0.9503,  0.7745, -0.9725],\n",
            "        [ 0.1549,  1.0000,  0.8726,  ..., -0.9308,  0.7662, -0.9700],\n",
            "        ...,\n",
            "        [ 0.1316,  1.0000,  0.9296,  ..., -0.9182,  0.7864, -0.9719],\n",
            "        [ 0.3394,  1.0000,  0.8515,  ..., -0.7891,  0.8781, -0.9830],\n",
            "        [ 0.2647,  1.0000,  0.8567,  ..., -0.8943,  0.8826, -0.9810]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2871,  1.0000,  0.8357,  ..., -0.9060,  0.9022, -0.9821],\n",
            "        [ 0.5470,  1.0000,  0.7960,  ..., -0.8562,  0.8413, -0.9894],\n",
            "        [-0.0990,  1.0000,  0.8923,  ..., -0.8936,  0.6083, -0.9622],\n",
            "        ...,\n",
            "        [ 0.4182,  1.0000,  0.8255,  ..., -0.9195,  0.8637, -0.9782],\n",
            "        [ 0.6089,  1.0000,  0.8484,  ..., -0.8721,  0.9086, -0.9804],\n",
            "        [ 0.7081,  1.0000,  0.7875,  ..., -0.8642,  0.9288, -0.9890]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5599,  1.0000,  0.8190,  ..., -0.8706,  0.8971, -0.9899],\n",
            "        [ 0.6414,  1.0000,  0.9118,  ..., -0.9169,  0.8298, -0.9785],\n",
            "        [ 0.5727,  1.0000,  0.8301,  ..., -0.8602,  0.9245, -0.9672],\n",
            "        ...,\n",
            "        [ 0.4993,  1.0000,  0.7309,  ..., -0.8676,  0.9081, -0.9894],\n",
            "        [ 0.3428,  1.0000,  0.9297,  ..., -0.8977,  0.7752, -0.9779],\n",
            "        [ 0.2663,  1.0000,  0.9074,  ..., -0.9297,  0.7809, -0.9899]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0427,  1.0000,  0.8935,  ..., -0.9260,  0.6378, -0.9741],\n",
            "        [-0.0038,  1.0000,  0.8626,  ..., -0.9138,  0.8440, -0.9674],\n",
            "        [ 0.3393,  1.0000,  0.8049,  ..., -0.8496,  0.8436, -0.9808],\n",
            "        ...,\n",
            "        [ 0.6445,  1.0000,  0.8359,  ..., -0.9215,  0.8591, -0.9833],\n",
            "        [ 0.6632,  1.0000,  0.8592,  ..., -0.8852,  0.9357, -0.9798],\n",
            "        [ 0.0266,  1.0000,  0.9147,  ..., -0.8804,  0.7228, -0.9701]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6382,  1.0000,  0.6697,  ..., -0.8444,  0.9221, -0.9761],\n",
            "        [ 0.4805,  1.0000,  0.6511,  ..., -0.8843,  0.9418, -0.9859],\n",
            "        [ 0.5397,  1.0000,  0.7120,  ..., -0.8560,  0.8974, -0.9847],\n",
            "        ...,\n",
            "        [ 0.7217,  1.0000,  0.5260,  ..., -0.8201,  0.9277, -0.9682],\n",
            "        [ 0.7196,  1.0000,  0.7781,  ..., -0.8160,  0.8897, -0.9833],\n",
            "        [ 0.6158,  1.0000,  0.5894,  ..., -0.8065,  0.9219, -0.9848]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5334,  1.0000,  0.7737,  ..., -0.9104,  0.8713, -0.9792],\n",
            "        [ 0.3090,  1.0000,  0.9005,  ..., -0.8930,  0.8670, -0.9835],\n",
            "        [ 0.4091,  1.0000,  0.7131,  ..., -0.8311,  0.8971, -0.9684],\n",
            "        ...,\n",
            "        [ 0.5541,  1.0000,  0.8176,  ..., -0.9075,  0.8633, -0.9771],\n",
            "        [ 0.1793,  1.0000,  0.8953,  ..., -0.9024,  0.8857, -0.9771],\n",
            "        [ 0.3658,  1.0000,  0.7284,  ..., -0.9240,  0.8662, -0.9824]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4293,  1.0000,  0.8402,  ..., -0.9334,  0.8961, -0.9690],\n",
            "        [ 0.3886,  1.0000,  0.8605,  ..., -0.7141,  0.7519, -0.9674],\n",
            "        [ 0.3068,  1.0000,  0.8396,  ..., -0.9423,  0.9112, -0.9575],\n",
            "        ...,\n",
            "        [ 0.7272,  1.0000,  0.7580,  ..., -0.7928,  0.9380, -0.9908],\n",
            "        [ 0.5593,  1.0000,  0.6977,  ..., -0.8999,  0.9376, -0.9796],\n",
            "        [ 0.8044,  1.0000,  0.6132,  ..., -0.7955,  0.9171, -0.9841]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6208,  1.0000,  0.7924,  ..., -0.6911,  0.9421, -0.9818],\n",
            "        [ 0.2069,  1.0000,  0.9064,  ..., -0.9252,  0.8693, -0.9915],\n",
            "        [ 0.6678,  1.0000,  0.7227,  ..., -0.8052,  0.8713, -0.9825],\n",
            "        ...,\n",
            "        [ 0.6987,  1.0000,  0.6733,  ..., -0.8301,  0.8932, -0.9875],\n",
            "        [ 0.0898,  1.0000,  0.8360,  ..., -0.7156,  0.8176, -0.9452],\n",
            "        [ 0.4555,  1.0000,  0.7984,  ..., -0.7683,  0.8800, -0.9889]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3846,  1.0000,  0.9456,  ..., -0.9042,  0.8102, -0.9715],\n",
            "        [ 0.5127,  1.0000,  0.7736,  ..., -0.8921,  0.8436, -0.9810],\n",
            "        [ 0.4740,  1.0000,  0.8297,  ..., -0.8507,  0.7924, -0.9750],\n",
            "        ...,\n",
            "        [ 0.5226,  1.0000,  0.7350,  ..., -0.8164,  0.8684, -0.9814],\n",
            "        [ 0.4460,  1.0000,  0.9075,  ..., -0.9139,  0.8078, -0.9901],\n",
            "        [ 0.4323,  1.0000,  0.9190,  ..., -0.8990,  0.9068, -0.9845]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4575,  1.0000,  0.8623,  ..., -0.9411,  0.8654, -0.9638],\n",
            "        [ 0.5536,  1.0000,  0.8134,  ..., -0.8836,  0.8480, -0.9852],\n",
            "        [ 0.3892,  1.0000,  0.4095,  ..., -0.7227,  0.9221, -0.9757],\n",
            "        ...,\n",
            "        [ 0.4476,  1.0000,  0.9289,  ..., -0.9407,  0.8098, -0.9943],\n",
            "        [ 0.2623,  1.0000,  0.9323,  ..., -0.9418,  0.6893, -0.9772],\n",
            "        [ 0.3016,  1.0000,  0.8099,  ..., -0.9071,  0.8333, -0.9801]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2751,  1.0000,  0.9542,  ..., -0.8644,  0.7558, -0.9767],\n",
            "        [ 0.3589,  1.0000,  0.9127,  ..., -0.9362,  0.7893, -0.9858],\n",
            "        [-0.2302,  1.0000,  0.8583,  ..., -0.8484,  0.6609, -0.9415],\n",
            "        ...,\n",
            "        [ 0.4038,  1.0000,  0.8245,  ..., -0.7622,  0.9276, -0.9906],\n",
            "        [ 0.4581,  1.0000,  0.7559,  ..., -0.8805,  0.9050, -0.9908],\n",
            "        [ 0.3321,  1.0000,  0.8475,  ..., -0.8966,  0.6957, -0.9850]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3251,  1.0000,  0.9316,  ..., -0.9438,  0.7982, -0.9845],\n",
            "        [ 0.0244,  1.0000,  0.9285,  ..., -0.9483,  0.6481, -0.9784],\n",
            "        [ 0.6429,  1.0000,  0.8767,  ..., -0.7223,  0.9116, -0.9945],\n",
            "        ...,\n",
            "        [ 0.2310,  1.0000,  0.9200,  ..., -0.9089,  0.5990, -0.9744],\n",
            "        [ 0.4632,  1.0000,  0.5596,  ..., -0.8310,  0.7858, -0.9309],\n",
            "        [ 0.2651,  1.0000,  0.6307,  ..., -0.7787,  0.8348, -0.9464]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6055,  1.0000,  0.9229,  ..., -0.9091,  0.8258, -0.9811],\n",
            "        [ 0.1916,  1.0000,  0.9522,  ..., -0.7617,  0.1796, -0.9534],\n",
            "        [ 0.3544,  1.0000,  0.9576,  ..., -0.8926,  0.6804, -0.9825],\n",
            "        ...,\n",
            "        [-0.0376,  1.0000,  0.9594,  ..., -0.8950,  0.2961, -0.9527],\n",
            "        [ 0.0834,  1.0000,  0.9332,  ..., -0.9058,  0.8307, -0.9781],\n",
            "        [-0.0387,  1.0000,  0.8977,  ..., -0.9220,  0.5348, -0.9579]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0648,  1.0000,  0.9549,  ..., -0.4766,  0.5703, -0.9220],\n",
            "        [ 0.5070,  1.0000,  0.9321,  ..., -0.8906,  0.7394, -0.9713],\n",
            "        [ 0.5716,  1.0000,  0.8465,  ..., -0.9101,  0.7481, -0.9824],\n",
            "        ...,\n",
            "        [ 0.5855,  1.0000,  0.8423,  ..., -0.8329,  0.8263, -0.9940],\n",
            "        [ 0.7310,  1.0000,  0.7870,  ..., -0.6564,  0.8808, -0.9886],\n",
            "        [ 0.6147,  1.0000,  0.8466,  ..., -0.8847,  0.9127, -0.9858]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5337,  1.0000,  0.9105,  ..., -0.9376,  0.7849, -0.9849],\n",
            "        [ 0.4636,  1.0000,  0.7514,  ..., -0.6954,  0.8644, -0.9801],\n",
            "        [ 0.5252,  1.0000,  0.5248,  ..., -0.4278,  0.9073, -0.9443],\n",
            "        ...,\n",
            "        [-0.2029,  1.0000,  0.9508,  ..., -0.6941,  0.4605, -0.9308],\n",
            "        [ 0.2955,  1.0000,  0.9525,  ..., -0.8520,  0.8169, -0.9868],\n",
            "        [ 0.5674,  1.0000,  0.9248,  ..., -0.9163,  0.8725, -0.9782]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2913,  1.0000,  0.9182,  ..., -0.7961,  0.2230, -0.8918],\n",
            "        [ 0.4588,  1.0000,  0.9505,  ..., -0.9379,  0.4765, -0.9797],\n",
            "        [ 0.4071,  1.0000,  0.7923,  ..., -0.8521,  0.8092, -0.9431],\n",
            "        ...,\n",
            "        [ 0.5335,  1.0000,  0.8791,  ..., -0.9102,  0.7737, -0.9905],\n",
            "        [ 0.2689,  1.0000,  0.8650,  ..., -0.9223,  0.7383, -0.9894],\n",
            "        [ 0.2456,  1.0000,  0.8408,  ..., -0.7919,  0.6330, -0.9744]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5148,  1.0000,  0.9086,  ..., -0.8910,  0.8121, -0.9921],\n",
            "        [ 0.5388,  1.0000,  0.8426,  ..., -0.9142,  0.7923, -0.9933],\n",
            "        [ 0.5920,  1.0000,  0.8385,  ..., -0.7016,  0.8580, -0.9680],\n",
            "        ...,\n",
            "        [-0.0234,  1.0000,  0.9340,  ..., -0.8946,  0.6671, -0.9617],\n",
            "        [ 0.6343,  1.0000,  0.6608,  ..., -0.7597,  0.8508, -0.9868],\n",
            "        [ 0.4964,  1.0000,  0.9106,  ..., -0.8659,  0.8651, -0.9801]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5929,  1.0000,  0.8369,  ..., -0.7822,  0.8526, -0.9844],\n",
            "        [ 0.0398,  1.0000,  0.5876,  ..., -0.8881,  0.5949, -0.9409],\n",
            "        [ 0.2862,  1.0000,  0.4646,  ..., -0.8537,  0.7968, -0.9652],\n",
            "        ...,\n",
            "        [ 0.5656,  1.0000,  0.6509,  ..., -0.8091,  0.8609, -0.9815],\n",
            "        [ 0.2196,  1.0000,  0.9495,  ..., -0.9006,  0.6664, -0.9757],\n",
            "        [ 0.6601,  1.0000,  0.7037,  ..., -0.8128,  0.9459, -0.9772]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3320,  1.0000,  0.9432,  ..., -0.8817,  0.7544, -0.9810],\n",
            "        [-0.0999,  1.0000,  0.9590,  ..., -0.8240,  0.4705, -0.9417],\n",
            "        [ 0.4127,  1.0000,  0.9033,  ..., -0.8484,  0.8409, -0.9915],\n",
            "        ...,\n",
            "        [ 0.5236,  1.0000,  0.9442,  ..., -0.8775,  0.8200, -0.9856],\n",
            "        [ 0.7020,  1.0000,  0.5638,  ..., -0.4097,  0.8453, -0.9521],\n",
            "        [-0.1502,  1.0000,  0.9253,  ..., -0.8900,  0.6629, -0.9464]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5940,  1.0000,  0.8730,  ..., -0.8346,  0.8807, -0.9850],\n",
            "        [ 0.6489,  1.0000,  0.6229,  ..., -0.5804,  0.9381, -0.9685],\n",
            "        [-0.0151,  1.0000,  0.6161,  ..., -0.8568,  0.5777, -0.9727],\n",
            "        ...,\n",
            "        [ 0.6245,  1.0000,  0.6082,  ..., -0.7263,  0.9068, -0.9774],\n",
            "        [ 0.0523,  1.0000,  0.8772,  ..., -0.9324,  0.5354, -0.9697],\n",
            "        [ 0.2131,  1.0000,  0.9487,  ..., -0.7779,  0.7972, -0.9868]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5318,  1.0000,  0.8124,  ..., -0.8468,  0.8601, -0.9700],\n",
            "        [ 0.1132,  1.0000,  0.9368,  ..., -0.9038,  0.5038, -0.9723],\n",
            "        [ 0.3871,  1.0000,  0.6118,  ..., -0.8624,  0.9000, -0.9571],\n",
            "        ...,\n",
            "        [ 0.3379,  1.0000,  0.9466,  ..., -0.8128,  0.7917, -0.9899],\n",
            "        [ 0.4477,  1.0000,  0.9082,  ..., -0.8234,  0.7834, -0.9809],\n",
            "        [ 0.5419,  1.0000,  0.4837,  ..., -0.6226,  0.8835, -0.9566]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6110,  1.0000,  0.7787,  ..., -0.8285,  0.9113, -0.9626],\n",
            "        [ 0.5884,  1.0000,  0.9456,  ..., -0.8642,  0.7169, -0.9909],\n",
            "        [ 0.5254,  1.0000,  0.8285,  ..., -0.8220,  0.9215, -0.9649],\n",
            "        ...,\n",
            "        [-0.2748,  1.0000,  0.9673,  ..., -0.7791,  0.2757, -0.9563],\n",
            "        [ 0.6906,  1.0000,  0.7644,  ..., -0.7154,  0.9268, -0.9813],\n",
            "        [ 0.0200,  1.0000,  0.9114,  ..., -0.7766,  0.6189, -0.9559]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4654,  1.0000,  0.7609,  ..., -0.6397,  0.6929, -0.9756],\n",
            "        [ 0.3406,  1.0000,  0.9094,  ..., -0.9014,  0.6754, -0.9900],\n",
            "        [ 0.4902,  1.0000,  0.9052,  ..., -0.7886,  0.7727, -0.9852],\n",
            "        ...,\n",
            "        [ 0.3655,  1.0000,  0.9281,  ..., -0.8525,  0.7127, -0.9838],\n",
            "        [ 0.7088,  1.0000,  0.7759,  ..., -0.7845,  0.8475, -0.9767],\n",
            "        [ 0.6743,  1.0000,  0.8163,  ..., -0.7979,  0.9352, -0.9811]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3966,  1.0000,  0.9563,  ..., -0.8688,  0.7816, -0.9880],\n",
            "        [ 0.4118,  1.0000,  0.9151,  ..., -0.7770,  0.7744, -0.9901],\n",
            "        [ 0.6895,  1.0000,  0.7925,  ..., -0.6605,  0.9035, -0.9915],\n",
            "        ...,\n",
            "        [ 0.5770,  1.0000,  0.9164,  ..., -0.8407,  0.8356, -0.9914],\n",
            "        [ 0.4103,  1.0000,  0.9271,  ..., -0.8902,  0.5235, -0.9870],\n",
            "        [ 0.0655,  1.0000,  0.9318,  ..., -0.6329,  0.6707, -0.9670]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0079,  1.0000,  0.9327,  ..., -0.8234,  0.4053, -0.9676],\n",
            "        [ 0.4551,  1.0000,  0.8934,  ..., -0.8526,  0.8996, -0.9874],\n",
            "        [ 0.4184,  1.0000,  0.9328,  ..., -0.9135,  0.7021, -0.9859],\n",
            "        ...,\n",
            "        [ 0.6303,  1.0000,  0.7521,  ..., -0.8498,  0.8937, -0.9925],\n",
            "        [ 0.8222,  1.0000,  0.6334,  ..., -0.6786,  0.8506, -0.9846],\n",
            "        [ 0.3429,  1.0000,  0.8052,  ..., -0.5766,  0.5682, -0.9583]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4215,  1.0000,  0.9518,  ..., -0.8785,  0.7280, -0.9880],\n",
            "        [ 0.5657,  1.0000,  0.8753,  ..., -0.9526,  0.7604, -0.9821],\n",
            "        [ 0.2888,  1.0000,  0.6776,  ..., -0.8250,  0.8481, -0.9773],\n",
            "        ...,\n",
            "        [ 0.7782,  1.0000,  0.7909,  ..., -0.8008,  0.8102, -0.9762],\n",
            "        [ 0.3257,  1.0000,  0.9585,  ..., -0.8115,  0.7073, -0.9883],\n",
            "        [ 0.3279,  1.0000,  0.9482,  ..., -0.8739,  0.5601, -0.9755]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5165,  1.0000,  0.9748,  ..., -0.8865,  0.8115, -0.9895],\n",
            "        [ 0.5347,  1.0000,  0.9490,  ..., -0.8255,  0.6577, -0.9938],\n",
            "        [ 0.6573,  1.0000,  0.9040,  ..., -0.8699,  0.8830, -0.9908],\n",
            "        ...,\n",
            "        [ 0.6267,  1.0000,  0.8728,  ..., -0.7565,  0.7975, -0.9880],\n",
            "        [ 0.7344,  1.0000,  0.6838,  ..., -0.5396,  0.9095, -0.9683],\n",
            "        [ 0.8323,  1.0000,  0.8395,  ..., -0.5908,  0.7460, -0.9676]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.8080,  1.0000,  0.6476,  ..., -0.7195,  0.9150, -0.9725],\n",
            "        [ 0.5847,  1.0000,  0.9621,  ..., -0.8314,  0.6530, -0.9858],\n",
            "        [ 0.6277,  1.0000,  0.9372,  ..., -0.8749,  0.8843, -0.9888],\n",
            "        ...,\n",
            "        [ 0.6161,  1.0000,  0.7585,  ..., -0.7742,  0.7932, -0.9756],\n",
            "        [ 0.7485,  1.0000,  0.6603,  ..., -0.6996,  0.8715, -0.9667],\n",
            "        [ 0.7657,  1.0000,  0.7720,  ..., -0.6015,  0.8245, -0.9691]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5646,  1.0000,  0.9542,  ..., -0.6849,  0.6519, -0.9751],\n",
            "        [ 0.2065,  1.0000,  0.9135,  ..., -0.5680,  0.4475, -0.9725],\n",
            "        [ 0.8787,  1.0000,  0.7829,  ..., -0.7461,  0.8787, -0.9826],\n",
            "        ...,\n",
            "        [ 0.8308,  1.0000,  0.6105,  ..., -0.6263,  0.8955, -0.9527],\n",
            "        [ 0.4211,  1.0000,  0.7465,  ..., -0.6984,  0.6532, -0.9689],\n",
            "        [ 0.6040,  1.0000,  0.8976,  ..., -0.8387,  0.7984, -0.9848]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3129,  1.0000,  0.9320,  ..., -0.6456,  0.2264, -0.8953],\n",
            "        [ 0.6887,  1.0000,  0.7309,  ..., -0.7816,  0.7523, -0.9884],\n",
            "        [ 0.4629,  1.0000,  0.9098,  ..., -0.8262,  0.4133, -0.9825],\n",
            "        ...,\n",
            "        [ 0.2144,  1.0000,  0.9465,  ..., -0.8987,  0.4717, -0.9656],\n",
            "        [ 0.5475,  1.0000,  0.9033,  ..., -0.8118,  0.8922, -0.9761],\n",
            "        [ 0.2756,  1.0000,  0.8767,  ..., -0.8217,  0.4274, -0.9751]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7501,  1.0000,  0.9386,  ..., -0.7899,  0.4825, -0.9816],\n",
            "        [ 0.5760,  1.0000,  0.6707,  ..., -0.7958,  0.8547, -0.9596],\n",
            "        [ 0.4896,  1.0000,  0.9430,  ..., -0.8487,  0.4355, -0.9561],\n",
            "        ...,\n",
            "        [ 0.6447,  1.0000,  0.9393,  ..., -0.8449,  0.6263, -0.9714],\n",
            "        [ 0.7845,  1.0000,  0.8320,  ..., -0.7592,  0.8230, -0.9778],\n",
            "        [ 0.5145,  1.0000,  0.9392,  ..., -0.8422,  0.6200, -0.9707]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5603,  1.0000,  0.9522,  ..., -0.7662,  0.3845, -0.9504],\n",
            "        [ 0.4434,  1.0000,  0.9605,  ..., -0.4308,  0.2723, -0.9378],\n",
            "        [ 0.5386,  1.0000,  0.9577,  ..., -0.8718,  0.5638, -0.9846],\n",
            "        ...,\n",
            "        [ 0.4177,  1.0000,  0.8995,  ..., -0.8864,  0.7048, -0.9854],\n",
            "        [ 0.3899,  1.0000,  0.9601,  ..., -0.7882,  0.1344, -0.9702],\n",
            "        [ 0.1878,  1.0000,  0.9141,  ..., -0.6247,  0.0211, -0.9270]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6490,  1.0000,  0.9642,  ..., -0.6985,  0.4780, -0.9681],\n",
            "        [ 0.5630,  1.0000,  0.8279,  ..., -0.8634,  0.8075, -0.9841],\n",
            "        [ 0.2989,  1.0000,  0.9378,  ..., -0.5768, -0.1819, -0.9051],\n",
            "        ...,\n",
            "        [ 0.7808,  1.0000,  0.6967,  ..., -0.6591,  0.7464, -0.9635],\n",
            "        [ 0.3772,  1.0000,  0.9372,  ..., -0.8303,  0.6211, -0.9700],\n",
            "        [ 0.6063,  1.0000,  0.8561,  ..., -0.7704,  0.8002, -0.9924]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5252,  1.0000,  0.9503,  ..., -0.1341,  0.2586, -0.9696],\n",
            "        [ 0.5914,  1.0000,  0.5319,  ..., -0.5870,  0.7127, -0.9480],\n",
            "        [ 0.6957,  1.0000,  0.9546,  ..., -0.7139,  0.6489, -0.9807],\n",
            "        ...,\n",
            "        [ 0.6653,  1.0000,  0.9173,  ..., -0.7687,  0.4538, -0.9742],\n",
            "        [ 0.5255,  1.0000,  0.9497,  ..., -0.5753,  0.3578, -0.9758],\n",
            "        [ 0.2334,  1.0000,  0.9315,  ..., -0.7649,  0.5880, -0.9734]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7084,  1.0000,  0.7782,  ..., -0.8705,  0.7245, -0.9918],\n",
            "        [ 0.7162,  1.0000,  0.5461,  ..., -0.6987,  0.6437, -0.9691],\n",
            "        [ 0.6482,  1.0000,  0.3109,  ..., -0.7014,  0.6668, -0.9470],\n",
            "        ...,\n",
            "        [ 0.5300,  1.0000,  0.0862,  ..., -0.7333,  0.6872, -0.9011],\n",
            "        [ 0.6911,  1.0000,  0.5975,  ..., -0.4527,  0.8605, -0.9587],\n",
            "        [ 0.6918,  1.0000,  0.4773,  ..., -0.8396,  0.7104, -0.9630]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2645,  1.0000,  0.9341,  ..., -0.7733,  0.5886, -0.9444],\n",
            "        [ 0.4393,  1.0000,  0.6572,  ..., -0.8861,  0.7660, -0.9729],\n",
            "        [ 0.1842,  1.0000,  0.8091,  ..., -0.7549,  0.3797, -0.9259],\n",
            "        ...,\n",
            "        [ 0.2925,  1.0000,  0.9453,  ..., -0.7125,  0.6562, -0.9686],\n",
            "        [ 0.5228,  1.0000,  0.8748,  ..., -0.8504,  0.5479, -0.9855],\n",
            "        [ 0.7051,  1.0000,  0.3200,  ..., -0.4967,  0.6231, -0.9363]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4946,  1.0000,  0.9512,  ..., -0.7344,  0.6074, -0.9725],\n",
            "        [ 0.5164,  1.0000,  0.5501,  ..., -0.7134,  0.6751, -0.9745],\n",
            "        [ 0.4818,  1.0000,  0.9131,  ..., -0.6952,  0.7769, -0.9930],\n",
            "        ...,\n",
            "        [ 0.6636,  1.0000,  0.7604,  ..., -0.8478,  0.8840, -0.9877],\n",
            "        [ 0.7901,  1.0000,  0.6127,  ..., -0.5420,  0.8313, -0.9762],\n",
            "        [ 0.7569,  1.0000,  0.9060,  ..., -0.1890,  0.9060, -0.9944]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5360,  1.0000,  0.9375,  ..., -0.7694,  0.7950, -0.9851],\n",
            "        [ 0.5893,  1.0000,  0.7459,  ..., -0.6493,  0.8287, -0.9935],\n",
            "        [ 0.5658,  1.0000,  0.8812,  ..., -0.8391,  0.7826, -0.9936],\n",
            "        ...,\n",
            "        [ 0.6866,  1.0000,  0.9167,  ..., -0.8472,  0.6880, -0.9872],\n",
            "        [ 0.4499,  1.0000,  0.9226,  ..., -0.8260,  0.4488, -0.9660],\n",
            "        [ 0.5496,  1.0000,  0.9489,  ..., -0.8528,  0.6459, -0.9893]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5542,  1.0000,  0.6584,  ..., -0.7777,  0.7650, -0.9825],\n",
            "        [ 0.6721,  1.0000,  0.5948,  ..., -0.7863,  0.6241, -0.9746],\n",
            "        [ 0.4580,  1.0000,  0.2546,  ..., -0.8445,  0.5898, -0.9092],\n",
            "        ...,\n",
            "        [ 0.5810,  1.0000,  0.6658,  ..., -0.8217,  0.7515, -0.9552],\n",
            "        [ 0.4604,  1.0000,  0.8449,  ..., -0.8652,  0.8565, -0.9922],\n",
            "        [ 0.5743,  1.0000,  0.6875,  ..., -0.7597,  0.7892, -0.9863]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4131,  1.0000,  0.9415,  ..., -0.7765,  0.6094, -0.9757],\n",
            "        [ 0.1696,  1.0000,  0.6586,  ..., -0.8656,  0.5662, -0.9680],\n",
            "        [ 0.5202,  1.0000,  0.6137,  ..., -0.8830,  0.5716, -0.9200],\n",
            "        ...,\n",
            "        [ 0.4387,  1.0000,  0.5783,  ..., -0.9148,  0.6601, -0.9793],\n",
            "        [ 0.7152,  1.0000,  0.9159,  ..., -0.5605,  0.8237, -0.9798],\n",
            "        [ 0.6376,  1.0000,  0.8990,  ..., -0.8207,  0.7219, -0.9947]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6656,  1.0000,  0.8258,  ..., -0.7909,  0.7213, -0.9883],\n",
            "        [ 0.2982,  1.0000,  0.6809,  ..., -0.8918,  0.8363, -0.9818],\n",
            "        [ 0.4550,  1.0000,  0.6227,  ..., -0.8311,  0.5944, -0.9783],\n",
            "        ...,\n",
            "        [ 0.4784,  1.0000,  0.6852,  ..., -0.9217,  0.6520, -0.9767],\n",
            "        [ 0.5657,  1.0000,  0.8925,  ..., -0.8720,  0.8283, -0.9931],\n",
            "        [ 0.4571,  1.0000,  0.8854,  ..., -0.7879,  0.6323, -0.9698]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4254,  1.0000,  0.8032,  ..., -0.8681,  0.6911, -0.9915],\n",
            "        [ 0.6386,  1.0000,  0.9399,  ..., -0.8039,  0.8126, -0.9939],\n",
            "        [ 0.6025,  1.0000,  0.6459,  ..., -0.8365,  0.7028, -0.9802],\n",
            "        ...,\n",
            "        [ 0.2335,  1.0000,  0.8037,  ..., -0.8649,  0.6964, -0.9803],\n",
            "        [ 0.4185,  1.0000,  0.8902,  ..., -0.9011,  0.6286, -0.9883],\n",
            "        [ 0.5847,  1.0000,  0.7825,  ..., -0.8909,  0.7338, -0.9935]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5033,  1.0000,  0.9522,  ..., -0.8293,  0.5971, -0.9892],\n",
            "        [ 0.4301,  1.0000,  0.9387,  ..., -0.7717,  0.3546, -0.9790],\n",
            "        [ 0.4816,  1.0000,  0.8081,  ..., -0.8605,  0.7312, -0.9828],\n",
            "        ...,\n",
            "        [ 0.6589,  1.0000,  0.9491,  ..., -0.7137,  0.6433, -0.9834],\n",
            "        [ 0.3257,  1.0000,  0.9559,  ..., -0.6956,  0.0622, -0.9543],\n",
            "        [ 0.0510,  1.0000,  0.8389,  ..., -0.8578,  0.6660, -0.9922]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5730,  1.0000,  0.9267,  ..., -0.7533,  0.5283, -0.9711],\n",
            "        [ 0.3344,  1.0000,  0.9047,  ..., -0.7811,  0.5420, -0.9656],\n",
            "        [ 0.4898,  1.0000,  0.9577,  ..., -0.8016,  0.8474, -0.9908],\n",
            "        ...,\n",
            "        [ 0.5198,  1.0000,  0.6222,  ..., -0.8815,  0.5726, -0.9708],\n",
            "        [ 0.3823,  1.0000,  0.9338,  ..., -0.8875,  0.4132, -0.9800],\n",
            "        [ 0.3800,  1.0000,  0.4306,  ..., -0.8138,  0.7030, -0.9765]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5064,  1.0000,  0.8551,  ..., -0.8202,  0.5375, -0.9862],\n",
            "        [ 0.4785,  1.0000,  0.9353,  ..., -0.8972,  0.4861, -0.9855],\n",
            "        [ 0.1849,  1.0000,  0.6735,  ..., -0.8061,  0.7086, -0.9888],\n",
            "        ...,\n",
            "        [ 0.4963,  1.0000,  0.8803,  ..., -0.8345,  0.7541, -0.9906],\n",
            "        [ 0.3046,  1.0000,  0.7727,  ..., -0.9051,  0.5442, -0.9470],\n",
            "        [ 0.3697,  1.0000,  0.8888,  ..., -0.8758,  0.7289, -0.9870]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3540,  1.0000,  0.9235,  ..., -0.8498,  0.4475, -0.9710],\n",
            "        [ 0.3580,  1.0000,  0.8866,  ..., -0.9146,  0.3838, -0.9750],\n",
            "        [ 0.4325,  1.0000,  0.9514,  ..., -0.7056,  0.3856, -0.9671],\n",
            "        ...,\n",
            "        [ 0.2597,  1.0000,  0.3810,  ..., -0.9073,  0.6512, -0.9152],\n",
            "        [ 0.4809,  1.0000,  0.7511,  ..., -0.8048,  0.6564, -0.9897],\n",
            "        [-0.0261,  1.0000,  0.9362,  ..., -0.6955, -0.1201, -0.9016]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2559,  1.0000,  0.9416,  ..., -0.8419,  0.7522, -0.9773],\n",
            "        [ 0.3544,  1.0000,  0.6079,  ..., -0.9050,  0.6714, -0.9644],\n",
            "        [ 0.3390,  1.0000,  0.8140,  ..., -0.8823,  0.6951, -0.9876],\n",
            "        ...,\n",
            "        [ 0.6397,  1.0000,  0.9270,  ..., -0.7901,  0.3787, -0.9619],\n",
            "        [ 0.5873,  1.0000,  0.9272,  ..., -0.6494,  0.1752, -0.9848],\n",
            "        [ 0.0588,  1.0000,  0.9087,  ..., -0.8589,  0.3518, -0.9857]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5795,  1.0000,  0.9369,  ..., -0.8774,  0.6221, -0.9871],\n",
            "        [ 0.3273,  1.0000,  0.9633,  ..., -0.8295,  0.4797, -0.9633],\n",
            "        [ 0.5903,  1.0000,  0.4249,  ..., -0.8325,  0.6861, -0.9283],\n",
            "        ...,\n",
            "        [ 0.0466,  1.0000,  0.9372,  ..., -0.7458,  0.5132, -0.9647],\n",
            "        [ 0.3659,  1.0000,  0.7103,  ..., -0.8729,  0.6429, -0.9615],\n",
            "        [ 0.3498,  1.0000,  0.9222,  ..., -0.8516,  0.5766, -0.9682]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4275,  1.0000,  0.5738,  ..., -0.9514,  0.7193, -0.9570],\n",
            "        [ 0.2301,  1.0000,  0.8843,  ..., -0.8903,  0.6286, -0.9616],\n",
            "        [ 0.1005,  1.0000,  0.9511,  ..., -0.8849,  0.5322, -0.9426],\n",
            "        ...,\n",
            "        [ 0.1880,  1.0000,  0.9239,  ..., -0.8444,  0.7295, -0.9855],\n",
            "        [ 0.0469,  1.0000,  0.9532,  ..., -0.7202,  0.1303, -0.9036],\n",
            "        [-0.3327,  1.0000,  0.9469,  ..., -0.5999, -0.0696, -0.8511]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0425,  1.0000,  0.5639,  ..., -0.9035,  0.4786, -0.9507],\n",
            "        [ 0.2689,  1.0000,  0.8533,  ..., -0.9307,  0.4043, -0.9735],\n",
            "        [ 0.1794,  1.0000,  0.7939,  ..., -0.9141,  0.5908, -0.9758],\n",
            "        ...,\n",
            "        [ 0.0561,  1.0000,  0.8125,  ..., -0.8477,  0.8017, -0.9677],\n",
            "        [ 0.2621,  1.0000,  0.9326,  ..., -0.6698,  0.7702, -0.9751],\n",
            "        [ 0.3982,  1.0000,  0.9546,  ..., -0.8167,  0.6759, -0.9440]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2109,  1.0000,  0.9246,  ..., -0.8528,  0.4636, -0.9750],\n",
            "        [ 0.4581,  1.0000,  0.8439,  ..., -0.8721,  0.5893, -0.9765],\n",
            "        [ 0.3181,  1.0000,  0.8957,  ..., -0.8906,  0.7056, -0.9738],\n",
            "        ...,\n",
            "        [ 0.1515,  1.0000,  0.9189,  ..., -0.7303,  0.0040, -0.9713],\n",
            "        [-0.2919,  1.0000,  0.1647,  ..., -0.8753,  0.4127, -0.9512],\n",
            "        [ 0.3874,  1.0000,  0.8699,  ..., -0.7078,  0.3473, -0.9805]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1879,  1.0000,  0.9176,  ..., -0.8802,  0.4248, -0.9618],\n",
            "        [-0.0454,  1.0000,  0.9173,  ..., -0.8763,  0.4577, -0.9571],\n",
            "        [ 0.2668,  1.0000,  0.8113,  ..., -0.8566,  0.7081, -0.9680],\n",
            "        ...,\n",
            "        [-0.4140,  1.0000,  0.4120,  ..., -0.8988,  0.5870, -0.8977],\n",
            "        [ 0.2074,  1.0000,  0.5606,  ..., -0.8755,  0.5185, -0.9317],\n",
            "        [-0.0967,  1.0000,  0.3456,  ..., -0.8604,  0.2200, -0.6997]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3058,  1.0000,  0.9503,  ..., -0.6629,  0.5557, -0.9764],\n",
            "        [ 0.2688,  1.0000,  0.8486,  ..., -0.8615,  0.4577, -0.9462],\n",
            "        [ 0.2704,  1.0000,  0.7080,  ..., -0.7795,  0.6355, -0.9574],\n",
            "        ...,\n",
            "        [ 0.0509,  1.0000,  0.9539,  ..., -0.7384,  0.6736, -0.9689],\n",
            "        [ 0.2301,  1.0000,  0.7706,  ..., -0.8828,  0.5816, -0.9757],\n",
            "        [ 0.3589,  1.0000,  0.9278,  ..., -0.7933,  0.5953, -0.9626]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0767,  1.0000,  0.6039,  ..., -0.8593,  0.7398, -0.9685],\n",
            "        [ 0.1631,  1.0000,  0.3759,  ..., -0.8013,  0.7324, -0.9378],\n",
            "        [ 0.0106,  1.0000,  0.6691,  ..., -0.9000,  0.8900, -0.9586],\n",
            "        ...,\n",
            "        [-0.0321,  1.0000,  0.8636,  ..., -0.8688,  0.7473, -0.9793],\n",
            "        [-0.2133,  1.0000,  0.1375,  ..., -0.8438,  0.1657, -0.7841],\n",
            "        [ 0.4603,  1.0000,  0.3936,  ..., -0.8520,  0.7943, -0.9619]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3179,  1.0000,  0.9494,  ..., -0.7963,  0.6079, -0.9863],\n",
            "        [ 0.4573,  1.0000,  0.8890,  ..., -0.7717,  0.7935, -0.9883],\n",
            "        [-0.1983,  1.0000,  0.2745,  ..., -0.8987,  0.7338, -0.8966],\n",
            "        ...,\n",
            "        [ 0.3102,  1.0000,  0.8849,  ..., -0.8415,  0.6281, -0.9918],\n",
            "        [ 0.3281,  1.0000,  0.9544,  ..., -0.5683,  0.6254, -0.9302],\n",
            "        [-0.0332,  1.0000,  0.6204,  ..., -0.8706,  0.7038, -0.9088]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2307,  1.0000,  0.5655,  ..., -0.8142,  0.6465, -0.9630],\n",
            "        [ 0.0395,  1.0000,  0.5316,  ..., -0.8918,  0.6223, -0.9604],\n",
            "        [ 0.3410,  1.0000,  0.9141,  ..., -0.8180,  0.6779, -0.9763],\n",
            "        ...,\n",
            "        [ 0.4200,  1.0000,  0.8486,  ..., -0.8768,  0.3380, -0.9496],\n",
            "        [ 0.1452,  1.0000,  0.9407,  ..., -0.8193,  0.6475, -0.9631],\n",
            "        [ 0.5436,  1.0000,  0.9287,  ..., -0.7937,  0.6641, -0.9891]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1209,  1.0000,  0.1478,  ..., -0.8898,  0.7745, -0.9067],\n",
            "        [ 0.2528,  1.0000,  0.5780,  ..., -0.7644,  0.6288, -0.9399],\n",
            "        [-0.1843,  1.0000,  0.8904,  ..., -0.7496, -0.0742, -0.8685],\n",
            "        ...,\n",
            "        [ 0.1884,  1.0000,  0.8909,  ..., -0.8928,  0.8180, -0.9803],\n",
            "        [ 0.1406,  1.0000,  0.6786,  ..., -0.7703,  0.6891, -0.9521],\n",
            "        [ 0.3320,  1.0000,  0.9467,  ..., -0.8062,  0.6141, -0.9738]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2686,  1.0000,  0.9249,  ..., -0.8465,  0.6333, -0.9757],\n",
            "        [ 0.3308,  1.0000,  0.8941,  ..., -0.9040,  0.8129, -0.9714],\n",
            "        [ 0.0757,  1.0000,  0.5081,  ..., -0.9109,  0.6175, -0.9037],\n",
            "        ...,\n",
            "        [ 0.4218,  1.0000,  0.9464,  ..., -0.8020,  0.5833, -0.9736],\n",
            "        [ 0.3528,  1.0000,  0.6668,  ..., -0.7840,  0.7004, -0.9357],\n",
            "        [ 0.1469,  1.0000,  0.1279,  ..., -0.8698,  0.6407, -0.8801]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0678,  1.0000,  0.9504,  ..., -0.7360, -0.1144, -0.8756],\n",
            "        [ 0.3127,  1.0000,  0.8633,  ..., -0.8902,  0.4823, -0.9868],\n",
            "        [ 0.0733,  1.0000,  0.9584,  ..., -0.8293,  0.3725, -0.9523],\n",
            "        ...,\n",
            "        [ 0.0256,  1.0000,  0.9266,  ..., -0.8312,  0.3742, -0.8628],\n",
            "        [ 0.1649,  1.0000,  0.9404,  ..., -0.8009,  0.7785, -0.9799],\n",
            "        [-0.2129,  1.0000,  0.9608,  ..., -0.4984, -0.4346, -0.7249]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3131,  1.0000,  0.8743,  ..., -0.8417,  0.8447, -0.9838],\n",
            "        [ 0.0214,  1.0000, -0.3359,  ..., -0.8936,  0.4858, -0.6383],\n",
            "        [-0.0357,  1.0000,  0.5321,  ..., -0.8810,  0.6858, -0.9447],\n",
            "        ...,\n",
            "        [-0.1776,  1.0000,  0.9392,  ..., -0.8406,  0.4820, -0.9113],\n",
            "        [ 0.2337,  1.0000,  0.8928,  ..., -0.8649,  0.7946, -0.9657],\n",
            "        [ 0.1448,  1.0000,  0.9554,  ..., -0.6260,  0.1492, -0.8856]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2460,  1.0000,  0.8531,  ..., -0.8727,  0.7151, -0.9804],\n",
            "        [ 0.2642,  1.0000,  0.8541,  ..., -0.7402,  0.7223, -0.9862],\n",
            "        [ 0.2490,  1.0000,  0.3455,  ..., -0.8292,  0.6739, -0.8826],\n",
            "        ...,\n",
            "        [-0.1947,  1.0000,  0.9663,  ..., -0.6995, -0.0461, -0.8513],\n",
            "        [ 0.0578,  1.0000,  0.9708,  ..., -0.7228,  0.4722, -0.9423],\n",
            "        [ 0.4087,  1.0000,  0.9127,  ..., -0.8033,  0.6264, -0.9502]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0143,  1.0000,  0.9182,  ..., -0.7066,  0.8039, -0.9554],\n",
            "        [ 0.4634,  1.0000,  0.8873,  ..., -0.7368,  0.6901, -0.9690],\n",
            "        [ 0.2027,  1.0000,  0.6871,  ..., -0.8299,  0.4826, -0.9651],\n",
            "        ...,\n",
            "        [ 0.2183,  1.0000,  0.6068,  ..., -0.8921,  0.7630, -0.9512],\n",
            "        [ 0.0818,  1.0000,  0.7876,  ..., -0.8629,  0.8531, -0.9781],\n",
            "        [-0.3682,  1.0000,  0.9024,  ..., -0.8228, -0.0383, -0.8245]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0399,  1.0000,  0.3816,  ..., -0.8499,  0.8109, -0.9520],\n",
            "        [ 0.2835,  1.0000,  0.7722,  ..., -0.8610,  0.6180, -0.9673],\n",
            "        [-0.1202,  1.0000,  0.2900,  ..., -0.9111,  0.6655, -0.8774],\n",
            "        ...,\n",
            "        [-0.3131,  1.0000,  0.9303,  ..., -0.8069,  0.1604, -0.9374],\n",
            "        [ 0.3346,  1.0000,  0.9433,  ..., -0.8785,  0.4776, -0.9255],\n",
            "        [ 0.1101,  1.0000,  0.9207,  ..., -0.9000,  0.7002, -0.9682]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0824,  1.0000,  0.9570,  ..., -0.7089, -0.0621, -0.9200],\n",
            "        [-0.2233,  1.0000,  0.9462,  ..., -0.8199,  0.2627, -0.9206],\n",
            "        [ 0.3905,  1.0000,  0.4553,  ..., -0.8901,  0.7464, -0.9269],\n",
            "        ...,\n",
            "        [-0.4723,  1.0000,  0.9484,  ..., -0.6897, -0.0379, -0.8538],\n",
            "        [ 0.3638,  1.0000,  0.6126,  ..., -0.9067,  0.6158, -0.9775],\n",
            "        [-0.4364,  1.0000,  0.8716,  ..., -0.8011, -0.3260, -0.7625]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1522,  1.0000, -0.1906,  ..., -0.8578,  0.4193, -0.7120],\n",
            "        [ 0.0817,  1.0000,  0.8936,  ..., -0.8590,  0.3464, -0.9062],\n",
            "        [-0.0469,  1.0000,  0.2848,  ..., -0.8760,  0.6111, -0.8592],\n",
            "        ...,\n",
            "        [ 0.2211,  1.0000,  0.9482,  ..., -0.6950,  0.6679, -0.9680],\n",
            "        [ 0.1101,  1.0000,  0.0338,  ..., -0.8337,  0.5499, -0.9665],\n",
            "        [ 0.1174,  1.0000,  0.7924,  ..., -0.8500,  0.7996, -0.9831]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2101,  1.0000,  0.6160,  ..., -0.8433,  0.7473, -0.9153],\n",
            "        [ 0.0986,  1.0000,  0.7580,  ..., -0.7656,  0.8227, -0.9702],\n",
            "        [-0.1327,  1.0000, -0.0394,  ..., -0.8562,  0.3788, -0.7983],\n",
            "        ...,\n",
            "        [-0.1359,  1.0000,  0.8990,  ..., -0.8332,  0.6247, -0.9235],\n",
            "        [ 0.2891,  1.0000,  0.9069,  ..., -0.8215,  0.6720, -0.9699],\n",
            "        [ 0.1268,  1.0000,  0.3421,  ..., -0.7988,  0.7415, -0.9062]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0472,  1.0000, -0.5205,  ..., -0.7937,  0.5041, -0.8600],\n",
            "        [ 0.3256,  1.0000,  0.6122,  ..., -0.8997,  0.7490, -0.9801],\n",
            "        [ 0.0350,  0.9999,  0.5992,  ..., -0.8368,  0.5421, -0.9479],\n",
            "        ...,\n",
            "        [ 0.2359,  1.0000,  0.0103,  ..., -0.7875,  0.6973, -0.9214],\n",
            "        [ 0.0162,  1.0000,  0.9080,  ..., -0.8537,  0.2426, -0.8886],\n",
            "        [-0.1613,  1.0000, -0.0300,  ..., -0.8457,  0.4027, -0.7109]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1098,  1.0000,  0.2474,  ..., -0.8335,  0.7525, -0.9405],\n",
            "        [ 0.1937,  1.0000,  0.7333,  ..., -0.6844,  0.6295, -0.9659],\n",
            "        [ 0.1057,  1.0000,  0.0263,  ..., -0.8519,  0.5794, -0.8463],\n",
            "        ...,\n",
            "        [ 0.3872,  1.0000,  0.6804,  ..., -0.7693,  0.8269, -0.9714],\n",
            "        [ 0.2006,  1.0000,  0.9146,  ..., -0.8758,  0.5940, -0.9593],\n",
            "        [-0.0148,  1.0000,  0.1471,  ..., -0.8234,  0.6308, -0.8072]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2884,  1.0000,  0.3175,  ..., -0.8703,  0.8089, -0.9207],\n",
            "        [ 0.1558,  1.0000,  0.8553,  ..., -0.7804,  0.6755, -0.9839],\n",
            "        [-0.2364,  0.9998, -0.2850,  ..., -0.8283,  0.6071, -0.8902],\n",
            "        ...,\n",
            "        [ 0.0519,  1.0000,  0.8915,  ..., -0.3275,  0.2739, -0.9660],\n",
            "        [ 0.2050,  1.0000,  0.0387,  ..., -0.8817,  0.5385, -0.9019],\n",
            "        [ 0.1365,  1.0000,  0.8306,  ..., -0.5571,  0.3483, -0.9593]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4622,  1.0000,  0.1926,  ..., -0.8419,  0.8447, -0.9308],\n",
            "        [ 0.3647,  1.0000,  0.8477,  ..., -0.8484,  0.7660, -0.9643],\n",
            "        [ 0.0359,  1.0000,  0.4689,  ..., -0.8702,  0.7856, -0.9158],\n",
            "        ...,\n",
            "        [ 0.1246,  1.0000,  0.7921,  ..., -0.7079,  0.7494, -0.9852],\n",
            "        [ 0.4537,  1.0000,  0.6906,  ..., -0.7873,  0.8430, -0.9724],\n",
            "        [ 0.2346,  1.0000,  0.6228,  ..., -0.8627,  0.8769, -0.9668]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2874,  1.0000,  0.6691,  ..., -0.8762,  0.7262, -0.9706],\n",
            "        [ 0.0316,  1.0000,  0.9264,  ..., -0.6162,  0.1025, -0.9262],\n",
            "        [ 0.1506,  1.0000,  0.6287,  ..., -0.7602,  0.7237, -0.9715],\n",
            "        ...,\n",
            "        [ 0.3518,  1.0000,  0.8409,  ..., -0.9082,  0.8275, -0.9630],\n",
            "        [-0.0389,  1.0000,  0.0371,  ..., -0.7862,  0.7877, -0.9472],\n",
            "        [ 0.0515,  1.0000,  0.8814,  ..., -0.8206,  0.5784, -0.9609]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1592,  1.0000,  0.4528,  ..., -0.8135,  0.8371, -0.9456],\n",
            "        [ 0.2543,  1.0000,  0.9536,  ..., -0.6726,  0.5546, -0.9741],\n",
            "        [ 0.1783,  1.0000,  0.5531,  ..., -0.7908,  0.6971, -0.9679],\n",
            "        ...,\n",
            "        [ 0.3815,  1.0000,  0.9345,  ..., -0.6401,  0.4864, -0.9718],\n",
            "        [ 0.0530,  1.0000,  0.6283,  ..., -0.8041,  0.7671, -0.9561],\n",
            "        [ 0.3041,  1.0000,  0.9442,  ..., -0.7881,  0.8721, -0.9831]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1954,  1.0000,  0.9622,  ..., -0.6782,  0.1141, -0.9192],\n",
            "        [ 0.3453,  1.0000,  0.1559,  ..., -0.7264,  0.8188, -0.9581],\n",
            "        [ 0.2985,  1.0000,  0.5601,  ..., -0.7502,  0.7820, -0.9540],\n",
            "        ...,\n",
            "        [ 0.0756,  1.0000,  0.7340,  ..., -0.7953,  0.6516, -0.9313],\n",
            "        [ 0.1053,  1.0000,  0.8956,  ..., -0.8000,  0.4815, -0.9585],\n",
            "        [ 0.4484,  1.0000,  0.7315,  ..., -0.8344,  0.6893, -0.9586]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3362,  1.0000,  0.8877,  ..., -0.8312,  0.7079, -0.9745],\n",
            "        [-0.5641,  1.0000,  0.8772,  ..., -0.8013,  0.3404, -0.8885],\n",
            "        [-0.0195,  1.0000,  0.9304,  ..., -0.7390,  0.0667, -0.9114],\n",
            "        ...,\n",
            "        [-0.3653,  1.0000,  0.9339,  ..., -0.3605,  0.0401, -0.8411],\n",
            "        [-0.3998,  1.0000,  0.8787,  ..., -0.7927, -0.2070, -0.8576],\n",
            "        [ 0.2024,  1.0000,  0.8052,  ..., -0.6570,  0.8081, -0.9725]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3806,  1.0000,  0.7511,  ..., -0.7752,  0.7873, -0.9703],\n",
            "        [-0.1774,  1.0000,  0.9482,  ..., -0.7585,  0.0164, -0.8981],\n",
            "        [ 0.3895,  1.0000,  0.5693,  ..., -0.7061,  0.8420, -0.9643],\n",
            "        ...,\n",
            "        [-0.2291,  1.0000,  0.9368,  ..., -0.6971,  0.2563, -0.8880],\n",
            "        [-0.5668,  1.0000,  0.9253,  ..., -0.3713,  0.0876, -0.8042],\n",
            "        [ 0.2001,  1.0000,  0.7188,  ..., -0.8628,  0.7727, -0.9635]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3567,  1.0000,  0.6281,  ..., -0.7565,  0.8605, -0.9688],\n",
            "        [ 0.3079,  1.0000,  0.9008,  ..., -0.7610,  0.7130, -0.9834],\n",
            "        [ 0.5786,  1.0000,  0.7189,  ..., -0.7747,  0.8705, -0.9779],\n",
            "        ...,\n",
            "        [ 0.0132,  1.0000,  0.9240,  ..., -0.6794,  0.5545, -0.9787],\n",
            "        [-0.4113,  1.0000,  0.9022,  ..., -0.6818,  0.1188, -0.9325],\n",
            "        [ 0.3993,  1.0000,  0.7877,  ..., -0.7967,  0.8132, -0.9787]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2291,  1.0000,  0.3755,  ..., -0.8460,  0.8425, -0.9748],\n",
            "        [ 0.2981,  1.0000,  0.7560,  ..., -0.8897,  0.7328, -0.9634],\n",
            "        [ 0.3583,  1.0000,  0.8340,  ..., -0.7390,  0.8011, -0.9918],\n",
            "        ...,\n",
            "        [ 0.5332,  1.0000,  0.7437,  ..., -0.7238,  0.8356, -0.9803],\n",
            "        [ 0.0821,  1.0000,  0.9247,  ..., -0.7580,  0.5482, -0.9887],\n",
            "        [ 0.3427,  1.0000,  0.7227,  ..., -0.8031,  0.8004, -0.9728]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1288,  1.0000,  0.9203,  ..., -0.7657,  0.3226, -0.9674],\n",
            "        [ 0.4921,  1.0000,  0.8528,  ..., -0.7184,  0.6491, -0.9563],\n",
            "        [ 0.4519,  1.0000,  0.5549,  ..., -0.7193,  0.8751, -0.9861],\n",
            "        ...,\n",
            "        [ 0.3789,  1.0000,  0.7971,  ..., -0.7976,  0.8532, -0.9874],\n",
            "        [ 0.5554,  1.0000,  0.8472,  ..., -0.8064,  0.7895, -0.9878],\n",
            "        [-0.2985,  1.0000,  0.9546,  ..., -0.5715,  0.0580, -0.8306]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0890,  1.0000,  0.9277,  ..., -0.8262,  0.6220, -0.9819],\n",
            "        [-0.1276,  1.0000,  0.9528,  ..., -0.6292,  0.3319, -0.9170],\n",
            "        [ 0.2538,  1.0000,  0.5826,  ..., -0.8362,  0.7929, -0.9592],\n",
            "        ...,\n",
            "        [ 0.3668,  1.0000,  0.9123,  ..., -0.8165,  0.6600, -0.9895],\n",
            "        [ 0.0838,  1.0000,  0.7714,  ..., -0.7421,  0.8265, -0.9902],\n",
            "        [ 0.2493,  1.0000,  0.6092,  ..., -0.8310,  0.8204, -0.9729]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2768,  1.0000,  0.7586,  ..., -0.7955,  0.8881, -0.9724],\n",
            "        [ 0.0722,  1.0000,  0.9450,  ..., -0.7110,  0.1800, -0.9647],\n",
            "        [-0.1562,  1.0000,  0.9218,  ..., -0.8575,  0.1529, -0.9423],\n",
            "        ...,\n",
            "        [-0.0047,  1.0000,  0.8965,  ..., -0.5498,  0.5679, -0.9733],\n",
            "        [ 0.3221,  1.0000,  0.9119,  ..., -0.8800,  0.6987, -0.9771],\n",
            "        [ 0.4040,  1.0000,  0.6090,  ..., -0.8311,  0.8439, -0.9694]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1051,  1.0000,  0.9404,  ..., -0.8269,  0.5914, -0.9825],\n",
            "        [ 0.2484,  1.0000,  0.8267,  ..., -0.6058,  0.8423, -0.9736],\n",
            "        [-0.0713,  1.0000,  0.9325,  ..., -0.5819, -0.1660, -0.9158],\n",
            "        ...,\n",
            "        [ 0.2655,  1.0000,  0.9394,  ..., -0.8398,  0.5832, -0.9854],\n",
            "        [ 0.0833,  1.0000,  0.6041,  ..., -0.8064,  0.6309, -0.9619],\n",
            "        [ 0.3773,  1.0000,  0.8987,  ..., -0.7080,  0.6145, -0.9792]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3613,  1.0000,  0.9459,  ..., -0.7004, -0.1677, -0.9137],\n",
            "        [ 0.4398,  1.0000,  0.8489,  ..., -0.7838,  0.6259, -0.9892],\n",
            "        [ 0.0578,  0.9999,  0.9325,  ..., -0.5047,  0.0270, -0.9118],\n",
            "        ...,\n",
            "        [ 0.2333,  1.0000,  0.7099,  ..., -0.8757,  0.7648, -0.9833],\n",
            "        [ 0.5769,  1.0000,  0.5930,  ..., -0.8497,  0.9018, -0.9768],\n",
            "        [-0.2778,  1.0000,  0.8799,  ..., -0.7956,  0.1071, -0.8913]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 5.3400e-01,  1.0000e+00,  8.8502e-01,  ..., -8.6697e-01,\n",
            "          8.1389e-01, -9.8642e-01],\n",
            "        [ 5.7318e-01,  1.0000e+00,  5.1481e-01,  ..., -7.7514e-01,\n",
            "          8.1017e-01, -9.7828e-01],\n",
            "        [-1.7416e-01,  1.0000e+00,  9.3082e-01,  ..., -8.7659e-01,\n",
            "          4.1988e-01, -9.6722e-01],\n",
            "        ...,\n",
            "        [ 4.1518e-01,  1.0000e+00,  8.0052e-01,  ..., -8.1377e-01,\n",
            "          7.8664e-01, -9.8725e-01],\n",
            "        [ 4.4983e-02,  1.0000e+00,  9.0661e-01,  ..., -8.6743e-01,\n",
            "          3.4517e-01, -9.5395e-01],\n",
            "        [-1.6810e-01,  1.0000e+00,  9.3510e-01,  ..., -6.9109e-01,\n",
            "         -6.7729e-04, -9.4675e-01]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0415,  1.0000,  0.8322,  ..., -0.8502,  0.7116, -0.9781],\n",
            "        [ 0.4066,  1.0000,  0.7350,  ..., -0.8497,  0.6413, -0.9851],\n",
            "        [ 0.1033,  1.0000,  0.8821,  ..., -0.8269,  0.4940, -0.9717],\n",
            "        ...,\n",
            "        [-0.0098,  1.0000,  0.9260,  ..., -0.6878,  0.3915, -0.9146],\n",
            "        [ 0.1754,  1.0000,  0.9316,  ..., -0.5243, -0.0348, -0.9083],\n",
            "        [ 0.1672,  1.0000,  0.7053,  ..., -0.8579,  0.7386, -0.9811]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2253,  1.0000,  0.7729,  ..., -0.9128,  0.8206, -0.9836],\n",
            "        [ 0.1485,  1.0000,  0.9224,  ..., -0.8661,  0.6242, -0.9537],\n",
            "        [ 0.5040,  1.0000,  0.4423,  ..., -0.8514,  0.7698, -0.9640],\n",
            "        ...,\n",
            "        [ 0.2279,  1.0000,  0.6106,  ..., -0.7948,  0.8415, -0.9659],\n",
            "        [ 0.1685,  1.0000,  0.8385,  ..., -0.7192,  0.3474, -0.9626],\n",
            "        [-0.1240,  1.0000,  0.9462,  ..., -0.8597,  0.3828, -0.9845]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4000,  1.0000,  0.9049,  ..., -0.8366,  0.2827, -0.9475],\n",
            "        [ 0.2860,  1.0000,  0.3113,  ..., -0.8278,  0.8171, -0.9712],\n",
            "        [ 0.0434,  1.0000,  0.9081,  ..., -0.6965,  0.1411, -0.9306],\n",
            "        ...,\n",
            "        [ 0.2492,  1.0000,  0.4255,  ..., -0.9404,  0.7729, -0.9840],\n",
            "        [-0.1005,  1.0000,  0.8664,  ..., -0.7767,  0.2205, -0.9494],\n",
            "        [ 0.2899,  1.0000,  0.8732,  ..., -0.8015,  0.6580, -0.9730]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4332,  1.0000,  0.7641,  ..., -0.7746,  0.8125, -0.9613],\n",
            "        [-0.0627,  1.0000,  0.8676,  ..., -0.7218,  0.3352, -0.9361],\n",
            "        [-0.2308,  1.0000,  0.8902,  ..., -0.7370, -0.3184, -0.8973],\n",
            "        ...,\n",
            "        [ 0.6514,  1.0000,  0.4732,  ..., -0.8166,  0.8237, -0.9919],\n",
            "        [-0.0346,  1.0000,  0.9209,  ..., -0.8394,  0.6057, -0.9638],\n",
            "        [ 0.4663,  1.0000,  0.3383,  ..., -0.8482,  0.8194, -0.9675]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2169,  1.0000,  0.4745,  ..., -0.8678,  0.7771, -0.9703],\n",
            "        [-0.4175,  0.9999,  0.9089,  ..., -0.3453, -0.1966, -0.7650],\n",
            "        [-0.0464,  1.0000,  0.9416,  ..., -0.1773,  0.2052, -0.8965],\n",
            "        ...,\n",
            "        [ 0.1585,  1.0000,  0.9310,  ..., -0.7460,  0.4399, -0.9748],\n",
            "        [ 0.2097,  1.0000,  0.7213,  ..., -0.8632,  0.8429, -0.9832],\n",
            "        [ 0.3594,  1.0000,  0.4447,  ..., -0.8690,  0.7360, -0.9799]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2808,  1.0000,  0.8097,  ..., -0.8764,  0.8254, -0.9872],\n",
            "        [ 0.5601,  1.0000,  0.5068,  ..., -0.8649,  0.8590, -0.9747],\n",
            "        [ 0.2539,  1.0000,  0.7873,  ..., -0.8590,  0.6760, -0.9884],\n",
            "        ...,\n",
            "        [ 0.1018,  1.0000,  0.7325,  ..., -0.9576,  0.7379, -0.9854],\n",
            "        [-0.2053,  1.0000,  0.8518,  ..., -0.6293, -0.0483, -0.9215],\n",
            "        [ 0.4436,  1.0000,  0.2174,  ..., -0.8677,  0.9220, -0.9855]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0983,  1.0000,  0.9246,  ..., -0.4031,  0.6432, -0.9810],\n",
            "        [ 0.0753,  1.0000,  0.8885,  ..., -0.8337,  0.1496, -0.9634],\n",
            "        [ 0.5888,  1.0000,  0.1535,  ..., -0.9394,  0.8773, -0.9617],\n",
            "        ...,\n",
            "        [ 0.5179,  1.0000,  0.0895,  ..., -0.8921,  0.7958, -0.9637],\n",
            "        [ 0.4449,  1.0000,  0.5427,  ..., -0.9085,  0.8570, -0.9735],\n",
            "        [ 0.4168,  1.0000,  0.0864,  ..., -0.9326,  0.7933, -0.9623]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2936,  1.0000,  0.2268,  ..., -0.8832,  0.8356, -0.9526],\n",
            "        [-0.0526,  1.0000,  0.8992,  ..., -0.6768,  0.4152, -0.9116],\n",
            "        [-0.1503,  1.0000,  0.9113,  ..., -0.8352,  0.2193, -0.9520],\n",
            "        ...,\n",
            "        [ 0.3337,  1.0000,  0.8833,  ..., -0.9258,  0.8404, -0.9871],\n",
            "        [ 0.5012,  1.0000,  0.2260,  ..., -0.8242,  0.8928, -0.9771],\n",
            "        [ 0.0500,  1.0000,  0.5172,  ..., -0.8724,  0.7968, -0.9831]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0531,  1.0000,  0.9407,  ..., -0.6198,  0.1388, -0.9645],\n",
            "        [ 0.4624,  1.0000, -0.1121,  ..., -0.9088,  0.8133, -0.9706],\n",
            "        [ 0.5114,  1.0000,  0.2780,  ..., -0.9076,  0.8093, -0.9709],\n",
            "        ...,\n",
            "        [-0.1799,  1.0000,  0.8570,  ..., -0.7954,  0.1854, -0.8336],\n",
            "        [ 0.5975,  1.0000,  0.5464,  ..., -0.8315,  0.6521, -0.9935],\n",
            "        [ 0.2761,  1.0000,  0.5898,  ..., -0.8507,  0.7860, -0.9837]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3339,  1.0000,  0.4638,  ..., -0.8324,  0.7804, -0.9489],\n",
            "        [-0.2589,  1.0000,  0.9021,  ..., -0.6810, -0.0040, -0.7982],\n",
            "        [-0.2242,  0.9999,  0.9065,  ..., -0.4765, -0.4331, -0.7470],\n",
            "        ...,\n",
            "        [-0.0785,  1.0000,  0.8325,  ..., -0.3948,  0.0177, -0.8207],\n",
            "        [-0.1197,  1.0000,  0.9220,  ..., -0.5125, -0.0896, -0.8670],\n",
            "        [ 0.3291,  1.0000,  0.7209,  ..., -0.8745,  0.7318, -0.9804]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1541,  1.0000,  0.8124,  ..., -0.8367,  0.7011, -0.9773],\n",
            "        [-0.1344,  1.0000,  0.8707,  ..., -0.3721,  0.0342, -0.8282],\n",
            "        [ 0.4295,  1.0000,  0.7773,  ..., -0.9036,  0.7093, -0.9842],\n",
            "        ...,\n",
            "        [ 0.5056,  1.0000,  0.0839,  ..., -0.9005,  0.8543, -0.9656],\n",
            "        [ 0.1720,  1.0000,  0.8845,  ..., -0.2724,  0.0868, -0.8653],\n",
            "        [-0.0043,  1.0000,  0.8208,  ..., -0.8904,  0.3981, -0.9702]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0681,  1.0000,  0.9290,  ..., -0.8162,  0.3700, -0.9167],\n",
            "        [ 0.2600,  1.0000,  0.8777,  ..., -0.7170,  0.4204, -0.9747],\n",
            "        [-0.2601,  0.9998,  0.8486,  ..., -0.6065, -0.2474, -0.6649],\n",
            "        ...,\n",
            "        [ 0.1332,  1.0000,  0.9038,  ..., -0.7422,  0.5380, -0.9673],\n",
            "        [-0.1131,  1.0000,  0.8429,  ..., -0.8824,  0.1100, -0.9613],\n",
            "        [ 0.4311,  1.0000,  0.6671,  ..., -0.8506,  0.6341, -0.9828]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4375,  1.0000,  0.5536,  ..., -0.7863,  0.8456, -0.9831],\n",
            "        [ 0.3710,  1.0000,  0.6168,  ..., -0.8812,  0.7364, -0.9423],\n",
            "        [ 0.2150,  1.0000, -0.1234,  ..., -0.8628,  0.8122, -0.9570],\n",
            "        ...,\n",
            "        [-0.1600,  0.9999,  0.9261,  ..., -0.6288,  0.0685, -0.7635],\n",
            "        [-0.1374,  1.0000,  0.9001,  ..., -0.6884,  0.0790, -0.8645],\n",
            "        [ 0.0257,  1.0000,  0.9221,  ..., -0.6760,  0.4687, -0.9389]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4324,  1.0000,  0.9418,  ...,  0.0183, -0.0191, -0.8556],\n",
            "        [ 0.2283,  1.0000,  0.8595,  ..., -0.8133,  0.8242, -0.9703],\n",
            "        [-0.1350,  0.9999,  0.9381,  ..., -0.3514, -0.1109, -0.7079],\n",
            "        ...,\n",
            "        [ 0.4805,  1.0000,  0.6841,  ..., -0.8898,  0.8489, -0.9903],\n",
            "        [ 0.0738,  1.0000,  0.7961,  ..., -0.7561,  0.8491, -0.9866],\n",
            "        [-0.3485,  0.9997,  0.8468,  ..., -0.6772, -0.1530, -0.7622]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2574,  1.0000,  0.4073,  ..., -0.9052,  0.8437, -0.9592],\n",
            "        [-0.0100,  1.0000,  0.9253,  ..., -0.8701,  0.7193, -0.9525],\n",
            "        [ 0.4063,  1.0000,  0.2446,  ..., -0.9320,  0.8252, -0.9808],\n",
            "        ...,\n",
            "        [ 0.0871,  1.0000,  0.7557,  ..., -0.8094,  0.7718, -0.9902],\n",
            "        [ 0.2811,  0.9999,  0.9317,  ..., -0.1309, -0.0193, -0.8268],\n",
            "        [ 0.2499,  1.0000,  0.2740,  ..., -0.9181,  0.7442, -0.9854]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1976,  0.9998,  0.8848,  ..., -0.2355, -0.1584, -0.7361],\n",
            "        [-0.2009,  1.0000,  0.8961,  ..., -0.7064,  0.1106, -0.8383],\n",
            "        [ 0.4216,  1.0000,  0.2888,  ..., -0.9065,  0.8986, -0.9762],\n",
            "        ...,\n",
            "        [ 0.5186,  1.0000,  0.3697,  ..., -0.8561,  0.8409, -0.9898],\n",
            "        [-0.4378,  1.0000,  0.8652,  ..., -0.7666, -0.1070, -0.9361],\n",
            "        [-0.0557,  1.0000,  0.8276,  ..., -0.7806,  0.0743, -0.9207]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0506,  1.0000,  0.5294,  ..., -0.9494,  0.5937, -0.9756],\n",
            "        [ 0.2736,  1.0000,  0.4992,  ..., -0.8683,  0.8429, -0.9823],\n",
            "        [-0.0186,  1.0000,  0.8102,  ..., -0.9211,  0.7290, -0.9802],\n",
            "        ...,\n",
            "        [ 0.2223,  1.0000,  0.5366,  ..., -0.8526,  0.8126, -0.9802],\n",
            "        [ 0.0953,  1.0000,  0.1555,  ..., -0.9195,  0.7787, -0.9799],\n",
            "        [ 0.0761,  1.0000,  0.5201,  ..., -0.8675,  0.6990, -0.9818]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2938,  1.0000,  0.1444, -0.9990,  0.9098, -0.1368,  0.9256,  0.5034,\n",
            "         -0.9998,  0.5470,  0.6870,  0.4154, -0.5600,  1.0000, -0.1696, -0.9630,\n",
            "          0.0564, -0.9995,  0.9409, -0.9465,  0.7900,  0.2124,  0.9143, -0.8514,\n",
            "         -0.4334, -0.3896, -0.2581,  0.9550, -0.7997,  0.9132, -0.9059, -0.7549,\n",
            "          0.9918,  0.9443,  0.7448, -0.9921, -0.9214, -0.9558, -0.9997, -0.9996,\n",
            "         -0.9486, -0.7878,  1.0000, -0.9499,  0.9990, -0.9983,  0.5043, -0.9472,\n",
            "          0.9505,  0.9409, -0.7730, -0.8919,  0.8910,  0.8979, -0.9045, -0.9998,\n",
            "         -0.6541,  0.9759, -0.9646, -0.4464,  0.8445, -0.8895, -0.6854,  0.7604,\n",
            "         -0.8279,  0.9369,  0.9487,  0.7725,  0.0061, -0.9994,  0.6257, -0.9920,\n",
            "          0.9202, -0.5871,  0.9509,  0.9388, -0.7664, -0.7797, -0.7464,  0.9989,\n",
            "          0.8892,  0.9173,  0.8738, -1.0000,  0.6579, -0.9633,  0.9943, -0.9984,\n",
            "         -0.9940,  0.2020,  0.9473,  0.6759, -0.3848, -0.6957, -0.6189, -0.9788,\n",
            "         -0.1821,  0.0948, -1.0000,  0.9043,  0.9222,  0.9611, -0.2856, -0.8993,\n",
            "         -1.0000, -0.4680, -0.0189, -0.9850, -1.0000, -0.9693, -0.9250, -0.8915,\n",
            "         -0.2888,  0.9962,  0.3477,  1.0000,  0.5991,  0.9859, -1.0000, -0.9918,\n",
            "          0.4846,  0.9824, -0.8835, -0.8666,  0.8815, -0.9980, -0.9979, -1.0000,\n",
            "          0.9279, -0.6367, -0.7878,  0.9839,  0.5107, -0.9902, -0.9616, -0.0398,\n",
            "         -0.9999,  0.4383, -0.5590, -0.9995,  0.9972,  0.9898,  0.1074, -0.8849,\n",
            "         -0.5466,  0.9930,  0.5388,  0.2874, -0.6356, -0.6015, -0.7202,  0.8260,\n",
            "          0.8651,  0.1935, -1.0000,  0.9425,  0.3824,  0.9986, -0.4020,  0.5748,\n",
            "         -0.6317, -1.0000,  0.9763,  0.8235,  0.2464,  0.8011, -0.8623,  0.9623,\n",
            "          0.0984,  0.8564,  0.9416,  0.8242,  0.7801,  0.9692,  0.8491, -0.9813,\n",
            "         -0.9371, -0.9510,  0.9498, -0.9957,  0.9983, -0.9369,  0.9941, -0.9941,\n",
            "         -0.9679,  0.9391,  0.1447, -1.0000,  0.9877,  0.9721,  0.8680, -0.9661,\n",
            "          0.9765, -0.7749,  0.7838, -0.2866, -0.9402,  0.8797, -0.7993,  0.9932,\n",
            "          0.7263, -0.9973,  0.9998,  0.9856,  0.8650, -0.9991,  0.5525,  0.9986,\n",
            "         -0.9990, -0.9828,  0.6544, -0.6203,  0.7956, -0.3525, -0.9545, -0.9445,\n",
            "          0.9942, -0.6408,  0.9887,  0.3544,  0.9173,  0.6740, -0.9587,  0.7178,\n",
            "          0.2443,  0.7746, -0.8004,  0.5810, -0.5611, -1.0000,  0.7109,  0.7062,\n",
            "          0.7337, -0.8697,  1.0000,  0.8833, -0.2968,  0.9959, -0.9995, -0.7041,\n",
            "         -0.6832, -0.9993,  0.8390, -0.5497,  1.0000, -0.9998,  0.9994,  0.2508,\n",
            "          0.9235,  0.8127, -0.9122,  0.8423,  0.9403,  0.8451,  0.4481,  0.9877,\n",
            "         -0.8593, -0.9999,  0.1660,  0.9209, -0.9977, -0.3333, -0.4545, -0.9746,\n",
            "          0.9983,  1.0000, -0.9248,  0.7582,  0.8958,  0.9733,  0.9779, -0.9994,\n",
            "          0.9943,  1.0000, -0.9944, -0.8850,  1.0000,  0.9216, -0.9713,  0.6318,\n",
            "          0.5598, -0.9993, -0.3664, -0.9305,  0.6512,  0.6711,  0.3976, -0.9985,\n",
            "         -0.9996, -0.9993,  0.9996, -0.7281, -0.0814,  0.6395,  0.6086, -0.9034,\n",
            "          0.9029,  0.9921, -0.9978,  1.0000,  0.9940, -0.9836, -0.9982, -0.7380,\n",
            "          0.4158,  0.8296,  0.9975,  0.0376, -0.9871,  0.8500,  0.9912,  0.6822,\n",
            "          0.9992, -0.6769,  0.8792,  0.1675,  0.8817, -0.9989, -0.9459, -0.8418,\n",
            "          0.9586,  0.9985,  0.9384, -0.9305,  0.9994,  0.6500, -1.0000,  1.0000,\n",
            "          0.9974, -0.9990,  0.4229, -0.4933,  0.9588,  0.5694,  0.8570, -0.9499,\n",
            "         -0.6559, -0.9992,  0.9856,  0.6893,  0.4417,  0.8831, -0.3111,  0.9295,\n",
            "          0.7388,  0.9113,  0.4594, -0.9857, -0.9992,  0.3824,  0.8443,  0.8891,\n",
            "         -0.5753,  0.9984,  0.8378,  1.0000, -0.6018,  0.9999, -0.9550,  0.9776,\n",
            "          0.2021,  0.8678,  0.7430, -0.9783, -1.0000,  0.3551, -0.9622,  0.9278,\n",
            "          0.3657, -0.9988, -0.9797,  0.6252, -0.8107,  0.0675, -0.6396, -0.8249,\n",
            "          1.0000,  0.9859,  0.7717, -0.9232, -0.8634,  0.9284,  0.9933,  0.8274,\n",
            "          0.9943, -0.9571,  0.9844, -0.6987,  0.7858, -0.8155,  0.0935,  0.5824,\n",
            "          0.5682,  0.9975,  0.9625,  0.9953, -0.9082,  0.8038, -0.9990,  1.0000,\n",
            "          0.6368,  0.9463,  0.6089, -0.1601,  0.8788, -0.8423,  0.9640, -0.9521,\n",
            "          0.9897, -0.4635,  0.8912,  0.4260,  0.9186, -0.8930,  0.3624,  0.8127,\n",
            "          0.8280, -0.9695, -0.9985,  0.9936, -0.9959, -0.7414, -0.9847, -0.5116,\n",
            "          0.9988, -0.9492, -0.4054, -0.9057, -0.9418, -0.8690, -0.7850, -0.9731,\n",
            "          0.3413, -0.9990,  0.9999, -0.9982,  0.9454, -0.7519, -0.7969,  0.8830,\n",
            "          0.4612, -0.9111, -0.5690,  0.1989, -0.9489,  0.9531, -0.4398,  0.3211,\n",
            "          0.3319, -0.7456,  0.8294,  0.9674,  0.8655,  0.9986, -0.8841, -0.9976,\n",
            "         -0.9488, -0.7425,  0.7616,  0.9994, -0.9985,  0.7326,  1.0000, -0.9993,\n",
            "         -0.9262, -0.6155, -0.9999,  0.9481, -0.9691, -0.9965, -0.5310, -0.9688,\n",
            "          0.9680,  0.9882,  0.9999, -0.3781, -0.9500, -0.9988, -0.8904,  0.9884,\n",
            "         -0.9994,  0.8823, -0.7709, -0.9992,  0.9978,  0.9046, -0.8119,  0.5256,\n",
            "          0.2542,  0.9994, -0.6587, -0.9975,  0.9177,  0.8721, -0.2158,  0.9034,\n",
            "         -0.7814, -0.8634, -0.9995,  0.5296,  1.0000, -0.5361, -0.9188,  0.9717,\n",
            "          0.8640,  0.7907,  1.0000, -0.9984,  0.9837,  1.0000, -0.4271,  0.9656,\n",
            "         -0.6125, -0.8739, -0.2020,  0.7499, -0.8211,  1.0000, -0.9642, -0.9704,\n",
            "         -1.0000,  0.6793, -0.9836,  0.9698,  0.9765, -0.6364,  0.7331,  0.6244,\n",
            "         -0.9994,  0.9859, -0.9290, -1.0000, -0.9999,  0.8077, -0.6730, -0.8752,\n",
            "          0.4402, -0.6580, -0.9595,  0.9999,  0.2190, -1.0000, -0.7922,  0.9824,\n",
            "          0.9995, -0.6368,  0.9557, -0.8539, -0.8330, -0.5491, -1.0000, -0.8094,\n",
            "          0.9908,  0.4304,  0.2927,  0.9999,  0.3122, -0.9632, -0.6494,  0.7436,\n",
            "          0.8101, -1.0000, -0.9339,  1.0000, -0.9486, -0.4449, -0.9896, -0.7602,\n",
            "          0.6123,  0.9632,  0.9986, -0.9982,  1.0000,  0.6976,  0.9706,  0.9912,\n",
            "         -0.0643, -0.9371, -0.9951, -0.1491,  0.8600, -0.3147,  0.1614, -0.9814,\n",
            "          0.9782,  0.4873, -0.9714,  0.4822, -0.7070, -0.7209, -0.7362,  0.9889,\n",
            "          0.8346, -0.7702,  0.9998, -0.5278, -0.9420,  0.7591,  0.6646,  0.6864,\n",
            "         -1.0000,  0.4798,  0.4052, -0.9973, -0.1634,  0.7847, -0.9684, -0.8367,\n",
            "          0.9624, -0.7497,  0.8070,  0.9998,  0.9694,  0.8201, -0.9976, -1.0000,\n",
            "         -0.7366,  0.3029, -0.9956,  0.8273, -0.8070,  0.9998,  0.1769,  0.7561,\n",
            "          0.9516,  1.0000, -0.1668,  0.8944, -0.4860,  0.4629, -0.9830,  0.9891,\n",
            "         -0.1581, -0.9973, -0.9038, -0.0493, -0.7419,  0.3589, -0.1313,  0.7150,\n",
            "          1.0000, -0.0057,  0.9248,  0.9366, -0.7857,  0.2947, -0.9692,  0.9949,\n",
            "         -1.0000,  0.9973,  0.7708, -0.7907,  0.9428, -0.2142, -0.6695, -0.8327,\n",
            "         -0.8238, -0.9091, -0.6524,  0.3234, -0.8647,  0.8337,  0.9909, -0.9710,\n",
            "         -1.0000,  0.2168,  0.1691,  0.8560, -0.4081, -0.8344,  0.9541, -0.2485,\n",
            "          0.9971, -0.8775, -0.8858, -0.9780, -0.9351, -0.1724,  0.9212,  0.9644,\n",
            "          0.8841,  0.5167, -0.5459, -0.7215, -0.5370, -0.7278,  0.6186,  0.4542,\n",
            "          0.9919,  0.8299,  0.9633,  0.9959,  0.6864, -0.7924,  0.8837, -0.8580,\n",
            "         -0.5605, -0.9996,  0.9993,  0.6551, -0.9358, -1.0000,  0.4457,  0.5732,\n",
            "          0.4589,  0.6063, -0.7848, -0.9729, -0.8149,  0.7915, -1.0000,  0.5506,\n",
            "         -0.0656, -0.7909,  0.7748, -0.9996, -0.7739,  0.8408, -0.9331,  0.4476,\n",
            "          0.9999, -0.9787, -0.9967, -0.9912, -0.6555,  0.9200,  0.8067, -0.9976,\n",
            "         -0.7460,  0.9694, -0.9998,  0.7573, -0.5025, -0.6162,  0.8967,  0.7767,\n",
            "          0.9856, -1.0000,  0.8933, -0.6017,  0.8992,  0.1100,  0.2719,  0.9129,\n",
            "          0.7879, -1.0000,  0.7664,  0.6503,  0.9748,  0.9746,  0.6597, -0.8640,\n",
            "         -0.6946, -0.8583,  0.9844,  0.9310, -0.9382,  0.8986,  0.9999, -0.3424,\n",
            "          0.9673, -0.2946, -0.9878, -0.9980, -0.9846, -0.8704,  0.8035, -0.9482]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluation... :   0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f4f054c4ceb4eb4b22900a1439698fa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1810,  1.0000,  0.9081,  ..., -0.5688, -0.0747, -0.8233],\n",
            "        [ 0.0405,  1.0000,  0.9216,  ..., -0.0388, -0.0352, -0.7774],\n",
            "        [ 0.2427,  1.0000, -0.2934,  ..., -0.9360,  0.8165, -0.9471],\n",
            "        ...,\n",
            "        [ 0.1082,  1.0000,  0.8187,  ..., -0.9121,  0.8074, -0.9882],\n",
            "        [ 0.3021,  1.0000,  0.4244,  ..., -0.8816,  0.8733, -0.9791],\n",
            "        [ 0.3027,  1.0000,  0.1232,  ..., -0.8689,  0.7891, -0.9691]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4909,  1.0000,  0.8657,  ..., -0.8036,  0.2647, -0.8630],\n",
            "        [-0.0673,  1.0000,  0.7566,  ..., -0.8656,  0.7524, -0.9801],\n",
            "        [-0.2791,  1.0000,  0.8716,  ..., -0.5000, -0.1698, -0.6432],\n",
            "        ...,\n",
            "        [ 0.0414,  1.0000,  0.7670,  ..., -0.8605,  0.7832, -0.9877],\n",
            "        [ 0.0370,  1.0000,  0.6296,  ..., -0.9021,  0.8000, -0.9832],\n",
            "        [ 0.2883,  1.0000,  0.7363,  ..., -0.8962,  0.7861, -0.9852]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0779,  1.0000,  0.8625,  ..., -0.2978, -0.1618, -0.6751],\n",
            "        [-0.1388,  0.9999,  0.9226,  ..., -0.2205, -0.0010, -0.7858],\n",
            "        [-0.0567,  1.0000,  0.8786,  ..., -0.7361,  0.5919, -0.9694],\n",
            "        ...,\n",
            "        [-0.0978,  1.0000,  0.8753,  ..., -0.8539,  0.6540, -0.9771],\n",
            "        [ 0.1836,  1.0000,  0.3214,  ..., -0.8937,  0.7982, -0.9705],\n",
            "        [-0.1583,  1.0000,  0.8434,  ..., -0.8561,  0.7491, -0.9845]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1729,  1.0000,  0.8799,  ..., -0.8218,  0.3770, -0.9528],\n",
            "        [-0.0186,  1.0000,  0.8183,  ..., -0.9284,  0.7491, -0.9651],\n",
            "        [ 0.1290,  1.0000,  0.8524,  ..., -0.8851,  0.7794, -0.9943],\n",
            "        ...,\n",
            "        [ 0.0433,  1.0000,  0.8750,  ..., -0.6353,  0.1311, -0.8175],\n",
            "        [ 0.1936,  1.0000,  0.4652,  ..., -0.8979,  0.8547, -0.9802],\n",
            "        [-0.1936,  1.0000,  0.9108,  ..., -0.3458, -0.1074, -0.7241]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2269,  1.0000,  0.9199,  ..., -0.7731,  0.1089, -0.9026],\n",
            "        [ 0.0211,  1.0000,  0.7965,  ..., -0.8438,  0.7502, -0.9746],\n",
            "        [ 0.2135,  1.0000,  0.7663,  ..., -0.8980,  0.6058, -0.9872],\n",
            "        ...,\n",
            "        [ 0.1580,  1.0000,  0.7135,  ..., -0.9355,  0.7000, -0.9897],\n",
            "        [-0.2787,  1.0000,  0.9048,  ..., -0.2750, -0.0797, -0.7748],\n",
            "        [-0.0121,  0.9999,  0.8943,  ..., -0.0960, -0.1497, -0.7250]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2222,  1.0000,  0.8780,  ..., -0.4918, -0.1336, -0.6967],\n",
            "        [ 0.0474,  1.0000,  0.8225,  ..., -0.8480,  0.5928, -0.9697],\n",
            "        [ 0.5112,  1.0000, -0.0903,  ..., -0.9155,  0.8845, -0.9420],\n",
            "        ...,\n",
            "        [ 0.3992,  1.0000, -0.0524,  ..., -0.9322,  0.8551, -0.9469],\n",
            "        [-0.1205,  1.0000,  0.8585,  ..., -0.8367,  0.2543, -0.9420],\n",
            "        [-0.0419,  1.0000,  0.9093,  ..., -0.7867,  0.6120, -0.9228]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4973,  1.0000,  0.3498,  ..., -0.9121,  0.8412, -0.9863],\n",
            "        [ 0.3750,  1.0000,  0.1149,  ..., -0.9411,  0.8255, -0.9695],\n",
            "        [ 0.1349,  1.0000,  0.9182,  ..., -0.5092,  0.0579, -0.8445],\n",
            "        ...,\n",
            "        [ 0.2855,  1.0000,  0.6937,  ..., -0.9056,  0.7647, -0.9872],\n",
            "        [-0.0478,  1.0000,  0.8697,  ..., -0.4632,  0.1475, -0.7725],\n",
            "        [ 0.0594,  1.0000,  0.5333,  ..., -0.8900,  0.6994, -0.9824]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-4.1592e-01,  1.0000e+00,  8.5311e-01,  ..., -4.1188e-01,\n",
            "         -4.1897e-04, -8.5831e-01],\n",
            "        [-1.5948e-01,  9.9999e-01,  9.2714e-01,  ..., -3.7625e-01,\n",
            "         -4.2913e-02, -8.0844e-01],\n",
            "        [-7.0281e-02,  9.9999e-01,  9.3701e-01,  ...,  1.3461e-01,\n",
            "          1.5646e-01, -8.3596e-01],\n",
            "        ...,\n",
            "        [-1.0856e-01,  9.9999e-01,  9.2161e-01,  ..., -5.4446e-01,\n",
            "          1.8263e-01, -8.3108e-01],\n",
            "        [-2.4351e-01,  9.9999e-01,  8.8561e-01,  ..., -6.7084e-01,\n",
            "          9.3551e-02, -7.8022e-01],\n",
            "        [ 9.0591e-02,  1.0000e+00,  8.2089e-01,  ..., -8.0607e-01,\n",
            "          7.7671e-01, -9.7486e-01]], device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1658,  1.0000,  0.8982,  ..., -0.6582,  0.1436, -0.8633],\n",
            "        [ 0.0380,  1.0000,  0.7255,  ..., -0.8945,  0.7741, -0.9801],\n",
            "        [-0.1854,  1.0000,  0.8159,  ..., -0.9233,  0.7778, -0.9758],\n",
            "        ...,\n",
            "        [-0.0487,  0.9999,  0.8830,  ..., -0.2755, -0.2313, -0.7175],\n",
            "        [ 0.3096,  1.0000,  0.2474,  ..., -0.9186,  0.8369, -0.9817],\n",
            "        [-0.1228,  0.9999,  0.8882,  ..., -0.0846, -0.0669, -0.7488]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3914,  1.0000, -0.0901,  ..., -0.9003,  0.8024, -0.9581],\n",
            "        [-0.2956,  1.0000,  0.8536,  ..., -0.8679,  0.4350, -0.9084],\n",
            "        [-0.2684,  1.0000,  0.8877,  ..., -0.6668,  0.1777, -0.8814],\n",
            "        ...,\n",
            "        [-0.0650,  1.0000,  0.8797,  ..., -0.5510, -0.0523, -0.7886],\n",
            "        [-0.1928,  1.0000,  0.8758,  ..., -0.5559,  0.0174, -0.8060],\n",
            "        [ 0.0748,  1.0000,  0.9182,  ...,  0.3831,  0.1022, -0.8826]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3473,  1.0000,  0.2029,  ..., -0.9138,  0.8200, -0.9710],\n",
            "        [ 0.0552,  1.0000,  0.3669,  ..., -0.9240,  0.7477, -0.9597],\n",
            "        [-0.2735,  1.0000,  0.7863,  ..., -0.7949,  0.1845, -0.8894],\n",
            "        ...,\n",
            "        [ 0.1433,  1.0000,  0.8971,  ..., -0.7362,  0.4778, -0.9707],\n",
            "        [-0.0250,  1.0000,  0.7056,  ..., -0.9057,  0.5520, -0.9669],\n",
            "        [-0.2661,  1.0000,  0.8913,  ..., -0.4420, -0.1848, -0.7829]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2867,  1.0000,  0.9196,  ..., -0.5640, -0.0010, -0.8072],\n",
            "        [ 0.2773,  1.0000,  0.3568,  ..., -0.9008,  0.8502, -0.9823],\n",
            "        [ 0.0327,  1.0000,  0.8113,  ..., -0.9352,  0.5624, -0.9713],\n",
            "        ...,\n",
            "        [ 0.2466,  1.0000,  0.0526,  ..., -0.9065,  0.8017, -0.9634],\n",
            "        [ 0.2558,  1.0000,  0.5053,  ..., -0.9087,  0.8125, -0.9925],\n",
            "        [ 0.2723,  1.0000,  0.1199,  ..., -0.9294,  0.7370, -0.9726]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4399,  1.0000,  0.6741,  ..., -0.5821,  0.9369, -0.9815],\n",
            "        [-0.0034,  1.0000,  0.7515,  ..., -0.8331,  0.7678, -0.9852],\n",
            "        [ 0.2880,  1.0000,  0.3318,  ..., -0.9331,  0.7494, -0.9682],\n",
            "        ...,\n",
            "        [-0.3433,  1.0000,  0.7382,  ..., -0.8368,  0.6858, -0.9623],\n",
            "        [ 0.4423,  1.0000, -0.1210,  ..., -0.9053,  0.8240, -0.9557],\n",
            "        [ 0.2592,  1.0000,  0.4381,  ..., -0.8738,  0.8161, -0.9832]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3440,  1.0000,  0.4875,  ..., -0.8885,  0.7420, -0.9790],\n",
            "        [ 0.0753,  1.0000,  0.6187,  ..., -0.9063,  0.7152, -0.9739],\n",
            "        [ 0.3729,  1.0000,  0.2057,  ..., -0.8543,  0.7977, -0.9786],\n",
            "        ...,\n",
            "        [ 0.3422,  1.0000,  0.4224,  ..., -0.8803,  0.7262, -0.9698],\n",
            "        [ 0.2666,  1.0000,  0.7683,  ..., -0.8935,  0.9084, -0.9805],\n",
            "        [-0.2657,  1.0000,  0.8354,  ..., -0.5226, -0.2228, -0.7301]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3810,  1.0000,  0.4805, -0.9995,  0.8131,  0.6036,  0.9533,  0.8769,\n",
            "         -0.9999, -0.5816,  0.7709, -0.6308, -0.7795,  1.0000, -0.6943, -0.7798,\n",
            "          0.8931, -0.9999,  0.9633, -0.9797,  0.8914,  0.0208,  0.9691, -0.9428,\n",
            "          0.6414,  0.3124, -0.1651,  0.9419, -0.8341,  0.9227, -0.5992, -0.9046,\n",
            "          0.9708,  0.7034,  0.9521, -0.9989, -0.9231, -0.9861, -0.9998, -0.9999,\n",
            "         -0.9843, -0.9717,  1.0000, -0.9287,  0.9999, -0.9995, -0.2585, -0.8543,\n",
            "          0.9753,  0.9111, -0.9182,  0.0066,  0.8656,  0.9835, -0.7776, -0.9995,\n",
            "         -0.8805,  0.9423, -0.9915, -0.3561,  0.9490, -0.7390, -0.7147,  0.3624,\n",
            "         -0.9602,  0.9318,  0.8216,  0.8745, -0.8397, -0.9993,  0.8882, -0.9917,\n",
            "          0.9303, -0.8114,  0.8241,  0.9863, -0.9494,  0.4352, -0.8243,  0.9978,\n",
            "          0.8984,  0.8875,  0.8761, -1.0000,  0.9023, -0.9649,  0.9989, -0.9994,\n",
            "         -0.9987,  0.8242,  0.9421,  0.9313,  0.4761, -0.9173, -0.8398, -0.8951,\n",
            "         -0.2730,  0.7869, -1.0000,  0.9573,  0.9194,  0.9353, -0.0345, -0.8261,\n",
            "         -1.0000, -0.1582, -0.4115, -0.9769, -1.0000, -0.9480, -0.8689, -0.8913,\n",
            "         -0.6973,  0.9990,  0.3243,  1.0000,  0.8880,  0.9990, -1.0000, -0.9981,\n",
            "          0.7338,  0.9924, -0.9190, -0.8634,  0.8333, -0.9981, -0.9917, -1.0000,\n",
            "          0.9136, -0.9619, -0.9214,  0.9925,  0.8064, -0.9773, -0.9796, -0.0803,\n",
            "         -1.0000,  0.8201, -0.9629, -0.9998,  0.9987,  0.9944,  0.4326, -0.9426,\n",
            "         -0.4471,  0.9949,  0.8539, -0.3476, -0.7421, -0.4136, -0.8501,  0.9185,\n",
            "          0.9548, -0.3686, -1.0000,  0.7586,  0.6453,  0.9958, -0.9833,  0.9918,\n",
            "         -0.9718, -1.0000,  0.9852,  0.8901, -0.8896,  0.9228, -0.7400,  0.9911,\n",
            "         -0.8265,  0.9329,  0.9806,  0.8900,  0.7624,  0.9512,  0.9171, -0.9821,\n",
            "         -0.8705, -0.9511,  0.3613, -0.9994,  0.9984, -0.9454,  0.9965, -0.9916,\n",
            "         -0.9925,  0.9474,  0.0753, -1.0000,  0.9986,  0.9255,  0.9724, -0.9580,\n",
            "          0.9864, -0.9148,  0.9536, -0.6745, -0.9629,  0.9350, -0.9245,  0.9965,\n",
            "          0.7164, -0.9996,  0.9997,  0.9997,  0.9382, -0.9964, -0.1562,  0.9983,\n",
            "         -0.9997, -0.9684,  0.3559, -0.8922,  0.8884,  0.0896, -0.9518, -0.9341,\n",
            "          0.9896,  0.0060,  0.9663, -0.3440,  0.9755,  0.9243, -0.9669,  0.9211,\n",
            "          0.9151,  0.9975, -0.9122,  0.3655,  0.1504, -1.0000,  0.9066,  0.5234,\n",
            "          0.5951, -0.9265,  1.0000,  0.9716,  0.3777,  0.9971, -0.9993, -0.7748,\n",
            "         -0.8334, -0.9554,  0.8417,  0.2674,  1.0000, -1.0000,  0.9994,  0.3660,\n",
            "          0.8798,  0.6651, -0.9002,  0.5226,  0.9365,  0.8999, -0.3604,  0.9974,\n",
            "         -0.9227, -1.0000,  0.3134,  0.9279, -0.9966, -0.4891,  0.4884, -0.9729,\n",
            "          0.9999,  1.0000, -0.6832,  0.7189,  0.9278,  0.9790,  0.9875, -0.9990,\n",
            "          0.9982,  1.0000, -0.9956, -0.6841,  1.0000,  0.9535, -0.9698, -0.3477,\n",
            "          0.9039, -0.9979, -0.7264, -0.8930,  0.4909,  0.1383,  0.7643, -0.9991,\n",
            "         -0.9999, -0.9998,  0.9995, -0.8643, -0.8456,  0.8521,  0.3495, -0.9489,\n",
            "          0.5696,  0.9981, -0.9979,  1.0000,  0.9941, -0.9912, -0.9977, -0.7608,\n",
            "          0.8457,  0.5333,  0.9998,  0.0608, -0.9759,  0.9630,  0.9805,  0.6203,\n",
            "          0.9972, -0.7068,  0.8911, -0.0954,  0.9148, -0.9987, -0.9323, -0.9713,\n",
            "          0.9809,  0.9977,  0.9250, -0.9393,  0.9995,  0.8525, -1.0000,  1.0000,\n",
            "          0.9982, -0.9998,  0.5975, -0.8858,  0.9728,  0.8633,  0.9739, -0.9508,\n",
            "         -0.8094, -0.9999,  0.9780,  0.7660, -0.5848,  0.9112, -0.9183,  0.8935,\n",
            "          0.8065,  0.9425,  0.6656, -0.9648, -0.9999,  0.5846,  0.7452,  0.8605,\n",
            "          0.5164,  0.9983,  0.4027,  1.0000, -0.8951,  0.9969, -0.9150,  0.9616,\n",
            "          0.4196,  0.9517,  0.0345, -0.9268, -1.0000,  0.7461, -0.9327,  0.8859,\n",
            "          0.4916, -0.9995, -0.8887, -0.0228, -0.8944, -0.3524, -0.2111, -0.5249,\n",
            "          1.0000,  0.9764,  0.6169, -0.9219, -0.8233,  0.8952,  0.9941,  0.9725,\n",
            "          0.9993, -0.9799,  0.9665,  0.2576,  0.6269, -0.9248,  0.0765,  0.2309,\n",
            "          0.8203,  0.9990,  0.9853,  0.9820, -0.8561,  0.8894, -0.9994,  1.0000,\n",
            "          0.7473,  0.9210,  0.9791, -0.4855,  0.9586, -0.8916,  0.9685, -0.9756,\n",
            "          0.9951,  0.7320,  0.9186,  0.8431,  0.9727, -0.9666,  0.0559,  0.9579,\n",
            "          0.8873, -0.9592, -0.9960,  0.9979, -0.9981, -0.5139, -0.9801,  0.2844,\n",
            "          0.9984, -0.9776, -0.8823, -0.9311, -0.9618, -0.9753, -0.9608, -0.9988,\n",
            "         -0.1658, -0.9988,  1.0000, -0.9978,  0.9161, -0.9549, -0.9022,  0.9623,\n",
            "          0.4889, -0.9466, -0.8714, -0.0186, -0.9709,  0.9662, -0.0310,  0.6514,\n",
            "          0.4718, -0.7711,  0.9056,  0.8999,  0.7738,  0.9987, -0.9478, -0.9981,\n",
            "         -0.9583, -0.8469,  0.5735,  0.9993, -0.9984,  0.2885,  1.0000, -0.9998,\n",
            "         -0.8894, -0.0236, -0.9999,  0.8712, -0.9806, -0.9987, -0.8479, -0.9600,\n",
            "          0.9856,  0.9959,  1.0000, -0.6125, -0.9522, -0.9947, -0.7849,  0.9958,\n",
            "         -0.9996,  0.7921, -0.5745, -0.9998,  0.9892,  0.9185, -0.8216,  0.8004,\n",
            "         -0.6884,  0.9994, -0.8163, -0.9941,  0.8382,  0.9167,  0.2743,  0.9026,\n",
            "         -0.6842, -0.7268, -0.9991,  0.7954,  1.0000, -0.6547, -0.9873,  0.9724,\n",
            "          0.9858,  0.9374,  1.0000, -0.9978,  0.9827,  1.0000, -0.6633,  0.9431,\n",
            "         -0.8579, -0.9433, -0.0816,  0.9123, -0.9970,  1.0000, -0.9088, -0.9940,\n",
            "         -1.0000,  0.8147, -0.9659,  0.9366,  0.9928,  0.2956,  0.8479,  0.9370,\n",
            "         -0.9998,  0.9857, -0.9886, -1.0000, -1.0000,  0.9502, -0.2083, -0.7999,\n",
            "          0.7658, -0.8132, -0.9272,  1.0000,  0.7438, -1.0000, -0.9412,  0.9823,\n",
            "          0.9968, -0.8817,  0.9639, -0.8797, -0.4746, -0.0286, -1.0000, -0.9400,\n",
            "          0.9987, -0.4847,  0.5960,  1.0000,  0.9319, -0.9558, -0.9537,  0.8309,\n",
            "          0.9585, -1.0000, -0.9731,  1.0000, -0.9785, -0.7034, -0.9874, -0.2467,\n",
            "          0.8926,  0.9681,  0.9913, -0.9998,  0.9999,  0.9284,  0.8136,  0.9970,\n",
            "          0.3792, -0.9027, -0.9945, -0.8456,  0.9452, -0.5308,  0.8122, -0.9886,\n",
            "          0.9963,  0.8155, -0.9757,  0.9408,  0.3790, -0.7740, -0.9186,  0.9968,\n",
            "          0.7925, -0.7898,  0.9988, -0.5178, -0.8663,  0.2891,  0.8891,  0.9506,\n",
            "         -1.0000,  0.9104, -0.8355, -0.9935,  0.6700,  0.6396, -0.9527, -0.7614,\n",
            "          0.9823, -0.9444,  0.8087,  0.9984,  0.9703,  0.9763, -0.9942, -1.0000,\n",
            "         -0.8340, -0.5687, -0.9750,  0.6773, -0.6387,  0.9998,  0.6693,  0.7848,\n",
            "          0.9546,  1.0000, -0.4181,  0.9871, -0.8660,  0.9233, -0.9993,  0.9760,\n",
            "          0.0438, -0.9990, -0.9436,  0.7045, -0.8399,  0.7600, -0.9532,  0.8906,\n",
            "          1.0000, -0.5355,  0.7785,  0.9580, -0.9523,  0.8972, -0.9456,  0.9998,\n",
            "         -1.0000,  0.9965,  0.9001,  0.0346,  0.9353,  0.1531, -0.7498, -0.8914,\n",
            "         -0.9297, -0.9911, -0.8186,  0.8623, -0.8037,  0.9722,  0.9867, -0.9786,\n",
            "         -1.0000, -0.5740,  0.3373,  0.8910, -0.8701, -0.9700,  0.9783, -0.9041,\n",
            "          0.9956, -0.9588, -0.9504, -0.9266, -0.9702, -0.5377,  0.9212,  0.9817,\n",
            "          0.9569,  0.9105, -0.7912, -0.8805, -0.7996, -0.9680,  0.7918,  0.5632,\n",
            "          0.9855,  0.9122,  0.9430,  0.9965,  0.5344, -0.7074,  0.7469, -0.9319,\n",
            "         -0.8447, -0.9999,  0.9999,  0.8368, -0.9659, -1.0000,  0.8880,  0.7516,\n",
            "         -0.5771,  0.7592, -0.9308, -0.9908, -0.8340,  0.9865, -1.0000, -0.4303,\n",
            "          0.8939, -0.6666,  0.7820, -0.9999, -0.3079,  0.9087, -0.8863,  0.7492,\n",
            "          1.0000, -0.9639, -0.9984, -0.9962, -0.3103,  0.9152,  0.8728, -0.9995,\n",
            "         -0.8977,  0.9898, -1.0000,  0.7384, -0.8304, -0.9236,  0.9040,  0.8244,\n",
            "          0.9932, -1.0000,  0.9503, -0.9337,  0.9754, -0.2047,  0.7380,  0.9186,\n",
            "          0.9838, -1.0000,  0.8970,  0.7024,  0.9739,  0.8749,  0.9339, -0.9305,\n",
            "         -0.9637, -0.9664,  0.9968,  0.9953, -0.9522,  0.9777,  1.0000, -0.6731,\n",
            "          0.9835,  0.1345, -0.9439, -0.9998, -0.9869, -0.9134,  0.7161, -0.9715]],\n",
            "       device='cuda:0')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training... :   0%|          | 0/127 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82592d0ddb6f4667848b15d4ddf63edb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2965,  1.0000,  0.7790,  ..., -0.8919,  0.7821, -0.9770],\n",
            "        [-0.1840,  1.0000,  0.9038,  ..., -0.4630,  0.2551, -0.8254],\n",
            "        [ 0.2368,  1.0000,  0.4167,  ..., -0.8145,  0.7180, -0.9716],\n",
            "        ...,\n",
            "        [ 0.0936,  1.0000,  0.8922,  ..., -0.6109,  0.0759, -0.8646],\n",
            "        [ 0.4546,  1.0000, -0.0855,  ..., -0.9144,  0.7833, -0.9599],\n",
            "        [ 0.1061,  1.0000,  0.8873,  ..., -0.8104,  0.1632, -0.9331]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3662,  1.0000, -0.0793,  ..., -0.9038,  0.8304, -0.9581],\n",
            "        [-0.4099,  1.0000,  0.8853,  ..., -0.7035, -0.0697, -0.8600],\n",
            "        [ 0.3520,  1.0000,  0.4817,  ..., -0.8998,  0.8135, -0.9835],\n",
            "        ...,\n",
            "        [ 0.0381,  1.0000,  0.9034,  ..., -0.8109,  0.2876, -0.8999],\n",
            "        [ 0.3216,  1.0000,  0.8777,  ..., -0.7097, -0.1018, -0.8857],\n",
            "        [ 0.4194,  1.0000,  0.7697,  ..., -0.8376,  0.8380, -0.9919]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3312,  1.0000,  0.1649,  ..., -0.8658,  0.8431, -0.9707],\n",
            "        [-0.2882,  1.0000,  0.8639,  ..., -0.6082, -0.1173, -0.8781],\n",
            "        [-0.0822,  1.0000,  0.8891,  ..., -0.1506,  0.3498, -0.8666],\n",
            "        ...,\n",
            "        [ 0.0214,  1.0000,  0.8819,  ..., -0.6523,  0.1961, -0.8098],\n",
            "        [-0.1477,  1.0000,  0.9060,  ..., -0.4371, -0.0199, -0.7649],\n",
            "        [-0.1375,  1.0000,  0.8958,  ..., -0.7624, -0.0191, -0.8629]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0515,  1.0000,  0.7657,  ..., -0.4922,  0.1400, -0.9081],\n",
            "        [-0.2421,  1.0000,  0.8637,  ..., -0.5021, -0.0479, -0.8994],\n",
            "        [ 0.1617,  1.0000,  0.5607,  ..., -0.8915,  0.8128, -0.9737],\n",
            "        ...,\n",
            "        [ 0.5452,  1.0000,  0.0771,  ..., -0.8740,  0.8115, -0.9670],\n",
            "        [-0.0684,  1.0000,  0.8298,  ..., -0.6795,  0.0688, -0.9448],\n",
            "        [-0.1569,  1.0000,  0.8614,  ..., -0.8494,  0.5922, -0.9610]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2309,  1.0000, -0.0013,  ..., -0.8908,  0.6994, -0.9590],\n",
            "        [ 0.1211,  1.0000,  0.8708,  ..., -0.8054,  0.7661, -0.9840],\n",
            "        [-0.0324,  1.0000,  0.7182,  ..., -0.9269,  0.7194, -0.9710],\n",
            "        ...,\n",
            "        [ 0.0604,  1.0000,  0.6263,  ..., -0.8649,  0.9028, -0.9889],\n",
            "        [ 0.1045,  1.0000,  0.5589,  ..., -0.8814,  0.8002, -0.9848],\n",
            "        [-0.4046,  1.0000,  0.8858,  ..., -0.6649,  0.2920, -0.8927]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1692,  1.0000,  0.6017,  ..., -0.7745,  0.5100, -0.9623],\n",
            "        [-0.3368,  1.0000,  0.8491,  ..., -0.7862,  0.6850, -0.9427],\n",
            "        [ 0.0078,  1.0000,  0.6342,  ..., -0.8318,  0.7532, -0.9749],\n",
            "        ...,\n",
            "        [ 0.1602,  1.0000,  0.8270,  ..., -0.8311,  0.3097, -0.9618],\n",
            "        [-0.0829,  1.0000,  0.8968,  ..., -0.5467,  0.2279, -0.8578],\n",
            "        [-0.0663,  1.0000,  0.7965,  ..., -0.8124,  0.7401, -0.9851]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1668,  1.0000,  0.8257,  ..., -0.8652,  0.7540, -0.9581],\n",
            "        [ 0.1574,  1.0000,  0.9298,  ..., -0.7097,  0.8048, -0.9541],\n",
            "        [-0.1764,  1.0000,  0.9144,  ..., -0.2585, -0.1111, -0.8552],\n",
            "        ...,\n",
            "        [-0.1064,  1.0000,  0.9453,  ..., -0.1484, -0.2912, -0.7543],\n",
            "        [ 0.1974,  1.0000,  0.8419,  ..., -0.7843,  0.7823, -0.9651],\n",
            "        [ 0.2971,  1.0000,  0.4084,  ..., -0.9589,  0.8932, -0.9576]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1910,  0.9997,  0.8718,  ..., -0.5594, -0.2229, -0.5748],\n",
            "        [-0.0542,  1.0000,  0.9256,  ..., -0.6363, -0.3101, -0.7976],\n",
            "        [ 0.0717,  1.0000,  0.8819,  ..., -0.3757, -0.1301, -0.7051],\n",
            "        ...,\n",
            "        [ 0.0754,  1.0000,  0.8632,  ..., -0.8120,  0.8320, -0.9702],\n",
            "        [ 0.0150,  1.0000,  0.8058,  ..., -0.8309,  0.6440, -0.9740],\n",
            "        [ 0.1093,  1.0000, -0.0082,  ..., -0.9011,  0.8296, -0.9733]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0494,  1.0000,  0.7837,  ..., -0.8641,  0.6319, -0.9655],\n",
            "        [-0.2122,  1.0000,  0.7190,  ..., -0.4255,  0.0841, -0.8814],\n",
            "        [-0.0582,  1.0000,  0.4181,  ..., -0.9009,  0.5843, -0.9717],\n",
            "        ...,\n",
            "        [ 0.0532,  1.0000,  0.2770,  ..., -0.8994,  0.8678, -0.9566],\n",
            "        [-0.0738,  1.0000,  0.9410,  ..., -0.7495,  0.5722, -0.9334],\n",
            "        [ 0.0258,  1.0000,  0.4920,  ..., -0.9120,  0.7829, -0.9728]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3413,  1.0000,  0.8974,  ..., -0.2613, -0.0823, -0.8441],\n",
            "        [ 0.1520,  1.0000,  0.8012,  ..., -0.7613,  0.3852, -0.9743],\n",
            "        [ 0.4182,  1.0000,  0.9029,  ..., -0.5958,  0.7228, -0.9904],\n",
            "        ...,\n",
            "        [-0.1306,  1.0000,  0.9041,  ..., -0.4617,  0.1421, -0.8338],\n",
            "        [-0.1659,  1.0000,  0.8693,  ..., -0.4873,  0.3366, -0.8873],\n",
            "        [ 0.3280,  1.0000,  0.6576,  ..., -0.8984,  0.8871, -0.9772]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1722,  1.0000,  0.7125,  ..., -0.9144,  0.7463, -0.9478],\n",
            "        [ 0.2717,  1.0000,  0.8465,  ..., -0.8163,  0.7257, -0.9601],\n",
            "        [ 0.2987,  1.0000,  0.7849,  ..., -0.8879,  0.6851, -0.9340],\n",
            "        ...,\n",
            "        [ 0.2772,  0.9999,  0.9227,  ..., -0.1438,  0.3671, -0.7535],\n",
            "        [ 0.0697,  1.0000,  0.8116,  ..., -0.8892,  0.5524, -0.9313],\n",
            "        [-0.0948,  1.0000,  0.9266,  ..., -0.5112,  0.4843, -0.8461]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 5.3283e-02,  1.0000e+00,  1.2794e-01,  ..., -9.3432e-01,\n",
            "          8.1555e-01, -9.4743e-01],\n",
            "        [ 3.3625e-02,  9.9999e-01,  8.8269e-01,  ..., -5.5535e-01,\n",
            "          2.6181e-01, -6.4102e-01],\n",
            "        [ 3.4921e-01,  1.0000e+00,  9.4115e-03,  ..., -9.0032e-01,\n",
            "          8.2826e-01, -9.5089e-01],\n",
            "        ...,\n",
            "        [ 1.3009e-02,  9.9952e-01,  6.9062e-01,  ..., -5.2559e-02,\n",
            "          3.4811e-01, -7.7821e-01],\n",
            "        [ 1.6666e-04,  1.0000e+00,  7.7024e-01,  ..., -9.0594e-01,\n",
            "          6.3970e-01, -9.5863e-01],\n",
            "        [ 2.0143e-01,  1.0000e+00,  8.7267e-01,  ..., -7.2314e-01,\n",
            "          7.2561e-01, -9.6896e-01]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2109,  1.0000,  0.9390,  ..., -0.5011,  0.4257, -0.8351],\n",
            "        [ 0.2184,  1.0000,  0.1945,  ..., -0.9279,  0.6995, -0.9478],\n",
            "        [ 0.6072,  1.0000,  0.7792,  ..., -0.8206,  0.6017, -0.9672],\n",
            "        ...,\n",
            "        [ 0.1963,  1.0000,  0.8986,  ..., -0.6654,  0.0260, -0.8401],\n",
            "        [ 0.0779,  1.0000,  0.9121,  ..., -0.8607,  0.3801, -0.8995],\n",
            "        [ 0.1841,  1.0000,  0.5983,  ..., -0.8407,  0.8447, -0.9883]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0264,  1.0000,  0.9019,  ..., -0.8183,  0.5469, -0.9739],\n",
            "        [ 0.0761,  1.0000,  0.8617,  ..., -0.4465, -0.0079, -0.8754],\n",
            "        [ 0.0965,  1.0000,  0.3475,  ..., -0.9055,  0.8045, -0.9679],\n",
            "        ...,\n",
            "        [ 0.3910,  1.0000,  0.9459,  ..., -0.0713,  0.2637, -0.8066],\n",
            "        [ 0.0270,  1.0000,  0.3314,  ..., -0.8592,  0.7564, -0.9616],\n",
            "        [ 0.0745,  1.0000,  0.9434,  ..., -0.2406, -0.0589, -0.8514]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0129,  1.0000,  0.8923,  ..., -0.7336,  0.5019, -0.9658],\n",
            "        [ 0.0854,  1.0000,  0.3812,  ..., -0.9016,  0.8634, -0.9818],\n",
            "        [ 0.3613,  1.0000,  0.9465,  ..., -0.6380,  0.1589, -0.8785],\n",
            "        ...,\n",
            "        [ 0.1538,  1.0000,  0.3231,  ..., -0.8704,  0.7549, -0.9661],\n",
            "        [ 0.2125,  1.0000,  0.8793,  ..., -0.7301,  0.8165, -0.9656],\n",
            "        [ 0.1630,  1.0000,  0.9248,  ..., -0.3209, -0.1346, -0.8450]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0752,  1.0000,  0.9231,  ..., -0.7466,  0.5315, -0.9558],\n",
            "        [ 0.2334,  1.0000,  0.0359,  ..., -0.8470,  0.8646, -0.9645],\n",
            "        [-0.0859,  1.0000,  0.8918,  ..., -0.6146,  0.2335, -0.7446],\n",
            "        ...,\n",
            "        [ 0.2781,  1.0000,  0.5294,  ..., -0.9087,  0.8884, -0.9678],\n",
            "        [ 0.1650,  1.0000,  0.2978,  ..., -0.9366,  0.8787, -0.9557],\n",
            "        [ 0.0476,  1.0000, -0.0837,  ..., -0.9076,  0.7308, -0.9504]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 3.6460e-01,  1.0000e+00,  4.6516e-03,  ..., -8.8741e-01,\n",
            "          7.2549e-01, -9.7631e-01],\n",
            "        [ 2.9891e-01,  1.0000e+00, -2.9542e-01,  ..., -8.7570e-01,\n",
            "          7.2011e-01, -9.2332e-01],\n",
            "        [ 8.5455e-02,  1.0000e+00,  8.7434e-01,  ..., -4.7859e-01,\n",
            "          1.8045e-01, -8.4013e-01],\n",
            "        ...,\n",
            "        [ 3.3841e-01,  9.9999e-01,  8.6284e-01,  ..., -9.3583e-02,\n",
            "         -5.9030e-02, -6.5510e-01],\n",
            "        [ 4.4627e-01,  1.0000e+00,  8.4691e-01,  ..., -9.1031e-01,\n",
            "          8.7006e-01, -9.7956e-01],\n",
            "        [ 5.4208e-04,  9.9998e-01,  8.7920e-01,  ..., -2.3220e-01,\n",
            "          5.5921e-02, -6.5128e-01]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0978,  1.0000,  0.9347,  ..., -0.6206,  0.5037, -0.9309],\n",
            "        [-0.0103,  1.0000,  0.8079,  ..., -0.7674,  0.6992, -0.9569],\n",
            "        [ 0.2015,  1.0000,  0.9379,  ...,  0.0940, -0.1362, -0.4996],\n",
            "        ...,\n",
            "        [-0.2414,  1.0000,  0.4783,  ..., -0.8916,  0.6166, -0.9494],\n",
            "        [-0.0560,  0.9999,  0.9503,  ..., -0.0902, -0.2222, -0.4283],\n",
            "        [ 0.2539,  1.0000,  0.5704,  ..., -0.9146,  0.7159, -0.9719]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0455,  1.0000,  0.8325,  ..., -0.8815,  0.8433, -0.9640],\n",
            "        [ 0.1741,  1.0000,  0.9427,  ..., -0.3940,  0.0464, -0.8965],\n",
            "        [ 0.1847,  1.0000,  0.6771,  ..., -0.8484,  0.7821, -0.9755],\n",
            "        ...,\n",
            "        [ 0.0449,  1.0000,  0.8800,  ..., -0.5750,  0.5797, -0.9058],\n",
            "        [ 0.2331,  1.0000,  0.7537,  ..., -0.8770,  0.6916, -0.9712],\n",
            "        [-0.0289,  1.0000,  0.8823,  ..., -0.7272,  0.4913, -0.6906]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2492,  1.0000,  0.1156,  ..., -0.8985,  0.8084, -0.9225],\n",
            "        [ 0.2380,  1.0000,  0.9136,  ..., -0.4723,  0.5026, -0.9386],\n",
            "        [ 0.1067,  1.0000,  0.9586,  ..., -0.6769,  0.5040, -0.9050],\n",
            "        ...,\n",
            "        [ 0.0699,  1.0000,  0.8660,  ..., -0.7607,  0.5738, -0.9459],\n",
            "        [ 0.3224,  1.0000,  0.9196,  ..., -0.2525,  0.1976, -0.9317],\n",
            "        [-0.1142,  1.0000,  0.3735,  ..., -0.8676,  0.7972, -0.9432]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1419,  1.0000,  0.6946,  ..., -0.7991,  0.8452, -0.9682],\n",
            "        [ 0.0167,  1.0000,  0.9468,  ...,  0.0265,  0.4653, -0.9302],\n",
            "        [-0.0574,  1.0000,  0.8901,  ..., -0.7622,  0.6566, -0.9159],\n",
            "        ...,\n",
            "        [-0.0461,  1.0000,  0.6089,  ..., -0.8639,  0.8501, -0.9749],\n",
            "        [-0.0039,  1.0000, -0.1742,  ..., -0.9469,  0.8321, -0.9139],\n",
            "        [-0.0462,  0.9999,  0.9229,  ...,  0.0351, -0.0346, -0.7233]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2267,  1.0000, -0.2609,  ..., -0.8881,  0.9055, -0.9457],\n",
            "        [ 0.1653,  1.0000,  0.1223,  ..., -0.8688,  0.8329, -0.9702],\n",
            "        [-0.0080,  1.0000,  0.8726,  ..., -0.7784,  0.5602, -0.9407],\n",
            "        ...,\n",
            "        [-0.1596,  1.0000,  0.6292,  ..., -0.8790,  0.7480, -0.9475],\n",
            "        [ 0.3884,  1.0000,  0.8903,  ..., -0.6068,  0.5476, -0.9655],\n",
            "        [ 0.0573,  1.0000,  0.8334,  ..., -0.7862,  0.7034, -0.9850]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1022,  1.0000,  0.8213,  ..., -0.8734,  0.7651, -0.9682],\n",
            "        [ 0.1698,  1.0000,  0.8485,  ..., -0.9049,  0.8033, -0.9544],\n",
            "        [-0.0107,  1.0000, -0.3432,  ..., -0.8177,  0.7841, -0.9142],\n",
            "        ...,\n",
            "        [ 0.0356,  1.0000,  0.0049,  ..., -0.9362,  0.7993, -0.9194],\n",
            "        [-0.0185,  1.0000, -0.0653,  ..., -0.7818,  0.7886, -0.9452],\n",
            "        [ 0.5365,  1.0000,  0.8948,  ..., -0.4723,  0.0959, -0.8839]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0627,  1.0000,  0.8968,  ..., -0.2326,  0.2031, -0.9388],\n",
            "        [ 0.2078,  1.0000,  0.8105,  ..., -0.0809, -0.3273, -0.7524],\n",
            "        [ 0.7838,  1.0000,  0.9259,  ...,  0.4476,  0.2227, -0.9744],\n",
            "        ...,\n",
            "        [ 0.1014,  1.0000, -0.2807,  ..., -0.9119,  0.7871, -0.9220],\n",
            "        [-0.1422,  1.0000,  0.9179,  ..., -0.1116, -0.1074, -0.7361],\n",
            "        [ 0.0478,  1.0000,  0.9458,  ..., -0.2995,  0.0662, -0.7958]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0655,  0.9990,  0.8621,  ..., -0.1286, -0.3453, -0.6965],\n",
            "        [ 0.0144,  1.0000,  0.8785,  ..., -0.1531, -0.2319, -0.7851],\n",
            "        [ 0.1360,  1.0000,  0.0813,  ..., -0.9023,  0.8190, -0.8634],\n",
            "        ...,\n",
            "        [ 0.1814,  1.0000,  0.8852,  ..., -0.8134,  0.4879, -0.9589],\n",
            "        [-0.0448,  0.9997,  0.8810,  ...,  0.0806, -0.1155, -0.5545],\n",
            "        [ 0.6230,  0.9998,  0.8943,  ...,  0.6948, -0.3258, -0.7712]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2119,  1.0000,  0.9097,  ..., -0.7382,  0.7071, -0.9889],\n",
            "        [ 0.0503,  1.0000,  0.9329,  ..., -0.2167,  0.4836, -0.8812],\n",
            "        [ 0.2690,  1.0000,  0.8995,  ..., -0.5764,  0.4749, -0.8132],\n",
            "        ...,\n",
            "        [ 0.0299,  1.0000,  0.8196,  ..., -0.0232, -0.6089, -0.6738],\n",
            "        [ 0.1559,  1.0000,  0.8271,  ..., -0.8173,  0.7771, -0.9810],\n",
            "        [ 0.3074,  1.0000,  0.2353,  ..., -0.8178,  0.9016, -0.9109]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1120,  1.0000,  0.0307,  ..., -0.9034,  0.8998, -0.9260],\n",
            "        [ 0.1131,  0.9999,  0.9268,  ...,  0.3084, -0.3838, -0.7632],\n",
            "        [ 0.0630,  1.0000,  0.7936,  ..., -0.5791,  0.3505, -0.9204],\n",
            "        ...,\n",
            "        [ 0.1044,  0.9999,  0.9121,  ..., -0.0299, -0.1021, -0.7395],\n",
            "        [-0.3990,  1.0000,  0.2237,  ..., -0.9097,  0.6917, -0.9048],\n",
            "        [-0.3638,  1.0000,  0.7927,  ..., -0.7917,  0.8028, -0.9691]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0177,  1.0000,  0.4924,  ..., -0.8108,  0.6828, -0.9615],\n",
            "        [-0.0857,  1.0000,  0.7263,  ..., -0.8707,  0.7044, -0.9745],\n",
            "        [ 0.0222,  1.0000,  0.7964,  ..., -0.6785,  0.1113, -0.9610],\n",
            "        ...,\n",
            "        [ 0.4880,  1.0000,  0.9156,  ...,  0.0958,  0.3923, -0.8697],\n",
            "        [-0.1837,  1.0000,  0.3271,  ..., -0.8844,  0.7886, -0.9241],\n",
            "        [ 0.2013,  1.0000,  0.1175,  ..., -0.8640,  0.8086, -0.9354]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2458,  1.0000,  0.9273,  ...,  0.0776,  0.0704, -0.9126],\n",
            "        [ 0.0942,  1.0000,  0.9142,  ..., -0.5827,  0.4820, -0.9625],\n",
            "        [-0.3115,  1.0000,  0.8513,  ..., -0.8680,  0.6985, -0.9714],\n",
            "        ...,\n",
            "        [-0.0681,  1.0000,  0.8481,  ..., -0.5144,  0.3411, -0.9373],\n",
            "        [ 0.3708,  1.0000,  0.8990,  ..., -0.5814, -0.0997, -0.9182],\n",
            "        [ 0.6128,  1.0000,  0.9076,  ...,  0.4937, -0.2170, -0.9106]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2752,  1.0000,  0.9536,  ..., -0.1090, -0.0075, -0.8882],\n",
            "        [-0.1127,  1.0000,  0.2643,  ..., -0.8595,  0.5683, -0.9489],\n",
            "        [ 0.0156,  1.0000, -0.4273,  ..., -0.9254,  0.7047, -0.8264],\n",
            "        ...,\n",
            "        [ 0.4280,  1.0000,  0.9089,  ..., -0.1712,  0.1581, -0.9028],\n",
            "        [-0.1815,  1.0000,  0.4833,  ..., -0.9512,  0.8601, -0.9448],\n",
            "        [ 0.4799,  1.0000,  0.9327,  ...,  0.1761, -0.0019, -0.8672]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0039,  1.0000,  0.0311,  ..., -0.9304,  0.8121, -0.8648],\n",
            "        [-0.0476,  1.0000,  0.8819,  ..., -0.7629,  0.6821, -0.9686],\n",
            "        [ 0.3663,  1.0000,  0.9233,  ..., -0.4499,  0.5435, -0.9545],\n",
            "        ...,\n",
            "        [-0.2044,  1.0000,  0.0950,  ..., -0.9043,  0.8308, -0.9055],\n",
            "        [-0.0818,  1.0000,  0.7919,  ..., -0.8708,  0.6496, -0.9635],\n",
            "        [-0.1717,  1.0000,  0.3114,  ..., -0.8841,  0.8901, -0.9605]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0215,  1.0000,  0.8558,  ..., -0.8485,  0.8741, -0.9824],\n",
            "        [ 0.4576,  1.0000,  0.9280,  ..., -0.2682,  0.3211, -0.9330],\n",
            "        [-0.1830,  1.0000,  0.5782,  ..., -0.8659,  0.6620, -0.9360],\n",
            "        ...,\n",
            "        [-0.3964,  1.0000,  0.7811,  ..., -0.8639,  0.6042, -0.9566],\n",
            "        [ 0.4355,  1.0000,  0.8891,  ..., -0.0780,  0.0828, -0.9156],\n",
            "        [ 0.3015,  1.0000,  0.9447,  ..., -0.3684,  0.0723, -0.8630]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3605,  1.0000,  0.9113,  ..., -0.3539,  0.6288, -0.9293],\n",
            "        [-0.2025,  1.0000,  0.6024,  ..., -0.8156,  0.4869, -0.9256],\n",
            "        [-0.0905,  1.0000,  0.9433,  ..., -0.5220,  0.4635, -0.8791],\n",
            "        ...,\n",
            "        [ 0.4520,  1.0000,  0.8269,  ..., -0.6209,  0.8984, -0.9836],\n",
            "        [ 0.1566,  1.0000, -0.3158,  ..., -0.9247,  0.7806, -0.8408],\n",
            "        [-0.0950,  1.0000, -0.3153,  ..., -0.9017,  0.8194, -0.7394]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1266,  1.0000,  0.1947,  ..., -0.9166,  0.8590, -0.9510],\n",
            "        [ 0.2260,  1.0000,  0.8822,  ..., -0.8209,  0.7957, -0.9769],\n",
            "        [ 0.1861,  1.0000,  0.8627,  ..., -0.7409,  0.7039, -0.9675],\n",
            "        ...,\n",
            "        [-0.2850,  1.0000, -0.1191,  ..., -0.9000,  0.8459, -0.9151],\n",
            "        [ 0.0597,  1.0000,  0.9365,  ..., -0.5590,  0.2396, -0.9594],\n",
            "        [ 0.2520,  1.0000,  0.9219,  ..., -0.0375,  0.1776, -0.9092]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3074,  1.0000,  0.8991,  ..., -0.4769,  0.0605, -0.9129],\n",
            "        [ 0.1259,  1.0000,  0.9081,  ..., -0.6233,  0.6709, -0.9352],\n",
            "        [ 0.1822,  1.0000,  0.2300,  ..., -0.8714,  0.7068, -0.9636],\n",
            "        ...,\n",
            "        [-0.0915,  1.0000,  0.1349,  ..., -0.9433,  0.7636, -0.8121],\n",
            "        [-0.0782,  1.0000,  0.8744,  ..., -0.7934,  0.7837, -0.9780],\n",
            "        [ 0.3790,  1.0000,  0.9019,  ..., -0.0054,  0.1445, -0.8748]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2434,  1.0000, -0.5789,  ..., -0.8472,  0.8281, -0.8643],\n",
            "        [ 0.0794,  1.0000, -0.3072,  ..., -0.9202,  0.7581, -0.8036],\n",
            "        [-0.0328,  1.0000, -0.5856,  ..., -0.8951,  0.6037, -0.8365],\n",
            "        ...,\n",
            "        [ 0.1354,  1.0000,  0.8640,  ..., -0.7052,  0.6436, -0.9521],\n",
            "        [-0.2197,  1.0000,  0.2712,  ..., -0.9296,  0.3833, -0.8958],\n",
            "        [-0.0592,  1.0000,  0.0835,  ..., -0.9075,  0.8743, -0.9077]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2776,  1.0000,  0.5733,  ..., -0.8254,  0.6591, -0.9157],\n",
            "        [ 0.1462,  1.0000,  0.7467,  ..., -0.8539,  0.7224, -0.9585],\n",
            "        [ 0.0859,  1.0000,  0.3650,  ..., -0.7839,  0.4867, -0.9527],\n",
            "        ...,\n",
            "        [ 0.3928,  1.0000,  0.8756,  ..., -0.2040,  0.1583, -0.9458],\n",
            "        [-0.3217,  1.0000,  0.5519,  ..., -0.8883,  0.7540, -0.9743],\n",
            "        [ 0.2777,  1.0000,  0.4797,  ..., -0.8352,  0.8316, -0.9720]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5074,  1.0000,  0.9266,  ..., -0.0410,  0.3874, -0.8697],\n",
            "        [ 0.1621,  1.0000,  0.8146,  ..., -0.7875,  0.7546, -0.9416],\n",
            "        [ 0.3133,  1.0000,  0.6168,  ..., -0.7846,  0.8274, -0.9750],\n",
            "        ...,\n",
            "        [ 0.4372,  1.0000,  0.8923,  ..., -0.6255,  0.7678, -0.9389],\n",
            "        [-0.0502,  1.0000, -0.4320,  ..., -0.9322,  0.7432, -0.8355],\n",
            "        [ 0.0479,  1.0000, -0.2457,  ..., -0.9069,  0.5933, -0.8887]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2947,  1.0000, -0.3006,  ..., -0.8998,  0.8482, -0.9268],\n",
            "        [ 0.5117,  1.0000,  0.8643,  ..., -0.7266,  0.3848, -0.9636],\n",
            "        [ 0.5845,  1.0000,  0.8140,  ...,  0.5511,  0.1252, -0.7896],\n",
            "        ...,\n",
            "        [ 0.4484,  1.0000,  0.9053,  ..., -0.1068,  0.5511, -0.7081],\n",
            "        [ 0.4794,  1.0000,  0.8542,  ...,  0.3564,  0.3908, -0.8171],\n",
            "        [ 0.6209,  1.0000,  0.8326,  ...,  0.1195,  0.0870, -0.7387]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5313,  1.0000,  0.9024,  ...,  0.1596, -0.1019, -0.5969],\n",
            "        [ 0.2806,  1.0000,  0.8827,  ..., -0.5892,  0.7193, -0.9087],\n",
            "        [ 0.3160,  1.0000,  0.8284,  ..., -0.7902,  0.6972, -0.9619],\n",
            "        ...,\n",
            "        [-0.1599,  1.0000, -0.3077,  ..., -0.8755,  0.6001, -0.9611],\n",
            "        [ 0.4943,  1.0000,  0.8999,  ..., -0.5216,  0.6748, -0.9698],\n",
            "        [ 0.1565,  1.0000, -0.3729,  ..., -0.9080,  0.7639, -0.8707]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7281,  1.0000,  0.8989,  ...,  0.4393,  0.0909, -0.7088],\n",
            "        [ 0.0558,  1.0000, -0.2011,  ..., -0.8898,  0.8052, -0.8262],\n",
            "        [ 0.1022,  1.0000, -0.4538,  ..., -0.7159,  0.8073, -0.8390],\n",
            "        ...,\n",
            "        [ 0.6654,  1.0000,  0.9345,  ...,  0.4761, -0.1069, -0.8597],\n",
            "        [ 0.6213,  1.0000,  0.9050,  ...,  0.2910,  0.0308, -0.8398],\n",
            "        [ 0.4777,  1.0000,  0.7563,  ...,  0.0179,  0.5274, -0.7845]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 7.4972e-01,  9.9999e-01,  8.9185e-01,  ...,  6.2885e-01,\n",
            "          1.6481e-02, -7.4867e-01],\n",
            "        [ 6.0055e-01,  9.9997e-01,  8.6596e-01,  ...,  4.5747e-01,\n",
            "         -8.9885e-02, -5.7656e-01],\n",
            "        [ 5.4945e-04,  9.9998e-01,  2.5643e-01,  ..., -7.9333e-01,\n",
            "          5.4018e-01, -8.4133e-01],\n",
            "        ...,\n",
            "        [ 4.6896e-01,  1.0000e+00,  9.3223e-01,  ..., -2.1245e-01,\n",
            "          2.4258e-01, -8.9075e-01],\n",
            "        [-5.0192e-02,  9.9993e-01,  7.8402e-01,  ..., -1.2402e-01,\n",
            "          3.3876e-01, -7.5602e-01],\n",
            "        [ 5.5471e-01,  1.0000e+00,  9.4908e-01,  ..., -2.5470e-01,\n",
            "          4.0763e-01, -9.2466e-01]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5470,  1.0000,  0.8794,  ...,  0.5365,  0.3939, -0.8750],\n",
            "        [ 0.4670,  1.0000,  0.8692,  ..., -0.4391,  0.6656, -0.9551],\n",
            "        [ 0.5483,  1.0000,  0.7528,  ..., -0.2364,  0.5342, -0.8260],\n",
            "        ...,\n",
            "        [ 0.3843,  1.0000,  0.5905,  ..., -0.8137,  0.5316, -0.9419],\n",
            "        [ 0.0904,  1.0000, -0.2461,  ..., -0.9243,  0.7770, -0.9247],\n",
            "        [ 0.5418,  1.0000,  0.8659,  ..., -0.7089,  0.8342, -0.9110]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6805,  1.0000,  0.9157,  ...,  0.2138,  0.6855, -0.8853],\n",
            "        [ 0.6186,  1.0000,  0.8921,  ...,  0.7483, -0.1607, -0.7417],\n",
            "        [-0.0968,  1.0000,  0.3765,  ..., -0.8700,  0.6347, -0.9662],\n",
            "        ...,\n",
            "        [ 0.0552,  1.0000, -0.5769,  ..., -0.8666,  0.6716, -0.7942],\n",
            "        [ 0.6486,  1.0000,  0.8413,  ...,  0.4454, -0.0917, -0.7178],\n",
            "        [ 0.0591,  1.0000, -0.3549,  ..., -0.9099,  0.8720, -0.8865]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6153,  1.0000,  0.8775,  ...,  0.7003,  0.1639, -0.6117],\n",
            "        [ 0.6370,  1.0000,  0.9024,  ...,  0.6826, -0.3136, -0.6186],\n",
            "        [ 0.3419,  1.0000,  0.8699,  ..., -0.8133,  0.8111, -0.9757],\n",
            "        ...,\n",
            "        [ 0.6806,  1.0000,  0.8444,  ...,  0.5618, -0.0066, -0.7950],\n",
            "        [-0.1138,  1.0000, -0.4467,  ..., -0.9095,  0.6056, -0.8393],\n",
            "        [ 0.7547,  1.0000,  0.7997,  ...,  0.6518, -0.1234, -0.7705]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0642,  1.0000,  0.0851,  ..., -0.8379,  0.8912, -0.8726],\n",
            "        [ 0.5010,  1.0000,  0.7441,  ..., -0.1420,  0.5233, -0.8760],\n",
            "        [-0.0012,  1.0000,  0.8917,  ...,  0.5266,  0.3364, -0.8640],\n",
            "        ...,\n",
            "        [ 0.3339,  1.0000,  0.3971,  ..., -0.8740,  0.9274, -0.9641],\n",
            "        [-0.0784,  1.0000,  0.6511,  ..., -0.9416,  0.5713, -0.9274],\n",
            "        [ 0.2836,  1.0000, -0.3154,  ..., -0.8533,  0.8442, -0.8785]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2449,  1.0000,  0.6248,  ..., -0.3503,  0.5879, -0.7855],\n",
            "        [ 0.7128,  1.0000,  0.8824,  ...,  0.4634, -0.1603, -0.7006],\n",
            "        [-0.5340,  1.0000, -0.0087,  ..., -0.8298,  0.7883, -0.7885],\n",
            "        ...,\n",
            "        [ 0.6699,  1.0000,  0.5975,  ..., -0.8769,  0.7898, -0.9836],\n",
            "        [ 0.3170,  1.0000,  0.7840,  ..., -0.3366,  0.5345, -0.9531],\n",
            "        [-0.0139,  1.0000, -0.2178,  ..., -0.9047,  0.6323, -0.8387]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1224,  1.0000, -0.4302,  ..., -0.9283,  0.8631, -0.9027],\n",
            "        [ 0.7273,  1.0000,  0.8378,  ...,  0.6830,  0.0476, -0.7789],\n",
            "        [ 0.2522,  1.0000, -0.4316,  ..., -0.8889,  0.9104, -0.8992],\n",
            "        ...,\n",
            "        [ 0.4786,  1.0000,  0.7943,  ...,  0.4573,  0.0722, -0.7424],\n",
            "        [ 0.2019,  1.0000,  0.7417,  ..., -0.7589,  0.6894, -0.9745],\n",
            "        [ 0.2950,  1.0000,  0.8798,  ..., -0.5112,  0.4888, -0.9525]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0738,  1.0000, -0.2797,  ..., -0.8375,  0.5664, -0.4706],\n",
            "        [ 0.4556,  1.0000,  0.8541,  ...,  0.5995,  0.1072, -0.8524],\n",
            "        [ 0.5437,  1.0000,  0.8484,  ...,  0.3580,  0.1493, -0.7075],\n",
            "        ...,\n",
            "        [ 0.4831,  1.0000,  0.9210,  ..., -0.1376,  0.3482, -0.7674],\n",
            "        [-0.0691,  1.0000, -0.3219,  ..., -0.8841,  0.7180, -0.8042],\n",
            "        [ 0.3967,  1.0000, -0.2045,  ..., -0.9081,  0.7791, -0.9420]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0790,  1.0000,  0.8941,  ..., -0.7771,  0.6311, -0.9545],\n",
            "        [ 0.4988,  1.0000,  0.7335,  ..., -0.1396,  0.1028, -0.8513],\n",
            "        [ 0.2432,  1.0000,  0.6541,  ..., -0.7590,  0.7213, -0.9613],\n",
            "        ...,\n",
            "        [ 0.6883,  1.0000,  0.8383,  ...,  0.7596,  0.0179, -0.7674],\n",
            "        [ 0.5674,  1.0000,  0.7227,  ..., -0.7081,  0.4167, -0.9193],\n",
            "        [ 0.7265,  1.0000,  0.8447,  ...,  0.7655, -0.1132, -0.5631]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1523,  1.0000,  0.5882,  ..., -0.6284,  0.6509, -0.9203],\n",
            "        [ 0.3691,  1.0000,  0.6972,  ..., -0.6293,  0.3826, -0.9122],\n",
            "        [ 0.6515,  1.0000,  0.8778,  ..., -0.0082,  0.1594, -0.8555],\n",
            "        ...,\n",
            "        [ 0.0623,  1.0000, -0.2860,  ..., -0.8937,  0.7485, -0.8097],\n",
            "        [ 0.3137,  1.0000, -0.5986,  ..., -0.8384,  0.7981, -0.8641],\n",
            "        [-0.1187,  1.0000, -0.2763,  ..., -0.8288,  0.8554, -0.7004]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4150,  1.0000,  0.8769,  ..., -0.4318,  0.8596, -0.8657],\n",
            "        [ 0.2551,  1.0000,  0.8612,  ..., -0.8823,  0.6776, -0.9078],\n",
            "        [-0.3729,  1.0000, -0.2538,  ..., -0.8125,  0.7328, -0.6742],\n",
            "        ...,\n",
            "        [-0.0396,  1.0000, -0.3393,  ..., -0.8810,  0.8247, -0.8550],\n",
            "        [ 0.5622,  1.0000,  0.8662,  ...,  0.8590, -0.0142, -0.6581],\n",
            "        [ 0.7599,  1.0000,  0.8699,  ...,  0.4719,  0.3006, -0.7961]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7525,  1.0000,  0.9161,  ...,  0.5225,  0.3271, -0.8653],\n",
            "        [ 0.5908,  1.0000,  0.8808,  ...,  0.6098,  0.1465, -0.7668],\n",
            "        [ 0.3901,  1.0000, -0.3750,  ..., -0.8303,  0.8974, -0.9635],\n",
            "        ...,\n",
            "        [ 0.7174,  1.0000,  0.8652,  ...,  0.7152,  0.0418, -0.6743],\n",
            "        [-0.0149,  1.0000, -0.3848,  ..., -0.7933,  0.8416, -0.8542],\n",
            "        [ 0.1839,  1.0000, -0.5143,  ..., -0.8995,  0.7786, -0.9028]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2675,  1.0000, -0.5459,  ..., -0.9159,  0.7296, -0.7556],\n",
            "        [ 0.6227,  0.9999,  0.7815,  ...,  0.7477, -0.0437, -0.5486],\n",
            "        [ 0.6470,  1.0000,  0.7915,  ...,  0.5780,  0.0445, -0.4663],\n",
            "        ...,\n",
            "        [ 0.1161,  1.0000,  0.3485,  ..., -0.8015,  0.6055, -0.9658],\n",
            "        [ 0.7307,  1.0000,  0.7855,  ..., -0.3113,  0.6232, -0.9331],\n",
            "        [ 0.1782,  1.0000, -0.3574,  ..., -0.7702,  0.7785, -0.7013]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7089,  1.0000,  0.8880,  ..., -0.3781,  0.5683, -0.9577],\n",
            "        [ 0.5523,  1.0000,  0.8481,  ...,  0.5877,  0.0954, -0.6747],\n",
            "        [ 0.4413,  1.0000, -0.5119,  ..., -0.7098,  0.8291, -0.9005],\n",
            "        ...,\n",
            "        [ 0.1503,  1.0000, -0.2794,  ..., -0.8933,  0.7431, -0.7601],\n",
            "        [-0.3710,  1.0000, -0.4743,  ..., -0.8381,  0.6859, -0.7231],\n",
            "        [ 0.0619,  1.0000, -0.3756,  ..., -0.9433,  0.7390, -0.8767]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6868,  0.9998,  0.8771,  ...,  0.8646, -0.0890, -0.5382],\n",
            "        [-0.0267,  1.0000, -0.5893,  ..., -0.8944,  0.6515, -0.7938],\n",
            "        [ 0.5320,  1.0000,  0.8724,  ...,  0.5245,  0.3687, -0.6776],\n",
            "        ...,\n",
            "        [ 0.6081,  1.0000,  0.8488,  ...,  0.6407, -0.1549, -0.6278],\n",
            "        [-0.2925,  1.0000, -0.3024,  ..., -0.8740,  0.7025, -0.6337],\n",
            "        [ 0.1798,  1.0000,  0.8516,  ..., -0.2380,  0.1868, -0.9040]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7100,  1.0000,  0.8612,  ...,  0.8124, -0.1870, -0.4761],\n",
            "        [ 0.4887,  1.0000,  0.5160,  ...,  0.0015,  0.6497, -0.7683],\n",
            "        [ 0.5941,  1.0000,  0.8533,  ...,  0.7285, -0.2227, -0.6323],\n",
            "        ...,\n",
            "        [ 0.6112,  0.9999,  0.8031,  ...,  0.7904, -0.0552, -0.4468],\n",
            "        [ 0.1725,  1.0000,  0.1855,  ..., -0.8143,  0.8288, -0.9039],\n",
            "        [-0.0402,  1.0000, -0.6306,  ..., -0.8885,  0.6888, -0.6823]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.8502,  1.0000,  0.8252,  ...,  0.0214,  0.0823, -0.9544],\n",
            "        [ 0.3318,  0.9988,  0.8760,  ...,  0.5949, -0.4514, -0.5349],\n",
            "        [ 0.0283,  1.0000, -0.3427,  ..., -0.8907,  0.8415, -0.9457],\n",
            "        ...,\n",
            "        [-0.2063,  1.0000,  0.0063,  ..., -0.9094,  0.5532, -0.7368],\n",
            "        [ 0.2649,  1.0000,  0.7826,  ..., -0.3828,  0.5091, -0.9726],\n",
            "        [ 0.8031,  1.0000,  0.8429,  ...,  0.7039,  0.1780, -0.6977]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4271,  1.0000,  0.7029,  ..., -0.6319,  0.7467, -0.9316],\n",
            "        [ 0.1876,  1.0000,  0.3733,  ..., -0.8731,  0.7745, -0.8321],\n",
            "        [ 0.7258,  0.9975,  0.8635,  ...,  0.8320, -0.0552, -0.4075],\n",
            "        ...,\n",
            "        [-0.0573,  1.0000, -0.5762,  ..., -0.8551,  0.6618, -0.6983],\n",
            "        [ 0.6409,  1.0000,  0.8643,  ...,  0.3723,  0.1868, -0.7272],\n",
            "        [ 0.1172,  1.0000, -0.4886,  ..., -0.8951,  0.6928, -0.7597]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5211,  0.9999,  0.8072,  ...,  0.5276, -0.1021, -0.5520],\n",
            "        [ 0.0256,  1.0000,  0.6094,  ..., -0.7499,  0.8339, -0.9075],\n",
            "        [ 0.6016,  0.9997,  0.8774,  ...,  0.5979, -0.3606, -0.5736],\n",
            "        ...,\n",
            "        [ 0.6773,  1.0000,  0.8549,  ...,  0.5372, -0.2360, -0.5735],\n",
            "        [ 0.8010,  1.0000,  0.8474,  ...,  0.5560,  0.1111, -0.7648],\n",
            "        [ 0.7622,  1.0000,  0.8765,  ...,  0.8552, -0.1865, -0.6497]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4447,  1.0000,  0.7664,  ..., -0.0827,  0.7329, -0.9153],\n",
            "        [ 0.1557,  1.0000,  0.2284,  ..., -0.6448,  0.7039, -0.9583],\n",
            "        [ 0.1990,  1.0000, -0.4256,  ..., -0.8333,  0.6204, -0.7211],\n",
            "        ...,\n",
            "        [ 0.2434,  1.0000,  0.4535,  ..., -0.8604,  0.7676, -0.9300],\n",
            "        [-0.1370,  1.0000, -0.5589,  ..., -0.8175,  0.7037, -0.5397],\n",
            "        [-0.0651,  1.0000, -0.0992,  ..., -0.9022,  0.6352, -0.9509]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6248,  1.0000,  0.8346,  ...,  0.2404,  0.3189, -0.6104],\n",
            "        [ 0.0771,  1.0000, -0.3610,  ..., -0.7352,  0.6375, -0.7460],\n",
            "        [ 0.2849,  1.0000,  0.7694,  ..., -0.7306,  0.3325, -0.9045],\n",
            "        ...,\n",
            "        [ 0.7437,  1.0000,  0.8968,  ...,  0.5182, -0.1531, -0.6261],\n",
            "        [ 0.5907,  1.0000,  0.8431,  ...,  0.5844, -0.0147, -0.6144],\n",
            "        [-0.1569,  1.0000, -0.5838,  ..., -0.8527,  0.5127, -0.6799]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6415,  1.0000,  0.8840,  ...,  0.7710, -0.2757, -0.4340],\n",
            "        [ 0.0625,  1.0000,  0.5986,  ..., -0.7675,  0.7332, -0.8769],\n",
            "        [ 0.4544,  1.0000,  0.8286,  ...,  0.5804, -0.2959, -0.4867],\n",
            "        ...,\n",
            "        [ 0.6212,  1.0000,  0.8475,  ...,  0.6424, -0.3209, -0.6598],\n",
            "        [ 0.5506,  1.0000,  0.8257,  ...,  0.5079,  0.3590, -0.6441],\n",
            "        [ 0.6728,  0.9997,  0.8431,  ...,  0.6857, -0.4370, -0.4450]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6043,  0.9998,  0.8502,  ...,  0.4787, -0.4461, -0.4397],\n",
            "        [-0.1548,  1.0000,  0.3402,  ..., -0.4279,  0.8243, -0.9497],\n",
            "        [ 0.2618,  1.0000,  0.5411,  ..., -0.8029,  0.8076, -0.9790],\n",
            "        ...,\n",
            "        [ 0.5855,  1.0000,  0.8401,  ...,  0.5674, -0.2886, -0.6105],\n",
            "        [ 0.4945,  1.0000,  0.6633,  ...,  0.5123,  0.0555, -0.5864],\n",
            "        [ 0.6427,  1.0000,  0.7875,  ...,  0.1779,  0.0580, -0.6857]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4798,  1.0000,  0.6145,  ...,  0.2605, -0.1333, -0.8134],\n",
            "        [ 0.2428,  1.0000,  0.3304,  ..., -0.8419,  0.4595, -0.9539],\n",
            "        [-0.3532,  1.0000, -0.6021,  ..., -0.8869,  0.7583, -0.6276],\n",
            "        ...,\n",
            "        [ 0.2387,  1.0000, -0.2254,  ..., -0.6925,  0.7602, -0.6972],\n",
            "        [ 0.5105,  1.0000,  0.7180,  ...,  0.3136,  0.4663, -0.8291],\n",
            "        [ 0.4480,  1.0000,  0.6786,  ..., -0.5202,  0.5871, -0.9610]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5759,  1.0000,  0.9010,  ...,  0.6070, -0.1448, -0.6262],\n",
            "        [-0.4729,  1.0000, -0.5411,  ..., -0.8692,  0.4697, -0.7075],\n",
            "        [-0.1887,  1.0000, -0.5318,  ..., -0.8922,  0.4967, -0.5865],\n",
            "        ...,\n",
            "        [ 0.2583,  1.0000,  0.7516,  ..., -0.4558,  0.0514, -0.8517],\n",
            "        [ 0.6001,  1.0000,  0.8606,  ...,  0.7253,  0.1599, -0.7950],\n",
            "        [ 0.5314,  1.0000,  0.8537,  ...,  0.6196, -0.1314, -0.7101]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5124,  1.0000,  0.8016,  ...,  0.0572, -0.0836, -0.7780],\n",
            "        [ 0.5110,  1.0000,  0.7739,  ...,  0.0047,  0.5319, -0.8437],\n",
            "        [-0.3222,  1.0000, -0.4331,  ..., -0.8557,  0.6400, -0.6124],\n",
            "        ...,\n",
            "        [-0.2667,  1.0000, -0.7459,  ..., -0.8185,  0.4234, -0.4596],\n",
            "        [ 0.5582,  1.0000,  0.6859,  ...,  0.1940, -0.1623, -0.6187],\n",
            "        [ 0.6754,  1.0000,  0.8415,  ...,  0.4762, -0.1810, -0.6146]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2977,  1.0000, -0.2750,  ..., -0.8555,  0.7918, -0.9393],\n",
            "        [ 0.4635,  1.0000,  0.8209,  ..., -0.5463,  0.6987, -0.9825],\n",
            "        [-0.4123,  0.9999, -0.4840,  ..., -0.8512,  0.7336, -0.3752],\n",
            "        ...,\n",
            "        [ 0.4520,  1.0000,  0.7595,  ..., -0.6740,  0.6394, -0.9644],\n",
            "        [-0.1694,  1.0000, -0.2746,  ..., -0.9076,  0.6229, -0.8777],\n",
            "        [ 0.0953,  1.0000,  0.6003,  ..., -0.8911,  0.7202, -0.9175]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6576,  1.0000,  0.8683,  ...,  0.1393,  0.3162, -0.8866],\n",
            "        [ 0.4896,  1.0000,  0.6668,  ..., -0.7090,  0.5482, -0.9079],\n",
            "        [-0.1265,  1.0000, -0.6272,  ..., -0.9348,  0.8161, -0.7349],\n",
            "        ...,\n",
            "        [ 0.4936,  1.0000,  0.7406,  ...,  0.3427, -0.2052, -0.7012],\n",
            "        [ 0.6634,  1.0000,  0.7939,  ..., -0.2558,  0.5289, -0.8604],\n",
            "        [-0.4314,  1.0000, -0.0499,  ..., -0.8385,  0.5539, -0.7676]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6562,  1.0000,  0.6888,  ..., -0.3932,  0.5529, -0.9551],\n",
            "        [ 0.1909,  1.0000,  0.0866,  ..., -0.8986,  0.7861, -0.9174],\n",
            "        [ 0.0834,  1.0000,  0.6611,  ..., -0.7270,  0.8967, -0.9863],\n",
            "        ...,\n",
            "        [-0.3229,  0.9999, -0.5034,  ..., -0.8826,  0.5952, -0.5038],\n",
            "        [ 0.2607,  1.0000,  0.3188,  ..., -0.8700,  0.7546, -0.9270],\n",
            "        [-0.0177,  1.0000, -0.5708,  ..., -0.8342,  0.3975, -0.8266]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4247,  1.0000,  0.7785,  ..., -0.2171,  0.1069, -0.8124],\n",
            "        [ 0.5230,  1.0000,  0.8511,  ..., -0.3338,  0.3478, -0.9023],\n",
            "        [-0.2174,  1.0000,  0.1162,  ..., -0.8874,  0.7520, -0.9498],\n",
            "        ...,\n",
            "        [-0.1074,  1.0000, -0.3842,  ..., -0.8415,  0.8694, -0.9032],\n",
            "        [ 0.0612,  1.0000, -0.2544,  ..., -0.8762,  0.7351, -0.8567],\n",
            "        [ 0.4429,  1.0000,  0.7141,  ..., -0.6275,  0.4255, -0.8713]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1004,  1.0000, -0.4844,  ..., -0.9110,  0.6133, -0.9181],\n",
            "        [ 0.0753,  1.0000, -0.2278,  ..., -0.8422,  0.5316, -0.8135],\n",
            "        [ 0.5242,  1.0000,  0.7559,  ..., -0.3983,  0.5848, -0.9639],\n",
            "        ...,\n",
            "        [ 0.0029,  1.0000, -0.6214,  ..., -0.8856,  0.5835, -0.5555],\n",
            "        [ 0.3016,  1.0000,  0.7630,  ..., -0.8330,  0.6029, -0.9690],\n",
            "        [ 0.5183,  1.0000,  0.3745,  ..., -0.6811,  0.7265, -0.9570]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7229,  1.0000,  0.9036,  ..., -0.1308,  0.1567, -0.9069],\n",
            "        [ 0.6366,  1.0000,  0.8719,  ..., -0.2190,  0.1627, -0.9586],\n",
            "        [-0.0783,  1.0000, -0.5849,  ..., -0.8782,  0.6207, -0.7348],\n",
            "        ...,\n",
            "        [ 0.6181,  1.0000,  0.8501,  ..., -0.1027,  0.4425, -0.9230],\n",
            "        [ 0.5862,  1.0000,  0.8915,  ..., -0.0500, -0.0981, -0.8122],\n",
            "        [ 0.6536,  1.0000,  0.8563,  ..., -0.2278,  0.3452, -0.9378]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6182,  1.0000,  0.8929,  ..., -0.2617,  0.2398, -0.8395],\n",
            "        [ 0.5895,  1.0000,  0.8566,  ..., -0.4240,  0.4516, -0.9195],\n",
            "        [ 0.5732,  1.0000,  0.7912,  ..., -0.3546,  0.5014, -0.9388],\n",
            "        ...,\n",
            "        [ 0.6360,  1.0000,  0.8029,  ..., -0.1487,  0.1188, -0.7608],\n",
            "        [ 0.2470,  1.0000,  0.4014,  ..., -0.8578,  0.7448, -0.9570],\n",
            "        [ 0.1601,  1.0000,  0.0076,  ..., -0.9156,  0.6952, -0.9166]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2690,  1.0000, -0.7322,  ..., -0.8525,  0.2835, -0.6363],\n",
            "        [ 0.2923,  1.0000,  0.7075,  ..., -0.7882,  0.7080, -0.9318],\n",
            "        [ 0.4119,  1.0000,  0.7992,  ..., -0.2481,  0.4921, -0.9335],\n",
            "        ...,\n",
            "        [ 0.2887,  1.0000,  0.8309,  ..., -0.1704,  0.2730, -0.8919],\n",
            "        [ 0.1397,  1.0000,  0.8343,  ...,  0.0111,  0.0070, -0.6674],\n",
            "        [ 0.6147,  1.0000,  0.9189,  ...,  0.4984,  0.2158, -0.9033]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0364,  1.0000, -0.1821,  ..., -0.7855,  0.6387, -0.8518],\n",
            "        [ 0.4940,  1.0000,  0.4765,  ..., -0.8591,  0.6194, -0.9425],\n",
            "        [-0.0346,  1.0000, -0.4395,  ..., -0.9389,  0.5735, -0.8935],\n",
            "        ...,\n",
            "        [ 0.2389,  1.0000,  0.0540,  ..., -0.7915,  0.8098, -0.8778],\n",
            "        [ 0.5544,  1.0000,  0.8567,  ..., -0.4336,  0.7381, -0.9526],\n",
            "        [ 0.5397,  1.0000,  0.9049,  ..., -0.2990,  0.5053, -0.8716]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6272,  1.0000,  0.8511,  ...,  0.1758,  0.1693, -0.8733],\n",
            "        [ 0.4182,  1.0000,  0.6828,  ..., -0.7787,  0.3792, -0.9401],\n",
            "        [ 0.5265,  1.0000,  0.7945,  ..., -0.5726,  0.7348, -0.9647],\n",
            "        ...,\n",
            "        [ 0.6996,  1.0000,  0.8059,  ..., -0.1501,  0.3874, -0.9451],\n",
            "        [-0.0965,  1.0000, -0.4617,  ..., -0.9219,  0.5348, -0.8664],\n",
            "        [ 0.6981,  1.0000,  0.8712,  ...,  0.2379,  0.2556, -0.8932]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6420,  1.0000,  0.8188,  ..., -0.5680,  0.3731, -0.9585],\n",
            "        [ 0.4855,  1.0000,  0.8358,  ..., -0.4113,  0.4956, -0.9146],\n",
            "        [ 0.4532,  1.0000,  0.8296,  ..., -0.2099,  0.2822, -0.9095],\n",
            "        ...,\n",
            "        [-0.2965,  1.0000, -0.0733,  ..., -0.7844,  0.2592, -0.8492],\n",
            "        [ 0.1149,  1.0000, -0.3273,  ..., -0.8771,  0.4411, -0.8265],\n",
            "        [-0.1034,  1.0000, -0.6235,  ..., -0.9062,  0.5347, -0.7661]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5852,  1.0000,  0.8576,  ..., -0.0208,  0.2906, -0.8530],\n",
            "        [ 0.6724,  1.0000,  0.8490,  ..., -0.1290,  0.3747, -0.9355],\n",
            "        [ 0.6661,  1.0000,  0.8240,  ...,  0.1498,  0.3940, -0.9108],\n",
            "        ...,\n",
            "        [ 0.3399,  1.0000,  0.5688,  ..., -0.4848,  0.8315, -0.9414],\n",
            "        [ 0.7212,  1.0000,  0.8812,  ...,  0.1864,  0.5502, -0.9051],\n",
            "        [ 0.6840,  1.0000,  0.8844,  ...,  0.1670, -0.0493, -0.8390]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5714,  1.0000, -0.4052,  ..., -0.8130,  0.6700, -0.8488],\n",
            "        [ 0.5446,  1.0000,  0.6754,  ..., -0.6670,  0.4150, -0.9298],\n",
            "        [-0.1353,  1.0000, -0.3675,  ..., -0.9227,  0.6340, -0.8641],\n",
            "        ...,\n",
            "        [ 0.5150,  1.0000,  0.9046,  ..., -0.6565,  0.5697, -0.9487],\n",
            "        [ 0.7233,  1.0000,  0.8618,  ..., -0.4526,  0.4335, -0.9482],\n",
            "        [ 0.2388,  1.0000, -0.2331,  ..., -0.8479,  0.4838, -0.8544]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7221,  1.0000,  0.8331,  ...,  0.0591,  0.3904, -0.9184],\n",
            "        [ 0.7285,  1.0000,  0.9111,  ..., -0.2447,  0.5459, -0.9575],\n",
            "        [-0.0283,  1.0000, -0.2088,  ..., -0.9007,  0.5018, -0.7815],\n",
            "        ...,\n",
            "        [ 0.5503,  1.0000,  0.8686,  ..., -0.5778,  0.6387, -0.9692],\n",
            "        [ 0.6053,  1.0000,  0.8472,  ..., -0.1354,  0.4848, -0.9413],\n",
            "        [-0.2203,  1.0000, -0.5184,  ..., -0.8496,  0.2976, -0.7075]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2241,  1.0000, -0.3332,  ..., -0.9353,  0.3368, -0.6695],\n",
            "        [ 0.0846,  1.0000,  0.2180,  ..., -0.8366,  0.6125, -0.9200],\n",
            "        [ 0.0736,  1.0000,  0.5741,  ..., -0.5273,  0.5431, -0.9140],\n",
            "        ...,\n",
            "        [ 0.8027,  1.0000,  0.9265,  ...,  0.0104,  0.4561, -0.9259],\n",
            "        [ 0.6736,  1.0000,  0.8387,  ..., -0.3978,  0.5657, -0.9327],\n",
            "        [ 0.3547,  1.0000,  0.5316,  ..., -0.8210,  0.6465, -0.8596]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3934,  0.9999, -0.7950,  ..., -0.9123,  0.5311, -0.1209],\n",
            "        [-0.3341,  1.0000, -0.4572,  ..., -0.8727,  0.3449, -0.7623],\n",
            "        [ 0.4506,  1.0000,  0.8606,  ..., -0.1289,  0.4279, -0.8601],\n",
            "        ...,\n",
            "        [ 0.4607,  1.0000,  0.9224,  ..., -0.4151,  0.6107, -0.9538],\n",
            "        [-0.0716,  1.0000, -0.3578,  ..., -0.8201,  0.3026, -0.8039],\n",
            "        [ 0.4900,  1.0000,  0.8065,  ..., -0.6940,  0.6921, -0.9550]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7792,  1.0000,  0.8474,  ..., -0.0425,  0.3644, -0.9578],\n",
            "        [ 0.5956,  1.0000,  0.8316,  ...,  0.0596,  0.7098, -0.9415],\n",
            "        [ 0.5543,  1.0000,  0.8114,  ..., -0.7860,  0.7078, -0.9621],\n",
            "        ...,\n",
            "        [ 0.3721,  1.0000,  0.3896,  ..., -0.8512,  0.7157, -0.9174],\n",
            "        [ 0.2678,  1.0000,  0.2400,  ..., -0.7492,  0.7742, -0.9703],\n",
            "        [-0.0862,  0.9999, -0.6881,  ..., -0.9297,  0.2750, -0.4175]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7589,  1.0000,  0.8616,  ...,  0.2851,  0.4037, -0.9597],\n",
            "        [ 0.5395,  1.0000,  0.8470,  ..., -0.0438,  0.4914, -0.9142],\n",
            "        [ 0.7618,  1.0000,  0.8171,  ...,  0.0598,  0.7804, -0.9679],\n",
            "        ...,\n",
            "        [ 0.6886,  1.0000,  0.8156,  ..., -0.3882,  0.2262, -0.8969],\n",
            "        [-0.0290,  1.0000,  0.0818,  ..., -0.7656,  0.4015, -0.9272],\n",
            "        [ 0.8206,  1.0000,  0.8705,  ...,  0.2819,  0.0212, -0.8391]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0727,  1.0000, -0.3151,  ..., -0.9075,  0.3729, -0.8340],\n",
            "        [-0.1848,  0.9998, -0.7208,  ..., -0.8974,  0.6092, -0.4090],\n",
            "        [-0.1431,  1.0000, -0.5045,  ..., -0.9291,  0.2739, -0.5720],\n",
            "        ...,\n",
            "        [ 0.6670,  1.0000,  0.9199,  ...,  0.4859,  0.0355, -0.8547],\n",
            "        [ 0.7279,  1.0000,  0.8363,  ..., -0.2550,  0.4111, -0.9616],\n",
            "        [ 0.7257,  1.0000,  0.9240,  ...,  0.4970, -0.1430, -0.8053]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4885,  1.0000,  0.1602,  ..., -0.7784,  0.6186, -0.8753],\n",
            "        [ 0.7656,  1.0000,  0.8397,  ...,  0.3328,  0.1051, -0.8943],\n",
            "        [-0.1503,  1.0000, -0.4637,  ..., -0.8690,  0.4010, -0.6638],\n",
            "        ...,\n",
            "        [ 0.7493,  1.0000,  0.8643,  ...,  0.2965,  0.2340, -0.8954],\n",
            "        [ 0.7905,  1.0000,  0.9519,  ...,  0.2913,  0.5645, -0.9787],\n",
            "        [ 0.6435,  1.0000,  0.9053,  ...,  0.4280,  0.3876, -0.8769]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5653,  1.0000,  0.9147,  ..., -0.3139,  0.6979, -0.9828],\n",
            "        [ 0.3660,  1.0000,  0.7817,  ..., -0.3643,  0.4796, -0.9539],\n",
            "        [ 0.5641,  1.0000,  0.6721,  ..., -0.7263,  0.5923, -0.9508],\n",
            "        ...,\n",
            "        [ 0.1042,  1.0000, -0.3068,  ..., -0.8527,  0.3212, -0.9056],\n",
            "        [ 0.7159,  1.0000,  0.8949,  ...,  0.2461,  0.2676, -0.9076],\n",
            "        [ 0.7553,  1.0000,  0.8848,  ...,  0.1650,  0.1015, -0.9125]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5175,  0.9998, -0.8182,  ..., -0.8443,  0.3943, -0.1842],\n",
            "        [ 0.3931,  1.0000,  0.4077,  ..., -0.7525,  0.4591, -0.9685],\n",
            "        [ 0.2955,  1.0000, -0.2180,  ..., -0.7461,  0.7275, -0.8842],\n",
            "        ...,\n",
            "        [ 0.6435,  1.0000,  0.8404,  ..., -0.3243,  0.6773, -0.9634],\n",
            "        [ 0.6178,  1.0000,  0.9067,  ..., -0.0087,  0.2130, -0.9196],\n",
            "        [-0.0136,  1.0000, -0.4480,  ..., -0.8640,  0.2463, -0.6546]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7276,  1.0000,  0.9253,  ...,  0.4786,  0.3796, -0.8544],\n",
            "        [ 0.7653,  1.0000,  0.9042,  ...,  0.5769,  0.2399, -0.7592],\n",
            "        [-0.1981,  1.0000, -0.7471,  ..., -0.8888,  0.1201, -0.2222],\n",
            "        ...,\n",
            "        [ 0.6746,  1.0000,  0.9077,  ...,  0.5829, -0.0060, -0.7171],\n",
            "        [-0.3499,  0.9999, -0.7081,  ..., -0.6664,  0.0080, -0.1831],\n",
            "        [ 0.6604,  1.0000,  0.8872,  ...,  0.4255,  0.1596, -0.8492]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1526,  0.9999, -0.3492,  ..., -0.7342,  0.5064, -0.6351],\n",
            "        [ 0.8145,  1.0000,  0.8688,  ...,  0.5387,  0.3618, -0.8809],\n",
            "        [-0.3139,  1.0000, -0.4188,  ..., -0.8398,  0.6519, -0.8421],\n",
            "        ...,\n",
            "        [ 0.7745,  1.0000,  0.9119,  ...,  0.5482,  0.3064, -0.8993],\n",
            "        [ 0.5568,  1.0000,  0.7674,  ..., -0.5985,  0.5049, -0.9703],\n",
            "        [ 0.6696,  1.0000,  0.8953,  ...,  0.3406,  0.4195, -0.9539]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7556,  1.0000,  0.9326,  ...,  0.3654,  0.3008, -0.9291],\n",
            "        [ 0.7419,  1.0000,  0.9460,  ...,  0.3118,  0.2199, -0.9090],\n",
            "        [-0.1329,  0.9996, -0.5554,  ..., -0.8727,  0.1952, -0.4282],\n",
            "        ...,\n",
            "        [ 0.3333,  1.0000,  0.8975,  ...,  0.3907,  0.3351, -0.7563],\n",
            "        [ 0.5807,  1.0000,  0.8590,  ...,  0.4997,  0.1233, -0.8909],\n",
            "        [-0.3458,  1.0000, -0.3422,  ..., -0.8262,  0.4673, -0.4858]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0351,  0.9987, -0.5888,  ..., -0.7442,  0.6252,  0.1235],\n",
            "        [ 0.5964,  1.0000,  0.8271,  ...,  0.2869,  0.2587, -0.9603],\n",
            "        [ 0.4557,  1.0000,  0.9223,  ...,  0.2532,  0.2888, -0.8908],\n",
            "        ...,\n",
            "        [ 0.6307,  1.0000,  0.9203,  ..., -0.5923,  0.4379, -0.9637],\n",
            "        [ 0.5285,  1.0000,  0.8095,  ...,  0.1142,  0.1509, -0.8081],\n",
            "        [ 0.0573,  1.0000, -0.0927,  ..., -0.9081,  0.5411, -0.8619]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2647,  1.0000,  0.4126,  ..., -0.7695,  0.8593, -0.9228],\n",
            "        [-0.3026,  1.0000, -0.3547,  ..., -0.2909,  0.5658, -0.7318],\n",
            "        [-0.2087,  0.9999, -0.6253,  ..., -0.8515,  0.4441, -0.6030],\n",
            "        ...,\n",
            "        [ 0.0924,  0.9999, -0.4917,  ..., -0.2449,  0.6707, -0.3549],\n",
            "        [-0.2224,  0.9999, -0.3346,  ..., -0.8304,  0.5296, -0.5027],\n",
            "        [-0.0469,  0.9998, -0.7183,  ..., -0.8398,  0.2612, -0.3369]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0389,  1.0000, -0.4576,  ..., -0.8356,  0.4187, -0.6922],\n",
            "        [-0.1523,  1.0000,  0.0558,  ..., -0.6984,  0.5955, -0.9570],\n",
            "        [ 0.5939,  0.9999, -0.1614,  ..., -0.5130,  0.8128, -0.4924],\n",
            "        ...,\n",
            "        [ 0.6855,  1.0000,  0.9380,  ...,  0.4313,  0.1747, -0.8898],\n",
            "        [-0.0552,  0.9998, -0.6559,  ..., -0.8072,  0.4201, -0.4820],\n",
            "        [ 0.7757,  1.0000,  0.9248,  ...,  0.7226,  0.1977, -0.9124]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3090,  0.9997, -0.5660,  ..., -0.8019,  0.5049, -0.3671],\n",
            "        [ 0.8481,  1.0000,  0.9171,  ...,  0.3123,  0.4633, -0.8550],\n",
            "        [-0.1172,  1.0000, -0.5761,  ..., -0.8267,  0.5394, -0.5753],\n",
            "        ...,\n",
            "        [ 0.2388,  1.0000, -0.2121,  ..., -0.7640,  0.7747, -0.9249],\n",
            "        [ 0.6031,  1.0000,  0.8963,  ..., -0.0277,  0.6351, -0.9463],\n",
            "        [-0.1267,  0.9999, -0.6918,  ..., -0.7463,  0.5560, -0.4313]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 1.9661e-01,  1.0000e+00, -2.1724e-01,  ..., -6.7600e-01,\n",
            "          6.0604e-01, -6.0292e-01],\n",
            "        [ 4.6648e-01,  1.0000e+00,  9.0692e-01,  ...,  3.2409e-01,\n",
            "          1.2583e-01, -7.1715e-01],\n",
            "        [ 3.7075e-01,  1.0000e+00,  7.7576e-01,  ..., -5.4857e-01,\n",
            "          6.7057e-01, -9.6985e-01],\n",
            "        ...,\n",
            "        [ 1.5669e-01,  9.9999e-01, -4.8033e-01,  ..., -7.7382e-01,\n",
            "          3.7972e-01, -6.3142e-04],\n",
            "        [ 2.3027e-01,  9.9998e-01, -2.4025e-01,  ..., -5.9738e-01,\n",
            "          6.3547e-01, -2.0586e-01],\n",
            "        [ 7.1881e-01,  1.0000e+00,  9.3568e-01,  ...,  3.0536e-01,\n",
            "          2.4883e-01, -9.5115e-01]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4534,  1.0000, -0.4929,  ..., -0.6163,  0.5872, -0.6118],\n",
            "        [ 0.2325,  1.0000,  0.6739,  ..., -0.6915,  0.5740, -0.8914],\n",
            "        [ 0.2509,  1.0000, -0.2455,  ..., -0.4107,  0.6337, -0.5056],\n",
            "        ...,\n",
            "        [ 0.7303,  1.0000,  0.8600,  ..., -0.2622,  0.5865, -0.9769],\n",
            "        [-0.1778,  1.0000,  0.2716,  ..., -0.7511,  0.8534, -0.7295],\n",
            "        [ 0.7442,  1.0000,  0.9371,  ...,  0.0535,  0.5711, -0.9683]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7287,  1.0000,  0.9040,  ...,  0.3053,  0.1817, -0.8995],\n",
            "        [ 0.8607,  1.0000,  0.5122,  ..., -0.1052,  0.8309, -0.6880],\n",
            "        [ 0.4987,  1.0000, -0.3844,  ..., -0.5739,  0.6940, -0.7615],\n",
            "        ...,\n",
            "        [ 0.0292,  0.9999, -0.5368,  ..., -0.7385,  0.4569, -0.5362],\n",
            "        [-0.0206,  1.0000, -0.3976,  ..., -0.7192,  0.7223, -0.7754],\n",
            "        [ 0.3903,  1.0000, -0.1494,  ..., -0.4140,  0.6478, -0.6304]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0561,  1.0000,  0.3782,  ..., -0.8827,  0.6650, -0.8925],\n",
            "        [ 0.5106,  1.0000,  0.9105,  ...,  0.0033,  0.4485, -0.9235],\n",
            "        [ 0.7121,  1.0000,  0.9295,  ...,  0.4505,  0.0863, -0.7761],\n",
            "        ...,\n",
            "        [-0.0930,  0.9995,  0.5137,  ..., -0.1647,  0.0976, -0.6902],\n",
            "        [ 0.7735,  1.0000,  0.9330,  ...,  0.3237,  0.3346, -0.9294],\n",
            "        [ 0.2442,  1.0000,  0.3144,  ..., -0.5713,  0.7296, -0.8157]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5724,  1.0000, -0.1292,  ..., -0.4308,  0.8554, -0.8714],\n",
            "        [ 0.3079,  1.0000,  0.8053,  ..., -0.3492,  0.1285, -0.7574],\n",
            "        [ 0.5841,  1.0000,  0.3861,  ...,  0.0468,  0.6553, -0.8600],\n",
            "        ...,\n",
            "        [-0.2168,  0.9995,  0.7499,  ..., -0.0683,  0.0130, -0.6777],\n",
            "        [-0.0130,  0.9999,  0.7751,  ...,  0.0459,  0.3192, -0.7432],\n",
            "        [ 0.4499,  1.0000, -0.0635,  ..., -0.4195,  0.7158, -0.6473]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1113,  1.0000, -0.1363,  ..., -0.6586,  0.8964, -0.9333],\n",
            "        [ 0.5733,  1.0000,  0.9501,  ...,  0.0600,  0.6974, -0.9793],\n",
            "        [ 0.7561,  1.0000,  0.1011,  ..., -0.1935,  0.7985, -0.8466],\n",
            "        ...,\n",
            "        [ 0.7799,  1.0000,  0.7518,  ..., -0.2089,  0.4312, -0.9773],\n",
            "        [ 0.7611,  1.0000,  0.9488,  ...,  0.5085,  0.0198, -0.8836],\n",
            "        [ 0.4632,  1.0000,  0.9070,  ..., -0.6142,  0.6734, -0.9786]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.8818,  1.0000,  0.7397,  ...,  0.0414,  0.8652, -0.9614],\n",
            "        [ 0.4022,  1.0000,  0.5459,  ..., -0.3753,  0.6857, -0.9060],\n",
            "        [ 0.5059,  1.0000,  0.8408,  ..., -0.5928,  0.6504, -0.9818],\n",
            "        ...,\n",
            "        [ 0.6706,  1.0000,  0.8252,  ..., -0.4035,  0.7952, -0.9558],\n",
            "        [ 0.3514,  1.0000,  0.6645,  ..., -0.7731,  0.7266, -0.9628],\n",
            "        [ 0.5677,  1.0000,  0.5370,  ..., -0.4351,  0.8530, -0.9619]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6568,  1.0000,  0.8766,  ...,  0.3219,  0.4246, -0.9446],\n",
            "        [ 0.6626,  1.0000,  0.9166,  ..., -0.2901,  0.3393, -0.9740],\n",
            "        [ 0.3788,  1.0000, -0.2829,  ..., -0.4888,  0.7377, -0.9348],\n",
            "        ...,\n",
            "        [ 0.7604,  1.0000,  0.9251,  ..., -0.5873,  0.6766, -0.9718],\n",
            "        [ 0.5122,  1.0000,  0.6916,  ..., -0.6591,  0.8250, -0.9664],\n",
            "        [ 0.7740,  1.0000,  0.8910,  ...,  0.5987, -0.0749, -0.7602]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5764,  1.0000,  0.9491,  ...,  0.4354,  0.3903, -0.9291],\n",
            "        [ 0.2760,  1.0000,  0.9123,  ...,  0.3431,  0.3700, -0.7936],\n",
            "        [ 0.3617,  1.0000,  0.5017,  ..., -0.6145,  0.6412, -0.9563],\n",
            "        ...,\n",
            "        [ 0.5386,  1.0000,  0.9208,  ..., -0.1143,  0.4497, -0.9810],\n",
            "        [ 0.3425,  1.0000,  0.3446,  ..., -0.5834,  0.7985, -0.9690],\n",
            "        [ 0.7919,  1.0000,  0.7014,  ..., -0.6301,  0.8280, -0.9780]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3852,  1.0000,  0.7516,  ..., -0.3251,  0.6509, -0.9176],\n",
            "        [ 0.7930,  1.0000,  0.9114,  ...,  0.3888, -0.0679, -0.8339],\n",
            "        [ 0.6569,  1.0000,  0.8982,  ...,  0.4232, -0.0754, -0.8619],\n",
            "        ...,\n",
            "        [ 0.7528,  1.0000,  0.8628,  ...,  0.4082,  0.3189, -0.9048],\n",
            "        [ 0.7907,  1.0000,  0.9580,  ...,  0.0206,  0.6976, -0.9718],\n",
            "        [ 0.6507,  1.0000,  0.0955,  ..., -0.5362,  0.7095, -0.9076]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7692,  1.0000,  0.9332,  ...,  0.3311,  0.4611, -0.9348],\n",
            "        [ 0.7245,  1.0000,  0.9553,  ..., -0.0561,  0.5629, -0.9432],\n",
            "        [ 0.2817,  1.0000,  0.8433,  ...,  0.2826,  0.2554, -0.7535],\n",
            "        ...,\n",
            "        [ 0.6635,  1.0000,  0.9374,  ...,  0.4075,  0.0959, -0.8755],\n",
            "        [ 0.7824,  1.0000,  0.6978,  ..., -0.3937,  0.8966, -0.9873],\n",
            "        [ 0.7902,  1.0000,  0.9331,  ...,  0.3778,  0.2980, -0.8604]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7921,  1.0000,  0.9705,  ...,  0.2075,  0.4977, -0.9208],\n",
            "        [ 0.7318,  1.0000,  0.9413,  ...,  0.3803,  0.2419, -0.9693],\n",
            "        [ 0.7175,  1.0000,  0.9192,  ...,  0.5216,  0.0492, -0.7851],\n",
            "        ...,\n",
            "        [ 0.5144,  1.0000,  0.7350,  ..., -0.5763,  0.7927, -0.9506],\n",
            "        [ 0.6741,  1.0000, -0.0792,  ..., -0.1130,  0.8648, -0.9226],\n",
            "        [ 0.8291,  1.0000,  0.9070,  ...,  0.1483,  0.5102, -0.9351]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7032,  1.0000,  0.9614,  ..., -0.4731,  0.7617, -0.9707],\n",
            "        [ 0.8376,  1.0000,  0.4633,  ..., -0.6259,  0.8374, -0.9414],\n",
            "        [ 0.6724,  1.0000,  0.9383,  ...,  0.2676,  0.3780, -0.9666],\n",
            "        ...,\n",
            "        [ 0.6041,  1.0000,  0.3888,  ..., -0.4122,  0.6612, -0.8705],\n",
            "        [ 0.6638,  1.0000,  0.8802,  ..., -0.3614,  0.3314, -0.9259],\n",
            "        [ 0.7259,  1.0000,  0.9423,  ...,  0.3663,  0.3457, -0.9208]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4248,  1.0000,  0.6933,  ..., -0.2448,  0.5160, -0.8796],\n",
            "        [ 0.6487,  1.0000,  0.8204,  ..., -0.3880,  0.6606, -0.9871],\n",
            "        [ 0.7328,  1.0000,  0.9242,  ...,  0.5275,  0.1199, -0.9287],\n",
            "        ...,\n",
            "        [ 0.8671,  1.0000,  0.8415,  ...,  0.1388,  0.0887, -0.9156],\n",
            "        [ 0.7018,  1.0000,  0.9391,  ...,  0.5082, -0.0073, -0.8071],\n",
            "        [ 0.6782,  1.0000,  0.9499,  ..., -0.2199,  0.6368, -0.9863]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6509,  1.0000,  0.5176,  ..., -0.6723,  0.8017, -0.9170],\n",
            "        [ 0.6813,  1.0000,  0.9093,  ...,  0.2206,  0.5067, -0.9554],\n",
            "        [ 0.7673,  1.0000,  0.4675,  ..., -0.3438,  0.7994, -0.9474],\n",
            "        ...,\n",
            "        [ 0.6659,  1.0000,  0.9330,  ...,  0.4047,  0.3670, -0.8871],\n",
            "        [ 0.5859,  1.0000,  0.9379,  ..., -0.1398,  0.6046, -0.9383],\n",
            "        [ 0.6643,  1.0000,  0.9613,  ..., -0.1057,  0.3235, -0.9865]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3528,  1.0000,  0.8712,  ..., -0.2716,  0.3889, -0.9782],\n",
            "        [ 0.5800,  1.0000,  0.1436,  ..., -0.7148,  0.7644, -0.9510],\n",
            "        [ 0.6940,  1.0000,  0.9012,  ...,  0.6293,  0.2596, -0.8781],\n",
            "        ...,\n",
            "        [ 0.1726,  1.0000,  0.2390,  ..., -0.7918,  0.7732, -0.9714],\n",
            "        [ 0.7391,  1.0000,  0.9173,  ...,  0.3443,  0.3632, -0.9191],\n",
            "        [ 0.7232,  1.0000,  0.2457,  ..., -0.6930,  0.7707, -0.8988]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5543,  1.0000,  0.8229,  ..., -0.6708,  0.2962, -0.9400],\n",
            "        [ 0.8367,  1.0000,  0.9170,  ..., -0.1007,  0.5023, -0.9600],\n",
            "        [ 0.6696,  1.0000,  0.9376,  ...,  0.3975,  0.1667, -0.8851],\n",
            "        ...,\n",
            "        [ 0.6796,  1.0000,  0.8890,  ..., -0.3478,  0.7413, -0.9949],\n",
            "        [ 0.3071,  1.0000,  0.0439,  ..., -0.7878,  0.6293, -0.6859],\n",
            "        [ 0.7087,  1.0000, -0.1043,  ..., -0.5807,  0.7593, -0.8769]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0172,  1.0000,  0.5089,  ..., -0.6861,  0.8244, -0.9225],\n",
            "        [ 0.7083,  1.0000,  0.9698,  ...,  0.5018,  0.1849, -0.8540],\n",
            "        [ 0.2165,  1.0000,  0.8651,  ...,  0.1843,  0.1995, -0.7857],\n",
            "        ...,\n",
            "        [ 0.4757,  1.0000,  0.9372,  ...,  0.1095,  0.3399, -0.9668],\n",
            "        [ 0.8214,  1.0000,  0.8748,  ...,  0.0239,  0.6579, -0.9701],\n",
            "        [ 0.2280,  1.0000,  0.3185,  ..., -0.8694,  0.6329, -0.9555]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5102,  1.0000, -0.1354,  ..., -0.6594,  0.8002, -0.9009],\n",
            "        [ 0.7235,  1.0000,  0.7670,  ..., -0.7704,  0.6831, -0.9720],\n",
            "        [ 0.8336,  1.0000,  0.9694,  ...,  0.3900,  0.5930, -0.9703],\n",
            "        ...,\n",
            "        [ 0.8560,  1.0000,  0.9420,  ..., -0.5355,  0.4317, -0.9784],\n",
            "        [ 0.1974,  0.9999,  0.8783,  ...,  0.1033,  0.0289, -0.7562],\n",
            "        [ 0.6535,  1.0000,  0.9206,  ..., -0.4769,  0.9000, -0.9836]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7372,  1.0000,  0.9263,  ...,  0.3450,  0.2881, -0.9699],\n",
            "        [ 0.6522,  1.0000,  0.9086,  ...,  0.1268,  0.3757, -0.9223],\n",
            "        [ 0.5113,  1.0000, -0.2854,  ..., -0.7747,  0.7336, -0.8437],\n",
            "        ...,\n",
            "        [ 0.6020,  1.0000, -0.2322,  ..., -0.7541,  0.7607, -0.8502],\n",
            "        [ 0.6141,  1.0000,  0.1907,  ..., -0.7755,  0.7154, -0.8935],\n",
            "        [ 0.7757,  1.0000, -0.0277,  ..., -0.5915,  0.7829, -0.9012]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4645,  1.0000, -0.4214,  ..., -0.6098,  0.6629, -0.8359],\n",
            "        [ 0.7208,  1.0000,  0.9612,  ..., -0.3054,  0.7191, -0.9665],\n",
            "        [ 0.7115,  1.0000,  0.9164,  ..., -0.0389,  0.3419, -0.9595],\n",
            "        ...,\n",
            "        [ 0.4337,  1.0000, -0.2234,  ..., -0.8142,  0.8017, -0.8244],\n",
            "        [ 0.1458,  1.0000,  0.1991,  ..., -0.7778,  0.6582, -0.9256],\n",
            "        [ 0.5620,  1.0000,  0.4164,  ..., -0.8197,  0.7719, -0.9623]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7647,  1.0000,  0.9437,  ...,  0.5297,  0.1081, -0.9660],\n",
            "        [ 0.7717,  1.0000, -0.0951,  ..., -0.6522,  0.8899, -0.9260],\n",
            "        [ 0.3046,  1.0000, -0.0460,  ..., -0.7868,  0.7080, -0.8945],\n",
            "        ...,\n",
            "        [ 0.5762,  1.0000,  0.9149,  ..., -0.0115,  0.2010, -0.9729],\n",
            "        [ 0.4887,  1.0000,  0.7242,  ..., -0.6541,  0.6985, -0.9532],\n",
            "        [ 0.3192,  1.0000,  0.2488,  ..., -0.6835,  0.7045, -0.9397]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7241,  1.0000, -0.1064,  ..., -0.7122,  0.7762, -0.7458],\n",
            "        [ 0.4763,  1.0000,  0.9466,  ..., -0.5991,  0.4231, -0.9600],\n",
            "        [ 0.7091,  1.0000,  0.8146,  ...,  0.2962,  0.3000, -0.9040],\n",
            "        ...,\n",
            "        [ 0.4197,  1.0000,  0.9191,  ..., -0.0239,  0.3292, -0.9187],\n",
            "        [ 0.6754,  1.0000,  0.9365,  ..., -0.3410,  0.5795, -0.9648],\n",
            "        [ 0.2833,  1.0000,  0.5812,  ..., -0.7686,  0.7039, -0.9698]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1236,  1.0000,  0.5180,  ..., -0.6211,  0.8496, -0.9470],\n",
            "        [ 0.6834,  1.0000,  0.9438,  ...,  0.0410,  0.2386, -0.9437],\n",
            "        [ 0.7620,  1.0000,  0.9015,  ...,  0.2054,  0.3417, -0.9269],\n",
            "        ...,\n",
            "        [ 0.2872,  1.0000,  0.1737,  ..., -0.7661,  0.7246, -0.9507],\n",
            "        [ 0.5098,  1.0000,  0.9265,  ...,  0.0051,  0.2026, -0.8749],\n",
            "        [ 0.1873,  1.0000,  0.6992,  ..., -0.6319,  0.7073, -0.9787]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4433,  1.0000,  0.4736,  ..., -0.8015,  0.7672, -0.9214],\n",
            "        [ 0.4189,  1.0000,  0.3456,  ..., -0.8264,  0.7461, -0.9469],\n",
            "        [ 0.8115,  1.0000,  0.9550,  ...,  0.4088,  0.2125, -0.9371],\n",
            "        ...,\n",
            "        [ 0.2702,  1.0000,  0.8536,  ..., -0.5540,  0.6767, -0.8936],\n",
            "        [ 0.2760,  1.0000, -0.1727,  ..., -0.8176,  0.8862, -0.9656],\n",
            "        [ 0.3967,  1.0000,  0.4687,  ..., -0.8981,  0.7261, -0.9585]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6607,  1.0000,  0.6349,  ..., -0.6606,  0.8297, -0.9820],\n",
            "        [ 0.5707,  1.0000,  0.0640,  ..., -0.5970,  0.7697, -0.8898],\n",
            "        [ 0.6256,  1.0000,  0.6090,  ..., -0.7428,  0.7584, -0.9743],\n",
            "        ...,\n",
            "        [ 0.1591,  1.0000,  0.8832,  ..., -0.6117,  0.4196, -0.9628],\n",
            "        [ 0.6041,  1.0000,  0.4225,  ..., -0.8659,  0.6782, -0.9760],\n",
            "        [ 0.3698,  1.0000,  0.8469,  ..., -0.7763,  0.8302, -0.9868]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5157,  1.0000,  0.8991,  ..., -0.0498, -0.0029, -0.9251],\n",
            "        [ 0.3047,  1.0000,  0.1862,  ..., -0.6603,  0.7661, -0.9162],\n",
            "        [ 0.6585,  1.0000,  0.9107,  ..., -0.2685,  0.6054, -0.9735],\n",
            "        ...,\n",
            "        [ 0.3555,  1.0000, -0.2797,  ..., -0.8168,  0.6780, -0.8661],\n",
            "        [ 0.6599,  1.0000,  0.8742,  ...,  0.1692, -0.0189, -0.9547],\n",
            "        [ 0.6380,  1.0000,  0.9139,  ...,  0.0363,  0.3824, -0.8878]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1312,  1.0000, -0.5002,  ..., -0.8774,  0.5644, -0.8440],\n",
            "        [ 0.6457,  1.0000,  0.8935,  ..., -0.6548,  0.7899, -0.9891],\n",
            "        [ 0.3524,  1.0000,  0.0854,  ..., -0.8656,  0.8921, -0.9427],\n",
            "        ...,\n",
            "        [ 0.1613,  1.0000,  0.3889,  ..., -0.7441,  0.8153, -0.9850],\n",
            "        [ 0.6900,  1.0000,  0.8963,  ...,  0.4934, -0.0279, -0.9228],\n",
            "        [ 0.3523,  1.0000,  0.8020,  ..., -0.7912,  0.7930, -0.9733]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6962,  1.0000,  0.8736,  ..., -0.5171,  0.6048, -0.9732],\n",
            "        [ 0.2295,  1.0000,  0.5985,  ..., -0.5958,  0.4068, -0.9662],\n",
            "        [ 0.2369,  1.0000, -0.0055,  ..., -0.7605,  0.5810, -0.8165],\n",
            "        ...,\n",
            "        [ 0.2641,  1.0000, -0.2045,  ..., -0.8673,  0.6927, -0.8597],\n",
            "        [ 0.6111,  1.0000,  0.8324,  ...,  0.1794,  0.0525, -0.9474],\n",
            "        [ 0.7786,  1.0000,  0.8835,  ..., -0.1472,  0.2631, -0.9406]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3250,  1.0000,  0.7089,  ..., -0.8110,  0.4955, -0.9599],\n",
            "        [ 0.3273,  1.0000, -0.0926,  ..., -0.7283,  0.6782, -0.8953],\n",
            "        [ 0.2172,  1.0000,  0.4092,  ..., -0.8932,  0.8052, -0.9361],\n",
            "        ...,\n",
            "        [ 0.2063,  1.0000,  0.7161,  ..., -0.4687,  0.4378, -0.9846],\n",
            "        [ 0.1368,  1.0000, -0.0718,  ..., -0.7940,  0.5586, -0.9336],\n",
            "        [ 0.5458,  1.0000,  0.5514,  ..., -0.4960,  0.6389, -0.8859]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1849,  1.0000,  0.1119, -0.9997,  0.8220,  0.0545,  0.8863, -0.2756,\n",
            "         -1.0000,  0.5348,  0.4432,  0.7129, -0.7024,  1.0000,  0.0700, -0.9220,\n",
            "         -0.2450, -0.9999,  0.9492, -0.8563,  0.4379,  0.3252,  0.8540, -0.7299,\n",
            "         -0.5307, -0.6269,  0.1386,  0.9171, -0.6434,  0.8450, -0.8633, -0.3653,\n",
            "          0.9966,  0.9161,  0.6042, -0.9978, -0.7254, -0.9867, -0.9999, -0.9999,\n",
            "         -0.1863, -0.6006,  1.0000, -0.9221,  0.9994, -0.9994,  0.5091, -0.9003,\n",
            "          0.9269,  0.9153, -0.6894, -0.7970,  0.7994,  0.8582, -0.8800, -0.9996,\n",
            "         -0.5260,  0.9371, -0.8530, -0.1832,  0.4086, -0.8516,  0.0343,  0.7895,\n",
            "         -0.0663,  0.9087,  0.9238,  0.4060,  0.5534, -0.9984, -0.1468, -0.9920,\n",
            "          0.9357, -0.4021,  0.9355,  0.8933, -0.5130, -0.9236, -0.6028,  0.9995,\n",
            "          0.9053,  0.8110,  0.7163, -1.0000, -0.0579, -0.9844,  0.9985, -0.9990,\n",
            "         -0.9976,  0.2644,  0.8013, -0.2151, -0.6821, -0.6031,  0.0226, -0.9812,\n",
            "          0.0824, -0.1837, -1.0000,  0.9169,  0.9401,  0.8910, -0.2955, -0.6759,\n",
            "         -1.0000, -0.4982,  0.4205, -0.9507, -1.0000, -0.9417, -0.9306, -0.7670,\n",
            "          0.4654,  0.9958,  0.1023,  1.0000, -0.2207,  0.9992, -1.0000, -0.9988,\n",
            "          0.1429,  0.9782, -0.7335, -0.7893,  0.8047, -0.9996, -0.9984, -1.0000,\n",
            "          0.8893, -0.5142, -0.5087,  0.9919, -0.2157, -0.9706, -0.9061, -0.3453,\n",
            "         -1.0000,  0.3198, -0.4929, -0.9999,  0.9997,  0.9941, -0.3171, -0.7903,\n",
            "         -0.6831,  0.9945,  0.1245,  0.0731, -0.5386, -0.8420, -0.3069,  0.7066,\n",
            "          0.7569,  0.0750, -1.0000,  0.8520,  0.1069,  0.9920, -0.4040,  0.7336,\n",
            "         -0.9066, -1.0000,  0.9520,  0.8145,  0.7471,  0.5407, -0.8431,  0.9739,\n",
            "          0.4422,  0.7020,  0.9283,  0.8731,  0.7359,  0.9526,  0.8681, -0.9774,\n",
            "         -0.9565, -0.7658,  0.8926, -0.9972,  0.9991, -0.8366,  0.9961, -0.9862,\n",
            "         -0.8983,  0.9061,  0.3136, -1.0000,  0.9907,  0.9302,  0.4682, -0.9475,\n",
            "          0.9022, -0.7919,  0.3955,  0.0539, -0.8911,  0.7651, -0.2542,  0.9974,\n",
            "          0.7191, -0.9995,  0.9997,  0.9884,  0.8603, -0.9937,  0.2750,  0.9987,\n",
            "         -0.9998, -0.9869,  0.4205,  0.0133,  0.5668, -0.8335, -0.9080, -0.9020,\n",
            "          0.9884, -0.9372,  0.9640,  0.4717,  0.7955,  0.0283, -0.9247,  0.1215,\n",
            "          0.3165,  0.9046, -0.3547,  0.5447, -0.8378, -1.0000,  0.3650,  0.5148,\n",
            "          0.7058, -0.5551,  0.9999,  0.5967, -0.5534,  0.9987, -0.9998, -0.4740,\n",
            "          0.0850, -0.9962,  0.9177, -0.3707,  1.0000, -0.9999,  0.9997, -0.2808,\n",
            "          0.8097,  0.8109, -0.8717,  0.6594,  0.9548,  0.8875,  0.7544,  0.9786,\n",
            "         -0.1674, -0.9999,  0.1284,  0.9023, -0.9988,  0.1146, -0.7841, -0.9762,\n",
            "          0.9992,  1.0000, -0.9429,  0.7569,  0.8731,  0.9654,  0.9608, -0.9996,\n",
            "          0.9979,  1.0000, -0.9972, -0.9193,  1.0000,  0.8655, -0.9694,  0.5183,\n",
            "         -0.4125, -0.9998, -0.2576, -0.7636,  0.6791,  0.5600, -0.0952, -0.9995,\n",
            "         -0.9999, -0.9997,  0.9997, -0.1760,  0.6163,  0.2367,  0.5833, -0.8727,\n",
            "          0.8885,  0.9975, -0.9961,  1.0000,  0.9899, -0.9911, -0.9982, -0.7009,\n",
            "          0.4786,  0.8795,  0.9994,  0.0167, -0.9810,  0.6647,  0.9757,  0.2042,\n",
            "          0.9996, -0.4573,  0.6660,  0.1442,  0.8544, -0.9994, -0.9757, -0.3251,\n",
            "          0.8802,  0.9998,  0.7730, -0.7951,  0.9999,  0.3456, -1.0000,  1.0000,\n",
            "          0.9996, -0.9990,  0.1835,  0.4081,  0.8695,  0.5495,  0.6889, -0.8945,\n",
            "         -0.2890, -0.9987,  0.8815,  0.6870,  0.6515,  0.9020,  0.1892,  0.9309,\n",
            "          0.4363,  0.6352,  0.4858, -0.9628, -0.9999, -0.1779,  0.7074,  0.7104,\n",
            "         -0.6798,  0.9987,  0.8576,  1.0000, -0.3730,  0.9991, -0.9307,  0.9031,\n",
            "         -0.3410,  0.8864,  0.7627, -0.9450, -1.0000, -0.4023, -0.8977,  0.9401,\n",
            "          0.4021, -0.9998, -0.9214,  0.7404, -0.8264,  0.3331, -0.5552, -0.8788,\n",
            "          1.0000,  0.9777,  0.6350, -0.7489, -0.7097,  0.8955,  0.9938,  0.7175,\n",
            "          0.9987, -0.8710,  0.9700, -0.8163,  0.8244, -0.3227,  0.0515,  0.3638,\n",
            "          0.1630,  0.9984,  0.9444,  0.9814, -0.8370,  0.6375, -0.9998,  1.0000,\n",
            "          0.3015,  0.8824,  0.9347,  0.6784,  0.7194, -0.7879,  0.9694, -0.9437,\n",
            "          0.9890, -0.8368,  0.8979,  0.1992,  0.8271, -0.8568, -0.5488,  0.6256,\n",
            "          0.4047, -0.9690, -0.9975,  0.9970, -0.9979, -0.6364, -0.9487, -0.7449,\n",
            "          0.9976, -0.8980,  0.4256, -0.7412, -0.9464, -0.8920, -0.6638, -0.9914,\n",
            "          0.2975, -0.9982,  1.0000, -0.9986,  0.9084, -0.8767, -0.4939,  0.8986,\n",
            "          0.4703, -0.6947, -0.2122,  0.4031, -0.7858,  0.9378, -0.4394, -0.4752,\n",
            "          0.5856, -0.4893,  0.4510,  0.9745,  0.6083,  0.9996, -0.4617, -0.9975,\n",
            "         -0.8355, -0.1405,  0.7193,  0.9999, -0.9973,  0.8788,  1.0000, -0.9996,\n",
            "         -0.8688, -0.5013, -1.0000,  0.9331, -0.9130, -0.9989, -0.1621, -0.9368,\n",
            "          0.9158,  0.9986,  1.0000, -0.7425, -0.8653, -0.9991, -0.9237,  0.9866,\n",
            "         -0.9997,  0.8390, -0.9362, -0.9998,  0.9980,  0.8127, -0.4797,  0.5042,\n",
            "          0.4190,  0.9997, -0.3755, -0.9962,  0.8448,  0.8462,  0.1125,  0.8762,\n",
            "         -0.6658, -0.6179, -0.9991,  0.3612,  1.0000, -0.4889, -0.8526,  0.9335,\n",
            "          0.4746,  0.9246,  1.0000, -0.9991,  0.9602,  1.0000, -0.4825,  0.8924,\n",
            "         -0.2065, -0.6418,  0.5381,  0.5928, -0.8384,  1.0000, -0.9347, -0.9934,\n",
            "         -1.0000,  0.3357, -0.9837,  0.8951,  0.9880, -0.8321,  0.6027,  0.1343,\n",
            "         -0.9997,  0.9857, -0.7732, -1.0000, -1.0000,  0.3902, -0.7954, -0.8563,\n",
            "         -0.1099, -0.4765, -0.9822,  1.0000, -0.1431, -1.0000, -0.6654,  0.9824,\n",
            "          0.9990, -0.1594,  0.3767, -0.8995, -0.8741, -0.2507, -1.0000, -0.7031,\n",
            "          0.9896,  0.5846, -0.1024,  1.0000, -0.1870, -0.9358, -0.4536,  0.4201,\n",
            "          0.5606, -1.0000, -0.8749,  1.0000, -0.8370, -0.2461, -0.9168, -0.9024,\n",
            "          0.2979,  0.9374,  0.9945, -0.9988,  1.0000,  0.0618,  0.8821,  0.9883,\n",
            "         -0.5258, -0.9796, -0.9884,  0.4760,  0.7918,  0.3715,  0.3292, -0.9162,\n",
            "          0.9843, -0.1396, -0.9638,  0.7029, -0.7016, -0.7616, -0.6929,  0.9596,\n",
            "          0.7359, -0.7801,  0.9999, -0.5037, -0.9416,  0.6831, -0.1681, -0.5017,\n",
            "         -1.0000, -0.1104,  0.6673, -0.9947, -0.6681,  0.6589, -0.7930, -0.6311,\n",
            "          0.9240, -0.6253,  0.3872,  0.9997,  0.9661,  0.9352, -0.9966, -1.0000,\n",
            "         -0.4218,  0.7706, -0.9882,  0.7482, -0.8103,  1.0000, -0.2628,  0.7999,\n",
            "          0.9077,  1.0000, -0.1373,  0.9627,  0.0554,  0.3973, -0.9948,  0.9749,\n",
            "         -0.5071, -0.9988, -0.8724, -0.4552, -0.6739, -0.5951, -0.7653,  0.5126,\n",
            "          1.0000,  0.0863,  0.8841,  0.8036, -0.7911, -0.2192, -0.9519,  0.9985,\n",
            "         -1.0000,  0.9932,  0.5310, -0.6772,  0.8300, -0.5935, -0.8756, -0.8074,\n",
            "         -0.6396, -0.9744, -0.5775, -0.2875, -0.9167,  0.4683,  0.9634, -0.9374,\n",
            "         -1.0000,  0.7403, -0.0450,  0.9857,  0.2879, -0.8372,  0.9637,  0.5441,\n",
            "          0.9935, -0.8741, -0.6159, -0.9535, -0.7674, -0.0044,  0.8557,  0.9434,\n",
            "          0.3933,  0.1003,  0.1784, -0.6200,  0.0956,  0.0014,  0.5000,  0.0970,\n",
            "          0.9716,  0.8743,  0.9370,  0.9989,  0.4609, -0.8755,  0.7613, -0.7019,\n",
            "          0.3811, -1.0000,  1.0000,  0.4069, -0.8787, -1.0000,  0.1109,  0.4990,\n",
            "          0.4338,  0.6232, -0.4407, -0.9199, -0.5636,  0.7697, -1.0000,  0.1182,\n",
            "         -0.5855, -0.8160,  0.4646, -1.0000, -0.7169,  0.6586, -0.8981,  0.0136,\n",
            "          1.0000, -0.9860, -0.9989, -0.9990, -0.6221,  0.5686,  0.8546, -0.9942,\n",
            "         -0.1875,  0.9118, -0.9999,  0.5354, -0.0196,  0.3696,  0.5435, -0.1893,\n",
            "          0.9979, -1.0000,  0.8431, -0.6019,  0.8124,  0.6962, -0.0610,  0.7651,\n",
            "          0.6219, -1.0000,  0.5259,  0.7467,  0.9648,  0.9312, -0.2117, -0.5361,\n",
            "         -0.0914, -0.6544,  0.9981,  0.9561, -0.8070,  0.9035,  1.0000,  0.7154,\n",
            "          0.9726, -0.4896, -0.9575, -0.9995, -0.9528, -0.7763,  0.6558, -0.8065]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluation... :   0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "893286436692404194cfef6c856cdc67"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7535,  1.0000,  0.9027,  ...,  0.3799, -0.0028, -0.9045],\n",
            "        [ 0.7451,  1.0000,  0.8999,  ...,  0.6153, -0.0569, -0.8505],\n",
            "        [ 0.5534,  1.0000, -0.1749,  ..., -0.8932,  0.8573, -0.8818],\n",
            "        ...,\n",
            "        [ 0.3857,  1.0000,  0.9295,  ..., -0.0559,  0.4312, -0.9507],\n",
            "        [ 0.0306,  1.0000,  0.4702,  ..., -0.6725,  0.6784, -0.9419],\n",
            "        [ 0.1539,  1.0000, -0.4176,  ..., -0.7466,  0.6199, -0.8022]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5458,  1.0000,  0.8626,  ..., -0.1663,  0.2316, -0.9418],\n",
            "        [ 0.5214,  1.0000,  0.8134,  ..., -0.5471,  0.5271, -0.9709],\n",
            "        [ 0.5808,  1.0000,  0.9219,  ...,  0.0530,  0.3006, -0.8166],\n",
            "        ...,\n",
            "        [ 0.3230,  1.0000,  0.8509,  ..., -0.6297,  0.6067, -0.9825],\n",
            "        [ 0.5342,  1.0000,  0.8699,  ..., -0.8041,  0.7346, -0.9819],\n",
            "        [ 0.6822,  1.0000,  0.9257,  ..., -0.4167,  0.7277, -0.9929]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6366,  1.0000,  0.9145,  ...,  0.4538,  0.0254, -0.8645],\n",
            "        [ 0.5433,  1.0000,  0.9112,  ...,  0.3901,  0.1418, -0.7429],\n",
            "        [ 0.7239,  1.0000,  0.9226,  ...,  0.4146,  0.3656, -0.9450],\n",
            "        ...,\n",
            "        [ 0.5430,  1.0000,  0.8990,  ..., -0.2324,  0.6111, -0.9680],\n",
            "        [ 0.0827,  1.0000,  0.4902,  ..., -0.7945,  0.6784, -0.8509],\n",
            "        [ 0.5582,  1.0000,  0.9246,  ..., -0.3448,  0.6433, -0.9805]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3910,  1.0000,  0.8374,  ..., -0.3077,  0.2656, -0.9643],\n",
            "        [ 0.5328,  1.0000,  0.8816,  ..., -0.5003,  0.7421, -0.9867],\n",
            "        [ 0.5835,  1.0000,  0.9090,  ..., -0.6707,  0.7758, -0.9944],\n",
            "        ...,\n",
            "        [ 0.7353,  1.0000,  0.9034,  ...,  0.6579, -0.0293, -0.8032],\n",
            "        [ 0.0214,  1.0000,  0.2638,  ..., -0.8589,  0.7935, -0.9504],\n",
            "        [ 0.6917,  1.0000,  0.9145,  ...,  0.6522,  0.0334, -0.7626]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6981,  1.0000,  0.9328,  ..., -0.1437,  0.3708, -0.9613],\n",
            "        [ 0.5141,  1.0000,  0.9187,  ..., -0.0227,  0.7545, -0.9630],\n",
            "        [ 0.6568,  1.0000,  0.7064,  ..., -0.5510,  0.6358, -0.9749],\n",
            "        ...,\n",
            "        [ 0.4258,  1.0000,  0.8590,  ..., -0.6489,  0.7016, -0.9857],\n",
            "        [ 0.6630,  1.0000,  0.9268,  ...,  0.3960,  0.1460, -0.8985],\n",
            "        [ 0.4005,  1.0000,  0.8982,  ...,  0.3958,  0.2734, -0.7692]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6529,  1.0000,  0.8817,  ...,  0.5808,  0.1279, -0.7319],\n",
            "        [ 0.6527,  1.0000,  0.8265,  ..., -0.4031,  0.6127, -0.9815],\n",
            "        [ 0.4949,  1.0000, -0.4134,  ..., -0.7713,  0.8229, -0.8837],\n",
            "        ...,\n",
            "        [ 0.6560,  1.0000, -0.3077,  ..., -0.8955,  0.8812, -0.8590],\n",
            "        [ 0.5647,  1.0000,  0.6975,  ..., -0.4655,  0.4813, -0.9632],\n",
            "        [ 0.5915,  1.0000,  0.9291,  ...,  0.3574,  0.1211, -0.9190]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5087,  1.0000,  0.6925,  ..., -0.8203,  0.6436, -0.9765],\n",
            "        [ 0.1344,  1.0000,  0.2540,  ..., -0.9156,  0.7639, -0.9621],\n",
            "        [ 0.8017,  1.0000,  0.9015,  ...,  0.4848,  0.0254, -0.8770],\n",
            "        ...,\n",
            "        [ 0.4492,  1.0000,  0.8486,  ..., -0.6952,  0.5565, -0.9551],\n",
            "        [ 0.7202,  1.0000,  0.9211,  ...,  0.6701,  0.0471, -0.8092],\n",
            "        [ 0.3716,  1.0000,  0.7354,  ..., -0.6286,  0.6895, -0.9798]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7551,  1.0000,  0.9301,  ...,  0.6157,  0.1676, -0.9067],\n",
            "        [ 0.6937,  1.0000,  0.9352,  ...,  0.6613, -0.0059, -0.8295],\n",
            "        [ 0.7796,  1.0000,  0.9171,  ...,  0.6059, -0.1611, -0.7793],\n",
            "        ...,\n",
            "        [ 0.6562,  1.0000,  0.9268,  ...,  0.4201,  0.0384, -0.8725],\n",
            "        [ 0.5598,  1.0000,  0.9095,  ...,  0.2708,  0.4273, -0.8884],\n",
            "        [ 0.6355,  1.0000,  0.8708,  ..., -0.4688,  0.7333, -0.9776]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7343,  1.0000,  0.9136,  ...,  0.6472, -0.0988, -0.7838],\n",
            "        [ 0.3581,  1.0000, -0.0231,  ..., -0.7753,  0.6815, -0.9008],\n",
            "        [ 0.1455,  1.0000,  0.8290,  ..., -0.7992,  0.7031, -0.9469],\n",
            "        ...,\n",
            "        [ 0.5643,  1.0000,  0.9001,  ...,  0.4088,  0.3533, -0.7610],\n",
            "        [ 0.0702,  1.0000, -0.2754,  ..., -0.8640,  0.7384, -0.8967],\n",
            "        [ 0.6366,  1.0000,  0.9016,  ...,  0.6101, -0.0309, -0.7963]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3851,  1.0000, -0.4761,  ..., -0.8359,  0.6403, -0.8010],\n",
            "        [ 0.6003,  1.0000,  0.8392,  ..., -0.1683,  0.4686, -0.9559],\n",
            "        [ 0.6926,  1.0000,  0.9122,  ...,  0.3800,  0.1236, -0.8373],\n",
            "        ...,\n",
            "        [ 0.6664,  1.0000,  0.8763,  ...,  0.4734, -0.0649, -0.8385],\n",
            "        [ 0.6356,  1.0000,  0.8555,  ...,  0.4803,  0.0263, -0.7428],\n",
            "        [ 0.7463,  1.0000,  0.9297,  ...,  0.7089, -0.0934, -0.7584]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4041,  1.0000,  0.3244,  ..., -0.7965,  0.7916, -0.9525],\n",
            "        [ 0.1214,  1.0000, -0.1691,  ..., -0.8844,  0.6037, -0.7848],\n",
            "        [ 0.7656,  1.0000,  0.8583,  ..., -0.2144,  0.5398, -0.9741],\n",
            "        ...,\n",
            "        [ 0.7152,  1.0000,  0.9249,  ...,  0.1549,  0.4155, -0.9617],\n",
            "        [ 0.5003,  1.0000,  0.0482,  ..., -0.7975,  0.6076, -0.9426],\n",
            "        [ 0.7513,  1.0000,  0.9284,  ...,  0.4995, -0.0224, -0.8515]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5322,  1.0000,  0.9025,  ...,  0.2669,  0.3263, -0.8031],\n",
            "        [ 0.3175,  1.0000, -0.0487,  ..., -0.8141,  0.7970, -0.9511],\n",
            "        [ 0.0916,  1.0000,  0.5516,  ..., -0.8776,  0.4812, -0.9396],\n",
            "        ...,\n",
            "        [ 0.2025,  1.0000, -0.0562,  ..., -0.8730,  0.7320, -0.9211],\n",
            "        [ 0.6853,  1.0000,  0.9051,  ..., -0.5606,  0.7322, -0.9855],\n",
            "        [ 0.2142,  1.0000,  0.5040,  ..., -0.7849,  0.8187, -0.9326]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6171,  1.0000,  0.2613,  ..., -0.3196,  0.8638, -0.9096],\n",
            "        [ 0.4151,  1.0000,  0.8480,  ..., -0.2499,  0.7262, -0.9645],\n",
            "        [ 0.1588,  1.0000, -0.3463,  ..., -0.8882,  0.5355, -0.6825],\n",
            "        ...,\n",
            "        [ 0.0553,  1.0000,  0.8050,  ..., -0.5580,  0.5837, -0.9731],\n",
            "        [ 0.6153,  1.0000, -0.1549,  ..., -0.8149,  0.7616, -0.8844],\n",
            "        [ 0.1249,  1.0000,  0.1912,  ..., -0.6887,  0.6062, -0.9390]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6022,  1.0000,  0.9056,  ..., -0.6214,  0.2406, -0.9635],\n",
            "        [ 0.6555,  1.0000,  0.8605,  ..., -0.7035,  0.7848, -0.9801],\n",
            "        [ 0.0897,  1.0000, -0.3987,  ..., -0.7581,  0.4147, -0.8718],\n",
            "        ...,\n",
            "        [ 0.5378,  1.0000,  0.8847,  ..., -0.3716,  0.1842, -0.9610],\n",
            "        [ 0.5662,  1.0000,  0.8661,  ...,  0.1114,  0.8157, -0.9519],\n",
            "        [ 0.6312,  1.0000,  0.8688,  ...,  0.4600,  0.0977, -0.8658]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4214,  1.0000,  0.8607, -0.9967,  0.3887,  0.8983,  0.9608,  0.9159,\n",
            "         -0.9999, -0.8881,  0.9317, -0.8187, -0.6111,  1.0000, -0.6430, -0.7980,\n",
            "          0.9640, -0.9997,  0.9689, -0.9749,  0.8162, -0.2800,  0.9898, -0.8958,\n",
            "          0.8517,  0.8630, -0.5018,  0.9375, -0.8260,  0.8808, -0.7331, -0.9390,\n",
            "          0.9856,  0.8964,  0.9903, -0.9985, -0.8538, -0.9962, -0.9993, -0.9999,\n",
            "         -0.9899, -0.8489,  1.0000, -0.9081,  0.9999, -0.9995, -0.2915, -0.6793,\n",
            "          0.9731,  0.8322, -0.9801,  0.9688,  0.9369,  0.9905, -0.5767, -0.9987,\n",
            "         -0.9387,  0.9422, -0.9890, -0.2601,  0.9666, -0.0824, -0.8939,  0.1684,\n",
            "         -0.9773,  0.4972,  0.8180,  0.8795, -0.9483, -0.9923,  0.9645, -0.9801,\n",
            "          0.9697, -0.7921,  0.2544,  0.9854, -0.9194,  0.4347, -0.9264,  0.9982,\n",
            "          0.8637,  0.8383,  0.9082, -1.0000,  0.9531, -0.9735,  0.9992, -0.9995,\n",
            "         -0.9997,  0.9468,  0.9253,  0.9701,  0.8993, -0.8091, -0.8956, -0.9519,\n",
            "         -0.5019,  0.8086, -1.0000,  0.9489,  0.9463,  0.9631, -0.4777, -0.9106,\n",
            "         -1.0000,  0.3969, -0.7897, -0.9439, -1.0000, -0.9529, -0.8040, -0.9622,\n",
            "         -0.8578,  0.9984,  0.5920,  1.0000,  0.9653,  0.9997, -1.0000, -0.9967,\n",
            "          0.8640,  0.9907, -0.8980, -0.8335,  0.7727, -0.9983, -0.9139, -1.0000,\n",
            "          0.9549, -0.9936, -0.9695,  0.9916,  0.9712, -0.8951, -0.9505,  0.5246,\n",
            "         -1.0000,  0.6005, -0.9903, -0.9998,  0.9981,  0.9918,  0.8215, -0.9706,\n",
            "         -0.7637,  0.9948,  0.9594, -0.8312, -0.7593,  0.4621, -0.8918,  0.9554,\n",
            "          0.9346, -0.7334, -1.0000,  0.7916,  0.6217,  0.9789, -0.9864,  0.9978,\n",
            "         -0.9959, -1.0000,  0.9529,  0.8686, -0.9850,  0.9596, -0.9126,  0.9898,\n",
            "         -0.9191,  0.9133,  0.9909,  0.9236,  0.6436,  0.5770, -0.3885, -0.9641,\n",
            "         -0.1084, -0.9362, -0.6628, -0.9994,  0.9987, -0.9651,  0.9956, -0.9730,\n",
            "         -0.9520,  0.9474,  0.3849, -1.0000,  0.9983,  0.7340,  0.9387, -0.6416,\n",
            "          0.9741, -0.9034,  0.9614, -0.4824, -0.9176,  0.9777, -0.9002,  0.9958,\n",
            "          0.7739, -0.9999,  0.9988,  0.9997,  0.8725, -0.9928, -0.0384,  0.9992,\n",
            "         -0.9999, -0.9223, -0.0774, -0.9444,  0.8651,  0.6771, -0.9242, -0.9119,\n",
            "          0.9832,  0.6766,  0.8701, -0.7560,  0.9560,  0.8812, -0.9524,  0.9358,\n",
            "          0.9818,  0.9998, -0.9501, -0.1991,  0.5910, -1.0000,  0.9677,  0.1653,\n",
            "          0.5197, -0.9144,  0.9996,  0.9800,  0.9228,  0.9875, -0.9987, -0.8207,\n",
            "         -0.8378, -0.5386,  0.3997,  0.0099,  1.0000, -0.9999,  0.9989,  0.8120,\n",
            "          0.8736,  0.2460, -0.6898,  0.3522,  0.8216,  0.8101, -0.7366,  0.9979,\n",
            "         -0.9793, -0.9990,  0.7525,  0.8965, -0.9952, -0.9156,  0.9093, -0.9197,\n",
            "          0.9999,  1.0000,  0.1878,  0.7555,  0.9500,  0.9691,  0.9717, -0.9989,\n",
            "          0.9965,  1.0000, -0.9894, -0.3923,  1.0000,  0.9669, -0.9045, -0.4734,\n",
            "          0.9479, -0.9979, -0.8043, -0.8590, -0.2451, -0.2925,  0.6021, -0.9970,\n",
            "         -1.0000, -0.9999,  0.9986, -0.9470, -0.9745,  0.9388,  0.6912, -0.9301,\n",
            "         -0.2422,  0.9987, -0.9968,  1.0000,  0.9788, -0.9829, -0.9986, -0.8297,\n",
            "          0.9346,  0.5306,  0.9999,  0.4390, -0.9630,  0.9759,  0.9366,  0.5208,\n",
            "          0.9964, -0.8749,  0.9355,  0.0923,  0.8378, -0.9986, -0.7827, -0.9726,\n",
            "          0.9867,  0.9986,  0.9410, -0.9352,  0.9987,  0.9396, -1.0000,  1.0000,\n",
            "          0.9975, -0.9999,  0.9021, -0.8278,  0.9826,  0.7034,  0.9820, -0.9707,\n",
            "         -0.9622, -0.9999,  0.9887,  0.7311, -0.8174,  0.8885, -0.9782,  0.9215,\n",
            "          0.6971,  0.9078,  0.6894, -0.8890, -1.0000,  0.8351,  0.8867,  0.7616,\n",
            "          0.8974,  0.9978, -0.0950,  1.0000, -0.9747,  0.9748, -0.7756,  0.9255,\n",
            "          0.7866,  0.8950, -0.2202, -0.7211, -1.0000,  0.8181, -0.9047,  0.8503,\n",
            "          0.9142, -0.9995, -0.7295, -0.2027, -0.7696, -0.5561,  0.5683,  0.5791,\n",
            "          1.0000,  0.8851,  0.1051, -0.9155, -0.6034,  0.8746,  0.9901,  0.9889,\n",
            "          0.9995, -0.9727,  0.8831,  0.8488,  0.5381, -0.9249,  0.3516,  0.0825,\n",
            "          0.8391,  0.9991,  0.9683,  0.7719, -0.8876,  0.9059, -0.9994,  1.0000,\n",
            "          0.8444,  0.8612,  0.9960, -0.6073,  0.9805, -0.8400,  0.9561, -0.9594,\n",
            "          0.9972,  0.9258,  0.9547,  0.8078,  0.9323, -0.9326, -0.3371,  0.9652,\n",
            "          0.9010, -0.9513, -0.9952,  0.9986, -0.9953,  0.0016, -0.9133,  0.9166,\n",
            "          0.9837, -0.9436, -0.9764, -0.9575, -0.9075, -0.9868, -0.9823, -0.9998,\n",
            "         -0.5894, -0.9983,  1.0000, -0.9964,  0.9258, -0.9813, -0.9025,  0.9260,\n",
            "          0.0698, -0.9069, -0.9077,  0.1133, -0.9165,  0.9824,  0.3912,  0.9358,\n",
            "         -0.3290, -0.2027,  0.9044,  0.5128,  0.7216,  0.9854, -0.9352, -0.9993,\n",
            "         -0.9772, -0.9231, -0.5393,  0.9980, -0.9945, -0.1631,  1.0000, -0.9996,\n",
            "         -0.6601,  0.0099, -0.9999,  0.8130, -0.9708, -0.9971, -0.9458, -0.9086,\n",
            "          0.9706,  0.9975,  1.0000,  0.3038, -0.9504, -0.9974, -0.7508,  0.9983,\n",
            "         -0.9997,  0.3064,  0.3556, -0.9999,  0.9615,  0.9003, -0.7215,  0.9448,\n",
            "         -0.9489,  0.9990, -0.6669, -0.9980,  0.8731,  0.9144,  0.4548,  0.9712,\n",
            "         -0.3255, -0.5802, -0.9954,  0.8477,  1.0000, -0.1720, -0.9757,  0.9374,\n",
            "          0.9868,  0.9380,  1.0000, -0.9988,  0.9841,  1.0000, -0.8275,  0.9352,\n",
            "         -0.7891, -0.9556, -0.1628,  0.9116, -0.9988,  1.0000, -0.8507, -0.9983,\n",
            "         -1.0000,  0.9413, -0.9715,  0.9142,  0.9942,  0.6770,  0.8587,  0.9339,\n",
            "         -0.9997,  0.9379, -0.9847, -1.0000, -1.0000,  0.9590,  0.0979,  0.3264,\n",
            "          0.9385, -0.8286, -0.9014,  1.0000,  0.9490, -1.0000, -0.9508,  0.9405,\n",
            "          0.9909, -0.9458,  0.9731, -0.6775, -0.0785, -0.2648, -1.0000, -0.9618,\n",
            "          0.9993, -0.8366,  0.7874,  1.0000,  0.9549, -0.8678, -0.9887,  0.8974,\n",
            "          0.9767, -1.0000, -0.9655,  1.0000, -0.9683, -0.9276, -0.9614,  0.5972,\n",
            "          0.9531,  0.9752,  0.9790, -0.9999,  0.9998,  0.9815, -0.2711,  0.9988,\n",
            "         -0.0237, -0.9496, -0.9911, -0.9356,  0.9473, -0.7806,  0.9382, -0.9697,\n",
            "          0.9987,  0.9495, -0.9404,  0.9629,  0.9018, -0.9605, -0.8750,  0.9938,\n",
            "          0.7768, -0.6518,  0.9979, -0.6209, -0.9438, -0.7579,  0.9800,  0.9788,\n",
            "         -1.0000,  0.9768, -0.9040, -0.9734,  0.9584,  0.1198, -0.9454, -0.7521,\n",
            "          0.9667, -0.9607,  0.6127,  0.9895,  0.9743,  0.9665, -0.9971, -1.0000,\n",
            "         -0.9207, -0.8990, -0.9596, -0.1625, -0.5899,  0.9988,  0.8630,  0.5004,\n",
            "          0.9450,  1.0000, -0.8156,  0.9984, -0.9769,  0.9888, -0.9995,  0.9345,\n",
            "          0.4548, -0.9989, -0.9227,  0.9815, -0.9134,  0.9128, -0.9917,  0.9606,\n",
            "          1.0000, -0.9334,  0.5276,  0.9768, -0.9702,  0.9716, -0.8515,  0.9997,\n",
            "         -1.0000,  0.9971,  0.9287,  0.7295,  0.9117,  0.8258, -0.5499, -0.9281,\n",
            "         -0.9528, -0.9981, -0.3607,  0.9454, -0.7950,  0.9398,  0.9843, -0.9834,\n",
            "         -1.0000, -0.9417,  0.6693,  0.9841, -0.9322, -0.9991,  0.9939, -0.8847,\n",
            "          0.9988, -0.6203, -0.9485, -0.8904, -0.9478, -0.8018,  0.9450,  0.9639,\n",
            "          0.9898,  0.8163, -0.8975, -0.8497, -0.8944, -0.9867,  0.9455,  0.6980,\n",
            "          0.9252,  0.9288,  0.9238,  0.9988,  0.6782, -0.7603,  0.8600, -0.9231,\n",
            "         -0.9567, -1.0000,  1.0000,  0.9716, -0.9672, -1.0000,  0.9813,  0.9144,\n",
            "         -0.7463,  0.8976, -0.9398, -0.9763, -0.5319,  0.9922, -1.0000,  0.2169,\n",
            "          0.9538, -0.7956,  0.5349, -1.0000, -0.1173,  0.8250, -0.8930,  0.8740,\n",
            "          1.0000, -0.8575, -0.9967, -0.9959,  0.2316,  0.9473,  0.8231, -0.9991,\n",
            "         -0.8598,  0.9852, -1.0000,  0.7891, -0.9305, -0.8337,  0.9209,  0.9460,\n",
            "          0.9946, -1.0000,  0.9884, -0.9371,  0.9714, -0.6173,  0.8082,  0.9439,\n",
            "          0.9912, -1.0000,  0.9703,  0.7121,  0.8940,  0.8182,  0.9765, -0.9473,\n",
            "         -0.9856, -0.9471,  0.9956,  0.9981, -0.9174,  0.9760,  1.0000, -0.8009,\n",
            "          0.9438,  0.6208, -0.7222, -0.9999, -0.9739, -0.5591,  0.1136, -0.9647]],\n",
            "       device='cuda:0')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training... :   0%|          | 0/127 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d4d8827789e41f8be80a443f1a15bdf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0078,  1.0000, -0.0410,  ..., -0.9072,  0.7547, -0.9514],\n",
            "        [ 0.4513,  1.0000,  0.8990,  ...,  0.2360,  0.1007, -0.7875],\n",
            "        [ 0.6102,  1.0000,  0.8783,  ..., -0.0119, -0.0514, -0.8504],\n",
            "        ...,\n",
            "        [ 0.5848,  1.0000,  0.8261,  ...,  0.4974,  0.1575, -0.9347],\n",
            "        [ 0.6142,  1.0000,  0.1686,  ..., -0.6835,  0.7970, -0.8241],\n",
            "        [ 0.4498,  1.0000,  0.8714,  ..., -0.3641,  0.3584, -0.8916]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5627,  1.0000, -0.3086,  ..., -0.7799,  0.8073, -0.8758],\n",
            "        [ 0.5945,  1.0000,  0.9131,  ...,  0.0745,  0.0962, -0.8054],\n",
            "        [ 0.2496,  1.0000,  0.5316,  ..., -0.7997,  0.8262, -0.9766],\n",
            "        ...,\n",
            "        [ 0.6921,  1.0000,  0.9285,  ..., -0.5224,  0.7816, -0.9728],\n",
            "        [ 0.6607,  1.0000,  0.8704,  ...,  0.4805,  0.0569, -0.8466],\n",
            "        [ 0.6620,  1.0000,  0.9165,  ..., -0.0541,  0.1781, -0.9543]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3532,  1.0000, -0.1634,  ..., -0.7422,  0.8577, -0.9251],\n",
            "        [ 0.5978,  1.0000,  0.8922,  ...,  0.5312,  0.1200, -0.7945],\n",
            "        [ 0.6273,  1.0000,  0.8852,  ...,  0.5150,  0.1339, -0.7399],\n",
            "        ...,\n",
            "        [ 0.3462,  1.0000,  0.8722,  ...,  0.1750, -0.0693, -0.8654],\n",
            "        [ 0.6087,  1.0000,  0.8979,  ...,  0.7220, -0.2016, -0.8308],\n",
            "        [ 0.6418,  1.0000,  0.8472,  ...,  0.4352,  0.2126, -0.8585]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7150,  1.0000,  0.8714,  ...,  0.5874, -0.3016, -0.8202],\n",
            "        [ 0.2923,  1.0000,  0.8767,  ..., -0.3289,  0.3797, -0.9558],\n",
            "        [ 0.6032,  1.0000,  0.8513,  ...,  0.2959,  0.1548, -0.8989],\n",
            "        ...,\n",
            "        [ 0.4771,  1.0000, -0.3989,  ..., -0.7762,  0.6646, -0.8017],\n",
            "        [ 0.7190,  1.0000,  0.8506,  ...,  0.3073,  0.1460, -0.8553],\n",
            "        [ 0.2460,  1.0000,  0.5229,  ..., -0.8533,  0.7811, -0.9777]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4452,  1.0000, -0.5948,  ..., -0.8596,  0.5030, -0.8206],\n",
            "        [ 0.5889,  1.0000,  0.9408,  ..., -0.1239,  0.5909, -0.9693],\n",
            "        [ 0.6253,  1.0000,  0.6202,  ..., -0.6536,  0.5763, -0.9091],\n",
            "        ...,\n",
            "        [ 0.5570,  1.0000,  0.9174,  ...,  0.4289,  0.2960, -0.9042],\n",
            "        [ 0.7122,  1.0000,  0.8701,  ..., -0.2530,  0.4910, -0.8948],\n",
            "        [ 0.5894,  1.0000,  0.8858,  ...,  0.5758,  0.0227, -0.8659]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5333,  1.0000,  0.9073,  ..., -0.2591,  0.3902, -0.9598],\n",
            "        [ 0.2485,  1.0000,  0.8986,  ..., -0.0486,  0.2703, -0.8702],\n",
            "        [ 0.4430,  1.0000,  0.7950,  ..., -0.7128,  0.6633, -0.9523],\n",
            "        ...,\n",
            "        [ 0.7150,  1.0000,  0.9090,  ...,  0.3627, -0.0210, -0.8238],\n",
            "        [ 0.6918,  1.0000,  0.8495,  ...,  0.6167,  0.3948, -0.9299],\n",
            "        [-0.0928,  1.0000,  0.3981,  ..., -0.6757,  0.6924, -0.9410]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7927,  1.0000,  0.4463,  ..., -0.8199,  0.8711, -0.9105],\n",
            "        [ 0.7633,  1.0000,  0.9392,  ...,  0.6918,  0.2841, -0.8956],\n",
            "        [ 0.7368,  1.0000,  0.9251,  ...,  0.5320, -0.1515, -0.8655],\n",
            "        ...,\n",
            "        [ 0.6553,  1.0000,  0.9080,  ...,  0.5541, -0.2377, -0.7443],\n",
            "        [ 0.6627,  1.0000,  0.8594,  ...,  0.5833,  0.3281, -0.7442],\n",
            "        [ 0.1230,  1.0000,  0.1172,  ..., -0.9248,  0.8880, -0.9570]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3824,  1.0000,  0.8302,  ..., -0.0389, -0.1728, -0.9451],\n",
            "        [ 0.4388,  1.0000,  0.8905,  ...,  0.3758, -0.2209, -0.7998],\n",
            "        [ 0.8123,  1.0000,  0.8570,  ...,  0.5976,  0.1611, -0.8661],\n",
            "        ...,\n",
            "        [ 0.1163,  1.0000,  0.5452,  ..., -0.7096,  0.7134, -0.9740],\n",
            "        [ 0.3017,  1.0000, -0.1790,  ..., -0.7934,  0.6966, -0.8797],\n",
            "        [ 0.2523,  1.0000,  0.3192,  ..., -0.9357,  0.7730, -0.9655]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2284,  1.0000,  0.0843,  ..., -0.6881,  0.6878, -0.9167],\n",
            "        [ 0.4203,  1.0000,  0.8874,  ...,  0.0725,  0.3000, -0.9189],\n",
            "        [ 0.1572,  1.0000, -0.4183,  ..., -0.8928,  0.5826, -0.8839],\n",
            "        ...,\n",
            "        [-0.0260,  1.0000, -0.6054,  ..., -0.7759,  0.6606, -0.8152],\n",
            "        [ 0.6493,  1.0000,  0.9207,  ..., -0.4628,  0.5602, -0.9286],\n",
            "        [-0.2783,  1.0000, -0.4834,  ..., -0.9087,  0.3469, -0.6256]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6583,  1.0000,  0.9079,  ...,  0.4315,  0.1260, -0.7600],\n",
            "        [ 0.0364,  1.0000,  0.3719,  ..., -0.8993,  0.7091, -0.9384],\n",
            "        [ 0.8064,  1.0000,  0.9609,  ...,  0.2008,  0.4032, -0.9797],\n",
            "        ...,\n",
            "        [ 0.5931,  1.0000,  0.7660,  ...,  0.4702,  0.0381, -0.8570],\n",
            "        [ 0.7120,  1.0000,  0.9124,  ...,  0.7526, -0.0713, -0.7446],\n",
            "        [ 0.6538,  1.0000,  0.9450,  ...,  0.0866,  0.6612, -0.9757]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2622,  0.9998, -0.4022,  ..., -0.8883,  0.5338, -0.6887],\n",
            "        [ 0.8356,  1.0000,  0.9113,  ...,  0.2953,  0.4400, -0.8616],\n",
            "        [-0.0208,  1.0000,  0.6756,  ..., -0.6017,  0.4367, -0.9184],\n",
            "        ...,\n",
            "        [ 0.7799,  1.0000,  0.9545,  ...,  0.2778,  0.1997, -0.9395],\n",
            "        [ 0.2601,  1.0000,  0.6749,  ..., -0.7873,  0.7828, -0.9737],\n",
            "        [ 0.7896,  1.0000,  0.8806,  ...,  0.5797,  0.3644, -0.8363]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0737,  1.0000, -0.4845,  ..., -0.9248,  0.5977, -0.6505],\n",
            "        [ 0.7632,  1.0000,  0.9049,  ...,  0.1210,  0.1465, -0.7915],\n",
            "        [ 0.3126,  1.0000, -0.7310,  ..., -0.8574,  0.6436, -0.7553],\n",
            "        ...,\n",
            "        [ 0.7493,  1.0000,  0.8835,  ...,  0.6795,  0.1338, -0.8115],\n",
            "        [ 0.6393,  1.0000,  0.7997,  ..., -0.4706,  0.4481, -0.9630],\n",
            "        [ 0.6797,  1.0000,  0.9337,  ...,  0.3852,  0.1426, -0.9138]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6838,  1.0000,  0.8636,  ...,  0.6242, -0.0065, -0.8158],\n",
            "        [ 0.3125,  1.0000, -0.2022,  ..., -0.8177,  0.7923, -0.8475],\n",
            "        [ 0.0277,  1.0000, -0.5921,  ..., -0.8881,  0.5284, -0.5425],\n",
            "        ...,\n",
            "        [ 0.6611,  1.0000,  0.8962,  ...,  0.5794, -0.0505, -0.8690],\n",
            "        [ 0.6933,  1.0000,  0.8540,  ...,  0.2759, -0.0937, -0.8982],\n",
            "        [ 0.5700,  1.0000,  0.8860,  ..., -0.2687,  0.6078, -0.9517]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4973,  1.0000,  0.6502,  ..., -0.7069,  0.4899, -0.9731],\n",
            "        [ 0.1872,  1.0000,  0.6913,  ..., -0.3198,  0.6751, -0.9325],\n",
            "        [ 0.1075,  1.0000, -0.6110,  ..., -0.8759,  0.5796, -0.6558],\n",
            "        ...,\n",
            "        [ 0.7990,  1.0000,  0.9024,  ...,  0.7319,  0.1493, -0.8490],\n",
            "        [ 0.0178,  1.0000, -0.5421,  ..., -0.8639,  0.5251, -0.7053],\n",
            "        [ 0.7181,  1.0000,  0.7799,  ...,  0.7326,  0.2767, -0.7834]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5856,  1.0000,  0.7763,  ...,  0.5371,  0.1192, -0.8790],\n",
            "        [ 0.0188,  1.0000, -0.6064,  ..., -0.8418,  0.5978, -0.8338],\n",
            "        [ 0.6194,  1.0000,  0.8466,  ...,  0.4036,  0.1057, -0.8247],\n",
            "        ...,\n",
            "        [ 0.1660,  1.0000, -0.5068,  ..., -0.8929,  0.5522, -0.6166],\n",
            "        [ 0.0527,  1.0000,  0.7858,  ..., -0.4979,  0.8791, -0.8933],\n",
            "        [ 0.5306,  1.0000,  0.9076,  ...,  0.6536, -0.0413, -0.7355]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5838,  1.0000,  0.9350,  ...,  0.4412,  0.3342, -0.7758],\n",
            "        [-0.0302,  1.0000, -0.4666,  ..., -0.8463,  0.7341, -0.6859],\n",
            "        [ 0.7980,  1.0000,  0.8312,  ...,  0.7708, -0.4161, -0.7698],\n",
            "        ...,\n",
            "        [ 0.1944,  1.0000, -0.2339,  ..., -0.8631,  0.8655, -0.8691],\n",
            "        [ 0.2649,  1.0000, -0.6833,  ..., -0.8675,  0.6419, -0.6788],\n",
            "        [-0.1504,  1.0000, -0.6516,  ..., -0.7767,  0.7310, -0.6087]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0590,  1.0000, -0.1599,  ..., -0.8695,  0.6496, -0.9055],\n",
            "        [ 0.3318,  1.0000, -0.5042,  ..., -0.8688,  0.5368, -0.6748],\n",
            "        [ 0.6677,  1.0000,  0.8880,  ...,  0.5361, -0.0608, -0.8229],\n",
            "        ...,\n",
            "        [ 0.7013,  1.0000,  0.8746,  ..., -0.2260,  0.4575, -0.9417],\n",
            "        [ 0.4361,  1.0000,  0.8551,  ...,  0.3816,  0.2227, -0.7957],\n",
            "        [ 0.1567,  1.0000,  0.9286,  ...,  0.0998,  0.3628, -0.8587]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6724,  1.0000,  0.9726,  ...,  0.2752,  0.2552, -0.9097],\n",
            "        [ 0.2954,  1.0000,  0.1551,  ..., -0.7966,  0.7432, -0.9267],\n",
            "        [ 0.6247,  1.0000,  0.9021,  ...,  0.5918, -0.2170, -0.6042],\n",
            "        ...,\n",
            "        [ 0.0719,  1.0000,  0.8130,  ..., -0.4500,  0.4592, -0.9455],\n",
            "        [ 0.6548,  1.0000,  0.9190,  ...,  0.6142,  0.2856, -0.8438],\n",
            "        [ 0.5553,  1.0000,  0.9410,  ..., -0.3478,  0.5396, -0.9809]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4950,  1.0000,  0.9582,  ...,  0.1939,  0.1788, -0.9122],\n",
            "        [ 0.6995,  1.0000,  0.8809,  ...,  0.7411,  0.0493, -0.8166],\n",
            "        [-0.1676,  1.0000, -0.0403,  ..., -0.8201,  0.6770, -0.8688],\n",
            "        ...,\n",
            "        [ 0.4315,  1.0000,  0.9406,  ..., -0.2190,  0.3177, -0.8878],\n",
            "        [ 0.5093,  1.0000,  0.8823,  ...,  0.4161,  0.0695, -0.8862],\n",
            "        [ 0.6471,  1.0000,  0.8438,  ...,  0.4701, -0.1582, -0.7294]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1864,  1.0000, -0.2426,  ..., -0.7994,  0.7331, -0.7974],\n",
            "        [ 0.7188,  1.0000,  0.8881,  ...,  0.3362,  0.1327, -0.8969],\n",
            "        [ 0.7474,  1.0000,  0.9280,  ...,  0.5448,  0.0440, -0.6777],\n",
            "        ...,\n",
            "        [ 0.1792,  1.0000,  0.9294,  ..., -0.2293,  0.7862, -0.9846],\n",
            "        [ 0.5928,  1.0000,  0.9079,  ..., -0.2578,  0.7758, -0.9704],\n",
            "        [ 0.6846,  1.0000,  0.8748,  ...,  0.2476,  0.4663, -0.9647]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6059,  1.0000,  0.8418,  ...,  0.6431, -0.1481, -0.7971],\n",
            "        [ 0.4411,  1.0000,  0.8929,  ...,  0.3759, -0.0064, -0.8168],\n",
            "        [-0.0113,  1.0000,  0.9277,  ...,  0.1865, -0.0283, -0.8124],\n",
            "        ...,\n",
            "        [ 0.0227,  1.0000, -0.2874,  ..., -0.9383,  0.6456, -0.8969],\n",
            "        [-0.0544,  1.0000, -0.6906,  ..., -0.9284,  0.2085, -0.5955],\n",
            "        [ 0.3970,  1.0000,  0.9291,  ...,  0.3017,  0.1644, -0.6873]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1106,  1.0000, -0.5762,  ..., -0.8626,  0.6942, -0.6391],\n",
            "        [-0.3734,  1.0000, -0.5851,  ..., -0.8897,  0.2870, -0.7368],\n",
            "        [ 0.6778,  1.0000,  0.9009,  ...,  0.5577, -0.1285, -0.7963],\n",
            "        ...,\n",
            "        [ 0.0878,  1.0000, -0.3156,  ..., -0.7413,  0.7445, -0.7304],\n",
            "        [ 0.2515,  1.0000,  0.9017,  ...,  0.2669,  0.0296, -0.7653],\n",
            "        [ 0.1604,  1.0000, -0.3598,  ..., -0.7600,  0.2760, -0.9064]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4902,  1.0000,  0.8963,  ..., -0.5975,  0.6089, -0.9664],\n",
            "        [ 0.5455,  1.0000,  0.9673,  ..., -0.2801,  0.3801, -0.9092],\n",
            "        [ 0.2565,  1.0000, -0.4606,  ..., -0.8159,  0.7585, -0.6660],\n",
            "        ...,\n",
            "        [ 0.0680,  1.0000, -0.0781,  ..., -0.6825,  0.2805, -0.8714],\n",
            "        [ 0.2315,  1.0000, -0.4270,  ..., -0.7838,  0.7441, -0.7769],\n",
            "        [ 0.7333,  1.0000,  0.8680,  ...,  0.2763,  0.0352, -0.8526]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3401,  1.0000,  0.5934,  ..., -0.7653,  0.5232, -0.9813],\n",
            "        [ 0.6357,  1.0000,  0.8334,  ...,  0.4991, -0.1040, -0.7958],\n",
            "        [ 0.6089,  1.0000,  0.9318,  ...,  0.3606,  0.1750, -0.9572],\n",
            "        ...,\n",
            "        [ 0.3279,  1.0000, -0.6579,  ..., -0.8572,  0.5134, -0.7586],\n",
            "        [ 0.5606,  1.0000,  0.9268,  ...,  0.2779,  0.1127, -0.8894],\n",
            "        [ 0.3005,  1.0000,  0.9252,  ...,  0.7551,  0.0954, -0.7597]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4549,  1.0000,  0.8429,  ...,  0.4893, -0.2721, -0.8535],\n",
            "        [ 0.4434,  1.0000,  0.9184,  ...,  0.0102,  0.2382, -0.8906],\n",
            "        [-0.2298,  0.9999, -0.7020,  ..., -0.9295,  0.2047,  0.1530],\n",
            "        ...,\n",
            "        [ 0.3676,  1.0000,  0.7522,  ..., -0.7202,  0.8632, -0.9621],\n",
            "        [ 0.4367,  1.0000,  0.8971,  ...,  0.4429,  0.1766, -0.8815],\n",
            "        [ 0.4739,  1.0000,  0.9278,  ...,  0.5287, -0.0839, -0.8143]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1151,  1.0000,  0.1897,  ..., -0.8438,  0.6134, -0.8835],\n",
            "        [ 0.4349,  1.0000,  0.9207,  ...,  0.3812,  0.0160, -0.7050],\n",
            "        [ 0.6958,  1.0000,  0.9166,  ...,  0.5816, -0.1580, -0.8146],\n",
            "        ...,\n",
            "        [ 0.1881,  1.0000,  0.9091,  ..., -0.1004,  0.2713, -0.9799],\n",
            "        [ 0.3032,  1.0000,  0.8342,  ..., -0.6044,  0.5093, -0.9774],\n",
            "        [-0.2412,  1.0000, -0.4262,  ..., -0.8372,  0.6021, -0.6328]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0029,  1.0000, -0.7910,  ..., -0.8827,  0.3261, -0.4321],\n",
            "        [ 0.6267,  1.0000,  0.9091,  ...,  0.6377,  0.0047, -0.7608],\n",
            "        [ 0.2085,  1.0000,  0.8012,  ..., -0.5852,  0.7221, -0.9234],\n",
            "        ...,\n",
            "        [-0.1485,  1.0000,  0.8706,  ..., -0.7710,  0.5042, -0.9729],\n",
            "        [-0.4457,  1.0000, -0.7111,  ..., -0.7398,  0.4371, -0.6151],\n",
            "        [-0.3129,  1.0000, -0.3851,  ..., -0.8632,  0.5469, -0.7791]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2886,  1.0000, -0.1137,  ..., -0.8326,  0.5879, -0.8597],\n",
            "        [-0.1740,  1.0000, -0.7327,  ..., -0.9048,  0.5147, -0.5369],\n",
            "        [ 0.1020,  1.0000,  0.6316,  ..., -0.0616,  0.0449, -0.9090],\n",
            "        ...,\n",
            "        [ 0.7748,  1.0000,  0.9621,  ...,  0.5227,  0.2504, -0.8451],\n",
            "        [-0.1759,  1.0000, -0.6035,  ..., -0.8127,  0.5772, -0.6850],\n",
            "        [-0.2364,  1.0000, -0.7135,  ..., -0.8878,  0.3873, -0.5436]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5711,  1.0000,  0.9430,  ...,  0.6572, -0.1934, -0.7424],\n",
            "        [ 0.5567,  1.0000,  0.8105,  ..., -0.4602,  0.3096, -0.9099],\n",
            "        [ 0.5122,  1.0000,  0.9398,  ...,  0.4614, -0.2009, -0.8721],\n",
            "        ...,\n",
            "        [-0.3024,  1.0000, -0.5377,  ..., -0.6767,  0.5852, -0.7482],\n",
            "        [ 0.4544,  1.0000,  0.8586,  ...,  0.1028, -0.0798, -0.8927],\n",
            "        [ 0.1253,  1.0000,  0.9031,  ...,  0.2286,  0.2188, -0.7647]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0609,  1.0000,  0.7978,  ..., -0.4233,  0.0973, -0.7863],\n",
            "        [ 0.6604,  1.0000,  0.8491,  ...,  0.5669,  0.1919, -0.8999],\n",
            "        [ 0.1287,  1.0000, -0.6883,  ..., -0.8434,  0.4810, -0.6763],\n",
            "        ...,\n",
            "        [ 0.7105,  1.0000,  0.9060,  ...,  0.6681, -0.0788, -0.8183],\n",
            "        [-0.0718,  1.0000, -0.5088,  ..., -0.9034,  0.6774, -0.5221],\n",
            "        [ 0.5669,  1.0000,  0.8938,  ...,  0.7647, -0.3229, -0.5675]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4579,  1.0000, -0.4897,  ..., -0.8867,  0.6322, -0.4469],\n",
            "        [-0.3086,  1.0000,  0.5127,  ..., -0.7491,  0.5573, -0.9462],\n",
            "        [ 0.6427,  1.0000,  0.9039,  ...,  0.6344, -0.0374, -0.8283],\n",
            "        ...,\n",
            "        [-0.2280,  1.0000, -0.4252,  ..., -0.7566,  0.7202, -0.6524],\n",
            "        [ 0.6288,  1.0000,  0.9587,  ...,  0.6046, -0.0903, -0.8087],\n",
            "        [-0.4720,  1.0000, -0.8096,  ..., -0.9088,  0.4117, -0.4805]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2972,  0.9999,  0.7414,  ..., -0.1913, -0.0455, -0.3693],\n",
            "        [ 0.6879,  1.0000,  0.9256,  ...,  0.6773, -0.2220, -0.5893],\n",
            "        [-0.1319,  1.0000, -0.5835,  ..., -0.8415,  0.4034, -0.6265],\n",
            "        ...,\n",
            "        [-0.0722,  1.0000, -0.1142,  ..., -0.8248,  0.6559, -0.9166],\n",
            "        [ 0.7817,  1.0000,  0.9165,  ...,  0.8277, -0.1214, -0.7172],\n",
            "        [ 0.7269,  1.0000,  0.9089,  ...,  0.8714, -0.1798, -0.6568]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6044,  1.0000,  0.9275,  ...,  0.6956, -0.4662, -0.6775],\n",
            "        [ 0.1019,  1.0000,  0.0857,  ..., -0.5617,  0.1626, -0.7086],\n",
            "        [ 0.5009,  1.0000,  0.9393,  ...,  0.5388, -0.1632, -0.5568],\n",
            "        ...,\n",
            "        [ 0.6038,  1.0000,  0.9261,  ...,  0.4450,  0.3853, -0.9766],\n",
            "        [ 0.1574,  1.0000, -0.5999,  ..., -0.9342,  0.6105, -0.6255],\n",
            "        [-0.1677,  1.0000, -0.7793,  ..., -0.8077,  0.3871, -0.0921]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4664,  1.0000, -0.2865,  ..., -0.9372,  0.5046, -0.7598],\n",
            "        [ 0.6241,  1.0000, -0.1432,  ..., -0.6844,  0.6734, -0.8480],\n",
            "        [ 0.6917,  1.0000,  0.8985,  ...,  0.6540, -0.1946, -0.7546],\n",
            "        ...,\n",
            "        [ 0.0949,  1.0000, -0.4862,  ..., -0.8106,  0.6640, -0.7372],\n",
            "        [ 0.8806,  1.0000,  0.9653,  ...,  0.8338, -0.1304, -0.8544],\n",
            "        [ 0.6069,  1.0000,  0.9625,  ...,  0.6458, -0.1597, -0.6627]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6130,  1.0000,  0.9030,  ...,  0.7469, -0.1438, -0.8063],\n",
            "        [ 0.6060,  1.0000,  0.8785,  ...,  0.6924, -0.1691, -0.6594],\n",
            "        [ 0.0083,  1.0000,  0.9054,  ..., -0.2004,  0.1788, -0.9808],\n",
            "        ...,\n",
            "        [-0.3631,  1.0000, -0.7203,  ..., -0.8502,  0.3967, -0.6153],\n",
            "        [-0.1612,  1.0000, -0.6957,  ..., -0.7553,  0.7589, -0.6161],\n",
            "        [ 0.6563,  1.0000,  0.8896,  ...,  0.8700, -0.3306, -0.7093]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2586,  1.0000, -0.8474,  ..., -0.9167,  0.4215, -0.3343],\n",
            "        [-0.3377,  1.0000, -0.7318,  ..., -0.8845,  0.6170, -0.3268],\n",
            "        [ 0.5010,  1.0000, -0.1624,  ..., -0.7017,  0.6288, -0.7070],\n",
            "        ...,\n",
            "        [ 0.6152,  1.0000,  0.9021,  ...,  0.5420,  0.2479, -0.8667],\n",
            "        [-0.3584,  1.0000, -0.4990,  ..., -0.9217,  0.0883, -0.5741],\n",
            "        [-0.0722,  1.0000, -0.4529,  ..., -0.8989,  0.7478, -0.7674]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2657,  1.0000, -0.3257,  ..., -0.8539,  0.4862, -0.8887],\n",
            "        [ 0.5342,  1.0000,  0.9326,  ...,  0.3643,  0.1000, -0.7482],\n",
            "        [ 0.2846,  0.9998, -0.6283,  ..., -0.8510,  0.7108, -0.4352],\n",
            "        ...,\n",
            "        [ 0.7047,  1.0000,  0.9482,  ...,  0.6234, -0.0297, -0.9125],\n",
            "        [ 0.4593,  1.0000,  0.8935,  ...,  0.6609,  0.1217, -0.9514],\n",
            "        [ 0.4443,  1.0000,  0.7802,  ..., -0.7114,  0.4534, -0.9641]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6229,  1.0000,  0.8962,  ...,  0.7512, -0.2740, -0.7202],\n",
            "        [ 0.4523,  1.0000,  0.9069,  ..., -0.1593,  0.1993, -0.7806],\n",
            "        [ 0.7771,  1.0000,  0.9030,  ...,  0.8167, -0.3420, -0.7380],\n",
            "        ...,\n",
            "        [-0.3360,  1.0000, -0.7254,  ..., -0.9118,  0.5220, -0.3793],\n",
            "        [-0.3778,  1.0000, -0.8390,  ..., -0.9117,  0.4902, -0.1909],\n",
            "        [-0.0511,  1.0000, -0.7721,  ..., -0.9343,  0.7063, -0.7135]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2139,  1.0000, -0.4469,  ..., -0.8228,  0.7050, -0.8864],\n",
            "        [ 0.0326,  1.0000, -0.2833,  ..., -0.8259,  0.6123, -0.9098],\n",
            "        [ 0.7596,  1.0000,  0.8820,  ...,  0.8597, -0.3525, -0.5826],\n",
            "        ...,\n",
            "        [ 0.5896,  0.9998,  0.8881,  ...,  0.7745, -0.1032, -0.6325],\n",
            "        [ 0.7251,  1.0000,  0.9172,  ...,  0.7902, -0.3213, -0.7795],\n",
            "        [ 0.6901,  1.0000,  0.8880,  ...,  0.8119, -0.3521, -0.6283]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4610,  1.0000,  0.9093,  ...,  0.8540, -0.2233, -0.4790],\n",
            "        [ 0.7329,  1.0000,  0.9213,  ...,  0.7004, -0.4138, -0.8433],\n",
            "        [ 0.3070,  1.0000,  0.7871,  ..., -0.7047,  0.3339, -0.9560],\n",
            "        ...,\n",
            "        [-0.2827,  1.0000, -0.4729,  ..., -0.8992,  0.4496, -0.7886],\n",
            "        [ 0.8207,  1.0000,  0.9522,  ...,  0.8255, -0.1493, -0.6804],\n",
            "        [-0.0812,  1.0000, -0.8379,  ..., -0.9225,  0.5506, -0.4696]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6788,  1.0000,  0.9021,  ...,  0.8271, -0.3087, -0.5774],\n",
            "        [-0.2696,  1.0000, -0.7473,  ..., -0.8802,  0.4920, -0.4525],\n",
            "        [ 0.1730,  1.0000, -0.6074,  ..., -0.9015,  0.7773, -0.4972],\n",
            "        ...,\n",
            "        [ 0.7425,  1.0000,  0.9393,  ...,  0.7614, -0.1075, -0.7146],\n",
            "        [ 0.8239,  1.0000,  0.9319,  ...,  0.8723, -0.1774, -0.7779],\n",
            "        [ 0.6022,  1.0000,  0.8916,  ...,  0.5238,  0.0445, -0.7555]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7711,  1.0000,  0.8434,  ...,  0.7783, -0.5970, -0.6340],\n",
            "        [ 0.8238,  0.9999,  0.9440,  ...,  0.6412, -0.0722, -0.7713],\n",
            "        [ 0.2388,  1.0000, -0.7045,  ..., -0.8271,  0.4083, -0.6522],\n",
            "        ...,\n",
            "        [ 0.6672,  1.0000,  0.8916,  ...,  0.6754, -0.3906, -0.7575],\n",
            "        [ 0.6501,  1.0000,  0.8531,  ...,  0.4187, -0.0848, -0.7982],\n",
            "        [ 0.7037,  1.0000,  0.9157,  ...,  0.6641, -0.2933, -0.7508]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 6.8822e-01,  1.0000e+00,  8.5461e-01,  ...,  5.0816e-01,\n",
            "          7.5675e-04, -8.6687e-01],\n",
            "        [ 2.7577e-01,  1.0000e+00,  9.4601e-01,  ..., -1.2908e-03,\n",
            "          6.7362e-02, -9.0631e-01],\n",
            "        [ 7.1493e-01,  9.9999e-01,  9.3751e-01,  ...,  7.0669e-01,\n",
            "         -1.7892e-01, -7.1672e-01],\n",
            "        ...,\n",
            "        [ 2.7641e-01,  9.9999e-01, -5.3340e-01,  ..., -8.7515e-01,\n",
            "          5.7056e-01, -7.5053e-01],\n",
            "        [-1.6153e-01,  1.0000e+00, -7.5981e-01,  ..., -9.2849e-01,\n",
            "          4.0135e-01, -6.0424e-01],\n",
            "        [-6.7406e-02,  9.9999e-01, -4.7212e-01,  ..., -8.1443e-01,\n",
            "          6.3884e-01, -6.2212e-01]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6053,  1.0000,  0.9367,  ...,  0.7184, -0.2021, -0.7929],\n",
            "        [ 0.7815,  1.0000,  0.9515,  ...,  0.9122, -0.2229, -0.6432],\n",
            "        [ 0.5151,  1.0000,  0.8427,  ...,  0.1847, -0.3617, -0.9221],\n",
            "        ...,\n",
            "        [ 0.1507,  1.0000, -0.5692,  ..., -0.9411,  0.3553, -0.3095],\n",
            "        [ 0.7910,  1.0000,  0.9030,  ...,  0.7356,  0.1092, -0.8333],\n",
            "        [-0.1216,  1.0000, -0.2713,  ..., -0.8036,  0.6840, -0.7008]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7139,  1.0000,  0.8676,  ...,  0.8554, -0.2981, -0.5824],\n",
            "        [ 0.7411,  1.0000,  0.8839,  ...,  0.8378, -0.5848, -0.4810],\n",
            "        [ 0.0409,  1.0000,  0.6359,  ..., -0.7991,  0.4790, -0.9616],\n",
            "        ...,\n",
            "        [ 0.6466,  1.0000,  0.8649,  ...,  0.8613, -0.1508, -0.6101],\n",
            "        [-0.2982,  1.0000, -0.7008,  ..., -0.9188,  0.3126, -0.7539],\n",
            "        [ 0.7221,  1.0000,  0.9022,  ...,  0.8490, -0.3057, -0.6774]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0394,  1.0000,  0.5323,  ..., -0.7504,  0.7699, -0.9215],\n",
            "        [ 0.7285,  1.0000,  0.8815,  ...,  0.7511, -0.4214, -0.6777],\n",
            "        [ 0.6308,  1.0000,  0.9338,  ...,  0.5406, -0.4381, -0.7442],\n",
            "        ...,\n",
            "        [ 0.5812,  1.0000,  0.9185,  ...,  0.2640,  0.1844, -0.9782],\n",
            "        [-0.6201,  1.0000,  0.5207,  ..., -0.9124,  0.2367, -0.8462],\n",
            "        [-0.2296,  1.0000, -0.6529,  ..., -0.9236,  0.4564, -0.4403]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 5.8186e-01,  1.0000e+00,  8.2404e-01,  ...,  5.5584e-01,\n",
            "         -1.7333e-01, -6.1580e-01],\n",
            "        [ 7.7903e-01,  1.0000e+00,  8.6495e-01,  ...,  8.6978e-01,\n",
            "         -2.5897e-01, -5.6379e-01],\n",
            "        [-3.8161e-01,  9.9924e-01, -2.4867e-01,  ..., -8.3386e-01,\n",
            "          4.1810e-01, -6.8490e-01],\n",
            "        ...,\n",
            "        [ 3.8495e-01,  1.0000e+00,  6.5658e-01,  ..., -7.8462e-01,\n",
            "          4.9465e-01, -9.7215e-01],\n",
            "        [ 8.4031e-01,  1.0000e+00,  9.0996e-01,  ...,  7.9928e-01,\n",
            "         -1.4549e-01, -7.7254e-01],\n",
            "        [-3.5204e-01,  1.0000e+00, -8.1877e-04,  ..., -7.8592e-01,\n",
            "          4.8351e-01, -8.8584e-01]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1908,  1.0000, -0.8424,  ..., -0.9201,  0.5363, -0.6407],\n",
            "        [ 0.7511,  1.0000,  0.9318,  ...,  0.8166, -0.3835, -0.6148],\n",
            "        [ 0.1410,  1.0000, -0.4890,  ..., -0.9302,  0.8086, -0.7740],\n",
            "        ...,\n",
            "        [ 0.6648,  1.0000,  0.8291,  ...,  0.7388, -0.2326, -0.7970],\n",
            "        [ 0.5685,  1.0000,  0.8637,  ...,  0.6977, -0.2955, -0.7518],\n",
            "        [ 0.6840,  1.0000,  0.8772,  ...,  0.5893, -0.3655, -0.6300]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2027,  1.0000, -0.7700,  ..., -0.8340,  0.3504, -0.2574],\n",
            "        [ 0.7987,  1.0000,  0.9172,  ...,  0.8264, -0.0698, -0.6327],\n",
            "        [ 0.7447,  1.0000,  0.9022,  ...,  0.7782, -0.3046, -0.8038],\n",
            "        ...,\n",
            "        [ 0.7025,  1.0000,  0.8825,  ...,  0.6454, -0.1838, -0.5505],\n",
            "        [ 0.0794,  1.0000, -0.4740,  ..., -0.8329,  0.5526, -0.5341],\n",
            "        [-0.0044,  1.0000, -0.4484,  ..., -0.9377,  0.6423, -0.7237]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0354,  1.0000,  0.2799,  ..., -0.7661,  0.4936, -0.9382],\n",
            "        [ 0.7971,  1.0000,  0.8396,  ...,  0.7698, -0.5123, -0.4508],\n",
            "        [ 0.7636,  1.0000,  0.9291,  ...,  0.8531, -0.3158, -0.8065],\n",
            "        ...,\n",
            "        [ 0.7607,  1.0000,  0.8769,  ...,  0.7418, -0.2090, -0.7064],\n",
            "        [ 0.7942,  1.0000,  0.8866,  ...,  0.6682, -0.1855, -0.8187],\n",
            "        [ 0.7198,  1.0000,  0.9246,  ...,  0.8902, -0.3754, -0.6359]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1069,  1.0000,  0.7380,  ..., -0.7636,  0.6414, -0.9266],\n",
            "        [ 0.6547,  1.0000,  0.9082,  ...,  0.7658, -0.2820, -0.6216],\n",
            "        [ 0.4860,  1.0000,  0.9272,  ...,  0.3121,  0.0268, -0.8568],\n",
            "        ...,\n",
            "        [-0.1680,  1.0000, -0.4958,  ..., -0.8271,  0.5767, -0.6521],\n",
            "        [-0.0749,  1.0000, -0.7612,  ..., -0.8390,  0.1584, -0.5969],\n",
            "        [-0.2060,  1.0000, -0.7492,  ..., -0.8087,  0.3137, -0.2963]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6421,  1.0000,  0.8657,  ...,  0.7422, -0.3166, -0.6048],\n",
            "        [-0.1506,  1.0000, -0.5611,  ..., -0.9018,  0.7517, -0.5188],\n",
            "        [-0.1878,  1.0000, -0.4064,  ..., -0.8437,  0.5736, -0.6165],\n",
            "        ...,\n",
            "        [-0.3738,  1.0000, -0.8572,  ..., -0.8272,  0.4634, -0.2600],\n",
            "        [ 0.6865,  1.0000,  0.9035,  ...,  0.8156, -0.1330, -0.6455],\n",
            "        [ 0.6746,  1.0000,  0.9258,  ...,  0.4143,  0.0741, -0.8875]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7699,  1.0000,  0.8754,  ...,  0.7955, -0.2635, -0.6322],\n",
            "        [ 0.5813,  1.0000,  0.8929,  ..., -0.1045,  0.2238, -0.9477],\n",
            "        [ 0.2193,  1.0000, -0.4051,  ..., -0.8154,  0.7865, -0.8605],\n",
            "        ...,\n",
            "        [ 0.8138,  1.0000,  0.8644,  ...,  0.7831, -0.2725, -0.5272],\n",
            "        [ 0.1244,  1.0000, -0.5429,  ..., -0.8801,  0.6476, -0.6578],\n",
            "        [-0.0886,  1.0000, -0.6021,  ..., -0.9162,  0.6079, -0.6625]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2037,  0.9999, -0.8110,  ..., -0.8355,  0.4998, -0.3796],\n",
            "        [ 0.6870,  1.0000,  0.8802,  ...,  0.8410, -0.3131, -0.6044],\n",
            "        [ 0.6491,  1.0000,  0.8832,  ...,  0.7573, -0.1067, -0.6389],\n",
            "        ...,\n",
            "        [ 0.6755,  1.0000,  0.9199,  ...,  0.7117, -0.4099, -0.8507],\n",
            "        [ 0.8472,  1.0000,  0.9239,  ...,  0.7262, -0.1740, -0.7672],\n",
            "        [ 0.0653,  1.0000, -0.5365,  ..., -0.9275,  0.3594, -0.6023]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4475,  1.0000,  0.9663,  ...,  0.3884, -0.0746, -0.9320],\n",
            "        [ 0.1301,  0.9999,  0.8814,  ...,  0.1727, -0.1250, -0.8196],\n",
            "        [ 0.2753,  1.0000, -0.2078,  ..., -0.8747,  0.5795, -0.7644],\n",
            "        ...,\n",
            "        [-0.3353,  1.0000, -0.7747,  ..., -0.9135,  0.3284, -0.4416],\n",
            "        [-0.4794,  0.9999, -0.6366,  ..., -0.8724,  0.0857, -0.0821],\n",
            "        [ 0.0367,  0.9999, -0.4175,  ..., -0.8826,  0.5700, -0.7948]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7191,  1.0000,  0.8756,  ...,  0.8803, -0.2715, -0.4632],\n",
            "        [-0.0018,  1.0000, -0.6983,  ..., -0.9255,  0.5901, -0.6855],\n",
            "        [ 0.4083,  1.0000,  0.9280,  ...,  0.0344,  0.1469, -0.9300],\n",
            "        ...,\n",
            "        [ 0.6706,  1.0000,  0.9271,  ...,  0.8535, -0.3475, -0.5682],\n",
            "        [-0.3499,  1.0000, -0.0104,  ..., -0.9013,  0.4630, -0.4087],\n",
            "        [ 0.7221,  1.0000,  0.9009,  ...,  0.2115,  0.0534, -0.7627]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6740,  1.0000,  0.9003,  ...,  0.8574, -0.4445, -0.7134],\n",
            "        [ 0.7721,  1.0000,  0.8148,  ...,  0.8469, -0.3480, -0.7218],\n",
            "        [ 0.7555,  1.0000,  0.9435,  ...,  0.8964, -0.2139, -0.7404],\n",
            "        ...,\n",
            "        [ 0.7807,  1.0000,  0.8696,  ...,  0.7823, -0.3348, -0.6611],\n",
            "        [ 0.6836,  1.0000,  0.8528,  ...,  0.7996, -0.3845, -0.5307],\n",
            "        [-0.1086,  1.0000, -0.7743,  ..., -0.8893,  0.1724, -0.3092]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3772,  1.0000,  0.3410,  ..., -0.4333,  0.4599, -0.8445],\n",
            "        [ 0.7875,  1.0000,  0.9193,  ...,  0.8451, -0.3069, -0.6481],\n",
            "        [ 0.0251,  1.0000, -0.7818,  ..., -0.8774,  0.5537, -0.4301],\n",
            "        ...,\n",
            "        [-0.4168,  1.0000, -0.4691,  ..., -0.9240,  0.4863, -0.5374],\n",
            "        [ 0.6680,  0.9999,  0.9097,  ...,  0.6838, -0.2540, -0.6655],\n",
            "        [ 0.6255,  1.0000,  0.8982,  ...,  0.7790, -0.1931, -0.6335]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1027,  1.0000, -0.6573,  ..., -0.9035,  0.4430, -0.8194],\n",
            "        [ 0.0658,  1.0000, -0.7373,  ..., -0.9193,  0.3253, -0.5520],\n",
            "        [ 0.7800,  1.0000,  0.8799,  ...,  0.8626, -0.1310, -0.6584],\n",
            "        ...,\n",
            "        [ 0.2347,  1.0000, -0.8257,  ..., -0.8575,  0.6252, -0.5083],\n",
            "        [ 0.6218,  1.0000,  0.9250,  ...,  0.6500, -0.0293, -0.5534],\n",
            "        [-0.0875,  1.0000, -0.7194,  ..., -0.9143,  0.3488, -0.3189]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7471,  1.0000,  0.9214,  ...,  0.8688, -0.3050, -0.6628],\n",
            "        [-0.3787,  1.0000, -0.4323,  ..., -0.9016,  0.7146, -0.4868],\n",
            "        [ 0.6322,  1.0000,  0.9298,  ...,  0.8106, -0.3063, -0.5391],\n",
            "        ...,\n",
            "        [ 0.6602,  1.0000,  0.8415,  ...,  0.6874, -0.0675, -0.7486],\n",
            "        [ 0.8680,  1.0000,  0.9019,  ...,  0.6082, -0.3125, -0.5182],\n",
            "        [ 0.7475,  1.0000,  0.8641,  ...,  0.8576, -0.3587, -0.5824]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7117,  1.0000,  0.7805,  ..., -0.3346,  0.1848, -0.9811],\n",
            "        [-0.3198,  1.0000, -0.7025,  ..., -0.9251,  0.3290, -0.3984],\n",
            "        [-0.2032,  1.0000, -0.7089,  ..., -0.8934,  0.3183, -0.3751],\n",
            "        ...,\n",
            "        [-0.3270,  1.0000, -0.2597,  ..., -0.9017,  0.6953, -0.7273],\n",
            "        [-0.1137,  0.9998, -0.7667,  ..., -0.8120,  0.2697, -0.2342],\n",
            "        [ 0.0326,  1.0000, -0.6672,  ..., -0.8694,  0.5515, -0.7847]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5779,  1.0000,  0.9022,  ...,  0.1069,  0.2178, -0.9303],\n",
            "        [-0.3053,  0.9998, -0.8066,  ..., -0.8824,  0.4001, -0.2382],\n",
            "        [-0.4999,  1.0000, -0.6044,  ..., -0.9184,  0.2470, -0.7710],\n",
            "        ...,\n",
            "        [ 0.8487,  1.0000,  0.9033,  ...,  0.8156, -0.2031, -0.7550],\n",
            "        [ 0.7267,  1.0000,  0.8518,  ...,  0.8222, -0.2461, -0.6207],\n",
            "        [-0.2162,  1.0000, -0.6259,  ..., -0.8410,  0.2043, -0.2846]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.8370,  1.0000,  0.8895,  ...,  0.8663, -0.1981, -0.7308],\n",
            "        [-0.4810,  1.0000, -0.7920,  ..., -0.8620,  0.1459, -0.3145],\n",
            "        [ 0.7918,  1.0000,  0.9015,  ...,  0.6026, -0.4289, -0.8123],\n",
            "        ...,\n",
            "        [ 0.6876,  1.0000,  0.8617,  ...,  0.8314, -0.3598, -0.6560],\n",
            "        [-0.1681,  1.0000, -0.4822,  ..., -0.8687,  0.7389, -0.8985],\n",
            "        [ 0.7039,  1.0000,  0.8702,  ...,  0.8484, -0.3049, -0.4858]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.8085,  1.0000,  0.8954,  ...,  0.8761, -0.2042, -0.5943],\n",
            "        [-0.4090,  1.0000, -0.5276,  ..., -0.6871,  0.6415, -0.5638],\n",
            "        [ 0.6187,  1.0000,  0.8761,  ...,  0.1209, -0.2765, -0.9715],\n",
            "        ...,\n",
            "        [ 0.7695,  1.0000,  0.8878,  ...,  0.8398, -0.3840, -0.5684],\n",
            "        [-0.1152,  1.0000,  0.0661,  ..., -0.7941, -0.1201, -0.9240],\n",
            "        [ 0.1658,  0.9999,  0.8783,  ..., -0.2405, -0.1679, -0.7964]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7828,  1.0000,  0.8725,  ...,  0.8259, -0.1566, -0.6601],\n",
            "        [ 0.3078,  1.0000,  0.3412,  ..., -0.6419,  0.1307, -0.9579],\n",
            "        [-0.4579,  1.0000, -0.8237,  ..., -0.8876,  0.5941, -0.5955],\n",
            "        ...,\n",
            "        [ 0.0037,  1.0000, -0.3977,  ..., -0.8566,  0.3743, -0.7073],\n",
            "        [-0.0432,  1.0000,  0.3866,  ..., -0.7402,  0.5466, -0.9467],\n",
            "        [ 0.5004,  1.0000,  0.8175,  ...,  0.4972,  0.0433, -0.8745]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6272,  1.0000,  0.8740,  ...,  0.8881, -0.3619, -0.4405],\n",
            "        [-0.0865,  1.0000, -0.6891,  ..., -0.8641,  0.4796, -0.5788],\n",
            "        [-0.2466,  1.0000, -0.6427,  ..., -0.8553,  0.3905, -0.4380],\n",
            "        ...,\n",
            "        [-0.1354,  1.0000,  0.8428,  ..., -0.4504,  0.1661, -0.9473],\n",
            "        [ 0.6691,  1.0000,  0.8784,  ...,  0.8425, -0.6001, -0.5125],\n",
            "        [ 0.7847,  1.0000,  0.8929,  ...,  0.8523, -0.2034, -0.6605]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7282,  1.0000,  0.9341,  ...,  0.8590, -0.3389, -0.5840],\n",
            "        [ 0.7017,  1.0000,  0.8923,  ...,  0.8160,  0.0214, -0.7881],\n",
            "        [-0.3131,  1.0000, -0.5148,  ..., -0.8867,  0.4379, -0.4979],\n",
            "        ...,\n",
            "        [-0.0076,  1.0000, -0.5701,  ..., -0.8809,  0.4419, -0.6261],\n",
            "        [ 0.6786,  1.0000,  0.8945,  ...,  0.7954, -0.5500, -0.6106],\n",
            "        [ 0.7919,  1.0000,  0.8591,  ...,  0.9061,  0.0274, -0.5954]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2805,  1.0000,  0.6429,  ..., -0.1539,  0.2095, -0.9599],\n",
            "        [ 0.7760,  1.0000,  0.9107,  ...,  0.7867,  0.2693, -0.7375],\n",
            "        [-0.4485,  1.0000, -0.7265,  ..., -0.8953,  0.3406, -0.4098],\n",
            "        ...,\n",
            "        [ 0.7025,  1.0000,  0.8844,  ...,  0.8584, -0.2100, -0.6593],\n",
            "        [-0.4048,  1.0000,  0.4502,  ..., -0.7771,  0.1391, -0.9370],\n",
            "        [ 0.6985,  1.0000,  0.9097,  ...,  0.5576, -0.0077, -0.6696]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6410,  1.0000,  0.9368,  ...,  0.7841, -0.1667, -0.7884],\n",
            "        [ 0.7213,  1.0000,  0.8267,  ...,  0.6603, -0.2731, -0.6906],\n",
            "        [-0.1639,  0.9998, -0.7441,  ..., -0.8668,  0.6724, -0.5383],\n",
            "        ...,\n",
            "        [ 0.8689,  1.0000,  0.9273,  ...,  0.8469, -0.0272, -0.7274],\n",
            "        [ 0.7186,  1.0000,  0.8693,  ...,  0.7297, -0.1599, -0.6396],\n",
            "        [-0.0929,  1.0000,  0.6716,  ..., -0.0703,  0.3802, -0.8898]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7852,  1.0000,  0.8864,  ...,  0.8490, -0.3001, -0.7895],\n",
            "        [ 0.7229,  1.0000,  0.9088,  ...,  0.8002, -0.0877, -0.6178],\n",
            "        [ 0.6616,  1.0000,  0.8020,  ...,  0.3432, -0.2460, -0.8788],\n",
            "        ...,\n",
            "        [-0.0369,  1.0000, -0.7113,  ..., -0.7994,  0.4460, -0.3171],\n",
            "        [ 0.6718,  1.0000,  0.8736,  ...,  0.7218, -0.5080, -0.6138],\n",
            "        [-0.3958,  1.0000, -0.7965,  ..., -0.8401,  0.4583, -0.3698]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7407,  1.0000,  0.9161,  ...,  0.8083, -0.4027, -0.6087],\n",
            "        [ 0.7116,  1.0000,  0.8382,  ...,  0.7374, -0.4268, -0.5008],\n",
            "        [ 0.0224,  1.0000,  0.6398,  ..., -0.6897,  0.7024, -0.9604],\n",
            "        ...,\n",
            "        [-0.2959,  1.0000, -0.6464,  ..., -0.8405,  0.6693, -0.7835],\n",
            "        [-0.2398,  1.0000, -0.5549,  ..., -0.8653,  0.4915, -0.6179],\n",
            "        [ 0.7112,  1.0000,  0.9077,  ...,  0.6214, -0.1254, -0.7419]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1772,  1.0000, -0.7140,  ..., -0.9117,  0.4938, -0.5904],\n",
            "        [-0.2094,  1.0000, -0.7031,  ..., -0.9453,  0.2576, -0.1450],\n",
            "        [ 0.3668,  1.0000,  0.8104,  ..., -0.1567, -0.3269, -0.9351],\n",
            "        ...,\n",
            "        [-0.2177,  0.9999, -0.8471,  ..., -0.9238,  0.4480, -0.2413],\n",
            "        [ 0.4239,  1.0000,  0.8186,  ..., -0.5874,  0.2535, -0.9762],\n",
            "        [-0.2138,  1.0000, -0.6239,  ..., -0.7928,  0.5179, -0.4211]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6870,  1.0000,  0.9037,  ...,  0.6750, -0.2270, -0.7449],\n",
            "        [ 0.7585,  1.0000,  0.8865,  ...,  0.0487,  0.0417, -0.9615],\n",
            "        [ 0.0254,  1.0000, -0.4436,  ..., -0.8930,  0.5734, -0.7971],\n",
            "        ...,\n",
            "        [ 0.7578,  1.0000,  0.8877,  ...,  0.8122, -0.2139, -0.7832],\n",
            "        [ 0.5465,  1.0000,  0.8846,  ...,  0.8060, -0.3868, -0.5600],\n",
            "        [ 0.5734,  1.0000,  0.8964,  ...,  0.3898, -0.3819, -0.8359]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7527,  1.0000,  0.9188,  ...,  0.7164, -0.2932, -0.7167],\n",
            "        [ 0.2236,  1.0000,  0.0528,  ..., -0.8388,  0.7020, -0.9598],\n",
            "        [ 0.4971,  1.0000,  0.8348,  ..., -0.4000,  0.4206, -0.9039],\n",
            "        ...,\n",
            "        [ 0.6887,  1.0000,  0.8671,  ...,  0.7344, -0.2215, -0.6117],\n",
            "        [ 0.1998,  1.0000, -0.1181,  ..., -0.8796,  0.6881, -0.8832],\n",
            "        [-0.3690,  1.0000, -0.7025,  ..., -0.8976,  0.5119, -0.4734]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2975,  1.0000, -0.8656,  ..., -0.9121,  0.3110, -0.0676],\n",
            "        [ 0.4318,  1.0000,  0.8544,  ..., -0.7684,  0.2944, -0.9191],\n",
            "        [ 0.6525,  1.0000,  0.8853,  ...,  0.7456, -0.4359, -0.7943],\n",
            "        ...,\n",
            "        [ 0.3894,  1.0000,  0.8805,  ...,  0.4952, -0.0095, -0.7501],\n",
            "        [ 0.7216,  1.0000,  0.8386,  ...,  0.6780, -0.2298, -0.4012],\n",
            "        [ 0.4810,  1.0000,  0.9330,  ...,  0.7016, -0.1923, -0.7251]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0681,  0.9998, -0.6137,  ..., -0.8342,  0.2675, -0.3456],\n",
            "        [-0.1602,  1.0000, -0.4950,  ..., -0.9114,  0.5456, -0.5843],\n",
            "        [ 0.0637,  0.9999, -0.7820,  ..., -0.9064,  0.5142, -0.0677],\n",
            "        ...,\n",
            "        [ 0.0121,  1.0000, -0.3923,  ..., -0.8178,  0.5647, -0.2036],\n",
            "        [ 0.0617,  1.0000, -0.5821,  ..., -0.8064,  0.7403, -0.7129],\n",
            "        [ 0.1474,  1.0000,  0.1168,  ..., -0.7805,  0.7925, -0.8719]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4688,  1.0000,  0.8800,  ...,  0.0736, -0.2037, -0.9413],\n",
            "        [-0.1891,  1.0000, -0.6352,  ..., -0.8977,  0.3609, -0.4110],\n",
            "        [-0.1061,  1.0000, -0.5925,  ..., -0.8098,  0.7414, -0.8288],\n",
            "        ...,\n",
            "        [-0.0419,  0.9991,  0.6162,  ..., -0.1182,  0.1831, -0.8930],\n",
            "        [-0.4563,  0.9999, -0.7532,  ..., -0.8857,  0.2487, -0.4047],\n",
            "        [-0.0921,  0.9997,  0.5818,  ..., -0.5697,  0.1110, -0.9225]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1579,  1.0000,  0.0441,  ..., -0.8825,  0.5495, -0.8634],\n",
            "        [ 0.6399,  1.0000,  0.8870,  ...,  0.6550, -0.3901, -0.7129],\n",
            "        [ 0.6719,  1.0000,  0.8479,  ...,  0.6533, -0.2654, -0.7448],\n",
            "        ...,\n",
            "        [-0.3372,  1.0000, -0.7040,  ..., -0.9056,  0.1026, -0.5278],\n",
            "        [-0.3029,  1.0000, -0.4120,  ..., -0.8622,  0.4088, -0.6121],\n",
            "        [-0.2386,  0.9999, -0.6930,  ..., -0.9162,  0.1835, -0.3330]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6776,  1.0000,  0.8964,  ...,  0.7869, -0.3893, -0.6632],\n",
            "        [ 0.5571,  1.0000,  0.8555,  ...,  0.5090, -0.0724, -0.8249],\n",
            "        [ 0.7479,  1.0000,  0.8947,  ...,  0.5720, -0.0874, -0.8251],\n",
            "        ...,\n",
            "        [-0.1944,  1.0000,  0.2402,  ..., -0.5716,  0.2717, -0.9285],\n",
            "        [ 0.5133,  1.0000,  0.8819,  ...,  0.5113, -0.3711, -0.5137],\n",
            "        [ 0.6352,  1.0000,  0.8831,  ...,  0.7885, -0.4813, -0.4945]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0631,  1.0000, -0.6798,  ..., -0.8247,  0.5398, -0.8314],\n",
            "        [ 0.7337,  1.0000,  0.9007,  ...,  0.4586, -0.4982, -0.8454],\n",
            "        [-0.3645,  1.0000, -0.3236,  ..., -0.9433,  0.5865, -0.8613],\n",
            "        ...,\n",
            "        [ 0.5688,  1.0000,  0.8612,  ...,  0.6268, -0.3771, -0.6502],\n",
            "        [ 0.5979,  1.0000,  0.8534,  ..., -0.6135,  0.1521, -0.9695],\n",
            "        [-0.1740,  0.9999, -0.7370,  ..., -0.8380,  0.2582, -0.1344]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5175,  0.9999,  0.8144,  ...,  0.4444, -0.3621, -0.6013],\n",
            "        [ 0.4380,  1.0000,  0.7281,  ..., -0.4933,  0.3630, -0.9791],\n",
            "        [-0.2247,  1.0000, -0.2857,  ..., -0.8632,  0.4362, -0.6976],\n",
            "        ...,\n",
            "        [-0.0707,  1.0000,  0.4444,  ..., -0.8584,  0.4261, -0.9556],\n",
            "        [ 0.6689,  1.0000,  0.8988,  ...,  0.8213, -0.4213, -0.5211],\n",
            "        [-0.0381,  1.0000, -0.4171,  ..., -0.8118,  0.6044, -0.6181]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2596,  1.0000, -0.6780,  ..., -0.8983,  0.3142, -0.3378],\n",
            "        [ 0.0698,  1.0000, -0.1935,  ..., -0.8923,  0.4442, -0.6760],\n",
            "        [-0.1792,  1.0000,  0.3372,  ..., -0.7331,  0.4591, -0.7642],\n",
            "        ...,\n",
            "        [ 0.4814,  1.0000,  0.9184,  ...,  0.4133, -0.2911, -0.7131],\n",
            "        [ 0.6157,  1.0000,  0.8679,  ...,  0.6549, -0.2619, -0.4945],\n",
            "        [ 0.7433,  1.0000,  0.8333,  ...,  0.8450, -0.4458, -0.7297]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4032,  1.0000, -0.6813,  ..., -0.8984,  0.1008, -0.4249],\n",
            "        [-0.3874,  1.0000, -0.7659,  ..., -0.8747,  0.1101, -0.0946],\n",
            "        [ 0.3390,  0.9995,  0.8918,  ...,  0.1973, -0.2599, -0.6963],\n",
            "        ...,\n",
            "        [ 0.4232,  1.0000,  0.8005,  ...,  0.4201, -0.4035, -0.5476],\n",
            "        [-0.2263,  1.0000, -0.5253,  ..., -0.8684,  0.4243, -0.4772],\n",
            "        [ 0.5923,  1.0000,  0.4600,  ..., -0.3019,  0.4395, -0.9710]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7534,  1.0000,  0.8091,  ...,  0.6200, -0.2669, -0.7219],\n",
            "        [ 0.5948,  1.0000,  0.8481,  ...,  0.3419, -0.1602, -0.7603],\n",
            "        [-0.1000,  1.0000,  0.8765,  ..., -0.2912, -0.1106, -0.9039],\n",
            "        ...,\n",
            "        [-0.4346,  1.0000, -0.2430,  ..., -0.7483,  0.4150, -0.5018],\n",
            "        [ 0.5754,  1.0000,  0.8998,  ...,  0.2881, -0.3553, -0.6882],\n",
            "        [-0.1758,  1.0000, -0.5099,  ..., -0.8833,  0.0031, -0.6229]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7022,  1.0000,  0.8979,  ...,  0.6978, -0.3397, -0.5856],\n",
            "        [ 0.4735,  1.0000,  0.7662,  ...,  0.6209, -0.1007, -0.7273],\n",
            "        [ 0.5466,  1.0000,  0.8248,  ...,  0.4596, -0.4570, -0.6203],\n",
            "        ...,\n",
            "        [ 0.6794,  0.9999,  0.7930,  ...,  0.6347, -0.5759, -0.5536],\n",
            "        [-0.2166,  1.0000, -0.3686,  ..., -0.8406,  0.0311, -0.4560],\n",
            "        [ 0.5285,  1.0000,  0.9011,  ...,  0.1663, -0.0871, -0.7500]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2185,  1.0000, -0.2800,  ..., -0.8356,  0.2639, -0.8713],\n",
            "        [-0.4512,  1.0000, -0.6808,  ..., -0.8759,  0.2070, -0.4137],\n",
            "        [-0.3299,  1.0000, -0.6909,  ..., -0.8837,  0.0275, -0.4138],\n",
            "        ...,\n",
            "        [ 0.6359,  1.0000,  0.8829,  ...,  0.6548, -0.4496, -0.4250],\n",
            "        [ 0.6313,  1.0000,  0.8896,  ...,  0.3547, -0.2734, -0.7879],\n",
            "        [ 0.8042,  1.0000,  0.8977,  ...,  0.7195, -0.1494, -0.7426]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2227,  1.0000, -0.6118,  ..., -0.7814,  0.0135, -0.3540],\n",
            "        [ 0.5962,  1.0000,  0.7553,  ...,  0.5717, -0.1339, -0.7662],\n",
            "        [-0.2918,  1.0000, -0.6836,  ..., -0.9107,  0.4703, -0.2968],\n",
            "        ...,\n",
            "        [ 0.5839,  1.0000,  0.7727,  ...,  0.4300, -0.3118, -0.4765],\n",
            "        [ 0.6541,  1.0000,  0.9540,  ..., -0.2222,  0.4151, -0.9701],\n",
            "        [ 0.6488,  1.0000,  0.8621,  ...,  0.6243, -0.2372, -0.4556]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6338,  1.0000,  0.8740,  ...,  0.4998, -0.2149, -0.4751],\n",
            "        [ 0.7914,  1.0000,  0.8480,  ...,  0.7401, -0.1396, -0.6881],\n",
            "        [ 0.4895,  1.0000,  0.8995,  ..., -0.0510, -0.5017, -0.7036],\n",
            "        ...,\n",
            "        [-0.2290,  1.0000, -0.6804,  ..., -0.9138,  0.1790, -0.2708],\n",
            "        [ 0.5388,  1.0000,  0.8006,  ..., -0.1345,  0.3685, -0.9377],\n",
            "        [ 0.6262,  0.9999,  0.8365,  ...,  0.6183, -0.4678, -0.6187]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1923,  1.0000, -0.8304,  ..., -0.8969,  0.3069, -0.2445],\n",
            "        [ 0.2583,  1.0000, -0.1804,  ..., -0.8681,  0.1340, -0.4368],\n",
            "        [-0.0434,  1.0000, -0.1144,  ..., -0.8763,  0.4082, -0.9205],\n",
            "        ...,\n",
            "        [-0.3772,  1.0000, -0.6443,  ..., -0.8313,  0.1056, -0.5594],\n",
            "        [ 0.4477,  1.0000,  0.7538,  ...,  0.5426, -0.5378, -0.5631],\n",
            "        [-0.3840,  0.9999, -0.5978,  ..., -0.8628,  0.4360, -0.0078]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6519,  1.0000,  0.8695,  ...,  0.2653, -0.0489, -0.7780],\n",
            "        [ 0.5391,  1.0000,  0.8644,  ...,  0.7069, -0.4869, -0.5858],\n",
            "        [-0.1097,  1.0000, -0.8770,  ..., -0.8992,  0.3800, -0.3612],\n",
            "        ...,\n",
            "        [ 0.6450,  0.9998,  0.9258,  ...,  0.6949, -0.4409, -0.4078],\n",
            "        [-0.0201,  1.0000, -0.5203,  ..., -0.7661, -0.1215, -0.3685],\n",
            "        [ 0.6967,  1.0000,  0.8620,  ...,  0.7247, -0.4446, -0.5601]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2717,  1.0000, -0.4776,  ..., -0.8592,  0.5066, -0.7642],\n",
            "        [ 0.5705,  1.0000,  0.8662,  ...,  0.3692, -0.2248, -0.6641],\n",
            "        [-0.4479,  1.0000, -0.7039,  ..., -0.8854,  0.0715, -0.6982],\n",
            "        ...,\n",
            "        [ 0.2045,  1.0000,  0.7792,  ...,  0.2375,  0.5810, -0.9491],\n",
            "        [-0.4444,  1.0000, -0.6112,  ..., -0.9059,  0.1635, -0.7102],\n",
            "        [ 0.6383,  1.0000,  0.8770,  ...,  0.5323, -0.1840, -0.8588]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6067,  1.0000,  0.7742,  ...,  0.0400, -0.1782, -0.7693],\n",
            "        [ 0.4486,  1.0000,  0.9221,  ...,  0.3729, -0.3857, -0.6301],\n",
            "        [-0.3582,  0.9995, -0.6979,  ..., -0.9103,  0.1050,  0.0200],\n",
            "        ...,\n",
            "        [-0.1536,  0.9980,  0.7517,  ..., -0.1851, -0.1214, -0.6068],\n",
            "        [ 0.7209,  1.0000,  0.8668,  ...,  0.7024, -0.4212, -0.6002],\n",
            "        [-0.5823,  0.9999, -0.7985,  ..., -0.8882,  0.4336, -0.3590]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0093,  1.0000, -0.6126,  ..., -0.8505,  0.1998, -0.3186],\n",
            "        [ 0.4798,  1.0000,  0.7784,  ...,  0.4111, -0.3474, -0.7365],\n",
            "        [-0.2694,  0.9999,  0.6001,  ..., -0.4656,  0.4050, -0.6451],\n",
            "        ...,\n",
            "        [ 0.3551,  0.9999,  0.8936,  ..., -0.2881, -0.6007, -0.8589],\n",
            "        [ 0.4726,  1.0000,  0.7706,  ..., -0.6676,  0.2062, -0.9565],\n",
            "        [-0.0815,  1.0000, -0.2020,  ..., -0.8651,  0.2674, -0.8834]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3095,  0.9999, -0.8319,  ..., -0.8591,  0.3005, -0.3001],\n",
            "        [-0.4119,  0.9997, -0.8398,  ..., -0.9309,  0.2278, -0.3553],\n",
            "        [-0.3413,  0.9999, -0.7668,  ..., -0.9215,  0.3715, -0.0902],\n",
            "        ...,\n",
            "        [-0.1554,  1.0000,  0.2737,  ..., -0.8343,  0.5182, -0.9487],\n",
            "        [-0.1421,  0.9999, -0.5271,  ..., -0.9423,  0.3286, -0.6057],\n",
            "        [-0.3602,  0.9999, -0.5949,  ..., -0.8553,  0.4006, -0.1938]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2809,  1.0000, -0.5001,  ..., -0.8826,  0.2722, -0.6781],\n",
            "        [-0.1861,  1.0000, -0.5042,  ..., -0.8680,  0.2908, -0.8258],\n",
            "        [-0.3294,  0.9991, -0.7099,  ..., -0.9169,  0.0760, -0.0752],\n",
            "        ...,\n",
            "        [ 0.4350,  1.0000,  0.8801,  ...,  0.5459, -0.0719, -0.9349],\n",
            "        [-0.5071,  0.9997, -0.7704,  ..., -0.9576,  0.0268, -0.3943],\n",
            "        [ 0.7129,  1.0000,  0.9022,  ...,  0.4604,  0.0897, -0.9084]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1003,  0.9997, -0.7107,  ..., -0.9022, -0.1663, -0.2581],\n",
            "        [ 0.5299,  0.9999,  0.8567,  ...,  0.2979, -0.2226, -0.5664],\n",
            "        [-0.2061,  1.0000, -0.5658,  ..., -0.8334,  0.3950, -0.8306],\n",
            "        ...,\n",
            "        [ 0.2907,  1.0000,  0.6536,  ..., -0.8880,  0.4261, -0.9879],\n",
            "        [ 0.4412,  0.9999,  0.8441,  ...,  0.6084, -0.4137, -0.4894],\n",
            "        [-0.4305,  1.0000, -0.5523,  ..., -0.8904,  0.3354, -0.5080]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1960,  1.0000,  0.6312,  ..., -0.7264,  0.2673, -0.9025],\n",
            "        [ 0.5630,  0.9999,  0.8956,  ...,  0.4467, -0.4806, -0.3670],\n",
            "        [ 0.4392,  0.9999,  0.9014,  ...,  0.3759, -0.3748, -0.6293],\n",
            "        ...,\n",
            "        [-0.2117,  1.0000, -0.6644,  ..., -0.9295,  0.4032, -0.5039],\n",
            "        [-0.2266,  0.9999, -0.6640,  ..., -0.9004,  0.0903, -0.3757],\n",
            "        [ 0.5257,  1.0000,  0.8250,  ...,  0.5599, -0.2162, -0.5345]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2649,  1.0000, -0.6202,  ..., -0.8615,  0.2886, -0.6802],\n",
            "        [-0.2161,  1.0000, -0.4871,  ..., -0.9335,  0.3101, -0.5859],\n",
            "        [-0.0147,  1.0000, -0.1165,  ..., -0.8629,  0.3165, -0.6493],\n",
            "        ...,\n",
            "        [ 0.0596,  1.0000,  0.2135,  ..., -0.7659,  0.3028, -0.9566],\n",
            "        [-0.0963,  1.0000,  0.9237,  ..., -0.4953,  0.0051, -0.8581],\n",
            "        [ 0.5627,  1.0000,  0.8724,  ...,  0.5462, -0.4101, -0.5379]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3563,  0.9999,  0.8811,  ...,  0.2936, -0.4279, -0.6414],\n",
            "        [ 0.0908,  1.0000, -0.6773,  ..., -0.9448,  0.0414, -0.6743],\n",
            "        [-0.5027,  1.0000, -0.5802,  ..., -0.8694,  0.1272, -0.4934],\n",
            "        ...,\n",
            "        [-0.2379,  0.9999, -0.7226,  ..., -0.8920,  0.0425, -0.1164],\n",
            "        [-0.1817,  1.0000,  0.3278,  ..., -0.8585,  0.1886, -0.9375],\n",
            "        [ 0.5822,  1.0000,  0.7064,  ..., -0.7290,  0.4530, -0.9301]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5359,  1.0000,  0.8334,  ...,  0.2494, -0.4959, -0.4479],\n",
            "        [ 0.1430,  1.0000,  0.8221,  ..., -0.6302, -0.0987, -0.9269],\n",
            "        [ 0.5081,  1.0000,  0.8943,  ...,  0.5090, -0.3730, -0.4106],\n",
            "        ...,\n",
            "        [ 0.5881,  0.9999,  0.8076,  ...,  0.6319, -0.6312, -0.3226],\n",
            "        [ 0.5379,  1.0000,  0.8491,  ...,  0.5208, -0.3077, -0.6657],\n",
            "        [ 0.0375,  1.0000,  0.8213,  ..., -0.8541,  0.4509, -0.9229]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1516,  1.0000, -0.4464,  ..., -0.9029,  0.2741, -0.8209],\n",
            "        [ 0.3795,  0.9998,  0.8456,  ...,  0.3428, -0.6259, -0.3787],\n",
            "        [ 0.0421,  1.0000, -0.4343,  ..., -0.8941,  0.3025, -0.7694],\n",
            "        ...,\n",
            "        [ 0.2059,  0.9999,  0.7919,  ..., -0.3290, -0.4196, -0.8145],\n",
            "        [ 0.5579,  0.9999,  0.8766,  ...,  0.6392, -0.2820, -0.4751],\n",
            "        [ 0.2928,  1.0000, -0.4022,  ..., -0.9486,  0.2057, -0.6917]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2651,  1.0000, -0.3945,  ..., -0.8781,  0.4362, -0.8567],\n",
            "        [ 0.4829,  1.0000,  0.9159,  ..., -0.5031,  0.0688, -0.8991],\n",
            "        [-0.1877,  1.0000, -0.6773,  ..., -0.9159,  0.1647, -0.4763],\n",
            "        ...,\n",
            "        [ 0.3625,  1.0000, -0.1262,  ..., -0.8648, -0.0155, -0.8771],\n",
            "        [ 0.1542,  0.9992,  0.8408,  ...,  0.4542, -0.6489, -0.2593],\n",
            "        [ 0.4112,  1.0000,  0.8957,  ..., -0.6259,  0.2053, -0.9631]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1638,  1.0000,  0.4940,  ..., -0.6080,  0.6675, -0.8023],\n",
            "        [ 0.3213,  1.0000,  0.8239,  ..., -0.7921,  0.1852, -0.8854],\n",
            "        [ 0.1769,  1.0000,  0.9002,  ..., -0.4376,  0.3591, -0.9246],\n",
            "        ...,\n",
            "        [ 0.0505,  1.0000,  0.7995,  ..., -0.7712,  0.3991, -0.9656],\n",
            "        [-0.0178,  1.0000, -0.6415,  ..., -0.9268,  0.1906, -0.7563],\n",
            "        [ 0.2600,  1.0000,  0.4722,  ..., -0.8731,  0.6642, -0.9265]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3518,  1.0000,  0.4848,  ..., -0.8454,  0.4482, -0.9605],\n",
            "        [ 0.2963,  1.0000,  0.7385,  ..., -0.5638, -0.1683, -0.9304],\n",
            "        [-0.3566,  1.0000, -0.3995,  ..., -0.9318,  0.1797, -0.7734],\n",
            "        ...,\n",
            "        [ 0.0935,  1.0000,  0.5661,  ..., -0.6876,  0.6039, -0.9674],\n",
            "        [-0.0466,  1.0000,  0.1916,  ..., -0.8153,  0.4006, -0.9427],\n",
            "        [ 0.7112,  1.0000,  0.7917,  ...,  0.4791, -0.3941, -0.6396]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6274,  1.0000,  0.8870,  ...,  0.3965, -0.2449, -0.7305],\n",
            "        [ 0.4977,  1.0000,  0.8763,  ...,  0.5167, -0.4494, -0.5999],\n",
            "        [-0.3684,  1.0000, -0.4522,  ..., -0.8640,  0.1727, -0.5728],\n",
            "        ...,\n",
            "        [-0.4387,  1.0000,  0.0545,  ..., -0.8236,  0.2826, -0.9635],\n",
            "        [-0.0067,  1.0000, -0.5370,  ..., -0.8704,  0.3896, -0.6891],\n",
            "        [-0.1091,  1.0000, -0.4880,  ..., -0.8597,  0.5400, -0.8174]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3628,  1.0000, -0.6115,  ..., -0.8991,  0.2853, -0.3237],\n",
            "        [ 0.5858,  1.0000,  0.7823,  ...,  0.5710, -0.2400, -0.7847],\n",
            "        [ 0.3719,  1.0000,  0.8448,  ...,  0.2438, -0.4081, -0.5524],\n",
            "        ...,\n",
            "        [ 0.5034,  1.0000,  0.8295,  ...,  0.5897, -0.2349, -0.6157],\n",
            "        [ 0.1308,  1.0000,  0.9099,  ..., -0.2333, -0.0163, -0.9469],\n",
            "        [-0.2565,  1.0000, -0.5745,  ..., -0.9371,  0.0951, -0.7331]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5273,  1.0000,  0.8474,  ...,  0.2731, -0.3206, -0.6667],\n",
            "        [-0.1254,  1.0000,  0.8277,  ..., -0.3029, -0.2852, -0.9400],\n",
            "        [ 0.4774,  1.0000,  0.8695,  ...,  0.5121, -0.2366, -0.4254],\n",
            "        ...,\n",
            "        [ 0.5778,  1.0000,  0.9124,  ...,  0.5418, -0.2877, -0.6724],\n",
            "        [ 0.1479,  1.0000, -0.1686,  ..., -0.8625,  0.1947, -0.9342],\n",
            "        [ 0.4283,  1.0000,  0.4568,  ..., -0.4708, -0.0754, -0.9572]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2829,  1.0000,  0.5256,  ..., -0.7922,  0.6975, -0.8981],\n",
            "        [ 0.1427,  1.0000,  0.8261,  ..., -0.5977, -0.4011, -0.9740],\n",
            "        [ 0.5187,  0.9996,  0.8843,  ...,  0.5765, -0.0462, -0.5012],\n",
            "        ...,\n",
            "        [-0.0330,  1.0000,  0.2395,  ..., -0.9158,  0.1240, -0.8721],\n",
            "        [-0.1159,  1.0000, -0.4851,  ..., -0.9456,  0.3604, -0.7752],\n",
            "        [-0.2016,  1.0000, -0.1725,  ..., -0.8100, -0.0722, -0.8525]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1899,  1.0000,  0.6011,  ..., -0.8141,  0.2144, -0.9523],\n",
            "        [ 0.0453,  1.0000, -0.4139,  ..., -0.9317, -0.2502, -0.7740],\n",
            "        [ 0.2982,  1.0000,  0.8298,  ..., -0.1444, -0.0086, -0.9533],\n",
            "        ...,\n",
            "        [-0.1604,  1.0000, -0.3605,  ..., -0.9054,  0.2573, -0.5634],\n",
            "        [ 0.4331,  1.0000,  0.6837,  ..., -0.7172,  0.2959, -0.9475],\n",
            "        [ 0.6820,  1.0000,  0.9142,  ...,  0.6269, -0.1940, -0.5857]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2951,  1.0000, -0.1005,  ..., -0.8997,  0.1901, -0.8650],\n",
            "        [ 0.0972,  1.0000, -0.2232,  ..., -0.9223,  0.0355, -0.9021],\n",
            "        [ 0.5932,  1.0000,  0.8124,  ...,  0.5764, -0.2897, -0.6023],\n",
            "        ...,\n",
            "        [ 0.7452,  1.0000,  0.7503,  ..., -0.2443, -0.0406, -0.9005],\n",
            "        [ 0.7401,  1.0000,  0.8737,  ...,  0.6787, -0.4431, -0.4942],\n",
            "        [-0.0031,  1.0000,  0.6107,  ..., -0.6177, -0.3210, -0.9380]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0874,  1.0000,  0.6048,  ..., -0.4928,  0.2777, -0.9361],\n",
            "        [ 0.0363,  1.0000,  0.7701,  ..., -0.7351,  0.2493, -0.9684],\n",
            "        [ 0.0264,  1.0000,  0.0617,  ..., -0.8556,  0.2575, -0.9457],\n",
            "        ...,\n",
            "        [ 0.6787,  1.0000,  0.8024,  ...,  0.4942, -0.2596, -0.6692],\n",
            "        [ 0.1916,  1.0000, -0.5231,  ..., -0.8343,  0.4455, -0.6794],\n",
            "        [ 0.4913,  1.0000,  0.8869,  ...,  0.1077, -0.1972, -0.9157]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0052,  1.0000,  0.7484,  ..., -0.1590,  0.0628, -0.9125],\n",
            "        [ 0.6854,  1.0000,  0.8634,  ...,  0.4927, -0.2227, -0.6467],\n",
            "        [ 0.5929,  1.0000,  0.9338,  ...,  0.1848, -0.4135, -0.7823],\n",
            "        ...,\n",
            "        [ 0.0508,  1.0000, -0.4991,  ..., -0.9308,  0.1870, -0.7634],\n",
            "        [ 0.7133,  1.0000,  0.8754,  ...,  0.4797, -0.2570, -0.8531],\n",
            "        [ 0.3308,  1.0000, -0.3228,  ..., -0.8433,  0.3320, -0.9071]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3843,  1.0000,  0.3276,  ..., -0.8656,  0.3659, -0.9212],\n",
            "        [ 0.6284,  1.0000,  0.8957,  ...,  0.6292, -0.0810, -0.7457],\n",
            "        [ 0.6823,  1.0000,  0.9022,  ...,  0.6102, -0.5336, -0.4631],\n",
            "        ...,\n",
            "        [ 0.2235,  1.0000,  0.8172,  ..., -0.3989, -0.1172, -0.8847],\n",
            "        [-0.3263,  1.0000, -0.3266,  ..., -0.9042,  0.0859, -0.6895],\n",
            "        [-0.0353,  1.0000, -0.3356,  ..., -0.7414,  0.1167, -0.8649]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6518,  1.0000,  0.8541,  ..., -0.0015,  0.1607, -0.8931],\n",
            "        [ 0.6424,  1.0000,  0.9401,  ...,  0.8012, -0.1220, -0.5507],\n",
            "        [ 0.5099,  0.9999,  0.8950,  ...,  0.4193, -0.3935, -0.3788],\n",
            "        ...,\n",
            "        [ 0.6007,  1.0000,  0.8694,  ...,  0.7251, -0.2586, -0.6758],\n",
            "        [ 0.6309,  1.0000,  0.8436,  ...,  0.5694, -0.0979, -0.6123],\n",
            "        [ 0.7421,  1.0000,  0.7550,  ...,  0.4110,  0.2530, -0.8182]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3462,  1.0000, -0.2832,  ..., -0.8433,  0.2924, -0.9560],\n",
            "        [ 0.6394,  1.0000,  0.8540,  ...,  0.2371, -0.2478, -0.8425],\n",
            "        [ 0.7371,  1.0000,  0.8705,  ...,  0.3014, -0.2690, -0.9046],\n",
            "        ...,\n",
            "        [ 0.6390,  1.0000,  0.8694,  ...,  0.3844, -0.2806, -0.6145],\n",
            "        [ 0.4445,  0.9991,  0.8951,  ...,  0.1871, -0.0151, -0.6565],\n",
            "        [ 0.6782,  1.0000,  0.8954,  ...,  0.5646,  0.1322, -0.8477]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7242,  1.0000,  0.9198,  ...,  0.2560,  0.1143, -0.9566],\n",
            "        [ 0.7077,  1.0000,  0.8814,  ...,  0.5622, -0.3423, -0.6631],\n",
            "        [-0.0306,  1.0000, -0.3145,  ..., -0.8876,  0.2579, -0.8337],\n",
            "        ...,\n",
            "        [ 0.0548,  1.0000, -0.2030,  ..., -0.9084,  0.3170, -0.8930],\n",
            "        [-0.0572,  1.0000, -0.3042,  ..., -0.8873,  0.1735, -0.8446],\n",
            "        [-0.1776,  1.0000, -0.6860,  ..., -0.8868,  0.0616, -0.6227]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0496,  1.0000, -0.3697,  ..., -0.9302,  0.5751, -0.8328],\n",
            "        [ 0.4976,  1.0000,  0.9233,  ..., -0.4153,  0.1264, -0.9748],\n",
            "        [ 0.5978,  1.0000,  0.9015,  ...,  0.6177, -0.2876, -0.5530],\n",
            "        ...,\n",
            "        [-0.1512,  1.0000, -0.7304,  ..., -0.8946,  0.4121, -0.6024],\n",
            "        [-0.4329,  1.0000, -0.3070,  ..., -0.8776,  0.3992, -0.8263],\n",
            "        [-0.3212,  1.0000, -0.7022,  ..., -0.8998,  0.5231, -0.6505]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5936,  1.0000,  0.8970,  ...,  0.6729, -0.3389, -0.6811],\n",
            "        [ 0.1689,  1.0000, -0.0947,  ..., -0.8311,  0.6648, -0.7817],\n",
            "        [-0.0290,  1.0000, -0.4782,  ..., -0.9141,  0.5637, -0.8543],\n",
            "        ...,\n",
            "        [ 0.6439,  1.0000,  0.7999,  ...,  0.5100, -0.5091, -0.6417],\n",
            "        [-0.0219,  1.0000,  0.6441,  ..., -0.5091,  0.3260, -0.9684],\n",
            "        [ 0.1931,  1.0000,  0.3707,  ..., -0.8391,  0.4324, -0.9157]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0976,  1.0000, -0.5567,  ..., -0.7981,  0.6573, -0.6017],\n",
            "        [ 0.6319,  1.0000,  0.9149,  ...,  0.1853, -0.2384, -0.5628],\n",
            "        [ 0.5993,  0.9998,  0.8086,  ...,  0.5857, -0.3637, -0.5291],\n",
            "        ...,\n",
            "        [ 0.6148,  1.0000,  0.9175,  ...,  0.5835, -0.2331, -0.7873],\n",
            "        [ 0.6589,  1.0000,  0.8597,  ..., -0.0495,  0.2901, -0.9180],\n",
            "        [ 0.1641,  1.0000, -0.3454,  ..., -0.9097,  0.4819, -0.8998]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4124,  0.9999, -0.3259,  ..., -0.9507,  0.4726, -0.8993],\n",
            "        [ 0.5075,  1.0000,  0.9142,  ...,  0.0030,  0.0153, -0.8569],\n",
            "        [ 0.7623,  1.0000,  0.8794,  ...,  0.6519, -0.1388, -0.7042],\n",
            "        ...,\n",
            "        [ 0.6221,  1.0000,  0.8126,  ..., -0.1203, -0.1179, -0.9353],\n",
            "        [ 0.5676,  1.0000,  0.9119,  ...,  0.2843, -0.0858, -0.7933],\n",
            "        [ 0.4436,  1.0000,  0.8521,  ...,  0.0207, -0.2937, -0.8768]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1477,  1.0000,  0.3548,  ..., -0.6367,  0.6268, -0.8934],\n",
            "        [-0.1505,  1.0000,  0.4806,  ..., -0.8179,  0.5366, -0.9533],\n",
            "        [ 0.6149,  1.0000,  0.8841,  ...,  0.0223, -0.2071, -0.9086],\n",
            "        ...,\n",
            "        [-0.1580,  1.0000, -0.1685,  ..., -0.8374,  0.5674, -0.7809],\n",
            "        [-0.1694,  1.0000, -0.5445,  ..., -0.8904,  0.5216, -0.9171],\n",
            "        [ 0.0157,  1.0000, -0.4191,  ..., -0.8891,  0.3579, -0.9363]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2460,  1.0000, -0.2114,  ..., -0.8069,  0.3867, -0.8981],\n",
            "        [ 0.5482,  1.0000,  0.1734,  ..., -0.7879,  0.6353, -0.9583],\n",
            "        [ 0.7933,  1.0000,  0.8592,  ...,  0.1075, -0.0710, -0.7881],\n",
            "        ...,\n",
            "        [-0.1539,  1.0000,  0.3960,  ..., -0.6791,  0.2539, -0.8472],\n",
            "        [ 0.2424,  1.0000, -0.2025,  ..., -0.7862,  0.4678, -0.8981],\n",
            "        [ 0.6560,  1.0000,  0.7587,  ...,  0.5383, -0.1355, -0.9011]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0422,  0.9766,  0.4626,  ..., -0.2704,  0.1839, -0.6865],\n",
            "        [ 0.4283,  1.0000,  0.4123,  ..., -0.6288,  0.7191, -0.9711],\n",
            "        [ 0.3663,  1.0000,  0.4304,  ..., -0.6478,  0.5334, -0.9549],\n",
            "        ...,\n",
            "        [-0.5282,  1.0000, -0.6183,  ..., -0.8908,  0.0789, -0.4890],\n",
            "        [ 0.6819,  1.0000,  0.8175,  ...,  0.5152, -0.2057, -0.7924],\n",
            "        [ 0.6939,  1.0000,  0.8937,  ...,  0.7094, -0.3086, -0.7356]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3560,  1.0000, -0.7255,  ..., -0.9059,  0.4934, -0.4161],\n",
            "        [-0.3768,  1.0000, -0.2172,  ..., -0.8402,  0.6234, -0.8313],\n",
            "        [-0.1955,  1.0000, -0.6664,  ..., -0.9111,  0.5639, -0.8483],\n",
            "        ...,\n",
            "        [-0.3765,  1.0000, -0.7549,  ..., -0.8352,  0.4279, -0.6893],\n",
            "        [ 0.4378,  1.0000,  0.6196,  ..., -0.4254,  0.4028, -0.9816],\n",
            "        [-0.3484,  1.0000, -0.4975,  ..., -0.8655,  0.1875, -0.6425]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7641,  1.0000,  0.9360,  ...,  0.7526, -0.1036, -0.8511],\n",
            "        [ 0.8088,  1.0000,  0.8737,  ...,  0.6941, -0.2592, -0.8452],\n",
            "        [-0.2783,  1.0000, -0.2021,  ..., -0.9422,  0.5377, -0.8517],\n",
            "        ...,\n",
            "        [-0.2842,  1.0000, -0.7928,  ..., -0.8911,  0.3736, -0.6263],\n",
            "        [ 0.6941,  1.0000,  0.8759,  ...,  0.3748, -0.2255, -0.8331],\n",
            "        [ 0.6520,  1.0000,  0.8570,  ...,  0.1381, -0.3538, -0.9299]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0918,  1.0000,  0.0339,  ..., -0.7808,  0.7085, -0.8236],\n",
            "        [ 0.1395,  1.0000, -0.6591,  ..., -0.8605,  0.6505, -0.6974],\n",
            "        [-0.1784,  1.0000, -0.7932,  ..., -0.8883,  0.4305, -0.1609],\n",
            "        ...,\n",
            "        [ 0.6732,  1.0000,  0.8100,  ...,  0.1870, -0.1432, -0.8664],\n",
            "        [-0.0897,  1.0000, -0.6777,  ..., -0.9028,  0.5313, -0.7613],\n",
            "        [ 0.2836,  1.0000, -0.1335,  ..., -0.8719,  0.6186, -0.8640]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2765,  1.0000, -0.6644, -0.9978,  0.7498, -0.7421,  0.7347, -0.4295,\n",
            "         -0.9988,  0.4110, -0.3297,  0.8847, -0.6540,  1.0000, -0.2325, -0.5867,\n",
            "         -0.6373, -0.9989,  0.8038, -0.6867,  0.6103,  0.7313,  0.8607, -0.8060,\n",
            "         -0.6694, -0.4259,  0.4401,  0.8262, -0.5416,  0.3849, -0.8307, -0.0292,\n",
            "          0.9821,  0.7637,  0.4784, -0.9481, -0.4208, -0.8898, -0.9973, -0.9981,\n",
            "         -0.0562, -0.4048,  0.9999, -0.9642,  0.9955, -0.9777,  0.3752, -0.8383,\n",
            "          0.9346,  0.7701,  0.1312, -0.8982,  0.7602,  0.4541, -0.9091, -0.9969,\n",
            "         -0.6340,  0.8404, -0.8718,  0.6743,  0.2503, -0.8917,  0.6639,  0.6687,\n",
            "          0.7762,  0.7913,  0.8852,  0.2028,  0.8742, -0.9979, -0.4117, -0.9651,\n",
            "          0.5235, -0.5902,  0.8250,  0.5020,  0.1758, -0.8287, -0.4530,  0.9832,\n",
            "          0.2478,  0.7800,  0.8249, -1.0000,  0.1283, -0.8611,  0.9783, -0.9860,\n",
            "         -0.9757,  0.2828,  0.7003, -0.6890, -0.7399, -0.0988,  0.0248, -0.9074,\n",
            "         -0.1137, -0.7164, -0.9998,  0.7581,  0.9205,  0.8847,  0.3950, -0.5578,\n",
            "         -1.0000, -0.7122,  0.4041, -0.9599, -1.0000, -0.7268, -0.8476, -0.6449,\n",
            "          0.4414,  0.9472, -0.2590,  1.0000, -0.8166,  0.9305, -1.0000, -0.9723,\n",
            "          0.3900,  0.6276, -0.2777, -0.7574,  0.5404, -0.9912, -0.9918, -0.9997,\n",
            "          0.7369,  0.3354, -0.6039,  0.9200, -0.5368, -0.9139, -0.6349, -0.3577,\n",
            "         -0.9994,  0.5719,  0.3737, -0.9982,  0.9952,  0.9630, -0.2309, -0.7499,\n",
            "         -0.4395,  0.9701, -0.0443,  0.2811, -0.5113, -0.6783, -0.1478,  0.2225,\n",
            "         -0.0073,  0.5139, -1.0000,  0.8259,  0.6742,  0.9965,  0.6101,  0.5673,\n",
            "         -0.6941, -1.0000,  0.9051,  0.5787,  0.9741, -0.1061, -0.3861,  0.9301,\n",
            "          0.7123,  0.5213,  0.7608,  0.8431,  0.5174,  0.8718,  0.9852, -0.9622,\n",
            "         -0.8962, -0.8147,  0.8670, -0.9784,  0.9877, -0.7241,  0.9676, -0.9763,\n",
            "         -0.8521,  0.4265, -0.2419, -1.0000,  0.8983,  0.9239,  0.4279, -0.9686,\n",
            "          0.7454,  0.2383,  0.6494, -0.3276, -0.7807,  0.7811, -0.0429,  0.9755,\n",
            "          0.6030, -0.9840,  0.9984,  0.8549,  0.2317, -0.9940,  0.2106,  0.9955,\n",
            "         -0.9935, -0.9503,  0.5091, -0.2017,  0.6843, -0.7163, -0.6216, -0.6467,\n",
            "          0.9518, -0.9534,  0.9109,  0.5903,  0.5329, -0.1806, -0.6327, -0.2604,\n",
            "         -0.1496,  0.8664, -0.6455,  0.3857, -0.7109, -1.0000,  0.2618,  0.3240,\n",
            "          0.7625, -0.0904,  0.9993,  0.6710, -0.8392,  0.9802, -0.9973, -0.5375,\n",
            "          0.8385, -0.9968,  0.8703, -0.0817,  1.0000, -0.9987,  0.9953, -0.7628,\n",
            "          0.8443,  0.7155, -0.8145,  0.1584,  0.9132,  0.6635,  0.7817,  0.9488,\n",
            "          0.0588, -0.9988, -0.2821,  0.6717, -0.9907,  0.1075, -0.9508, -0.9615,\n",
            "          0.9902,  1.0000, -0.7841,  0.5056,  0.7384,  0.8020,  0.7480, -0.9978,\n",
            "          0.9054,  1.0000, -0.9794, -0.8910,  1.0000,  0.6829, -0.9528,  0.6150,\n",
            "         -0.6769, -0.9965,  0.6159, -0.6276,  0.5409,  0.6537, -0.0720, -0.9941,\n",
            "         -0.9989, -0.9934,  0.9982,  0.3409,  0.8296,  0.5306, -0.4089, -0.9224,\n",
            "          0.9232,  0.8971, -0.9875,  1.0000,  0.9482, -0.9615, -0.9918, -0.3201,\n",
            "          0.2527,  0.7946,  0.9876,  0.4232, -0.9195,  0.6917,  0.9071, -0.1410,\n",
            "          0.9941, -0.0471,  0.0844, -0.1796,  0.2458, -0.9950, -0.8881, -0.6603,\n",
            "          0.7937,  0.9955,  0.5817, -0.8734,  0.9959,  0.5026, -1.0000,  0.9999,\n",
            "          0.9923, -0.9870, -0.1334,  0.3178,  0.7865,  0.1105,  0.7903, -0.8300,\n",
            "         -0.1366, -0.9954,  0.9007,  0.7889,  0.6022,  0.7093,  0.5429,  0.8227,\n",
            "          0.6293,  0.1049,  0.6755, -0.8877, -0.9971, -0.3494,  0.5263,  0.7691,\n",
            "         -0.8452,  0.9909,  0.8447,  1.0000,  0.5976,  0.9987, -0.8897,  0.8019,\n",
            "         -0.4049,  0.5964,  0.7569, -0.9684, -1.0000, -0.4905, -0.7645,  0.7993,\n",
            "         -0.5699, -0.9927, -0.9552,  0.6651, -0.7416,  0.8282, -0.3811, -0.9450,\n",
            "          0.9996,  0.9007,  0.7185, -0.5937, -0.5225,  0.8555,  0.9612,  0.5161,\n",
            "          0.9756, -0.7277,  0.9513, -0.8402,  0.8582, -0.4016,  0.1754,  0.3043,\n",
            "          0.3177,  0.9872,  0.9109,  0.9762, -0.7510,  0.2036, -0.9993,  1.0000,\n",
            "         -0.3215,  0.7865,  0.6280,  0.3550,  0.8181, -0.8347,  0.9181, -0.7709,\n",
            "          0.9832, -0.8347,  0.8556,  0.6583,  0.8491, -0.6994, -0.3572,  0.5951,\n",
            "          0.2294, -0.8912, -0.9812,  0.9446, -0.9917, -0.7539, -0.9785, -0.9116,\n",
            "          0.9956, -0.8848,  0.5943, -0.7454, -0.8580, -0.8206, -0.5142, -0.9521,\n",
            "          0.5188, -0.9922,  0.9994, -0.9946,  0.8871, -0.8491, -0.0085,  0.8723,\n",
            "          0.6460,  0.0722,  0.0712, -0.0250, -0.4673,  0.8467, -0.5203, -0.6419,\n",
            "          0.5240, -0.0381,  0.4384,  0.9527, -0.2639,  0.9908,  0.0636, -0.9577,\n",
            "         -0.5922, -0.6279,  0.8824,  0.9982, -0.9835,  0.9157,  1.0000, -0.9937,\n",
            "         -0.7619, -0.4421, -0.9992,  0.9296, -0.9159, -0.9941, -0.1675, -0.7432,\n",
            "          0.9074,  0.9677,  0.9985, -0.4965, -0.7674, -0.9923, -0.8343,  0.4804,\n",
            "         -0.9917,  0.8031, -0.9337, -0.9951,  0.9969,  0.6188, -0.3511,  0.3504,\n",
            "          0.4239,  0.9977, -0.4641, -0.9732,  0.6115,  0.6454,  0.1143,  0.6761,\n",
            "         -0.7493, -0.7311, -0.9979,  0.5828,  1.0000, -0.4359, -0.5922,  0.9058,\n",
            "         -0.0969,  0.3416,  1.0000, -0.9838,  0.9216,  1.0000,  0.1688,  0.8840,\n",
            "         -0.5470,  0.0995,  0.0923,  0.6922, -0.6664,  0.9998, -0.9306, -0.9429,\n",
            "         -1.0000,  0.3718, -0.7981,  0.6640,  0.9540, -0.8364,  0.1022,  0.6692,\n",
            "         -0.9971,  0.9508, -0.6104, -1.0000, -0.9991, -0.3415, -0.4482, -0.9586,\n",
            "         -0.2130, -0.7404, -0.9409,  0.9991, -0.8738, -1.0000, -0.3112,  0.9484,\n",
            "          0.9794,  0.1758,  0.5706, -0.7032, -0.7283,  0.1368, -1.0000, -0.4496,\n",
            "          0.9683,  0.3668, -0.4071,  0.9978, -0.7296, -0.9109, -0.3645,  0.5653,\n",
            "          0.3740, -1.0000, -0.5763,  0.9993, -0.6412, -0.3832, -0.9168, -0.7526,\n",
            "         -0.5806,  0.4384,  0.9959, -0.9717,  0.9998, -0.3061,  0.9081,  0.9651,\n",
            "         -0.2738, -0.8371, -0.9036,  0.8300,  0.8388,  0.3137,  0.4536, -0.8646,\n",
            "          0.8330, -0.3562, -0.9277,  0.6587, -0.7141,  0.1055, -0.5532,  0.9584,\n",
            "          0.7653, -0.4858,  0.9983, -0.0774, -0.9374,  0.7950, -0.1761, -0.5266,\n",
            "         -1.0000, -0.7473,  0.6170, -0.9957, -0.5071,  0.6584, -0.7620, -0.7178,\n",
            "          0.9568, -0.2912,  0.6199,  0.9971,  0.8064,  0.7130, -0.9828, -1.0000,\n",
            "         -0.2865,  0.7932, -0.9602,  0.8008, -0.8126,  0.9993,  0.0756,  0.7434,\n",
            "          0.8187,  0.9998,  0.0215,  0.3820,  0.2366,  0.0732, -0.9094,  0.9464,\n",
            "         -0.5211, -0.9875, -0.8966, -0.6040, -0.4810, -0.4808,  0.1867,  0.5072,\n",
            "          1.0000,  0.8011,  0.9482,  0.7850,  0.1038, -0.2496, -0.8374,  0.9773,\n",
            "         -1.0000,  0.9614,  0.4178, -0.6454,  0.7833, -0.8378, -0.4890, -0.6012,\n",
            "         -0.7613, -0.9311, -0.7213, -0.5833, -0.7166, -0.1864,  0.9457, -0.7485,\n",
            "         -0.9993,  0.8931, -0.5737,  0.8778,  0.5495, -0.7673,  0.9077,  0.5483,\n",
            "          0.9787, -0.8197,  0.2306, -0.7893, -0.8789,  0.4460,  0.7358,  0.9075,\n",
            "          0.4317, -0.0337,  0.8269, -0.1748, -0.6798, -0.0088,  0.2165,  0.6025,\n",
            "          0.9495,  0.3812,  0.8787,  0.9744, -0.0979, -0.5890,  0.2041, -0.0409,\n",
            "          0.8434, -0.9982,  0.9987,  0.3125, -0.2567, -0.9999, -0.1801,  0.5525,\n",
            "          0.7452,  0.3584, -0.4789, -0.8438, -0.7855,  0.8788, -1.0000, -0.6971,\n",
            "         -0.3313, -0.2377,  0.7651, -0.9990, -0.6794,  0.7865, -0.6071, -0.2387,\n",
            "          0.9990, -0.8849, -0.9831, -0.9902, -0.8439,  0.3983,  0.8466, -0.9793,\n",
            "          0.1162,  0.9296, -0.9977, -0.4496,  0.1577,  0.6068, -0.0978, -0.0653,\n",
            "          0.9415, -1.0000,  0.7992, -0.6465, -0.0392,  0.6424, -0.7074,  0.7269,\n",
            "          0.5928, -0.9998,  0.3390,  0.1773,  0.9157,  0.8712, -0.3809, -0.5624,\n",
            "          0.2050, -0.6117,  0.9822,  0.9490, -0.3802,  0.2349,  0.9991,  0.6868,\n",
            "          0.8717, -0.1586, -0.9306, -0.9971, -0.7848, -0.7964,  0.5011, -0.3062]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluation... :   0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "270a2e26ad054a649f5169562e1326a5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.8434,  1.0000,  0.9043,  ...,  0.7092, -0.4506, -0.8152],\n",
            "        [ 0.7114,  1.0000,  0.8956,  ...,  0.7312, -0.3570, -0.6826],\n",
            "        [ 0.4102,  1.0000, -0.2909,  ..., -0.8116,  0.6291, -0.6050],\n",
            "        ...,\n",
            "        [ 0.4997,  1.0000,  0.8923,  ...,  0.4378, -0.2297, -0.7500],\n",
            "        [-0.0305,  1.0000, -0.4118,  ..., -0.7975,  0.5347, -0.8044],\n",
            "        [-0.4380,  1.0000, -0.6535,  ..., -0.8021,  0.5121, -0.5950]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2847,  1.0000,  0.3916,  ..., -0.7952,  0.6361, -0.9484],\n",
            "        [ 0.6633,  1.0000,  0.6804,  ..., -0.3640,  0.2014, -0.9458],\n",
            "        [ 0.5029,  1.0000,  0.9532,  ...,  0.2879, -0.1254, -0.8925],\n",
            "        ...,\n",
            "        [-0.0677,  1.0000,  0.5829,  ..., -0.6074,  0.3408, -0.9673],\n",
            "        [-0.1046,  1.0000,  0.6501,  ..., -0.7863,  0.4442, -0.9488],\n",
            "        [ 0.3374,  1.0000,  0.7219,  ..., -0.8479,  0.6698, -0.9811]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7172,  1.0000,  0.9032,  ...,  0.7817, -0.4218, -0.6003],\n",
            "        [ 0.0543,  0.9909,  0.6402,  ...,  0.2193,  0.2970, -0.5760],\n",
            "        [ 0.4680,  1.0000,  0.7581,  ...,  0.1078,  0.0632, -0.9492],\n",
            "        ...,\n",
            "        [ 0.3357,  1.0000,  0.8772,  ..., -0.6388,  0.1870, -0.9706],\n",
            "        [-0.3374,  1.0000, -0.4456,  ..., -0.8828,  0.4310, -0.6242],\n",
            "        [ 0.5141,  1.0000,  0.7925,  ..., -0.6100,  0.4691, -0.9816]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4101,  1.0000,  0.7007,  ..., -0.2596, -0.0407, -0.9190],\n",
            "        [-0.0249,  1.0000,  0.6915,  ..., -0.7711,  0.7139, -0.9828],\n",
            "        [ 0.2430,  1.0000,  0.5769,  ..., -0.7653,  0.3933, -0.9815],\n",
            "        ...,\n",
            "        [ 0.7304,  1.0000,  0.8835,  ...,  0.7879, -0.3173, -0.5615],\n",
            "        [-0.1966,  1.0000, -0.5200,  ..., -0.8781,  0.5980, -0.6790],\n",
            "        [ 0.7075,  1.0000,  0.9076,  ...,  0.8046, -0.3876, -0.6042]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6970,  1.0000,  0.8868,  ...,  0.3624, -0.2098, -0.8240],\n",
            "        [ 0.5132,  1.0000,  0.9087,  ...,  0.4669,  0.2612, -0.9037],\n",
            "        [ 0.2347,  1.0000, -0.5503,  ..., -0.7529,  0.3991, -0.8427],\n",
            "        ...,\n",
            "        [ 0.1337,  1.0000,  0.1569,  ..., -0.6533,  0.1931, -0.9637],\n",
            "        [ 0.6624,  1.0000,  0.9128,  ...,  0.6091, -0.3831, -0.5864],\n",
            "        [-0.0806,  0.8943,  0.3448,  ...,  0.1370,  0.0819, -0.4206]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4809,  0.9999,  0.8932,  ...,  0.6145, -0.2333, -0.5127],\n",
            "        [ 0.7226,  1.0000,  0.7134,  ...,  0.2963, -0.1894, -0.9223],\n",
            "        [ 0.0481,  1.0000, -0.7913,  ..., -0.8725,  0.6262, -0.5508],\n",
            "        ...,\n",
            "        [ 0.4441,  1.0000, -0.4672,  ..., -0.7595,  0.7618, -0.5156],\n",
            "        [ 0.5098,  1.0000,  0.2897,  ..., -0.6320,  0.1874, -0.9287],\n",
            "        [-0.0961,  1.0000, -0.4708,  ..., -0.8554,  0.4783, -0.6941]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3522,  1.0000,  0.0303,  ..., -0.8156,  0.2913, -0.9121],\n",
            "        [-0.1467,  1.0000, -0.7719,  ..., -0.8967,  0.3977, -0.3402],\n",
            "        [ 0.7595,  1.0000,  0.9029,  ...,  0.8081, -0.3911, -0.7041],\n",
            "        ...,\n",
            "        [-0.2798,  1.0000,  0.1501,  ..., -0.8563,  0.1800, -0.8253],\n",
            "        [ 0.6953,  1.0000,  0.9284,  ...,  0.7789, -0.3364, -0.6107],\n",
            "        [ 0.0845,  1.0000, -0.4420,  ..., -0.6928,  0.2602, -0.6017]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7731,  1.0000,  0.9183,  ...,  0.6214, -0.3165, -0.7972],\n",
            "        [ 0.7420,  1.0000,  0.9277,  ...,  0.7917, -0.3447, -0.6730],\n",
            "        [-0.0493,  0.9164,  0.4581,  ...,  0.0722,  0.0586, -0.4424],\n",
            "        ...,\n",
            "        [ 0.7280,  1.0000,  0.9186,  ...,  0.7359, -0.4465, -0.6754],\n",
            "        [ 0.5097,  1.0000,  0.8563,  ...,  0.6079, -0.3271, -0.8393],\n",
            "        [ 0.6562,  1.0000,  0.5939,  ..., -0.2542,  0.3928, -0.9465]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5862,  0.9999,  0.9102,  ...,  0.7124, -0.2772, -0.4260],\n",
            "        [-0.1676,  1.0000, -0.3064,  ..., -0.8326,  0.4488, -0.7669],\n",
            "        [-0.5963,  0.9997, -0.0354,  ..., -0.7723,  0.4970, -0.8377],\n",
            "        ...,\n",
            "        [-0.0582,  0.9533,  0.5378,  ...,  0.1040,  0.1455, -0.4780],\n",
            "        [-0.1751,  1.0000, -0.5583,  ..., -0.8675,  0.6870, -0.6248],\n",
            "        [ 0.5751,  0.9999,  0.8884,  ...,  0.7070, -0.4289, -0.4583]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2134,  1.0000, -0.7266,  ..., -0.8902,  0.4517, -0.5581],\n",
            "        [ 0.6688,  1.0000,  0.8762,  ...,  0.5672, -0.3768, -0.8197],\n",
            "        [ 0.5905,  1.0000,  0.9020,  ...,  0.6215, -0.4238, -0.6172],\n",
            "        ...,\n",
            "        [ 0.6644,  1.0000,  0.8455,  ...,  0.6483, -0.5831, -0.6638],\n",
            "        [ 0.7569,  1.0000,  0.8846,  ...,  0.7101, -0.2766, -0.6413],\n",
            "        [ 0.0470,  0.9613,  0.6452,  ...,  0.1742, -0.0186, -0.4448]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1663,  1.0000, -0.6139,  ..., -0.8735,  0.4678, -0.6975],\n",
            "        [-0.2265,  1.0000, -0.7092,  ..., -0.9230,  0.4497, -0.4961],\n",
            "        [-0.4236,  1.0000, -0.7907,  ..., -0.9265,  0.3313, -0.5498],\n",
            "        ...,\n",
            "        [ 0.7099,  1.0000,  0.8576,  ...,  0.0996,  0.1549, -0.9343],\n",
            "        [ 0.4136,  1.0000, -0.3219,  ..., -0.6849,  0.5707, -0.8447],\n",
            "        [ 0.7034,  1.0000,  0.9245,  ...,  0.7236, -0.4929, -0.5939]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1817,  0.8094,  0.1162,  ..., -0.0683,  0.1376, -0.3780],\n",
            "        [-0.1477,  1.0000, -0.7390,  ..., -0.8978,  0.4765, -0.5761],\n",
            "        [-0.3511,  1.0000, -0.5463,  ..., -0.8771,  0.4254, -0.7631],\n",
            "        ...,\n",
            "        [-0.0221,  1.0000, -0.4597,  ..., -0.8583,  0.4797, -0.8330],\n",
            "        [ 0.6234,  1.0000,  0.8372,  ..., -0.2901,  0.3932, -0.9383],\n",
            "        [-0.1597,  1.0000, -0.1782,  ..., -0.8802,  0.4452, -0.8334]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1218,  1.0000, -0.3847,  ..., -0.3789,  0.7202, -0.5454],\n",
            "        [ 0.7653,  1.0000,  0.9067,  ...,  0.4018, -0.0931, -0.9029],\n",
            "        [-0.2145,  0.9995, -0.6495,  ..., -0.8898,  0.4669, -0.3326],\n",
            "        ...,\n",
            "        [-0.4220,  1.0000, -0.5230,  ..., -0.8467,  0.6830, -0.8421],\n",
            "        [ 0.0717,  1.0000, -0.6849,  ..., -0.8421,  0.5391, -0.6279],\n",
            "        [-0.0448,  1.0000,  0.3693,  ..., -0.6230,  0.5295, -0.9756]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7218,  1.0000,  0.8818,  ..., -0.2584, -0.0601, -0.8525],\n",
            "        [ 0.6459,  1.0000,  0.8177,  ..., -0.0150, -0.1934, -0.9352],\n",
            "        [-0.1691,  1.0000, -0.7615,  ..., -0.8075,  0.2206, -0.4602],\n",
            "        ...,\n",
            "        [ 0.6253,  1.0000,  0.6104,  ..., -0.4736, -0.3063, -0.8833],\n",
            "        [ 0.1548,  1.0000,  0.4702,  ..., -0.6391,  0.5174, -0.8574],\n",
            "        [ 0.1145,  1.0000,  0.4367,  ..., -0.0708, -0.3131, -0.9317]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3431,  1.0000,  0.3513, -0.9956,  0.0806,  0.8890,  0.8538,  0.8080,\n",
            "         -0.9986, -0.7888,  0.7241, -0.4005,  0.1438,  0.9999, -0.3895,  0.1902,\n",
            "          0.9283, -0.9970,  0.9179, -0.9007,  0.7705, -0.5537,  0.9469, -0.7901,\n",
            "          0.8452,  0.6216, -0.3577,  0.8558, -0.7357,  0.5572, -0.6702, -0.8334,\n",
            "          0.9423,  0.7204,  0.9214, -0.9581, -0.5688, -0.9716, -0.9988, -0.9992,\n",
            "         -0.7884, -0.7919,  0.9998, -0.8482,  0.9983, -0.9943, -0.2675, -0.6448,\n",
            "          0.9308,  0.5935, -0.9228,  0.6869,  0.9139,  0.8370, -0.7426, -0.9810,\n",
            "         -0.9239,  0.9016, -0.9886,  0.1176,  0.9669,  0.3801, -0.3510,  0.1537,\n",
            "         -0.9193,  0.3249,  0.7401,  0.7542, -0.8058, -0.9870,  0.9042, -0.9814,\n",
            "          0.9051, -0.5830,  0.3827,  0.9700, -0.8693,  0.8061, -0.8452,  0.9898,\n",
            "          0.4804,  0.7143,  0.9130, -1.0000,  0.8750, -0.9597,  0.9863, -0.9962,\n",
            "         -0.9844,  0.8671,  0.7223,  0.8229,  0.5572, -0.7204, -0.8096, -0.7767,\n",
            "         -0.6303,  0.7913, -0.9998,  0.8987,  0.9350,  0.9661, -0.4992, -0.8474,\n",
            "         -0.9998, -0.3013, -0.8925, -0.8991, -1.0000, -0.8705, -0.8666, -0.8246,\n",
            "         -0.5473,  0.9853,  0.4481,  0.9999,  0.7778,  0.9947, -1.0000, -0.9803,\n",
            "          0.7106,  0.9823, -0.8379, -0.8611,  0.6789, -0.9902, -0.7999, -0.9992,\n",
            "          0.9338, -0.9770, -0.8464,  0.9142,  0.8847, -0.6663, -0.8021,  0.5178,\n",
            "         -0.9999,  0.3607, -0.9084, -0.9978,  0.9961,  0.9753,  0.7304, -0.8429,\n",
            "         -0.6467,  0.9517,  0.9051, -0.5972, -0.3763, -0.5291, -0.7909,  0.8869,\n",
            "          0.6092, -0.7816, -1.0000,  0.8015, -0.0827,  0.9790, -0.9620,  0.9966,\n",
            "         -0.9690, -1.0000,  0.8677,  0.6074, -0.0598,  0.9359, -0.9266,  0.9334,\n",
            "         -0.7380,  0.9095,  0.9368,  0.9305,  0.4372,  0.5871,  0.8748, -0.8916,\n",
            "          0.1781, -0.9067, -0.4993, -0.9943,  0.9795, -0.9402,  0.9828, -0.9314,\n",
            "         -0.6496,  0.6513, -0.0260, -1.0000,  0.9473,  0.7423,  0.8811, -0.5699,\n",
            "          0.7678, -0.6541,  0.7854, -0.3189, -0.8884,  0.9570, -0.6316,  0.9846,\n",
            "          0.8891, -0.9988,  0.9738,  0.9991,  0.6345, -0.9427, -0.0611,  0.9963,\n",
            "         -0.9982, -0.8802,  0.2332, -0.8729,  0.8750,  0.3334, -0.6671, -0.7108,\n",
            "          0.9734, -0.0441,  0.7174, -0.3689,  0.5566,  0.5801, -0.7812,  0.6612,\n",
            "          0.9399,  0.9994, -0.7855, -0.4935,  0.3814, -0.9998,  0.9352,  0.4789,\n",
            "          0.0424, -0.8117,  0.9974,  0.9601,  0.6842,  0.9776, -0.9739, -0.7857,\n",
            "         -0.4234,  0.1109,  0.6153,  0.0369,  1.0000, -0.9986,  0.9849,  0.8027,\n",
            "          0.5241,  0.2326, -0.1298, -0.0596,  0.6842,  0.5632, -0.5809,  0.9972,\n",
            "         -0.8913, -0.9956,  0.2757,  0.6048, -0.9880, -0.7332,  0.4810, -0.9072,\n",
            "          0.9951,  1.0000, -0.0675,  0.6928,  0.8726,  0.8810,  0.9461, -0.9867,\n",
            "          0.9920,  1.0000, -0.9758, -0.1513,  1.0000,  0.8623, -0.8036, -0.4024,\n",
            "          0.6876, -0.9689, -0.0910, -0.5821, -0.1331, -0.2508,  0.5579, -0.9612,\n",
            "         -0.9997, -0.9972,  0.9955, -0.8398, -0.7202,  0.9028, -0.7173, -0.8217,\n",
            "         -0.1561,  0.9927, -0.9209,  1.0000,  0.9131, -0.5976, -0.9774, -0.3847,\n",
            "          0.7637,  0.4177,  0.9987,  0.5439, -0.9207,  0.9337,  0.8916,  0.1076,\n",
            "          0.9367, -0.5451,  0.7624,  0.0160,  0.6934, -0.9823, -0.5517, -0.9401,\n",
            "          0.9784,  0.9855,  0.9185, -0.9066,  0.9631,  0.9009, -1.0000,  0.9997,\n",
            "          0.9732, -0.9963,  0.8819, -0.4916,  0.9405,  0.3188,  0.9388, -0.9216,\n",
            "         -0.9289, -0.9923,  0.9096,  0.5822, -0.6675,  0.8448, -0.9091,  0.8579,\n",
            "          0.5751,  0.6717,  0.3377, -0.7881, -0.9993,  0.7726,  0.8758,  0.5361,\n",
            "          0.8333,  0.9857,  0.4504,  1.0000, -0.9134,  0.9295, -0.5806,  0.9212,\n",
            "          0.4158,  0.8161,  0.2778, -0.3893, -1.0000, -0.0718, -0.3898,  0.6240,\n",
            "          0.3796, -0.9895, -0.6243, -0.3521, -0.7996,  0.3024,  0.0739,  0.2651,\n",
            "          0.9998,  0.8131, -0.1897, -0.7947, -0.5663,  0.5540,  0.9748,  0.9592,\n",
            "          0.9977, -0.8922,  0.7298,  0.7632,  0.1279, -0.8728,  0.2734,  0.5883,\n",
            "          0.5218,  0.9783,  0.9167,  0.5439, -0.7851,  0.8931, -0.9973,  1.0000,\n",
            "          0.5634,  0.8015,  0.9659, -0.1148,  0.9544, -0.7750,  0.6651, -0.8984,\n",
            "          0.9949,  0.8281,  0.7764,  0.5423,  0.8844, -0.4286, -0.8388,  0.9516,\n",
            "          0.3500, -0.8501, -0.9910,  0.9814, -0.9963,  0.0170, -0.8894,  0.7711,\n",
            "          0.9903, -0.8189, -0.7757, -0.8802, -0.6425, -0.9773, -0.9689, -0.9984,\n",
            "         -0.1557, -0.9756,  0.9999, -0.9954,  0.7706, -0.9587, -0.8562,  0.8816,\n",
            "          0.1911, -0.8154, -0.6855,  0.2085, -0.7675,  0.9480, -0.2079,  0.8085,\n",
            "         -0.0931,  0.1400,  0.8199,  0.7483,  0.5171,  0.8604, -0.8780, -0.9957,\n",
            "         -0.8781, -0.6707, -0.4327,  0.9610, -0.9863, -0.3168,  1.0000, -0.9929,\n",
            "         -0.1043, -0.3576, -0.9987,  0.8027, -0.9682, -0.9901, -0.7827, -0.8370,\n",
            "          0.9475,  0.9401,  0.9997, -0.1010, -0.6732, -0.9804, -0.7507,  0.9809,\n",
            "         -0.9901,  0.3640, -0.1479, -0.9987,  0.9680,  0.7544, -0.5197,  0.9304,\n",
            "         -0.8447,  0.9757, -0.1711, -0.9960,  0.9081,  0.9097,  0.2513,  0.9333,\n",
            "         -0.6647, -0.2994, -0.9584,  0.7125,  0.9999, -0.3868, -0.9506,  0.9060,\n",
            "          0.9217,  0.7929,  1.0000, -0.9410,  0.8142,  0.9999, -0.3137,  0.6988,\n",
            "         -0.4078, -0.8618, -0.3431,  0.8320, -0.9946,  0.9999, -0.5487, -0.9950,\n",
            "         -1.0000,  0.7187, -0.8702,  0.7426,  0.9736,  0.0857,  0.8974,  0.8005,\n",
            "         -0.9971,  0.9004, -0.9043, -1.0000, -0.9998,  0.8669, -0.0982, -0.4320,\n",
            "          0.7748, -0.5970, -0.8565,  0.9998,  0.8189, -1.0000, -0.8425,  0.4878,\n",
            "          0.9803, -0.8888,  0.8702,  0.0168, -0.0212, -0.3356, -1.0000, -0.9231,\n",
            "          0.9943, -0.4913,  0.2217,  0.9998,  0.8449, -0.5556, -0.9803,  0.7264,\n",
            "          0.9575, -1.0000, -0.9260,  0.9999, -0.8707, -0.7083, -0.9497, -0.2229,\n",
            "          0.7288,  0.8934,  0.9249, -0.9986,  0.9991,  0.8750, -0.6592,  0.9971,\n",
            "         -0.0484, -0.8677, -0.9666, -0.7440,  0.9470, -0.7542,  0.8925, -0.9095,\n",
            "          0.9946,  0.9344, -0.9387,  0.9344,  0.8704, -0.8295, -0.8263,  0.9830,\n",
            "          0.8763, -0.1523,  0.9848, -0.1698, -0.8618, -0.2191,  0.9195,  0.9126,\n",
            "         -1.0000,  0.9416, -0.6891, -0.9476,  0.6683, -0.2239, -0.9370, -0.5260,\n",
            "          0.7108, -0.8736,  0.7259,  0.9701,  0.9551,  0.9494, -0.9894, -1.0000,\n",
            "         -0.8032, -0.6088, -0.8711,  0.2709, -0.3100,  0.9905,  0.6557,  0.7728,\n",
            "          0.7381,  0.9999, -0.7205,  0.9648, -0.9118,  0.9664, -0.9966,  0.9214,\n",
            "          0.3360, -0.9932, -0.9081,  0.9022, -0.8517,  0.8862, -0.9724,  0.8042,\n",
            "          1.0000, -0.6921,  0.1453,  0.8847, -0.9472,  0.8670, -0.6897,  0.9986,\n",
            "         -1.0000,  0.9873,  0.7792,  0.6020,  0.8194,  0.5678,  0.2280, -0.8170,\n",
            "         -0.8899, -0.9944, -0.3798,  0.5858, -0.8291,  0.4802,  0.9856, -0.9636,\n",
            "         -0.9998, -0.7589,  0.2038,  0.9504, -0.5905, -0.9970,  0.9693, -0.6005,\n",
            "          0.9951, -0.5272, -0.7563, -0.8234, -0.8285, -0.6068,  0.8451,  0.8912,\n",
            "          0.9624,  0.7067, -0.5914, -0.5991, -0.6060, -0.8782,  0.8853,  0.4547,\n",
            "          0.8540,  0.8330,  0.9137,  0.9892,  0.5947, -0.5422,  0.8360, -0.6854,\n",
            "         -0.5114, -0.9998,  0.9993,  0.9259, -0.9154, -0.9999,  0.9406,  0.8737,\n",
            "         -0.5797,  0.9024, -0.7778, -0.9657, -0.4685,  0.9696, -1.0000, -0.7065,\n",
            "          0.6238, -0.5674, -0.0981, -0.9998, -0.5129,  0.7064, -0.6252,  0.4877,\n",
            "          0.9996, -0.5577, -0.9959, -0.9751, -0.3267,  0.7391,  0.5139, -0.9979,\n",
            "         -0.7215,  0.9492, -0.9993,  0.0270, -0.8986, -0.7851,  0.5765,  0.7721,\n",
            "          0.8794, -1.0000,  0.9333, -0.8544,  0.9527, -0.4901,  0.4817,  0.9150,\n",
            "          0.9436, -0.9997,  0.9442,  0.2877,  0.8694,  0.8688,  0.9366, -0.3892,\n",
            "         -0.9632, -0.9294,  0.9975,  0.9943, -0.5914,  0.9308,  0.9996, -0.4686,\n",
            "          0.7390,  0.5997, -0.7133, -0.9993, -0.8136, -0.7131, -0.3043, -0.9483]],\n",
            "       device='cuda:0')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training... :   0%|          | 0/127 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9210640196204e76b9afb46e09bc612e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6187,  0.9999, -0.6998,  ..., -0.8843,  0.3987, -0.5194],\n",
            "        [ 0.3747,  0.9976,  0.8169,  ...,  0.3480,  0.3077, -0.7166],\n",
            "        [ 0.5110,  1.0000,  0.8913,  ...,  0.6182, -0.2657, -0.6560],\n",
            "        ...,\n",
            "        [ 0.7855,  1.0000,  0.8947,  ...,  0.8018,  0.0064, -0.8699],\n",
            "        [ 0.4763,  1.0000, -0.0352,  ..., -0.7087,  0.7929, -0.7070],\n",
            "        [ 0.7126,  1.0000,  0.8682,  ...,  0.7074, -0.4911, -0.6098]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1859,  0.9999, -0.4787,  ..., -0.8567,  0.2970, -0.1542],\n",
            "        [ 0.7305,  1.0000,  0.8464,  ...,  0.7824, -0.4752, -0.6219],\n",
            "        [ 0.0883,  1.0000, -0.5692,  ..., -0.9090,  0.5604, -0.7680],\n",
            "        ...,\n",
            "        [ 0.5960,  1.0000,  0.6741,  ..., -0.5138,  0.3843, -0.9431],\n",
            "        [ 0.7909,  1.0000,  0.9072,  ...,  0.6575, -0.3589, -0.7586],\n",
            "        [ 0.7071,  1.0000,  0.9255,  ...,  0.4452, -0.4950, -0.9206]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2203,  1.0000, -0.5217,  ..., -0.7703,  0.6238, -0.7352],\n",
            "        [ 0.6769,  1.0000,  0.9271,  ...,  0.7085, -0.3441, -0.6614],\n",
            "        [ 0.5677,  1.0000,  0.9171,  ...,  0.5995, -0.2809, -0.6795],\n",
            "        ...,\n",
            "        [ 0.4523,  1.0000,  0.9244,  ...,  0.6575, -0.2929, -0.8641],\n",
            "        [ 0.5769,  1.0000,  0.9080,  ...,  0.7715, -0.4691, -0.6396],\n",
            "        [ 0.7254,  1.0000,  0.8582,  ...,  0.7598, -0.3011, -0.6420]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7914,  1.0000,  0.8763,  ...,  0.7937, -0.3628, -0.7276],\n",
            "        [-0.1751,  0.9991,  0.8058,  ..., -0.2013, -0.0929, -0.8003],\n",
            "        [ 0.5821,  1.0000,  0.7836,  ...,  0.3779, -0.1319, -0.6107],\n",
            "        ...,\n",
            "        [-0.0742,  1.0000, -0.6465,  ..., -0.7675,  0.4645, -0.7553],\n",
            "        [ 0.6961,  1.0000,  0.9242,  ...,  0.6790, -0.3056, -0.7912],\n",
            "        [-0.1076,  1.0000, -0.7839,  ..., -0.9119,  0.5023, -0.5705]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1104,  0.9999, -0.8480,  ..., -0.9096,  0.3175, -0.6275],\n",
            "        [ 0.2773,  1.0000,  0.3184,  ..., -0.5583,  0.6326, -0.9480],\n",
            "        [-0.3060,  1.0000, -0.6269,  ..., -0.8792,  0.4712, -0.6806],\n",
            "        ...,\n",
            "        [ 0.4590,  1.0000,  0.8370,  ..., -0.4486,  0.4492, -0.9721],\n",
            "        [ 0.6963,  1.0000,  0.8378,  ...,  0.7162, -0.2887, -0.6357],\n",
            "        [ 0.5196,  1.0000,  0.9140,  ...,  0.7033, -0.0870, -0.6349]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5853,  1.0000,  0.9192,  ...,  0.6775,  0.0256, -0.6639],\n",
            "        [-0.1430,  1.0000,  0.8811,  ..., -0.3778,  0.1544, -0.7838],\n",
            "        [-0.3148,  0.9996, -0.3225,  ..., -0.7462,  0.5480, -0.2590],\n",
            "        ...,\n",
            "        [ 0.5959,  1.0000,  0.8126,  ...,  0.6388, -0.1954, -0.5542],\n",
            "        [ 0.6354,  1.0000,  0.8355,  ...,  0.2983,  0.0407, -0.9351],\n",
            "        [-0.5367,  1.0000, -0.6411,  ..., -0.8767,  0.6141, -0.5539]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1077,  1.0000, -0.6668,  ..., -0.5587,  0.5129, -0.5523],\n",
            "        [ 0.5402,  1.0000,  0.9200,  ...,  0.7568, -0.2268, -0.6213],\n",
            "        [ 0.7547,  1.0000,  0.9225,  ...,  0.8631, -0.3050, -0.7369],\n",
            "        ...,\n",
            "        [ 0.8057,  1.0000,  0.9135,  ...,  0.8404, -0.5616, -0.6375],\n",
            "        [ 0.7670,  1.0000,  0.8277,  ...,  0.7639,  0.0418, -0.4503],\n",
            "        [-0.4051,  1.0000, -0.5903,  ..., -0.8585,  0.6923, -0.7329]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1463,  1.0000, -0.4161,  ..., -0.7750,  0.2482, -0.7932],\n",
            "        [ 0.7230,  1.0000,  0.9385,  ...,  0.7720, -0.4476, -0.5416],\n",
            "        [ 0.7333,  1.0000,  0.9041,  ...,  0.8306, -0.4834, -0.6247],\n",
            "        ...,\n",
            "        [-0.0524,  1.0000, -0.7156,  ..., -0.8733,  0.5743, -0.6610],\n",
            "        [-0.3630,  1.0000, -0.7989,  ..., -0.7939,  0.3609, -0.4659],\n",
            "        [-0.0207,  1.0000, -0.7433,  ..., -0.8986,  0.6344, -0.8438]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2203,  1.0000, -0.0156,  ..., -0.7920,  0.3134, -0.8556],\n",
            "        [ 0.6765,  1.0000,  0.8547,  ...,  0.4372, -0.3855, -0.7947],\n",
            "        [-0.2730,  1.0000, -0.4060,  ..., -0.9035,  0.5473, -0.9146],\n",
            "        ...,\n",
            "        [-0.0616,  1.0000, -0.6835,  ..., -0.8942,  0.6817, -0.4281],\n",
            "        [ 0.6996,  1.0000,  0.8936,  ...,  0.7739, -0.3882, -0.4345],\n",
            "        [-0.1372,  1.0000, -0.7833,  ..., -0.8659,  0.3619, -0.4313]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7681,  1.0000,  0.8730,  ...,  0.8232, -0.3008, -0.7445],\n",
            "        [ 0.2109,  1.0000,  0.3688,  ..., -0.7702,  0.4177, -0.9534],\n",
            "        [ 0.8047,  1.0000,  0.9366,  ...,  0.6867, -0.2728, -0.9119],\n",
            "        ...,\n",
            "        [ 0.6391,  1.0000,  0.9080,  ...,  0.7754, -0.4484, -0.4487],\n",
            "        [ 0.6047,  1.0000,  0.8976,  ...,  0.8398, -0.2789, -0.4071],\n",
            "        [ 0.7083,  1.0000,  0.8866,  ...,  0.5629, -0.2066, -0.8418]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1462,  0.9988, -0.8193,  ..., -0.8766,  0.2159, -0.2201],\n",
            "        [ 0.6817,  1.0000,  0.8084,  ...,  0.7445, -0.2753, -0.5483],\n",
            "        [-0.1223,  0.9996, -0.1607,  ..., -0.6322, -0.1763, -0.7544],\n",
            "        ...,\n",
            "        [ 0.6445,  1.0000,  0.9135,  ...,  0.8500, -0.4768, -0.7186],\n",
            "        [ 0.7525,  1.0000,  0.9113,  ...,  0.8210, -0.1584, -0.8260],\n",
            "        [ 0.7526,  1.0000,  0.8569,  ...,  0.8067, -0.2902, -0.6060]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2756,  0.9999, -0.6702,  ..., -0.9331,  0.5913, -0.5733],\n",
            "        [ 0.6811,  1.0000,  0.8774,  ...,  0.4709, -0.4814, -0.4580],\n",
            "        [-0.0948,  1.0000, -0.8228,  ..., -0.8259,  0.4958, -0.3634],\n",
            "        ...,\n",
            "        [ 0.1317,  0.9984,  0.7775,  ...,  0.4425, -0.0439, -0.5278],\n",
            "        [ 0.7489,  1.0000,  0.9010,  ...,  0.6795, -0.5106, -0.7297],\n",
            "        [ 0.6652,  1.0000,  0.8908,  ...,  0.8550, -0.3820, -0.5461]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6558,  1.0000,  0.9204,  ...,  0.8627, -0.2717, -0.6912],\n",
            "        [ 0.1313,  1.0000, -0.3451,  ..., -0.8937,  0.5712, -0.5423],\n",
            "        [-0.2888,  0.9998, -0.7553,  ..., -0.8289,  0.4844,  0.1216],\n",
            "        ...,\n",
            "        [ 0.7190,  1.0000,  0.9354,  ...,  0.7826, -0.2861, -0.5932],\n",
            "        [ 0.7284,  1.0000,  0.8480,  ...,  0.7731, -0.3492, -0.7968],\n",
            "        [ 0.7419,  1.0000,  0.9213,  ...,  0.8244, -0.2076, -0.8014]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7351,  1.0000,  0.8140,  ...,  0.3918, -0.3756, -0.9166],\n",
            "        [ 0.4697,  1.0000,  0.6186,  ..., -0.1224,  0.1347, -0.9193],\n",
            "        [-0.4817,  0.9998, -0.9002,  ..., -0.9035,  0.3629, -0.1224],\n",
            "        ...,\n",
            "        [ 0.7918,  1.0000,  0.9124,  ...,  0.8127, -0.2092, -0.7086],\n",
            "        [-0.4096,  1.0000, -0.6467,  ..., -0.8709,  0.6369, -0.7337],\n",
            "        [ 0.7231,  1.0000,  0.8846,  ...,  0.8058, -0.3767, -0.5729]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.8235,  1.0000,  0.8495,  ...,  0.8470, -0.3416, -0.6986],\n",
            "        [-0.1167,  1.0000, -0.8372,  ..., -0.8469,  0.3815, -0.3998],\n",
            "        [ 0.5222,  1.0000,  0.8545,  ...,  0.7866, -0.2910, -0.7023],\n",
            "        ...,\n",
            "        [-0.3855,  0.9999, -0.6647,  ..., -0.7871,  0.7376, -0.1725],\n",
            "        [ 0.3057,  1.0000,  0.4640,  ..., -0.5253,  0.5598, -0.9729],\n",
            "        [ 0.6344,  1.0000,  0.9248,  ...,  0.5990, -0.2119, -0.7688]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6495,  1.0000,  0.9553,  ...,  0.8538, -0.4839, -0.5968],\n",
            "        [-0.2030,  1.0000, -0.8495,  ..., -0.8761,  0.5244, -0.1953],\n",
            "        [ 0.8233,  1.0000,  0.8927,  ...,  0.8014, -0.2989, -0.6060],\n",
            "        ...,\n",
            "        [-0.1570,  1.0000, -0.5260,  ..., -0.8543,  0.6302, -0.4082],\n",
            "        [-0.0668,  0.9999, -0.8284,  ..., -0.8576,  0.3528,  0.0419],\n",
            "        [-0.1337,  1.0000, -0.7511,  ..., -0.7610,  0.3494, -0.2872]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1586,  0.9999, -0.7019,  ..., -0.9044,  0.5365, -0.4958],\n",
            "        [ 0.2157,  1.0000, -0.5649,  ..., -0.7826,  0.6555, -0.3536],\n",
            "        [ 0.6418,  1.0000,  0.9332,  ...,  0.8790, -0.4677, -0.3781],\n",
            "        ...,\n",
            "        [ 0.8030,  1.0000,  0.9333,  ...,  0.4519, -0.3538, -0.7493],\n",
            "        [ 0.5099,  1.0000,  0.8105,  ...,  0.6828, -0.5837, -0.6071],\n",
            "        [ 0.1722,  0.9994,  0.8554,  ...,  0.6657,  0.0257, -0.5936]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6952,  1.0000,  0.9574,  ...,  0.5240,  0.1179, -0.8745],\n",
            "        [-0.2573,  1.0000,  0.1751,  ..., -0.7220,  0.6468, -0.9375],\n",
            "        [ 0.7167,  1.0000,  0.9527,  ...,  0.8677, -0.2294, -0.6405],\n",
            "        ...,\n",
            "        [-0.2479,  1.0000,  0.6743,  ..., -0.5091,  0.2801, -0.9041],\n",
            "        [ 0.5792,  0.9999,  0.9416,  ...,  0.5434,  0.1158, -0.8086],\n",
            "        [ 0.7440,  1.0000,  0.9279,  ...,  0.6605, -0.0260, -0.8390]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6839,  1.0000,  0.8832,  ...,  0.7103, -0.1069, -0.7904],\n",
            "        [ 0.8208,  1.0000,  0.9195,  ...,  0.8040, -0.2819, -0.7787],\n",
            "        [-0.2788,  1.0000, -0.5743,  ..., -0.9118,  0.3872, -0.0731],\n",
            "        ...,\n",
            "        [ 0.7539,  1.0000,  0.9465,  ...,  0.7456, -0.2808, -0.7109],\n",
            "        [ 0.7855,  1.0000,  0.8909,  ...,  0.6387,  0.2718, -0.9006],\n",
            "        [ 0.4514,  1.0000,  0.8641,  ...,  0.6999,  0.3137, -0.4945]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2517,  0.9998, -0.7922,  ..., -0.9023,  0.2472, -0.1919],\n",
            "        [ 0.7048,  1.0000,  0.9078,  ...,  0.8172,  0.0826, -0.7226],\n",
            "        [ 0.6768,  1.0000,  0.9190,  ...,  0.8189, -0.1979, -0.5445],\n",
            "        ...,\n",
            "        [ 0.1629,  1.0000,  0.3779,  ..., -0.5907,  0.5347, -0.8890],\n",
            "        [ 0.3178,  1.0000,  0.5974,  ..., -0.5615,  0.1982, -0.8967],\n",
            "        [ 0.6939,  1.0000,  0.9067,  ...,  0.6693, -0.0981, -0.7942]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7229,  1.0000,  0.9243,  ...,  0.7774,  0.0831, -0.6951],\n",
            "        [ 0.7017,  1.0000,  0.8899,  ...,  0.6176, -0.3371, -0.6531],\n",
            "        [ 0.6792,  0.9999,  0.9036,  ...,  0.7104, -0.2201, -0.3658],\n",
            "        ...,\n",
            "        [-0.3833,  0.9964, -0.8974,  ..., -0.8995,  0.5265,  0.0662],\n",
            "        [-0.4418,  1.0000, -0.8696,  ..., -0.9245,  0.1615, -0.2784],\n",
            "        [-0.3343,  0.8935,  0.3474,  ...,  0.1982,  0.0531, -0.5128]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2800,  1.0000, -0.8032,  ..., -0.8729,  0.5060, -0.3722],\n",
            "        [-0.4686,  1.0000, -0.6753,  ..., -0.6808,  0.4418, -0.4365],\n",
            "        [ 0.6738,  1.0000,  0.9225,  ...,  0.7511, -0.2402, -0.6426],\n",
            "        ...,\n",
            "        [-0.5465,  1.0000, -0.8131,  ..., -0.9082,  0.7095, -0.6948],\n",
            "        [ 0.7368,  1.0000,  0.9436,  ...,  0.8262, -0.4466, -0.4688],\n",
            "        [ 0.0102,  1.0000,  0.8044,  ...,  0.0336,  0.3081, -0.9726]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3587,  1.0000,  0.5084,  ..., -0.3232,  0.2981, -0.9435],\n",
            "        [ 0.7780,  1.0000,  0.8910,  ...,  0.1706, -0.2830, -0.6480],\n",
            "        [ 0.0243,  0.9999, -0.4687,  ..., -0.8119,  0.8020, -0.1838],\n",
            "        ...,\n",
            "        [ 0.6517,  1.0000,  0.8152,  ...,  0.6339, -0.0446, -0.6169],\n",
            "        [-0.1222,  1.0000, -0.6583,  ..., -0.8075,  0.3764, -0.6464],\n",
            "        [ 0.7795,  1.0000,  0.9200,  ...,  0.7730, -0.0248, -0.7896]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2723,  1.0000, -0.8356,  ..., -0.9047,  0.2947, -0.0218],\n",
            "        [ 0.6932,  1.0000,  0.9178,  ...,  0.8178, -0.2599, -0.5615],\n",
            "        [ 0.6278,  1.0000,  0.9236,  ...,  0.2471,  0.2590, -0.9809],\n",
            "        ...,\n",
            "        [-0.3295,  0.9996, -0.8566,  ..., -0.8093,  0.4057, -0.2326],\n",
            "        [ 0.5935,  1.0000,  0.8758,  ...,  0.7778, -0.2917, -0.7132],\n",
            "        [ 0.7113,  1.0000,  0.9286,  ...,  0.9009, -0.1566, -0.7000]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3869,  1.0000,  0.9148,  ...,  0.7154,  0.0217, -0.6152],\n",
            "        [ 0.6551,  1.0000,  0.9273,  ...,  0.7488, -0.1291, -0.6783],\n",
            "        [-0.3003,  0.9990, -0.8964,  ..., -0.9146,  0.2441,  0.0966],\n",
            "        ...,\n",
            "        [-0.2020,  1.0000, -0.6913,  ..., -0.9134,  0.6100, -0.4707],\n",
            "        [ 0.7035,  1.0000,  0.8999,  ...,  0.6573, -0.1109, -0.7677],\n",
            "        [ 0.3400,  1.0000,  0.8811,  ...,  0.5838, -0.0611, -0.7728]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0855,  1.0000, -0.8399,  ..., -0.8773,  0.5908, -0.4520],\n",
            "        [ 0.5456,  1.0000,  0.9041,  ...,  0.5828, -0.1871, -0.6912],\n",
            "        [ 0.7727,  1.0000,  0.8888,  ...,  0.6018, -0.0618, -0.6523],\n",
            "        ...,\n",
            "        [-0.4500,  0.9999, -0.3783,  ..., -0.7916,  0.3186, -0.6958],\n",
            "        [ 0.1750,  1.0000, -0.2948,  ..., -0.7123,  0.4332, -0.9232],\n",
            "        [-0.2157,  1.0000, -0.6996,  ..., -0.8495,  0.7097, -0.3374]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1554,  0.9998, -0.8641,  ..., -0.9198,  0.3147, -0.1523],\n",
            "        [ 0.2921,  1.0000,  0.8699,  ...,  0.6791, -0.4142, -0.5836],\n",
            "        [ 0.5314,  1.0000,  0.9201,  ...,  0.1773,  0.1795, -0.9560],\n",
            "        ...,\n",
            "        [-0.0622,  1.0000,  0.8221,  ..., -0.7022,  0.3684, -0.8778],\n",
            "        [-0.4734,  0.9999, -0.8489,  ..., -0.9171,  0.5949, -0.0891],\n",
            "        [-0.2680,  1.0000, -0.7580,  ..., -0.8931,  0.5456, -0.1172]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5850,  1.0000, -0.5061,  ..., -0.8645,  0.5200, -0.6130],\n",
            "        [-0.5225,  0.9998, -0.8555,  ..., -0.8464,  0.5069,  0.0461],\n",
            "        [ 0.2015,  1.0000, -0.4632,  ..., -0.8207,  0.1791, -0.8474],\n",
            "        ...,\n",
            "        [ 0.7501,  1.0000,  0.8214,  ...,  0.6586,  0.1741, -0.7394],\n",
            "        [-0.1574,  1.0000, -0.7139,  ..., -0.8376,  0.5956, -0.5620],\n",
            "        [-0.1153,  0.9999, -0.7664,  ..., -0.8421,  0.4883, -0.0441]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6160,  1.0000,  0.8764,  ...,  0.6387, -0.0330, -0.7081],\n",
            "        [ 0.6156,  1.0000,  0.9014,  ...,  0.6794, -0.0935, -0.6226],\n",
            "        [ 0.0508,  1.0000,  0.6109,  ..., -0.8682,  0.5409, -0.9312],\n",
            "        ...,\n",
            "        [-0.1791,  0.9992, -0.6253,  ..., -0.8249,  0.4067, -0.0078],\n",
            "        [ 0.3079,  0.9986,  0.8271,  ...,  0.5471,  0.1327, -0.3474],\n",
            "        [ 0.5473,  1.0000,  0.9208,  ...,  0.7795, -0.0487, -0.5562]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1036,  0.9094,  0.3543,  ...,  0.4036,  0.0740, -0.3830],\n",
            "        [ 0.8385,  1.0000,  0.8339,  ...,  0.7469, -0.1203, -0.7495],\n",
            "        [-0.2009,  1.0000, -0.7963,  ..., -0.8844,  0.4101, -0.5114],\n",
            "        ...,\n",
            "        [ 0.8337,  1.0000,  0.9070,  ...,  0.8470, -0.1643, -0.6336],\n",
            "        [-0.2307,  0.9968, -0.8553,  ..., -0.9077,  0.5645,  0.1481],\n",
            "        [ 0.2797,  0.9977,  0.5517,  ...,  0.8107, -0.1586, -0.0380]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4967,  0.9996, -0.8586,  ..., -0.9014,  0.2725,  0.0625],\n",
            "        [-0.2361,  0.9996, -0.8504,  ..., -0.8990,  0.2042, -0.0668],\n",
            "        [ 0.4031,  1.0000,  0.7905,  ...,  0.4323,  0.1393, -0.7293],\n",
            "        ...,\n",
            "        [-0.5337,  0.9973, -0.8837,  ..., -0.8783,  0.3679,  0.5004],\n",
            "        [ 0.6936,  1.0000,  0.8911,  ...,  0.8058, -0.4343, -0.6726],\n",
            "        [-0.2175,  0.9996, -0.8337,  ..., -0.9018,  0.3663, -0.1092]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5726,  1.0000,  0.8169,  ...,  0.7946, -0.2637, -0.5386],\n",
            "        [ 0.6528,  1.0000,  0.9320,  ...,  0.7828, -0.2484, -0.4838],\n",
            "        [-0.1158,  1.0000, -0.7858,  ..., -0.8528,  0.5904, -0.4591],\n",
            "        ...,\n",
            "        [-0.2145,  1.0000, -0.2783,  ..., -0.7604,  0.5513, -0.7105],\n",
            "        [-0.0077,  0.9967,  0.7866,  ...,  0.4792, -0.2118, -0.2519],\n",
            "        [ 0.1217,  0.9976,  0.7446,  ...,  0.4120, -0.3584, -0.3253]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2097,  0.9996,  0.8257,  ...,  0.4616, -0.2703, -0.5335],\n",
            "        [-0.4177,  1.0000, -0.8911,  ..., -0.8455,  0.4292, -0.1133],\n",
            "        [ 0.2963,  1.0000,  0.9331,  ...,  0.7456, -0.2093, -0.1154],\n",
            "        ...,\n",
            "        [ 0.9079,  1.0000,  0.8931,  ...,  0.7855,  0.2153, -0.9238],\n",
            "        [-0.1571,  1.0000, -0.7027,  ..., -0.9314,  0.5416, -0.4950],\n",
            "        [-0.3191,  0.9999, -0.8581,  ..., -0.8307,  0.1944, -0.1925]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3303,  0.9999, -0.6509,  ..., -0.8499,  0.2633, -0.2824],\n",
            "        [-0.2543,  1.0000, -0.8435,  ..., -0.8595,  0.5253, -0.4573],\n",
            "        [ 0.6536,  1.0000,  0.8557,  ...,  0.8565, -0.2580, -0.6062],\n",
            "        ...,\n",
            "        [-0.4346,  1.0000, -0.8495,  ..., -0.8859,  0.7230, -0.4617],\n",
            "        [-0.0907,  0.8432,  0.4683,  ...,  0.3288, -0.1169, -0.2813],\n",
            "        [ 0.7897,  1.0000,  0.9350,  ...,  0.8246, -0.3166, -0.5061]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5279,  1.0000,  0.8793,  ...,  0.5311, -0.1559, -0.8788],\n",
            "        [ 0.7187,  1.0000,  0.8918,  ...,  0.5963, -0.0118, -0.6410],\n",
            "        [-0.0216,  1.0000,  0.3148,  ..., -0.6037, -0.1158, -0.8394],\n",
            "        ...,\n",
            "        [-0.4771,  0.9989, -0.8930,  ..., -0.9029,  0.1620,  0.2800],\n",
            "        [-0.2752,  1.0000, -0.6352,  ..., -0.7375,  0.0664, -0.6896],\n",
            "        [ 0.4816,  1.0000,  0.9472,  ...,  0.7721, -0.3820, -0.4229]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1477,  0.9998, -0.9208,  ..., -0.8937,  0.4473, -0.1121],\n",
            "        [-0.3132,  1.0000, -0.8552,  ..., -0.8902,  0.5309, -0.0128],\n",
            "        [ 0.2886,  1.0000,  0.2725,  ..., -0.7924,  0.7353, -0.9598],\n",
            "        ...,\n",
            "        [ 0.7392,  1.0000,  0.9241,  ...,  0.7338,  0.0233, -0.6762],\n",
            "        [-0.5018,  0.9999, -0.8513,  ..., -0.8986,  0.2437,  0.3453],\n",
            "        [-0.3342,  0.9983, -0.8777,  ..., -0.8695,  0.5900, -0.0995]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1585,  0.9999, -0.8204,  ..., -0.8953,  0.5025, -0.3909],\n",
            "        [ 0.6570,  1.0000,  0.8953,  ...,  0.6861, -0.5637, -0.6195],\n",
            "        [-0.1327,  0.9999, -0.7105,  ..., -0.7673,  0.6232, -0.4576],\n",
            "        ...,\n",
            "        [ 0.5918,  1.0000,  0.9059,  ...,  0.5851,  0.1692, -0.9443],\n",
            "        [ 0.6218,  1.0000,  0.9299,  ...,  0.7290, -0.0765, -0.7677],\n",
            "        [-0.6052,  1.0000, -0.4749,  ..., -0.5528,  0.4937, -0.7224]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7374,  1.0000,  0.8532,  ...,  0.7859, -0.1105, -0.4290],\n",
            "        [ 0.6297,  1.0000,  0.9326,  ...,  0.7837, -0.0523, -0.5087],\n",
            "        [ 0.5136,  1.0000,  0.8399,  ...,  0.7095, -0.2285, -0.2878],\n",
            "        ...,\n",
            "        [-0.3970,  1.0000, -0.7998,  ..., -0.8475,  0.4553, -0.1918],\n",
            "        [-0.4165,  1.0000, -0.7017,  ..., -0.9156,  0.6432, -0.2125],\n",
            "        [ 0.0185,  1.0000, -0.8557,  ..., -0.9165,  0.5215, -0.3986]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0908,  0.9999, -0.7829,  ..., -0.8682,  0.5490, -0.5694],\n",
            "        [-0.1924,  1.0000, -0.3130,  ..., -0.9047,  0.6232, -0.8321],\n",
            "        [ 0.6501,  1.0000,  0.9266,  ...,  0.7950, -0.4359, -0.5376],\n",
            "        ...,\n",
            "        [ 0.5713,  0.9999,  0.8512,  ...,  0.7371, -0.3649, -0.6791],\n",
            "        [ 0.6771,  1.0000,  0.8360,  ...,  0.7431, -0.3614, -0.6519],\n",
            "        [ 0.7002,  1.0000,  0.9322,  ...,  0.8612, -0.4076, -0.5306]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0813,  0.1907,  0.5826,  ...,  0.7001, -0.5136, -0.1576],\n",
            "        [ 0.6060,  1.0000,  0.9216,  ...,  0.8907, -0.3379, -0.4569],\n",
            "        [ 0.7552,  1.0000,  0.7953,  ...,  0.6560, -0.4353, -0.7245],\n",
            "        ...,\n",
            "        [-0.1955,  1.0000, -0.6822,  ..., -0.8598,  0.4892, -0.6478],\n",
            "        [ 0.6954,  1.0000,  0.9015,  ...,  0.9009, -0.3599, -0.4771],\n",
            "        [-0.1377,  0.9999, -0.8843,  ..., -0.8904,  0.4764, -0.2297]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7399,  1.0000,  0.9366,  ...,  0.8491, -0.4373, -0.4183],\n",
            "        [-0.2701,  0.9999, -0.8286,  ..., -0.8303,  0.1868, -0.2472],\n",
            "        [ 0.1285,  0.9999, -0.7762,  ..., -0.8588,  0.7070, -0.3761],\n",
            "        ...,\n",
            "        [-0.0690,  0.8499,  0.3885,  ...,  0.3915, -0.1688, -0.2572],\n",
            "        [ 0.3569,  0.9960,  0.9100,  ...,  0.7366, -0.4788, -0.3589],\n",
            "        [ 0.7104,  1.0000,  0.8972,  ...,  0.6398, -0.1104, -0.6560]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0688,  0.8905,  0.7494,  ...,  0.5651, -0.7669,  0.0065],\n",
            "        [ 0.5930,  1.0000,  0.9017,  ...,  0.6691, -0.4235, -0.4941],\n",
            "        [ 0.0310,  0.9999, -0.8597,  ..., -0.8902,  0.4955, -0.5289],\n",
            "        ...,\n",
            "        [ 0.6801,  0.9998,  0.8523,  ...,  0.8257, -0.6322, -0.5207],\n",
            "        [ 0.5857,  1.0000,  0.8531,  ...,  0.7208, -0.3749, -0.6788],\n",
            "        [ 0.5398,  1.0000,  0.9123,  ...,  0.6499, -0.5174, -0.5746]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5881,  1.0000,  0.8897,  ...,  0.7838, -0.3388, -0.6932],\n",
            "        [ 0.6748,  1.0000,  0.9195,  ...,  0.5828, -0.1647, -0.7914],\n",
            "        [ 0.6078,  1.0000,  0.9023,  ...,  0.8306, -0.2902, -0.6011],\n",
            "        ...,\n",
            "        [ 0.3670,  1.0000, -0.6691,  ..., -0.8576,  0.6170, -0.2534],\n",
            "        [-0.3269,  0.9998, -0.8409,  ..., -0.9379,  0.5363, -0.2466],\n",
            "        [-0.1157,  0.9994, -0.6813,  ..., -0.8095,  0.6309, -0.2293]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3587,  1.0000,  0.8710,  ...,  0.5813, -0.1275, -0.6270],\n",
            "        [ 0.6785,  0.9996,  0.9261,  ...,  0.7645, -0.4771, -0.5151],\n",
            "        [ 0.4107,  0.9997,  0.8733,  ...,  0.6658, -0.2265, -0.5491],\n",
            "        ...,\n",
            "        [-0.2450,  1.0000, -0.7754,  ..., -0.8802,  0.6077, -0.5206],\n",
            "        [ 0.7483,  1.0000,  0.8389,  ...,  0.8574, -0.4830, -0.5466],\n",
            "        [-0.2847,  0.9999, -0.7720,  ..., -0.8409,  0.6043, -0.4997]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3142,  0.9998,  0.9314,  ...,  0.7819, -0.3909, -0.1615],\n",
            "        [-0.0345,  0.9583,  0.5987,  ...,  0.6879, -0.6969, -0.0096],\n",
            "        [-0.4015,  1.0000, -0.7019,  ..., -0.8929,  0.5133, -0.7012],\n",
            "        ...,\n",
            "        [ 0.6485,  1.0000,  0.9295,  ...,  0.8418, -0.2404, -0.6121],\n",
            "        [-0.5420,  1.0000, -0.7688,  ..., -0.8648,  0.3092, -0.2065],\n",
            "        [ 0.5214,  1.0000,  0.9274,  ...,  0.7732, -0.2348, -0.6377]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3369,  1.0000, -0.7328,  ..., -0.8440,  0.4988,  0.3045],\n",
            "        [ 0.4478,  0.9996,  0.9218,  ...,  0.6644, -0.4010, -0.5058],\n",
            "        [-0.3463,  0.4987, -0.0453,  ...,  0.2792, -0.1681, -0.0532],\n",
            "        ...,\n",
            "        [ 0.6574,  1.0000,  0.8651,  ...,  0.7494, -0.4815, -0.8362],\n",
            "        [-0.4733,  1.0000, -0.4846,  ..., -0.8521,  0.5532, -0.7211],\n",
            "        [-0.2216,  1.0000, -0.7593,  ..., -0.8479,  0.6503, -0.2671]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5446,  1.0000,  0.8005,  ...,  0.5929, -0.3512, -0.6559],\n",
            "        [ 0.2340,  0.9989,  0.9135,  ...,  0.6797, -0.3375, -0.4059],\n",
            "        [-0.5458,  0.9996, -0.7515,  ..., -0.8901,  0.4344,  0.1359],\n",
            "        ...,\n",
            "        [ 0.2219,  1.0000,  0.4064,  ..., -0.6499,  0.6106, -0.8826],\n",
            "        [ 0.6734,  1.0000,  0.8494,  ...,  0.8141, -0.5194, -0.5738],\n",
            "        [-0.1964,  0.9994, -0.7713,  ..., -0.8370,  0.5476, -0.1693]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4366,  0.9999, -0.8524,  ..., -0.9410,  0.1506, -0.3941],\n",
            "        [ 0.7469,  1.0000,  0.9234,  ...,  0.8346, -0.4133, -0.5534],\n",
            "        [-0.3024,  1.0000, -0.7200,  ..., -0.8804,  0.8545, -0.3212],\n",
            "        ...,\n",
            "        [-0.2655,  0.9476,  0.1377,  ...,  0.5701, -0.3466,  0.0730],\n",
            "        [ 0.7160,  1.0000,  0.9312,  ...,  0.8500, -0.4241, -0.7361],\n",
            "        [-0.2043,  0.9954,  0.4643,  ...,  0.3295, -0.4335, -0.1602]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1682,  1.0000, -0.8213,  ..., -0.8696,  0.4757, -0.2871],\n",
            "        [ 0.7096,  1.0000,  0.8912,  ...,  0.7906, -0.3538, -0.5381],\n",
            "        [ 0.3804,  1.0000,  0.8278,  ...,  0.4665, -0.3633, -0.3944],\n",
            "        ...,\n",
            "        [-0.1204,  0.9992,  0.5424,  ...,  0.6135, -0.5211, -0.1635],\n",
            "        [-0.0044,  1.0000,  0.2459,  ..., -0.5748,  0.7061, -0.9601],\n",
            "        [-0.0768,  1.0000, -0.3951,  ..., -0.9025,  0.7321, -0.7415]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2926,  1.0000, -0.0260,  ..., -0.8212,  0.5544, -0.9293],\n",
            "        [ 0.3042,  1.0000,  0.8914,  ...,  0.0170,  0.3039, -0.8256],\n",
            "        [ 0.6587,  1.0000,  0.9174,  ...,  0.6993, -0.2788, -0.6886],\n",
            "        ...,\n",
            "        [ 0.7037,  1.0000,  0.8856,  ...,  0.7751, -0.5504, -0.5467],\n",
            "        [ 0.6857,  1.0000,  0.8889,  ...,  0.8954, -0.1977, -0.6510],\n",
            "        [ 0.0349,  0.9995,  0.7972,  ...,  0.5655, -0.4432, -0.2508]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2732,  1.0000, -0.3548,  ..., -0.8260,  0.2178, -0.0880],\n",
            "        [ 0.6102,  1.0000,  0.8944,  ...,  0.7961, -0.3255, -0.5401],\n",
            "        [ 0.0912,  1.0000,  0.9238,  ..., -0.1473,  0.5966, -0.8949],\n",
            "        ...,\n",
            "        [-0.2654,  1.0000, -0.6563,  ..., -0.8524,  0.5667, -0.6579],\n",
            "        [-0.2249,  1.0000, -0.3969,  ..., -0.8842,  0.5482, -0.4651],\n",
            "        [-0.0011,  1.0000, -0.7488,  ..., -0.8710,  0.5764, -0.4466]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6120,  1.0000,  0.8597,  ...,  0.8425, -0.2744, -0.5987],\n",
            "        [-0.3129,  1.0000, -0.5940,  ..., -0.9402,  0.8089, -0.7267],\n",
            "        [-0.6044,  1.0000, -0.7049,  ..., -0.8602,  0.1674, -0.3580],\n",
            "        ...,\n",
            "        [-0.6326,  1.0000, -0.8171,  ..., -0.9155,  0.6557, -0.5096],\n",
            "        [ 0.6728,  1.0000,  0.8965,  ...,  0.8152, -0.2357, -0.3490],\n",
            "        [ 0.6792,  1.0000,  0.9254,  ...,  0.8875,  0.0342, -0.6534]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7203,  1.0000,  0.9361,  ...,  0.8248, -0.3434, -0.6196],\n",
            "        [ 0.5069,  1.0000,  0.8492,  ...,  0.8342, -0.3583, -0.4993],\n",
            "        [ 0.4908,  1.0000,  0.0212,  ..., -0.6823,  0.7991, -0.9285],\n",
            "        ...,\n",
            "        [ 0.7975,  1.0000,  0.9408,  ...,  0.8880, -0.3718, -0.4980],\n",
            "        [ 0.1068,  1.0000, -0.6366,  ..., -0.8455,  0.6856, -0.6880],\n",
            "        [-0.3850,  1.0000, -0.4877,  ..., -0.7294,  0.6158, -0.7516]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3113,  0.9999, -0.7804,  ..., -0.8770,  0.5359, -0.6331],\n",
            "        [ 0.7112,  1.0000,  0.9411,  ...,  0.8151, -0.1251, -0.6463],\n",
            "        [ 0.6019,  1.0000,  0.9338,  ...,  0.7740, -0.3675, -0.4316],\n",
            "        ...,\n",
            "        [ 0.7005,  1.0000,  0.9269,  ...,  0.8834, -0.2408, -0.7106],\n",
            "        [ 0.6109,  1.0000,  0.9093,  ...,  0.7236, -0.2034, -0.6771],\n",
            "        [-0.4984,  0.9997, -0.8624,  ..., -0.8760,  0.4362,  0.2005]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6285,  1.0000,  0.8650,  ...,  0.7650, -0.4534, -0.6538],\n",
            "        [-0.2207,  0.9998,  0.5728,  ...,  0.5938, -0.0714, -0.5236],\n",
            "        [-0.0942,  1.0000, -0.5760,  ..., -0.8045,  0.6775, -0.7873],\n",
            "        ...,\n",
            "        [ 0.2655,  1.0000,  0.1960,  ..., -0.7011,  0.5341, -0.8334],\n",
            "        [-0.2737,  0.9997, -0.8435,  ..., -0.8679,  0.3357, -0.3133],\n",
            "        [-0.1112,  1.0000, -0.4274,  ..., -0.8319,  0.5360, -0.8065]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0086,  0.9999,  0.7605,  ...,  0.5320, -0.2098, -0.2843],\n",
            "        [-0.2571,  1.0000, -0.5810,  ..., -0.9431,  0.8162, -0.7307],\n",
            "        [ 0.7304,  1.0000,  0.9400,  ...,  0.9106, -0.2383, -0.6762],\n",
            "        ...,\n",
            "        [ 0.4754,  1.0000,  0.9280,  ...,  0.6918, -0.3001, -0.6140],\n",
            "        [-0.3742,  1.0000, -0.5108,  ..., -0.8404,  0.5119, -0.6757],\n",
            "        [ 0.7125,  1.0000,  0.8778,  ...,  0.8035, -0.1558, -0.7329]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6805,  1.0000,  0.8318,  ...,  0.8806, -0.0520, -0.6398],\n",
            "        [ 0.6721,  1.0000,  0.8746,  ...,  0.8742, -0.4777, -0.5283],\n",
            "        [ 0.6562,  1.0000,  0.9240,  ...,  0.8054, -0.3211, -0.7397],\n",
            "        ...,\n",
            "        [ 0.5196,  1.0000,  0.9341,  ...,  0.8499, -0.2109, -0.5266],\n",
            "        [ 0.6568,  1.0000,  0.9183,  ...,  0.8022, -0.3491, -0.5488],\n",
            "        [-0.4152,  1.0000, -0.8029,  ..., -0.8651,  0.5817, -0.3829]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3738,  1.0000, -0.0862,  ..., -0.4835,  0.2094, -0.7608],\n",
            "        [ 0.7093,  1.0000,  0.9090,  ...,  0.8841, -0.4837, -0.5392],\n",
            "        [-0.2484,  1.0000, -0.7539,  ..., -0.9284,  0.6327, -0.3557],\n",
            "        ...,\n",
            "        [-0.4506,  0.9999, -0.7645,  ..., -0.9152,  0.4936, -0.2640],\n",
            "        [ 0.8088,  1.0000,  0.8598,  ...,  0.8137, -0.3282, -0.7306],\n",
            "        [ 0.3053,  1.0000,  0.8676,  ...,  0.6233, -0.0296, -0.5584]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0391,  1.0000, -0.7694,  ..., -0.8310,  0.5418, -0.5052],\n",
            "        [-0.1941,  1.0000, -0.8257,  ..., -0.9308,  0.5481, -0.4547],\n",
            "        [ 0.5264,  1.0000,  0.9418,  ...,  0.8940, -0.4083, -0.5790],\n",
            "        ...,\n",
            "        [-0.2828,  0.9998, -0.8898,  ..., -0.9078,  0.3001, -0.3477],\n",
            "        [ 0.4592,  1.0000,  0.8781,  ...,  0.6352, -0.3447, -0.5052],\n",
            "        [-0.2652,  1.0000, -0.8485,  ..., -0.9102,  0.4343, -0.4216]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0422,  1.0000,  0.7199,  ...,  0.7005,  0.1075, -0.4760],\n",
            "        [ 0.1664,  1.0000, -0.1431,  ..., -0.8371,  0.7282, -0.9000],\n",
            "        [ 0.6660,  1.0000,  0.9097,  ...,  0.8429, -0.1994, -0.7106],\n",
            "        ...,\n",
            "        [ 0.6375,  1.0000,  0.9331,  ...,  0.8165, -0.0640, -0.5183],\n",
            "        [ 0.1251,  1.0000,  0.6933,  ...,  0.6999,  0.0467, -0.5626],\n",
            "        [ 0.5806,  1.0000,  0.9168,  ...,  0.7747, -0.3130, -0.7016]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6474,  1.0000,  0.8624,  ...,  0.6351, -0.3182, -0.8248],\n",
            "        [-0.6424,  0.9995, -0.8794,  ..., -0.9201,  0.5012, -0.0041],\n",
            "        [-0.3951,  1.0000, -0.8571,  ..., -0.8801,  0.1501, -0.3337],\n",
            "        ...,\n",
            "        [ 0.0896,  1.0000, -0.5331,  ..., -0.9151,  0.5816, -0.7506],\n",
            "        [-0.0927,  0.9984, -0.8797,  ..., -0.8231,  0.4446,  0.0908],\n",
            "        [-0.2347,  1.0000, -0.7502,  ..., -0.8673,  0.7210, -0.4952]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1606,  0.9992, -0.4470,  ..., -0.8244,  0.3496, -0.5196],\n",
            "        [-0.2038,  0.9972, -0.9449,  ..., -0.8834,  0.5480, -0.0953],\n",
            "        [-0.4031,  0.9999, -0.7703,  ..., -0.8890,  0.3632, -0.2145],\n",
            "        ...,\n",
            "        [ 0.7267,  1.0000,  0.9091,  ...,  0.8382, -0.0873, -0.6129],\n",
            "        [ 0.5658,  1.0000,  0.8482,  ...,  0.7450, -0.4891, -0.7590],\n",
            "        [-0.4129,  0.9990, -0.9000,  ..., -0.9043,  0.0877,  0.1683]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7109,  1.0000,  0.9225,  ...,  0.8060, -0.3675, -0.5508],\n",
            "        [-0.6585,  0.9996, -0.7631,  ..., -0.9330,  0.4607, -0.3035],\n",
            "        [ 0.6081,  1.0000,  0.9442,  ...,  0.4034, -0.2625, -0.8448],\n",
            "        ...,\n",
            "        [-0.1824,  1.0000,  0.6655,  ..., -0.7164,  0.2910, -0.9544],\n",
            "        [-0.0735,  1.0000,  0.0256,  ..., -0.8353,  0.6753, -0.8890],\n",
            "        [ 0.4653,  1.0000,  0.8974,  ...,  0.8312, -0.4530, -0.2980]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7549,  1.0000,  0.9368,  ...,  0.8941, -0.1615, -0.6667],\n",
            "        [-0.2020,  1.0000, -0.7660,  ..., -0.8231,  0.7486, -0.8622],\n",
            "        [ 0.6570,  1.0000,  0.9012,  ...,  0.8010, -0.4860, -0.7687],\n",
            "        ...,\n",
            "        [ 0.7293,  1.0000,  0.9338,  ...,  0.7592, -0.2964, -0.5313],\n",
            "        [-0.2927,  1.0000, -0.8634,  ..., -0.8790,  0.6005, -0.3231],\n",
            "        [-0.1927,  0.9999, -0.5447,  ..., -0.8533,  0.5745, -0.5342]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6805,  1.0000,  0.8641,  ...,  0.8366, -0.2082, -0.5269],\n",
            "        [ 0.8108,  1.0000,  0.9388,  ...,  0.8368, -0.2755, -0.8103],\n",
            "        [-0.5416,  0.9996, -0.8513,  ..., -0.9263,  0.4177, -0.3518],\n",
            "        ...,\n",
            "        [-0.2037,  0.9996, -0.8864,  ..., -0.8710,  0.3288, -0.1597],\n",
            "        [-0.4299,  0.9999, -0.8127,  ..., -0.8566,  0.3271, -0.4469],\n",
            "        [ 0.5995,  1.0000,  0.8213,  ..., -0.4240,  0.4432, -0.9602]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4146,  1.0000,  0.9414,  ...,  0.7750,  0.0484, -0.5969],\n",
            "        [-0.1621,  1.0000, -0.8216,  ..., -0.8962,  0.5130, -0.4514],\n",
            "        [-0.3553,  0.9966, -0.8857,  ..., -0.9188,  0.4402, -0.0317],\n",
            "        ...,\n",
            "        [ 0.4112,  1.0000,  0.7547,  ...,  0.7097, -0.5205, -0.7642],\n",
            "        [ 0.7851,  1.0000,  0.8993,  ...,  0.8372, -0.1432, -0.6362],\n",
            "        [ 0.5852,  1.0000,  0.9296,  ...,  0.9052, -0.3066, -0.7854]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7540,  1.0000,  0.9026,  ...,  0.8280, -0.3861, -0.6783],\n",
            "        [ 0.7010,  1.0000,  0.8477,  ...,  0.7883,  0.0547, -0.7941],\n",
            "        [-0.3546,  0.9530, -0.8731,  ..., -0.9429,  0.5128, -0.2386],\n",
            "        ...,\n",
            "        [-0.2802,  1.0000, -0.8348,  ..., -0.9145,  0.6185, -0.1333],\n",
            "        [ 0.7303,  1.0000,  0.8097,  ...,  0.8050, -0.0409, -0.7375],\n",
            "        [ 0.5735,  1.0000,  0.9057,  ...,  0.8110, -0.0240, -0.6761]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3104,  1.0000, -0.7837,  ..., -0.8936,  0.7318, -0.8127],\n",
            "        [ 0.8407,  1.0000,  0.8186,  ...,  0.1179, -0.0332, -0.9472],\n",
            "        [-0.6680,  0.9996, -0.8138,  ..., -0.9174,  0.3506, -0.0999],\n",
            "        ...,\n",
            "        [ 0.1099,  1.0000,  0.6969,  ...,  0.5828,  0.2870, -0.7409],\n",
            "        [ 0.0038,  1.0000,  0.8045,  ..., -0.2605, -0.1553, -0.9118],\n",
            "        [ 0.7311,  1.0000,  0.8432,  ...,  0.7755, -0.5021, -0.4601]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6935,  1.0000,  0.9598,  ...,  0.3689, -0.1832, -0.8567],\n",
            "        [ 0.6028,  1.0000,  0.8667,  ...,  0.6758, -0.0200, -0.8344],\n",
            "        [-0.2561,  1.0000, -0.6391,  ..., -0.9036,  0.7418, -0.4156],\n",
            "        ...,\n",
            "        [ 0.6958,  1.0000,  0.9290,  ...,  0.8695, -0.1026, -0.6477],\n",
            "        [ 0.2328,  0.9982,  0.3045,  ...,  0.6140,  0.0456, -0.4426],\n",
            "        [-0.2404,  1.0000, -0.7260,  ..., -0.9550,  0.5424, -0.6722]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7213,  1.0000,  0.9333,  ...,  0.8368, -0.3387, -0.6029],\n",
            "        [-0.0454,  1.0000,  0.4653,  ...,  0.4166, -0.2224, -0.4599],\n",
            "        [-0.5609,  1.0000, -0.6305,  ..., -0.8451,  0.5786, -0.8054],\n",
            "        ...,\n",
            "        [-0.5603,  0.9999, -0.8329,  ..., -0.8654,  0.5440, -0.1868],\n",
            "        [ 0.7684,  1.0000,  0.8282,  ...,  0.1949, -0.2108, -0.7388],\n",
            "        [-0.5111,  0.9999, -0.9255,  ..., -0.8106,  0.4631, -0.1170]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7675,  1.0000,  0.9296,  ...,  0.8767, -0.0450, -0.7445],\n",
            "        [ 0.7810,  1.0000,  0.8738,  ...,  0.8373, -0.3702, -0.5983],\n",
            "        [ 0.3438,  1.0000,  0.9135,  ...,  0.4031,  0.2830, -0.9692],\n",
            "        ...,\n",
            "        [-0.3141,  0.9997, -0.6828,  ..., -0.8020,  0.7781, -0.5284],\n",
            "        [-0.1917,  0.9999, -0.7330,  ..., -0.9315,  0.7423, -0.3641],\n",
            "        [ 0.7850,  1.0000,  0.8962,  ...,  0.8490, -0.2199, -0.6293]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3131,  1.0000, -0.7052,  ..., -0.8022,  0.6041, -0.7286],\n",
            "        [-0.1876,  0.9999, -0.9131,  ..., -0.9243,  0.2835,  0.0056],\n",
            "        [ 0.2803,  1.0000, -0.0224,  ..., -0.7453,  0.7384, -0.8688],\n",
            "        ...,\n",
            "        [-0.4384,  0.9980, -0.9046,  ..., -0.9290,  0.4375, -0.1900],\n",
            "        [ 0.5164,  1.0000,  0.9063,  ...,  0.7838, -0.5095, -0.7380],\n",
            "        [-0.0956,  0.9999, -0.8473,  ..., -0.8667,  0.3460,  0.1954]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7577,  1.0000,  0.9231,  ...,  0.7396, -0.3224, -0.7034],\n",
            "        [ 0.5942,  1.0000,  0.8821,  ...,  0.7900, -0.3935, -0.7110],\n",
            "        [-0.1639,  1.0000, -0.6604,  ..., -0.8381,  0.7487, -0.4503],\n",
            "        ...,\n",
            "        [ 0.5627,  1.0000,  0.8906,  ...,  0.8349, -0.4835, -0.5953],\n",
            "        [ 0.7627,  1.0000,  0.8662,  ...,  0.8563, -0.1827, -0.5619],\n",
            "        [ 0.6193,  1.0000,  0.8646,  ...,  0.8210, -0.3529, -0.5928]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7171,  1.0000,  0.9208,  ...,  0.8877, -0.4279, -0.5774],\n",
            "        [ 0.1313,  1.0000, -0.4383,  ..., -0.7717,  0.6190, -0.9560],\n",
            "        [ 0.6764,  1.0000,  0.8247,  ...,  0.7823, -0.1840, -0.6803],\n",
            "        ...,\n",
            "        [ 0.7010,  1.0000,  0.9067,  ...,  0.8459,  0.0116, -0.6985],\n",
            "        [ 0.5592,  1.0000,  0.2692,  ..., -0.8508,  0.6671, -0.9142],\n",
            "        [-0.3552,  1.0000, -0.5901,  ..., -0.9367,  0.6585, -0.2417]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2711,  0.9998, -0.8599,  ..., -0.9095,  0.1777,  0.2398],\n",
            "        [ 0.7549,  1.0000,  0.8655,  ...,  0.3858, -0.0636, -0.8380],\n",
            "        [ 0.6593,  1.0000,  0.8785,  ...,  0.7837, -0.5491, -0.7670],\n",
            "        ...,\n",
            "        [ 0.5706,  1.0000,  0.9329,  ...,  0.8728, -0.3573, -0.5478],\n",
            "        [ 0.1199,  1.0000,  0.6287,  ...,  0.6339,  0.3627, -0.2692],\n",
            "        [ 0.7071,  1.0000,  0.9567,  ...,  0.8204, -0.3009, -0.5364]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3206,  0.9942, -0.6171,  ..., -0.8163,  0.4098,  0.0216],\n",
            "        [-0.2264,  0.9995, -0.8682,  ..., -0.9199,  0.4276,  0.1685],\n",
            "        [-0.3192,  0.9924, -0.9161,  ..., -0.9156,  0.2755,  0.1713],\n",
            "        ...,\n",
            "        [-0.2996,  1.0000, -0.3904,  ..., -0.8623,  0.7274, -0.2402],\n",
            "        [ 0.0343,  1.0000, -0.8351,  ..., -0.9109,  0.6516, -0.5414],\n",
            "        [-0.0505,  0.9997, -0.8923,  ..., -0.9212,  0.2327,  0.0263]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5595,  1.0000,  0.9009,  ...,  0.8526, -0.4555, -0.6224],\n",
            "        [-0.3346,  0.9994, -0.8892,  ..., -0.9302,  0.2995, -0.0274],\n",
            "        [-0.2381,  1.0000, -0.8236,  ..., -0.8944,  0.7085, -0.5644],\n",
            "        ...,\n",
            "        [-0.3289,  0.9951,  0.4230,  ..., -0.1555,  0.1330, -0.4670],\n",
            "        [-0.5359,  0.9991, -0.7659,  ..., -0.8561,  0.5256,  0.0505],\n",
            "        [ 0.0916,  1.0000,  0.6967,  ...,  0.3856, -0.2302, -0.4578]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4424,  1.0000, -0.8116,  ..., -0.8983,  0.5040, -0.5543],\n",
            "        [ 0.6030,  1.0000,  0.7894,  ...,  0.7910, -0.3454, -0.4752],\n",
            "        [ 0.8211,  1.0000,  0.8741,  ...,  0.8324, -0.2251, -0.6261],\n",
            "        ...,\n",
            "        [-0.3971,  0.9998, -0.7391,  ..., -0.9331,  0.5884,  0.1279],\n",
            "        [-0.3986,  0.9995, -0.8516,  ..., -0.9006,  0.4132, -0.0519],\n",
            "        [-0.2272,  0.9993, -0.7809,  ..., -0.7722,  0.5935, -0.3612]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6643,  1.0000,  0.9484,  ...,  0.9117, -0.4171, -0.5520],\n",
            "        [ 0.4678,  1.0000,  0.8965,  ...,  0.6430, -0.2685, -0.5253],\n",
            "        [ 0.6875,  1.0000,  0.9207,  ...,  0.8274, -0.1136, -0.7139],\n",
            "        ...,\n",
            "        [-0.3340,  1.0000, -0.6852,  ..., -0.8753,  0.6678, -0.5003],\n",
            "        [ 0.6263,  1.0000,  0.9054,  ...,  0.8057, -0.3144, -0.5516],\n",
            "        [ 0.7157,  1.0000,  0.8930,  ...,  0.8707, -0.4339, -0.5525]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0777,  0.9998, -0.8836,  ..., -0.8897,  0.6576, -0.6770],\n",
            "        [ 0.4379,  1.0000,  0.8772,  ...,  0.4569, -0.4803, -0.6747],\n",
            "        [-0.5137,  0.9998, -0.8498,  ..., -0.9491,  0.6561, -0.2309],\n",
            "        ...,\n",
            "        [ 0.6048,  1.0000,  0.7996,  ...,  0.6310, -0.6115, -0.5622],\n",
            "        [ 0.1417,  1.0000, -0.4778,  ..., -0.8837,  0.5147, -0.9202],\n",
            "        [-0.0801,  0.9985, -0.8200,  ..., -0.9015,  0.1230,  0.0967]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4816,  1.0000,  0.9036,  ...,  0.7982, -0.3422, -0.4529],\n",
            "        [ 0.6712,  1.0000,  0.8169,  ...,  0.2243, -0.0234, -0.8716],\n",
            "        [-0.5251,  0.9994, -0.8725,  ..., -0.8850,  0.2063, -0.2328],\n",
            "        ...,\n",
            "        [-0.4027,  0.9725, -0.8347,  ..., -0.8887,  0.4848,  0.0145],\n",
            "        [ 0.5583,  1.0000,  0.9133,  ...,  0.8797, -0.5259, -0.6319],\n",
            "        [-0.5917,  0.9996, -0.9155,  ..., -0.8631,  0.0911,  0.0441]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1762,  0.9994, -0.7273,  ..., -0.9526,  0.4661, -0.2275],\n",
            "        [-0.4851,  0.9982, -0.9070,  ..., -0.9519,  0.3838, -0.0753],\n",
            "        [-0.2904,  1.0000, -0.8065,  ..., -0.8926,  0.5556, -0.1759],\n",
            "        ...,\n",
            "        [ 0.2518,  1.0000,  0.8180,  ...,  0.6540,  0.1516, -0.6841],\n",
            "        [ 0.6886,  1.0000,  0.9147,  ...,  0.6909, -0.4432, -0.5046],\n",
            "        [ 0.6217,  1.0000,  0.9074,  ...,  0.8850, -0.2305, -0.7380]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5456,  0.9998, -0.9212,  ..., -0.9452,  0.2815,  0.0913],\n",
            "        [-0.3647,  0.9999, -0.8420,  ..., -0.8967,  0.2741, -0.2944],\n",
            "        [ 0.2311,  1.0000,  0.5381,  ...,  0.5478,  0.3749, -0.6075],\n",
            "        ...,\n",
            "        [ 0.2638,  1.0000,  0.8294,  ...,  0.4909, -0.3973, -0.3963],\n",
            "        [-0.2330,  0.9983, -0.8219,  ..., -0.8764,  0.5472, -0.4792],\n",
            "        [ 0.6991,  1.0000,  0.8387,  ...,  0.5885, -0.0537, -0.7173]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6284,  1.0000,  0.9138,  ...,  0.8267, -0.3772, -0.5990],\n",
            "        [ 0.7196,  1.0000,  0.8794,  ...,  0.5654, -0.5073, -0.6219],\n",
            "        [ 0.5984,  1.0000,  0.9337,  ...,  0.7565, -0.4093, -0.6076],\n",
            "        ...,\n",
            "        [-0.3408,  0.9998, -0.7241,  ..., -0.8878,  0.2774, -0.4467],\n",
            "        [ 0.6092,  1.0000,  0.9527,  ...,  0.8133, -0.3838, -0.7002],\n",
            "        [-0.4095,  0.9992, -0.8359,  ..., -0.8908,  0.1281,  0.1312]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7229,  1.0000,  0.8874,  ...,  0.8222, -0.5419, -0.4951],\n",
            "        [ 0.3956,  1.0000,  0.8394,  ...,  0.5419, -0.4166, -0.7423],\n",
            "        [ 0.6424,  1.0000,  0.9262,  ...,  0.7412, -0.4230, -0.5898],\n",
            "        ...,\n",
            "        [ 0.4429,  0.9999,  0.8878,  ...,  0.7871, -0.3531, -0.2482],\n",
            "        [-0.0290,  0.9998,  0.2790,  ..., -0.4054,  0.1481, -0.8295],\n",
            "        [-0.0310,  1.0000,  0.4099,  ...,  0.4594,  0.2580, -0.5976]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4852,  0.9996, -0.7077,  ..., -0.8573,  0.6351, -0.2458],\n",
            "        [-0.1177,  0.9997, -0.8878,  ..., -0.9238,  0.3511, -0.3300],\n",
            "        [-0.2940,  0.9951, -0.8572,  ..., -0.8360,  0.3504,  0.0569],\n",
            "        ...,\n",
            "        [ 0.6679,  1.0000,  0.8962,  ...,  0.7907, -0.3531, -0.5811],\n",
            "        [ 0.4887,  1.0000,  0.9040,  ...,  0.6266, -0.3736, -0.7684],\n",
            "        [ 0.7174,  1.0000,  0.9049,  ...,  0.8068, -0.2593, -0.5281]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2423,  0.9968, -0.7836,  ..., -0.7173,  0.0589,  0.3540],\n",
            "        [ 0.7597,  1.0000,  0.9065,  ...,  0.8720, -0.2722, -0.5968],\n",
            "        [-0.5179,  0.9994, -0.8182,  ..., -0.9106,  0.3922, -0.1576],\n",
            "        ...,\n",
            "        [ 0.3169,  0.9999,  0.8551,  ...,  0.1196, -0.1973, -0.8055],\n",
            "        [ 0.6822,  1.0000,  0.9224,  ..., -0.1563,  0.3681, -0.9468],\n",
            "        [ 0.4881,  0.9999,  0.8272,  ...,  0.6766, -0.5623, -0.4026]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2085,  1.0000,  0.8684,  ...,  0.1439, -0.3473, -0.8424],\n",
            "        [ 0.6569,  1.0000,  0.8447,  ...,  0.6869, -0.4841, -0.5699],\n",
            "        [ 0.6338,  1.0000,  0.8520,  ..., -0.1230, -0.0034, -0.7268],\n",
            "        ...,\n",
            "        [-0.1185,  0.9992, -0.8718,  ..., -0.9407,  0.4285, -0.2044],\n",
            "        [ 0.5912,  1.0000,  0.8036,  ...,  0.4277, -0.2408, -0.7450],\n",
            "        [ 0.7136,  1.0000,  0.8964,  ...,  0.7921, -0.5504, -0.5834]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4119,  0.9980, -0.9375,  ..., -0.9090,  0.3179,  0.0850],\n",
            "        [-0.2456,  0.9983, -0.8884,  ..., -0.8564,  0.2408, -0.1335],\n",
            "        [-0.2226,  1.0000, -0.6278,  ..., -0.8670,  0.7203, -0.7903],\n",
            "        ...,\n",
            "        [-0.4413,  0.8865, -0.8836,  ..., -0.9027,  0.2763, -0.2210],\n",
            "        [ 0.4568,  1.0000,  0.7772,  ...,  0.6971, -0.6973, -0.6306],\n",
            "        [-0.4265,  0.9461, -0.8463,  ..., -0.9027,  0.4155,  0.2281]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6853,  1.0000,  0.8685,  ...,  0.4919, -0.1343, -0.8756],\n",
            "        [ 0.5722,  1.0000,  0.9125,  ...,  0.8972, -0.3332, -0.6277],\n",
            "        [-0.2008,  0.9980, -0.9213,  ..., -0.8766,  0.1856, -0.0016],\n",
            "        ...,\n",
            "        [ 0.6361,  0.9999,  0.8984,  ...,  0.8172, -0.6251, -0.4774],\n",
            "        [-0.2955,  0.9999, -0.7901,  ..., -0.8573,  0.1402, -0.2743],\n",
            "        [ 0.4506,  0.9999,  0.8838,  ...,  0.7094, -0.6107, -0.3659]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0981,  1.0000, -0.3477,  ..., -0.8549,  0.6305, -0.8718],\n",
            "        [ 0.2903,  1.0000,  0.8899,  ...,  0.2751, -0.5172, -0.6270],\n",
            "        [-0.4406,  0.9926, -0.9336,  ..., -0.8784,  0.4566,  0.0022],\n",
            "        ...,\n",
            "        [ 0.5567,  1.0000,  0.9223,  ...,  0.8750, -0.4565, -0.4162],\n",
            "        [-0.3150,  0.9985, -0.7672,  ..., -0.8470,  0.2576,  0.1795],\n",
            "        [ 0.6088,  1.0000,  0.9107,  ...,  0.7324, -0.3928, -0.7660]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7371,  1.0000,  0.8016,  ...,  0.3694, -0.3629, -0.7731],\n",
            "        [ 0.4830,  1.0000,  0.9475,  ...,  0.6436, -0.5217, -0.6275],\n",
            "        [-0.4151,  0.9946, -0.8313,  ..., -0.9247,  0.3173,  0.3490],\n",
            "        ...,\n",
            "        [ 0.1265,  1.0000,  0.7904,  ...,  0.2780,  0.2888, -0.6840],\n",
            "        [ 0.5578,  1.0000,  0.8726,  ...,  0.8176, -0.5111, -0.7196],\n",
            "        [-0.6571,  0.9961, -0.8599,  ..., -0.9058,  0.3365,  0.2552]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5337,  0.9998, -0.8781,  ..., -0.9439,  0.1963,  0.0595],\n",
            "        [ 0.7586,  1.0000,  0.8429,  ...,  0.7968, -0.5000, -0.6474],\n",
            "        [ 0.1473,  0.9992,  0.7352,  ..., -0.4893,  0.2015, -0.6747],\n",
            "        ...,\n",
            "        [-0.0122,  0.9999,  0.5845,  ..., -0.3751,  0.1306, -0.9421],\n",
            "        [ 0.3871,  1.0000,  0.4708,  ..., -0.4682,  0.4207, -0.9058],\n",
            "        [-0.4144,  0.9989, -0.8059,  ..., -0.9210, -0.0657, -0.1060]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4802, -0.7643, -0.9262,  ..., -0.9134,  0.5470,  0.2145],\n",
            "        [-0.4889,  0.8811, -0.9610,  ..., -0.9262,  0.4285,  0.1289],\n",
            "        [-0.5769,  0.9995, -0.8565,  ..., -0.9211,  0.2942,  0.1067],\n",
            "        ...,\n",
            "        [-0.4748,  0.9998, -0.8431,  ..., -0.9083,  0.5596, -0.1395],\n",
            "        [-0.2907,  0.9924, -0.7686,  ..., -0.9235,  0.1666, -0.0962],\n",
            "        [-0.3108,  0.9737, -0.9019,  ..., -0.8991,  0.3054,  0.0342]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3716,  0.9964, -0.7649,  ..., -0.8959,  0.5508, -0.5824],\n",
            "        [-0.2493,  1.0000, -0.2547,  ..., -0.9149,  0.3602, -0.8797],\n",
            "        [-0.4553,  0.9966, -0.8726,  ..., -0.9124,  0.1146,  0.0811],\n",
            "        ...,\n",
            "        [ 0.7578,  1.0000,  0.9282,  ...,  0.8085,  0.3850, -0.9410],\n",
            "        [-0.3688,  0.9936, -0.8758,  ..., -0.9291,  0.2807,  0.0521],\n",
            "        [ 0.7773,  1.0000,  0.9431,  ...,  0.6788, -0.0276, -0.9463]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0362,  0.9998, -0.8652,  ..., -0.9150,  0.4652, -0.4101],\n",
            "        [ 0.6784,  1.0000,  0.8819,  ...,  0.6973, -0.4558, -0.5038],\n",
            "        [-0.1054,  0.9789, -0.8477,  ..., -0.8433,  0.4352, -0.2263],\n",
            "        ...,\n",
            "        [-0.4298,  1.0000, -0.7819,  ..., -0.9275,  0.6916, -0.5934],\n",
            "        [ 0.7061,  1.0000,  0.9150,  ...,  0.8402, -0.3718, -0.6049],\n",
            "        [-0.4496,  0.9969, -0.8682,  ..., -0.8713,  0.4931, -0.4118]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4023,  0.9999, -0.5140,  ..., -0.8649,  0.0513, -0.1172],\n",
            "        [ 0.7279,  1.0000,  0.9114,  ...,  0.6914, -0.3858, -0.7234],\n",
            "        [ 0.6677,  1.0000,  0.8947,  ...,  0.7385, -0.3569, -0.5775],\n",
            "        ...,\n",
            "        [-0.3231,  1.0000, -0.7571,  ..., -0.9557,  0.4160, -0.1895],\n",
            "        [-0.4327,  0.9984, -0.9076,  ..., -0.8939,  0.0129, -0.1656],\n",
            "        [ 0.7641,  1.0000,  0.8167,  ...,  0.7459, -0.4668, -0.7263]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0356,  1.0000, -0.8399,  ..., -0.9028,  0.3561, -0.5231],\n",
            "        [-0.3646,  0.9560, -0.9156,  ..., -0.9348,  0.4287, -0.1148],\n",
            "        [ 0.3475,  1.0000, -0.1575,  ..., -0.7417,  0.5366, -0.8865],\n",
            "        ...,\n",
            "        [-0.2484,  1.0000, -0.5212,  ..., -0.8428,  0.5917, -0.9007],\n",
            "        [ 0.3420,  1.0000,  0.8581,  ...,  0.0268, -0.0528, -0.8953],\n",
            "        [ 0.6915,  1.0000,  0.9200,  ...,  0.6708, -0.3920, -0.6913]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6568,  1.0000,  0.9266,  ...,  0.5868, -0.2240, -0.5837],\n",
            "        [ 0.6122,  1.0000, -0.3941,  ..., -0.6666,  0.5828, -0.6221],\n",
            "        [-0.3643,  0.9999, -0.7485,  ..., -0.8822,  0.3665, -0.2844],\n",
            "        ...,\n",
            "        [-0.2539,  0.9994, -0.8849,  ..., -0.9162,  0.3231, -0.0639],\n",
            "        [-0.1742,  0.9999, -0.7207,  ..., -0.8179,  0.6281, -0.4975],\n",
            "        [ 0.7202,  1.0000,  0.9198,  ...,  0.4978, -0.4142, -0.8059]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5144,  1.0000,  0.8707,  ...,  0.5539, -0.5458, -0.4687],\n",
            "        [ 0.3278,  1.0000,  0.8517,  ...,  0.1188, -0.1597, -0.8932],\n",
            "        [ 0.7233,  1.0000,  0.9234,  ...,  0.8326, -0.3906, -0.6256],\n",
            "        ...,\n",
            "        [ 0.7134,  0.9999,  0.9321,  ...,  0.8195, -0.1030, -0.7631],\n",
            "        [ 0.5422,  1.0000,  0.8859,  ...,  0.7030, -0.7021, -0.6357],\n",
            "        [-0.3883,  1.0000,  0.5452,  ..., -0.7537,  0.6793, -0.6706]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3327,  1.0000, -0.6329,  ..., -0.8208,  0.6200, -0.6809],\n",
            "        [ 0.4356,  1.0000,  0.9167,  ...,  0.6799, -0.1656, -0.6830],\n",
            "        [ 0.5175,  1.0000,  0.0939,  ..., -0.8793,  0.6752, -0.9526],\n",
            "        ...,\n",
            "        [ 0.3178,  1.0000,  0.8876,  ...,  0.4767,  0.3495, -0.7497],\n",
            "        [ 0.7904,  1.0000,  0.9301,  ...,  0.7636, -0.2021, -0.4632],\n",
            "        [-0.0387,  1.0000, -0.1203,  ..., -0.8290,  0.3645, -0.7781]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0560,  1.0000, -0.4899,  ..., -0.9150,  0.5645, -0.9260],\n",
            "        [ 0.3485,  1.0000,  0.8965,  ...,  0.5860, -0.5577, -0.5868],\n",
            "        [-0.2191,  0.9993, -0.8879,  ..., -0.9228,  0.3215, -0.0614],\n",
            "        ...,\n",
            "        [ 0.1779,  1.0000, -0.7015,  ..., -0.8878,  0.2146, -0.4592],\n",
            "        [ 0.4698,  0.9997,  0.9164,  ...,  0.7093, -0.4945, -0.4491],\n",
            "        [ 0.6988,  1.0000,  0.9425,  ...,  0.3427, -0.3896, -0.8424]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1374,  1.0000, -0.6131,  ..., -0.8948,  0.5605, -0.5621],\n",
            "        [ 0.5408,  1.0000,  0.0358,  ..., -0.6808,  0.5555, -0.8575],\n",
            "        [ 0.6850,  1.0000,  0.9311,  ...,  0.1834, -0.1235, -0.9373],\n",
            "        ...,\n",
            "        [ 0.3295,  1.0000,  0.8290,  ..., -0.5154,  0.6896, -0.9581],\n",
            "        [-0.3827,  1.0000, -0.8496,  ..., -0.9669,  0.2885, -0.5750],\n",
            "        [ 0.1304,  1.0000, -0.6239,  ..., -0.8109,  0.5325, -0.4968]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1789,  0.9997, -0.9226,  ..., -0.9398,  0.4872, -0.4588],\n",
            "        [ 0.6591,  1.0000,  0.9228,  ...,  0.6421, -0.3632, -0.6524],\n",
            "        [ 0.4531,  1.0000, -0.1535,  ..., -0.8845,  0.4895, -0.9171],\n",
            "        ...,\n",
            "        [ 0.4240,  1.0000,  0.8699,  ...,  0.6067, -0.4651, -0.7874],\n",
            "        [-0.2984,  0.9995, -0.7385,  ..., -0.9112,  0.4254, -0.3757],\n",
            "        [ 0.6393,  1.0000,  0.9277,  ...,  0.8010, -0.5652, -0.5354]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6923,  1.0000,  0.9479,  ...,  0.7998, -0.4011, -0.7934],\n",
            "        [ 0.4212,  1.0000,  0.9054,  ...,  0.6843, -0.3605, -0.5790],\n",
            "        [-0.3107,  1.0000, -0.8473,  ..., -0.8647,  0.3460,  0.0143],\n",
            "        ...,\n",
            "        [-0.6360,  0.9973, -0.7928,  ..., -0.9097,  0.2286, -0.4198],\n",
            "        [-0.4027,  0.9999, -0.7727,  ..., -0.9138,  0.3487,  0.0209],\n",
            "        [-0.0570,  0.9999, -0.8296,  ..., -0.8985,  0.3640, -0.5748]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5141,  0.9990, -0.8746,  ..., -0.8708,  0.2290, -0.0874],\n",
            "        [ 0.7677,  1.0000,  0.8913,  ...,  0.6756, -0.4221, -0.4228],\n",
            "        [ 0.5917,  1.0000,  0.8700,  ...,  0.7663, -0.3774, -0.5949],\n",
            "        ...,\n",
            "        [ 0.5408,  1.0000,  0.8770,  ...,  0.7526, -0.3049, -0.7270],\n",
            "        [ 0.6806,  1.0000,  0.8918,  ...,  0.4626, -0.1664, -0.8110],\n",
            "        [-0.2189,  0.9998, -0.8159,  ..., -0.8846,  0.3476, -0.0069]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7048,  1.0000,  0.9198,  ...,  0.6643, -0.4537, -0.7204],\n",
            "        [ 0.3877,  1.0000,  0.8767,  ...,  0.5691, -0.2702, -0.5065],\n",
            "        [ 0.5073,  1.0000,  0.8958,  ...,  0.6251, -0.1828, -0.5234],\n",
            "        ...,\n",
            "        [ 0.6738,  1.0000,  0.9458,  ...,  0.6845, -0.2885, -0.7758],\n",
            "        [ 0.4622,  1.0000, -0.6734,  ..., -0.8554,  0.4742, -0.6735],\n",
            "        [ 0.6148,  1.0000,  0.8962,  ...,  0.7941, -0.5055, -0.6887]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5523,  1.0000,  0.7830,  ...,  0.0684, -0.2034, -0.9278],\n",
            "        [ 0.5815,  1.0000,  0.9059,  ...,  0.6010, -0.5316, -0.8247],\n",
            "        [ 0.3604,  1.0000,  0.7701,  ...,  0.4943,  0.4580, -0.7909],\n",
            "        ...,\n",
            "        [ 0.3070,  1.0000, -0.4046,  ..., -0.9157,  0.5978, -0.6744],\n",
            "        [-0.2304,  0.9999, -0.9352,  ..., -0.9064,  0.4341, -0.0921],\n",
            "        [-0.1406,  1.0000, -0.2751,  ..., -0.8719,  0.3885, -0.8317]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2230,  0.9993, -0.4228,  ..., -0.8856,  0.3961, -0.3542],\n",
            "        [ 0.2133,  0.9999, -0.8273,  ..., -0.9137,  0.3312, -0.4772],\n",
            "        [ 0.7424,  1.0000,  0.8678,  ...,  0.4275, -0.1684, -0.8918],\n",
            "        ...,\n",
            "        [ 0.1462,  0.9997, -0.6150,  ..., -0.7785,  0.3448, -0.3781],\n",
            "        [-0.2632,  1.0000, -0.5660,  ..., -0.9347,  0.5626, -0.2836],\n",
            "        [ 0.6176,  1.0000,  0.9137,  ...,  0.7563, -0.3651, -0.7292]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4339,  1.0000, -0.5789,  ..., -0.8744,  0.6725, -0.7321],\n",
            "        [ 0.2763,  1.0000, -0.7175,  ..., -0.9103,  0.3092, -0.8708],\n",
            "        [ 0.6455,  1.0000,  0.8945,  ...,  0.4771, -0.3544, -0.7141],\n",
            "        ...,\n",
            "        [-0.1104,  0.9998, -0.6894,  ..., -0.9206,  0.5743, -0.2188],\n",
            "        [ 0.6513,  1.0000,  0.9030,  ...,  0.7155, -0.4097, -0.6274],\n",
            "        [-0.1345,  1.0000,  0.2614,  ..., -0.6466,  0.5385, -0.9491]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1322,  0.9999, -0.6597,  ..., -0.8629,  0.3716, -0.3998],\n",
            "        [-0.2366,  1.0000, -0.0606,  ..., -0.8783,  0.7448, -0.9117],\n",
            "        [ 0.2064,  1.0000, -0.2387,  ..., -0.8889,  0.6608, -0.9523],\n",
            "        ...,\n",
            "        [ 0.6138,  1.0000,  0.8776,  ...,  0.6545, -0.4352, -0.7042],\n",
            "        [ 0.4338,  1.0000, -0.6626,  ..., -0.7771,  0.6614, -0.8158],\n",
            "        [ 0.6206,  1.0000,  0.6981,  ..., -0.5306,  0.4229, -0.9650]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2804,  0.9936,  0.3466,  ..., -0.5774,  0.4714, -0.4969],\n",
            "        [ 0.6860,  1.0000,  0.8962,  ...,  0.7220, -0.1302, -0.5942],\n",
            "        [ 0.4936,  1.0000,  0.9317,  ...,  0.5722, -0.3785, -0.7558],\n",
            "        ...,\n",
            "        [-0.2033,  1.0000, -0.6043,  ..., -0.8621,  0.4454, -0.7835],\n",
            "        [ 0.5389,  1.0000,  0.9132,  ...,  0.6930, -0.3205, -0.6306],\n",
            "        [ 0.2045,  1.0000, -0.5818,  ..., -0.8448,  0.5754, -0.7187]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2330,  1.0000,  0.2599,  ..., -0.8803,  0.8568, -0.8394],\n",
            "        [ 0.7593,  1.0000,  0.8507,  ...,  0.7078, -0.4162, -0.7660],\n",
            "        [ 0.4336,  1.0000,  0.9024,  ...,  0.6958, -0.3308, -0.6481],\n",
            "        ...,\n",
            "        [ 0.6645,  1.0000,  0.8572,  ..., -0.4845,  0.0202, -0.9496],\n",
            "        [-0.1172,  0.9998, -0.8636,  ..., -0.8885,  0.1448, -0.1225],\n",
            "        [-0.0305,  1.0000, -0.7396,  ..., -0.8757, -0.0854, -0.3839]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7823,  1.0000,  0.8379,  ...,  0.4488,  0.0361, -0.8651],\n",
            "        [ 0.6099,  1.0000,  0.9506,  ...,  0.7898, -0.5282, -0.5019],\n",
            "        [ 0.4755,  0.9999,  0.9254,  ...,  0.6574, -0.4210, -0.6075],\n",
            "        ...,\n",
            "        [ 0.5009,  1.0000,  0.9032,  ...,  0.7401, -0.6520, -0.7293],\n",
            "        [ 0.4104,  1.0000,  0.7970,  ...,  0.7393, -0.3021, -0.6521],\n",
            "        [ 0.5882,  1.0000,  0.7506,  ...,  0.4480, -0.2105, -0.7626]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0396,  0.9995, -0.8329,  ..., -0.9066,  0.3200, -0.5460],\n",
            "        [ 0.7254,  1.0000,  0.8256,  ...,  0.6925, -0.2316, -0.7806],\n",
            "        [ 0.8400,  1.0000,  0.9241,  ...,  0.7176, -0.3159, -0.7772],\n",
            "        ...,\n",
            "        [ 0.6574,  1.0000,  0.8511,  ...,  0.6133, -0.3101, -0.6109],\n",
            "        [ 0.4658,  1.0000,  0.9065,  ...,  0.3305,  0.4463, -0.8124],\n",
            "        [ 0.7030,  1.0000,  0.9201,  ...,  0.6618, -0.4645, -0.7731]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6344,  1.0000,  0.9223,  ...,  0.2630,  0.1465, -0.9799],\n",
            "        [ 0.5744,  0.9999,  0.9116,  ...,  0.7230, -0.4812, -0.5903],\n",
            "        [-0.0439,  1.0000, -0.7684,  ..., -0.9530,  0.6219, -0.4975],\n",
            "        ...,\n",
            "        [ 0.0958,  1.0000, -0.8090,  ..., -0.9032,  0.5306, -0.5391],\n",
            "        [ 0.0476,  0.9997, -0.6624,  ..., -0.8947,  0.4829, -0.5587],\n",
            "        [-0.2484,  0.9984, -0.9022,  ..., -0.8901,  0.2486, -0.0084]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0474,  1.0000, -0.4207,  ..., -0.8503,  0.7837, -0.8981],\n",
            "        [ 0.4371,  1.0000,  0.1686,  ..., -0.4194,  0.4830, -0.8124],\n",
            "        [ 0.5703,  0.9999,  0.8883,  ...,  0.7609, -0.5389, -0.5307],\n",
            "        ...,\n",
            "        [-0.0243,  0.9992, -0.8842,  ..., -0.9271,  0.5943, -0.1665],\n",
            "        [-0.5248,  0.9997, -0.7732,  ..., -0.8394,  0.5938,  0.0740],\n",
            "        [-0.5428,  0.9999, -0.8973,  ..., -0.9164,  0.3701, -0.2573]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.8158,  1.0000,  0.8777,  ...,  0.7858, -0.3027, -0.7645],\n",
            "        [ 0.7258,  1.0000, -0.0071,  ..., -0.6397,  0.5542, -0.9513],\n",
            "        [-0.1652,  1.0000, -0.8266,  ..., -0.9303,  0.5563, -0.4129],\n",
            "        ...,\n",
            "        [ 0.4919,  1.0000,  0.8238,  ...,  0.7724, -0.6573, -0.6731],\n",
            "        [-0.4037,  1.0000,  0.2421,  ..., -0.2512,  0.5878, -0.8613],\n",
            "        [-0.2196,  1.0000, -0.4576,  ..., -0.7510,  0.3765, -0.5048]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3074,  1.0000, -0.8405,  ..., -0.8806,  0.0104, -0.0132],\n",
            "        [ 0.3666,  1.0000,  0.8998,  ...,  0.5542, -0.4078, -0.4438],\n",
            "        [ 0.5847,  1.0000,  0.8922,  ...,  0.7735, -0.4653, -0.7994],\n",
            "        ...,\n",
            "        [ 0.5862,  1.0000,  0.9082,  ...,  0.4309, -0.6514, -0.7919],\n",
            "        [ 0.3224,  1.0000,  0.8755,  ..., -0.6051,  0.8498, -0.9351],\n",
            "        [ 0.2874,  1.0000, -0.3019,  ..., -0.8084,  0.7409, -0.8958]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2686,  1.0000, -0.6208,  ..., -0.8680,  0.5921, -0.3986],\n",
            "        [ 0.4561,  1.0000,  0.9124,  ...,  0.6177, -0.2948, -0.7033],\n",
            "        [ 0.3145,  1.0000,  0.8597,  ...,  0.5471, -0.4239, -0.6408],\n",
            "        ...,\n",
            "        [ 0.3636,  1.0000,  0.7862,  ...,  0.3366, -0.2992, -0.7006],\n",
            "        [ 0.2940,  0.9999,  0.8444,  ...,  0.6375, -0.6429, -0.3894],\n",
            "        [ 0.5295,  1.0000,  0.9115,  ...,  0.0779, -0.1514, -0.9225]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1191,  1.0000, -0.4421,  ..., -0.7420,  0.3521, -0.3690],\n",
            "        [-0.5185,  1.0000, -0.2234,  ..., -0.8894,  0.6103, -0.8069],\n",
            "        [ 0.7473,  1.0000,  0.8849,  ...,  0.6544, -0.3335, -0.8425],\n",
            "        ...,\n",
            "        [ 0.1784,  1.0000, -0.2567,  ..., -0.8922,  0.6454, -0.8209],\n",
            "        [ 0.1101,  1.0000, -0.7274,  ..., -0.9036,  0.6137, -0.9253],\n",
            "        [ 0.1220,  1.0000, -0.5279,  ..., -0.9440,  0.5248, -0.8686]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0222,  1.0000, -0.5304,  ..., -0.8803,  0.3408, -0.6957],\n",
            "        [ 0.5447,  1.0000,  0.8228,  ..., -0.3815,  0.4311, -0.9414],\n",
            "        [ 0.4046,  1.0000,  0.9294,  ...,  0.4622, -0.3895, -0.5398],\n",
            "        ...,\n",
            "        [ 0.0648,  1.0000,  0.8518,  ...,  0.0442,  0.4402, -0.9609],\n",
            "        [ 0.3519,  1.0000, -0.0244,  ..., -0.9002,  0.4366, -0.9452],\n",
            "        [ 0.4116,  1.0000,  0.8063,  ...,  0.5547, -0.1834, -0.9212]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4551,  1.0000,  0.9377,  ...,  0.2215,  0.1321, -0.9061],\n",
            "        [-0.1453,  1.0000, -0.2812,  ..., -0.7205,  0.6519, -0.8297],\n",
            "        [-0.1271,  0.9996, -0.8260,  ..., -0.8348,  0.3818, -0.6029],\n",
            "        ...,\n",
            "        [-0.4304,  0.9995, -0.8790,  ..., -0.9363,  0.2637,  0.0561],\n",
            "        [ 0.3961,  1.0000,  0.8748,  ...,  0.8198, -0.5555, -0.5954],\n",
            "        [ 0.2013,  1.0000,  0.8534,  ...,  0.3091, -0.5997, -0.7422]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2913,  0.9999, -0.8918,  ..., -0.9550,  0.3770, -0.0550],\n",
            "        [-0.4418,  1.0000, -0.6273,  ..., -0.8731,  0.6788, -0.1922],\n",
            "        [-0.0242,  1.0000, -0.8119,  ..., -0.9162,  0.6395, -0.8064],\n",
            "        ...,\n",
            "        [-0.4710,  0.9994, -0.9026,  ..., -0.8718,  0.3471, -0.0520],\n",
            "        [ 0.4204,  1.0000,  0.7971,  ...,  0.2100, -0.3822, -0.8325],\n",
            "        [-0.4764,  1.0000, -0.8806,  ..., -0.9443,  0.4695, -0.4018]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5414,  1.0000,  0.9007,  ...,  0.2748,  0.2226, -0.9315],\n",
            "        [ 0.8215,  1.0000,  0.8473,  ...,  0.7040, -0.4937, -0.8664],\n",
            "        [-0.3485,  0.9999, -0.5444,  ..., -0.9410,  0.6648, -0.6721],\n",
            "        ...,\n",
            "        [-0.4903,  0.9951, -0.8591,  ..., -0.9349,  0.4201,  0.0231],\n",
            "        [ 0.4254,  1.0000,  0.8085,  ...,  0.4801, -0.3764, -0.7976],\n",
            "        [ 0.5794,  1.0000,  0.8306,  ...,  0.5267, -0.6700, -0.5951]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1930,  1.0000, -0.5532,  ..., -0.8601,  0.4206, -0.9014],\n",
            "        [-0.0898,  0.9996, -0.7760,  ..., -0.8554,  0.1438, -0.2454],\n",
            "        [-0.3218,  0.9958, -0.8812,  ..., -0.9087,  0.2253,  0.3661],\n",
            "        ...,\n",
            "        [ 0.4395,  1.0000,  0.8468,  ...,  0.5236, -0.2760, -0.7293],\n",
            "        [-0.3896,  1.0000, -0.8427,  ..., -0.9309,  0.4613, -0.6333],\n",
            "        [-0.2831,  0.9998, -0.7818,  ..., -0.9164,  0.2773, -0.5562]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-4.0639e-01,  9.9965e-01, -8.1005e-01, -9.8433e-01,  5.7341e-01,\n",
            "         -8.6376e-01, -1.9955e-01, -3.5049e-01, -9.5846e-01,  3.1689e-01,\n",
            "         -6.2846e-01,  8.6906e-01, -3.1281e-01,  9.9760e-01, -1.3999e-01,\n",
            "          6.7112e-01, -6.1768e-01, -9.6758e-01,  6.8836e-01, -6.6800e-01,\n",
            "          4.7752e-01,  8.4910e-01,  6.1624e-01, -6.9991e-01, -8.2732e-01,\n",
            "         -7.0940e-01,  5.5020e-01,  6.0156e-01, -5.2931e-01,  2.6498e-01,\n",
            "         -5.8655e-01,  2.0402e-01,  8.9822e-01,  6.0217e-01,  2.5833e-01,\n",
            "         -8.3921e-01, -1.1140e-01, -3.7816e-01, -9.8272e-01, -9.7259e-01,\n",
            "          4.5901e-01, -2.8362e-01,  9.9219e-01, -9.0230e-01,  9.6010e-01,\n",
            "         -9.5185e-01,  2.3547e-01, -7.6226e-01,  8.0431e-01,  5.3807e-01,\n",
            "         -8.3764e-02, -9.8393e-01,  7.5787e-01, -4.3346e-01, -7.2335e-01,\n",
            "         -9.9280e-01, -6.3593e-01,  7.5133e-01, -6.3789e-01,  6.4218e-01,\n",
            "         -3.8323e-02, -7.8648e-01,  8.1497e-01,  5.4455e-01,  7.8916e-01,\n",
            "          6.4202e-01,  8.3612e-01,  5.3497e-01,  9.1079e-01, -9.8852e-01,\n",
            "         -5.1631e-01, -7.9127e-01,  2.8252e-01, -5.5420e-01,  6.7444e-01,\n",
            "         -2.4510e-01,  3.7713e-01, -6.7613e-01, -4.2377e-01,  7.7818e-01,\n",
            "         -1.7827e-01,  7.5033e-01,  7.7542e-01, -9.9933e-01, -2.5167e-01,\n",
            "         -8.2536e-01,  9.4514e-01, -8.7600e-01, -8.0188e-01,  1.5387e-01,\n",
            "          2.8263e-01, -6.3611e-01, -6.1160e-01,  3.6369e-02, -2.0941e-02,\n",
            "         -8.5101e-01,  3.8245e-02, -5.8315e-01, -9.9351e-01,  4.6895e-01,\n",
            "          8.2592e-01,  8.2344e-01,  6.1076e-01, -2.9677e-01, -9.9817e-01,\n",
            "         -8.4126e-01,  2.2188e-01, -8.8592e-01, -9.9938e-01, -1.9667e-01,\n",
            "         -8.0234e-01, -1.7366e-01,  3.8084e-01,  8.2436e-01, -2.6949e-01,\n",
            "          9.9845e-01, -8.8928e-01,  6.1095e-01, -9.9855e-01, -8.8671e-01,\n",
            "          1.2641e-01,  4.1857e-01,  1.7137e-02, -6.0646e-01,  1.8665e-01,\n",
            "         -9.6409e-01, -9.2495e-01, -9.9185e-01,  3.2405e-01, -3.0801e-03,\n",
            "         -4.5729e-01,  5.0954e-01, -6.5448e-01, -8.3159e-01, -1.6175e-01,\n",
            "         -4.1494e-01, -9.9056e-01,  6.3145e-01,  5.1338e-01, -9.6586e-01,\n",
            "          9.6699e-01,  9.5164e-01, -2.3812e-01, -5.9690e-01, -2.0016e-01,\n",
            "          9.0530e-01, -5.0701e-02,  2.1096e-01, -6.8319e-02, -8.4710e-01,\n",
            "          3.3591e-02,  1.1071e-01, -1.3100e-01,  4.5726e-01, -9.9953e-01,\n",
            "          7.5484e-01,  7.1884e-01,  9.6638e-01,  9.2810e-01,  1.6621e-01,\n",
            "         -6.1275e-01, -9.9934e-01,  8.4422e-01,  4.6534e-01,  9.7100e-01,\n",
            "          9.1170e-03, -3.6043e-02,  8.9106e-01,  5.7406e-01,  1.6128e-01,\n",
            "          5.1695e-01,  6.5252e-01,  5.1370e-01,  7.6237e-01,  9.7722e-01,\n",
            "         -8.9196e-01, -8.7859e-01, -7.3514e-01,  8.8225e-01, -7.4655e-01,\n",
            "          9.4074e-01, -6.0715e-01,  7.0298e-01, -9.3988e-01, -5.4921e-01,\n",
            "          5.7683e-04, -2.8500e-01, -9.9955e-01, -2.4648e-02,  8.3080e-01,\n",
            "         -1.8873e-01, -9.0164e-01,  4.4352e-01,  2.1500e-01,  6.3639e-01,\n",
            "         -3.0766e-01, -6.7045e-01,  5.7709e-01, -2.8762e-02,  8.8463e-01,\n",
            "          6.7244e-01, -8.8972e-01,  9.8781e-01,  3.3673e-01, -2.1955e-01,\n",
            "         -9.7955e-01,  5.0789e-01,  9.6146e-01, -9.3273e-01, -8.1990e-01,\n",
            "          1.4964e-01,  1.1384e-01,  5.6276e-01, -7.3850e-01, -1.0254e-01,\n",
            "         -5.1053e-01,  8.8894e-01, -8.6917e-01,  7.8868e-01,  6.9052e-01,\n",
            "         -8.8139e-02, -5.2246e-01, -4.4853e-01, -5.7258e-01,  2.8390e-01,\n",
            "         -1.6098e-02, -5.1418e-01,  2.1558e-01, -8.9783e-01, -9.9832e-01,\n",
            "          2.1767e-01,  6.0277e-01,  6.0323e-01,  5.4692e-02,  9.9792e-01,\n",
            "          4.1272e-01, -7.3747e-01,  9.2781e-01, -9.6325e-01, -4.5861e-01,\n",
            "          7.1070e-01, -9.8811e-01,  7.8582e-01, -3.1330e-01,  9.9938e-01,\n",
            "         -9.8337e-01,  9.0983e-01, -8.0264e-01,  5.7869e-01,  7.8740e-01,\n",
            "         -5.8261e-01,  1.4479e-01,  8.7976e-01,  7.7450e-01,  8.4030e-01,\n",
            "          8.5393e-01,  9.1589e-02, -9.8848e-01, -3.6293e-02,  6.0848e-01,\n",
            "         -9.7233e-01,  3.4446e-01, -9.6770e-01, -9.0223e-01,  9.1527e-01,\n",
            "          9.9877e-01, -8.2501e-01,  2.5888e-01,  5.5961e-01,  6.4503e-01,\n",
            "          6.8737e-01, -9.5129e-01,  5.0642e-01,  9.9966e-01, -9.1956e-01,\n",
            "         -8.4516e-01,  9.9929e-01,  3.6175e-01, -9.2691e-01,  5.0809e-01,\n",
            "         -7.2520e-01, -9.3160e-01,  5.5034e-01, -3.1253e-01,  4.6601e-01,\n",
            "          6.7274e-01,  2.8099e-01, -9.4056e-01, -9.8988e-01, -8.9953e-01,\n",
            "          9.8348e-01,  4.5743e-01,  6.7467e-01,  3.1643e-01, -7.9220e-01,\n",
            "         -9.2857e-01,  9.1609e-01,  4.2818e-01, -9.1679e-01,  9.9959e-01,\n",
            "          6.8651e-01, -6.2042e-01, -9.6036e-01,  2.2862e-01,  2.2601e-01,\n",
            "          7.1761e-01,  8.5582e-01,  5.7347e-01, -8.0415e-01,  2.8793e-01,\n",
            "          7.6691e-01, -3.9375e-01,  9.4714e-01,  6.9190e-02, -2.5000e-01,\n",
            "         -2.3879e-01, -2.7083e-01, -9.5330e-01, -6.9639e-01, -5.7443e-01,\n",
            "          5.4175e-01,  9.5619e-01,  6.0082e-01, -8.6824e-01,  9.3141e-01,\n",
            "          3.5383e-01, -9.9936e-01,  9.9545e-01,  9.2160e-01, -8.5004e-01,\n",
            "         -1.4782e-01,  6.7195e-01,  6.3454e-01, -3.1184e-01,  6.6616e-01,\n",
            "         -7.0945e-01, -3.2276e-01, -8.5604e-01,  3.8634e-01,  7.4766e-01,\n",
            "          7.2264e-01,  5.4471e-01,  4.1223e-01,  5.2063e-01,  1.0046e-01,\n",
            "         -5.2024e-01,  7.1909e-01, -6.6163e-01, -9.2947e-01, -5.2946e-01,\n",
            "          1.9377e-01,  6.9824e-01, -8.0704e-01,  8.5788e-01,  8.4616e-01,\n",
            "          9.9967e-01,  5.4073e-01,  9.9782e-01, -8.0963e-01,  6.5985e-01,\n",
            "         -4.7889e-01,  3.7807e-01,  8.3478e-01, -9.0991e-01, -9.9926e-01,\n",
            "         -2.1048e-01, -4.7048e-01,  6.0622e-01, -7.5341e-01, -9.3169e-01,\n",
            "         -8.9986e-01,  4.7290e-01, -4.8172e-01,  8.9293e-01, -5.0319e-01,\n",
            "         -8.3368e-01,  9.8317e-01,  5.2768e-01,  7.0265e-01,  1.9380e-01,\n",
            "         -5.7567e-01,  8.0991e-01,  8.4421e-01,  4.0838e-01,  8.6141e-01,\n",
            "         -3.9209e-01,  8.7451e-01, -8.0488e-01,  7.4661e-01, -1.9430e-01,\n",
            "          2.6819e-01, -7.2587e-04,  2.3523e-01,  7.8294e-01,  7.4872e-01,\n",
            "          9.5446e-01, -3.9150e-01,  2.9251e-02, -9.9310e-01,  9.9968e-01,\n",
            "         -1.8459e-01,  5.2615e-01,  6.0113e-02,  4.7285e-01,  7.8815e-01,\n",
            "         -8.3797e-01,  6.1744e-01, -4.0279e-01,  9.3580e-01, -7.8565e-01,\n",
            "          8.7016e-01,  6.3547e-01,  8.2601e-01, -3.3511e-01, -8.2113e-01,\n",
            "          3.1043e-01, -1.7728e-01, -7.2953e-01, -9.5274e-01,  8.8619e-01,\n",
            "         -9.2625e-01, -6.6633e-01, -8.5519e-01, -9.3242e-01,  9.8522e-01,\n",
            "         -8.5442e-01,  7.1225e-01, -7.8402e-01, -8.1559e-01, -8.1879e-01,\n",
            "         -4.8432e-01, -6.7924e-01,  5.0248e-01, -9.3004e-01,  9.9419e-01,\n",
            "         -9.6690e-01,  7.0279e-01, -7.2079e-01,  2.9588e-01,  7.6847e-01,\n",
            "          6.1824e-01,  1.6164e-01,  5.0051e-01, -3.7744e-02,  5.7689e-02,\n",
            "          7.2422e-01, -7.1938e-01, -7.2604e-01,  1.9563e-01,  4.1362e-01,\n",
            "          3.9666e-01,  9.3768e-01, -2.6510e-01,  9.6777e-01,  3.8176e-01,\n",
            "         -7.9374e-01, -5.0052e-01, -5.3666e-01,  8.9895e-01,  9.8965e-01,\n",
            "         -9.3867e-01,  8.5972e-01,  9.9924e-01, -9.1771e-01, -2.4856e-01,\n",
            "         -2.2347e-01, -9.7813e-01,  6.6792e-01, -8.7198e-01, -9.6238e-01,\n",
            "          2.0913e-01, -5.4817e-01,  7.3594e-01,  6.6845e-01,  9.7387e-01,\n",
            "         -6.9191e-01, -7.4423e-01, -9.6102e-01, -5.1850e-01, -6.9441e-01,\n",
            "         -8.7661e-01,  8.3289e-01, -9.3447e-01, -9.2818e-01,  9.6092e-01,\n",
            "          3.8634e-01, -1.3951e-01,  2.5962e-01,  5.8829e-01,  9.4874e-01,\n",
            "         -6.3777e-01, -9.4670e-01,  3.0210e-01,  5.9598e-01,  1.8929e-01,\n",
            "          4.5668e-01, -8.3315e-01, -5.4007e-01, -9.6418e-01,  7.5409e-01,\n",
            "          9.9749e-01, -4.5586e-01, -5.3961e-01,  7.4016e-01,  1.0205e-01,\n",
            "         -2.3162e-01,  9.9952e-01, -6.4938e-01,  7.8533e-01,  9.9794e-01,\n",
            "          4.8768e-02,  7.2054e-01, -5.7903e-01,  5.9433e-02,  5.1716e-02,\n",
            "          8.2507e-01, -6.3078e-02,  9.8407e-01, -8.0342e-01, -8.7639e-01,\n",
            "         -9.9957e-01,  2.4395e-01, -6.0817e-01, -2.4118e-02,  7.3504e-01,\n",
            "         -8.0425e-01, -4.5007e-01,  4.6213e-01, -9.9071e-01,  8.6688e-01,\n",
            "         -9.3950e-02, -9.9851e-01, -9.7094e-01, -6.3903e-01, -4.2873e-01,\n",
            "         -9.5903e-01, -1.6652e-02, -7.1250e-01, -8.6330e-01,  9.5080e-01,\n",
            "         -7.5282e-01, -9.9938e-01, -3.3575e-01,  7.8343e-01,  9.8844e-01,\n",
            "          3.2558e-01,  2.6902e-01, -6.3832e-01, -6.9245e-01,  4.0215e-01,\n",
            "         -9.9976e-01, -8.4088e-02,  8.2319e-01,  5.2680e-01, -5.3386e-01,\n",
            "          9.6871e-01, -6.1851e-01, -8.3778e-01, -4.2031e-01,  4.4394e-01,\n",
            "          5.1969e-01, -9.9978e-01, -1.6499e-01,  9.8483e-01, -1.7164e-01,\n",
            "         -3.7598e-01, -8.1858e-01, -8.1153e-01, -6.4089e-01, -1.8782e-02,\n",
            "          9.8396e-01, -7.1956e-01,  9.9568e-01, -2.6989e-01,  6.0855e-01,\n",
            "          8.6853e-01,  1.1785e-02, -8.5900e-01, -5.7967e-01,  7.7039e-01,\n",
            "          7.5271e-01,  4.1580e-01,  5.0672e-01, -5.8310e-01,  1.7742e-01,\n",
            "         -2.0529e-01, -7.9219e-01,  5.4454e-01, -6.7051e-01,  4.4701e-01,\n",
            "         -2.8594e-01,  7.2655e-01,  7.0004e-01, -4.6444e-01,  9.9638e-01,\n",
            "          2.5029e-01, -8.2361e-01,  7.1091e-01, -1.8952e-01, -2.6660e-01,\n",
            "         -9.9940e-01, -6.9309e-01,  7.1655e-01, -9.6339e-01, -7.4654e-01,\n",
            "          4.9252e-01, -4.4696e-01, -4.4660e-01,  7.3888e-01, -2.9280e-01,\n",
            "          7.5687e-01,  9.9012e-01,  7.5347e-01,  6.1421e-01, -9.0751e-01,\n",
            "         -9.9763e-01,  1.3784e-01,  7.3623e-01, -8.5996e-01,  8.2727e-01,\n",
            "         -7.6452e-01,  9.9505e-01,  1.1545e-02,  6.4761e-01,  5.3029e-01,\n",
            "          9.8533e-01,  1.9131e-02, -4.8221e-01,  5.6838e-01,  2.6214e-01,\n",
            "         -5.5468e-01,  9.1477e-01, -5.2939e-01, -9.5166e-01, -6.9937e-01,\n",
            "         -7.0315e-01, -1.8179e-01, -4.1318e-01,  5.8864e-01, -3.0509e-02,\n",
            "          9.9965e-01,  8.1792e-01,  8.9388e-01,  4.1194e-01,  6.2721e-01,\n",
            "         -5.2738e-01, -6.5800e-01,  8.9823e-01, -9.9952e-01,  9.1753e-01,\n",
            "          2.5066e-01, -7.3453e-01,  3.9182e-01, -8.4992e-01, -5.5421e-01,\n",
            "         -4.2288e-01, -6.4837e-01, -6.8429e-01, -7.5866e-01, -7.5304e-01,\n",
            "         -4.1257e-01, -3.5759e-01,  8.4836e-01, -6.8979e-01, -9.8347e-01,\n",
            "          9.1925e-01, -5.9900e-01,  6.0408e-01,  5.3492e-01, -3.1982e-01,\n",
            "          4.9420e-01,  6.7401e-01,  8.4500e-01, -6.9726e-01,  2.2155e-01,\n",
            "         -4.6619e-01, -7.4501e-01,  3.7981e-01,  2.8474e-01,  8.5713e-01,\n",
            "          4.3753e-01,  1.6282e-01,  8.2668e-01, -1.7870e-01, -6.5230e-01,\n",
            "          3.0507e-01,  2.5565e-01,  5.0373e-01,  8.3776e-01, -2.8857e-01,\n",
            "          7.6380e-01,  7.8285e-01, -2.1305e-01, -5.0970e-01,  3.8653e-01,\n",
            "          1.9833e-01,  8.9807e-01, -9.9105e-01,  9.9252e-01,  3.3748e-01,\n",
            "         -2.7122e-01, -9.9442e-01, -2.5083e-01,  3.0744e-01,  4.9719e-01,\n",
            "          5.7731e-01,  9.8363e-02, -6.0001e-01, -7.3233e-01,  7.9692e-01,\n",
            "         -9.9977e-01, -8.1831e-01, -6.5114e-01, -1.5156e-02,  7.1752e-01,\n",
            "         -9.8780e-01, -5.9482e-01,  4.3819e-01, -2.5227e-01, -1.1797e-01,\n",
            "          9.8209e-01, -6.9081e-01, -8.7398e-01, -9.2894e-01, -9.2647e-01,\n",
            "          3.6349e-01,  7.0957e-01, -9.3459e-01,  4.3586e-01,  6.8466e-01,\n",
            "         -9.5150e-01, -2.6987e-01,  1.4141e-01,  6.8423e-01, -4.7412e-01,\n",
            "         -3.2882e-01,  8.5047e-01, -9.9967e-01,  7.9959e-01, -2.1477e-01,\n",
            "         -3.3816e-01,  6.4885e-01, -8.1542e-01,  7.1917e-01,  6.2313e-01,\n",
            "         -9.9442e-01,  5.1990e-01, -2.5047e-02,  7.9378e-01,  6.8674e-01,\n",
            "         -5.1726e-01,  3.3135e-01,  4.7524e-01, -3.4831e-01,  9.2373e-01,\n",
            "          4.1474e-01, -6.6364e-02,  1.2924e-01,  9.8347e-01,  6.3329e-01,\n",
            "          7.8843e-01, -2.6954e-02, -9.0257e-01, -9.6492e-01, -3.7069e-01,\n",
            "         -9.2453e-01,  1.7633e-01, -2.2066e-02]], device='cuda:0',\n",
            "       grad_fn=<TanhBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluation... :   0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0811f59155e945598ab2daf8db337ea5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7521,  1.0000,  0.8886,  ...,  0.7293, -0.5455, -0.7694],\n",
            "        [ 0.5936,  1.0000,  0.8982,  ...,  0.7500, -0.5754, -0.6286],\n",
            "        [ 0.8039,  1.0000,  0.3753,  ..., -0.6686,  0.6417, -0.8835],\n",
            "        ...,\n",
            "        [ 0.3786,  1.0000,  0.8748,  ...,  0.3163, -0.3833, -0.7855],\n",
            "        [ 0.0052,  0.9981, -0.7497,  ..., -0.8520,  0.5159, -0.4746],\n",
            "        [-0.4800,  0.9996, -0.8316,  ..., -0.8219,  0.3624, -0.2190]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0806,  1.0000, -0.2766,  ..., -0.9071,  0.6906, -0.8543],\n",
            "        [ 0.5501,  1.0000,  0.7013,  ..., -0.4551, -0.1568, -0.8791],\n",
            "        [ 0.4914,  1.0000,  0.9657,  ..., -0.1020,  0.2034, -0.9684],\n",
            "        ...,\n",
            "        [ 0.2262,  1.0000,  0.7607,  ..., -0.6086,  0.3445, -0.9719],\n",
            "        [-0.3871,  1.0000,  0.2797,  ..., -0.8463,  0.5086, -0.8658],\n",
            "        [ 0.3552,  1.0000,  0.6232,  ..., -0.8585,  0.6676, -0.9812]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5138,  1.0000,  0.9007,  ...,  0.7322, -0.4788, -0.5182],\n",
            "        [ 0.4127,  1.0000,  0.7798,  ...,  0.4174,  0.7664, -0.8707],\n",
            "        [ 0.4786,  1.0000,  0.9067,  ...,  0.4166, -0.1036, -0.9129],\n",
            "        ...,\n",
            "        [ 0.2863,  1.0000,  0.6575,  ..., -0.8843,  0.7964, -0.9870],\n",
            "        [-0.4482,  1.0000, -0.6980,  ..., -0.9114,  0.4033, -0.5664],\n",
            "        [ 0.3795,  1.0000,  0.6808,  ..., -0.8337,  0.4673, -0.9870]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3529,  1.0000,  0.4962,  ..., -0.4342, -0.2874, -0.9230],\n",
            "        [ 0.2450,  1.0000,  0.8131,  ..., -0.4512,  0.5471, -0.9703],\n",
            "        [ 0.3164,  1.0000,  0.2595,  ..., -0.8430,  0.3645, -0.9734],\n",
            "        ...,\n",
            "        [ 0.6824,  1.0000,  0.9054,  ...,  0.8119, -0.4381, -0.6367],\n",
            "        [-0.2038,  0.9996, -0.7167,  ..., -0.9191,  0.5913, -0.5789],\n",
            "        [ 0.6448,  1.0000,  0.9167,  ...,  0.7927, -0.5560, -0.7172]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6223,  1.0000,  0.7965,  ...,  0.0772, -0.0553, -0.7724],\n",
            "        [ 0.3188,  1.0000,  0.9106,  ...,  0.4404,  0.1139, -0.9087],\n",
            "        [-0.0350,  0.9996, -0.7162,  ..., -0.7288,  0.3496, -0.4992],\n",
            "        ...,\n",
            "        [ 0.2137,  1.0000,  0.2966,  ..., -0.5935,  0.0093, -0.9603],\n",
            "        [ 0.5802,  1.0000,  0.9123,  ...,  0.5594, -0.4659, -0.6245],\n",
            "        [ 0.4258,  1.0000,  0.8616,  ...,  0.5459,  0.6380, -0.8609]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5489,  1.0000,  0.8852,  ...,  0.7742, -0.4600, -0.6556],\n",
            "        [ 0.7066,  1.0000,  0.7936,  ...,  0.6295, -0.5138, -0.8333],\n",
            "        [ 0.0018,  0.9999, -0.9014,  ..., -0.9051,  0.5165, -0.3928],\n",
            "        ...,\n",
            "        [ 0.7729,  1.0000,  0.0213,  ..., -0.7110,  0.7514, -0.8193],\n",
            "        [ 0.2742,  1.0000,  0.2364,  ..., -0.5704,  0.0202, -0.8894],\n",
            "        [-0.0661,  1.0000,  0.3808,  ..., -0.8257,  0.4091, -0.9509]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2001,  1.0000, -0.4307,  ..., -0.8596,  0.1302, -0.8704],\n",
            "        [-0.2460,  0.9997, -0.9077,  ..., -0.9325,  0.2490,  0.0446],\n",
            "        [ 0.6472,  1.0000,  0.8804,  ...,  0.7657, -0.4786, -0.7224],\n",
            "        ...,\n",
            "        [-0.2300,  1.0000,  0.0615,  ..., -0.8670, -0.1377, -0.8476],\n",
            "        [ 0.5767,  1.0000,  0.9138,  ...,  0.7485, -0.6053, -0.6339],\n",
            "        [-0.1679,  0.9999, -0.6853,  ..., -0.8202,  0.0993, -0.1559]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6557,  1.0000,  0.9081,  ...,  0.4847, -0.3060, -0.8021],\n",
            "        [ 0.6637,  1.0000,  0.9187,  ...,  0.7836, -0.4919, -0.7002],\n",
            "        [ 0.5972,  1.0000,  0.9266,  ...,  0.7475, -0.3259, -0.6566],\n",
            "        ...,\n",
            "        [ 0.5851,  1.0000,  0.9140,  ...,  0.6733, -0.5826, -0.6306],\n",
            "        [ 0.3467,  1.0000,  0.9013,  ...,  0.5920, -0.0823, -0.9274],\n",
            "        [ 0.6585,  1.0000,  0.7310,  ..., -0.3276,  0.3421, -0.9387]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6364,  1.0000,  0.9135,  ...,  0.8316, -0.5743, -0.6617],\n",
            "        [-0.0953,  1.0000, -0.7242,  ..., -0.8592,  0.2909, -0.4110],\n",
            "        [-0.5924,  0.9990, -0.1143,  ..., -0.8324,  0.2900, -0.7738],\n",
            "        ...,\n",
            "        [ 0.4701,  1.0000,  0.9349,  ...,  0.6034,  0.3529, -0.7930],\n",
            "        [-0.3701,  0.9999, -0.7216,  ..., -0.9075,  0.6584, -0.3866],\n",
            "        [ 0.5615,  1.0000,  0.9047,  ...,  0.7156, -0.5348, -0.6202]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1139,  0.9998, -0.8639,  ..., -0.9010,  0.3132, -0.3461],\n",
            "        [ 0.5841,  1.0000,  0.8307,  ..., -0.4075,  0.0155, -0.9614],\n",
            "        [ 0.4835,  1.0000,  0.8999,  ...,  0.6479, -0.5423, -0.6558],\n",
            "        ...,\n",
            "        [ 0.6390,  1.0000,  0.8471,  ...,  0.6631, -0.6110, -0.7099],\n",
            "        [ 0.5564,  1.0000,  0.8589,  ...,  0.5729, -0.3529, -0.6454],\n",
            "        [ 0.7315,  1.0000,  0.9487,  ...,  0.8465, -0.0697, -0.8817]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1359,  1.0000, -0.7730,  ..., -0.8949,  0.4816, -0.4444],\n",
            "        [-0.1431,  0.9999, -0.8259,  ..., -0.9470,  0.4369, -0.4012],\n",
            "        [-0.4736,  0.9998, -0.9209,  ..., -0.9583,  0.1360, -0.2417],\n",
            "        ...,\n",
            "        [ 0.6950,  1.0000,  0.8943,  ...,  0.3899,  0.0758, -0.9260],\n",
            "        [ 0.6750,  1.0000, -0.1314,  ..., -0.6661,  0.4623, -0.9300],\n",
            "        [ 0.6357,  1.0000,  0.9308,  ...,  0.7560, -0.5049, -0.6884]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3818,  1.0000,  0.7239,  ...,  0.4306,  0.7484, -0.8537],\n",
            "        [-0.1113,  1.0000, -0.8820,  ..., -0.9198,  0.3732, -0.3461],\n",
            "        [-0.2030,  1.0000,  0.0669,  ..., -0.8733,  0.4728, -0.9098],\n",
            "        ...,\n",
            "        [ 0.1535,  1.0000, -0.3954,  ..., -0.8731,  0.5329, -0.8746],\n",
            "        [ 0.5695,  1.0000,  0.7889,  ..., -0.3685,  0.1508, -0.9226],\n",
            "        [-0.0116,  1.0000, -0.3821,  ..., -0.9318,  0.5531, -0.8143]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0038,  0.9999, -0.7199,  ..., -0.6069,  0.6414, -0.0228],\n",
            "        [ 0.5373,  1.0000,  0.8683,  ...,  0.2536, -0.2714, -0.9064],\n",
            "        [-0.3229,  0.8708, -0.7806,  ..., -0.9240,  0.4702, -0.0115],\n",
            "        ...,\n",
            "        [-0.6463,  1.0000, -0.8817,  ..., -0.8331,  0.5812, -0.3952],\n",
            "        [ 0.0882,  1.0000, -0.8009,  ..., -0.8812,  0.4944, -0.5821],\n",
            "        [-0.4475,  1.0000, -0.4128,  ..., -0.7808,  0.4747, -0.8624]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7161,  1.0000,  0.8865,  ...,  0.0270, -0.3719, -0.8331],\n",
            "        [ 0.6442,  1.0000,  0.8568,  ...,  0.0626, -0.2420, -0.9206],\n",
            "        [-0.2760,  0.9982, -0.8961,  ..., -0.8617,  0.1060,  0.0785],\n",
            "        ...,\n",
            "        [ 0.4964,  1.0000,  0.5220,  ..., -0.5396, -0.2951, -0.9118],\n",
            "        [-0.0221,  1.0000,  0.3542,  ..., -0.5975,  0.6395, -0.8348],\n",
            "        [ 0.0863,  1.0000,  0.2551,  ..., -0.0618, -0.2925, -0.9228]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3841,  1.0000,  0.4836, -0.9875, -0.0282,  0.9234,  0.8226,  0.8255,\n",
            "         -0.9986, -0.7708,  0.7922, -0.6373,  0.2191,  0.9998, -0.1371,  0.0812,\n",
            "          0.9148, -0.9916,  0.9062, -0.8211,  0.6097, -0.5501,  0.9247, -0.6406,\n",
            "          0.8345,  0.6856, -0.2291,  0.8642, -0.5094,  0.3662, -0.6822, -0.6364,\n",
            "          0.9715,  0.7745,  0.9185, -0.9728, -0.4853, -0.9749, -0.9976, -0.9993,\n",
            "         -0.6437, -0.6269,  0.9998, -0.8676,  0.9982, -0.9954,  0.1839, -0.3986,\n",
            "          0.8524,  0.5590, -0.9157,  0.8246,  0.8802,  0.8720, -0.6957, -0.9590,\n",
            "         -0.9073,  0.7814, -0.9756, -0.2928,  0.9244,  0.4921, -0.5547, -0.1243,\n",
            "         -0.8723, -0.0626,  0.6686,  0.7401, -0.8222, -0.9816,  0.9041, -0.9544,\n",
            "          0.8825, -0.3513, -0.1876,  0.9357, -0.9013,  0.7921, -0.8663,  0.9946,\n",
            "          0.5530,  0.7219,  0.8394, -1.0000,  0.7874, -0.9281,  0.9937, -0.9947,\n",
            "         -0.9892,  0.8610,  0.7591,  0.7818,  0.7398, -0.4415, -0.7471, -0.8192,\n",
            "         -0.7308,  0.7332, -0.9997,  0.8894,  0.8756,  0.9330, -0.5945, -0.7890,\n",
            "         -0.9999,  0.3288, -0.7540, -0.7672, -1.0000, -0.8316, -0.8402, -0.9002,\n",
            "         -0.6168,  0.9685,  0.5244,  0.9999,  0.8460,  0.9988, -1.0000, -0.9931,\n",
            "          0.6332,  0.9620, -0.7816, -0.5992,  0.5947, -0.9919, -0.2818, -0.9992,\n",
            "          0.9162, -0.9785, -0.7147,  0.8074,  0.9152, -0.2796, -0.7864,  0.6156,\n",
            "         -0.9999,  0.4035, -0.8862, -0.9980,  0.9970,  0.9603,  0.8384, -0.7608,\n",
            "         -0.4876,  0.9520,  0.9294, -0.7262, -0.1972, -0.3693, -0.8499,  0.8931,\n",
            "          0.4063, -0.6865, -1.0000,  0.6724, -0.1443,  0.9721, -0.9810,  0.9895,\n",
            "         -0.9794, -1.0000,  0.7989,  0.5054, -0.6781,  0.9037, -0.8994,  0.9181,\n",
            "         -0.7405,  0.8635,  0.8879,  0.8609,  0.3551,  0.0069,  0.7398, -0.8597,\n",
            "          0.6466, -0.8395, -0.5763, -0.9865,  0.9876, -0.7951,  0.9758, -0.9422,\n",
            "         -0.6574,  0.6079,  0.0557, -1.0000,  0.9335,  0.4346,  0.7025,  0.0544,\n",
            "          0.5931, -0.5923,  0.5500, -0.2406, -0.8133,  0.9233, -0.3794,  0.9660,\n",
            "          0.7936, -0.9996,  0.9529,  0.9984,  0.3548, -0.8571, -0.1123,  0.9950,\n",
            "         -0.9990, -0.8093,  0.3627, -0.7447,  0.7988,  0.3599, -0.6714, -0.7765,\n",
            "          0.9116,  0.2977,  0.5104, -0.3230,  0.3887,  0.6868, -0.6718,  0.7005,\n",
            "          0.9345,  0.9994, -0.7843, -0.5563,  0.5228, -0.9998,  0.9265,  0.4790,\n",
            "         -0.0789, -0.8008,  0.9969,  0.9285,  0.7778,  0.9820, -0.9693, -0.5587,\n",
            "         -0.5352,  0.7258,  0.2109,  0.0343,  1.0000, -0.9985,  0.9888,  0.8463,\n",
            "          0.2130, -0.2330,  0.3685,  0.1713,  0.2387,  0.3022, -0.5904,  0.9958,\n",
            "         -0.8832, -0.9948,  0.4756,  0.4242, -0.9681, -0.8749,  0.6108, -0.8158,\n",
            "          0.9935,  1.0000,  0.5623,  0.5791,  0.8140,  0.8751,  0.9016, -0.9882,\n",
            "          0.9842,  1.0000, -0.9646,  0.1461,  1.0000,  0.8172, -0.6621, -0.4722,\n",
            "          0.5801, -0.9833, -0.2363, -0.4335, -0.0697, -0.2349,  0.1846, -0.9749,\n",
            "         -0.9998, -0.9970,  0.9911, -0.7839, -0.6202,  0.8285, -0.6738, -0.6554,\n",
            "         -0.4418,  0.9959, -0.9154,  1.0000,  0.8320, -0.7855, -0.9785, -0.4196,\n",
            "          0.8197,  0.2779,  0.9995,  0.3583, -0.8724,  0.8901,  0.7164,  0.3322,\n",
            "          0.9254, -0.5780,  0.6789,  0.1297,  0.5145, -0.9826, -0.3540, -0.9277,\n",
            "          0.9578,  0.9889,  0.8017, -0.6499,  0.9799,  0.9017, -1.0000,  0.9997,\n",
            "          0.9865, -0.9969,  0.8780, -0.2312,  0.9301,  0.0703,  0.8490, -0.9319,\n",
            "         -0.9195, -0.9928,  0.9074,  0.5164, -0.6524,  0.7129, -0.9356,  0.8987,\n",
            "          0.2420,  0.7295,  0.1376, -0.5549, -0.9992,  0.7938,  0.8834,  0.3091,\n",
            "          0.8114,  0.9901,  0.3464,  1.0000, -0.8234,  0.7623, -0.3221,  0.8424,\n",
            "          0.4807,  0.7779, -0.1461, -0.0942, -1.0000,  0.0972, -0.6123,  0.3971,\n",
            "          0.5304, -0.9915,  0.0523, -0.3971, -0.4579, -0.0552,  0.3792,  0.6268,\n",
            "          0.9998,  0.6230, -0.2221, -0.7118, -0.4756,  0.3434,  0.9596,  0.9436,\n",
            "          0.9967, -0.8859,  0.3396,  0.8225,  0.1622, -0.7824,  0.1816,  0.6129,\n",
            "          0.4585,  0.9676,  0.8941,  0.1127, -0.6814,  0.8807, -0.9986,  1.0000,\n",
            "          0.5643,  0.6305,  0.9735, -0.1731,  0.9290, -0.2643,  0.6418, -0.8354,\n",
            "          0.9923,  0.7047,  0.7367,  0.3892,  0.6259, -0.4480, -0.8335,  0.9003,\n",
            "          0.3040, -0.7683, -0.9781,  0.9861, -0.9914,  0.2985, -0.6909,  0.7819,\n",
            "          0.9877, -0.6995, -0.8574, -0.8135, -0.3218, -0.9546, -0.9626, -0.9978,\n",
            "         -0.0906, -0.9747,  1.0000, -0.9952,  0.7377, -0.9295, -0.8732,  0.8335,\n",
            "          0.0938, -0.6346, -0.7982, -0.0484, -0.6656,  0.9196, -0.0492,  0.8032,\n",
            "         -0.3244,  0.3280,  0.6630,  0.4929,  0.4531,  0.9078, -0.7853, -0.9922,\n",
            "         -0.8849, -0.8015, -0.6183,  0.9772, -0.9820, -0.6165,  1.0000, -0.9945,\n",
            "          0.2026, -0.2550, -0.9988,  0.5780, -0.8962, -0.9854, -0.8400, -0.7844,\n",
            "          0.8999,  0.9513,  0.9997,  0.0973, -0.3021, -0.9859, -0.7667,  0.9962,\n",
            "         -0.9903, -0.0415,  0.0238, -0.9987,  0.9271,  0.7324, -0.5406,  0.9139,\n",
            "         -0.8220,  0.9846,  0.1104, -0.9979,  0.8319,  0.8822,  0.1446,  0.8927,\n",
            "         -0.3925, -0.1191, -0.9783,  0.6271,  0.9999,  0.1050, -0.9578,  0.7007,\n",
            "          0.9143,  0.8191,  1.0000, -0.9725,  0.8372,  0.9999, -0.5092,  0.6970,\n",
            "         -0.1044, -0.7939, -0.0726,  0.7622, -0.9907,  0.9999, -0.4956, -0.9881,\n",
            "         -1.0000,  0.6488, -0.8555,  0.8060,  0.9693,  0.2114,  0.9146,  0.6538,\n",
            "         -0.9977,  0.7232, -0.8709, -1.0000, -0.9999,  0.8774, -0.0532, -0.0266,\n",
            "          0.8109, -0.5046, -0.8527,  0.9999,  0.9179, -1.0000, -0.7226,  0.4968,\n",
            "          0.9721, -0.8394,  0.8222,  0.1287,  0.2016, -0.3475, -1.0000, -0.8391,\n",
            "          0.9955, -0.4100,  0.2235,  0.9998,  0.8060, -0.0540, -0.9771,  0.6090,\n",
            "          0.9048, -1.0000, -0.8020,  0.9999, -0.7654, -0.5351, -0.8790,  0.2587,\n",
            "          0.7033,  0.7973,  0.6910, -0.9989,  0.9983,  0.9323, -0.6760,  0.9982,\n",
            "         -0.2582, -0.8223, -0.9026, -0.7687,  0.9109, -0.7137,  0.8290, -0.7141,\n",
            "          0.9934,  0.9334, -0.7139,  0.9161,  0.9129, -0.8340, -0.6360,  0.9565,\n",
            "          0.8243,  0.1289,  0.9896, -0.2157, -0.8213, -0.1875,  0.7985,  0.9566,\n",
            "         -1.0000,  0.9383, -0.6371, -0.9482,  0.7749, -0.4941, -0.8953, -0.2333,\n",
            "          0.2844, -0.8290,  0.4867,  0.9634,  0.9286,  0.9218, -0.9920, -1.0000,\n",
            "         -0.7176, -0.6360, -0.8684, -0.2828, -0.0993,  0.9897,  0.6230,  0.5871,\n",
            "          0.6693,  1.0000, -0.5694,  0.9886, -0.9197,  0.9669, -0.9938,  0.8180,\n",
            "          0.4367, -0.9925, -0.8816,  0.9501, -0.7835,  0.8686, -0.9626,  0.8972,\n",
            "          1.0000, -0.7759, -0.2484,  0.8584, -0.9109,  0.8690, -0.2967,  0.9979,\n",
            "         -1.0000,  0.9898,  0.5814,  0.5837,  0.7021,  0.6943,  0.4445, -0.6952,\n",
            "         -0.8365, -0.9920, -0.0119,  0.5730, -0.7597,  0.5373,  0.9832, -0.9332,\n",
            "         -0.9997, -0.6747,  0.2982,  0.9280, -0.5470, -0.9928,  0.9656, -0.4676,\n",
            "          0.9900, -0.1273, -0.8397, -0.6849, -0.6916, -0.7184,  0.8024,  0.8823,\n",
            "          0.9485,  0.4982, -0.7579, -0.6734, -0.5508, -0.8938,  0.9002,  0.2875,\n",
            "          0.5509,  0.7518,  0.8801,  0.9894,  0.4594, -0.1400,  0.7941, -0.7331,\n",
            "         -0.6817, -0.9999,  0.9997,  0.9260, -0.9028, -0.9999,  0.9541,  0.7096,\n",
            "         -0.5996,  0.8778, -0.5529, -0.9457, -0.2231,  0.9595, -1.0000, -0.6251,\n",
            "          0.6076, -0.4997, -0.3096, -0.9999, -0.4425,  0.4642, -0.4075,  0.4348,\n",
            "          0.9995, -0.3632, -0.9932, -0.9755, -0.3341,  0.7944,  0.4474, -0.9939,\n",
            "         -0.6574,  0.9505, -0.9992,  0.4281, -0.8545, -0.6309,  0.4824,  0.6860,\n",
            "          0.9493, -1.0000,  0.9509, -0.8740,  0.9310, -0.5092,  0.4411,  0.8526,\n",
            "          0.8226, -0.9996,  0.9502,  0.3150,  0.8856,  0.8149,  0.9135, -0.1774,\n",
            "         -0.9476, -0.8100,  0.9888,  0.9892, -0.6604,  0.9197,  0.9997, -0.6981,\n",
            "          0.7699,  0.5809, -0.3428, -0.9995, -0.8282, -0.5722, -0.4276, -0.9261]],\n",
            "       device='cuda:0')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training... :   0%|          | 0/127 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9aed995118b443409667bc495b4e25df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4234,  1.0000, -0.8079,  ..., -0.8953,  0.4403, -0.5166],\n",
            "        [ 0.6646,  0.9998,  0.9233,  ...,  0.6683, -0.6931, -0.5730],\n",
            "        [ 0.6604,  0.9997,  0.8965,  ...,  0.6125, -0.6687, -0.6399],\n",
            "        ...,\n",
            "        [ 0.3550,  1.0000,  0.7044,  ...,  0.3481, -0.3726, -0.8455],\n",
            "        [ 0.7545,  1.0000,  0.2608,  ..., -0.7127,  0.6819, -0.9128],\n",
            "        [ 0.4838,  1.0000,  0.8839,  ...,  0.6986, -0.5635, -0.6675]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3568,  0.9973, -0.8341,  ..., -0.9324,  0.3338, -0.0544],\n",
            "        [ 0.5135,  1.0000,  0.9249,  ...,  0.6463,  0.0649, -0.8398],\n",
            "        [-0.1101,  0.9996, -0.8127,  ..., -0.9435,  0.4677, -0.5314],\n",
            "        ...,\n",
            "        [ 0.7438,  1.0000,  0.1121,  ..., -0.8969,  0.7412, -0.9388],\n",
            "        [ 0.7045,  1.0000,  0.8691,  ...,  0.6785, -0.4458, -0.6999],\n",
            "        [ 0.5403,  1.0000,  0.7609,  ...,  0.4566, -0.2978, -0.8289]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0077,  1.0000, -0.7461,  ..., -0.9212,  0.5579, -0.5040],\n",
            "        [ 0.4612,  0.9998,  0.8588,  ...,  0.4336,  0.0837, -0.7498],\n",
            "        [ 0.3115,  0.9998,  0.9156,  ...,  0.6664, -0.7150, -0.4736],\n",
            "        ...,\n",
            "        [ 0.1711,  1.0000,  0.8335,  ..., -0.3573,  0.2429, -0.6982],\n",
            "        [ 0.6912,  1.0000,  0.8933,  ...,  0.8059, -0.6189, -0.6399],\n",
            "        [ 0.7283,  1.0000,  0.8429,  ...,  0.7762, -0.6287, -0.5761]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5105,  1.0000,  0.8627,  ...,  0.6854, -0.5080, -0.7079],\n",
            "        [ 0.0886,  1.0000,  0.7209,  ...,  0.0478,  0.3919, -0.7415],\n",
            "        [ 0.5985,  1.0000,  0.8526,  ...,  0.7558,  0.2293, -0.7160],\n",
            "        ...,\n",
            "        [-0.2906,  1.0000, -0.8031,  ..., -0.8854,  0.1629, -0.4821],\n",
            "        [ 0.5704,  1.0000,  0.8696,  ...,  0.6505, -0.5531, -0.6818],\n",
            "        [-0.3475,  0.9967, -0.9014,  ..., -0.9615,  0.2171, -0.1284]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1688,  0.9989, -0.8802,  ..., -0.9008,  0.1470, -0.1577],\n",
            "        [ 0.5987,  1.0000,  0.9340,  ...,  0.5947, -0.2362, -0.7848],\n",
            "        [-0.2895,  0.9987, -0.8558,  ..., -0.9236,  0.1269,  0.0014],\n",
            "        ...,\n",
            "        [ 0.3687,  1.0000,  0.8820,  ...,  0.1180, -0.0304, -0.9228],\n",
            "        [ 0.6891,  1.0000,  0.8935,  ...,  0.6420, -0.3346, -0.6974],\n",
            "        [ 0.5352,  1.0000,  0.8881,  ...,  0.6126, -0.4255, -0.7736]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5002,  0.9999,  0.8605,  ...,  0.4433, -0.2914, -0.7441],\n",
            "        [ 0.5577,  1.0000,  0.8942,  ...,  0.5155, -0.3089, -0.7961],\n",
            "        [-0.0589,  0.9993, -0.2853,  ..., -0.6366,  0.1346, -0.7572],\n",
            "        ...,\n",
            "        [ 0.7091,  1.0000,  0.8352,  ...,  0.3589, -0.4860, -0.6335],\n",
            "        [-0.3649,  1.0000, -0.2733,  ..., -0.8412,  0.5410, -0.7099],\n",
            "        [-0.3243,  0.9994, -0.8716,  ..., -0.9256,  0.5940, -0.2346]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4965,  0.9998, -0.7320,  ..., -0.8429,  0.1953, -0.0885],\n",
            "        [ 0.3892,  1.0000,  0.8699,  ...,  0.3095,  0.1358, -0.7261],\n",
            "        [ 0.4904,  1.0000,  0.8820,  ...,  0.5556, -0.4276, -0.7064],\n",
            "        ...,\n",
            "        [ 0.5996,  1.0000,  0.8990,  ...,  0.6956, -0.5953, -0.4861],\n",
            "        [ 0.6719,  1.0000,  0.8275,  ...,  0.7581, -0.1953, -0.6637],\n",
            "        [-0.1460,  0.9996, -0.8688,  ..., -0.9321,  0.5075, -0.4009]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2464,  1.0000, -0.6234,  ..., -0.9186,  0.6376, -0.7141],\n",
            "        [ 0.6659,  1.0000,  0.9328,  ...,  0.7613, -0.6259, -0.7414],\n",
            "        [ 0.6113,  1.0000,  0.8863,  ...,  0.7669, -0.5679, -0.5730],\n",
            "        ...,\n",
            "        [-0.5147,  0.9998, -0.8658,  ..., -0.9095,  0.4338, -0.3376],\n",
            "        [-0.3519,  0.9990, -0.9037,  ..., -0.8949,  0.1134, -0.3265],\n",
            "        [-0.1304,  0.9997, -0.8173,  ..., -0.9243,  0.5525, -0.6859]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6438,  1.0000, -0.4982,  ..., -0.7301, -0.2481,  0.3031],\n",
            "        [ 0.4802,  1.0000,  0.7497,  ...,  0.0828,  0.1006, -0.9263],\n",
            "        [ 0.0835,  0.9999, -0.8312,  ..., -0.9512,  0.3629, -0.5935],\n",
            "        ...,\n",
            "        [-0.2228,  0.9990, -0.9322,  ..., -0.9299,  0.5106, -0.1810],\n",
            "        [ 0.4148,  1.0000,  0.8510,  ...,  0.3680, -0.4053, -0.5781],\n",
            "        [-0.1823,  0.9997, -0.8825,  ..., -0.9106,  0.2060, -0.1468]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5808,  0.9998,  0.8875,  ...,  0.4571, -0.5817, -0.4438],\n",
            "        [-0.1430,  0.9999, -0.6953,  ..., -0.8935,  0.7274, -0.4227],\n",
            "        [ 0.8468,  1.0000,  0.9528,  ...,  0.1874,  0.3627, -0.9574],\n",
            "        ...,\n",
            "        [ 0.2075,  1.0000,  0.5389,  ..., -0.7209,  0.7314, -0.9499],\n",
            "        [ 0.3680,  0.9999,  0.8512,  ...,  0.7704, -0.4360, -0.5024],\n",
            "        [ 0.7706,  1.0000,  0.9182,  ...,  0.7368, -0.4480, -0.7604]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3690,  0.6895, -0.8962,  ..., -0.9331,  0.2919,  0.2287],\n",
            "        [ 0.7511,  1.0000,  0.8242,  ...,  0.4943, -0.3516, -0.4225],\n",
            "        [-0.2626,  0.9995, -0.6266,  ..., -0.6034, -0.1011, -0.9089],\n",
            "        ...,\n",
            "        [ 0.3202,  0.9996,  0.6131,  ..., -0.3749,  0.3159, -0.9445],\n",
            "        [ 0.7280,  1.0000,  0.8891,  ...,  0.4022, -0.3200, -0.8679],\n",
            "        [ 0.1083,  1.0000,  0.7919,  ...,  0.1928, -0.1635, -0.9058]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0477,  0.9986, -0.8797,  ..., -0.9410,  0.4192, -0.2694],\n",
            "        [ 0.2982,  1.0000,  0.8174,  ..., -0.2139,  0.2382, -0.7069],\n",
            "        [-0.1517,  0.9997, -0.8088,  ..., -0.8631,  0.6149, -0.2909],\n",
            "        ...,\n",
            "        [ 0.5054,  0.9999,  0.8616,  ...,  0.5841, -0.0207, -0.6046],\n",
            "        [ 0.6937,  1.0000,  0.8406,  ...,  0.5338, -0.5060, -0.7515],\n",
            "        [ 0.7204,  1.0000,  0.8310,  ...,  0.7744, -0.2613, -0.6066]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5590,  1.0000,  0.8431,  ...,  0.7060, -0.5824, -0.5415],\n",
            "        [ 0.4048,  1.0000, -0.7845,  ..., -0.9199,  0.2064, -0.2455],\n",
            "        [-0.4620,  0.9987, -0.8464,  ..., -0.8788,  0.3501,  0.2206],\n",
            "        ...,\n",
            "        [ 0.5946,  1.0000,  0.8823,  ...,  0.6322, -0.7188, -0.5961],\n",
            "        [ 0.7058,  1.0000,  0.8382,  ..., -0.0753, -0.2134, -0.8781],\n",
            "        [ 0.5792,  1.0000,  0.8573,  ...,  0.7274, -0.3613, -0.7098]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4004,  1.0000,  0.6913,  ..., -0.0624, -0.1581, -0.9422],\n",
            "        [ 0.0800,  1.0000,  0.4413,  ..., -0.6081,  0.3913, -0.8372],\n",
            "        [-0.2754,  0.9634, -0.9299,  ..., -0.9423,  0.2380, -0.0495],\n",
            "        ...,\n",
            "        [ 0.6742,  1.0000,  0.9041,  ...,  0.7661, -0.5357, -0.6640],\n",
            "        [-0.2583,  0.9999, -0.7116,  ..., -0.9273,  0.5014, -0.4496],\n",
            "        [ 0.5840,  1.0000,  0.8560,  ...,  0.6367, -0.4999, -0.6693]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5379,  1.0000,  0.7907,  ...,  0.6452, -0.4147, -0.7002],\n",
            "        [-0.1968,  0.9996, -0.8403,  ..., -0.8976,  0.2645, -0.4247],\n",
            "        [ 0.5172,  1.0000,  0.8022,  ...,  0.7212, -0.5939, -0.5212],\n",
            "        ...,\n",
            "        [-0.2050,  0.9969, -0.8640,  ..., -0.9087,  0.4223,  0.3454],\n",
            "        [ 0.1097,  1.0000, -0.3566,  ..., -0.7791,  0.8520, -0.9422],\n",
            "        [ 0.3103,  0.9998,  0.8845,  ...,  0.7056, -0.5148, -0.6537]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5415,  1.0000,  0.7314,  ...,  0.7922, -0.1316, -0.6841],\n",
            "        [-0.4593,  0.9996, -0.8874,  ..., -0.9300,  0.0875, -0.1430],\n",
            "        [ 0.5362,  0.9999,  0.9113,  ...,  0.5084, -0.5773, -0.4708],\n",
            "        ...,\n",
            "        [-0.2871,  0.9982, -0.8085,  ..., -0.9085,  0.7718, -0.3492],\n",
            "        [-0.1330,  0.9888, -0.9229,  ..., -0.8775,  0.3252,  0.2599],\n",
            "        [-0.3232,  0.9979, -0.8113,  ..., -0.8574,  0.2930,  0.0436]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4244,  1.0000, -0.7618,  ..., -0.8275,  0.5852, -0.6351],\n",
            "        [ 0.0654,  0.9999, -0.8064,  ..., -0.8876,  0.5321, -0.5159],\n",
            "        [ 0.5303,  1.0000,  0.8686,  ...,  0.7397, -0.7372, -0.5012],\n",
            "        ...,\n",
            "        [ 0.7981,  0.9999,  0.9150,  ..., -0.3249,  0.1698, -0.8879],\n",
            "        [ 0.5456,  1.0000,  0.9032,  ...,  0.8321, -0.7065, -0.7287],\n",
            "        [ 0.0932,  1.0000,  0.7081,  ...,  0.1798,  0.4596, -0.8318]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2665,  1.0000, -0.3176,  ..., -0.7603,  0.7156, -0.8795],\n",
            "        [-0.1765,  1.0000, -0.6389,  ..., -0.7886,  0.5204, -0.8381],\n",
            "        [ 0.2545,  0.9983,  0.8798,  ...,  0.5452, -0.6594, -0.2830],\n",
            "        ...,\n",
            "        [ 0.1560,  1.0000,  0.4783,  ..., -0.7456,  0.4591, -0.9659],\n",
            "        [ 0.2336,  0.9991,  0.9292,  ...,  0.5760, -0.5974, -0.5592],\n",
            "        [ 0.5475,  1.0000,  0.9449,  ...,  0.6229, -0.5201, -0.7556]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4839,  1.0000,  0.8863,  ...,  0.7202, -0.3487, -0.6411],\n",
            "        [ 0.4829,  1.0000,  0.8463,  ...,  0.7353, -0.6777, -0.5019],\n",
            "        [-0.5086,  0.9922, -0.7997,  ..., -0.8952,  0.1299,  0.1889],\n",
            "        ...,\n",
            "        [ 0.5999,  1.0000,  0.8844,  ...,  0.1707, -0.2813, -0.7459],\n",
            "        [ 0.6532,  1.0000,  0.7619,  ...,  0.0377, -0.2568, -0.8856],\n",
            "        [ 0.6756,  1.0000,  0.8278,  ...,  0.3833, -0.3624, -0.3846]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2070,  0.9993, -0.8412,  ..., -0.8649,  0.1731, -0.1765],\n",
            "        [ 0.6162,  1.0000,  0.8913,  ...,  0.8246, -0.3411, -0.5793],\n",
            "        [ 0.5313,  0.9999,  0.9380,  ...,  0.7160, -0.4510, -0.4278],\n",
            "        ...,\n",
            "        [ 0.1092,  0.9997, -0.2394,  ..., -0.7429,  0.2413, -0.8012],\n",
            "        [ 0.0340,  1.0000, -0.3231,  ..., -0.5809,  0.5064, -0.8381],\n",
            "        [ 0.5054,  1.0000,  0.9001,  ...,  0.5895, -0.3537, -0.8194]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5711,  1.0000,  0.8296,  ...,  0.8153, -0.6183, -0.5157],\n",
            "        [ 0.3968,  0.9999,  0.8244,  ...,  0.7021, -0.5287, -0.5336],\n",
            "        [ 0.5360,  1.0000,  0.8538,  ...,  0.7362, -0.3692, -0.6501],\n",
            "        ...,\n",
            "        [-0.2622,  0.9827, -0.8752,  ..., -0.9103,  0.3751, -0.1843],\n",
            "        [-0.3292,  0.9977, -0.8414,  ..., -0.9532,  0.0041,  0.1124],\n",
            "        [ 0.3839,  0.9999,  0.8815,  ...,  0.8143, -0.5846, -0.3704]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5736,  0.9997, -0.8505,  ..., -0.9067,  0.6543, -0.3942],\n",
            "        [-0.5932,  0.9987, -0.8602,  ..., -0.9196,  0.0467, -0.2195],\n",
            "        [ 0.4687,  1.0000,  0.8282,  ...,  0.7020, -0.6198, -0.5832],\n",
            "        ...,\n",
            "        [-0.0455,  0.9997, -0.7295,  ..., -0.8488,  0.7813, -0.7567],\n",
            "        [ 0.5042,  0.9999,  0.8641,  ...,  0.7409, -0.5852, -0.3474],\n",
            "        [-0.0707,  1.0000, -0.5392,  ..., -0.6752,  0.4590, -0.8309]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 6.4350e-01,  9.9997e-01,  8.5918e-01,  ...,  5.7305e-01,\n",
            "         -7.1036e-01, -7.2397e-01],\n",
            "        [ 7.0910e-01,  9.9995e-01,  8.9063e-01,  ...,  6.0550e-01,\n",
            "         -6.1276e-01, -6.0259e-01],\n",
            "        [ 6.4473e-01,  1.0000e+00,  8.0236e-04,  ..., -6.9516e-01,\n",
            "          6.8015e-01, -7.9721e-01],\n",
            "        ...,\n",
            "        [ 5.5853e-01,  9.9999e-01,  7.1072e-01,  ...,  7.2790e-01,\n",
            "         -1.5615e-01, -4.4284e-01],\n",
            "        [-2.4050e-01,  9.9998e-01, -6.7803e-01,  ..., -8.4884e-01,\n",
            "          3.0855e-01, -8.4231e-01],\n",
            "        [ 7.1844e-01,  9.9999e-01,  9.0908e-01,  ...,  6.8042e-01,\n",
            "         -3.3183e-01, -7.9567e-01]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1141,  0.9998, -0.7089,  ..., -0.8877,  0.2760,  0.2775],\n",
            "        [ 0.3638,  0.9999,  0.7913,  ...,  0.7333, -0.6644, -0.4628],\n",
            "        [ 0.3788,  1.0000,  0.9336,  ...,  0.4064,  0.1920, -0.9700],\n",
            "        ...,\n",
            "        [-0.2521,  0.9998, -0.5439,  ..., -0.8161,  0.0156, -0.5618],\n",
            "        [ 0.2374,  1.0000,  0.8843,  ...,  0.6557, -0.5632, -0.4098],\n",
            "        [ 0.5300,  1.0000,  0.9316,  ...,  0.7472, -0.5158, -0.5387]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0660,  0.9985,  0.9279,  ...,  0.4106, -0.4853, -0.3653],\n",
            "        [ 0.7015,  1.0000,  0.8296,  ...,  0.8432, -0.6251, -0.6905],\n",
            "        [-0.4442,  0.9769, -0.9360,  ..., -0.9209,  0.0713,  0.4187],\n",
            "        ...,\n",
            "        [-0.2832,  0.9982, -0.7202,  ..., -0.7614,  0.3541, -0.1018],\n",
            "        [ 0.5966,  1.0000,  0.7926,  ...,  0.6108, -0.2660, -0.5170],\n",
            "        [ 0.4630,  0.9998,  0.8655,  ...,  0.7105, -0.4297, -0.4915]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3523,  0.9999, -0.8141,  ..., -0.8901,  0.2596, -0.4393],\n",
            "        [ 0.5527,  1.0000,  0.9001,  ...,  0.7571, -0.6143, -0.5577],\n",
            "        [ 0.5731,  1.0000,  0.8552,  ...,  0.6013, -0.6563, -0.5744],\n",
            "        ...,\n",
            "        [-0.3074,  1.0000, -0.3097,  ..., -0.6895, -0.0555, -0.8572],\n",
            "        [ 0.6286,  1.0000,  0.8600,  ...,  0.5666, -0.4408, -0.8259],\n",
            "        [ 0.0667,  0.9999, -0.6498,  ..., -0.8811,  0.5105, -0.4139]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4650,  0.9981, -0.9001,  ..., -0.8706,  0.3711,  0.1717],\n",
            "        [ 0.6604,  1.0000,  0.8915,  ...,  0.8771, -0.5454, -0.7433],\n",
            "        [ 0.5222,  1.0000,  0.8723,  ...,  0.5987, -0.2352, -0.8930],\n",
            "        ...,\n",
            "        [ 0.4855,  1.0000,  0.8356,  ..., -0.5040, -0.2086, -0.8981],\n",
            "        [-0.4673,  0.9993, -0.8759,  ..., -0.9364,  0.0320,  0.0716],\n",
            "        [-0.2890,  1.0000, -0.6660,  ..., -0.8557,  0.2181, -0.3843]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4283,  0.9999, -0.1232,  ..., -0.6301, -0.1714, -0.7821],\n",
            "        [-0.3658,  0.9999, -0.7456,  ..., -0.8820,  0.2684, -0.1261],\n",
            "        [-0.1156,  1.0000, -0.2447,  ..., -0.6877, -0.0157, -0.7284],\n",
            "        ...,\n",
            "        [ 0.5868,  0.9999,  0.8828,  ...,  0.8929, -0.5984, -0.1959],\n",
            "        [-0.2856,  1.0000, -0.7447,  ..., -0.7308,  0.3282, -0.5299],\n",
            "        [-0.3443,  0.9964, -0.8619,  ..., -0.8201,  0.0916,  0.2148]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3208,  0.9975,  0.8464,  ...,  0.6918, -0.6311, -0.4711],\n",
            "        [ 0.4816,  1.0000,  0.7818,  ...,  0.6937, -0.0794, -0.7425],\n",
            "        [ 0.5681,  1.0000,  0.8689,  ...,  0.7616, -0.5405, -0.7043],\n",
            "        ...,\n",
            "        [-0.4092,  0.9683, -0.7461,  ..., -0.7965,  0.1992,  0.4317],\n",
            "        [ 0.4689,  0.9999,  0.9350,  ...,  0.7756, -0.5057, -0.6654],\n",
            "        [ 0.5560,  0.9998,  0.8662,  ...,  0.7085, -0.3860, -0.5932]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3647,  0.9998,  0.7823,  ...,  0.3181, -0.5601, -0.6712],\n",
            "        [ 0.6239,  1.0000,  0.8188,  ...,  0.3661, -0.2970, -0.6864],\n",
            "        [-0.0852,  0.9997, -0.8045,  ..., -0.8746,  0.6144, -0.3403],\n",
            "        ...,\n",
            "        [ 0.6468,  1.0000,  0.8427,  ...,  0.8650, -0.5941, -0.5884],\n",
            "        [-0.1030,  0.9979, -0.8639,  ..., -0.9348,  0.5163, -0.0702],\n",
            "        [ 0.6811,  1.0000,  0.9545,  ...,  0.8474, -0.4035, -0.6470]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5371,  0.9939, -0.8615,  ..., -0.9577,  0.1888,  0.3777],\n",
            "        [-0.2905,  0.9999, -0.7369,  ..., -0.9296,  0.3314, -0.3875],\n",
            "        [ 0.8288,  1.0000,  0.8562,  ...,  0.7259, -0.2524, -0.7138],\n",
            "        ...,\n",
            "        [-0.5479,  0.5197, -0.8355,  ..., -0.8985,  0.5492,  0.6578],\n",
            "        [ 0.6829,  1.0000,  0.8837,  ...,  0.8160, -0.6471, -0.5136],\n",
            "        [-0.6424,  0.9931, -0.8439,  ..., -0.8451,  0.2714,  0.0138]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4480,  0.9999,  0.8651,  ...,  0.7769, -0.5237, -0.3804],\n",
            "        [ 0.6084,  1.0000,  0.9044,  ...,  0.8110, -0.6384, -0.4300],\n",
            "        [ 0.1359,  0.9998, -0.3750,  ..., -0.8950,  0.5902, -0.2626],\n",
            "        ...,\n",
            "        [ 0.0756,  1.0000, -0.0949,  ..., -0.6438,  0.6436, -0.9318],\n",
            "        [ 0.4610,  0.9997,  0.9128,  ...,  0.7529, -0.6669, -0.6327],\n",
            "        [ 0.5851,  1.0000,  0.9511,  ...,  0.8140, -0.4181, -0.7333]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2583,  1.0000,  0.8265,  ...,  0.6896, -0.5473, -0.6159],\n",
            "        [ 0.0289,  1.0000, -0.7900,  ..., -0.8378,  0.2857, -0.5690],\n",
            "        [ 0.3143,  1.0000,  0.8984,  ...,  0.6775, -0.4307, -0.6615],\n",
            "        ...,\n",
            "        [ 0.7983,  1.0000,  0.9019,  ...,  0.5136, -0.2116, -0.8511],\n",
            "        [-0.1255,  0.9999, -0.8608,  ..., -0.9085,  0.4202, -0.1193],\n",
            "        [-0.3812,  0.9930, -0.8698,  ..., -0.8978,  0.2536, -0.0106]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1798,  0.9913,  0.2560,  ..., -0.7503, -0.2941, -0.6922],\n",
            "        [ 0.0163,  1.0000, -0.7140,  ..., -0.8829,  0.2152, -0.4911],\n",
            "        [ 0.4551,  1.0000,  0.8483,  ...,  0.7797, -0.4755, -0.7802],\n",
            "        ...,\n",
            "        [-0.5112,  0.9669, -0.8493,  ..., -0.8941,  0.0758, -0.2242],\n",
            "        [ 0.6949,  1.0000,  0.9482,  ...,  0.5891, -0.2911, -0.8797],\n",
            "        [ 0.4310,  0.9999,  0.8781,  ...,  0.8752, -0.5451, -0.5253]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7281,  1.0000,  0.9052,  ...,  0.7499, -0.3914, -0.6657],\n",
            "        [ 0.6978,  1.0000,  0.8294,  ...,  0.7022, -0.5989, -0.6779],\n",
            "        [ 0.5912,  1.0000,  0.8578,  ...,  0.7755, -0.6163, -0.6797],\n",
            "        ...,\n",
            "        [-0.5519,  0.9996, -0.8822,  ..., -0.8851,  0.2008,  0.3240],\n",
            "        [-0.1805,  0.9999, -0.6021,  ..., -0.8089,  0.4363, -0.1634],\n",
            "        [ 0.4326,  1.0000,  0.8998,  ...,  0.8160, -0.5440, -0.5470]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3594,  0.9981, -0.9059,  ..., -0.8869,  0.2388,  0.0141],\n",
            "        [-0.3903,  0.9982, -0.8880,  ..., -0.9123,  0.3900,  0.4842],\n",
            "        [ 0.3948,  1.0000,  0.9049,  ...,  0.3488, -0.1993, -0.8061],\n",
            "        ...,\n",
            "        [ 0.5431,  1.0000,  0.8627,  ...,  0.5526, -0.3638, -0.5228],\n",
            "        [-0.2554,  0.9996, -0.8401,  ..., -0.8727, -0.1433,  0.1866],\n",
            "        [-0.4622,  0.9759, -0.8487,  ..., -0.7911,  0.5584,  0.3080]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2797,  0.9998, -0.6740,  ..., -0.7076,  0.2893, -0.1781],\n",
            "        [ 0.5372,  0.9999,  0.8128,  ...,  0.5392, -0.7774, -0.3751],\n",
            "        [-0.3304,  1.0000, -0.4857,  ..., -0.5947,  0.5496, -0.7777],\n",
            "        ...,\n",
            "        [ 0.4291,  1.0000,  0.9104,  ...,  0.3939, -0.3970, -0.6988],\n",
            "        [ 0.5310,  1.0000,  0.8769,  ...,  0.4436, -0.0947, -0.8629],\n",
            "        [ 0.6008,  1.0000,  0.9357,  ...,  0.3106,  0.0894, -0.7759]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4471,  0.9994,  0.7637,  ...,  0.5755, -0.7552, -0.4926],\n",
            "        [ 0.6255,  1.0000,  0.7863,  ...,  0.6756, -0.4600, -0.3201],\n",
            "        [ 0.5448,  0.9997,  0.9131,  ...,  0.7629, -0.7470, -0.4549],\n",
            "        ...,\n",
            "        [-0.7664,  0.9967, -0.8598,  ..., -0.9019,  0.2108,  0.3099],\n",
            "        [-0.3347,  0.9999, -0.7975,  ..., -0.9205,  0.4521, -0.0765],\n",
            "        [-0.1334,  1.0000, -0.8286,  ..., -0.9102,  0.6088, -0.2541]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2933,  0.9993, -0.8017,  ..., -0.9176,  0.3289, -0.1100],\n",
            "        [-0.5657,  1.0000, -0.8286,  ..., -0.8805,  0.2414, -0.6645],\n",
            "        [ 0.4643,  0.9995,  0.8381,  ...,  0.7816, -0.6322, -0.3073],\n",
            "        ...,\n",
            "        [-0.1958,  0.9995,  0.8397,  ..., -0.5123,  0.1362, -0.8698],\n",
            "        [ 0.5617,  1.0000,  0.7989,  ...,  0.8295, -0.5531, -0.5943],\n",
            "        [ 0.2627,  1.0000,  0.9006,  ...,  0.3247, -0.5855, -0.8003]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3534,  0.9998,  0.9199,  ...,  0.6439, -0.4437, -0.5162],\n",
            "        [ 0.5348,  1.0000,  0.8196,  ...,  0.7162, -0.7109, -0.2755],\n",
            "        [ 0.5200,  1.0000,  0.9608,  ...,  0.4304,  0.0892, -0.9150],\n",
            "        ...,\n",
            "        [-0.5053,  0.9935, -0.8678,  ..., -0.9020,  0.2675,  0.1432],\n",
            "        [ 0.4079,  0.9999,  0.7815,  ...,  0.6982, -0.7163, -0.4572],\n",
            "        [-0.2539,  0.9905, -0.9304,  ..., -0.9394,  0.3600,  0.2534]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5771,  1.0000,  0.9232,  ...,  0.8814, -0.5015, -0.5710],\n",
            "        [-0.4813,  0.9918, -0.8961,  ..., -0.8412,  0.0813,  0.2876],\n",
            "        [ 0.2733,  1.0000, -0.7647,  ..., -0.9097,  0.6905, -0.6129],\n",
            "        ...,\n",
            "        [ 0.3560,  1.0000,  0.9000,  ...,  0.3886, -0.4456, -0.7679],\n",
            "        [ 0.5586,  1.0000,  0.9281,  ...,  0.8293, -0.4434, -0.8041],\n",
            "        [ 0.2331,  1.0000,  0.8740,  ...,  0.5819, -0.4320, -0.4833]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6155,  1.0000,  0.9271,  ...,  0.8794, -0.4711, -0.5452],\n",
            "        [ 0.6864,  1.0000,  0.8835,  ...,  0.6781, -0.2332, -0.8039],\n",
            "        [-0.0118,  0.9624, -0.8711,  ..., -0.8683,  0.1996, -0.1496],\n",
            "        ...,\n",
            "        [ 0.4522,  0.9999, -0.1405,  ..., -0.6331,  0.0532, -0.6579],\n",
            "        [ 0.6481,  0.9996,  0.8490,  ...,  0.5313, -0.4968, -0.6558],\n",
            "        [ 0.5975,  1.0000,  0.9098,  ...,  0.7797, -0.5680, -0.6434]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7140,  1.0000,  0.7859,  ...,  0.7866, -0.5974, -0.5290],\n",
            "        [-0.4455,  1.0000, -0.5292,  ..., -0.9196,  0.2676, -0.7990],\n",
            "        [ 0.2691,  1.0000,  0.9025,  ...,  0.1457, -0.0292, -0.9162],\n",
            "        ...,\n",
            "        [ 0.2567,  0.9997, -0.8815,  ..., -0.9319,  0.6554,  0.1428],\n",
            "        [-0.3584,  0.9984, -0.8875,  ..., -0.8951,  0.3007,  0.1152],\n",
            "        [-0.6060,  0.6972, -0.9399,  ..., -0.8491,  0.3204,  0.5809]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5710,  1.0000,  0.8883,  ...,  0.5879, -0.5699, -0.7188],\n",
            "        [ 0.5092,  1.0000,  0.9370,  ...,  0.7106, -0.2726, -0.9243],\n",
            "        [ 0.4392,  1.0000,  0.8558,  ...,  0.1402, -0.4083, -0.8627],\n",
            "        ...,\n",
            "        [-0.4617,  0.9962, -0.8777,  ..., -0.9308, -0.1734, -0.1068],\n",
            "        [ 0.7188,  1.0000,  0.7035,  ...,  0.7554, -0.2023, -0.8363],\n",
            "        [-0.3882,  0.9805, -0.7565,  ..., -0.8795,  0.5460, -0.4356]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5789,  1.0000,  0.9666,  ...,  0.9057, -0.3011, -0.6338],\n",
            "        [ 0.7147,  1.0000,  0.9118,  ...,  0.7936, -0.5842, -0.4825],\n",
            "        [-0.5821,  0.9997, -0.8140,  ..., -0.9105,  0.7492, -0.3735],\n",
            "        ...,\n",
            "        [ 0.5196,  1.0000,  0.8885,  ...,  0.8981, -0.5351, -0.5362],\n",
            "        [-0.5123,  0.9993, -0.8279,  ..., -0.9115,  0.0010,  0.2357],\n",
            "        [ 0.5421,  1.0000,  0.8821,  ...,  0.7981, -0.2351, -0.5406]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5388,  0.9977, -0.8058,  ..., -0.8353,  0.1188,  0.3899],\n",
            "        [ 0.5795,  0.9999,  0.8465,  ...,  0.8242, -0.7703, -0.5652],\n",
            "        [ 0.3205,  1.0000,  0.9571,  ...,  0.4425, -0.0619, -0.7725],\n",
            "        ...,\n",
            "        [ 0.6604,  1.0000,  0.8619,  ...,  0.8404, -0.4523, -0.6648],\n",
            "        [-0.7068,  0.9997, -0.4558,  ..., -0.9095,  0.1769, -0.3040],\n",
            "        [-0.3783,  0.9999, -0.9178,  ..., -0.8945,  0.3625, -0.2849]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5980,  1.0000,  0.7140,  ...,  0.8033, -0.6378, -0.4313],\n",
            "        [ 0.6655,  0.9999,  0.9036,  ...,  0.8892, -0.6478, -0.5062],\n",
            "        [-0.4440,  0.9967, -0.7587,  ..., -0.8098,  0.5136,  0.0774],\n",
            "        ...,\n",
            "        [-0.5064,  0.9999, -0.8255,  ..., -0.8686,  0.4464, -0.3272],\n",
            "        [ 0.4772,  1.0000,  0.8719,  ...,  0.8477, -0.7319, -0.6000],\n",
            "        [-0.3188,  0.9995, -0.7830,  ..., -0.8851, -0.0099,  0.0755]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0470,  0.9991, -0.8130,  ..., -0.9246, -0.1409, -0.3499],\n",
            "        [ 0.6436,  1.0000,  0.9181,  ...,  0.9159, -0.6385, -0.5174],\n",
            "        [-0.3486,  0.9999, -0.8331,  ..., -0.9012,  0.6917, -0.2591],\n",
            "        ...,\n",
            "        [ 0.5478,  1.0000,  0.8890,  ...,  0.7440, -0.5256, -0.6203],\n",
            "        [ 0.7472,  1.0000,  0.9360,  ...,  0.9030, -0.5879, -0.6629],\n",
            "        [ 0.4360,  0.9999,  0.9336,  ..., -0.1141,  0.0668, -0.7701]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4598,  0.9967, -0.7631,  ..., -0.7773,  0.0952,  0.4711],\n",
            "        [ 0.6267,  1.0000,  0.8677,  ...,  0.8489, -0.5257, -0.5714],\n",
            "        [ 0.4564,  1.0000,  0.8154,  ...,  0.7706, -0.5702, -0.7603],\n",
            "        ...,\n",
            "        [ 0.6933,  0.9999,  0.9247,  ...,  0.7707, -0.5212, -0.7707],\n",
            "        [-0.3934,  0.9969, -0.8014,  ..., -0.7724,  0.3583,  0.4093],\n",
            "        [ 0.1880,  1.0000,  0.1047,  ..., -0.8823,  0.4383, -0.9195]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0542,  1.0000, -0.0627,  ..., -0.9276,  0.1498, -0.7556],\n",
            "        [ 0.4411,  1.0000,  0.9062,  ...,  0.8023, -0.3395, -0.7138],\n",
            "        [ 0.8164,  1.0000,  0.9175,  ...,  0.7538, -0.6076, -0.6216],\n",
            "        ...,\n",
            "        [ 0.6135,  0.9999,  0.8683,  ...,  0.8586, -0.5320, -0.6996],\n",
            "        [ 0.7441,  1.0000,  0.8523,  ...,  0.8088, -0.5581, -0.6583],\n",
            "        [ 0.5305,  1.0000,  0.8993,  ...,  0.8109, -0.2942, -0.6848]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5728,  1.0000, -0.5312,  ..., -0.7320,  0.2490,  0.0711],\n",
            "        [ 0.6125,  1.0000,  0.8533,  ...,  0.8421, -0.4958, -0.4709],\n",
            "        [-0.4158,  1.0000, -0.7455,  ..., -0.8768,  0.5568, -0.6949],\n",
            "        ...,\n",
            "        [-0.2115,  1.0000, -0.7275,  ..., -0.8784,  0.3756, -0.5002],\n",
            "        [ 0.1240,  1.0000, -0.4829,  ..., -0.8491, -0.0041, -0.7387],\n",
            "        [-0.2583,  0.9998, -0.7927,  ..., -0.7808,  0.3040, -0.2037]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3286,  1.0000,  0.8946,  ...,  0.7839, -0.6317, -0.6736],\n",
            "        [ 0.0334,  0.9999, -0.3963,  ..., -0.9201,  0.5792, -0.5267],\n",
            "        [-0.5722,  1.0000, -0.8283,  ..., -0.7537,  0.3961, -0.2032],\n",
            "        ...,\n",
            "        [-0.5573,  1.0000, -0.8382,  ..., -0.8842,  0.5177, -0.2676],\n",
            "        [ 0.5553,  1.0000,  0.8961,  ...,  0.8349, -0.5498, -0.4702],\n",
            "        [ 0.7491,  1.0000,  0.6973,  ...,  0.3258,  0.3334, -0.9095]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6351,  1.0000,  0.9214,  ...,  0.7755, -0.5840, -0.5487],\n",
            "        [ 0.6279,  1.0000,  0.9213,  ...,  0.8130, -0.5371, -0.7185],\n",
            "        [ 0.2876,  0.9999, -0.5767,  ..., -0.7172,  0.6355, -0.5975],\n",
            "        ...,\n",
            "        [ 0.7680,  0.9999,  0.9104,  ...,  0.8323, -0.4559, -0.5420],\n",
            "        [-0.2884,  0.9999, -0.7490,  ..., -0.9404,  0.5650, -0.0799],\n",
            "        [ 0.1685,  1.0000,  0.2567,  ..., -0.7455,  0.2505, -0.8862]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1833,  1.0000, -0.7709,  ..., -0.9055,  0.5407, -0.2202],\n",
            "        [ 0.7513,  1.0000,  0.9363,  ...,  0.8643, -0.4023, -0.7238],\n",
            "        [ 0.6076,  1.0000,  0.8968,  ...,  0.8699, -0.5200, -0.7035],\n",
            "        ...,\n",
            "        [ 0.5601,  1.0000,  0.8926,  ...,  0.8611, -0.4010, -0.7044],\n",
            "        [ 0.5854,  1.0000,  0.9213,  ...,  0.7510, -0.3268, -0.6713],\n",
            "        [-0.0373,  1.0000, -0.5566,  ..., -0.8508,  0.4552, -0.5509]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4172,  1.0000,  0.9313,  ...,  0.8300, -0.4686, -0.6138],\n",
            "        [ 0.4121,  1.0000,  0.9387,  ...,  0.5350, -0.0617, -0.8892],\n",
            "        [ 0.2586,  1.0000,  0.2038,  ..., -0.8403,  0.6871, -0.9652],\n",
            "        ...,\n",
            "        [ 0.2333,  1.0000, -0.0379,  ..., -0.7332,  0.3316, -0.8947],\n",
            "        [-0.6277,  0.9803, -0.8726,  ..., -0.8624, -0.2577,  0.4179],\n",
            "        [ 0.1069,  1.0000, -0.0144,  ..., -0.7021, -0.0373, -0.7849]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7416,  1.0000,  0.9426,  ...,  0.8428, -0.1380, -0.9168],\n",
            "        [-0.2093,  1.0000, -0.8565,  ..., -0.9523,  0.3261, -0.7170],\n",
            "        [ 0.6694,  1.0000,  0.9366,  ...,  0.8110, -0.4838, -0.5527],\n",
            "        ...,\n",
            "        [ 0.7351,  1.0000,  0.9168,  ...,  0.8211, -0.2621, -0.6400],\n",
            "        [-0.0295,  1.0000,  0.0296,  ..., -0.8588,  0.5146, -0.8952],\n",
            "        [ 0.5509,  1.0000,  0.9192,  ...,  0.8161, -0.5849, -0.6131]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6946,  1.0000,  0.9524,  ...,  0.9322, -0.3499, -0.7580],\n",
            "        [ 0.7048,  1.0000,  0.8212,  ...,  0.8652, -0.5883, -0.5122],\n",
            "        [ 0.6486,  1.0000,  0.8808,  ...,  0.8752, -0.4031, -0.6506],\n",
            "        ...,\n",
            "        [ 0.6250,  1.0000,  0.9207,  ...,  0.9063, -0.2164, -0.7629],\n",
            "        [ 0.5562,  0.9999,  0.8835,  ...,  0.8761, -0.3804, -0.3944],\n",
            "        [-0.4888,  0.9979, -0.9043,  ..., -0.9063, -0.1687,  0.0552]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 4.4234e-01,  1.0000e+00,  9.6671e-02,  ..., -5.7824e-01,\n",
            "         -9.4932e-02, -7.6152e-01],\n",
            "        [ 7.4691e-01,  9.9998e-01,  9.0967e-01,  ...,  8.7292e-01,\n",
            "         -4.4068e-01, -7.5452e-01],\n",
            "        [-2.7722e-01,  9.9719e-01, -8.0684e-01,  ..., -9.1625e-01,\n",
            "          5.9068e-01, -5.5512e-01],\n",
            "        ...,\n",
            "        [-7.4191e-02,  1.0000e+00, -1.1593e-02,  ..., -9.3067e-01,\n",
            "         -3.1354e-04, -7.3395e-01],\n",
            "        [ 4.5343e-01,  9.9999e-01,  9.5046e-01,  ...,  6.7145e-01,\n",
            "         -1.7580e-01, -7.2213e-01],\n",
            "        [ 6.3562e-01,  1.0000e+00,  9.4278e-01,  ...,  9.0398e-01,\n",
            "          1.2420e-01, -9.0949e-01]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1760,  0.9988, -0.6141,  ..., -0.8239,  0.2921, -0.5596],\n",
            "        [-0.4227,  1.0000, -0.4548,  ..., -0.8414,  0.6180, -0.4533],\n",
            "        [ 0.5810,  1.0000,  0.9505,  ...,  0.7968, -0.0937, -0.8658],\n",
            "        ...,\n",
            "        [-0.2707,  0.9998, -0.8776,  ..., -0.9345,  0.3393,  0.0046],\n",
            "        [ 0.5939,  1.0000,  0.9439,  ...,  0.8035, -0.2873, -0.7349],\n",
            "        [-0.2152,  0.9996, -0.8824,  ..., -0.9228,  0.1703, -0.2203]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5738,  1.0000,  0.8957,  ...,  0.4689, -0.1894, -0.7085],\n",
            "        [-0.1233,  1.0000, -0.6936,  ..., -0.8575,  0.5395, -0.6397],\n",
            "        [ 0.6446,  1.0000,  0.9437,  ...,  0.8600, -0.5131, -0.7733],\n",
            "        ...,\n",
            "        [ 0.4146,  1.0000,  0.8929,  ...,  0.6926, -0.3458, -0.5399],\n",
            "        [ 0.6621,  1.0000,  0.9415,  ...,  0.6828, -0.2968, -0.7798],\n",
            "        [ 0.6436,  1.0000,  0.9575,  ...,  0.8789,  0.2449, -0.8883]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.8046,  1.0000,  0.8710,  ...,  0.7983, -0.3214, -0.7757],\n",
            "        [-0.6418,  0.9990, -0.8941,  ..., -0.8902,  0.3382,  0.3275],\n",
            "        [-0.4079,  0.9988, -0.8944,  ..., -0.9182,  0.0071,  0.0912],\n",
            "        ...,\n",
            "        [-0.3558,  1.0000, -0.4767,  ..., -0.9281,  0.3970, -0.0874],\n",
            "        [-0.0072,  0.9908, -0.8220,  ..., -0.6617,  0.3410,  0.1848],\n",
            "        [-0.1837,  1.0000, -0.3652,  ..., -0.9488,  0.5281, -0.7692]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5178,  1.0000, -0.4690,  ..., -0.9217, -0.1192, -0.8466],\n",
            "        [-0.4377,  0.9861, -0.8700,  ..., -0.8659,  0.2321,  0.3259],\n",
            "        [-0.2867,  1.0000, -0.6590,  ..., -0.8443,  0.2024, -0.2228],\n",
            "        ...,\n",
            "        [ 0.6774,  1.0000,  0.9506,  ...,  0.8154, -0.4255, -0.4742],\n",
            "        [ 0.5898,  1.0000,  0.9426,  ...,  0.8229, -0.0361, -0.9232],\n",
            "        [-0.0973,  0.9996, -0.8325,  ..., -0.8480,  0.2523,  0.0444]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6846,  1.0000,  0.9354,  ...,  0.8648, -0.3109, -0.6645],\n",
            "        [-0.4657,  1.0000, -0.7492,  ..., -0.8580,  0.2601, -0.5389],\n",
            "        [ 0.4668,  1.0000,  0.9174,  ...,  0.8464, -0.4227, -0.6859],\n",
            "        ...,\n",
            "        [ 0.2716,  1.0000,  0.9396,  ...,  0.8150, -0.3971, -0.7430],\n",
            "        [ 0.3730,  1.0000,  0.3890,  ..., -0.7216,  0.2054, -0.9765],\n",
            "        [ 0.5313,  1.0000,  0.9548,  ...,  0.8749, -0.2551, -0.8209]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6161,  1.0000,  0.9210,  ...,  0.8940,  0.0643, -0.8972],\n",
            "        [ 0.2696,  1.0000, -0.1927,  ..., -0.5597,  0.6589, -0.8735],\n",
            "        [ 0.6185,  1.0000,  0.9092,  ...,  0.8820, -0.4220, -0.8256],\n",
            "        ...,\n",
            "        [ 0.7014,  1.0000,  0.9445,  ...,  0.8030, -0.0652, -0.7651],\n",
            "        [-0.3909,  0.9996, -0.8937,  ..., -0.9172,  0.3828, -0.0081],\n",
            "        [-0.4605,  0.9950, -0.6159,  ..., -0.9011,  0.1833, -0.1142]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5241,  1.0000,  0.8615,  ...,  0.8319,  0.0114, -0.6601],\n",
            "        [ 0.6901,  1.0000,  0.9416,  ...,  0.8542, -0.5167, -0.8400],\n",
            "        [-0.6049,  0.9999, -0.8743,  ..., -0.9154,  0.5071, -0.1668],\n",
            "        ...,\n",
            "        [-0.4856,  0.9988, -0.9100,  ..., -0.9143,  0.3243,  0.3600],\n",
            "        [-0.3993,  1.0000, -0.7200,  ..., -0.8563,  0.4297, -0.6141],\n",
            "        [ 0.7419,  1.0000,  0.8795,  ...,  0.8166,  0.1255, -0.8359]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6720,  1.0000,  0.9518,  ...,  0.8989,  0.2006, -0.9157],\n",
            "        [-0.4385,  0.9984, -0.8083,  ..., -0.9048,  0.0614, -0.0072],\n",
            "        [-0.1015,  0.9977, -0.7125,  ..., -0.8866,  0.1993,  0.3798],\n",
            "        ...,\n",
            "        [ 0.3879,  1.0000,  0.8884,  ...,  0.8078, -0.5468, -0.6690],\n",
            "        [ 0.7366,  1.0000,  0.9669,  ...,  0.8238,  0.1124, -0.9217],\n",
            "        [ 0.7378,  1.0000,  0.9280,  ...,  0.8639, -0.1798, -0.7715]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6710,  1.0000,  0.9104,  ...,  0.8591, -0.4369, -0.7966],\n",
            "        [ 0.3743,  1.0000,  0.9156,  ...,  0.7254, -0.0516, -0.6377],\n",
            "        [-0.5298,  0.9940, -0.8178,  ..., -0.8785,  0.4784, -0.0702],\n",
            "        ...,\n",
            "        [-0.1213,  0.9999, -0.8847,  ..., -0.8602,  0.3785, -0.1247],\n",
            "        [ 0.7367,  1.0000,  0.9187,  ...,  0.8331, -0.4190, -0.7309],\n",
            "        [ 0.6852,  1.0000,  0.9373,  ...,  0.8485,  0.3073, -0.9235]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3030,  1.0000, -0.7545,  ..., -0.9159,  0.4725, -0.6597],\n",
            "        [ 0.7197,  1.0000,  0.9164,  ...,  0.8782, -0.3046, -0.8474],\n",
            "        [-0.6437,  0.9987, -0.8922,  ..., -0.8528,  0.1949,  0.2490],\n",
            "        ...,\n",
            "        [ 0.6070,  1.0000,  0.9594,  ...,  0.8403,  0.0580, -0.9243],\n",
            "        [ 0.5165,  1.0000,  0.8957,  ...,  0.7362, -0.4258, -0.7907],\n",
            "        [ 0.7060,  1.0000,  0.8819,  ...,  0.6208, -0.1276, -0.8149]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4161,  0.9991, -0.4280,  ..., -0.8247,  0.1364, -0.6194],\n",
            "        [ 0.2542,  1.0000,  0.8348,  ...,  0.7775, -0.2533, -0.7300],\n",
            "        [-0.4070,  0.9710, -0.8193,  ..., -0.8846,  0.2656,  0.0994],\n",
            "        ...,\n",
            "        [ 0.5903,  1.0000,  0.9508,  ...,  0.8568,  0.1993, -0.9079],\n",
            "        [ 0.3203,  0.9999,  0.8050,  ...,  0.1869, -0.3996, -0.9165],\n",
            "        [-0.6653,  1.0000, -0.8125,  ..., -0.9150,  0.3217, -0.2279]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 5.4202e-01,  1.0000e+00,  9.4472e-01,  ...,  8.3571e-01,\n",
            "          3.8231e-04, -8.0725e-01],\n",
            "        [ 6.1641e-01,  1.0000e+00,  9.6665e-01,  ...,  6.5694e-01,\n",
            "          2.6848e-01, -9.1307e-01],\n",
            "        [ 3.1424e-01,  1.0000e+00, -3.6563e-01,  ..., -7.9652e-01,\n",
            "          6.3361e-01, -9.3218e-01],\n",
            "        ...,\n",
            "        [-2.3856e-01,  9.9998e-01, -7.0843e-01,  ..., -9.1110e-01,\n",
            "          5.2895e-01, -3.2216e-01],\n",
            "        [ 6.6883e-01,  1.0000e+00,  9.2236e-01,  ...,  8.2572e-01,\n",
            "         -3.2903e-01, -7.6538e-01],\n",
            "        [-5.4309e-01,  9.9991e-01, -7.8493e-01,  ..., -8.5578e-01,\n",
            "          6.0243e-01, -4.5325e-01]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6621,  1.0000,  0.9132,  ...,  0.8585, -0.1063, -0.7373],\n",
            "        [ 0.8375,  1.0000,  0.9134,  ...,  0.7876, -0.4403, -0.6328],\n",
            "        [ 0.5074,  1.0000,  0.9536,  ...,  0.7779, -0.2372, -0.8979],\n",
            "        ...,\n",
            "        [-0.1111,  0.9999, -0.7483,  ..., -0.8692,  0.7153, -0.6981],\n",
            "        [ 0.1360,  1.0000, -0.1869,  ..., -0.8223,  0.5912, -0.9428],\n",
            "        [ 0.3509,  1.0000,  0.9147,  ...,  0.7320, -0.0078, -0.8164]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6185,  0.9999, -0.8320,  ..., -0.8956,  0.5501, -0.7347],\n",
            "        [-0.5483,  0.9998, -0.8283,  ..., -0.9102,  0.2401,  0.2970],\n",
            "        [-0.1066,  0.9994, -0.7419,  ..., -0.8658,  0.5781,  0.0017],\n",
            "        ...,\n",
            "        [-0.5084,  0.6221, -0.9361,  ..., -0.9146,  0.2413,  0.2670],\n",
            "        [ 0.6650,  1.0000,  0.8837,  ...,  0.7972, -0.4995, -0.7836],\n",
            "        [-0.6268,  0.9988, -0.8485,  ..., -0.7184, -0.0504,  0.3467]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5164,  1.0000,  0.9317,  ...,  0.8630, -0.2494, -0.7000],\n",
            "        [ 0.6489,  1.0000,  0.8915,  ...,  0.8764, -0.4434, -0.8037],\n",
            "        [ 0.1321,  1.0000, -0.4375,  ..., -0.8864,  0.5679, -0.8487],\n",
            "        ...,\n",
            "        [ 0.6494,  1.0000,  0.9167,  ...,  0.7678, -0.4848, -0.7851],\n",
            "        [ 0.6933,  1.0000,  0.9098,  ...,  0.8384, -0.2739, -0.7898],\n",
            "        [ 0.6975,  1.0000,  0.8790,  ...,  0.6621, -0.2277, -0.7739]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7274,  1.0000,  0.9330,  ...,  0.8887, -0.0069, -0.6220],\n",
            "        [ 0.5555,  1.0000,  0.6751,  ..., -0.1107,  0.3544, -0.9625],\n",
            "        [ 0.6761,  1.0000,  0.9236,  ...,  0.8298,  0.0064, -0.7047],\n",
            "        ...,\n",
            "        [ 0.6189,  1.0000,  0.9615,  ...,  0.7904, -0.0728, -0.7557],\n",
            "        [ 0.6939,  1.0000,  0.8976,  ..., -0.0546,  0.4094, -0.9402],\n",
            "        [-0.4184,  0.9348, -0.8171,  ..., -0.8344,  0.0282,  0.1114]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4931,  0.9381, -0.9192,  ..., -0.9294,  0.0181,  0.6705],\n",
            "        [ 0.5060,  1.0000,  0.8761,  ...,  0.6151, -0.0446, -0.6970],\n",
            "        [ 0.6860,  1.0000,  0.9368,  ...,  0.8704, -0.4022, -0.7535],\n",
            "        ...,\n",
            "        [ 0.3895,  1.0000,  0.9028,  ...,  0.7692, -0.4108, -0.4698],\n",
            "        [ 0.5909,  1.0000,  0.9397,  ...,  0.8981, -0.2167, -0.7863],\n",
            "        [ 0.6352,  1.0000,  0.9525,  ...,  0.9070,  0.0608, -0.8392]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3908,  0.9997, -0.0709,  ..., -0.6149,  0.3944, -0.6413],\n",
            "        [-0.1391,  0.9996, -0.8911,  ..., -0.9399,  0.5524,  0.2343],\n",
            "        [-0.5228,  0.9772, -0.8971,  ..., -0.9230,  0.4993,  0.1968],\n",
            "        ...,\n",
            "        [-0.4085,  0.9982, -0.5926,  ..., -0.8247,  0.7265, -0.2273],\n",
            "        [-0.1646,  0.9999, -0.8468,  ..., -0.8887,  0.2943,  0.1541],\n",
            "        [-0.2819,  0.9978, -0.9142,  ..., -0.9295,  0.1677,  0.3458]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6896,  1.0000,  0.8904,  ...,  0.6768, -0.4386, -0.6889],\n",
            "        [-0.2879,  0.9693, -0.9064,  ..., -0.8989,  0.1228,  0.2889],\n",
            "        [-0.2692,  0.9975, -0.8465,  ..., -0.8866,  0.4340,  0.0458],\n",
            "        ...,\n",
            "        [ 0.2336,  1.0000,  0.1817,  ..., -0.7892,  0.8037, -0.8821],\n",
            "        [-0.3766,  0.9998, -0.7834,  ..., -0.8907,  0.4178, -0.2440],\n",
            "        [ 0.5702,  1.0000,  0.9493,  ...,  0.6764, -0.0016, -0.7089]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4158,  0.9944, -0.8466,  ..., -0.8887,  0.2475, -0.1799],\n",
            "        [ 0.3968,  1.0000,  0.9067,  ...,  0.8529, -0.2281, -0.7950],\n",
            "        [ 0.7034,  1.0000,  0.7383,  ...,  0.3508, -0.4942, -0.7970],\n",
            "        ...,\n",
            "        [-0.4971,  0.9814, -0.8249,  ..., -0.8332,  0.3435,  0.0170],\n",
            "        [-0.4318,  0.9965, -0.9209,  ..., -0.9463,  0.1345,  0.2336],\n",
            "        [-0.5548,  0.9911, -0.8831,  ..., -0.8834,  0.3342,  0.1308]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5393,  1.0000,  0.9442,  ...,  0.9115,  0.2656, -0.8988],\n",
            "        [ 0.6405,  1.0000,  0.8678,  ...,  0.6927, -0.4942, -0.7806],\n",
            "        [ 0.5773,  1.0000,  0.9214,  ...,  0.7649, -0.1403, -0.8440],\n",
            "        ...,\n",
            "        [-0.4845,  1.0000, -0.5512,  ..., -0.7528,  0.5699, -0.2062],\n",
            "        [ 0.5768,  1.0000,  0.9670,  ...,  0.8836,  0.0825, -0.9068],\n",
            "        [ 0.7211,  1.0000,  0.8648,  ...,  0.8848, -0.4635, -0.6761]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0579,  0.9993, -0.8598,  ..., -0.8962,  0.3791,  0.0316],\n",
            "        [ 0.5969,  1.0000,  0.9097,  ...,  0.6553, -0.3001, -0.5789],\n",
            "        [-0.4757,  0.9979, -0.8247,  ..., -0.9604,  0.4910,  0.1211],\n",
            "        ...,\n",
            "        [ 0.3451,  1.0000,  0.7845,  ...,  0.5311, -0.3484, -0.6173],\n",
            "        [ 0.8609,  1.0000,  0.8710,  ...,  0.3741, -0.1547, -0.9312],\n",
            "        [-0.3800,  0.9974, -0.8561,  ..., -0.8029,  0.2095,  0.1556]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6030,  1.0000,  0.9344,  ...,  0.8085, -0.3149, -0.7563],\n",
            "        [ 0.6547,  1.0000,  0.8208,  ...,  0.1600,  0.6333, -0.9389],\n",
            "        [-0.5095,  0.9973, -0.7588,  ..., -0.8480,  0.2344, -0.0362],\n",
            "        ...,\n",
            "        [-0.5368,  0.9996, -0.8785,  ..., -0.8864,  0.3061,  0.0052],\n",
            "        [ 0.6711,  1.0000,  0.9471,  ...,  0.8792, -0.2975, -0.8985],\n",
            "        [-0.6161,  0.9923, -0.9253,  ..., -0.8896,  0.2951,  0.3548]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5511,  0.9964, -0.9374,  ..., -0.9232,  0.0508, -0.1903],\n",
            "        [-0.4857,  0.8969, -0.9327,  ..., -0.9408,  0.3022,  0.0399],\n",
            "        [-0.3697,  0.9999, -0.8982,  ..., -0.9050,  0.2343,  0.4326],\n",
            "        ...,\n",
            "        [ 0.6794,  1.0000,  0.9524,  ...,  0.9094,  0.1156, -0.8388],\n",
            "        [ 0.5227,  1.0000,  0.8735,  ...,  0.7897, -0.6485, -0.7326],\n",
            "        [ 0.5211,  1.0000,  0.9528,  ...,  0.9047, -0.4544, -0.7930]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5643,  0.9989, -0.9133,  ..., -0.9384,  0.0150,  0.3801],\n",
            "        [-0.2898,  0.9995, -0.8633,  ..., -0.7836,  0.3776, -0.0952],\n",
            "        [ 0.6055,  1.0000,  0.9191,  ...,  0.7748,  0.1495, -0.9550],\n",
            "        ...,\n",
            "        [ 0.4033,  1.0000,  0.8067,  ...,  0.5237, -0.0582, -0.8813],\n",
            "        [-0.3337,  0.9401, -0.8984,  ..., -0.9274,  0.3698,  0.2371],\n",
            "        [ 0.5118,  1.0000,  0.7634,  ...,  0.3855,  0.0342, -0.8941]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7457,  1.0000,  0.7488,  ...,  0.7477, -0.3057, -0.8260],\n",
            "        [ 0.4706,  1.0000,  0.9070,  ...,  0.6501, -0.3006, -0.5836],\n",
            "        [ 0.4759,  1.0000,  0.9368,  ...,  0.7258, -0.3928, -0.8680],\n",
            "        ...,\n",
            "        [-0.3162,  0.9988, -0.8855,  ..., -0.8596, -0.1319,  0.1944],\n",
            "        [ 0.3980,  1.0000,  0.9456,  ...,  0.8010, -0.4910, -0.7061],\n",
            "        [-0.3899,  0.9928, -0.8973,  ..., -0.8752,  0.0867,  0.0199]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7106,  1.0000,  0.9575,  ...,  0.8655, -0.0503, -0.8393],\n",
            "        [ 0.3979,  1.0000,  0.8219,  ...,  0.4776, -0.3647, -0.8253],\n",
            "        [ 0.5857,  1.0000,  0.9102,  ...,  0.6513, -0.4194, -0.7694],\n",
            "        ...,\n",
            "        [ 0.3120,  1.0000,  0.9433,  ...,  0.8987,  0.1124, -0.7287],\n",
            "        [-0.4107,  0.9716, -0.8924,  ..., -0.9060,  0.0716,  0.4740],\n",
            "        [ 0.5637,  1.0000,  0.9367,  ...,  0.7478,  0.1067, -0.8842]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5305,  0.9892, -0.9010,  ..., -0.9287,  0.2754, -0.0881],\n",
            "        [-0.4585,  0.9987, -0.8924,  ..., -0.8757,  0.1471,  0.0423],\n",
            "        [-0.5321,  0.9952, -0.9023,  ..., -0.9151,  0.1339,  0.2640],\n",
            "        ...,\n",
            "        [ 0.6347,  1.0000,  0.9273,  ...,  0.8811, -0.4250, -0.5847],\n",
            "        [ 0.4081,  1.0000,  0.6949,  ...,  0.2052, -0.6406, -0.7820],\n",
            "        [ 0.7148,  1.0000,  0.9111,  ...,  0.6997, -0.3301, -0.7636]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4672,  0.9868, -0.8740,  ..., -0.7557, -0.3358,  0.4794],\n",
            "        [ 0.6165,  1.0000,  0.9314,  ...,  0.7394, -0.1816, -0.7123],\n",
            "        [-0.5809,  0.9970, -0.9138,  ..., -0.8873,  0.0607,  0.3429],\n",
            "        ...,\n",
            "        [-0.0958,  1.0000, -0.1562,  ..., -0.8239,  0.5692, -0.8625],\n",
            "        [-0.4811,  0.8624, -0.8775,  ..., -0.9152,  0.3457,  0.0541],\n",
            "        [ 0.4815,  1.0000,  0.8088,  ...,  0.7036, -0.2552, -0.7006]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6463,  1.0000,  0.9556,  ...,  0.8699, -0.0216, -0.9112],\n",
            "        [ 0.6567,  1.0000,  0.8831,  ...,  0.7742, -0.3534, -0.6081],\n",
            "        [ 0.5607,  1.0000,  0.9395,  ...,  0.7649,  0.3603, -0.9232],\n",
            "        ...,\n",
            "        [-0.5083,  0.9961, -0.8995,  ..., -0.9330,  0.3102,  0.1803],\n",
            "        [ 0.7546,  1.0000,  0.3951,  ..., -0.3127, -0.0344, -0.8705],\n",
            "        [ 0.6442,  1.0000,  0.9146,  ...,  0.8388, -0.5312, -0.7543]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3978,  0.9943, -0.9134,  ..., -0.9158,  0.4914, -0.1039],\n",
            "        [-0.3994,  0.7043, -0.9294,  ..., -0.8915,  0.1140,  0.3223],\n",
            "        [-0.1467,  0.9998, -0.7801,  ..., -0.9581,  0.7393, -0.6399],\n",
            "        ...,\n",
            "        [-0.3769,  0.9107, -0.8050,  ..., -0.9350,  0.3597,  0.0754],\n",
            "        [ 0.2631,  1.0000,  0.8397,  ...,  0.7038, -0.4495, -0.6327],\n",
            "        [-0.4970,  0.9735, -0.8877,  ..., -0.8887,  0.2992,  0.3575]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3708,  1.0000,  0.8405,  ...,  0.1980,  0.1726, -0.8901],\n",
            "        [ 0.4166,  1.0000,  0.9137,  ...,  0.7984, -0.5692, -0.4694],\n",
            "        [-0.4964,  0.6678, -0.9470,  ..., -0.8853,  0.0597,  0.2834],\n",
            "        ...,\n",
            "        [ 0.7071,  1.0000,  0.9373,  ...,  0.8429, -0.2370, -0.8737],\n",
            "        [-0.3245,  0.9986, -0.8102,  ..., -0.8528,  0.5057,  0.0143],\n",
            "        [ 0.7112,  1.0000,  0.9373,  ...,  0.8439, -0.3562, -0.7556]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1462,  1.0000, -0.0438,  ..., -0.8556,  0.7967, -0.8243],\n",
            "        [ 0.5278,  1.0000,  0.8799,  ...,  0.7297,  0.0050, -0.6650],\n",
            "        [-0.5463, -0.0612, -0.9207,  ..., -0.9102, -0.0041,  0.4502],\n",
            "        ...,\n",
            "        [ 0.5479,  1.0000,  0.9491,  ...,  0.9309, -0.2433, -0.7764],\n",
            "        [-0.4057,  0.9987, -0.9289,  ..., -0.8984,  0.0743,  0.1244],\n",
            "        [ 0.5894,  1.0000,  0.8874,  ...,  0.8997, -0.3647, -0.6099]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4567,  1.0000,  0.8455,  ..., -0.1069, -0.1760, -0.8479],\n",
            "        [ 0.6683,  1.0000,  0.9000,  ...,  0.7784, -0.4167, -0.6049],\n",
            "        [-0.5422,  0.9473, -0.9034,  ..., -0.9340,  0.2041,  0.2603],\n",
            "        ...,\n",
            "        [ 0.4660,  1.0000,  0.9489,  ...,  0.7905,  0.0076, -0.8633],\n",
            "        [ 0.6032,  1.0000,  0.8689,  ...,  0.8185, -0.5938, -0.6554],\n",
            "        [-0.6697,  0.7966, -0.8478,  ..., -0.8910,  0.3002,  0.4703]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4550,  0.9991, -0.8502,  ..., -0.8667,  0.2601,  0.1523],\n",
            "        [ 0.4241,  1.0000,  0.9081,  ...,  0.8041, -0.4299, -0.7355],\n",
            "        [ 0.4223,  1.0000,  0.9563,  ...,  0.5281, -0.3482, -0.8863],\n",
            "        ...,\n",
            "        [ 0.7007,  1.0000,  0.8942,  ...,  0.3068, -0.1730, -0.9676],\n",
            "        [ 0.7911,  1.0000,  0.7730,  ...,  0.4590, -0.0245, -0.9494],\n",
            "        [-0.6989,  0.9947, -0.8982,  ..., -0.9270, -0.1279,  0.1505]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4924, -0.4456, -0.9014,  ..., -0.9132,  0.4408,  0.3927],\n",
            "        [-0.6778,  0.9349, -0.9483,  ..., -0.9376,  0.3750,  0.5736],\n",
            "        [-0.5542,  0.9853, -0.8736,  ..., -0.8747,  0.2629,  0.4228],\n",
            "        ...,\n",
            "        [-0.7611,  0.9994, -0.7436,  ..., -0.8285,  0.3472, -0.1717],\n",
            "        [-0.3645,  0.9521, -0.7948,  ..., -0.8936,  0.1672,  0.3990],\n",
            "        [-0.5942,  0.6712, -0.8464,  ..., -0.9028,  0.1378,  0.3818]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5185,  0.9966, -0.8106,  ..., -0.8560,  0.6432,  0.0522],\n",
            "        [-0.5946,  0.7069, -0.8048,  ..., -0.8291,  0.2580, -0.5524],\n",
            "        [-0.0260,  0.9997, -0.8566,  ..., -0.8284,  0.0915, -0.2733],\n",
            "        ...,\n",
            "        [ 0.5829,  1.0000,  0.9536,  ...,  0.4414,  0.2682, -0.9746],\n",
            "        [-0.4380,  0.9505, -0.8321,  ..., -0.9157,  0.3050, -0.1025],\n",
            "        [ 0.6931,  1.0000,  0.8882,  ...,  0.5399,  0.3921, -0.9504]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2981,  0.7806, -0.8974,  ..., -0.8721,  0.1473,  0.3780],\n",
            "        [ 0.6677,  1.0000,  0.9575,  ...,  0.6514,  0.0393, -0.7928],\n",
            "        [-0.3868,  0.9923, -0.9020,  ..., -0.7867,  0.3434,  0.3069],\n",
            "        ...,\n",
            "        [-0.1772,  0.9997, -0.8170,  ..., -0.8388,  0.2016, -0.0773],\n",
            "        [ 0.5830,  1.0000,  0.9440,  ...,  0.8733, -0.0104, -0.8148],\n",
            "        [-0.4474,  0.9950, -0.8503,  ..., -0.8816,  0.4608,  0.0550]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6089,  0.9838, -0.8331,  ..., -0.8246,  0.0389,  0.0897],\n",
            "        [ 0.5906,  1.0000,  0.9232,  ...,  0.8118, -0.3258, -0.8250],\n",
            "        [ 0.6565,  1.0000,  0.9112,  ...,  0.7875, -0.2113, -0.5366],\n",
            "        ...,\n",
            "        [-0.1849,  0.9979, -0.8394,  ..., -0.9288,  0.5474,  0.1105],\n",
            "        [-0.4781,  0.9848, -0.8831,  ..., -0.9322,  0.0498,  0.3874],\n",
            "        [ 0.6309,  1.0000,  0.9187,  ...,  0.8823, -0.4915, -0.7807]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2260,  0.9994, -0.8675,  ..., -0.9232,  0.4063, -0.3034],\n",
            "        [-0.5708, -0.1542, -0.8765,  ..., -0.8963,  0.1293,  0.1421],\n",
            "        [ 0.1186,  1.0000, -0.6460,  ..., -0.7398,  0.4442, -0.6773],\n",
            "        ...,\n",
            "        [-0.2168,  1.0000, -0.7527,  ..., -0.8422,  0.2362, -0.8293],\n",
            "        [-0.4764,  1.0000,  0.8415,  ..., -0.0743,  0.2431, -0.9366],\n",
            "        [ 0.7309,  1.0000,  0.9006,  ...,  0.8277, -0.1062, -0.6265]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0990,  1.0000,  0.8642,  ...,  0.0698, -0.0778, -0.4786],\n",
            "        [ 0.6634,  1.0000, -0.3606,  ..., -0.8055,  0.6204, -0.8323],\n",
            "        [-0.6215,  0.9999, -0.8242,  ..., -0.8904,  0.2698,  0.0197],\n",
            "        ...,\n",
            "        [-0.4307,  0.9207, -0.9414,  ..., -0.9444, -0.2178,  0.3406],\n",
            "        [-0.3605,  1.0000, -0.8296,  ..., -0.8964,  0.7056, -0.3638],\n",
            "        [ 0.6931,  1.0000,  0.9034,  ...,  0.6302, -0.1915, -0.8999]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7174,  1.0000,  0.8454,  ...,  0.7448, -0.4760, -0.6278],\n",
            "        [ 0.5049,  1.0000,  0.8739,  ...,  0.5759, -0.0173, -0.8360],\n",
            "        [ 0.6699,  1.0000,  0.9394,  ...,  0.8864,  0.0685, -0.8976],\n",
            "        ...,\n",
            "        [ 0.5160,  1.0000,  0.9277,  ...,  0.8729,  0.1389, -0.8696],\n",
            "        [ 0.4099,  1.0000,  0.8447,  ...,  0.8591, -0.6414, -0.7205],\n",
            "        [ 0.0088,  1.0000, -0.1941,  ..., -0.8438,  0.3115, -0.3912]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1141,  0.9997, -0.9702,  ..., -0.9065,  0.3652, -0.3882],\n",
            "        [ 0.5327,  1.0000,  0.9373,  ...,  0.8233,  0.2643, -0.9264],\n",
            "        [ 0.1595,  1.0000, -0.4099,  ..., -0.7100,  0.6342, -0.8636],\n",
            "        ...,\n",
            "        [ 0.6308,  1.0000,  0.9639,  ...,  0.8166,  0.0709, -0.8515],\n",
            "        [ 0.5546,  1.0000,  0.9347,  ...,  0.8967, -0.3699, -0.8501],\n",
            "        [-0.2284,  0.9980, -0.8361,  ..., -0.9022,  0.1877, -0.0743]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1683,  1.0000, -0.0090,  ..., -0.7718,  0.6835, -0.9484],\n",
            "        [ 0.4833,  1.0000,  0.9308,  ...,  0.8761, -0.0827, -0.8257],\n",
            "        [-0.1862,  0.9970, -0.9472,  ..., -0.9250,  0.2691,  0.0037],\n",
            "        ...,\n",
            "        [ 0.1425,  1.0000, -0.7771,  ..., -0.8815,  0.2454, -0.2664],\n",
            "        [ 0.6141,  1.0000,  0.9520,  ...,  0.9030,  0.0204, -0.8728],\n",
            "        [ 0.7037,  1.0000,  0.9399,  ...,  0.6747, -0.0683, -0.8399]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5503,  1.0000, -0.7060,  ..., -0.8342,  0.3946, -0.7710],\n",
            "        [ 0.4833,  1.0000, -0.1745,  ..., -0.8682,  0.5987, -0.7131],\n",
            "        [ 0.6200,  1.0000,  0.9289,  ...,  0.1087,  0.0720, -0.9343],\n",
            "        ...,\n",
            "        [ 0.6930,  1.0000,  0.5926,  ..., -0.3558,  0.5476, -0.9060],\n",
            "        [-0.3233,  0.9869, -0.9252,  ..., -0.9347,  0.1954,  0.0415],\n",
            "        [-0.0773,  0.9646, -0.8499,  ..., -0.9043,  0.5401, -0.3830]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1182,  0.9002, -0.9418,  ..., -0.9104,  0.1322,  0.1082],\n",
            "        [ 0.6072,  1.0000,  0.9516,  ...,  0.8142, -0.3503, -0.5583],\n",
            "        [-0.4697,  1.0000, -0.8584,  ..., -0.9254, -0.0820, -0.0592],\n",
            "        ...,\n",
            "        [ 0.5558,  1.0000,  0.9034,  ...,  0.7419, -0.3723, -0.7713],\n",
            "        [-0.2660,  0.9991, -0.8907,  ..., -0.9120,  0.2576, -0.1511],\n",
            "        [ 0.6330,  1.0000,  0.9217,  ...,  0.8672,  0.0593, -0.8667]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5763,  1.0000,  0.9129,  ...,  0.7705, -0.3971, -0.5623],\n",
            "        [ 0.5325,  1.0000,  0.9214,  ...,  0.8806, -0.4660, -0.7123],\n",
            "        [-0.3047,  0.9995, -0.9132,  ..., -0.9330,  0.3767,  0.1797],\n",
            "        ...,\n",
            "        [-0.5119,  0.9883, -0.7537,  ..., -0.8741,  0.3510, -0.0912],\n",
            "        [-0.3679,  1.0000, -0.8854,  ..., -0.8026,  0.2693, -0.4269],\n",
            "        [-0.2175,  0.9894, -0.8705,  ..., -0.8441,  0.3262, -0.0607]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4040,  0.9961, -0.8773,  ..., -0.9164,  0.2267,  0.4794],\n",
            "        [ 0.5953,  1.0000,  0.8721,  ...,  0.7611, -0.5004, -0.6615],\n",
            "        [ 0.4800,  1.0000,  0.8625,  ...,  0.8042, -0.5762, -0.4609],\n",
            "        ...,\n",
            "        [ 0.4460,  1.0000,  0.8546,  ...,  0.8420, -0.3032, -0.7454],\n",
            "        [ 0.6443,  1.0000,  0.9095,  ...,  0.8311,  0.1385, -0.7456],\n",
            "        [-0.3321,  0.9979, -0.8311,  ..., -0.9335, -0.0826,  0.0703]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6563,  1.0000,  0.9358,  ...,  0.7229, -0.6542, -0.4462],\n",
            "        [ 0.2750,  1.0000,  0.9185,  ...,  0.6879,  0.1891, -0.6272],\n",
            "        [ 0.5985,  1.0000,  0.9434,  ...,  0.8333,  0.2548, -0.9033],\n",
            "        ...,\n",
            "        [ 0.4714,  1.0000,  0.9052,  ...,  0.8175, -0.5950, -0.6132],\n",
            "        [ 0.5502,  1.0000, -0.7242,  ..., -0.8482,  0.7502, -0.7144],\n",
            "        [ 0.6466,  1.0000,  0.9557,  ...,  0.8062, -0.1876, -0.7311]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1792,  0.9999, -0.8737,  ..., -0.8778,  0.5046, -0.4053],\n",
            "        [ 0.7076,  1.0000,  0.9364,  ...,  0.8112, -0.2612, -0.7821],\n",
            "        [ 0.6078,  1.0000,  0.9575,  ...,  0.6930,  0.3042, -0.9279],\n",
            "        ...,\n",
            "        [ 0.3086,  1.0000, -0.7559,  ..., -0.8956,  0.3714, -0.5079],\n",
            "        [-0.5048,  0.9982, -0.9061,  ..., -0.8730,  0.2975,  0.0924],\n",
            "        [ 0.3893,  1.0000,  0.7161,  ..., -0.3302, -0.0900, -0.8586]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0651,  0.9987, -0.3300,  ..., -0.7747,  0.3532, -0.0393],\n",
            "        [-0.0815,  0.9978, -0.8789,  ..., -0.9149,  0.2288, -0.0666],\n",
            "        [ 0.5498,  1.0000,  0.8394,  ...,  0.6494, -0.1987, -0.8621],\n",
            "        ...,\n",
            "        [-0.2604,  0.9749, -0.8461,  ..., -0.8343,  0.2459,  0.2059],\n",
            "        [-0.1047,  0.9992, -0.6843,  ..., -0.8969,  0.1718, -0.1335],\n",
            "        [ 0.6970,  1.0000,  0.9587,  ...,  0.8188, -0.1032, -0.8466]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5058,  1.0000, -0.8744,  ..., -0.8916,  0.2889,  0.1610],\n",
            "        [-0.2861,  0.9993, -0.7117,  ..., -0.7851,  0.2839, -0.6469],\n",
            "        [ 0.4544,  1.0000,  0.8891,  ...,  0.8288, -0.5583, -0.6394],\n",
            "        ...,\n",
            "        [-0.4041,  0.9999, -0.7335,  ..., -0.9007,  0.4325, -0.0782],\n",
            "        [ 0.5865,  1.0000,  0.9380,  ...,  0.8621, -0.3388, -0.7338],\n",
            "        [-0.2377,  0.9928, -0.7561,  ..., -0.9124,  0.2978,  0.0170]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1264,  0.9957, -0.6201,  ..., -0.8332,  0.1583, -0.2501],\n",
            "        [-0.1303,  1.0000,  0.0883,  ..., -0.7704,  0.7958, -0.8352],\n",
            "        [ 0.1098,  1.0000, -0.7898,  ..., -0.9082,  0.5029, -0.7114],\n",
            "        ...,\n",
            "        [ 0.5816,  1.0000,  0.8868,  ...,  0.8685, -0.4141, -0.6210],\n",
            "        [ 0.5130,  0.9999, -0.4807,  ..., -0.7473,  0.5586, -0.5695],\n",
            "        [-0.2322,  1.0000, -0.5372,  ..., -0.3911,  0.5124, -0.7513]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2087,  0.9938, -0.0868,  ..., -0.6939,  0.1398, -0.6848],\n",
            "        [ 0.4514,  1.0000,  0.8749,  ...,  0.7565, -0.5147, -0.5515],\n",
            "        [ 0.6948,  1.0000,  0.9295,  ...,  0.8678,  0.0106, -0.8007],\n",
            "        ...,\n",
            "        [-0.2578,  1.0000, -0.6771,  ..., -0.9315,  0.2466, -0.6580],\n",
            "        [ 0.7258,  1.0000,  0.9113,  ...,  0.8439, -0.3730, -0.6626],\n",
            "        [ 0.3872,  1.0000, -0.6096,  ..., -0.6381,  0.4199, -0.6327]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5731,  1.0000,  0.0334,  ..., -0.7163,  0.8689, -0.6535],\n",
            "        [ 0.2986,  1.0000,  0.8800,  ...,  0.8587, -0.4166, -0.6166],\n",
            "        [ 0.5960,  1.0000,  0.9343,  ...,  0.8769, -0.0853, -0.8493],\n",
            "        ...,\n",
            "        [ 0.4575,  1.0000,  0.9654,  ...,  0.9062,  0.1195, -0.8762],\n",
            "        [-0.4631,  0.9995, -0.5933,  ..., -0.8405,  0.3579,  0.3664],\n",
            "        [-0.0917,  1.0000, -0.7536,  ..., -0.7838,  0.1341, -0.4425]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.8174,  1.0000,  0.8217,  ...,  0.5923,  0.0490, -0.7446],\n",
            "        [ 0.6466,  1.0000,  0.9614,  ...,  0.9140, -0.0994, -0.8850],\n",
            "        [ 0.6337,  1.0000,  0.9295,  ...,  0.8535,  0.0911, -0.9008],\n",
            "        ...,\n",
            "        [ 0.3322,  1.0000,  0.9194,  ...,  0.7916, -0.4377, -0.6334],\n",
            "        [ 0.6821,  1.0000,  0.8659,  ...,  0.8513, -0.5487, -0.3613],\n",
            "        [ 0.6415,  1.0000,  0.7713,  ...,  0.6788, -0.3129, -0.7290]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2895,  0.9994, -0.8622,  ..., -0.8839,  0.2501, -0.4855],\n",
            "        [ 0.5083,  1.0000,  0.8265,  ...,  0.7871, -0.7256, -0.4626],\n",
            "        [ 0.6617,  1.0000,  0.9515,  ...,  0.9069, -0.1112, -0.7780],\n",
            "        ...,\n",
            "        [ 0.7346,  1.0000,  0.8647,  ...,  0.7016, -0.5565, -0.5807],\n",
            "        [ 0.6621,  1.0000,  0.9428,  ...,  0.7538,  0.1876, -0.9116],\n",
            "        [ 0.4803,  1.0000,  0.9381,  ...,  0.8843, -0.3641, -0.7023]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6741,  1.0000,  0.9571,  ...,  0.4147,  0.2076, -0.9796],\n",
            "        [ 0.6117,  1.0000,  0.8476,  ...,  0.7132, -0.5101, -0.5160],\n",
            "        [-0.0900,  1.0000, -0.7913,  ..., -0.9020,  0.4707, -0.5332],\n",
            "        ...,\n",
            "        [-0.1574,  0.9999, -0.9328,  ..., -0.9218,  0.5708, -0.1561],\n",
            "        [-0.2221,  0.9893, -0.8993,  ..., -0.8527,  0.2577, -0.0367],\n",
            "        [-0.5421,  0.5030, -0.9288,  ..., -0.8923, -0.0888,  0.2900]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5088,  1.0000,  0.4042,  ..., -0.4226,  0.5114, -0.8820],\n",
            "        [ 0.5695,  1.0000,  0.9399,  ...,  0.5351, -0.2854, -0.8183],\n",
            "        [ 0.4088,  0.9998,  0.8837,  ...,  0.8071, -0.6349, -0.4606],\n",
            "        ...,\n",
            "        [-0.4104,  0.7988, -0.9120,  ..., -0.9292,  0.3387,  0.1151],\n",
            "        [-0.2998,  0.9999, -0.3431,  ..., -0.8594,  0.5240, -0.4198],\n",
            "        [-0.3418,  0.9991, -0.9087,  ..., -0.9371,  0.3313,  0.0027]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5194,  1.0000,  0.9288,  ...,  0.8798, -0.4188, -0.6421],\n",
            "        [ 0.7696,  1.0000,  0.2753,  ..., -0.5660,  0.5079, -0.9306],\n",
            "        [ 0.0159,  1.0000, -0.7514,  ..., -0.9193,  0.6816, -0.6176],\n",
            "        ...,\n",
            "        [ 0.4292,  1.0000,  0.8939,  ...,  0.7720, -0.4929, -0.6794],\n",
            "        [-0.4234,  1.0000,  0.0676,  ..., -0.5962,  0.5932, -0.4801],\n",
            "        [-0.1674,  1.0000, -0.6104,  ..., -0.8360,  0.4396, -0.6654]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1832,  0.9966, -0.9146,  ..., -0.7680, -0.0370,  0.4632],\n",
            "        [ 0.3659,  1.0000,  0.9363,  ...,  0.7015, -0.2083, -0.5714],\n",
            "        [ 0.6706,  1.0000,  0.9521,  ...,  0.8941, -0.2278, -0.8523],\n",
            "        ...,\n",
            "        [ 0.5900,  1.0000,  0.9464,  ...,  0.8322, -0.4603, -0.8471],\n",
            "        [-0.1849,  1.0000, -0.7451,  ..., -0.8465,  0.6032, -0.5819],\n",
            "        [ 0.3529,  1.0000, -0.3111,  ..., -0.9010,  0.6962, -0.7872]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3552,  0.9991, -0.5665,  ..., -0.8503,  0.5098, -0.0906],\n",
            "        [ 0.4293,  1.0000,  0.9157,  ...,  0.6748, -0.6959, -0.7289],\n",
            "        [ 0.4623,  1.0000,  0.7707,  ...,  0.8210, -0.3438, -0.5475],\n",
            "        ...,\n",
            "        [ 0.5512,  1.0000,  0.8514,  ...,  0.6968, -0.3309, -0.5794],\n",
            "        [ 0.5333,  0.9999,  0.8927,  ...,  0.8683, -0.5421, -0.4892],\n",
            "        [ 0.3576,  1.0000,  0.8606,  ...,  0.2057, -0.3031, -0.8529]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1535,  1.0000,  0.2854,  ..., -0.6538,  0.6925, -0.9069],\n",
            "        [-0.6716,  0.9998, -0.6936,  ..., -0.8900,  0.4358, -0.0028],\n",
            "        [ 0.5708,  1.0000,  0.9251,  ...,  0.8239, -0.5730, -0.6156],\n",
            "        ...,\n",
            "        [ 0.0145,  0.9998, -0.7034,  ..., -0.9498,  0.6343, -0.4414],\n",
            "        [ 0.0159,  1.0000, -0.6371,  ..., -0.8633,  0.7341, -0.9211],\n",
            "        [ 0.1631,  0.9986, -0.8399,  ..., -0.9101,  0.4105, -0.3133]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3352,  1.0000, -0.6390,  ..., -0.7580,  0.7969, -0.7789],\n",
            "        [ 0.5472,  1.0000,  0.6928,  ..., -0.2115,  0.0609, -0.9389],\n",
            "        [ 0.4773,  1.0000,  0.9189,  ...,  0.5412, -0.5642, -0.5981],\n",
            "        ...,\n",
            "        [-0.2311,  1.0000,  0.0199,  ..., -0.7014,  0.2766, -0.4504],\n",
            "        [ 0.5526,  1.0000, -0.7313,  ..., -0.8163,  0.6404, -0.7185],\n",
            "        [ 0.4402,  1.0000,  0.8261,  ...,  0.8258, -0.4885, -0.4752]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0041,  1.0000,  0.5051,  ...,  0.0598,  0.6682, -0.7948],\n",
            "        [ 0.2507,  1.0000,  0.2592,  ..., -0.5436,  0.5579, -0.8886],\n",
            "        [-0.2035,  0.0070, -0.8594,  ..., -0.8354,  0.1601, -0.0741],\n",
            "        ...,\n",
            "        [-0.4227,  0.9934, -0.8121,  ..., -0.9172,  0.2062,  0.0644],\n",
            "        [ 0.4461,  1.0000,  0.8561,  ...,  0.8012, -0.6174, -0.6099],\n",
            "        [ 0.5268,  0.9999,  0.9069,  ...,  0.7665, -0.5667, -0.5175]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5670,  0.9908, -0.9343,  ..., -0.8621, -0.0975,  0.4360],\n",
            "        [-0.2454,  0.9993, -0.6343,  ..., -0.8921,  0.6041,  0.1542],\n",
            "        [ 0.3636,  1.0000, -0.7609,  ..., -0.9249,  0.7088, -0.8132],\n",
            "        ...,\n",
            "        [-0.5005,  0.9997, -0.8684,  ..., -0.8873,  0.2474, -0.2064],\n",
            "        [ 0.4758,  1.0000,  0.8106,  ...,  0.1387, -0.3660, -0.8181],\n",
            "        [-0.4258,  0.9998, -0.8615,  ..., -0.9056,  0.1715, -0.0283]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3621,  1.0000,  0.1536,  ...,  0.0039,  0.2304, -0.8869],\n",
            "        [ 0.4828,  1.0000,  0.8406,  ...,  0.7624, -0.6444, -0.8364],\n",
            "        [ 0.1331,  1.0000, -0.6353,  ..., -0.9273,  0.6961, -0.8434],\n",
            "        ...,\n",
            "        [-0.6112,  0.9706, -0.8738,  ..., -0.9275,  0.1653, -0.0060],\n",
            "        [ 0.6592,  1.0000,  0.8857,  ...,  0.7294, -0.3360, -0.7923],\n",
            "        [ 0.6721,  0.9999,  0.8414,  ...,  0.7023, -0.7032, -0.4368]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1113,  1.0000, -0.7223,  ..., -0.7886,  0.5793, -0.8050],\n",
            "        [-0.2280,  0.9752, -0.9055,  ..., -0.8521,  0.0916, -0.0772],\n",
            "        [-0.4445,  0.9487, -0.9334,  ..., -0.9293, -0.0068,  0.2794],\n",
            "        ...,\n",
            "        [ 0.3989,  1.0000,  0.8846,  ...,  0.8652, -0.4223, -0.4195],\n",
            "        [-0.2056,  0.9999, -0.8279,  ..., -0.8816,  0.6620, -0.5137],\n",
            "        [-0.4007,  0.9998, -0.8333,  ..., -0.8953,  0.5344, -0.2904]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5320,  0.9981, -0.8707, -0.9427,  0.3940, -0.8727,  0.3063, -0.5294,\n",
            "         -0.6500,  0.6044, -0.6352,  0.9048, -0.4207,  0.9819, -0.1652, -0.0965,\n",
            "         -0.5986, -0.9478,  0.1087, -0.3715,  0.4257,  0.8510,  0.2763, -0.6074,\n",
            "         -0.6420, -0.7122,  0.4318,  0.5804, -0.0318, -0.1437, -0.4704,  0.4136,\n",
            "          0.8594,  0.4586,  0.5164, -0.4614,  0.1527, -0.1793, -0.9026, -0.9514,\n",
            "          0.7940,  0.0981,  0.9789, -0.9450,  0.6925, -0.9282,  0.2672, -0.5660,\n",
            "          0.7905,  0.3126,  0.4323, -0.9916,  0.5019, -0.8333, -0.6690, -0.9765,\n",
            "         -0.5442,  0.6831, -0.3871,  0.6865, -0.2227, -0.5219,  0.7823,  0.2790,\n",
            "          0.9357,  0.4568,  0.7592, -0.0976,  0.8724, -0.9527, -0.6449, -0.4147,\n",
            "          0.4562, -0.6186,  0.6095, -0.0947,  0.5448, -0.8441, -0.4156,  0.5036,\n",
            "         -0.7015,  0.6400,  0.7441, -0.9974, -0.5493, -0.7213,  0.9351, -0.6612,\n",
            "         -0.6358,  0.2448,  0.2892, -0.6944, -0.6170,  0.1140,  0.1766, -0.6857,\n",
            "          0.0050, -0.5485, -0.9332,  0.3055,  0.7317,  0.7333,  0.6572, -0.0558,\n",
            "         -0.9922, -0.8055,  0.3468, -0.7481, -0.9967, -0.4277, -0.6970, -0.2496,\n",
            "          0.7977,  0.4068, -0.4689,  0.9889, -0.8344, -0.1847, -0.9917, -0.8358,\n",
            "          0.1559, -0.1190,  0.1444, -0.4555, -0.0468, -0.9041, -0.9580, -0.9352,\n",
            "          0.5651,  0.2401, -0.2817, -0.3855, -0.7306, -0.7612,  0.1386, -0.2494,\n",
            "         -0.9898,  0.4984,  0.6053, -0.8874,  0.9282,  0.4600, -0.2456, -0.6044,\n",
            "          0.0214,  0.8824,  0.0648,  0.6112, -0.3781, -0.8124,  0.2899, -0.3206,\n",
            "         -0.2775,  0.3483, -0.9984,  0.6408,  0.6718,  0.9091,  0.9390, -0.5826,\n",
            "          0.4110, -0.9907,  0.7198,  0.5043,  0.9931, -0.4809, -0.1090,  0.4605,\n",
            "          0.8209,  0.0061,  0.0100,  0.6996,  0.6449,  0.6980,  0.9840, -0.7776,\n",
            "         -0.6681, -0.4171,  0.9115, -0.3661,  0.8181, -0.2761, -0.1230, -0.8728,\n",
            "         -0.0667, -0.3390, -0.5406, -0.9970,  0.3288,  0.8131, -0.2411, -0.9090,\n",
            "          0.2558,  0.7431,  0.4407, -0.3603, -0.4668,  0.4937, -0.1892,  0.7918,\n",
            "          0.8210, -0.7393,  0.9595,  0.0935, -0.6166, -0.9456,  0.5900,  0.8694,\n",
            "         -0.8550, -0.3463,  0.4793,  0.2877,  0.4798, -0.7275, -0.3063,  0.1831,\n",
            "          0.7322, -0.9072,  0.7877,  0.7681, -0.3477, -0.6071, -0.3922, -0.7060,\n",
            "          0.0792, -0.6667, -0.1001,  0.4395, -0.7583, -0.9907,  0.3561,  0.5707,\n",
            "          0.5123,  0.7490,  0.9915,  0.3852, -0.8328,  0.8476, -0.8482, -0.4545,\n",
            "          0.8069, -0.9629,  0.6332,  0.1321,  0.9927, -0.9137,  0.5207, -0.6414,\n",
            "          0.2658,  0.7466, -0.6048, -0.1607,  0.6637,  0.6929,  0.6209,  0.5465,\n",
            "          0.4541, -0.9723, -0.4562,  0.4184, -0.7951,  0.3390, -0.9446, -0.8924,\n",
            "          0.6592,  0.9962, -0.6011,  0.0102,  0.4752,  0.3660,  0.5269, -0.8286,\n",
            "          0.1347,  0.9981, -0.6628, -0.7432,  0.9969,  0.2905, -0.8944,  0.5161,\n",
            "         -0.8592, -0.7402,  0.7204,  0.0033,  0.1831,  0.1936,  0.2866, -0.6629,\n",
            "         -0.9825, -0.7063,  0.9727,  0.6915,  0.8427,  0.4092, -0.4456, -0.8439,\n",
            "          0.8336, -0.0331, -0.8721,  0.9985,  0.4394, -0.7569, -0.9063,  0.3211,\n",
            "         -0.1240,  0.6451, -0.0633,  0.5351, -0.8111,  0.4533,  0.6136, -0.3744,\n",
            "          0.6241,  0.2834, -0.0143, -0.6244, -0.1180, -0.7624, -0.2756,  0.0326,\n",
            "          0.4560,  0.9502,  0.2374, -0.6245,  0.6746,  0.4758, -0.9940,  0.9714,\n",
            "          0.6942, -0.7851, -0.1116,  0.7188,  0.3752, -0.5539,  0.7116, -0.3970,\n",
            "         -0.1241, -0.6196,  0.2491,  0.7871,  0.6697,  0.4668,  0.5210,  0.3828,\n",
            "          0.3041, -0.5591,  0.6009, -0.5169, -0.8103, -0.5140,  0.0417,  0.6319,\n",
            "         -0.8224,  0.5187,  0.6001,  0.9985,  0.6104,  0.9872, -0.7340,  0.6530,\n",
            "         -0.3956,  0.3944,  0.8301, -0.8320, -0.9939, -0.5809, -0.3533,  0.2756,\n",
            "         -0.9542, -0.8643, -0.7871,  0.4773, -0.2665,  0.8973, -0.3618, -0.9107,\n",
            "          0.9503,  0.4038,  0.8046,  0.0402, -0.4471,  0.5302,  0.7934,  0.4851,\n",
            "          0.5223, -0.4359,  0.7308, -0.7635,  0.6464, -0.0272, -0.0320,  0.2496,\n",
            "          0.5043,  0.6270,  0.6086,  0.9032, -0.3135, -0.3637, -0.9617,  0.9984,\n",
            "         -0.6002,  0.3010, -0.3296,  0.3684,  0.6595, -0.5274,  0.5040, -0.4445,\n",
            "          0.8536, -0.9099,  0.7351,  0.5763,  0.6579, -0.0223, -0.2387,  0.4885,\n",
            "         -0.7138, -0.4736, -0.8126,  0.7270, -0.8808, -0.7618, -0.8433, -0.8884,\n",
            "          0.9467, -0.6930,  0.7499, -0.7147, -0.7832, -0.6544, -0.3381, -0.4548,\n",
            "          0.6141, -0.9514,  0.9869, -0.9088,  0.3603, -0.0135,  0.5107,  0.5293,\n",
            "          0.8193,  0.5648,  0.6006, -0.3062,  0.4061,  0.4363, -0.6682, -0.8465,\n",
            "         -0.1007,  0.6552,  0.4994,  0.7961, -0.4758,  0.9481,  0.6628, -0.5151,\n",
            "         -0.3190, -0.6286,  0.9078,  0.9916, -0.7685,  0.9112,  0.9970, -0.6234,\n",
            "         -0.2928, -0.0786, -0.9005,  0.7970, -0.8083, -0.8446,  0.4526, -0.2026,\n",
            "          0.5840,  0.4307,  0.8477, -0.3564, -0.3402, -0.8985, -0.1129, -0.8825,\n",
            "         -0.5459,  0.7706, -0.8915, -0.8672,  0.8038,  0.0044,  0.0290,  0.4475,\n",
            "          0.7270,  0.8787, -0.3730, -0.4529,  0.3636,  0.5957,  0.5178,  0.3959,\n",
            "         -0.7539, -0.4325, -0.8165,  0.3746,  0.9903, -0.7702, -0.3634,  0.3902,\n",
            "         -0.1409, -0.8519,  0.9983, -0.1176,  0.5502,  0.9923,  0.3675,  0.6690,\n",
            "         -0.4664,  0.6047, -0.3439,  0.4775,  0.8451,  0.9695, -0.7266, -0.7367,\n",
            "         -0.9982,  0.2527, -0.3415, -0.0069, -0.1793, -0.7993, -0.2616,  0.2559,\n",
            "         -0.9333,  0.4842, -0.3401, -0.9925, -0.9230, -0.4285, -0.6910, -0.8845,\n",
            "          0.1406, -0.6906, -0.8095,  0.9380, -0.8830, -0.9965, -0.3966,  0.5525,\n",
            "          0.9378,  0.5976,  0.2214, -0.3496, -0.6753,  0.5348, -0.9991, -0.0554,\n",
            "          0.5921,  0.7008, -0.6580,  0.9189, -0.7430, -0.6444, -0.4532,  0.6084,\n",
            "          0.7447, -0.9991, -0.1297,  0.9022, -0.1095, -0.3672, -0.7868, -0.4510,\n",
            "         -0.7333, -0.6480,  0.9504, -0.3523,  0.9765, -0.6466,  0.7214,  0.5866,\n",
            "          0.0058, -0.7551, -0.1046,  0.8417,  0.7264,  0.5967,  0.6341, -0.4341,\n",
            "          0.0585, -0.1660, -0.5719,  0.4211, -0.7268,  0.5958, -0.4693,  0.5408,\n",
            "          0.3063, -0.4688,  0.9920,  0.4074, -0.7747,  0.7739, -0.4488, -0.5425,\n",
            "         -0.9973, -0.7596,  0.7566, -0.9310, -0.8004,  0.4601, -0.5349, -0.3588,\n",
            "          0.9171, -0.2756,  0.8338,  0.9700,  0.6238,  0.0647, -0.7773, -0.9929,\n",
            "          0.2333,  0.8292, -0.5084,  0.8082, -0.6704,  0.9926,  0.1505,  0.5175,\n",
            "          0.6172,  0.9755,  0.1185, -0.7327,  0.5667, -0.0179,  0.4042,  0.8360,\n",
            "         -0.2250, -0.9461, -0.4229, -0.6062, -0.2839, -0.4795,  0.8917,  0.2681,\n",
            "          0.9974,  0.6812,  0.7628,  0.4134,  0.7280, -0.5119, -0.2430,  0.6482,\n",
            "         -0.9960,  0.7383, -0.1586, -0.6884,  0.2625, -0.8523, -0.6258, -0.1150,\n",
            "         -0.2533,  0.1513, -0.7794, -0.7013,  0.0112, -0.6645,  0.8189, -0.4984,\n",
            "         -0.9506,  0.8508, -0.6979,  0.4227,  0.8007,  0.1287, -0.3037,  0.8515,\n",
            "         -0.2992, -0.7329,  0.5531, -0.1719, -0.5734,  0.6480,  0.1827,  0.7931,\n",
            "          0.4267, -0.0589,  0.8387,  0.2542, -0.6358,  0.5568, -0.2530,  0.5097,\n",
            "          0.7660, -0.5707,  0.6570,  0.4823, -0.4731, -0.4314,  0.0809,  0.3130,\n",
            "          0.9783, -0.9908,  0.9790,  0.3344, -0.3488, -0.9832, -0.1199,  0.1494,\n",
            "          0.7665, -0.1304,  0.0951, -0.1962, -0.7031,  0.6769, -0.9976, -0.8247,\n",
            "         -0.6334,  0.5883,  0.6127, -0.9894, -0.4234,  0.3577, -0.0276, -0.2768,\n",
            "          0.9572, -0.2996, -0.7687, -0.9191, -0.9232,  0.0867,  0.5217, -0.7024,\n",
            "          0.4841,  0.2670, -0.6912, -0.5649,  0.4203,  0.5962, -0.4946, -0.3211,\n",
            "          0.6779, -0.9976,  0.5665, -0.1211, -0.7219,  0.6928, -0.8282,  0.6801,\n",
            "          0.3889, -0.9680,  0.4821,  0.1587,  0.5735,  0.7287, -0.6813,  0.5673,\n",
            "          0.6600, -0.5220,  0.9099, -0.0187,  0.0558,  0.1145,  0.9499,  0.6413,\n",
            "          0.6746, -0.1296, -0.8425, -0.8262, -0.1050, -0.8025,  0.0520,  0.3954]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluation... :   0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "02f80e5f64814c3082ae935a9072716c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6729,  0.9999,  0.8944,  ...,  0.7976, -0.6764, -0.5604],\n",
            "        [ 0.6210,  1.0000,  0.9214,  ...,  0.8187, -0.4707, -0.7462],\n",
            "        [ 0.8621,  1.0000,  0.6607,  ..., -0.4294,  0.6489, -0.8221],\n",
            "        ...,\n",
            "        [ 0.0939,  1.0000,  0.8549,  ...,  0.4233, -0.5605, -0.7081],\n",
            "        [ 0.2802,  0.9999, -0.3604,  ..., -0.8203,  0.6355, -0.7705],\n",
            "        [-0.5083,  0.9981, -0.8717,  ..., -0.7825,  0.2527,  0.1501]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1057,  1.0000, -0.4271,  ..., -0.8840,  0.7042, -0.7302],\n",
            "        [ 0.3540,  1.0000,  0.7281,  ..., -0.5398, -0.1771, -0.8308],\n",
            "        [ 0.4475,  1.0000,  0.8435,  ..., -0.4109,  0.4867, -0.9777],\n",
            "        ...,\n",
            "        [ 0.0412,  1.0000,  0.2432,  ..., -0.6598,  0.1711, -0.9141],\n",
            "        [-0.2685,  1.0000,  0.4085,  ..., -0.8202,  0.3495, -0.8559],\n",
            "        [ 0.5636,  1.0000,  0.8466,  ..., -0.5354,  0.5686, -0.9845]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4891,  1.0000,  0.9126,  ...,  0.8008, -0.6031, -0.5375],\n",
            "        [ 0.2770,  0.9999,  0.9333,  ...,  0.5481, -0.3183, -0.6933],\n",
            "        [ 0.4827,  1.0000,  0.8678,  ...,  0.6911, -0.4580, -0.7824],\n",
            "        ...,\n",
            "        [-0.1575,  1.0000, -0.0843,  ..., -0.8731,  0.7441, -0.8839],\n",
            "        [-0.5082,  0.9715, -0.8185,  ..., -0.9174,  0.2946, -0.0696],\n",
            "        [ 0.3409,  1.0000,  0.7374,  ..., -0.3224,  0.3059, -0.9742]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1271,  1.0000, -0.2117,  ..., -0.6066, -0.2018, -0.9247],\n",
            "        [ 0.0132,  1.0000,  0.7493,  ..., -0.3856,  0.4326, -0.9735],\n",
            "        [ 0.3150,  1.0000, -0.0321,  ..., -0.8520,  0.5321, -0.9658],\n",
            "        ...,\n",
            "        [ 0.5900,  1.0000,  0.8901,  ...,  0.8222, -0.6215, -0.5196],\n",
            "        [-0.0880,  0.9954, -0.7823,  ..., -0.9283,  0.6783, -0.5411],\n",
            "        [ 0.5708,  1.0000,  0.8876,  ...,  0.8293, -0.7478, -0.4838]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4144,  1.0000,  0.7510,  ...,  0.2471, -0.1084, -0.7220],\n",
            "        [ 0.3800,  1.0000,  0.8747,  ...,  0.7772, -0.2732, -0.7502],\n",
            "        [-0.3097,  0.9992, -0.8255,  ..., -0.8120,  0.3604, -0.0286],\n",
            "        ...,\n",
            "        [ 0.3070,  1.0000,  0.5312,  ...,  0.0061, -0.2825, -0.9392],\n",
            "        [ 0.5210,  0.9998,  0.9174,  ...,  0.7292, -0.6383, -0.4071],\n",
            "        [ 0.6344,  0.9999,  0.9508,  ...,  0.7207, -0.5755, -0.5900]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4786,  1.0000,  0.8915,  ...,  0.8240, -0.6307, -0.4840],\n",
            "        [ 0.6313,  1.0000,  0.7632,  ...,  0.5808, -0.6294, -0.8050],\n",
            "        [ 0.4292,  1.0000, -0.8719,  ..., -0.8806,  0.6545, -0.5943],\n",
            "        ...,\n",
            "        [ 0.8501,  1.0000,  0.2849,  ..., -0.5577,  0.6819, -0.7658],\n",
            "        [ 0.1832,  1.0000,  0.1140,  ..., -0.3105,  0.0645, -0.9089],\n",
            "        [-0.2715,  1.0000,  0.2845,  ..., -0.8039,  0.3701, -0.9027]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0410,  1.0000, -0.5316,  ..., -0.8321,  0.2305, -0.8450],\n",
            "        [-0.3288,  0.9751, -0.9292,  ..., -0.9489,  0.1581,  0.2820],\n",
            "        [ 0.5369,  0.9999,  0.8774,  ...,  0.8588, -0.6953, -0.4367],\n",
            "        ...,\n",
            "        [-0.1537,  1.0000, -0.1280,  ..., -0.8327, -0.1555, -0.7622],\n",
            "        [ 0.5238,  0.9999,  0.9013,  ...,  0.8491, -0.7543, -0.4186],\n",
            "        [-0.1432,  1.0000, -0.6069,  ..., -0.8176,  0.2660, -0.4421]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5883,  1.0000,  0.9042,  ...,  0.8160, -0.5819, -0.6148],\n",
            "        [ 0.6155,  1.0000,  0.9243,  ...,  0.8595, -0.6308, -0.5991],\n",
            "        [ 0.6933,  1.0000,  0.9295,  ...,  0.8096,  0.0849, -0.9439],\n",
            "        ...,\n",
            "        [ 0.4939,  0.9999,  0.9194,  ...,  0.8311, -0.6999, -0.4476],\n",
            "        [ 0.3372,  1.0000,  0.8803,  ...,  0.6138, -0.2011, -0.8892],\n",
            "        [ 0.4985,  1.0000,  0.7845,  ...,  0.2963, -0.2542, -0.7925]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6045,  1.0000,  0.9235,  ...,  0.8524, -0.6379, -0.5853],\n",
            "        [ 0.3066,  1.0000, -0.7705,  ..., -0.8503,  0.4591, -0.7574],\n",
            "        [-0.7758,  0.5053, -0.7589,  ..., -0.9196,  0.3132, -0.3352],\n",
            "        ...,\n",
            "        [ 0.5427,  1.0000,  0.9027,  ...,  0.7995, -0.6017, -0.4623],\n",
            "        [-0.3954,  0.9991, -0.8365,  ..., -0.9234,  0.5905,  0.1785],\n",
            "        [ 0.4352,  0.9998,  0.8913,  ...,  0.7873, -0.6733, -0.4244]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0954,  0.9984, -0.9161,  ..., -0.8965,  0.2823, -0.1643],\n",
            "        [ 0.2744,  1.0000,  0.1626,  ..., -0.8413,  0.6396, -0.9120],\n",
            "        [ 0.4826,  0.9999,  0.8925,  ...,  0.8185, -0.7069, -0.5078],\n",
            "        ...,\n",
            "        [ 0.6049,  1.0000,  0.8433,  ...,  0.7672, -0.6758, -0.6424],\n",
            "        [ 0.5103,  1.0000,  0.8602,  ...,  0.6569, -0.3901, -0.4281],\n",
            "        [ 0.7022,  1.0000,  0.9242,  ...,  0.8056,  0.0520, -0.9434]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0260,  0.9999, -0.8253,  ..., -0.8906,  0.2794, -0.0679],\n",
            "        [-0.2929,  0.9882, -0.8643,  ..., -0.9394,  0.3503, -0.0558],\n",
            "        [-0.6075,  0.9996, -0.9439,  ..., -0.9607,  0.0379, -0.2622],\n",
            "        ...,\n",
            "        [ 0.5764,  1.0000,  0.8792,  ...,  0.4243, -0.2694, -0.9010],\n",
            "        [ 0.8409,  1.0000, -0.2906,  ..., -0.4986,  0.4790, -0.9132],\n",
            "        [ 0.4251,  1.0000,  0.9141,  ...,  0.8115, -0.6660, -0.4163]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5848,  1.0000,  0.9274,  ...,  0.3896, -0.0555, -0.8302],\n",
            "        [-0.2038,  0.9996, -0.8949,  ..., -0.9170,  0.4213, -0.1506],\n",
            "        [-0.5340,  0.9999, -0.7947,  ..., -0.8885,  0.2686, -0.5200],\n",
            "        ...,\n",
            "        [-0.2567,  1.0000, -0.8886,  ..., -0.9089,  0.3853, -0.1548],\n",
            "        [ 0.4219,  1.0000,  0.5064,  ..., -0.6578,  0.2583, -0.9101],\n",
            "        [ 0.0838,  1.0000, -0.4684,  ..., -0.8935,  0.6341, -0.7833]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0804,  0.9998, -0.7579,  ..., -0.5809,  0.6852,  0.1180],\n",
            "        [ 0.4441,  1.0000,  0.8246,  ...,  0.3651, -0.1644, -0.8986],\n",
            "        [-0.4512, -0.3059, -0.8472,  ..., -0.9296,  0.3887,  0.1352],\n",
            "        ...,\n",
            "        [-0.6651,  1.0000, -0.8602,  ..., -0.6849,  0.7316, -0.3308],\n",
            "        [ 0.5808,  1.0000, -0.6549,  ..., -0.8456,  0.6038, -0.8564],\n",
            "        [-0.6196,  0.9999, -0.7650,  ..., -0.8064,  0.4115, -0.5270]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5534,  1.0000,  0.9304,  ...,  0.6072, -0.4677, -0.6883],\n",
            "        [ 0.5513,  1.0000,  0.8096,  ..., -0.0622, -0.0911, -0.9214],\n",
            "        [-0.4180,  0.9691, -0.9226,  ..., -0.8646, -0.0606,  0.2055],\n",
            "        ...,\n",
            "        [ 0.4332,  1.0000,  0.8243,  ...,  0.2755, -0.5818, -0.7230],\n",
            "        [ 0.1210,  1.0000,  0.6957,  ...,  0.3145,  0.5300, -0.8687],\n",
            "        [ 0.2785,  1.0000,  0.4814,  ...,  0.4620, -0.3609, -0.8827]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4019,  1.0000,  0.8444, -0.9477, -0.6113,  0.9320,  0.8151,  0.9127,\n",
            "         -0.9985, -0.7273,  0.9179, -0.7927,  0.4130,  0.9995,  0.2537, -0.4742,\n",
            "          0.8673, -0.9813,  0.8213, -0.5848,  0.5776, -0.7734,  0.9288, -0.3564,\n",
            "          0.8248,  0.8724, -0.6011,  0.6495, -0.0324,  0.5196, -0.6887, -0.5909,\n",
            "          0.9177,  0.8135,  0.9267, -0.9710, -0.4521, -0.9655, -0.9856, -0.9980,\n",
            "         -0.7198, -0.6069,  0.9997, -0.8002,  0.9982, -0.9814,  0.4535, -0.3768,\n",
            "          0.8370,  0.4635, -0.8627,  0.9854,  0.8373,  0.9624, -0.6944, -0.9253,\n",
            "         -0.7795,  0.4918, -0.9011, -0.5088,  0.9097,  0.7892, -0.6945, -0.1489,\n",
            "         -0.9468, -0.7355,  0.6891,  0.6339, -0.8650, -0.9792,  0.9112, -0.9603,\n",
            "          0.7866, -0.2087, -0.6855,  0.9058, -0.8845,  0.8583, -0.8963,  0.9930,\n",
            "          0.7657,  0.7199,  0.7554, -1.0000,  0.8390, -0.9303,  0.9947, -0.9900,\n",
            "         -0.9840,  0.8566,  0.8608,  0.8506,  0.9026, -0.2078, -0.7804, -0.9602,\n",
            "         -0.6895,  0.7569, -0.9990,  0.8420,  0.7056,  0.8096, -0.6966, -0.7408,\n",
            "         -0.9996,  0.6368, -0.5415, -0.6561, -1.0000, -0.8586, -0.8109, -0.9489,\n",
            "         -0.6983,  0.9389,  0.5865,  0.9999,  0.9496,  0.9989, -1.0000, -0.9893,\n",
            "          0.3994,  0.9564, -0.7565, -0.2590,  0.6600, -0.9813,  0.1983, -0.9988,\n",
            "          0.7418, -0.9536, -0.7011,  0.9119,  0.9491,  0.5177, -0.7506,  0.5775,\n",
            "         -0.9998,  0.0206, -0.9094, -0.9917,  0.9944,  0.9311,  0.9039, -0.7922,\n",
            "         -0.4946,  0.9246,  0.9544, -0.8435, -0.2837,  0.3749, -0.8669,  0.7929,\n",
            "          0.6137, -0.6595, -1.0000,  0.4081, -0.5982,  0.9863, -0.9851,  0.9762,\n",
            "         -0.9816, -1.0000,  0.6223,  0.2683, -0.9664,  0.8614, -0.7541,  0.9576,\n",
            "         -0.7501,  0.6627,  0.8172,  0.7838,  0.3791, -0.7864, -0.4367, -0.9038,\n",
            "          0.8542, -0.7396, -0.7901, -0.9823,  0.9868, -0.7575,  0.9790, -0.9707,\n",
            "         -0.8559,  0.7142,  0.4570, -1.0000,  0.9489,  0.4443,  0.6808,  0.8744,\n",
            "          0.5948, -0.5174,  0.5776, -0.1666, -0.6031,  0.7612, -0.5693,  0.9424,\n",
            "          0.4635, -0.9995,  0.9414,  0.9885,  0.4740, -0.5829,  0.1104,  0.9923,\n",
            "         -0.9981, -0.8110,  0.0580, -0.8304,  0.5610,  0.6814, -0.6638, -0.8607,\n",
            "          0.6471,  0.6278, -0.1221, -0.7325,  0.6972,  0.8338, -0.5603,  0.6275,\n",
            "          0.8641,  0.9996, -0.8731, -0.7114,  0.7903, -0.9997,  0.9174,  0.2494,\n",
            "         -0.4140, -0.8035,  0.9869,  0.8968,  0.8390,  0.9739, -0.9770, -0.2979,\n",
            "         -0.8374,  0.4912, -0.5141, -0.2918,  1.0000, -0.9927,  0.9910,  0.9017,\n",
            "          0.4115, -0.2935,  0.5615,  0.3977, -0.5205, -0.2221, -0.8534,  0.9962,\n",
            "         -0.8240, -0.9831,  0.7560, -0.1223, -0.9381, -0.9338,  0.9342, -0.7112,\n",
            "          0.9921,  1.0000,  0.8114,  0.5642,  0.8289,  0.7796,  0.8587, -0.9910,\n",
            "          0.9643,  1.0000, -0.9744,  0.5360,  1.0000,  0.8876, -0.1035, -0.7021,\n",
            "          0.6458, -0.9884, -0.5539, -0.6606, -0.5969, -0.5316,  0.0180, -0.9553,\n",
            "         -0.9995, -0.9932,  0.9828, -0.8081, -0.8848,  0.7725, -0.2674,  0.0115,\n",
            "         -0.8600,  0.9955, -0.8684,  1.0000,  0.6820, -0.7722, -0.9760, -0.5885,\n",
            "          0.7903,  0.3244,  0.9994,  0.0786, -0.6554,  0.7130,  0.7186,  0.5203,\n",
            "          0.9665, -0.7970,  0.7829,  0.3127,  0.3768, -0.9787, -0.5532, -0.9612,\n",
            "          0.8849,  0.9852,  0.7216, -0.1584,  0.9808,  0.9296, -1.0000,  0.9994,\n",
            "          0.9785, -0.9965,  0.8868, -0.4512,  0.9469,  0.1158,  0.7077, -0.9416,\n",
            "         -0.9339, -0.9968,  0.9005,  0.3564, -0.8784,  0.3602, -0.9674,  0.8240,\n",
            "          0.4455,  0.8793, -0.2939, -0.0294, -0.9967,  0.7712,  0.8639, -0.3991,\n",
            "          0.8904,  0.9937, -0.2023,  1.0000, -0.8968, -0.1493,  0.3131,  0.6760,\n",
            "          0.7733,  0.4938, -0.4285,  0.4204, -1.0000,  0.5522, -0.6986,  0.2600,\n",
            "          0.5181, -0.9901,  0.4275, -0.2760,  0.3333, -0.4372,  0.5876,  0.6927,\n",
            "          0.9996,  0.3656, -0.5528, -0.7919,  0.0985,  0.2835,  0.9125,  0.8395,\n",
            "          0.9911, -0.8456, -0.2343,  0.8110,  0.1908, -0.8400,  0.0733,  0.6217,\n",
            "          0.4226,  0.9804,  0.8466, -0.6681, -0.6538,  0.8487, -0.9980,  1.0000,\n",
            "          0.6387,  0.7569,  0.9548, -0.5389,  0.7631,  0.4654,  0.6935, -0.7896,\n",
            "          0.9913,  0.8504,  0.8427,  0.1503,  0.2393, -0.3770, -0.7829,  0.7620,\n",
            "          0.7304, -0.6127, -0.9803,  0.9951, -0.9759,  0.5585, -0.3724,  0.9302,\n",
            "          0.9333, -0.6733, -0.9618, -0.5782,  0.2667, -0.8179, -0.9300, -0.9936,\n",
            "         -0.2622, -0.9425,  0.9999, -0.9933,  0.7515, -0.9677, -0.8683,  0.8370,\n",
            "         -0.4829, -0.6288, -0.8940, -0.2622, -0.6332,  0.8714,  0.2759,  0.9223,\n",
            "         -0.6830,  0.2798,  0.6707, -0.1272,  0.3929,  0.9568, -0.7272, -0.9845,\n",
            "         -0.8358, -0.7752, -0.8104,  0.9693, -0.9503, -0.9012,  1.0000, -0.9925,\n",
            "         -0.3095, -0.3887, -0.9986,  0.5578, -0.6538, -0.9646, -0.8100, -0.7883,\n",
            "          0.8167,  0.9689,  0.9995,  0.5297, -0.0309, -0.9407, -0.5964,  0.9990,\n",
            "         -0.9901, -0.6544,  0.5401, -0.9970,  0.9468,  0.5745, -0.4270,  0.8910,\n",
            "         -0.8950,  0.9726,  0.5954, -0.9983,  0.5508,  0.8230, -0.1066,  0.9199,\n",
            "          0.5162, -0.0885, -0.9724,  0.2747,  0.9997,  0.6272, -0.8645,  0.2831,\n",
            "          0.8956,  0.8871,  1.0000, -0.9867,  0.9079,  0.9997, -0.4577,  0.7200,\n",
            "          0.2805, -0.8642, -0.0564,  0.5419, -0.9785,  0.9999, -0.4591, -0.9875,\n",
            "         -1.0000,  0.7363, -0.9299,  0.8187,  0.9905,  0.7841,  0.8671,  0.6249,\n",
            "         -0.9989,  0.1300, -0.7189, -0.9999, -0.9998,  0.8963,  0.6069,  0.5134,\n",
            "          0.8858, -0.4878, -0.7412,  0.9998,  0.9632, -1.0000, -0.4308,  0.4190,\n",
            "          0.9854, -0.8593,  0.8309,  0.3784,  0.6273, -0.5079, -1.0000, -0.7295,\n",
            "          0.9852, -0.4421,  0.3575,  0.9998,  0.8233,  0.5007, -0.9729,  0.4942,\n",
            "          0.8258, -1.0000, -0.7296,  0.9999, -0.5897, -0.3768, -0.6171,  0.7518,\n",
            "          0.8241,  0.7821,  0.6745, -0.9985,  0.9956,  0.9446, -0.6385,  0.9976,\n",
            "         -0.4195, -0.7586, -0.8797, -0.8756,  0.8821, -0.7284,  0.6979, -0.4775,\n",
            "          0.9864,  0.8925, -0.4059,  0.8467,  0.9530, -0.9101, -0.5467,  0.9209,\n",
            "          0.6767,  0.3747,  0.9532, -0.6313, -0.8119, -0.6939,  0.8535,  0.9491,\n",
            "         -0.9999,  0.9591, -0.7912, -0.9481,  0.8862, -0.6300, -0.6950, -0.4737,\n",
            "         -0.3645, -0.8589,  0.0393,  0.9719,  0.8451,  0.8371, -0.9896, -0.9999,\n",
            "         -0.8312, -0.7782, -0.8988, -0.7552,  0.2861,  0.9413,  0.6049,  0.2429,\n",
            "          0.4070,  0.9998, -0.6011,  0.9931, -0.9522,  0.9538, -0.9936,  0.6272,\n",
            "          0.6306, -0.9644, -0.7489,  0.9867, -0.5746,  0.8529, -0.9828,  0.8049,\n",
            "          1.0000, -0.8995, -0.7422,  0.8743, -0.9352,  0.9181,  0.1620,  0.9948,\n",
            "         -1.0000,  0.9933,  0.3296,  0.6249,  0.6369,  0.7796,  0.5889, -0.7263,\n",
            "         -0.6619, -0.9956,  0.4731,  0.8291, -0.6967,  0.7201,  0.9318, -0.9074,\n",
            "         -0.9993, -0.8759,  0.5585,  0.9373, -0.7630, -0.9982,  0.9829, -0.6669,\n",
            "          0.9866,  0.3392, -0.7928, -0.4573, -0.5764, -0.7639,  0.8328,  0.7710,\n",
            "          0.9465,  0.6561, -0.9014, -0.7361, -0.4557, -0.9165,  0.8964, -0.0703,\n",
            "          0.0439,  0.8758,  0.8995,  0.9841,  0.6969,  0.0467,  0.7717, -0.8177,\n",
            "         -0.8285, -0.9997,  0.9994,  0.9620, -0.8923, -0.9998,  0.9615,  0.5873,\n",
            "         -0.5652,  0.7821, -0.5193, -0.8581,  0.2811,  0.8701, -1.0000, -0.0326,\n",
            "          0.6752, -0.6567, -0.6369, -0.9997, -0.4479,  0.3691, -0.4521,  0.6111,\n",
            "          0.9991, -0.5645, -0.9753, -0.9741,  0.3500,  0.8008,  0.4330, -0.9741,\n",
            "         -0.7888,  0.9424, -0.9990,  0.8403, -0.6204, -0.6408,  0.6149,  0.9010,\n",
            "          0.9376, -1.0000,  0.9177, -0.8015,  0.9423, -0.7221,  0.6912,  0.6179,\n",
            "          0.6778, -0.9990,  0.9188,  0.5224,  0.8129,  0.6918,  0.9326, -0.3539,\n",
            "         -0.9236, -0.7615,  0.9806,  0.9721, -0.7435,  0.7632,  0.9995, -0.7763,\n",
            "          0.6431,  0.6759,  0.2721, -0.9993, -0.9195,  0.0877, -0.5770, -0.8388]],\n",
            "       device='cuda:0')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training... :   0%|          | 0/127 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "86e0e04f92c34c38b98de2716e28e376"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3743,  0.9997, -0.8514,  ..., -0.9266,  0.3656, -0.0620],\n",
            "        [ 0.6860,  1.0000,  0.9364,  ...,  0.8646,  0.3008, -0.9215],\n",
            "        [ 0.5302,  0.9996,  0.9131,  ...,  0.6488, -0.6415, -0.3833],\n",
            "        ...,\n",
            "        [-0.0071,  1.0000, -0.3579,  ..., -0.8273,  0.4428, -0.9133],\n",
            "        [ 0.6895,  1.0000, -0.3419,  ..., -0.7143,  0.6782, -0.7141],\n",
            "        [ 0.6051,  1.0000,  0.7783,  ...,  0.8023, -0.5238, -0.3441]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0712,  0.9969, -0.8153,  ..., -0.9263,  0.3644, -0.3457],\n",
            "        [ 0.5078,  1.0000,  0.9005,  ...,  0.7489, -0.5903, -0.7818],\n",
            "        [-0.2725,  0.9795, -0.9144,  ..., -0.9499,  0.0464, -0.0561],\n",
            "        ...,\n",
            "        [ 0.7319,  1.0000, -0.1083,  ..., -0.7247,  0.8076, -0.8786],\n",
            "        [ 0.6404,  1.0000,  0.9091,  ...,  0.8019, -0.5689, -0.6785],\n",
            "        [ 0.6321,  1.0000,  0.8593,  ...,  0.7821, -0.5826, -0.5587]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7399,  1.0000, -0.4083,  ..., -0.6449,  0.7603, -0.8437],\n",
            "        [ 0.4509,  1.0000,  0.8508,  ...,  0.7419, -0.5001, -0.5548],\n",
            "        [ 0.6315,  1.0000,  0.9510,  ...,  0.8678, -0.3108, -0.8402],\n",
            "        ...,\n",
            "        [ 0.2072,  0.9995,  0.9194,  ...,  0.7495, -0.7003, -0.4977],\n",
            "        [ 0.5825,  1.0000,  0.8502,  ...,  0.8242, -0.7314, -0.4588],\n",
            "        [ 0.6802,  0.9998,  0.8161,  ...,  0.8110, -0.7499, -0.5196]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6165,  0.9999,  0.8366,  ...,  0.8208, -0.6726, -0.5297],\n",
            "        [ 0.5766,  0.9981,  0.9203,  ...,  0.4877, -0.2492, -0.8400],\n",
            "        [ 0.3246,  1.0000,  0.7030,  ...,  0.6704, -0.1785, -0.6264],\n",
            "        ...,\n",
            "        [ 0.3913,  0.9999, -0.8234,  ..., -0.7952,  0.4445, -0.8281],\n",
            "        [ 0.6364,  1.0000,  0.6978,  ...,  0.3263, -0.3060, -0.8981],\n",
            "        [-0.0199,  0.9868, -0.8989,  ..., -0.9199,  0.4929, -0.2980]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2696,  0.9988, -0.8994,  ..., -0.8743,  0.3112, -0.0902],\n",
            "        [ 0.6417,  1.0000,  0.9597,  ...,  0.7142,  0.1375, -0.9126],\n",
            "        [-0.3355,  0.9960, -0.8716,  ..., -0.8988,  0.3792,  0.0373],\n",
            "        ...,\n",
            "        [ 0.2896,  1.0000,  0.9330,  ...,  0.6646, -0.5465, -0.7861],\n",
            "        [ 0.6891,  1.0000,  0.8174,  ...,  0.7790, -0.6909, -0.5083],\n",
            "        [ 0.4583,  1.0000,  0.9503,  ...,  0.8396, -0.3002, -0.6039]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5955,  1.0000,  0.9393,  ...,  0.5552, -0.4672, -0.6319],\n",
            "        [-0.0021,  0.9998,  0.9258,  ...,  0.0705, -0.4575, -0.8127],\n",
            "        [ 0.0188,  0.9697, -0.4380,  ..., -0.8307, -0.1211, -0.2913],\n",
            "        ...,\n",
            "        [ 0.4845,  1.0000,  0.8167,  ...,  0.3926, -0.7182, -0.4059],\n",
            "        [-0.2389,  0.9999, -0.5422,  ..., -0.8051,  0.1416, -0.0539],\n",
            "        [-0.6557,  0.9408, -0.9086,  ..., -0.9228,  0.2600, -0.0475]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1830,  0.9990, -0.8974,  ..., -0.8394,  0.1234,  0.1087],\n",
            "        [ 0.3611,  1.0000,  0.9332,  ...,  0.8460, -0.5802, -0.6887],\n",
            "        [ 0.6341,  1.0000,  0.8839,  ...,  0.8568, -0.6622, -0.5531],\n",
            "        ...,\n",
            "        [ 0.5968,  1.0000,  0.9228,  ...,  0.8940, -0.6142, -0.5672],\n",
            "        [ 0.5917,  1.0000,  0.7388,  ...,  0.8022, -0.4863, -0.4016],\n",
            "        [-0.0824,  0.9999, -0.8364,  ..., -0.8538,  0.4660, -0.4393]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1439,  1.0000, -0.7124,  ..., -0.8051,  0.2180, -0.3067],\n",
            "        [ 0.6691,  1.0000,  0.8592,  ...,  0.9049, -0.5709, -0.3594],\n",
            "        [ 0.4514,  1.0000,  0.8427,  ...,  0.8555, -0.8315, -0.4105],\n",
            "        ...,\n",
            "        [-0.4289,  0.9973, -0.9013,  ..., -0.9006,  0.2980, -0.0566],\n",
            "        [-0.5940,  0.9223, -0.9446,  ..., -0.9328, -0.0878,  0.3620],\n",
            "        [-0.1590,  0.9975, -0.9026,  ..., -0.8756,  0.2968, -0.4175]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5270,  0.9959, -0.5722,  ..., -0.7070,  0.1604, -0.2770],\n",
            "        [ 0.3498,  1.0000,  0.8275,  ...,  0.7753, -0.5477, -0.3757],\n",
            "        [-0.0011,  0.9999, -0.6981,  ..., -0.9456,  0.5991, -0.8042],\n",
            "        ...,\n",
            "        [-0.2327,  0.8889, -0.9606,  ..., -0.9635,  0.3135,  0.2717],\n",
            "        [ 0.5964,  1.0000,  0.7036,  ...,  0.4722, -0.5930, -0.5664],\n",
            "        [-0.0393,  0.9970, -0.9104,  ..., -0.8927,  0.2055, -0.2443]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5620,  1.0000,  0.8281,  ...,  0.6412, -0.7077, -0.3766],\n",
            "        [-0.2702,  0.9768, -0.8889,  ..., -0.9115,  0.1920,  0.0928],\n",
            "        [ 0.5605,  0.9999,  0.9255,  ...,  0.8652, -0.4792, -0.5629],\n",
            "        ...,\n",
            "        [ 0.5447,  1.0000,  0.9033,  ...,  0.7761, -0.0689, -0.7797],\n",
            "        [ 0.5138,  0.9999,  0.9084,  ...,  0.8249, -0.4893, -0.6370],\n",
            "        [ 0.7622,  1.0000,  0.8928,  ...,  0.4754, -0.4221, -0.7121]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4598, -0.9109, -0.8844,  ..., -0.9348,  0.2130,  0.2307],\n",
            "        [ 0.7364,  1.0000,  0.8039,  ...,  0.7621, -0.3966, -0.6247],\n",
            "        [ 0.2753,  0.9986, -0.1156,  ..., -0.8560,  0.0834, -0.8538],\n",
            "        ...,\n",
            "        [ 0.5040,  0.9990,  0.9292,  ...,  0.6331, -0.4815, -0.6524],\n",
            "        [ 0.7401,  1.0000,  0.9003,  ...,  0.6827, -0.7214, -0.5930],\n",
            "        [-0.1069,  0.9996,  0.0280,  ..., -0.8221,  0.5196, -0.7141]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0320,  0.9996, -0.8694,  ..., -0.9306,  0.5090, -0.2040],\n",
            "        [-0.2014,  0.9994, -0.1823,  ..., -0.5280,  0.5630, -0.4811],\n",
            "        [ 0.0839,  1.0000, -0.8340,  ..., -0.8462,  0.3260, -0.2143],\n",
            "        ...,\n",
            "        [ 0.2861,  1.0000,  0.8839,  ...,  0.7550, -0.3619, -0.7749],\n",
            "        [ 0.5997,  1.0000,  0.8431,  ...,  0.7191, -0.7879, -0.3053],\n",
            "        [ 0.5014,  1.0000,  0.7564,  ...,  0.8224, -0.5340, -0.6135]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4975,  0.9999,  0.8825,  ...,  0.8388, -0.7781, -0.3632],\n",
            "        [ 0.1380,  0.9942, -0.8493,  ..., -0.9224,  0.4314, -0.3115],\n",
            "        [-0.4136,  0.8940, -0.9276,  ..., -0.8850,  0.1362,  0.5161],\n",
            "        ...,\n",
            "        [ 0.3589,  0.9997,  0.8175,  ...,  0.7627, -0.7594, -0.3013],\n",
            "        [ 0.3322,  0.9988,  0.6444,  ...,  0.0910, -0.4428, -0.5875],\n",
            "        [ 0.2157,  1.0000,  0.7081,  ...,  0.2446, -0.2234, -0.7908]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2737,  1.0000,  0.7097,  ...,  0.6159, -0.4302, -0.8426],\n",
            "        [ 0.0748,  1.0000, -0.1366,  ..., -0.6824,  0.1069, -0.8001],\n",
            "        [-0.5571,  0.0210, -0.9444,  ..., -0.9123,  0.1618,  0.2850],\n",
            "        ...,\n",
            "        [ 0.5952,  0.9999,  0.8938,  ...,  0.8529, -0.7191, -0.5259],\n",
            "        [-0.2452,  0.9943, -0.9335,  ..., -0.9519,  0.2986, -0.0221],\n",
            "        [ 0.5441,  0.9996,  0.8828,  ...,  0.6948, -0.6884, -0.1876]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6546,  0.9996,  0.7572,  ...,  0.7339, -0.8453, -0.3822],\n",
            "        [-0.0618,  0.9859, -0.9184,  ..., -0.8792,  0.3337,  0.0670],\n",
            "        [ 0.7080,  0.9999,  0.8414,  ...,  0.8061, -0.7847, -0.2452],\n",
            "        ...,\n",
            "        [-0.2267,  0.9950, -0.9293,  ..., -0.8865,  0.2490,  0.1437],\n",
            "        [ 0.1986,  1.0000, -0.6716,  ..., -0.6694,  0.8533, -0.9389],\n",
            "        [ 0.5445,  0.9986,  0.8842,  ...,  0.5887, -0.6561, -0.6196]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5079,  0.9995,  0.8198,  ...,  0.8903, -0.7298, -0.0019],\n",
            "        [-0.2454,  0.9993, -0.9032,  ..., -0.9003,  0.6094,  0.0066],\n",
            "        [ 0.5651,  0.9999,  0.9440,  ...,  0.8591, -0.6297, -0.5986],\n",
            "        ...,\n",
            "        [-0.4400,  0.6511, -0.9263,  ..., -0.7742,  0.5309,  0.4369],\n",
            "        [-0.0751,  0.9865, -0.9080,  ..., -0.8727,  0.3786,  0.2409],\n",
            "        [-0.6980,  0.9215, -0.9053,  ..., -0.8506,  0.1422,  0.1623]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5667,  0.9994, -0.8067,  ..., -0.8387,  0.3928, -0.4488],\n",
            "        [ 0.5954,  1.0000, -0.5432,  ..., -0.5936,  0.6176, -0.5134],\n",
            "        [ 0.4219,  0.9995,  0.8643,  ...,  0.8071, -0.8059, -0.3621],\n",
            "        ...,\n",
            "        [ 0.6132,  0.9999,  0.8484,  ...,  0.6111, -0.6320, -0.5957],\n",
            "        [ 0.5133,  0.9998,  0.7704,  ...,  0.8802, -0.7116, -0.5037],\n",
            "        [ 0.5266,  1.0000,  0.9611,  ...,  0.3573,  0.2983, -0.9214]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1291,  1.0000, -0.0502,  ..., -0.8165,  0.8445, -0.8286],\n",
            "        [-0.2629,  0.9999, -0.7852,  ..., -0.8111,  0.4189, -0.7825],\n",
            "        [ 0.5703,  0.9999,  0.9235,  ...,  0.8624, -0.7430, -0.4076],\n",
            "        ...,\n",
            "        [ 0.0168,  1.0000, -0.4915,  ..., -0.7144,  0.6217, -0.7778],\n",
            "        [ 0.4716,  0.9999,  0.9370,  ...,  0.8850, -0.6053, -0.3798],\n",
            "        [ 0.2072,  1.0000,  0.8462,  ...,  0.1470, -0.4044, -0.7580]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5334,  0.9999,  0.8685,  ...,  0.8379, -0.6240, -0.6399],\n",
            "        [ 0.4741,  0.9998,  0.8306,  ...,  0.7830, -0.7607, -0.1586],\n",
            "        [-0.3594,  0.9990, -0.7461,  ..., -0.9273,  0.1361,  0.3230],\n",
            "        ...,\n",
            "        [ 0.2627,  1.0000,  0.8125,  ..., -0.1936, -0.3666, -0.8360],\n",
            "        [ 0.4472,  0.9999,  0.8828,  ...,  0.7843, -0.6888, -0.3946],\n",
            "        [ 0.8022,  1.0000,  0.7463,  ...,  0.3608, -0.3205, -0.5152]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3114,  0.9891, -0.8988,  ..., -0.8954,  0.2513,  0.3043],\n",
            "        [ 0.5119,  0.9999,  0.8243,  ...,  0.8347, -0.6883, -0.3712],\n",
            "        [ 0.5373,  0.9996,  0.9210,  ...,  0.8238, -0.6317, -0.2049],\n",
            "        ...,\n",
            "        [-0.1448,  1.0000, -0.4386,  ..., -0.7774,  0.3964, -0.5218],\n",
            "        [-0.1421,  1.0000, -0.3731,  ..., -0.7926,  0.7142, -0.4667],\n",
            "        [ 0.5601,  0.9999,  0.8842,  ...,  0.7245, -0.5833, -0.6637]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7025,  1.0000,  0.7859,  ...,  0.7780, -0.6763, -0.4832],\n",
            "        [ 0.5015,  0.9998,  0.8427,  ...,  0.8619, -0.6583, -0.5547],\n",
            "        [ 0.4514,  1.0000,  0.8583,  ...,  0.7440, -0.4102, -0.3293],\n",
            "        ...,\n",
            "        [-0.5947,  0.8335, -0.9438,  ..., -0.9045,  0.2768,  0.2508],\n",
            "        [-0.5031,  0.9825, -0.9094,  ..., -0.9431,  0.0039,  0.1811],\n",
            "        [ 0.2605,  0.9997,  0.8468,  ...,  0.7498, -0.7346, -0.1267]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.8110,  0.9904, -0.9029,  ..., -0.8805,  0.4398,  0.5297],\n",
            "        [-0.3908,  1.0000, -0.6996,  ..., -0.8682,  0.2704, -0.6057],\n",
            "        [ 0.6086,  0.9994,  0.8947,  ...,  0.8244, -0.7371, -0.4613],\n",
            "        ...,\n",
            "        [-0.4315,  0.9602, -0.8950,  ..., -0.8658,  0.3433,  0.0132],\n",
            "        [ 0.4455,  0.9997,  0.8597,  ...,  0.8628, -0.7961, -0.4020],\n",
            "        [-0.5273,  0.9982, -0.5067,  ..., -0.7363, -0.0590, -0.3989]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5186,  1.0000,  0.8593,  ...,  0.8284, -0.6806, -0.3704],\n",
            "        [ 0.7218,  1.0000,  0.8825,  ...,  0.7255, -0.7881, -0.2491],\n",
            "        [ 0.6975,  1.0000, -0.5082,  ..., -0.8297,  0.6448, -0.5447],\n",
            "        ...,\n",
            "        [ 0.5532,  1.0000,  0.6935,  ...,  0.5523, -0.7113, -0.5733],\n",
            "        [ 0.0982,  0.9897, -0.8491,  ..., -0.9074,  0.0920, -0.7335],\n",
            "        [ 0.5795,  0.9999,  0.9158,  ...,  0.7793, -0.8033, -0.5656]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4922,  0.9986, -0.8566,  ..., -0.8915,  0.3474,  0.3362],\n",
            "        [ 0.3706,  0.9997,  0.8825,  ...,  0.8537, -0.7773, -0.2436],\n",
            "        [ 0.4923,  1.0000,  0.9432,  ..., -0.0171,  0.2870, -0.9754],\n",
            "        ...,\n",
            "        [-0.2368,  0.6869, -0.8987,  ..., -0.8548,  0.2309, -0.0521],\n",
            "        [ 0.3923,  0.9999,  0.8496,  ...,  0.8187, -0.7697, -0.0524],\n",
            "        [ 0.6362,  0.9999,  0.8690,  ...,  0.9026, -0.7035, -0.5266]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3315,  0.9996,  0.8605,  ...,  0.8106, -0.7449, -0.2498],\n",
            "        [ 0.6368,  1.0000,  0.9106,  ...,  0.8922, -0.7073, -0.4827],\n",
            "        [-0.5308, -0.6311, -0.9385,  ..., -0.9213, -0.0922,  0.7943],\n",
            "        ...,\n",
            "        [-0.3779,  0.9697, -0.7328,  ..., -0.8426,  0.7084,  0.2417],\n",
            "        [ 0.5441,  0.9999,  0.8695,  ...,  0.7402, -0.8095, -0.5917],\n",
            "        [ 0.3039,  0.9991,  0.8134,  ...,  0.7917, -0.7382, -0.4311]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3055,  0.9995, -0.8961,  ..., -0.9578, -0.0651, -0.2270],\n",
            "        [ 0.6344,  0.9996,  0.8687,  ...,  0.8839, -0.6065, -0.6025],\n",
            "        [ 0.4424,  0.9996,  0.7912,  ...,  0.7618, -0.8517, -0.2819],\n",
            "        ...,\n",
            "        [-0.5508,  0.9579, -0.6652,  ..., -0.8372,  0.1204, -0.4699],\n",
            "        [ 0.6805,  0.9999,  0.8474,  ...,  0.8309, -0.4139, -0.4183],\n",
            "        [-0.2243,  0.9997, -0.7289,  ..., -0.8844,  0.6684, -0.0688]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4350,  0.8510, -0.9217,  ..., -0.9176,  0.1925,  0.3473],\n",
            "        [ 0.6069,  1.0000,  0.8923,  ...,  0.8509, -0.7570, -0.5355],\n",
            "        [ 0.1017,  1.0000,  0.8249,  ...,  0.4207, -0.6684, -0.6634],\n",
            "        ...,\n",
            "        [-0.0833,  1.0000, -0.1554,  ..., -0.7842,  0.3609, -0.6165],\n",
            "        [-0.7749,  0.9849, -0.9218,  ..., -0.9451,  0.3130,  0.4049],\n",
            "        [-0.2709,  0.9577, -0.8958,  ..., -0.9137,  0.1505,  0.4098]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4783,  0.9652, -0.4779,  ..., -0.8110,  0.1181, -0.5039],\n",
            "        [-0.4190,  0.9396, -0.8963,  ..., -0.9306,  0.3179,  0.1915],\n",
            "        [-0.1124,  1.0000, -0.1238,  ..., -0.7223, -0.1181, -0.5847],\n",
            "        ...,\n",
            "        [ 0.5816,  0.9999,  0.8088,  ...,  0.8602, -0.6602, -0.2881],\n",
            "        [-0.4526,  0.6028, -0.7487,  ..., -0.7830,  0.5455, -0.1242],\n",
            "        [-0.4380,  0.9093, -0.8751,  ..., -0.8885,  0.1220,  0.3744]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3772,  0.9997,  0.8620,  ...,  0.8648, -0.7460,  0.0461],\n",
            "        [ 0.6444,  1.0000,  0.8732,  ...,  0.5527, -0.7152, -0.5571],\n",
            "        [ 0.6312,  0.9999,  0.8789,  ...,  0.8160, -0.6981, -0.4664],\n",
            "        ...,\n",
            "        [-0.3362,  0.0117, -0.8265,  ..., -0.8713,  0.3604, -0.0457],\n",
            "        [ 0.4239,  0.9997,  0.8780,  ...,  0.8449, -0.7994, -0.4051],\n",
            "        [ 0.3416,  0.9999,  0.8486,  ...,  0.8048, -0.7905, -0.2132]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4359,  0.9991,  0.7419,  ...,  0.6998, -0.8624, -0.1686],\n",
            "        [ 0.6287,  0.9999,  0.7935,  ...,  0.7543, -0.7895, -0.2290],\n",
            "        [ 0.1561,  0.9991, -0.8178,  ..., -0.8826,  0.5521, -0.4119],\n",
            "        ...,\n",
            "        [ 0.6842,  0.9997,  0.8724,  ...,  0.7933, -0.7850, -0.5575],\n",
            "        [-0.6134, -0.9896, -0.8777,  ..., -0.9376,  0.4535,  0.4840],\n",
            "        [ 0.5069,  1.0000,  0.9127,  ...,  0.8496, -0.6828, -0.5636]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5119,  0.9429, -0.9258,  ..., -0.9203,  0.1756,  0.4256],\n",
            "        [ 0.1556,  1.0000, -0.4237,  ..., -0.8266,  0.3299, -0.7060],\n",
            "        [ 0.6704,  1.0000,  0.8502,  ...,  0.8369, -0.6091, -0.5411],\n",
            "        ...,\n",
            "        [-0.5443, -0.7251, -0.9177,  ..., -0.8994,  0.1185,  0.7983],\n",
            "        [ 0.6807,  0.9999,  0.8966,  ...,  0.8203, -0.7309, -0.4229],\n",
            "        [-0.6319, -0.1497, -0.9372,  ..., -0.9579,  0.0540,  0.2987]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3677,  0.9977,  0.8012,  ...,  0.8017, -0.8215, -0.0705],\n",
            "        [ 0.5465,  0.9998,  0.9039,  ...,  0.8408, -0.7554, -0.3410],\n",
            "        [ 0.0198,  0.9993, -0.7094,  ..., -0.9176,  0.4794,  0.0572],\n",
            "        ...,\n",
            "        [ 0.6929,  1.0000,  0.4074,  ..., -0.4976,  0.4459, -0.9111],\n",
            "        [ 0.4545,  0.9993,  0.9313,  ...,  0.7770, -0.6365, -0.4264],\n",
            "        [ 0.6966,  0.9995,  0.9121,  ...,  0.7668, -0.7455, -0.4689]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2218,  1.0000,  0.8341,  ...,  0.7020, -0.7146, -0.7002],\n",
            "        [ 0.1230,  0.9978, -0.9030,  ..., -0.8243,  0.3548,  0.4649],\n",
            "        [ 0.2034,  0.9998,  0.8903,  ...,  0.7822, -0.7517, -0.1608],\n",
            "        ...,\n",
            "        [ 0.7522,  1.0000,  0.8942,  ...,  0.7684, -0.3276, -0.5652],\n",
            "        [-0.3061,  0.9930, -0.8432,  ..., -0.9029,  0.4399, -0.0551],\n",
            "        [-0.3444,  0.4630, -0.9395,  ..., -0.8875,  0.1031,  0.4328]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5683,  0.9478, -0.9053,  ..., -0.8949,  0.0211,  0.4698],\n",
            "        [-0.2303,  0.9999, -0.7501,  ..., -0.4448,  0.6095, -0.2194],\n",
            "        [ 0.5370,  0.9997,  0.8085,  ...,  0.8684, -0.7226, -0.5245],\n",
            "        ...,\n",
            "        [-0.6225, -0.1250, -0.8441,  ..., -0.9146, -0.0088,  0.1767],\n",
            "        [ 0.8393,  1.0000,  0.9694,  ...,  0.8316, -0.6063, -0.7834],\n",
            "        [ 0.5000,  0.9961,  0.8300,  ...,  0.8280, -0.7017, -0.4085]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3897,  0.9998,  0.7855,  ...,  0.7715, -0.6213, -0.5776],\n",
            "        [ 0.7089,  0.9999,  0.8878,  ...,  0.8731, -0.6007, -0.4678],\n",
            "        [ 0.5668,  0.9997,  0.6702,  ...,  0.6781, -0.5976, -0.6466],\n",
            "        ...,\n",
            "        [-0.5311,  0.8822, -0.9344,  ..., -0.8730,  0.0308,  0.3208],\n",
            "        [-0.2062,  0.9968, -0.7756,  ..., -0.7955,  0.5592, -0.1839],\n",
            "        [ 0.6699,  0.9998,  0.8411,  ...,  0.7777, -0.7004, -0.5039]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6117, -0.9436, -0.9341,  ..., -0.9275,  0.3090,  0.3255],\n",
            "        [-0.3909,  0.0459, -0.9382,  ..., -0.9222,  0.3615,  0.4638],\n",
            "        [ 0.3686,  0.9997,  0.8601,  ...,  0.6669, -0.6888, -0.6237],\n",
            "        ...,\n",
            "        [ 0.6228,  1.0000,  0.8724,  ...,  0.4389, -0.4916, -0.5492],\n",
            "        [-0.7026,  0.9953, -0.8822,  ..., -0.8726, -0.1961,  0.4148],\n",
            "        [-0.3603,  0.9951, -0.8702,  ..., -0.8990,  0.4898,  0.1403]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5784,  0.9947, -0.7977,  ..., -0.8847,  0.3827, -0.2522],\n",
            "        [ 0.8169,  1.0000,  0.7139,  ...,  0.3425, -0.2624, -0.8255],\n",
            "        [-0.4813,  0.9997, -0.7415,  ..., -0.7238,  0.4785, -0.2471],\n",
            "        ...,\n",
            "        [ 0.5660,  0.9999,  0.8895,  ...,  0.7579, -0.7353, -0.3695],\n",
            "        [ 0.2384,  1.0000,  0.9232,  ...,  0.4977, -0.5424, -0.8280],\n",
            "        [ 0.6342,  1.0000,  0.8935,  ...,  0.7302, -0.2636, -0.8021]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5100,  0.9999,  0.9265,  ...,  0.8081, -0.6829, -0.3485],\n",
            "        [ 0.5702,  1.0000,  0.7679,  ...,  0.7562, -0.3483, -0.4810],\n",
            "        [ 0.5283,  0.9998,  0.7912,  ...,  0.7981, -0.7802, -0.2928],\n",
            "        ...,\n",
            "        [-0.7712,  0.8933, -0.9124,  ..., -0.9143,  0.1500,  0.2033],\n",
            "        [ 0.2028,  0.9999, -0.8210,  ..., -0.9103,  0.7538, -0.6306],\n",
            "        [-0.4224,  0.9995, -0.7586,  ..., -0.9076,  0.5324, -0.0607]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2047,  0.6355, -0.9300,  ..., -0.8657,  0.2994,  0.0313],\n",
            "        [-0.1651,  1.0000, -0.7718,  ..., -0.7820,  0.6537, -0.6709],\n",
            "        [ 0.3904,  0.9985,  0.8487,  ...,  0.7739, -0.7179, -0.1438],\n",
            "        ...,\n",
            "        [ 0.4253,  0.9996,  0.8066,  ...,  0.8646, -0.5528, -0.5293],\n",
            "        [ 0.4785,  1.0000,  0.6911,  ...,  0.8145, -0.6383, -0.3598],\n",
            "        [ 0.1643,  1.0000,  0.8649,  ...,  0.6952, -0.4588, -0.4755]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6229,  1.0000,  0.9491,  ...,  0.6671, -0.4560, -0.5468],\n",
            "        [ 0.4455,  0.9999,  0.8829,  ...,  0.8243, -0.6933,  0.1086],\n",
            "        [ 0.6771,  1.0000,  0.8820,  ...,  0.8026,  0.2337, -0.8195],\n",
            "        ...,\n",
            "        [-0.5530,  0.9896, -0.8935,  ..., -0.9528,  0.3553, -0.2380],\n",
            "        [ 0.3951,  0.9991,  0.7809,  ...,  0.7603, -0.6794, -0.2114],\n",
            "        [-0.4113, -0.4849, -0.9631,  ..., -0.9542,  0.2023,  0.4205]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6475,  1.0000,  0.9169,  ...,  0.8109, -0.6516, -0.3626],\n",
            "        [-0.2925,  0.0681, -0.9228,  ..., -0.8890,  0.2621,  0.1359],\n",
            "        [ 0.4065,  0.9997, -0.8612,  ..., -0.8697,  0.7459, -0.4852],\n",
            "        ...,\n",
            "        [ 0.0028,  1.0000,  0.8653,  ..., -0.0789, -0.1139, -0.7975],\n",
            "        [ 0.6012,  0.9999,  0.8876,  ...,  0.8080, -0.4904, -0.5939],\n",
            "        [ 0.4933,  1.0000,  0.8181,  ...,  0.7553, -0.4747, -0.5363]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7616,  1.0000,  0.8772,  ...,  0.8004, -0.7539, -0.6669],\n",
            "        [ 0.1955,  0.9999, -0.5082,  ..., -0.5639,  0.5552, -0.6375],\n",
            "        [-0.1637, -0.8936, -0.9056,  ..., -0.8525,  0.5063,  0.2479],\n",
            "        ...,\n",
            "        [ 0.6758,  0.9998,  0.8379,  ...,  0.7821, -0.7904, -0.5055],\n",
            "        [ 0.6262,  1.0000,  0.4018,  ...,  0.0703,  0.0532, -0.9265],\n",
            "        [ 0.7106,  1.0000,  0.8978,  ...,  0.7280, -0.5210, -0.8216]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7700,  1.0000,  0.7495,  ...,  0.6726, -0.2218, -0.6508],\n",
            "        [ 0.5595,  1.0000,  0.8165,  ...,  0.5590, -0.5585, -0.6560],\n",
            "        [ 0.5675,  1.0000,  0.8895,  ...,  0.1354, -0.5170, -0.8716],\n",
            "        ...,\n",
            "        [ 0.5507,  0.9960, -0.8504,  ..., -0.9257,  0.7170,  0.1053],\n",
            "        [-0.3952, -0.7903, -0.9266,  ..., -0.9130,  0.0383,  0.3078],\n",
            "        [-0.4949, -0.8106, -0.9321,  ..., -0.9073,  0.0654,  0.4518]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4255,  1.0000,  0.8655,  ...,  0.6725, -0.5589, -0.6368],\n",
            "        [ 0.5270,  1.0000,  0.9085,  ...,  0.7384, -0.2961, -0.9139],\n",
            "        [ 0.4892,  1.0000,  0.9119,  ...,  0.3420, -0.5831, -0.8129],\n",
            "        ...,\n",
            "        [-0.3417,  0.1936, -0.9213,  ..., -0.8993, -0.0048,  0.0317],\n",
            "        [ 0.6184,  1.0000,  0.6770,  ...,  0.3988, -0.2064, -0.7480],\n",
            "        [-0.3957, -0.8624, -0.9427,  ..., -0.9524,  0.2440,  0.1675]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4749,  0.9985,  0.8718,  ...,  0.8479, -0.8514, -0.3365],\n",
            "        [ 0.7009,  0.9999,  0.9239,  ...,  0.8539, -0.7069, -0.7465],\n",
            "        [-0.5541,  0.4844, -0.9206,  ..., -0.9004,  0.5697,  0.1140],\n",
            "        ...,\n",
            "        [ 0.4994,  1.0000,  0.6192,  ...,  0.6499, -0.3832, -0.6006],\n",
            "        [-0.3324,  0.6781, -0.9503,  ..., -0.9147, -0.0172,  0.1092],\n",
            "        [ 0.5676,  1.0000,  0.8076,  ...,  0.4626, -0.2945, -0.6783]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5104,  0.5930, -0.9026,  ..., -0.9125,  0.1701,  0.6108],\n",
            "        [ 0.6296,  0.9980,  0.8653,  ...,  0.7826, -0.7907, -0.0849],\n",
            "        [-0.1200,  1.0000,  0.7361,  ..., -0.2424,  0.0497, -0.8262],\n",
            "        ...,\n",
            "        [ 0.5635,  1.0000,  0.8750,  ...,  0.4569, -0.4241, -0.8796],\n",
            "        [-0.6566,  0.9097, -0.8899,  ..., -0.9297,  0.2279, -0.1337],\n",
            "        [-0.6219,  0.9818, -0.9382,  ..., -0.8621,  0.2414,  0.2986]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2387,  0.9998,  0.0708,  ..., -0.3623, -0.2865, -0.6255],\n",
            "        [ 0.4933,  0.9999,  0.8556,  ...,  0.8250, -0.7821, -0.2167],\n",
            "        [-0.4857, -0.9966, -0.9077,  ..., -0.9084,  0.2421,  0.7209],\n",
            "        ...,\n",
            "        [-0.6702, -0.2388, -0.9161,  ..., -0.9420,  0.1994,  0.4521],\n",
            "        [ 0.3166,  1.0000,  0.5765,  ..., -0.0439, -0.5164, -0.7543],\n",
            "        [-0.2107,  0.1511, -0.9319,  ..., -0.9133,  0.1580,  0.2506]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5861, -0.9091, -0.9498,  ..., -0.9232,  0.1648,  0.4196],\n",
            "        [ 0.4538,  0.9997,  0.8558,  ...,  0.8742, -0.8354, -0.4898],\n",
            "        [-0.1876,  0.9562, -0.9041,  ..., -0.9089,  0.5702,  0.2779],\n",
            "        ...,\n",
            "        [ 0.1189,  1.0000,  0.7797,  ...,  0.6603, -0.4401, -0.6085],\n",
            "        [ 0.5690,  1.0000,  0.8501,  ...,  0.8722, -0.6171, -0.5322],\n",
            "        [ 0.7209,  1.0000,  0.9215,  ...,  0.7620, -0.6289, -0.7139]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5005, -0.9657, -0.8955,  ..., -0.8945,  0.0460,  0.5686],\n",
            "        [ 0.6961,  0.9997,  0.7256,  ...,  0.8524, -0.6447, -0.4791],\n",
            "        [ 0.1691,  0.9997,  0.6147,  ...,  0.0933, -0.6940, -0.6496],\n",
            "        ...,\n",
            "        [ 0.5616,  0.9995,  0.8268,  ...,  0.8081, -0.6977, -0.6031],\n",
            "        [-0.5218, -0.6692, -0.9132,  ..., -0.9077,  0.1479,  0.5233],\n",
            "        [-0.5404,  0.9804, -0.8879,  ..., -0.9379, -0.0020,  0.1834]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4185,  0.8746, -0.7679,  ..., -0.8630,  0.3108, -0.1947],\n",
            "        [ 0.2680,  1.0000,  0.8406,  ...,  0.2614, -0.1681, -0.6185],\n",
            "        [ 0.6283,  1.0000,  0.8945,  ...,  0.7572, -0.5281, -0.6474],\n",
            "        ...,\n",
            "        [ 0.6792,  0.9998,  0.6637,  ...,  0.6637, -0.5075, -0.5425],\n",
            "        [ 0.5579,  1.0000,  0.7505,  ...,  0.5461, -0.7078, -0.7467],\n",
            "        [ 0.4540,  0.9999,  0.8711,  ...,  0.7492, -0.7503, -0.4087]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5412,  0.9900, -0.6646,  ..., -0.8584, -0.1809,  0.4025],\n",
            "        [ 0.2156,  1.0000,  0.6841,  ...,  0.6103, -0.5224, -0.3586],\n",
            "        [-0.4852,  0.9875, -0.8767,  ..., -0.8710,  0.3807, -0.3031],\n",
            "        ...,\n",
            "        [-0.7310,  0.8766, -0.8867,  ..., -0.9121,  0.0513,  0.4658],\n",
            "        [-0.4568, -0.9953, -0.9436,  ..., -0.9183,  0.0828,  0.6450],\n",
            "        [ 0.0478,  0.9910, -0.8744,  ..., -0.7967,  0.4005, -0.1800]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5670,  1.0000,  0.8143,  ...,  0.7355, -0.4771, -0.6804],\n",
            "        [-0.4790, -0.9910, -0.9465,  ..., -0.9440,  0.3802,  0.6070],\n",
            "        [-0.6964, -0.2209, -0.8708,  ..., -0.9084, -0.0362,  0.3199],\n",
            "        ...,\n",
            "        [-0.6911,  0.6196, -0.9266,  ..., -0.8957,  0.1425,  0.5616],\n",
            "        [ 0.5467,  1.0000,  0.8652,  ...,  0.8612, -0.7894, -0.1074],\n",
            "        [ 0.5925,  1.0000,  0.8608,  ...,  0.5394, -0.2435, -0.7588]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7242,  0.9997,  0.9067,  ...,  0.8248, -0.6648, -0.5772],\n",
            "        [ 0.6518,  0.9999,  0.7984,  ...,  0.7984, -0.6877, -0.4518],\n",
            "        [-0.1777,  0.9801, -0.9056,  ..., -0.8330,  0.7028,  0.0626],\n",
            "        ...,\n",
            "        [ 0.6513,  0.9996,  0.8074,  ...,  0.7985, -0.7120, -0.2330],\n",
            "        [-0.5235,  0.5610, -0.9208,  ..., -0.9178,  0.3350,  0.4192],\n",
            "        [-0.3541,  0.9246, -0.9153,  ..., -0.9010,  0.1566,  0.2465]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3322, -0.7161, -0.9356,  ..., -0.9355,  0.1893,  0.2746],\n",
            "        [ 0.6438,  0.9999,  0.9331,  ...,  0.8988, -0.7783, -0.5656],\n",
            "        [ 0.3525,  1.0000,  0.8295,  ...,  0.7601, -0.7491, -0.4466],\n",
            "        ...,\n",
            "        [ 0.4829,  1.0000,  0.8879,  ...,  0.7905, -0.5346, -0.8043],\n",
            "        [ 0.5334,  1.0000,  0.8364,  ...,  0.8359, -0.5860, -0.5487],\n",
            "        [-0.4178,  0.7987, -0.9030,  ..., -0.8621, -0.0121,  0.2931]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4348,  0.9999,  0.9117,  ...,  0.7348, -0.8064, -0.4213],\n",
            "        [ 0.0397,  0.9989,  0.5083,  ..., -0.2786, -0.0600, -0.8031],\n",
            "        [-0.5242,  0.9957, -0.9224,  ..., -0.8800,  0.5934,  0.1518],\n",
            "        ...,\n",
            "        [-0.5050,  0.4160, -0.9196,  ..., -0.8642,  0.2005,  0.3931],\n",
            "        [-0.6224, -0.9775, -0.9273,  ..., -0.9241,  0.0646,  0.4478],\n",
            "        [-0.4516, -0.8013, -0.9474,  ..., -0.9073,  0.3332,  0.2346]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4148,  0.9999,  0.9193,  ...,  0.7731, -0.7463, -0.3860],\n",
            "        [-0.1461,  0.9904, -0.8424,  ..., -0.9167,  0.0972,  0.2058],\n",
            "        [ 0.3352,  0.9998,  0.8272,  ...,  0.7854, -0.7109, -0.5114],\n",
            "        ...,\n",
            "        [ 0.6153,  1.0000,  0.8193,  ...,  0.7787, -0.6224, -0.4336],\n",
            "        [-0.8369, -0.9898, -0.9149,  ..., -0.9026,  0.0796,  0.7300],\n",
            "        [ 0.6164,  1.0000,  0.7694,  ...,  0.8825, -0.6888, -0.6721]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4396,  0.9997,  0.7606,  ...,  0.8237, -0.8636, -0.1727],\n",
            "        [ 0.7269,  1.0000,  0.6707,  ...,  0.8255, -0.6853, -0.4261],\n",
            "        [ 0.5403,  1.0000,  0.8396,  ...,  0.8246, -0.7659, -0.2888],\n",
            "        ...,\n",
            "        [ 0.3477,  1.0000,  0.8662,  ...,  0.8456, -0.5419, -0.5253],\n",
            "        [ 0.7236,  1.0000,  0.8991,  ...,  0.7310, -0.5946, -0.3520],\n",
            "        [-0.5515,  0.7971, -0.9582,  ..., -0.9487,  0.1824,  0.5857]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2156,  0.9993, -0.8418,  ..., -0.8035,  0.0799, -0.1723],\n",
            "        [ 0.5535,  1.0000,  0.9450,  ...,  0.9113, -0.5633, -0.6190],\n",
            "        [-0.3420,  0.8923, -0.9341,  ..., -0.9366,  0.3442,  0.1558],\n",
            "        ...,\n",
            "        [-0.5907,  0.9964, -0.8707,  ..., -0.9227, -0.0214,  0.2607],\n",
            "        [ 0.5559,  0.9999,  0.8981,  ...,  0.8073, -0.7267, -0.6375],\n",
            "        [ 0.6504,  1.0000,  0.9506,  ...,  0.7883, -0.5665, -0.7940]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2835,  0.9374, -0.9076,  ..., -0.8734,  0.3986, -0.1498],\n",
            "        [-0.2535,  0.6602, -0.9219,  ..., -0.9261,  0.3739,  0.2769],\n",
            "        [ 0.6859,  0.9999,  0.9223,  ...,  0.8902, -0.6919, -0.4866],\n",
            "        ...,\n",
            "        [-0.4281,  0.2948, -0.9312,  ..., -0.8946,  0.3699,  0.3007],\n",
            "        [-0.0757,  0.9989,  0.7745,  ..., -0.4645, -0.4996, -0.5459],\n",
            "        [-0.4535,  0.9166, -0.9154,  ..., -0.9388,  0.2480,  0.4688]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3717,  1.0000,  0.9235,  ...,  0.5582,  0.1610, -0.7197],\n",
            "        [-0.4622,  0.6837, -0.8414,  ..., -0.9052,  0.1286,  0.4163],\n",
            "        [ 0.7382,  1.0000,  0.8628,  ...,  0.7056, -0.5640, -0.6243],\n",
            "        ...,\n",
            "        [ 0.4476,  1.0000,  0.9264,  ...,  0.8408, -0.7340, -0.5615],\n",
            "        [ 0.5917,  1.0000,  0.9181,  ...,  0.6838, -0.5813, -0.5945],\n",
            "        [ 0.6662,  1.0000,  0.9306,  ...,  0.7505, -0.6598, -0.6144]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7437,  1.0000,  0.8384,  ...,  0.6685, -0.5427, -0.7790],\n",
            "        [-0.6675,  0.9060, -0.9323,  ..., -0.9546,  0.3071,  0.3823],\n",
            "        [-0.7687,  0.0810, -0.9222,  ..., -0.9085,  0.1075,  0.4475],\n",
            "        ...,\n",
            "        [-0.0827,  0.9986, -0.8086,  ..., -0.9375,  0.6914, -0.4205],\n",
            "        [-0.2349, -0.5351, -0.8730,  ..., -0.8214,  0.4031,  0.4936],\n",
            "        [-0.6185,  0.9555, -0.8482,  ..., -0.8654,  0.2162, -0.1182]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1613,  1.0000, -0.2255,  ..., -0.8621,  0.4283, -0.7613],\n",
            "        [-0.4639, -0.9670, -0.8675,  ..., -0.8800,  0.2660,  0.6249],\n",
            "        [-0.1508,  0.9999, -0.8117,  ..., -0.8590,  0.0769, -0.1445],\n",
            "        ...,\n",
            "        [ 0.5863,  1.0000,  0.9133,  ...,  0.7638, -0.7073, -0.2289],\n",
            "        [ 0.6546,  1.0000,  0.9516,  ...,  0.7675, -0.3519, -0.7192],\n",
            "        [-0.2982,  0.9862, -0.9230,  ..., -0.8517, -0.2395,  0.2895]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4590,  1.0000,  0.9263,  ...,  0.6074,  0.0315, -0.7189],\n",
            "        [-0.4815,  0.8429, -0.9092,  ..., -0.8680,  0.0540,  0.2143],\n",
            "        [ 0.5273,  0.9999,  0.8774,  ...,  0.7861, -0.6373, -0.2524],\n",
            "        ...,\n",
            "        [ 0.3456,  0.9999,  0.9322,  ...,  0.8575, -0.7195, -0.4500],\n",
            "        [-0.4359,  0.3695, -0.8550,  ..., -0.8315,  0.4748,  0.5650],\n",
            "        [ 0.4401,  0.9999,  0.9090,  ...,  0.8028, -0.6624, -0.4756]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5988,  1.0000,  0.9283,  ...,  0.8824, -0.3431, -0.6235],\n",
            "        [-0.3351,  0.9915, -0.6792,  ..., -0.6673,  0.4769, -0.4920],\n",
            "        [ 0.7229,  1.0000,  0.8941,  ...,  0.9216, -0.6484, -0.5687],\n",
            "        ...,\n",
            "        [ 0.6235,  1.0000,  0.9357,  ...,  0.8144, -0.5133, -0.5911],\n",
            "        [-0.4754,  0.9143, -0.9037,  ..., -0.9038,  0.1232,  0.4469],\n",
            "        [ 0.1527,  0.6144, -0.6424,  ..., -0.8602,  0.2939, -0.4206]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4194,  1.0000,  0.8631,  ...,  0.8979, -0.5206, -0.6992],\n",
            "        [ 0.6934,  1.0000,  0.9217,  ...,  0.9224, -0.7607, -0.7455],\n",
            "        [-0.5229, -0.6662, -0.8399,  ..., -0.9417,  0.2163,  0.2756],\n",
            "        ...,\n",
            "        [-0.4175,  0.2174, -0.9150,  ..., -0.9022,  0.2685,  0.5661],\n",
            "        [-0.5116,  0.1707, -0.9322,  ..., -0.8492, -0.0920,  0.3131],\n",
            "        [ 0.5685,  1.0000,  0.8575,  ...,  0.7856, -0.2996, -0.7864]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7229,  1.0000,  0.9403,  ...,  0.8162, -0.3076, -0.8252],\n",
            "        [-0.4789,  0.9205, -0.8422,  ..., -0.9139,  0.0872,  0.4643],\n",
            "        [-0.2067, -0.8302, -0.7937,  ..., -0.9505,  0.2386,  0.6871],\n",
            "        ...,\n",
            "        [ 0.5179,  1.0000,  0.8911,  ...,  0.7301, -0.6114, -0.8013],\n",
            "        [ 0.7094,  1.0000,  0.9530,  ...,  0.8869, -0.1761, -0.8354],\n",
            "        [ 0.7426,  1.0000,  0.9615,  ...,  0.9138, -0.2797, -0.7814]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6690,  1.0000,  0.8481,  ...,  0.7695, -0.7011, -0.4222],\n",
            "        [ 0.4481,  1.0000,  0.9449,  ...,  0.7634, -0.6016, -0.5802],\n",
            "        [-0.6595, -0.7614, -0.7654,  ..., -0.8676,  0.4720,  0.3147],\n",
            "        ...,\n",
            "        [-0.6626,  0.9943, -0.8702,  ..., -0.8346,  0.1388,  0.5091],\n",
            "        [ 0.5765,  1.0000,  0.8676,  ...,  0.8604, -0.6826, -0.5264],\n",
            "        [ 0.7202,  1.0000,  0.9531,  ...,  0.8049, -0.0257, -0.8525]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2639,  0.9999, -0.8654,  ..., -0.8983,  0.4297, -0.4302],\n",
            "        [ 0.7465,  1.0000,  0.9481,  ...,  0.8536, -0.4853, -0.8083],\n",
            "        [-0.6732,  0.0730, -0.9177,  ..., -0.8656,  0.1929,  0.4994],\n",
            "        ...,\n",
            "        [ 0.7770,  1.0000,  0.9611,  ...,  0.8359, -0.2793, -0.8258],\n",
            "        [ 0.3561,  1.0000,  0.8086,  ...,  0.7309, -0.5649, -0.4574],\n",
            "        [ 0.6854,  1.0000,  0.8662,  ...,  0.7890, -0.7489, -0.6659]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2987,  0.2860, -0.6065,  ..., -0.6756,  0.3287, -0.0495],\n",
            "        [ 0.6385,  1.0000,  0.9357,  ...,  0.9193, -0.4909, -0.7179],\n",
            "        [-0.5754,  0.9966, -0.9203,  ..., -0.7679,  0.5427,  0.4766],\n",
            "        ...,\n",
            "        [ 0.6108,  1.0000,  0.9480,  ...,  0.8501, -0.3135, -0.7534],\n",
            "        [ 0.5456,  1.0000,  0.9113,  ...,  0.7315, -0.3571, -0.7168],\n",
            "        [-0.8165,  0.9947, -0.9181,  ..., -0.8487,  0.0187,  0.2098]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6333,  1.0000,  0.9477,  ...,  0.9237, -0.6286, -0.4278],\n",
            "        [ 0.5912,  1.0000,  0.9691,  ...,  0.7824, -0.3319, -0.8892],\n",
            "        [-0.3259,  1.0000, -0.4638,  ..., -0.9029,  0.1846, -0.8862],\n",
            "        ...,\n",
            "        [-0.7901,  0.7535, -0.8763,  ..., -0.7911, -0.0312,  0.5670],\n",
            "        [ 0.7177,  1.0000,  0.9054,  ...,  0.8065, -0.6889, -0.3639],\n",
            "        [-0.4919,  0.9977, -0.8394,  ..., -0.8316,  0.5105, -0.2024]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6242,  1.0000,  0.8631,  ...,  0.8044, -0.5470, -0.4462],\n",
            "        [ 0.7411,  1.0000,  0.9093,  ...,  0.9235, -0.6682, -0.4973],\n",
            "        [ 0.3619,  1.0000,  0.9526,  ...,  0.8456, -0.5488, -0.7755],\n",
            "        ...,\n",
            "        [-0.3027,  0.2487, -0.8559,  ..., -0.8278,  0.8810, -0.2489],\n",
            "        [-0.5178,  0.9045, -0.8381,  ..., -0.9247,  0.5016,  0.3045],\n",
            "        [ 0.5491,  1.0000,  0.9352,  ...,  0.8496, -0.3458, -0.7379]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4018,  0.9999, -0.8534,  ..., -0.9143,  0.7695, -0.7728],\n",
            "        [-0.3237,  0.9554, -0.8735,  ..., -0.8289, -0.2427,  0.5750],\n",
            "        [-0.2524,  0.9997, -0.7529,  ..., -0.7386,  0.7947, -0.5044],\n",
            "        ...,\n",
            "        [-0.5214, -0.7809, -0.9417,  ..., -0.9182,  0.4173,  0.3933],\n",
            "        [ 0.5526,  1.0000,  0.8918,  ...,  0.9141, -0.8145, -0.6743],\n",
            "        [-0.7058,  0.8017, -0.9325,  ..., -0.8573,  0.2054,  0.6089]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7912,  1.0000,  0.9395,  ...,  0.9217, -0.5539, -0.7042],\n",
            "        [ 0.5358,  0.9999,  0.9182,  ...,  0.9152, -0.7392, -0.5516],\n",
            "        [ 0.5701,  1.0000,  0.5377,  ...,  0.3270,  0.3937, -0.9416],\n",
            "        ...,\n",
            "        [ 0.6943,  1.0000,  0.9531,  ...,  0.8331, -0.5246, -0.7761],\n",
            "        [ 0.6878,  1.0000,  0.9347,  ...,  0.8323, -0.6769, -0.7480],\n",
            "        [ 0.6605,  1.0000,  0.8628,  ...,  0.8717, -0.7268, -0.5820]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7832,  1.0000,  0.9499,  ...,  0.8983, -0.5492, -0.7377],\n",
            "        [ 0.0710,  0.9998, -0.4691,  ..., -0.7856,  0.3911, -0.6262],\n",
            "        [ 0.7534,  1.0000,  0.9403,  ...,  0.9037, -0.6528, -0.5416],\n",
            "        ...,\n",
            "        [ 0.7015,  1.0000,  0.9705,  ...,  0.6673, -0.3650, -0.8666],\n",
            "        [ 0.6780,  1.0000,  0.8627,  ...,  0.5869, -0.2778, -0.7981],\n",
            "        [-0.2055,  0.9993, -0.4956,  ..., -0.8235,  0.2231, -0.3213]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6043,  0.4101, -0.9358,  ..., -0.9092,  0.0098,  0.6947],\n",
            "        [ 0.7652,  1.0000,  0.9218,  ...,  0.8523, -0.4503, -0.5640],\n",
            "        [ 0.6764,  1.0000,  0.8998,  ...,  0.6632, -0.5562, -0.7383],\n",
            "        ...,\n",
            "        [ 0.5315,  1.0000,  0.9231,  ...,  0.8775, -0.6577, -0.6317],\n",
            "        [ 0.5982,  1.0000,  0.9487,  ...,  0.7734, -0.3027, -0.8091],\n",
            "        [ 0.5884,  1.0000,  0.9535,  ...,  0.7633, -0.3693, -0.7580]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5632,  0.9990, -0.3666,  ..., -0.4882,  0.7372, -0.6391],\n",
            "        [-0.4316,  0.9105, -0.9234,  ..., -0.9637,  0.1358,  0.5598],\n",
            "        [-0.3644, -0.9365, -0.9173,  ..., -0.9186,  0.4226,  0.4442],\n",
            "        ...,\n",
            "        [-0.4634,  0.9979, -0.3762,  ..., -0.4288,  0.6536,  0.5734],\n",
            "        [-0.3292,  0.9978, -0.8638,  ..., -0.8615,  0.3430,  0.3552],\n",
            "        [-0.3842,  0.9982, -0.8797,  ..., -0.9023,  0.4990,  0.1998]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4712,  1.0000,  0.8998,  ...,  0.8168, -0.7326, -0.3214],\n",
            "        [-0.3994, -0.2363, -0.9168,  ..., -0.8581,  0.2759,  0.2824],\n",
            "        [-0.3129,  0.9354, -0.8779,  ..., -0.7816,  0.6434,  0.1009],\n",
            "        ...,\n",
            "        [ 0.6457,  0.9999,  0.5083,  ..., -0.1047,  0.5721, -0.8877],\n",
            "        [-0.3701,  0.9921, -0.8718,  ..., -0.8642,  0.3176,  0.2154],\n",
            "        [ 0.5552,  1.0000,  0.9265,  ...,  0.5730,  0.5191, -0.8404]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1594,  0.9969, -0.8311,  ..., -0.9143,  0.4554,  0.2437],\n",
            "        [ 0.4892,  1.0000,  0.9157,  ...,  0.8532, -0.5246, -0.7064],\n",
            "        [ 0.7432,  1.0000,  0.8211,  ...,  0.8322, -0.6857, -0.5687],\n",
            "        ...,\n",
            "        [-0.6117,  0.9041, -0.8927,  ..., -0.8434,  0.2972, -0.1624],\n",
            "        [-0.5629,  0.6046, -0.8670,  ..., -0.8844,  0.3110,  0.2834],\n",
            "        [-0.5221,  0.9015, -0.9045,  ..., -0.8940,  0.1614,  0.3728]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5025,  1.0000,  0.9638,  ...,  0.7679, -0.4554, -0.6959],\n",
            "        [ 0.6740,  1.0000,  0.8922,  ...,  0.8204, -0.5534, -0.6094],\n",
            "        [ 0.6234,  1.0000,  0.9474,  ...,  0.8695, -0.5828, -0.7035],\n",
            "        ...,\n",
            "        [-0.3751,  0.9998, -0.5381,  ..., -0.6797,  0.3953,  0.4749],\n",
            "        [ 0.5481,  1.0000,  0.9050,  ...,  0.8537, -0.5611, -0.7257],\n",
            "        [ 0.7965,  1.0000,  0.9295,  ...,  0.8514, -0.7504, -0.6674]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0721,  0.9997, -0.9026,  ..., -0.8454,  0.7047, -0.1611],\n",
            "        [ 0.6685,  1.0000,  0.8434,  ...,  0.8505, -0.6948, -0.4166],\n",
            "        [-0.6824,  0.9277, -0.8630,  ..., -0.9510,  0.4360,  0.2168],\n",
            "        ...,\n",
            "        [ 0.4614,  1.0000,  0.8274,  ...,  0.7635, -0.6132, -0.4769],\n",
            "        [ 0.4941,  1.0000,  0.8745,  ...,  0.6540, -0.5300, -0.8387],\n",
            "        [-0.5672,  0.5423, -0.9072,  ..., -0.8145,  0.1261,  0.4194]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5874,  1.0000,  0.9239,  ...,  0.8211, -0.6400, -0.7220],\n",
            "        [ 0.7758,  1.0000,  0.8590,  ...,  0.7398, -0.5855, -0.6039],\n",
            "        [-0.7393,  0.5089, -0.9102,  ..., -0.8930, -0.0049,  0.6508],\n",
            "        ...,\n",
            "        [-0.6737,  0.8864, -0.9189,  ..., -0.8406, -0.0337,  0.3536],\n",
            "        [ 0.5815,  1.0000,  0.9468,  ...,  0.8625, -0.3996, -0.8650],\n",
            "        [-0.6535,  0.9745, -0.9158,  ..., -0.8680,  0.2634,  0.4315]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6187,  0.2640, -0.8752,  ..., -0.8493,  0.3014,  0.1860],\n",
            "        [-0.5880,  0.3029, -0.8823,  ..., -0.8931,  0.4609,  0.3492],\n",
            "        [-0.5471,  0.8775, -0.8931,  ..., -0.8705,  0.2822,  0.4424],\n",
            "        ...,\n",
            "        [ 0.6028,  1.0000,  0.9413,  ...,  0.8708, -0.0456, -0.8976],\n",
            "        [ 0.6389,  1.0000,  0.9125,  ...,  0.7933, -0.6430, -0.5653],\n",
            "        [ 0.7504,  1.0000,  0.9727,  ...,  0.8550, -0.2278, -0.8188]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4721,  0.9895, -0.9358,  ..., -0.8651,  0.2359,  0.1456],\n",
            "        [-0.4452,  0.9684, -0.8779,  ..., -0.8457,  0.4451,  0.2328],\n",
            "        [ 0.6833,  1.0000,  0.9593,  ...,  0.3144,  0.2833, -0.9516],\n",
            "        ...,\n",
            "        [ 0.4054,  1.0000,  0.8436,  ...,  0.7576, -0.4610, -0.5311],\n",
            "        [-0.5252,  0.9446, -0.9160,  ..., -0.8487,  0.3411,  0.0048],\n",
            "        [ 0.3999,  1.0000,  0.8299,  ...,  0.8659, -0.7787, -0.4315]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6248,  1.0000,  0.8806,  ...,  0.8421, -0.6962, -0.5040],\n",
            "        [ 0.6433,  1.0000,  0.9006,  ...,  0.8371, -0.7002, -0.4467],\n",
            "        [ 0.5837,  1.0000,  0.9395,  ...,  0.6478, -0.2506, -0.8019],\n",
            "        ...,\n",
            "        [-0.7461,  0.8029, -0.8524,  ..., -0.8633,  0.2109,  0.6405],\n",
            "        [ 0.4567,  1.0000,  0.9281,  ...,  0.8522, -0.7508, -0.4052],\n",
            "        [-0.4381, -0.9314, -0.9303,  ..., -0.8629,  0.1164,  0.4500]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7397,  1.0000,  0.9567,  ...,  0.8261, -0.0448, -0.9145],\n",
            "        [ 0.1086,  1.0000,  0.7629,  ...,  0.3195,  0.1285, -0.8513],\n",
            "        [ 0.5699,  1.0000,  0.9229,  ...,  0.8006, -0.4438, -0.7706],\n",
            "        ...,\n",
            "        [ 0.6868,  1.0000,  0.9141,  ...,  0.8297, -0.5335, -0.6766],\n",
            "        [-0.5704, -0.9761, -0.8782,  ..., -0.8935, -0.1402,  0.6278],\n",
            "        [ 0.6301,  1.0000,  0.9446,  ...,  0.5616, -0.2502, -0.8628]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2349,  0.9984, -0.9263,  ..., -0.7769,  0.1746, -0.2206],\n",
            "        [-0.3110,  0.6488, -0.9486,  ..., -0.8812,  0.1624,  0.6393],\n",
            "        [-0.7272,  0.8680, -0.9164,  ..., -0.8752,  0.3815,  0.4709],\n",
            "        ...,\n",
            "        [ 0.6690,  1.0000,  0.9348,  ...,  0.8947, -0.6436, -0.5364],\n",
            "        [ 0.3897,  0.9999,  0.7355,  ...,  0.7202, -0.7360, -0.3921],\n",
            "        [ 0.6828,  1.0000,  0.9213,  ...,  0.8348, -0.6112, -0.7291]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5840, -0.9442, -0.9085,  ..., -0.7601, -0.0948,  0.6738],\n",
            "        [ 0.7077,  1.0000,  0.9298,  ...,  0.8550, -0.5122, -0.5913],\n",
            "        [-0.4768,  0.9408, -0.8921,  ..., -0.9121,  0.0954,  0.1838],\n",
            "        ...,\n",
            "        [-0.3339,  1.0000, -0.1742,  ..., -0.8868,  0.7552, -0.8907],\n",
            "        [-0.1916,  0.8651, -0.8488,  ..., -0.7703,  0.3282,  0.4388],\n",
            "        [ 0.6707,  1.0000,  0.8737,  ...,  0.8738, -0.6409, -0.4385]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5352,  1.0000,  0.9597,  ...,  0.8327, -0.4277, -0.5878],\n",
            "        [ 0.7033,  1.0000,  0.7895,  ...,  0.8572, -0.6184, -0.4079],\n",
            "        [ 0.7171,  1.0000,  0.8613,  ...,  0.4336, -0.1431, -0.9576],\n",
            "        ...,\n",
            "        [-0.4004,  0.4306, -0.8590,  ..., -0.9032,  0.1320,  0.2774],\n",
            "        [ 0.6867,  1.0000,  0.9150,  ...,  0.8398, -0.7822, -0.4988],\n",
            "        [ 0.8049,  1.0000,  0.8757,  ...,  0.8724, -0.3375, -0.5635]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3239, -0.9893, -0.9391,  ..., -0.8681,  0.2875,  0.1210],\n",
            "        [-0.2960, -0.8299, -0.8678,  ..., -0.8175,  0.5204,  0.4961],\n",
            "        [-0.0345,  0.9994, -0.8487,  ..., -0.9094,  0.3708, -0.2469],\n",
            "        ...,\n",
            "        [-0.7086,  0.3128, -0.8982,  ..., -0.8077, -0.0984,  0.6041],\n",
            "        [ 0.5181,  0.9999,  0.8364,  ...,  0.8578, -0.7338, -0.5017],\n",
            "        [-0.5376, -0.9333, -0.8986,  ..., -0.8776,  0.4576,  0.4171]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4457,  1.0000, -0.0414,  ..., -0.8371,  0.5478, -0.8803],\n",
            "        [ 0.5451,  1.0000,  0.9116,  ...,  0.7693, -0.5121, -0.6155],\n",
            "        [-0.4290, -0.9505, -0.9302,  ..., -0.8963,  0.2769,  0.3783],\n",
            "        ...,\n",
            "        [ 0.7199,  1.0000,  0.9527,  ...,  0.7852, -0.0283, -0.9393],\n",
            "        [-0.7645,  0.4604, -0.8896,  ..., -0.7922,  0.1935,  0.5857],\n",
            "        [ 0.6898,  1.0000,  0.9394,  ...,  0.7394, -0.3668, -0.7785]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6728,  1.0000,  0.4620,  ..., -0.7547,  0.7698, -0.9640],\n",
            "        [ 0.3820,  1.0000,  0.8921,  ...,  0.3403,  0.4037, -0.9094],\n",
            "        [-0.6170, -0.8927, -0.9230,  ..., -0.8873, -0.0815,  0.4920],\n",
            "        ...,\n",
            "        [ 0.5958,  1.0000,  0.8998,  ...,  0.8840, -0.5700, -0.4930],\n",
            "        [-0.4648,  0.9972, -0.8761,  ..., -0.8899,  0.3658,  0.1141],\n",
            "        [ 0.5401,  1.0000,  0.8565,  ...,  0.7305, -0.1682, -0.6637]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5725,  1.0000,  0.8053,  ...,  0.4372, -0.0837, -0.6748],\n",
            "        [ 0.6858,  0.9999,  0.8956,  ...,  0.8908, -0.6761, -0.6050],\n",
            "        [-0.5394, -0.7252, -0.9109,  ..., -0.9213,  0.0851,  0.7728],\n",
            "        ...,\n",
            "        [ 0.1853,  1.0000,  0.8190,  ...,  0.4467,  0.5125, -0.8160],\n",
            "        [ 0.4973,  1.0000,  0.9026,  ...,  0.8315, -0.7222, -0.5079],\n",
            "        [-0.7721, -0.0716, -0.8870,  ..., -0.9176,  0.3894,  0.4386]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6183,  0.5088, -0.9275,  ..., -0.8762,  0.0270,  0.6475],\n",
            "        [ 0.5070,  1.0000,  0.9631,  ...,  0.8238, -0.4637, -0.6550],\n",
            "        [ 0.5405,  1.0000,  0.9712,  ...,  0.5199, -0.1912, -0.7459],\n",
            "        ...,\n",
            "        [ 0.5315,  1.0000,  0.9468,  ...,  0.3991, -0.1169, -0.9449],\n",
            "        [ 0.6186,  1.0000,  0.8329,  ...,  0.8710, -0.7002, -0.7817],\n",
            "        [-0.4992,  0.9936, -0.7995,  ..., -0.9214,  0.2909,  0.4349]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6337, -0.9968, -0.9120,  ..., -0.9218,  0.1338,  0.2878],\n",
            "        [-0.5153,  0.6752, -0.9600,  ..., -0.8869,  0.5346,  0.5108],\n",
            "        [-0.5867,  0.1470, -0.9297,  ..., -0.8753,  0.1065,  0.4750],\n",
            "        ...,\n",
            "        [-0.6685,  0.9987, -0.8891,  ..., -0.9122,  0.2283, -0.1960],\n",
            "        [-0.3808, -0.9187, -0.8892,  ..., -0.9480, -0.0038,  0.5431],\n",
            "        [-0.4849, -0.0503, -0.8923,  ..., -0.8489,  0.4868,  0.3908]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3765,  0.8294, -0.8706,  ..., -0.8479,  0.4958,  0.2470],\n",
            "        [-0.4903, -0.4334, -0.7860,  ..., -0.9189,  0.1353, -0.3334],\n",
            "        [-0.2853,  0.9743, -0.9137,  ..., -0.9233,  0.1976,  0.4034],\n",
            "        ...,\n",
            "        [ 0.6435,  1.0000,  0.9468,  ...,  0.1393,  0.2992, -0.9760],\n",
            "        [-0.5126, -0.7977, -0.9403,  ..., -0.9053,  0.2338,  0.2671],\n",
            "        [ 0.7362,  1.0000,  0.9389,  ...,  0.2770,  0.3172, -0.9743]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3552, -0.6324, -0.9437,  ..., -0.9216,  0.4964,  0.4837],\n",
            "        [ 0.7967,  1.0000,  0.9402,  ...,  0.7670, -0.4733, -0.7684],\n",
            "        [-0.4618, -0.8486, -0.8969,  ..., -0.8432,  0.2317,  0.5063],\n",
            "        ...,\n",
            "        [-0.3428,  0.9831, -0.8830,  ..., -0.9211,  0.3545,  0.0214],\n",
            "        [ 0.6176,  1.0000,  0.9485,  ...,  0.8233, -0.5579, -0.7866],\n",
            "        [-0.6753,  0.3397, -0.8895,  ..., -0.8306, -0.0300,  0.1040]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6146,  0.5541, -0.8709,  ..., -0.8884,  0.2963,  0.7149],\n",
            "        [ 0.4418,  1.0000,  0.8990,  ...,  0.6741, -0.5023, -0.7330],\n",
            "        [ 0.5194,  1.0000,  0.8933,  ...,  0.7019, -0.4088, -0.6737],\n",
            "        ...,\n",
            "        [ 0.5454,  1.0000, -0.0842,  ..., -0.8256,  0.3505, -0.7937],\n",
            "        [-0.4093, -0.2137, -0.9249,  ..., -0.9216, -0.1658,  0.2129],\n",
            "        [ 0.7450,  1.0000,  0.9455,  ...,  0.9445, -0.5681, -0.7117]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1952,  0.9341, -0.8832,  ..., -0.8481,  0.4143,  0.1293],\n",
            "        [-0.3894, -0.9943, -0.9355,  ..., -0.8878,  0.2510,  0.4241],\n",
            "        [ 0.7517,  1.0000, -0.4709,  ..., -0.8291,  0.8011, -0.9184],\n",
            "        ...,\n",
            "        [-0.2189,  1.0000, -0.3459,  ..., -0.5494,  0.4372, -0.6289],\n",
            "        [ 0.4045,  1.0000,  0.8002,  ...,  0.6799, -0.2004, -0.8984],\n",
            "        [ 0.7260,  0.9999,  0.8955,  ...,  0.8127, -0.6949, -0.3965]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6507,  1.0000,  0.8958,  ...,  0.8277, -0.5207, -0.6933],\n",
            "        [ 0.6925,  0.9998, -0.2152,  ..., -0.3748,  0.6725, -0.7287],\n",
            "        [-0.5166,  0.9981, -0.8348,  ..., -0.8785,  0.2733,  0.4165],\n",
            "        ...,\n",
            "        [-0.5371, -0.4914, -0.9039,  ..., -0.9433,  0.1226,  0.4447],\n",
            "        [-0.4712,  0.4334, -0.9009,  ..., -0.7426,  0.6461,  0.0075],\n",
            "        [ 0.7029,  1.0000,  0.9151,  ...,  0.8457, -0.5076, -0.6948]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6469,  1.0000,  0.8750,  ...,  0.8658, -0.5957, -0.3489],\n",
            "        [ 0.6296,  1.0000,  0.7703,  ...,  0.0833, -0.1078, -0.9432],\n",
            "        [ 0.7723,  1.0000,  0.9370,  ...,  0.8630, -0.3044, -0.6828],\n",
            "        ...,\n",
            "        [ 0.6940,  1.0000,  0.9189,  ...,  0.4953,  0.4228, -0.9471],\n",
            "        [ 0.5620,  1.0000,  0.9109,  ...,  0.8654, -0.6973, -0.4407],\n",
            "        [-0.4002,  1.0000, -0.5392,  ..., -0.7584,  0.3572, -0.2095]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0587,  0.9882, -0.8881,  ..., -0.9450,  0.3945,  0.2330],\n",
            "        [ 0.6370,  1.0000,  0.9532,  ...,  0.7235, -0.0876, -0.9187],\n",
            "        [ 0.4297,  1.0000,  0.4730,  ..., -0.7146,  0.6258, -0.8970],\n",
            "        ...,\n",
            "        [ 0.6001,  1.0000,  0.8860,  ...,  0.7224, -0.4627, -0.6456],\n",
            "        [ 0.7157,  0.9999,  0.9533,  ...,  0.8199, -0.3277, -0.8100],\n",
            "        [ 0.1890,  0.9912, -0.8780,  ..., -0.8976,  0.4639,  0.1255]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6042,  1.0000,  0.6768,  ..., -0.5956,  0.7043, -0.9647],\n",
            "        [ 0.6820,  1.0000,  0.9375,  ...,  0.6782, -0.6009, -0.8804],\n",
            "        [-0.3548, -0.6059, -0.9556,  ..., -0.8913,  0.4533,  0.2173],\n",
            "        ...,\n",
            "        [-0.0039,  0.9998, -0.8973,  ..., -0.9060,  0.3901, -0.0898],\n",
            "        [ 0.4234,  1.0000,  0.9494,  ...,  0.7907, -0.6214, -0.5385],\n",
            "        [ 0.6736,  1.0000,  0.9212,  ...,  0.5483, -0.3961, -0.8214]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1992,  0.9997, -0.8007,  ..., -0.8725,  0.6045, -0.3243],\n",
            "        [ 0.4342,  1.0000, -0.6975,  ..., -0.6595,  0.5937, -0.5919],\n",
            "        [ 0.6442,  1.0000,  0.8928,  ...,  0.7698, -0.4043, -0.8230],\n",
            "        ...,\n",
            "        [ 0.5814,  1.0000,  0.9002,  ...,  0.3786,  0.0954, -0.9209],\n",
            "        [-0.5038, -0.7357, -0.8967,  ..., -0.9487,  0.2402,  0.3880],\n",
            "        [-0.1425, -0.1635, -0.8984,  ..., -0.8838,  0.4132, -0.0848]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4414, -0.7836, -0.9446,  ..., -0.8542, -0.0716,  0.4028],\n",
            "        [ 0.7782,  1.0000,  0.9674,  ...,  0.8175, -0.5165, -0.7838],\n",
            "        [-0.6554,  0.9878, -0.9146,  ..., -0.9014, -0.0628,  0.4968],\n",
            "        ...,\n",
            "        [ 0.4660,  1.0000,  0.8790,  ...,  0.8261, -0.6029, -0.7701],\n",
            "        [-0.3033,  0.3102, -0.8824,  ..., -0.8992,  0.1641,  0.1331],\n",
            "        [ 0.6947,  1.0000,  0.8711,  ...,  0.8542, -0.4631, -0.6505]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 3.8280e-01,  9.9999e-01,  8.8198e-01,  ...,  8.1225e-01,\n",
            "         -5.4474e-01, -5.2122e-01],\n",
            "        [ 5.5800e-01,  9.9996e-01,  9.1802e-01,  ...,  8.5093e-01,\n",
            "         -5.1796e-01, -4.7815e-01],\n",
            "        [-2.8362e-01,  6.4752e-01, -9.2337e-01,  ..., -9.0536e-01,\n",
            "          3.0302e-01,  6.0084e-01],\n",
            "        ...,\n",
            "        [-6.3069e-01, -9.9620e-01, -8.9885e-01,  ..., -9.1092e-01,\n",
            "         -2.4422e-04,  4.8473e-01],\n",
            "        [-5.5874e-01,  9.9446e-01, -8.4069e-01,  ..., -8.3666e-01,\n",
            "          1.5304e-01,  6.9840e-02],\n",
            "        [ 2.9244e-01,  1.2007e-01, -9.0624e-01,  ..., -9.1371e-01,\n",
            "          5.3815e-01,  7.3292e-02]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4832,  0.9602, -0.7877,  ..., -0.7578,  0.5625,  0.2106],\n",
            "        [ 0.7266,  1.0000,  0.8485,  ...,  0.7846, -0.4607, -0.5937],\n",
            "        [ 0.4320,  0.9999,  0.8620,  ...,  0.8009, -0.7752, -0.2767],\n",
            "        ...,\n",
            "        [ 0.5295,  1.0000,  0.8845,  ...,  0.8099, -0.6524, -0.6272],\n",
            "        [ 0.6077,  1.0000,  0.9395,  ...,  0.7056, -0.4732, -0.7471],\n",
            "        [-0.3949,  0.2276, -0.9048,  ..., -0.8908,  0.2076,  0.4886]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6102,  1.0000,  0.8284,  ...,  0.6946, -0.7062, -0.3674],\n",
            "        [ 0.4967,  1.0000,  0.9213,  ...,  0.7732, -0.3272, -0.7074],\n",
            "        [ 0.5617,  1.0000,  0.9368,  ...,  0.5899, -0.1806, -0.8641],\n",
            "        ...,\n",
            "        [ 0.3491,  1.0000,  0.7816,  ...,  0.7813, -0.6570, -0.6845],\n",
            "        [ 0.1021,  0.9988, -0.8820,  ..., -0.8158,  0.4816, -0.4405],\n",
            "        [ 0.5509,  1.0000,  0.9312,  ...,  0.8262, -0.5494, -0.3948]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1349, -0.3889, -0.9076,  ..., -0.9155,  0.1570,  0.5950],\n",
            "        [ 0.8465,  1.0000,  0.9304,  ...,  0.5323, -0.5616, -0.9442],\n",
            "        [ 0.7217,  1.0000,  0.9567,  ...,  0.6408, -0.0468, -0.9204],\n",
            "        ...,\n",
            "        [-0.1514,  0.9931, -0.8839,  ..., -0.8993,  0.3975, -0.1418],\n",
            "        [-0.4551,  0.2010, -0.9489,  ..., -0.8046,  0.2001,  0.5587],\n",
            "        [-0.4936,  0.6447, -0.9117,  ..., -0.7802,  0.1650,  0.3904]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4671, -0.8182, -0.3284,  ..., -0.8153,  0.5674,  0.0276],\n",
            "        [ 0.0407, -0.3812, -0.9409,  ..., -0.9295,  0.1139,  0.3080],\n",
            "        [ 0.5237,  1.0000,  0.6694,  ..., -0.3763, -0.4125, -0.9112],\n",
            "        ...,\n",
            "        [-0.6058, -0.2030, -0.8717,  ..., -0.8592,  0.2577,  0.3742],\n",
            "        [-0.5328,  0.7507, -0.9069,  ..., -0.9016,  0.2338,  0.4369],\n",
            "        [ 0.7066,  1.0000,  0.9432,  ...,  0.7891, -0.3901, -0.7842]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6962,  0.7513, -0.8730,  ..., -0.8312, -0.2186,  0.5740],\n",
            "        [-0.4873,  0.9938, -0.8249,  ..., -0.8659,  0.4566, -0.1682],\n",
            "        [ 0.3825,  1.0000,  0.9087,  ...,  0.7159, -0.6162, -0.6548],\n",
            "        ...,\n",
            "        [-0.5361,  0.6656, -0.8237,  ..., -0.9026,  0.3285,  0.5569],\n",
            "        [ 0.6982,  1.0000,  0.9119,  ...,  0.8597, -0.6388, -0.6570],\n",
            "        [-0.3871,  0.9967, -0.7507,  ..., -0.7671,  0.4468,  0.0264]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5127, -0.4548, -0.8716,  ..., -0.7778, -0.1210,  0.5628],\n",
            "        [-0.3621,  0.9998, -0.7007,  ..., -0.8550,  0.7551, -0.3646],\n",
            "        [ 0.1391,  0.9977, -0.8385,  ..., -0.9068,  0.4549, -0.2996],\n",
            "        ...,\n",
            "        [ 0.6590,  1.0000,  0.8313,  ...,  0.8134, -0.6269, -0.6967],\n",
            "        [ 0.2160,  0.9947, -0.8121,  ..., -0.7398,  0.4413,  0.3955],\n",
            "        [-0.3695,  0.9906, -0.8740,  ..., -0.8370,  0.3998, -0.0168]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5231, -0.1692, -0.5582,  ..., -0.7507, -0.0855,  0.4218],\n",
            "        [ 0.7037,  1.0000,  0.7840,  ...,  0.8205, -0.4768, -0.7112],\n",
            "        [ 0.1643,  1.0000,  0.9536,  ...,  0.8067, -0.3843, -0.8376],\n",
            "        ...,\n",
            "        [-0.5134,  0.9976, -0.8914,  ..., -0.9056,  0.5359,  0.0088],\n",
            "        [ 0.3702,  0.9998,  0.9064,  ...,  0.8265, -0.5141, -0.5014],\n",
            "        [-0.1303,  0.2050, -0.9311,  ..., -0.8808,  0.3643,  0.3035]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2429,  0.9999, -0.6414,  ..., -0.7687,  0.6036, -0.0714],\n",
            "        [ 0.6322,  1.0000,  0.8546,  ...,  0.6361, -0.1619, -0.7503],\n",
            "        [ 0.6238,  1.0000,  0.9374,  ...,  0.8861, -0.5761, -0.6554],\n",
            "        ...,\n",
            "        [ 0.5686,  1.0000,  0.9109,  ...,  0.6901, -0.6011, -0.7937],\n",
            "        [-0.6539,  0.9410, -0.7866,  ..., -0.8777,  0.3786,  0.4517],\n",
            "        [-0.2818,  0.9856, -0.8987,  ..., -0.8164,  0.1929,  0.2789]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5282,  1.0000,  0.7280,  ...,  0.6105, -0.3058, -0.3091],\n",
            "        [ 0.7511,  1.0000,  0.9658,  ...,  0.8367, -0.3996, -0.5436],\n",
            "        [ 0.6551,  1.0000,  0.9508,  ...,  0.7093,  0.1025, -0.9200],\n",
            "        ...,\n",
            "        [ 0.3749,  1.0000,  0.9300,  ...,  0.7954, -0.6749, -0.6911],\n",
            "        [ 0.6585,  1.0000,  0.8018,  ...,  0.8148, -0.6704, -0.4451],\n",
            "        [ 0.7824,  1.0000,  0.6862,  ...,  0.5293, -0.2250, -0.8141]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4191, -0.5335, -0.8609,  ..., -0.8383,  0.2817, -0.2365],\n",
            "        [ 0.5983,  1.0000,  0.7414,  ...,  0.8174, -0.7064, -0.5192],\n",
            "        [ 0.6480,  1.0000,  0.9364,  ...,  0.8964, -0.7232, -0.7307],\n",
            "        ...,\n",
            "        [ 0.6422,  1.0000,  0.7767,  ...,  0.6552, -0.4712, -0.3392],\n",
            "        [ 0.6529,  1.0000,  0.9698,  ...,  0.7591,  0.2208, -0.9189],\n",
            "        [ 0.6457,  0.9999,  0.9160,  ...,  0.8163, -0.5266, -0.7253]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 4.0200e-01,  1.0000e+00,  9.3206e-01,  ...,  3.3114e-01,\n",
            "          5.3132e-01, -9.8005e-01],\n",
            "        [ 7.2160e-01,  9.9998e-01,  8.9799e-01,  ...,  7.0325e-01,\n",
            "         -6.7339e-01, -6.0876e-01],\n",
            "        [-3.3165e-02,  9.9545e-01, -8.3037e-01,  ..., -8.9536e-01,\n",
            "          3.8610e-01, -3.7267e-04],\n",
            "        ...,\n",
            "        [-4.4315e-01, -2.3592e-01, -9.0726e-01,  ..., -9.1289e-01,\n",
            "          3.6526e-01,  1.1080e-01],\n",
            "        [-4.6908e-01,  8.1970e-01, -8.9779e-01,  ..., -9.0434e-01,\n",
            "          4.7913e-01,  9.6144e-02],\n",
            "        [-4.9761e-01, -7.7653e-01, -9.4926e-01,  ..., -8.4109e-01,\n",
            "         -4.4654e-02,  4.8015e-01]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5275, -0.9974, -0.9508,  ..., -0.9417,  0.0792,  0.5153],\n",
            "        [ 0.5169,  1.0000,  0.9139,  ...,  0.6287, -0.4167, -0.7220],\n",
            "        [ 0.5615,  0.9999,  0.8632,  ...,  0.8559, -0.7024, -0.2643],\n",
            "        ...,\n",
            "        [-0.2336, -0.3074, -0.9536,  ..., -0.8717,  0.1589,  0.5863],\n",
            "        [-0.8139,  0.9976, -0.7366,  ..., -0.8825,  0.2721,  0.2726],\n",
            "        [-0.5161,  0.5004, -0.9153,  ..., -0.8826,  0.4385,  0.2070]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4015,  1.0000,  0.8948,  ...,  0.8720, -0.7015, -0.3396],\n",
            "        [ 0.8821,  1.0000,  0.3124,  ..., -0.7102,  0.6862, -0.9804],\n",
            "        [-0.3741,  0.9816, -0.8778,  ..., -0.9157,  0.3057, -0.0297],\n",
            "        ...,\n",
            "        [ 0.5493,  1.0000,  0.8857,  ...,  0.8072, -0.6247, -0.8166],\n",
            "        [-0.0769,  1.0000, -0.7550,  ..., -0.7542,  0.5245, -0.7780],\n",
            "        [ 0.0039,  1.0000,  0.0827,  ..., -0.7206,  0.5413, -0.9201]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3399, -0.2772, -0.8825,  ..., -0.7628,  0.0099,  0.5599],\n",
            "        [ 0.2730,  1.0000,  0.9288,  ...,  0.7887, -0.7048, -0.5530],\n",
            "        [ 0.6000,  1.0000,  0.9236,  ...,  0.8917, -0.5122, -0.6491],\n",
            "        ...,\n",
            "        [ 0.7691,  1.0000,  0.9391,  ...,  0.6023, -0.3716, -0.8421],\n",
            "        [-0.1765,  0.9993, -0.7577,  ..., -0.8852,  0.5218, -0.3623],\n",
            "        [-0.3974,  0.9850, -0.9107,  ..., -0.9091,  0.0618,  0.2935]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2308,  0.9868, -0.4972,  ..., -0.7464,  0.4964,  0.0390],\n",
            "        [ 0.2100,  0.9999,  0.9472,  ...,  0.6534, -0.6448, -0.4798],\n",
            "        [ 0.6320,  1.0000,  0.8714,  ...,  0.8865, -0.5747, -0.5873],\n",
            "        ...,\n",
            "        [ 0.5679,  1.0000,  0.8875,  ...,  0.5628, -0.3446, -0.7588],\n",
            "        [ 0.5880,  0.9995,  0.8544,  ...,  0.8372, -0.6190, -0.1993],\n",
            "        [ 0.6368,  1.0000,  0.9227,  ...,  0.3452, -0.3086, -0.8462]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0243,  0.9983, -0.5288,  ..., -0.6968,  0.3763,  0.1206],\n",
            "        [-0.4700,  0.8064, -0.8345,  ..., -0.8810,  0.4820,  0.1275],\n",
            "        [ 0.6995,  1.0000,  0.9011,  ...,  0.7412, -0.7354, -0.5708],\n",
            "        ...,\n",
            "        [-0.2424,  0.9929, -0.1700,  ..., -0.8232,  0.3136, -0.0071],\n",
            "        [-0.1362,  0.9958, -0.8842,  ..., -0.8686,  0.4065, -0.0814],\n",
            "        [-0.2662,  0.8541, -0.7613,  ..., -0.9117,  0.2990, -0.1022]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2539,  0.9999, -0.6151,  ..., -0.8623,  0.6404, -0.1882],\n",
            "        [ 0.6498,  1.0000,  0.8761,  ...,  0.4483, -0.5756, -0.8210],\n",
            "        [ 0.7458,  1.0000,  0.9249,  ...,  0.4675, -0.6596, -0.6182],\n",
            "        ...,\n",
            "        [-0.5488,  1.0000, -0.5327,  ..., -0.7503,  0.1131,  0.1141],\n",
            "        [-0.2665,  0.9999, -0.6711,  ..., -0.8073,  0.3884, -0.6527],\n",
            "        [ 0.5938,  0.9999,  0.9080,  ...,  0.8639, -0.5226, -0.4914]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1505,  1.0000,  0.6182,  ...,  0.1419,  0.4612, -0.7595],\n",
            "        [-0.5130,  1.0000, -0.6816,  ..., -0.7453,  0.5188, -0.2244],\n",
            "        [-0.3618, -0.9723, -0.8026,  ..., -0.7254,  0.0510, -0.1181],\n",
            "        ...,\n",
            "        [-0.6189,  0.9861, -0.9239,  ..., -0.9158,  0.0104,  0.2280],\n",
            "        [ 0.3788,  0.9999,  0.8246,  ...,  0.8666, -0.4411, -0.5229],\n",
            "        [ 0.1742,  0.9986,  0.7577,  ...,  0.6546, -0.5142, -0.3941]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4995,  0.9745, -0.9152,  ..., -0.9219,  0.2023,  0.2425],\n",
            "        [-0.5221,  0.9994, -0.4409,  ..., -0.8727,  0.7273, -0.3568],\n",
            "        [-0.2679,  0.9973, -0.9120,  ..., -0.9346,  0.3036,  0.2608],\n",
            "        ...,\n",
            "        [-0.5579,  0.9988, -0.9159,  ..., -0.8352,  0.1346, -0.1102],\n",
            "        [ 0.6021,  1.0000,  0.8290,  ...,  0.5233, -0.3637, -0.8585],\n",
            "        [-0.5992,  0.9939, -0.7983,  ..., -0.8967, -0.1464,  0.1208]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6708,  1.0000,  0.8860,  ...,  0.8508, -0.5230, -0.6829],\n",
            "        [ 0.7136,  1.0000,  0.8153,  ...,  0.7467, -0.7958, -0.6626],\n",
            "        [-0.6213,  0.9966, -0.7429,  ..., -0.9115,  0.2464, -0.0901],\n",
            "        ...,\n",
            "        [-0.4952,  0.7903, -0.7779,  ..., -0.8940,  0.7036, -0.5473],\n",
            "        [ 0.5961,  1.0000,  0.8522,  ...,  0.7097, -0.6226, -0.8680],\n",
            "        [ 0.6650,  0.9998,  0.8111,  ...,  0.7785, -0.7658, -0.3543]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0880,  0.9912, -0.9060,  ..., -0.9251, -0.0677, -0.3631],\n",
            "        [-0.4658,  0.9998, -0.5985,  ..., -0.6612,  0.2245, -0.1171],\n",
            "        [-0.4893, -0.9895, -0.9175,  ..., -0.9124, -0.0044,  0.6719],\n",
            "        ...,\n",
            "        [ 0.3999,  0.9999,  0.7317,  ...,  0.8848, -0.8442, -0.3662],\n",
            "        [-0.2152,  0.9982, -0.8605,  ..., -0.8541,  0.2859,  0.0232],\n",
            "        [-0.5150,  0.9773, -0.8854,  ..., -0.8621,  0.3465,  0.3627]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.7280,  0.9714, -0.9186, -0.8451,  0.1817, -0.9347,  0.1613, -0.2370,\n",
            "          0.2112,  0.6686, -0.7934,  0.8839, -0.2653,  0.8176, -0.2975,  0.8998,\n",
            "         -0.5826, -0.8625,  0.5012,  0.0564,  0.3319,  0.8809,  0.3825, -0.2665,\n",
            "         -0.7651, -0.9010,  0.6803,  0.1773,  0.0897, -0.4140, -0.1493,  0.5942,\n",
            "          0.5316,  0.3953,  0.2357, -0.3052,  0.4756, -0.4420, -0.8908, -0.8627,\n",
            "          0.8480,  0.4382,  0.9444, -0.8136,  0.6336, -0.9066,  0.0672, -0.7997,\n",
            "          0.6833,  0.3261,  0.2833, -0.9719,  0.3536, -0.7063, -0.8077, -0.7268,\n",
            "         -0.3457,  0.3493, -0.1361,  0.6782,  0.0078, -0.4809,  0.9063,  0.4980,\n",
            "          0.9577,  0.5254,  0.7161,  0.1376,  0.8841, -0.7907, -0.8236, -0.0457,\n",
            "         -0.0268, -0.6374,  0.4150, -0.0553,  0.3907, -0.4130, -0.4609,  0.5795,\n",
            "         -0.6966,  0.5782,  0.8482, -0.9855, -0.7463, -0.4785,  0.7890, -0.6960,\n",
            "         -0.7188,  0.1794,  0.3266, -0.8079, -0.7415,  0.5062,  0.3961, -0.7839,\n",
            "          0.2145, -0.7467, -0.7734,  0.4559,  0.7902,  0.6022,  0.5080,  0.1681,\n",
            "         -0.9737, -0.8783,  0.4381, -0.6812, -0.9243, -0.1201, -0.7613, -0.1090,\n",
            "          0.5038,  0.0493, -0.4780,  0.9647, -0.8494, -0.7124, -0.9369, -0.5394,\n",
            "          0.1288, -0.1457,  0.2799, -0.5875,  0.0774, -0.7070, -0.7468, -0.4682,\n",
            "          0.4669,  0.1672, -0.4412, -0.5930, -0.7865, -0.7763,  0.2203, -0.1172,\n",
            "         -0.9850,  0.5248,  0.6007, -0.6481,  0.9124,  0.7936, -0.2917, -0.3827,\n",
            "          0.1339,  0.7768, -0.1717,  0.6943, -0.3870, -0.7483,  0.1211, -0.4044,\n",
            "         -0.7642,  0.0476, -0.9893,  0.6397,  0.5275,  0.7578,  0.9637, -0.4643,\n",
            "          0.4758, -0.8400,  0.6542,  0.3309,  0.9615, -0.4896, -0.1232,  0.4833,\n",
            "          0.8993, -0.2898, -0.0227,  0.6829,  0.5488,  0.6520,  0.9711, -0.8118,\n",
            "         -0.8716,  0.0249,  0.9104,  0.1663,  0.6656, -0.4022, -0.6676, -0.8700,\n",
            "          0.1358, -0.3582, -0.5188, -0.9326, -0.6011,  0.7354, -0.0758, -0.9074,\n",
            "         -0.2342,  0.8948,  0.0051, -0.1008, -0.5444,  0.6990,  0.2034,  0.4299,\n",
            "          0.5994, -0.1611,  0.5817, -0.5462, -0.6941, -0.8757, -0.0373,  0.5033,\n",
            "         -0.8170,  0.0139,  0.5138,  0.4275,  0.5343, -0.6678,  0.0046,  0.3575,\n",
            "          0.6473, -0.9151,  0.7563,  0.7749, -0.7446, -0.7148, -0.1527, -0.7883,\n",
            "         -0.1389, -0.6449, -0.2856,  0.1153, -0.7729, -0.9372,  0.1844,  0.5187,\n",
            "          0.6005,  0.6279,  0.9891,  0.0939, -0.8755,  0.6957, -0.2546, -0.6428,\n",
            "          0.8342, -0.5183,  0.7857, -0.0486,  0.8760, -0.7702, -0.1862, -0.8771,\n",
            "          0.0316,  0.6599, -0.4124, -0.2083,  0.8377,  0.7248,  0.6082,  0.6627,\n",
            "          0.6170, -0.9089, -0.5216,  0.2526, -0.8402,  0.3207, -0.9550, -0.8692,\n",
            "          0.4395,  0.9847, -0.7109, -0.0195,  0.5346,  0.4136,  0.6499, -0.0445,\n",
            "         -0.4867,  0.9953, -0.1050, -0.7823,  0.9802,  0.2510, -0.8864,  0.7629,\n",
            "         -0.9438,  0.1412,  0.8165,  0.2335,  0.0608,  0.4968,  0.2246,  0.1795,\n",
            "         -0.9831, -0.4146,  0.9300,  0.7202,  0.9010,  0.0623, -0.2090, -0.8917,\n",
            "          0.8683, -0.2460, -0.3624,  0.9922,  0.4836,  0.5478, -0.6632,  0.3798,\n",
            "          0.1006,  0.7880, -0.4452,  0.5576, -0.5577, -0.1954,  0.5179, -0.7171,\n",
            "          0.2062,  0.4824, -0.3998, -0.7164, -0.1694, -0.4737, -0.4470, -0.0482,\n",
            "          0.1899,  0.8845, -0.4760, -0.8081,  0.0079,  0.2312, -0.8491,  0.8024,\n",
            "          0.1808, -0.2322, -0.3157,  0.8793, -0.1016, -0.5860,  0.6811, -0.4971,\n",
            "         -0.1135,  0.5046,  0.0562,  0.8291,  0.7588,  0.5718,  0.6780,  0.2758,\n",
            "          0.4712, -0.7187,  0.5454, -0.4762, -0.6540, -0.5617, -0.3133,  0.1784,\n",
            "         -0.7943,  0.0054,  0.8083,  0.9913,  0.5927,  0.9546, -0.7097,  0.5840,\n",
            "         -0.6637,  0.3337,  0.7589, -0.7674, -0.9022, -0.6318,  0.2624,  0.2532,\n",
            "         -0.7626, -0.3921, -0.5787,  0.4918, -0.0229,  0.9159, -0.4607, -0.8940,\n",
            "          0.8930,  0.3814,  0.8270,  0.0768, -0.6015,  0.3442,  0.8569,  0.5559,\n",
            "          0.2180, -0.1586,  0.7463, -0.7731,  0.7170,  0.0445,  0.2610,  0.2807,\n",
            "          0.0955, -0.2374,  0.3601,  0.8976, -0.3293, -0.5009, -0.9425,  0.9917,\n",
            "         -0.6302,  0.0661, -0.0039,  0.3454,  0.7991, -0.5609,  0.0996, -0.2302,\n",
            "          0.7144, -0.8712,  0.6666,  0.6758,  0.7197,  0.2423, -0.5368,  0.2975,\n",
            "         -0.8282, -0.3928, -0.7556,  0.5642, -0.6021, -0.7118, -0.8304, -0.9251,\n",
            "          0.8786, -0.5414,  0.8688, -0.7812, -0.7444, -0.6243, -0.3545, -0.5285,\n",
            "          0.7445, -0.8197,  0.9754, -0.9315,  0.2819, -0.3691,  0.7453,  0.5120,\n",
            "          0.6918,  0.6296,  0.7890, -0.2293,  0.3411,  0.4208, -0.5868, -0.8302,\n",
            "          0.1780,  0.6453, -0.0787,  0.8362, -0.7116,  0.8810,  0.6644, -0.0859,\n",
            "         -0.0464, -0.4633,  0.9306,  0.9239, -0.6114,  0.8741,  0.9826,  0.2516,\n",
            "         -0.1517, -0.0929, -0.7055,  0.7174, -0.8764, -0.7740,  0.5982,  0.2662,\n",
            "          0.4968, -0.5018,  0.7946, -0.1647, -0.3401, -0.7142, -0.1986, -0.9652,\n",
            "         -0.5367,  0.6558, -0.9013, -0.8064,  0.6692,  0.1890,  0.1619,  0.5970,\n",
            "          0.7940, -0.0560, -0.2150, -0.7155,  0.2151,  0.8576,  0.3627,  0.2348,\n",
            "         -0.7060, -0.4066, -0.6188,  0.0057,  0.9523, -0.8038, -0.3862,  0.6021,\n",
            "         -0.4092, -0.8368,  0.9882,  0.8073,  0.4907,  0.9413,  0.6301,  0.6437,\n",
            "         -0.3006,  0.8197, -0.3432,  0.5744,  0.4747,  0.9496, -0.7156, -0.9022,\n",
            "         -0.9830, -0.2823, -0.2569, -0.3070, -0.2861, -0.8402, -0.3240,  0.1539,\n",
            "         -0.8601,  0.5104,  0.2153, -0.9706, -0.8723, -0.6651, -0.6825, -0.8451,\n",
            "         -0.1523, -0.6116, -0.7836,  0.9361, -0.9311, -0.9847, -0.3867,  0.4527,\n",
            "          0.8255,  0.5226, -0.1814, -0.4090, -0.3736,  0.4958, -0.9949, -0.3796,\n",
            "          0.7857,  0.8395, -0.7306,  0.8522, -0.7740, -0.4621, -0.2176,  0.2932,\n",
            "          0.5657, -0.9912,  0.4190,  0.5531,  0.3926, -0.5131, -0.4522, -0.7916,\n",
            "         -0.7483, -0.7247,  0.9173,  0.5193,  0.8843, -0.6962,  0.1978,  0.9036,\n",
            "          0.1841, -0.6971,  0.4900,  0.8604,  0.7975,  0.7205,  0.4208, -0.6828,\n",
            "          0.0600, -0.3895, -0.5492,  0.2973, -0.6041,  0.6676, -0.1720,  0.3902,\n",
            "          0.6580, -0.4599,  0.9858,  0.5526, -0.6679,  0.9081, -0.4827, -0.8268,\n",
            "         -0.9905, -0.8419,  0.7792, -0.5661, -0.8177,  0.4061, -0.2020, -0.3241,\n",
            "          0.5487, -0.1233,  0.7336,  0.8986,  0.3490,  0.1199, -0.6339, -0.9783,\n",
            "          0.1013,  0.8184, -0.3713,  0.5951, -0.3207,  0.9516,  0.4719,  0.6569,\n",
            "          0.2649,  0.9520,  0.2820, -0.7139,  0.4734, -0.1516,  0.5728,  0.8689,\n",
            "         -0.5314, -0.9355, -0.5931, -0.7777, -0.4142, -0.7745,  0.8414, -0.1101,\n",
            "          0.9377,  0.7429,  0.7279,  0.2685,  0.5299, -0.6301, -0.2630,  0.6582,\n",
            "         -0.9026,  0.7917, -0.1736, -0.7417,  0.0953, -0.8481, -0.4767,  0.2988,\n",
            "         -0.4730, -0.2729, -0.8571, -0.8024,  0.1160, -0.6333,  0.6980, -0.5992,\n",
            "         -0.8725,  0.9168, -0.5132, -0.2161,  0.8658,  0.6250, -0.5393,  0.8603,\n",
            "          0.0873, -0.4525,  0.7472,  0.2570, -0.6353,  0.5631,  0.3112,  0.2500,\n",
            "          0.2308, -0.3566,  0.9259,  0.2544,  0.0076,  0.6476, -0.1738,  0.6242,\n",
            "          0.7174, -0.5792,  0.6183, -0.2027, -0.4116, -0.6046, -0.2364,  0.4509,\n",
            "          0.8357, -0.9825,  0.9656,  0.5952, -0.4931, -0.9545, -0.3175,  0.2760,\n",
            "          0.6471, -0.2142,  0.4224, -0.4689, -0.7988,  0.6455, -0.9654, -0.8663,\n",
            "         -0.7607,  0.4649,  0.5360, -0.9599, -0.7078,  0.5037,  0.2091, -0.3449,\n",
            "          0.8588,  0.1084, -0.5876, -0.6299, -0.9040, -0.2149,  0.3261, -0.6062,\n",
            "          0.5324, -0.1023, -0.2623, -0.6418,  0.6120,  0.5976, -0.5029, -0.7091,\n",
            "          0.4738, -0.9881,  0.4725, -0.3431, -0.8022,  0.6755, -0.7985,  0.5270,\n",
            "          0.3696, -0.9606,  0.4471,  0.0504,  0.4885,  0.5820, -0.7485,  0.4741,\n",
            "          0.7825, -0.1851,  0.8889,  0.1814,  0.5486,  0.3404,  0.9077,  0.8581,\n",
            "          0.6808, -0.4900, -0.8886, -0.3654,  0.6084, -0.8782,  0.1781,  0.5540]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluation... :   0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d7f309d5689f49c39dbc1e9cd8f6d6a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7036,  0.9996,  0.9075,  ...,  0.8599, -0.7657, -0.4450],\n",
            "        [ 0.7355,  1.0000,  0.9530,  ...,  0.8182, -0.2688, -0.8770],\n",
            "        [ 0.8689,  1.0000,  0.4242,  ..., -0.5408,  0.6618, -0.9062],\n",
            "        ...,\n",
            "        [ 0.4024,  0.9999,  0.8371,  ...,  0.8076, -0.7541, -0.3040],\n",
            "        [ 0.1952,  0.9998, -0.2632,  ..., -0.7942,  0.6169, -0.6474],\n",
            "        [-0.6361,  0.9499, -0.8781,  ..., -0.7329,  0.3279,  0.3737]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1230,  1.0000, -0.5221,  ..., -0.8676,  0.6617, -0.6851],\n",
            "        [ 0.7047,  1.0000,  0.8275,  ...,  0.5551, -0.7136, -0.4799],\n",
            "        [ 0.3951,  1.0000,  0.8112,  ..., -0.3639,  0.3936, -0.9609],\n",
            "        ...,\n",
            "        [-0.0179,  0.9999,  0.1991,  ..., -0.6463,  0.2281, -0.8846],\n",
            "        [-0.4474,  1.0000,  0.2815,  ..., -0.7892,  0.3290, -0.7989],\n",
            "        [ 0.6547,  1.0000,  0.9007,  ..., -0.2411,  0.4761, -0.9817]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5756,  1.0000,  0.9342,  ...,  0.8428, -0.7101, -0.5510],\n",
            "        [ 0.3239,  1.0000,  0.7747,  ...,  0.4498,  0.6662, -0.8302],\n",
            "        [ 0.5681,  1.0000,  0.8856,  ...,  0.8530, -0.6791, -0.6135],\n",
            "        ...,\n",
            "        [ 0.0923,  1.0000,  0.5398,  ..., -0.8478,  0.5357, -0.9465],\n",
            "        [-0.6384,  0.9974, -0.7697,  ..., -0.9138,  0.3299, -0.2221],\n",
            "        [ 0.5047,  1.0000,  0.7725,  ...,  0.1994,  0.2167, -0.9514]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3367,  1.0000,  0.6891,  ...,  0.4347, -0.6309, -0.7300],\n",
            "        [ 0.1515,  1.0000,  0.8364,  ..., -0.3584,  0.3536, -0.9660],\n",
            "        [ 0.5135,  1.0000,  0.6425,  ..., -0.6697,  0.2931, -0.9783],\n",
            "        ...,\n",
            "        [ 0.6874,  1.0000,  0.9020,  ...,  0.8632, -0.6357, -0.5126],\n",
            "        [ 0.2544,  0.9925, -0.4926,  ..., -0.8603,  0.6589, -0.6532],\n",
            "        [ 0.6284,  0.9999,  0.8986,  ...,  0.8783, -0.8150, -0.3853]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6904,  1.0000,  0.8306,  ...,  0.7088, -0.4254, -0.4293],\n",
            "        [ 0.4462,  1.0000,  0.8811,  ...,  0.8459, -0.3806, -0.6366],\n",
            "        [ 0.0093,  0.9999, -0.6154,  ..., -0.6426,  0.4120, -0.4575],\n",
            "        ...,\n",
            "        [ 0.5225,  1.0000,  0.7031,  ...,  0.7082, -0.4063, -0.8491],\n",
            "        [ 0.5338,  0.9999,  0.9214,  ...,  0.6515, -0.6371, -0.4647],\n",
            "        [ 0.5023,  1.0000,  0.9443,  ...,  0.5852,  0.4319, -0.7972]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5719,  1.0000,  0.8952,  ...,  0.8772, -0.6776, -0.5771],\n",
            "        [ 0.7800,  1.0000,  0.7395,  ...,  0.5776, -0.5342, -0.8941],\n",
            "        [-0.2280,  0.9350, -0.9519,  ..., -0.8884,  0.5654,  0.0586],\n",
            "        ...,\n",
            "        [ 0.8258,  1.0000, -0.2043,  ..., -0.6485,  0.7509, -0.8027],\n",
            "        [ 0.4791,  1.0000,  0.4405,  ...,  0.4578, -0.3147, -0.7154],\n",
            "        [-0.2117,  1.0000,  0.1589,  ..., -0.7204,  0.3533, -0.9061]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3204,  0.9999, -0.0096,  ..., -0.7007, -0.2611, -0.8829],\n",
            "        [-0.4601,  0.5763, -0.9233,  ..., -0.9376,  0.1071,  0.5702],\n",
            "        [ 0.5826,  0.9998,  0.8735,  ...,  0.8906, -0.7935, -0.3902],\n",
            "        ...,\n",
            "        [-0.0073,  1.0000,  0.2966,  ..., -0.5835, -0.4109, -0.8051],\n",
            "        [ 0.5765,  0.9999,  0.9187,  ...,  0.8935, -0.8261, -0.3794],\n",
            "        [-0.1863,  0.9999, -0.4823,  ..., -0.7506,  0.2291, -0.3750]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6258,  1.0000,  0.9052,  ...,  0.8488, -0.7238, -0.6111],\n",
            "        [ 0.6498,  1.0000,  0.9326,  ...,  0.8972, -0.7145, -0.5562],\n",
            "        [ 0.7156,  1.0000,  0.9462,  ...,  0.8101,  0.0850, -0.9212],\n",
            "        ...,\n",
            "        [ 0.5790,  0.9998,  0.9131,  ...,  0.8457, -0.8418, -0.3164],\n",
            "        [ 0.4566,  1.0000,  0.8555,  ...,  0.8112, -0.6462, -0.6899],\n",
            "        [ 0.5641,  1.0000,  0.7993,  ...,  0.5790, -0.4474, -0.6935]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7149,  1.0000,  0.9423,  ...,  0.8693, -0.6111, -0.6773],\n",
            "        [ 0.0508,  0.9999, -0.8139,  ..., -0.8589,  0.4158, -0.4574],\n",
            "        [-0.7212,  0.9970, -0.4424,  ..., -0.8823,  0.2102, -0.3921],\n",
            "        ...,\n",
            "        [ 0.6433,  1.0000,  0.9065,  ...,  0.8227, -0.6646, -0.4691],\n",
            "        [-0.5226,  0.9483, -0.8788,  ..., -0.9015,  0.3510,  0.5724],\n",
            "        [ 0.5364,  0.9998,  0.9028,  ...,  0.8109, -0.7595, -0.3557]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3937,  0.7513, -0.9334,  ..., -0.8909,  0.1696,  0.2468],\n",
            "        [ 0.1806,  1.0000,  0.4802,  ..., -0.6606,  0.3658, -0.9051],\n",
            "        [ 0.5535,  0.9999,  0.9084,  ...,  0.8625, -0.8021, -0.4327],\n",
            "        ...,\n",
            "        [ 0.6803,  0.9999,  0.8461,  ...,  0.8730, -0.8005, -0.4094],\n",
            "        [ 0.5003,  1.0000,  0.8654,  ...,  0.6822, -0.5275, -0.2979],\n",
            "        [ 0.7129,  1.0000,  0.9322,  ...,  0.7446,  0.2627, -0.9578]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0286,  0.9992, -0.7850,  ..., -0.8231,  0.4329, -0.1214],\n",
            "        [-0.3750,  0.0299, -0.8691,  ..., -0.9361,  0.2137,  0.2284],\n",
            "        [-0.5613,  0.9993, -0.9260,  ..., -0.9373,  0.0016, -0.1977],\n",
            "        ...,\n",
            "        [ 0.6963,  1.0000,  0.8807,  ...,  0.6418, -0.4562, -0.8618],\n",
            "        [ 0.6840,  1.0000, -0.1906,  ..., -0.5452,  0.4778, -0.8796],\n",
            "        [ 0.4905,  0.9999,  0.9305,  ...,  0.8777, -0.7349, -0.4207]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0231,  1.0000,  0.5165,  ...,  0.2415,  0.6947, -0.8014],\n",
            "        [-0.3053,  0.7451, -0.9324,  ..., -0.9185,  0.2846,  0.2658],\n",
            "        [-0.6272,  0.9975, -0.8561,  ..., -0.8890,  0.2669, -0.3111],\n",
            "        ...,\n",
            "        [-0.3651,  0.9997, -0.8808,  ..., -0.9071,  0.4631,  0.0580],\n",
            "        [ 0.5117,  1.0000,  0.6573,  ..., -0.1793, -0.1792, -0.8373],\n",
            "        [-0.1234,  1.0000, -0.2190,  ..., -0.8623,  0.7025, -0.8099]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4368,  1.0000, -0.4654,  ..., -0.3580,  0.7932, -0.3074],\n",
            "        [ 0.4635,  1.0000,  0.8276,  ...,  0.2736, -0.0841, -0.8906],\n",
            "        [-0.4525,  0.7347, -0.6743,  ..., -0.8931,  0.5120, -0.1721],\n",
            "        ...,\n",
            "        [-0.6319,  1.0000, -0.8144,  ..., -0.7059,  0.7154, -0.2775],\n",
            "        [ 0.0040,  1.0000, -0.8708,  ..., -0.8692,  0.5210, -0.5285],\n",
            "        [-0.0347,  1.0000, -0.0897,  ..., -0.6606,  0.4656, -0.9394]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7247,  1.0000,  0.9312,  ...,  0.5327, -0.4981, -0.6955],\n",
            "        [ 0.6962,  1.0000,  0.8871,  ...,  0.4924, -0.2476, -0.8391],\n",
            "        [-0.6112,  0.9581, -0.8969,  ..., -0.8467, -0.1726,  0.2316],\n",
            "        ...,\n",
            "        [ 0.5100,  1.0000,  0.7642,  ...,  0.0300, -0.5468, -0.7425],\n",
            "        [ 0.5213,  1.0000,  0.8167,  ...,  0.7530, -0.0926, -0.6847],\n",
            "        [-0.1810,  1.0000,  0.0875,  ..., -0.0407, -0.3222, -0.8575]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 4.5458e-01,  1.0000e+00,  7.8023e-01, -9.8035e-01, -4.8912e-01,\n",
            "          9.3616e-01,  7.9050e-01,  8.4106e-01, -9.9932e-01, -7.1580e-01,\n",
            "          8.6677e-01, -6.2628e-01,  3.5730e-01,  9.9986e-01,  3.1774e-01,\n",
            "         -2.0337e-01,  7.7649e-01, -9.9153e-01,  7.3561e-01, -4.3259e-01,\n",
            "          4.3628e-01, -8.1343e-01,  8.9706e-01, -4.6217e-01,  8.1653e-01,\n",
            "          7.7855e-01, -5.7696e-01,  6.6791e-01, -9.2416e-02,  4.1477e-01,\n",
            "         -6.9119e-01, -4.4804e-01,  9.5303e-01,  7.5814e-01,  8.7166e-01,\n",
            "         -9.7376e-01, -4.3954e-01, -9.7342e-01, -9.9442e-01, -9.9896e-01,\n",
            "          5.4997e-02, -5.6095e-01,  9.9988e-01, -8.2028e-01,  9.9858e-01,\n",
            "         -9.9205e-01,  5.3561e-01, -4.0946e-01,  7.3537e-01,  5.4670e-01,\n",
            "         -8.1803e-01,  9.6661e-01,  8.1764e-01,  9.0697e-01, -6.5869e-01,\n",
            "         -9.4618e-01, -8.1378e-01,  5.2484e-01, -9.0609e-01, -5.3035e-01,\n",
            "          8.5689e-01,  6.9078e-01, -7.0309e-01, -6.7087e-03, -9.1852e-01,\n",
            "         -5.5842e-01,  6.3939e-01,  5.6665e-01, -7.7152e-01, -9.8084e-01,\n",
            "          8.7300e-01, -9.6802e-01,  7.5224e-01,  7.5624e-03, -4.1815e-01,\n",
            "          8.9345e-01, -9.0252e-01,  8.7266e-01, -8.3305e-01,  9.9679e-01,\n",
            "          7.2268e-01,  5.5440e-01,  7.5211e-01, -9.9999e-01,  7.4879e-01,\n",
            "         -9.3894e-01,  9.9444e-01, -9.9468e-01, -9.8116e-01,  7.6947e-01,\n",
            "          8.4993e-01,  7.5057e-01,  8.2103e-01, -1.8628e-01, -5.3592e-01,\n",
            "         -9.3800e-01, -6.9515e-01,  6.7843e-01, -9.9965e-01,  8.1154e-01,\n",
            "          7.5528e-01,  8.2050e-01, -7.0009e-01, -7.4405e-01, -9.9984e-01,\n",
            "          4.9202e-01, -6.2685e-01, -6.1195e-01, -9.9999e-01, -8.2387e-01,\n",
            "         -8.2838e-01, -8.9586e-01, -4.6314e-01,  9.3803e-01,  5.6286e-01,\n",
            "          9.9995e-01,  9.0568e-01,  9.9948e-01, -9.9999e-01, -9.9620e-01,\n",
            "          2.7066e-01,  9.4725e-01, -6.9842e-01, -1.9104e-01,  6.4716e-01,\n",
            "         -9.8756e-01,  3.9796e-01, -9.9956e-01,  7.9415e-01, -9.5382e-01,\n",
            "         -6.3722e-01,  9.2713e-01,  9.2571e-01,  3.8608e-01, -7.1505e-01,\n",
            "          6.0694e-01, -9.9987e-01,  4.2027e-02, -7.9714e-01, -9.9668e-01,\n",
            "          9.9704e-01,  9.4388e-01,  8.7851e-01, -6.0841e-01, -4.7092e-01,\n",
            "          9.2298e-01,  9.0249e-01, -7.5832e-01, -1.5733e-01, -2.6537e-02,\n",
            "         -8.6390e-01,  8.3121e-01,  5.7020e-01, -5.3443e-01, -9.9999e-01,\n",
            "          5.0209e-01, -6.5197e-01,  9.8321e-01, -9.9188e-01,  9.8703e-01,\n",
            "         -9.8018e-01, -1.0000e+00,  5.1463e-01,  3.4540e-01, -9.2662e-01,\n",
            "          8.3058e-01, -8.2328e-01,  9.3720e-01, -6.4143e-01,  7.1016e-01,\n",
            "          7.7852e-01,  7.4916e-01,  3.5650e-01, -6.2843e-01,  1.4072e-01,\n",
            "         -8.7744e-01,  7.9942e-01, -7.4982e-01, -6.7349e-01, -9.8557e-01,\n",
            "          9.8986e-01, -5.9341e-01,  9.9138e-01, -9.7198e-01, -8.6239e-01,\n",
            "          6.0410e-01,  3.8227e-01, -1.0000e+00,  9.6085e-01,  5.0923e-01,\n",
            "          5.4550e-01,  6.3015e-01,  4.8607e-01, -4.8989e-01,  3.2825e-01,\n",
            "         -1.0003e-01, -5.7643e-01,  7.6696e-01, -3.8279e-01,  9.6021e-01,\n",
            "          3.8144e-01, -9.9979e-01,  9.2878e-01,  9.9600e-01,  3.6607e-01,\n",
            "         -5.6027e-01,  1.3602e-01,  9.9359e-01, -9.9901e-01, -8.4659e-01,\n",
            "          2.3803e-01, -7.1613e-01,  4.6518e-01,  5.4562e-01, -5.9171e-01,\n",
            "         -8.3193e-01,  7.4383e-01,  4.2034e-01, -5.6867e-02, -5.1422e-01,\n",
            "          5.3025e-01,  7.2857e-01, -4.9059e-01,  5.5495e-01,  8.2530e-01,\n",
            "          9.9950e-01, -7.0209e-01, -5.9596e-01,  6.8008e-01, -9.9991e-01,\n",
            "          8.8396e-01,  4.0500e-01, -2.8487e-01, -7.1627e-01,  9.9556e-01,\n",
            "          8.3898e-01,  7.2675e-01,  9.8889e-01, -9.8618e-01, -2.6314e-01,\n",
            "         -6.7250e-01,  7.7294e-01, -4.3192e-01, -1.5257e-01,  9.9999e-01,\n",
            "         -9.9789e-01,  9.9516e-01,  9.1115e-01,  2.2792e-01, -3.4267e-01,\n",
            "          5.5410e-01,  3.4111e-01, -2.3454e-01, -9.1440e-02, -7.5730e-01,\n",
            "          9.9550e-01, -7.7834e-01, -9.9294e-01,  6.0980e-01, -1.2627e-01,\n",
            "         -9.6761e-01, -8.8472e-01,  8.3830e-01, -7.0506e-01,  9.9366e-01,\n",
            "          9.9998e-01,  7.6980e-01,  5.2673e-01,  7.9811e-01,  7.1648e-01,\n",
            "          8.3794e-01, -9.9518e-01,  9.8413e-01,  1.0000e+00, -9.7776e-01,\n",
            "          3.7911e-01,  9.9999e-01,  7.6454e-01, -2.5875e-01, -5.9394e-01,\n",
            "          5.0243e-01, -9.9461e-01, -2.5954e-01, -5.9381e-01, -4.5820e-01,\n",
            "         -4.9124e-01,  4.7153e-03, -9.8084e-01, -9.9975e-01, -9.9481e-01,\n",
            "          9.9034e-01, -7.7023e-01, -7.5883e-01,  7.0098e-01, -7.1116e-01,\n",
            "          2.6881e-01, -7.2335e-01,  9.9654e-01, -8.4019e-01,  9.9999e-01,\n",
            "          7.1800e-01, -7.9316e-01, -9.8374e-01, -4.5642e-01,  6.6584e-01,\n",
            "          2.5007e-01,  9.9969e-01,  7.2928e-02, -7.4385e-01,  7.4543e-01,\n",
            "          7.7119e-01,  3.8055e-01,  9.7649e-01, -6.9922e-01,  7.4602e-01,\n",
            "          3.9447e-01,  1.9021e-01, -9.8787e-01, -5.7052e-01, -9.0351e-01,\n",
            "          8.6194e-01,  9.8575e-01,  7.3862e-01, -2.1016e-03,  9.9078e-01,\n",
            "          8.7874e-01, -1.0000e+00,  9.9977e-01,  9.9146e-01, -9.9708e-01,\n",
            "          8.6209e-01, -3.2238e-01,  9.2469e-01, -6.6765e-04,  5.8934e-01,\n",
            "         -9.1773e-01, -8.8559e-01, -9.9455e-01,  8.8456e-01,  3.3031e-01,\n",
            "         -7.9286e-01,  4.4595e-01, -9.3615e-01,  8.1605e-01,  2.8415e-01,\n",
            "          8.6462e-01, -2.8761e-01, -8.1151e-02, -9.9860e-01,  7.2921e-01,\n",
            "          8.8233e-01, -2.5691e-01,  8.0674e-01,  9.9517e-01, -1.3655e-02,\n",
            "          1.0000e+00, -8.1909e-01, -2.1240e-01,  1.2868e-01,  6.7504e-01,\n",
            "          5.4375e-01,  5.5238e-01, -3.0825e-01,  3.6287e-01, -1.0000e+00,\n",
            "          3.4019e-01, -6.6885e-01,  3.8728e-01,  5.8621e-01, -9.9482e-01,\n",
            "          4.3044e-01, -4.1979e-01,  4.0006e-02, -2.3500e-01,  3.4941e-01,\n",
            "          6.1868e-01,  9.9978e-01,  4.1606e-01, -5.0091e-01, -7.7109e-01,\n",
            "         -5.7510e-02,  2.5136e-01,  9.3104e-01,  7.8666e-01,  9.9584e-01,\n",
            "         -8.6313e-01, -1.5895e-01,  6.9913e-01,  1.5064e-01, -7.6720e-01,\n",
            "         -1.0157e-01,  6.3147e-01,  1.5693e-01,  9.8192e-01,  8.1400e-01,\n",
            "         -4.8013e-01, -6.5729e-01,  8.3445e-01, -9.9917e-01,  9.9999e-01,\n",
            "          4.6005e-01,  6.7598e-01,  9.6657e-01, -4.1131e-01,  7.8040e-01,\n",
            "          3.5250e-01,  5.6024e-01, -7.8806e-01,  9.8850e-01,  7.8509e-01,\n",
            "          7.6351e-01,  2.3440e-01,  1.2523e-01, -3.8418e-01, -9.0674e-01,\n",
            "          6.5195e-01,  5.4858e-01, -6.0276e-01, -9.9146e-01,  9.9629e-01,\n",
            "         -9.8917e-01,  3.3916e-01, -4.3284e-01,  8.6271e-01,  9.7389e-01,\n",
            "         -6.5725e-01, -9.1838e-01, -3.9059e-01,  1.2101e-01, -7.8070e-01,\n",
            "         -8.6757e-01, -9.9501e-01, -1.4334e-01, -9.6609e-01,  9.9995e-01,\n",
            "         -9.9548e-01,  6.7488e-01, -9.6637e-01, -8.9991e-01,  8.2104e-01,\n",
            "         -4.4541e-01, -7.0823e-01, -8.7049e-01, -8.8895e-02, -6.1332e-01,\n",
            "          8.4718e-01,  7.8470e-02,  8.4427e-01, -5.1185e-01,  2.1468e-01,\n",
            "          7.0941e-01,  1.1543e-01,  3.6465e-01,  9.5995e-01, -6.5752e-01,\n",
            "         -9.7901e-01, -7.7456e-01, -6.9756e-01, -7.0916e-01,  9.8138e-01,\n",
            "         -9.6138e-01, -8.2158e-01,  1.0000e+00, -9.9433e-01, -6.5700e-02,\n",
            "         -4.0105e-01, -9.9918e-01,  6.0820e-01, -5.3061e-01, -9.6802e-01,\n",
            "         -7.3155e-01, -8.1021e-01,  7.7983e-01,  9.8086e-01,  9.9977e-01,\n",
            "          3.2884e-01, -7.7404e-02, -9.8189e-01, -6.6824e-01,  9.9916e-01,\n",
            "         -9.9377e-01, -5.5816e-01,  4.2826e-01, -9.9854e-01,  9.6951e-01,\n",
            "          5.3796e-01, -5.4663e-01,  8.7081e-01, -8.2053e-01,  9.9042e-01,\n",
            "          6.5204e-01, -9.9853e-01,  5.8333e-01,  7.7345e-01, -2.5479e-01,\n",
            "          8.9857e-01,  3.4753e-01, -2.0049e-02, -9.8321e-01,  1.4161e-01,\n",
            "          9.9988e-01,  5.4605e-01, -8.7923e-01,  3.3058e-01,  8.2951e-01,\n",
            "          9.0226e-01,  9.9999e-01, -9.9240e-01,  8.0962e-01,  9.9992e-01,\n",
            "         -4.1088e-01,  6.2635e-01,  1.4625e-01, -8.4493e-01,  5.6986e-03,\n",
            "          5.3056e-01, -9.8615e-01,  9.9996e-01, -3.1671e-01, -9.9109e-01,\n",
            "         -9.9999e-01,  5.2974e-01, -8.7185e-01,  7.9831e-01,  9.9034e-01,\n",
            "          6.6672e-01,  8.7087e-01,  4.5248e-01, -9.9943e-01,  1.3810e-01,\n",
            "         -6.9317e-01, -9.9996e-01, -9.9985e-01,  8.7526e-01,  2.2660e-01,\n",
            "          4.4722e-01,  8.1739e-01, -2.7389e-01, -7.8133e-01,  9.9991e-01,\n",
            "          9.2007e-01, -9.9999e-01, -3.7641e-01,  4.7750e-01,  9.8234e-01,\n",
            "         -8.2386e-01,  7.5641e-01,  3.1643e-01,  4.6882e-01, -4.5899e-01,\n",
            "         -9.9999e-01, -6.2573e-01,  9.8887e-01, -2.0767e-01,  8.3299e-02,\n",
            "          9.9988e-01,  7.6711e-01,  3.3840e-01, -9.6659e-01,  2.2126e-01,\n",
            "          7.8314e-01, -9.9999e-01, -7.7700e-01,  9.9994e-01, -5.4832e-01,\n",
            "         -2.8354e-01, -6.4363e-01,  4.7040e-01,  7.1200e-01,  7.8319e-01,\n",
            "          4.5157e-01, -9.9893e-01,  9.9838e-01,  9.0901e-01, -8.0456e-01,\n",
            "          9.9865e-01, -4.9472e-01, -7.8378e-01, -8.5215e-01, -7.4604e-01,\n",
            "          8.2440e-01, -7.2407e-01,  6.1382e-01, -5.0355e-01,  9.9026e-01,\n",
            "          9.0011e-01, -4.4130e-01,  7.9850e-01,  9.2528e-01, -8.6090e-01,\n",
            "         -4.9386e-01,  9.0254e-01,  6.7241e-01,  3.8033e-01,  9.8732e-01,\n",
            "         -5.6069e-01, -8.1014e-01, -5.2685e-01,  7.6681e-01,  9.3729e-01,\n",
            "         -9.9998e-01,  9.3786e-01, -6.6648e-01, -9.5615e-01,  7.8734e-01,\n",
            "         -5.0469e-01, -7.5408e-01, -3.7807e-01, -2.9739e-01, -7.6400e-01,\n",
            "          1.4530e-01,  9.7762e-01,  8.1369e-01,  8.5985e-01, -9.9339e-01,\n",
            "         -9.9998e-01, -7.3552e-01, -7.0536e-01, -9.0831e-01, -6.1194e-01,\n",
            "          2.0329e-01,  9.7407e-01,  4.1802e-01,  3.6730e-01,  4.4390e-01,\n",
            "          9.9995e-01, -4.7762e-01,  9.9534e-01, -8.7512e-01,  9.4058e-01,\n",
            "         -9.9463e-01,  6.8098e-01,  6.0301e-01, -9.7767e-01, -7.0029e-01,\n",
            "          9.7449e-01, -4.5100e-01,  8.3072e-01, -9.8643e-01,  7.4374e-01,\n",
            "          1.0000e+00, -8.1041e-01, -5.8713e-01,  8.1166e-01, -9.1560e-01,\n",
            "          8.5692e-01, -5.2985e-02,  9.9710e-01, -9.9999e-01,  9.9364e-01,\n",
            "          7.6871e-02,  5.0795e-01,  7.2731e-01,  6.4951e-01,  5.7751e-01,\n",
            "         -6.8843e-01, -6.0838e-01, -9.9587e-01,  5.5562e-01,  5.8124e-01,\n",
            "         -6.7890e-01,  5.1538e-01,  9.4695e-01, -8.7807e-01, -9.9972e-01,\n",
            "         -7.2739e-01,  4.6804e-01,  9.7307e-01, -6.0716e-01, -9.9658e-01,\n",
            "          9.8772e-01, -4.0993e-01,  9.8384e-01,  8.2534e-02, -7.7298e-01,\n",
            "         -4.5374e-01, -4.1984e-01, -6.1764e-01,  7.1794e-01,  7.4161e-01,\n",
            "          8.7597e-01,  4.6544e-01, -8.7878e-01, -5.6187e-01, -2.8987e-01,\n",
            "         -8.6107e-01,  8.1894e-01, -1.6875e-01,  8.3776e-02,  7.7805e-01,\n",
            "          8.9412e-01,  9.9269e-01,  5.5614e-01,  6.0096e-02,  7.7655e-01,\n",
            "         -7.8660e-01, -6.4013e-01, -9.9989e-01,  9.9964e-01,  9.1317e-01,\n",
            "         -8.5221e-01, -9.9994e-01,  9.4922e-01,  3.9461e-01, -4.2097e-01,\n",
            "          7.8789e-01, -3.4433e-01, -8.1072e-01,  2.4719e-01,  8.8521e-01,\n",
            "         -1.0000e+00, -3.6319e-01,  4.6737e-01, -5.4267e-01, -5.8317e-01,\n",
            "         -9.9990e-01, -5.0668e-01,  2.7819e-01, -4.3426e-01,  4.1474e-01,\n",
            "          9.9964e-01, -5.9096e-01, -9.9408e-01, -9.8809e-01, -4.7412e-02,\n",
            "          7.7203e-01,  3.6091e-01, -9.8072e-01, -6.5512e-01,  9.2988e-01,\n",
            "         -9.9954e-01,  7.7154e-01, -6.2120e-01, -5.6919e-01,  3.6745e-01,\n",
            "          8.2203e-01,  9.5796e-01, -9.9999e-01,  9.1912e-01, -7.8497e-01,\n",
            "          9.3410e-01, -5.7173e-01,  6.0887e-01,  6.2909e-01,  5.3388e-01,\n",
            "         -9.9951e-01,  8.8796e-01,  4.2138e-01,  8.3675e-01,  7.7018e-01,\n",
            "          8.7838e-01, -2.7444e-01, -8.9910e-01, -7.1627e-01,  9.8989e-01,\n",
            "          9.8796e-01, -7.3399e-01,  7.5868e-01,  9.9971e-01, -7.1092e-01,\n",
            "          6.4531e-01,  6.2375e-01,  5.1813e-03, -9.9973e-01, -9.0389e-01,\n",
            "         -1.0640e-01, -5.4242e-01, -8.5037e-01]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training... :   0%|          | 0/127 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb70fdbcdc9d4d36a8aa15a5047d5374"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4208,  0.9998, -0.6310,  ..., -0.7825,  0.5701, -0.0048],\n",
            "        [ 0.6489,  1.0000,  0.9337,  ...,  0.7724, -0.3197, -0.7889],\n",
            "        [ 0.7058,  0.9999,  0.8978,  ...,  0.7411, -0.8257, -0.1277],\n",
            "        ...,\n",
            "        [-0.0599,  1.0000, -0.4202,  ..., -0.7771,  0.5094, -0.8747],\n",
            "        [ 0.7837,  1.0000, -0.1183,  ..., -0.7467,  0.8523, -0.8404],\n",
            "        [ 0.7486,  0.9998,  0.8096,  ...,  0.8942, -0.7075, -0.2666]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2873,  0.7575, -0.8246,  ..., -0.9095,  0.2883,  0.2058],\n",
            "        [ 0.5563,  1.0000,  0.9521,  ...,  0.7659, -0.7184, -0.6547],\n",
            "        [-0.3739,  0.8292, -0.8807,  ..., -0.9268,  0.4278,  0.2536],\n",
            "        ...,\n",
            "        [ 0.4712,  1.0000, -0.7422,  ..., -0.9455,  0.8006, -0.7228],\n",
            "        [ 0.5832,  0.9999,  0.8615,  ...,  0.8805, -0.6883, -0.4416],\n",
            "        [ 0.5218,  1.0000,  0.7669,  ...,  0.7842, -0.8049, -0.6360]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0698,  0.9958, -0.8743,  ..., -0.9063,  0.5800, -0.3739],\n",
            "        [ 0.1874,  1.0000,  0.9191,  ...,  0.6914, -0.2185, -0.5531],\n",
            "        [ 0.7103,  1.0000,  0.9502,  ...,  0.8843, -0.6574, -0.6803],\n",
            "        ...,\n",
            "        [ 0.6008,  0.9997,  0.9327,  ...,  0.8524, -0.6789, -0.5443],\n",
            "        [ 0.5607,  0.9999,  0.8773,  ...,  0.9035, -0.8387, -0.3018],\n",
            "        [ 0.6356,  0.9999,  0.8595,  ...,  0.8618, -0.8319, -0.2957]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5893,  0.9992,  0.9010,  ...,  0.8265, -0.8471, -0.6030],\n",
            "        [ 0.4840,  0.9999,  0.9457,  ...,  0.7972, -0.6605, -0.6112],\n",
            "        [ 0.3074,  1.0000,  0.4300,  ...,  0.4654, -0.1441, -0.6316],\n",
            "        ...,\n",
            "        [-0.2609,  0.9615, -0.9326,  ..., -0.8630,  0.4052, -0.0512],\n",
            "        [ 0.7041,  0.9997,  0.8571,  ...,  0.8287, -0.7294, -0.3680],\n",
            "        [-0.3611, -0.7389, -0.9543,  ..., -0.9310,  0.2545,  0.0540]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0396, -0.8898, -0.9377,  ..., -0.8757, -0.0283,  0.1015],\n",
            "        [ 0.6116,  1.0000,  0.9327,  ...,  0.7986, -0.0160, -0.8492],\n",
            "        [-0.6142,  0.3771, -0.9589,  ..., -0.9162,  0.1090,  0.3286],\n",
            "        ...,\n",
            "        [ 0.4457,  0.9998,  0.9284,  ...,  0.7610, -0.6382, -0.5993],\n",
            "        [ 0.7169,  0.9999,  0.7888,  ...,  0.8720, -0.6506, -0.3596],\n",
            "        [ 0.5531,  0.9997,  0.8979,  ...,  0.8383, -0.5330, -0.4408]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5204,  0.9998,  0.9519,  ...,  0.7782, -0.5418, -0.8132],\n",
            "        [ 0.6226,  0.9998,  0.9172,  ...,  0.6967, -0.7352, -0.6292],\n",
            "        [-0.1391,  0.9988,  0.2054,  ..., -0.8581,  0.3957, -0.7018],\n",
            "        ...,\n",
            "        [ 0.5889,  1.0000,  0.8304,  ...,  0.7504, -0.7683, -0.2584],\n",
            "        [-0.3119,  0.9997, -0.8110,  ..., -0.6595, -0.0702, -0.0335],\n",
            "        [-0.7224,  0.9855, -0.9205,  ..., -0.9257,  0.4897,  0.1093]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5438,  0.3356, -0.9123,  ..., -0.8794, -0.0148,  0.4335],\n",
            "        [ 0.6803,  1.0000,  0.9299,  ...,  0.8549, -0.7416, -0.2602],\n",
            "        [ 0.6540,  1.0000,  0.8438,  ...,  0.8804, -0.7413, -0.4056],\n",
            "        ...,\n",
            "        [ 0.7714,  1.0000,  0.9564,  ...,  0.8785, -0.6442, -0.7672],\n",
            "        [ 0.7324,  1.0000,  0.8232,  ...,  0.8911, -0.6466, -0.1293],\n",
            "        [-0.3584,  0.9952, -0.8296,  ..., -0.7652,  0.6721, -0.0366]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4728,  0.9999, -0.9264,  ..., -0.8594, -0.2802, -0.2139],\n",
            "        [ 0.6587,  1.0000,  0.8669,  ...,  0.9220, -0.8366, -0.3810],\n",
            "        [ 0.6655,  1.0000,  0.9038,  ...,  0.8546, -0.7021, -0.4887],\n",
            "        ...,\n",
            "        [-0.3228,  0.9250, -0.8890,  ..., -0.8408,  0.2324,  0.0309],\n",
            "        [-0.5675, -0.8336, -0.8936,  ..., -0.8688, -0.0841,  0.4364],\n",
            "        [-0.0440,  0.9585, -0.8503,  ..., -0.8550,  0.7491, -0.5254]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5784,  0.9956, -0.7585,  ..., -0.8650, -0.4090,  0.1006],\n",
            "        [ 0.2745,  0.9996,  0.9172,  ...,  0.4093, -0.2473, -0.4985],\n",
            "        [-0.2657,  0.9944, -0.5804,  ..., -0.9211,  0.2431, -0.5229],\n",
            "        ...,\n",
            "        [-0.4954, -0.0057, -0.9505,  ..., -0.9327,  0.5042,  0.4451],\n",
            "        [ 0.6983,  0.9999,  0.8569,  ...,  0.6950, -0.7272, -0.5069],\n",
            "        [-0.4771,  0.9304, -0.9324,  ..., -0.8768,  0.1213,  0.4533]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3996,  0.9999,  0.8887,  ...,  0.7995, -0.5921, -0.3524],\n",
            "        [-0.3390,  0.8097, -0.9386,  ..., -0.8955,  0.2679,  0.4087],\n",
            "        [ 0.6205,  0.9998,  0.9174,  ...,  0.8385, -0.7010, -0.6604],\n",
            "        ...,\n",
            "        [ 0.6002,  0.9999,  0.8780,  ...,  0.7935, -0.4720, -0.5480],\n",
            "        [ 0.6236,  0.9992,  0.8963,  ...,  0.8633, -0.7293, -0.2286],\n",
            "        [ 0.7045,  1.0000,  0.8521,  ...,  0.7992, -0.8080, -0.3298]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6125, -0.9981, -0.9565,  ..., -0.9525, -0.0331,  0.5019],\n",
            "        [ 0.6275,  0.9998,  0.8608,  ...,  0.8490, -0.7884, -0.2232],\n",
            "        [-0.2762,  0.9999, -0.3745,  ..., -0.5982,  0.3148, -0.6045],\n",
            "        ...,\n",
            "        [ 0.6754,  0.9999,  0.9515,  ...,  0.8111, -0.5889, -0.6677],\n",
            "        [ 0.7769,  1.0000,  0.9186,  ...,  0.6324, -0.7118, -0.6341],\n",
            "        [ 0.3230,  0.9999,  0.3943,  ..., -0.5077, -0.1084, -0.8445]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0823,  0.9998, -0.7141,  ..., -0.9020,  0.5798, -0.5205],\n",
            "        [-0.1836,  0.9991, -0.3790,  ..., -0.5781,  0.0307, -0.2891],\n",
            "        [-0.4387,  0.1731, -0.9093,  ..., -0.8588,  0.3116,  0.3064],\n",
            "        ...,\n",
            "        [ 0.4831,  1.0000,  0.9239,  ...,  0.6684,  0.1883, -0.8103],\n",
            "        [ 0.5029,  0.9999,  0.8009,  ...,  0.8728, -0.8592, -0.2111],\n",
            "        [ 0.4357,  0.9999,  0.8398,  ...,  0.8146, -0.7628, -0.1576]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5977,  1.0000,  0.8991,  ...,  0.8956, -0.6877, -0.0524],\n",
            "        [-0.0269,  0.7157, -0.8741,  ..., -0.8600,  0.3612,  0.1975],\n",
            "        [-0.3987,  0.8285, -0.8842,  ..., -0.8148,  0.5277,  0.7070],\n",
            "        ...,\n",
            "        [ 0.6269,  0.9996,  0.8403,  ...,  0.8560, -0.8585, -0.2533],\n",
            "        [ 0.7423,  0.9999,  0.8276,  ...,  0.6453, -0.2847, -0.7064],\n",
            "        [ 0.5536,  0.9993,  0.8763,  ...,  0.8519, -0.8208, -0.3578]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5901,  1.0000,  0.8098,  ...,  0.8073, -0.7372, -0.3045],\n",
            "        [ 0.2836,  0.9999,  0.2493,  ..., -0.6720,  0.2745, -0.7032],\n",
            "        [-0.4053, -0.9727, -0.9262,  ..., -0.9270, -0.1013,  0.4584],\n",
            "        ...,\n",
            "        [ 0.6165,  0.9994,  0.9024,  ...,  0.8971, -0.7867, -0.4874],\n",
            "        [-0.1623,  0.6854, -0.8539,  ..., -0.9116,  0.6003,  0.0085],\n",
            "        [ 0.6172,  0.9993,  0.8181,  ...,  0.8498, -0.6659, -0.2493]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6048,  0.9997,  0.6877,  ...,  0.8740, -0.8598, -0.3026],\n",
            "        [-0.0647, -0.2321, -0.9358,  ..., -0.9288,  0.1526,  0.1400],\n",
            "        [ 0.6405,  0.9997,  0.7561,  ...,  0.8211, -0.8383, -0.2169],\n",
            "        ...,\n",
            "        [-0.2733,  0.5468, -0.9210,  ..., -0.7893,  0.3139,  0.4878],\n",
            "        [ 0.3212,  1.0000, -0.6382,  ..., -0.7520,  0.8071, -0.7780],\n",
            "        [ 0.4338,  0.9999,  0.9348,  ...,  0.8319, -0.6556, -0.5155]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6978,  0.9999,  0.7491,  ...,  0.9345, -0.7649, -0.3127],\n",
            "        [-0.5665,  0.8526, -0.9271,  ..., -0.8710,  0.2451,  0.6117],\n",
            "        [ 0.5116,  1.0000,  0.9393,  ...,  0.8050, -0.4844, -0.7628],\n",
            "        ...,\n",
            "        [-0.4171,  0.9740, -0.8564,  ..., -0.7969,  0.4120, -0.1875],\n",
            "        [-0.1502, -0.0155, -0.9084,  ..., -0.8812,  0.2494,  0.3480],\n",
            "        [-0.5996,  0.9443, -0.8897,  ..., -0.9154, -0.1906, -0.1902]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6923,  0.9897, -0.8788,  ..., -0.8473,  0.3326, -0.1565],\n",
            "        [ 0.5059,  1.0000, -0.6692,  ..., -0.8455,  0.6411, -0.6276],\n",
            "        [ 0.3427,  0.9995,  0.8804,  ...,  0.8552, -0.7758, -0.4314],\n",
            "        ...,\n",
            "        [ 0.5639,  0.9999,  0.8872,  ...,  0.7106, -0.3422, -0.6109],\n",
            "        [ 0.3672,  0.9996,  0.8290,  ...,  0.8491, -0.8194, -0.3995],\n",
            "        [ 0.0777,  1.0000,  0.5813,  ...,  0.3400,  0.6216, -0.7590]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1522,  1.0000, -0.3750,  ..., -0.5845,  0.7518, -0.6344],\n",
            "        [-0.3247,  0.9992, -0.7890,  ..., -0.8530,  0.7256, -0.4662],\n",
            "        [ 0.4462,  0.9999,  0.8659,  ...,  0.8244, -0.8279, -0.4020],\n",
            "        ...,\n",
            "        [ 0.3344,  1.0000, -0.4164,  ..., -0.4255,  0.5697, -0.7821],\n",
            "        [ 0.5224,  0.9954,  0.8823,  ...,  0.8422, -0.7118, -0.3283],\n",
            "        [ 0.5323,  0.9995,  0.9141,  ...,  0.8469, -0.6713, -0.4795]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3293,  0.9999,  0.8819,  ...,  0.8530, -0.7814, -0.2687],\n",
            "        [ 0.5637,  0.9998,  0.8829,  ...,  0.8802, -0.7635, -0.3927],\n",
            "        [-0.3892, -0.3844, -0.8836,  ..., -0.9149, -0.0289,  0.6172],\n",
            "        ...,\n",
            "        [-0.1288,  1.0000,  0.2503,  ...,  0.0303,  0.6172, -0.6523],\n",
            "        [ 0.7797,  1.0000,  0.8646,  ...,  0.8331, -0.7029, -0.5957],\n",
            "        [ 0.4853,  1.0000,  0.8700,  ...,  0.6167, -0.7363, -0.4483]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4512,  0.9427, -0.8824,  ..., -0.8630,  0.3065,  0.0736],\n",
            "        [ 0.6266,  0.9999,  0.8269,  ...,  0.8717, -0.6509, -0.3667],\n",
            "        [ 0.6647,  0.9999,  0.9210,  ...,  0.8167, -0.7257, -0.4001],\n",
            "        ...,\n",
            "        [-0.3749,  0.9579, -0.6594,  ..., -0.8314,  0.2721, -0.0618],\n",
            "        [ 0.0438,  0.9973, -0.7761,  ..., -0.7922,  0.2190, -0.5783],\n",
            "        [ 0.7277,  0.9997,  0.9211,  ...,  0.8490, -0.4530, -0.6111]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7014,  0.9998,  0.7780,  ...,  0.8666, -0.7734, -0.2648],\n",
            "        [ 0.3532,  0.9996,  0.8486,  ...,  0.8641, -0.6625, -0.2880],\n",
            "        [ 0.4329,  1.0000,  0.8108,  ...,  0.7448, -0.3986, -0.4170],\n",
            "        ...,\n",
            "        [-0.4822, -0.9304, -0.9146,  ..., -0.8786,  0.4759,  0.1809],\n",
            "        [-0.6986, -0.6944, -0.9133,  ..., -0.9444,  0.0484,  0.4229],\n",
            "        [ 0.3200,  1.0000,  0.9359,  ...,  0.6039,  0.0129, -0.7702]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4996,  0.9906, -0.9276,  ..., -0.9166,  0.3624,  0.0972],\n",
            "        [-0.3214,  1.0000, -0.6745,  ..., -0.8223,  0.5618, -0.7851],\n",
            "        [ 0.5550,  0.9998,  0.8744,  ...,  0.8875, -0.8377, -0.2200],\n",
            "        ...,\n",
            "        [-0.3440, -0.3464, -0.8927,  ..., -0.9069,  0.3857, -0.0916],\n",
            "        [ 0.2978,  0.9999,  0.8921,  ...,  0.8465, -0.8170, -0.3751],\n",
            "        [-0.1195,  0.8843, -0.4155,  ..., -0.8413,  0.1238, -0.7026]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5394,  0.9999,  0.7472,  ...,  0.7769, -0.7486, -0.1444],\n",
            "        [ 0.5461,  0.9994,  0.8350,  ...,  0.6847, -0.7692,  0.0899],\n",
            "        [ 0.3463,  1.0000, -0.3206,  ..., -0.8029,  0.8279, -0.7036],\n",
            "        ...,\n",
            "        [ 0.6712,  0.9999,  0.8174,  ...,  0.8317, -0.7239, -0.3121],\n",
            "        [ 0.1056,  0.9354, -0.8251,  ..., -0.8969,  0.2763, -0.5631],\n",
            "        [ 0.6911,  0.9997,  0.8065,  ...,  0.8121, -0.7825, -0.5705]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3648,  0.9088, -0.8504,  ..., -0.8419, -0.2480,  0.4147],\n",
            "        [ 0.4332,  0.9995,  0.8696,  ...,  0.8238, -0.7861, -0.0950],\n",
            "        [ 0.6432,  1.0000,  0.9180,  ...,  0.2146,  0.2886, -0.9718],\n",
            "        ...,\n",
            "        [ 0.1219,  0.9787, -0.7635,  ..., -0.8597,  0.3524, -0.3430],\n",
            "        [ 0.5795,  0.9994,  0.8562,  ...,  0.8292, -0.8134,  0.0096],\n",
            "        [ 0.6892,  0.9999,  0.8975,  ...,  0.8662, -0.7384, -0.4638]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5410,  0.9979,  0.8486,  ...,  0.8277, -0.6905, -0.4721],\n",
            "        [ 0.6715,  0.9999,  0.8672,  ...,  0.8511, -0.5490, -0.4002],\n",
            "        [-0.3740, -0.9058, -0.9195,  ..., -0.8755,  0.1506,  0.5926],\n",
            "        ...,\n",
            "        [-0.4599,  0.4576, -0.8574,  ..., -0.8868,  0.2931,  0.2083],\n",
            "        [ 0.4736,  0.9999,  0.8010,  ...,  0.7754, -0.7455, -0.5699],\n",
            "        [ 0.6097,  0.9993,  0.8999,  ...,  0.8306, -0.7835, -0.1744]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3507,  0.9980, -0.7926,  ..., -0.8866,  0.3395, -0.3489],\n",
            "        [ 0.3040,  0.9992,  0.8611,  ...,  0.7740, -0.7270, -0.4677],\n",
            "        [ 0.4684,  0.9991,  0.6402,  ...,  0.7861, -0.8493, -0.2804],\n",
            "        ...,\n",
            "        [-0.4771,  0.9926, -0.6470,  ..., -0.7774,  0.3021, -0.7133],\n",
            "        [ 0.7176,  0.9999,  0.8761,  ...,  0.8388, -0.7625, -0.4443],\n",
            "        [-0.3336,  0.9849, -0.7624,  ..., -0.9033,  0.4870, -0.1168]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6019, -0.5272, -0.9410,  ..., -0.9063,  0.4285,  0.4867],\n",
            "        [ 0.6174,  0.9991,  0.8802,  ...,  0.8399, -0.8154, -0.2691],\n",
            "        [ 0.4136,  0.9997,  0.8333,  ...,  0.8931, -0.7295, -0.4620],\n",
            "        ...,\n",
            "        [-0.3628,  1.0000, -0.5935,  ..., -0.9028,  0.2295, -0.5320],\n",
            "        [-0.6523,  0.5364, -0.9277,  ..., -0.9266,  0.1679,  0.7081],\n",
            "        [-0.4456,  0.9076, -0.7317,  ..., -0.8893,  0.4094,  0.4432]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2720,  0.9909, -0.7432,  ..., -0.7633,  0.2405, -0.3141],\n",
            "        [-0.4039, -0.2653, -0.9280,  ..., -0.9194,  0.3616,  0.0486],\n",
            "        [-0.3849,  0.9658, -0.6128,  ..., -0.8778,  0.4653, -0.2866],\n",
            "        ...,\n",
            "        [ 0.5921,  0.9997,  0.8820,  ...,  0.8905, -0.8179, -0.2027],\n",
            "        [-0.3641, -0.9480, -0.8122,  ..., -0.8261,  0.4978, -0.3297],\n",
            "        [-0.4231, -0.2090, -0.9309,  ..., -0.8445,  0.1215,  0.3632]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3555,  0.9947,  0.8978,  ...,  0.7593, -0.8419,  0.1716],\n",
            "        [ 0.3608,  0.9998,  0.8311,  ...,  0.7537, -0.7167, -0.3312],\n",
            "        [ 0.5896,  0.9997,  0.8156,  ...,  0.8410, -0.8336, -0.3293],\n",
            "        ...,\n",
            "        [-0.3620,  0.6284, -0.9134,  ..., -0.8665,  0.3214,  0.4018],\n",
            "        [ 0.4966,  0.9997,  0.9355,  ...,  0.7854, -0.8603, -0.4859],\n",
            "        [ 0.4826,  0.9996,  0.8495,  ...,  0.8694, -0.8253, -0.4314]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5891,  1.0000,  0.7935,  ...,  0.7595, -0.6725, -0.6661],\n",
            "        [ 0.6635,  0.9999,  0.7305,  ...,  0.8038, -0.8479, -0.3125],\n",
            "        [-0.1224,  0.9366, -0.8588,  ..., -0.8927,  0.6120, -0.2984],\n",
            "        ...,\n",
            "        [ 0.6635,  0.9999,  0.8631,  ...,  0.8358, -0.7822, -0.2706],\n",
            "        [-0.6278, -0.8690, -0.8999,  ..., -0.9326,  0.2829,  0.4044],\n",
            "        [ 0.5612,  1.0000,  0.9522,  ...,  0.8948, -0.3548, -0.7164]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6631, -0.9432, -0.9175,  ..., -0.9502,  0.1655,  0.6526],\n",
            "        [ 0.0952,  0.9991, -0.4516,  ..., -0.8520, -0.0460, -0.4996],\n",
            "        [ 0.7227,  0.9999,  0.8054,  ...,  0.8743, -0.6781, -0.3615],\n",
            "        ...,\n",
            "        [-0.4848, -1.0000, -0.8947,  ..., -0.9349, -0.1239,  0.8254],\n",
            "        [ 0.8087,  0.9998,  0.8925,  ...,  0.8662, -0.7843, -0.5181],\n",
            "        [-0.6814, -0.9040, -0.9349,  ..., -0.9347,  0.1035,  0.4040]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5284,  0.9998,  0.8016,  ...,  0.8903, -0.8059, -0.3463],\n",
            "        [ 0.4999,  0.9997,  0.8807,  ...,  0.8860, -0.8333, -0.2660],\n",
            "        [-0.2432,  0.9967, -0.8755,  ..., -0.9136,  0.2169, -0.1371],\n",
            "        ...,\n",
            "        [-0.0892,  0.9999, -0.4755,  ..., -0.5636,  0.5645, -0.7061],\n",
            "        [ 0.6053,  0.9995,  0.9270,  ...,  0.9022, -0.7976, -0.3560],\n",
            "        [ 0.5111,  0.9999,  0.9324,  ...,  0.8905, -0.5516, -0.4855]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5610,  0.9998,  0.8579,  ...,  0.7596, -0.6498, -0.4695],\n",
            "        [-0.3598,  0.9497, -0.9389,  ..., -0.7781,  0.5167,  0.5341],\n",
            "        [ 0.5801,  0.9997,  0.9315,  ...,  0.8031, -0.7684, -0.1580],\n",
            "        ...,\n",
            "        [ 0.7506,  1.0000,  0.7207,  ...,  0.7625, -0.6060, -0.7045],\n",
            "        [-0.1453,  0.9953, -0.9133,  ..., -0.9337,  0.3104,  0.0231],\n",
            "        [-0.3793, -0.9459, -0.9030,  ..., -0.8980,  0.0664,  0.6568]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4324,  0.1324, -0.8086,  ..., -0.8408, -0.2901,  0.5021],\n",
            "        [-0.6078,  0.9482, -0.8140,  ..., -0.9060,  0.0257,  0.4441],\n",
            "        [ 0.6379,  0.9998,  0.8505,  ...,  0.8991, -0.8186, -0.6439],\n",
            "        ...,\n",
            "        [-0.6971, -0.2485, -0.8795,  ..., -0.9354,  0.2354,  0.4688],\n",
            "        [ 0.6927,  0.9999,  0.9239,  ...,  0.7091, -0.6852, -0.6039],\n",
            "        [ 0.2841,  0.9959,  0.8448,  ...,  0.8403, -0.9090, -0.0060]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6000,  1.0000,  0.9358,  ...,  0.8883, -0.8199, -0.6872],\n",
            "        [ 0.5269,  0.9999,  0.8736,  ...,  0.7545, -0.7867, -0.3569],\n",
            "        [ 0.5402,  0.9999,  0.7947,  ...,  0.8115, -0.7623, -0.3234],\n",
            "        ...,\n",
            "        [-0.6425, -0.0638, -0.9075,  ..., -0.8639,  0.1518,  0.5786],\n",
            "        [-0.3877,  0.9552, -0.7962,  ..., -0.8344,  0.6688, -0.5015],\n",
            "        [ 0.5781,  0.9998,  0.8924,  ...,  0.8956, -0.7222, -0.4993]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4084, -0.9888, -0.9660,  ..., -0.9079,  0.0548,  0.6869],\n",
            "        [-0.3816, -0.9451, -0.9069,  ..., -0.9071,  0.2794,  0.5660],\n",
            "        [ 0.5724,  0.9989,  0.9101,  ...,  0.8293, -0.7707, -0.3830],\n",
            "        ...,\n",
            "        [ 0.7928,  0.9992,  0.7484,  ...,  0.8898, -0.7582, -0.3012],\n",
            "        [-0.7114,  0.9742, -0.8536,  ..., -0.9091,  0.0210,  0.5525],\n",
            "        [-0.5171, -0.9462, -0.8971,  ..., -0.8935,  0.2790,  0.6206]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6193, -0.2941, -0.9344,  ..., -0.8192,  0.4552,  0.2532],\n",
            "        [ 0.6244,  0.9997,  0.7618,  ...,  0.7916, -0.7039, -0.2056],\n",
            "        [ 0.3869,  1.0000,  0.0717,  ..., -0.6170,  0.2597, -0.8219],\n",
            "        ...,\n",
            "        [ 0.4276,  0.9990,  0.8933,  ...,  0.8083, -0.8510, -0.5019],\n",
            "        [ 0.4658,  0.9994,  0.9300,  ...,  0.7822, -0.5581, -0.6122],\n",
            "        [ 0.6064,  0.9998,  0.8742,  ...,  0.7254, -0.4014, -0.6739]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5683,  0.9966,  0.8595,  ...,  0.8659, -0.7984,  0.0386],\n",
            "        [ 0.4716,  1.0000,  0.8309,  ...,  0.6171, -0.6242, -0.3863],\n",
            "        [ 0.5422,  0.9998,  0.8050,  ...,  0.7775, -0.8892, -0.1386],\n",
            "        ...,\n",
            "        [-0.9034,  0.3998, -0.8822,  ..., -0.8306,  0.2420,  0.6882],\n",
            "        [ 0.2192,  0.9998, -0.8415,  ..., -0.9009,  0.5998, -0.3918],\n",
            "        [-0.1075,  0.9996, -0.8245,  ..., -0.9172,  0.4288,  0.0673]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1436,  0.4044, -0.9530,  ..., -0.8732,  0.4991,  0.2370],\n",
            "        [-0.1878,  0.9999, -0.4958,  ..., -0.7371,  0.0532, -0.6897],\n",
            "        [ 0.4593,  0.9997,  0.8927,  ...,  0.9379, -0.6755, -0.3805],\n",
            "        ...,\n",
            "        [ 0.6094,  0.9999,  0.9170,  ...,  0.8712, -0.5511, -0.5407],\n",
            "        [ 0.5537,  0.9996,  0.8079,  ...,  0.9105, -0.7658, -0.3515],\n",
            "        [ 0.0227,  1.0000,  0.8829,  ...,  0.4080, -0.4915, -0.8728]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3139,  1.0000,  0.9319,  ...,  0.2758, -0.3348, -0.8742],\n",
            "        [ 0.6467,  0.9993,  0.8348,  ...,  0.8874, -0.7330, -0.2178],\n",
            "        [ 0.6913,  0.9995,  0.8461,  ...,  0.8961, -0.6674, -0.5259],\n",
            "        ...,\n",
            "        [-0.5167,  0.9734, -0.8321,  ..., -0.8970,  0.3705,  0.2120],\n",
            "        [ 0.3362,  0.9993,  0.8825,  ...,  0.8864, -0.8030, -0.0466],\n",
            "        [-0.2241, -0.7491, -0.9457,  ..., -0.9056,  0.2710,  0.5285]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6867,  0.9999,  0.9268,  ...,  0.9264, -0.8679, -0.5972],\n",
            "        [-0.2440, -0.6139, -0.9206,  ..., -0.8862,  0.3235,  0.0958],\n",
            "        [ 0.3986,  1.0000, -0.4049,  ..., -0.8591,  0.7375, -0.7542],\n",
            "        ...,\n",
            "        [ 0.2534,  1.0000,  0.9146,  ...,  0.5662, -0.3091, -0.8938],\n",
            "        [ 0.6227,  0.9993,  0.9247,  ...,  0.8425, -0.7614, -0.5880],\n",
            "        [ 0.5781,  0.9999,  0.8099,  ...,  0.8121, -0.8157, -0.1564]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6042,  0.9999,  0.9548,  ...,  0.7503, -0.6162, -0.4328],\n",
            "        [-0.0123,  1.0000, -0.5278,  ..., -0.3039,  0.6988, -0.7134],\n",
            "        [-0.3155, -0.9003, -0.9308,  ..., -0.8069,  0.3218,  0.1103],\n",
            "        ...,\n",
            "        [ 0.6777,  0.9940,  0.8032,  ...,  0.9098, -0.8078, -0.0999],\n",
            "        [ 0.6593,  0.9995,  0.8010,  ...,  0.8043, -0.8040, -0.3073],\n",
            "        [ 0.4880,  0.9998,  0.9218,  ...,  0.7051, -0.8458, -0.3179]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5092,  0.9992,  0.8645,  ...,  0.8388, -0.6507, -0.0521],\n",
            "        [ 0.6292,  1.0000,  0.7977,  ...,  0.7916, -0.6475, -0.6370],\n",
            "        [ 0.4010,  1.0000,  0.8799,  ...,  0.8193, -0.8355, -0.5491],\n",
            "        ...,\n",
            "        [ 0.5547,  1.0000, -0.5822,  ..., -0.8740,  0.8428, -0.6373],\n",
            "        [-0.5596, -0.9928, -0.9000,  ..., -0.9200,  0.1321,  0.6685],\n",
            "        [-0.6399, -0.9726, -0.9409,  ..., -0.8547,  0.2772,  0.6639]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5924,  1.0000,  0.7882,  ...,  0.7779, -0.7024, -0.4237],\n",
            "        [ 0.7700,  1.0000,  0.9616,  ...,  0.7540, -0.6806, -0.6385],\n",
            "        [ 0.4368,  0.9999,  0.8493,  ...,  0.4805, -0.6879, -0.8434],\n",
            "        ...,\n",
            "        [-0.5426, -0.2312, -0.8933,  ..., -0.9412, -0.1840,  0.1794],\n",
            "        [ 0.6624,  1.0000,  0.7831,  ...,  0.8294, -0.5705, -0.6388],\n",
            "        [-0.6819, -0.9904, -0.9488,  ..., -0.9304,  0.1399,  0.3615]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7264,  0.9999,  0.9226,  ...,  0.8992, -0.7658, -0.6097],\n",
            "        [ 0.8332,  1.0000,  0.9593,  ...,  0.8496, -0.3592, -0.7993],\n",
            "        [-0.6142, -0.9937, -0.9437,  ..., -0.9004,  0.2448,  0.5916],\n",
            "        ...,\n",
            "        [ 0.5139,  0.9991,  0.8195,  ...,  0.8143, -0.8541, -0.1385],\n",
            "        [-0.6011,  0.6809, -0.9489,  ..., -0.8853,  0.0031,  0.2601],\n",
            "        [ 0.3470,  0.9998,  0.7968,  ...,  0.8547, -0.6337, -0.1987]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-6.4272e-01, -9.9945e-01, -9.1701e-01,  ..., -9.1431e-01,\n",
            "         -9.5171e-05,  6.6076e-01],\n",
            "        [ 5.7404e-01,  9.9859e-01,  7.7638e-01,  ...,  8.3336e-01,\n",
            "         -7.6449e-01, -1.1863e-01],\n",
            "        [ 6.4592e-01,  9.9995e-01,  9.5652e-01,  ...,  4.3635e-01,\n",
            "         -4.8073e-01, -5.0494e-01],\n",
            "        ...,\n",
            "        [ 5.3654e-01,  9.9998e-01,  7.4417e-01,  ...,  8.7016e-01,\n",
            "         -7.4346e-01, -7.7988e-01],\n",
            "        [-7.2893e-01, -4.4739e-01, -7.8722e-01,  ..., -9.2737e-01,\n",
            "         -8.0032e-02,  2.9502e-01],\n",
            "        [-7.0917e-01,  1.4797e-01, -9.5905e-01,  ..., -8.3285e-01,\n",
            "          1.6844e-02,  5.6408e-01]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6054,  0.9991,  0.8106,  ...,  0.8573, -0.8444, -0.2776],\n",
            "        [ 0.4554,  0.9997,  0.8883,  ...,  0.8622, -0.8619, -0.3666],\n",
            "        [-0.5950, -0.9974, -0.9477,  ..., -0.9161,  0.2724,  0.5600],\n",
            "        ...,\n",
            "        [-0.5941, -0.1413, -0.9398,  ..., -0.9109,  0.0389,  0.4888],\n",
            "        [ 0.7034,  1.0000,  0.7955,  ...,  0.4641, -0.7359, -0.5551],\n",
            "        [-0.2686, -0.9855, -0.9169,  ..., -0.8852,  0.1259,  0.3871]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4500, -0.9916, -0.9546,  ..., -0.9323,  0.0527,  0.3512],\n",
            "        [ 0.4639,  0.9994,  0.8444,  ...,  0.8637, -0.9010, -0.3153],\n",
            "        [-0.3448, -0.6136, -0.9550,  ..., -0.9139,  0.2845,  0.5418],\n",
            "        ...,\n",
            "        [ 0.4270,  0.9999,  0.7637,  ...,  0.9057, -0.7030, -0.2809],\n",
            "        [ 0.6661,  1.0000,  0.8205,  ...,  0.9291, -0.7054, -0.6955],\n",
            "        [ 0.4958,  1.0000,  0.8984,  ...,  0.6415, -0.2763, -0.8785]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5376, -0.9985, -0.8636,  ..., -0.8568,  0.0751,  0.7093],\n",
            "        [ 0.5323,  0.9992,  0.7931,  ...,  0.8426, -0.7878, -0.3603],\n",
            "        [ 0.3373,  1.0000,  0.7593,  ...,  0.3313, -0.2677, -0.6430],\n",
            "        ...,\n",
            "        [ 0.5793,  0.9994,  0.9171,  ...,  0.8159, -0.7739, -0.3800],\n",
            "        [-0.7123, -0.9916, -0.9353,  ..., -0.8995,  0.1539,  0.6447],\n",
            "        [-0.4509,  0.6330, -0.9242,  ..., -0.9289,  0.3437,  0.2942]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6746,  0.1686, -0.8979,  ..., -0.9464, -0.0055,  0.2110],\n",
            "        [ 0.4941,  0.9995,  0.7166,  ...,  0.7719, -0.6922, -0.6619],\n",
            "        [ 0.6064,  1.0000,  0.8103,  ...,  0.3033,  0.0335, -0.7614],\n",
            "        ...,\n",
            "        [ 0.3870,  1.0000,  0.7001,  ...,  0.3728, -0.2922, -0.7360],\n",
            "        [ 0.6473,  0.9999,  0.7901,  ...,  0.7139, -0.7902, -0.4431],\n",
            "        [ 0.3970,  0.9996,  0.9282,  ...,  0.8774, -0.6758, -0.5774]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.7486,  0.0381, -0.6827,  ..., -0.7614, -0.2100,  0.7546],\n",
            "        [ 0.4304,  0.9993,  0.7307,  ...,  0.7100, -0.6930, -0.0267],\n",
            "        [ 0.0068,  0.9993, -0.8521,  ..., -0.8004,  0.6238, -0.5358],\n",
            "        ...,\n",
            "        [-0.7074, -0.6910, -0.9107,  ..., -0.8928,  0.0157,  0.4924],\n",
            "        [-0.5587, -0.9724, -0.9694,  ..., -0.8904, -0.0304,  0.5354],\n",
            "        [-0.1846,  0.6632, -0.9203,  ..., -0.8110,  0.3810,  0.0551]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5987,  0.9990,  0.7744,  ...,  0.8069, -0.7975, -0.3409],\n",
            "        [-0.6055, -0.9999, -0.9245,  ..., -0.9301,  0.2868,  0.8136],\n",
            "        [-0.6296, -0.5834, -0.9642,  ..., -0.8857,  0.0709,  0.4996],\n",
            "        ...,\n",
            "        [-0.6655, -0.9428, -0.9542,  ..., -0.8405,  0.3515,  0.3335],\n",
            "        [ 0.6421,  0.9998,  0.8587,  ...,  0.8256, -0.8703, -0.1156],\n",
            "        [ 0.5829,  1.0000,  0.7133,  ..., -0.2155,  0.0877, -0.8768]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6266,  0.9997,  0.8923,  ...,  0.7952, -0.7212, -0.4762],\n",
            "        [ 0.6932,  0.9997,  0.8497,  ...,  0.8785, -0.8153, -0.4388],\n",
            "        [-0.3460,  0.8456, -0.9251,  ..., -0.7374,  0.4434,  0.5510],\n",
            "        ...,\n",
            "        [ 0.7832,  0.9997,  0.8448,  ...,  0.8827, -0.7699, -0.3096],\n",
            "        [-0.5962, -0.9455, -0.9524,  ..., -0.8876, -0.0362,  0.6161],\n",
            "        [-0.5021, -0.8134, -0.9006,  ..., -0.9221, -0.1302,  0.4432]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5525, -0.9900, -0.9596,  ..., -0.9293,  0.3066,  0.5437],\n",
            "        [ 0.6128,  0.9996,  0.8696,  ...,  0.8965, -0.8818, -0.2314],\n",
            "        [ 0.4065,  0.9994,  0.7266,  ...,  0.8293, -0.8541, -0.3890],\n",
            "        ...,\n",
            "        [ 0.5716,  1.0000,  0.7391,  ...,  0.7228, -0.6701, -0.4863],\n",
            "        [ 0.5731,  1.0000,  0.8177,  ...,  0.7115, -0.6578, -0.5596],\n",
            "        [-0.6091, -0.9598, -0.9463,  ..., -0.8334,  0.2784,  0.5442]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6379,  0.9997,  0.8771,  ...,  0.8117, -0.7683, -0.5670],\n",
            "        [ 0.7904,  1.0000,  0.9311,  ...,  0.8462, -0.6035, -0.7140],\n",
            "        [-0.4844, -0.1927, -0.9383,  ..., -0.8277,  0.3357,  0.2876],\n",
            "        ...,\n",
            "        [-0.4177, -0.9723, -0.9421,  ..., -0.9113, -0.0700,  0.7765],\n",
            "        [-0.5705, -0.9920, -0.9317,  ..., -0.9033, -0.0368,  0.7384],\n",
            "        [-0.6506, -0.9995, -0.9421,  ..., -0.9187,  0.1939,  0.7436]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5926,  0.9999,  0.9357,  ...,  0.8849, -0.6709, -0.3004],\n",
            "        [-0.4798,  0.6229, -0.9200,  ..., -0.9325,  0.1921,  0.1879],\n",
            "        [ 0.4062,  0.9995,  0.7946,  ...,  0.8207, -0.8021, -0.4733],\n",
            "        ...,\n",
            "        [ 0.6729,  1.0000,  0.8559,  ...,  0.7378, -0.7630, -0.6685],\n",
            "        [-0.7196, -0.8395, -0.8153,  ..., -0.8871,  0.2024,  0.7319],\n",
            "        [ 0.6254,  1.0000,  0.7212,  ..., -0.0327, -0.4685, -0.9389]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5255,  0.9997,  0.7980,  ...,  0.9022, -0.8312, -0.1989],\n",
            "        [ 0.6118,  0.9999,  0.7666,  ...,  0.8942, -0.8165, -0.1444],\n",
            "        [ 0.5011,  1.0000,  0.7072,  ...,  0.5305, -0.7282, -0.3475],\n",
            "        ...,\n",
            "        [ 0.4940,  1.0000,  0.8704,  ...,  0.8000, -0.6848, -0.3742],\n",
            "        [ 0.6036,  0.9986,  0.7358,  ...,  0.7868, -0.8597, -0.1500],\n",
            "        [-0.6219, -0.7819, -0.9533,  ..., -0.8970,  0.1019,  0.6087]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1862,  0.9997, -0.7737,  ..., -0.7282, -0.1487, -0.2377],\n",
            "        [ 0.6484,  0.9997,  0.8559,  ...,  0.8607, -0.6982, -0.3084],\n",
            "        [-0.3723,  0.4654, -0.9360,  ..., -0.9176,  0.2714,  0.3820],\n",
            "        ...,\n",
            "        [-0.7314,  0.5184, -0.8977,  ..., -0.9373, -0.1565,  0.4736],\n",
            "        [ 0.5804,  1.0000,  0.9165,  ...,  0.5678, -0.6063, -0.7865],\n",
            "        [ 0.6908,  1.0000,  0.9385,  ...,  0.6437, -0.0354, -0.9662]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2520,  0.9909, -0.7500,  ..., -0.8008,  0.4440, -0.0852],\n",
            "        [-0.2428,  0.6364, -0.9410,  ..., -0.9208,  0.3052,  0.4481],\n",
            "        [ 0.6692,  0.9995,  0.9104,  ...,  0.8977, -0.8225, -0.2744],\n",
            "        ...,\n",
            "        [-0.4010, -0.7815, -0.9447,  ..., -0.8793,  0.1221,  0.3426],\n",
            "        [ 0.7211,  1.0000,  0.8770,  ...,  0.7439, -0.5333, -0.3700],\n",
            "        [-0.5946, -0.1825, -0.8998,  ..., -0.9066,  0.0240,  0.4924]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3051,  1.0000,  0.7123,  ...,  0.2184,  0.2621, -0.6722],\n",
            "        [-0.4891, -0.6198, -0.9195,  ..., -0.9202,  0.0260,  0.3343],\n",
            "        [ 0.5886,  1.0000,  0.8689,  ...,  0.7292, -0.5745, -0.5839],\n",
            "        ...,\n",
            "        [ 0.4931,  1.0000,  0.8554,  ...,  0.8058, -0.7089, -0.5768],\n",
            "        [ 0.4521,  1.0000,  0.9365,  ...,  0.2080, -0.4716, -0.7383],\n",
            "        [ 0.5760,  1.0000,  0.9018,  ...,  0.6803, -0.3661, -0.8293]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6957,  0.9999,  0.8443,  ...,  0.7991, -0.6692, -0.5150],\n",
            "        [-0.3953, -0.0036, -0.9284,  ..., -0.8920,  0.0834,  0.4293],\n",
            "        [-0.5883, -0.9461, -0.9316,  ..., -0.9396, -0.1688,  0.5704],\n",
            "        ...,\n",
            "        [-0.2859,  0.9798, -0.8925,  ..., -0.8963,  0.6845,  0.1264],\n",
            "        [-0.2758, -0.8692, -0.9241,  ..., -0.8232,  0.2485,  0.6044],\n",
            "        [-0.6807, -0.9776, -0.9336,  ..., -0.9273,  0.4941,  0.0819]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.7045,  0.9997, -0.5014,  ..., -0.8511, -0.1504, -0.6341],\n",
            "        [-0.6399, -0.9993, -0.9527,  ..., -0.9125,  0.2760,  0.6812],\n",
            "        [-0.2931,  0.9006, -0.9105,  ..., -0.8729, -0.0989,  0.4527],\n",
            "        ...,\n",
            "        [ 0.5780,  0.9999,  0.9316,  ...,  0.5477, -0.5617,  0.0219],\n",
            "        [ 0.7285,  1.0000,  0.9031,  ...,  0.8544, -0.4941, -0.7469],\n",
            "        [-0.3460, -0.5542, -0.9263,  ..., -0.9175,  0.1367,  0.6194]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5850,  1.0000,  0.9406,  ...,  0.8897, -0.7484, -0.6189],\n",
            "        [-0.6022, -0.9615, -0.9411,  ..., -0.9059,  0.0902,  0.6836],\n",
            "        [ 0.5799,  1.0000,  0.8607,  ...,  0.7653, -0.6502, -0.4115],\n",
            "        ...,\n",
            "        [ 0.5036,  0.9999,  0.8164,  ...,  0.9046, -0.7644, -0.6540],\n",
            "        [-0.3599, -0.3845, -0.9046,  ..., -0.8008,  0.2795,  0.2217],\n",
            "        [ 0.4284,  0.9998,  0.8837,  ...,  0.7823, -0.6860, -0.6523]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6628,  1.0000,  0.8799,  ...,  0.9140, -0.6522, -0.6032],\n",
            "        [-0.5285,  0.3158, -0.9176,  ..., -0.7945,  0.4346, -0.1762],\n",
            "        [ 0.7301,  0.9998,  0.8801,  ...,  0.9014, -0.7832, -0.3430],\n",
            "        ...,\n",
            "        [ 0.7879,  1.0000,  0.9294,  ...,  0.8167, -0.4531, -0.6772],\n",
            "        [-0.5594, -0.4115, -0.9380,  ..., -0.9176,  0.1904,  0.6354],\n",
            "        [-0.1210, -0.8416, -0.7367,  ..., -0.8702,  0.3275,  0.1622]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4920,  1.0000,  0.8997,  ...,  0.8927, -0.2831, -0.7262],\n",
            "        [ 0.6491,  1.0000,  0.8506,  ...,  0.9433, -0.7538, -0.6296],\n",
            "        [-0.6032, -0.5558, -0.9327,  ..., -0.8866,  0.4612,  0.5456],\n",
            "        ...,\n",
            "        [-0.5240, -0.9601, -0.9289,  ..., -0.9093, -0.0186,  0.3552],\n",
            "        [-0.4537, -0.9137, -0.9325,  ..., -0.8823,  0.0614,  0.4359],\n",
            "        [ 0.7007,  1.0000,  0.8515,  ...,  0.6715, -0.4257, -0.7379]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5800,  1.0000,  0.9567,  ...,  0.9044, -0.5977, -0.7328],\n",
            "        [-0.2202, -0.0471, -0.8868,  ..., -0.8413,  0.2655,  0.4752],\n",
            "        [-0.4721, -0.9934, -0.8810,  ..., -0.9121, -0.0010,  0.5637],\n",
            "        ...,\n",
            "        [ 0.4105,  0.9999,  0.8297,  ...,  0.7662, -0.8147, -0.3097],\n",
            "        [ 0.4499,  1.0000,  0.8801,  ...,  0.6739, -0.4950, -0.7615],\n",
            "        [ 0.6903,  0.9999,  0.8621,  ...,  0.8691, -0.7406, -0.5677]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6886,  0.9998,  0.8562,  ...,  0.8954, -0.6771, -0.3875],\n",
            "        [ 0.5364,  1.0000,  0.8841,  ...,  0.7615, -0.4850, -0.6984],\n",
            "        [-0.6967, -0.9263, -0.8847,  ..., -0.9167,  0.4129,  0.3115],\n",
            "        ...,\n",
            "        [-0.2243,  0.9760, -0.8953,  ..., -0.8867,  0.2763,  0.1253],\n",
            "        [ 0.6199,  1.0000,  0.8858,  ...,  0.8666, -0.6048, -0.4031],\n",
            "        [ 0.6317,  1.0000,  0.9279,  ...,  0.8594, -0.3483, -0.8071]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6771,  0.6994, -0.9392,  ..., -0.9364,  0.1201,  0.4110],\n",
            "        [ 0.7965,  1.0000,  0.7891,  ...,  0.7940, -0.6477, -0.6597],\n",
            "        [-0.7035, -0.9399, -0.9448,  ..., -0.8833, -0.3506,  0.7831],\n",
            "        ...,\n",
            "        [ 0.7817,  1.0000,  0.9559,  ...,  0.6869, -0.3621, -0.9135],\n",
            "        [ 0.6074,  1.0000,  0.8115,  ...,  0.8539, -0.6677, -0.7358],\n",
            "        [ 0.7340,  0.9999,  0.8558,  ...,  0.8716, -0.7882, -0.5276]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0287, -0.8264, -0.6897,  ..., -0.8503,  0.1366, -0.5636],\n",
            "        [ 0.5223,  1.0000,  0.7346,  ...,  0.6903, -0.5978, -0.8864],\n",
            "        [-0.7704, -0.9221, -0.9093,  ..., -0.8587,  0.5382,  0.4461],\n",
            "        ...,\n",
            "        [ 0.6738,  1.0000,  0.9231,  ...,  0.8932, -0.4893, -0.6836],\n",
            "        [ 0.3151,  0.9999,  0.9004,  ...,  0.5650, -0.1663, -0.7731],\n",
            "        [-0.6520, -0.9082, -0.9558,  ..., -0.9062,  0.3278,  0.3740]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6265,  0.9999,  0.9438,  ...,  0.8403, -0.6476, -0.5917],\n",
            "        [ 0.4782,  1.0000,  0.9460,  ...,  0.3751,  0.4339, -0.9374],\n",
            "        [-0.7423,  0.9991, -0.8680,  ..., -0.9392,  0.1002,  0.0281],\n",
            "        ...,\n",
            "        [-0.6625, -0.9836, -0.9230,  ..., -0.8413,  0.0097,  0.6664],\n",
            "        [ 0.7157,  1.0000,  0.8839,  ...,  0.8407, -0.8465, -0.2360],\n",
            "        [-0.5984,  0.2810, -0.9053,  ..., -0.8620,  0.1956,  0.3125]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7841,  0.9999,  0.8927,  ...,  0.8738, -0.6743, -0.5191],\n",
            "        [ 0.7163,  0.9999,  0.8955,  ...,  0.8433, -0.5490, -0.4859],\n",
            "        [ 0.6283,  1.0000,  0.8948,  ...,  0.6434, -0.6670, -0.7819],\n",
            "        ...,\n",
            "        [-0.4775, -0.8788, -0.9054,  ..., -0.8632,  0.3982,  0.2949],\n",
            "        [-0.4412, -0.6844, -0.9187,  ..., -0.8538,  0.2838,  0.3739],\n",
            "        [ 0.7403,  1.0000,  0.8739,  ...,  0.7717, -0.6558, -0.6885]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1546,  0.9986, -0.9364,  ..., -0.8344,  0.5628, -0.5514],\n",
            "        [-0.6489,  0.8256, -0.8683,  ..., -0.9180,  0.1542,  0.6586],\n",
            "        [-0.2092,  1.0000, -0.5846,  ..., -0.8129,  0.6947, -0.3419],\n",
            "        ...,\n",
            "        [-0.4419, -0.9780, -0.9450,  ..., -0.9474,  0.0465,  0.5626],\n",
            "        [ 0.6001,  0.9999,  0.8153,  ...,  0.8337, -0.7887, -0.5225],\n",
            "        [-0.6205,  0.9212, -0.8331,  ..., -0.7844,  0.4248,  0.6383]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7434,  1.0000,  0.8768,  ...,  0.8882, -0.7966, -0.4991],\n",
            "        [ 0.6484,  1.0000,  0.8311,  ...,  0.8869, -0.6873, -0.6160],\n",
            "        [-0.4466,  0.4938, -0.8982,  ..., -0.8890,  0.0147,  0.5778],\n",
            "        ...,\n",
            "        [ 0.6204,  1.0000,  0.9262,  ...,  0.8648, -0.6023, -0.5667],\n",
            "        [ 0.6889,  1.0000,  0.9300,  ...,  0.7885, -0.7676, -0.4705],\n",
            "        [ 0.7155,  1.0000,  0.8573,  ...,  0.8760, -0.7450, -0.5887]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.8298,  1.0000,  0.9245,  ...,  0.8499, -0.4909, -0.6603],\n",
            "        [-0.1683,  0.9989, -0.6880,  ..., -0.8497,  0.4594, -0.7433],\n",
            "        [ 0.6887,  0.9999,  0.8383,  ...,  0.8552, -0.6007, -0.3508],\n",
            "        ...,\n",
            "        [ 0.5400,  1.0000,  0.9433,  ...,  0.5698, -0.0157, -0.8840],\n",
            "        [ 0.6087,  1.0000,  0.9333,  ..., -0.1547, -0.1804, -0.9004],\n",
            "        [-0.6341, -0.7314, -0.9098,  ..., -0.8390,  0.2563,  0.4563]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5858, -0.7631, -0.9533,  ..., -0.8310, -0.2638,  0.7101],\n",
            "        [ 0.6374,  1.0000,  0.8433,  ...,  0.7667, -0.7053, -0.4874],\n",
            "        [ 0.6488,  1.0000,  0.9060,  ...,  0.7353, -0.6059, -0.7916],\n",
            "        ...,\n",
            "        [ 0.4245,  0.9994,  0.7969,  ...,  0.8205, -0.7942, -0.1919],\n",
            "        [ 0.5008,  1.0000,  0.9659,  ...,  0.4936,  0.2320, -0.9153],\n",
            "        [ 0.4327,  0.9996,  0.9303,  ...,  0.7889, -0.6629, -0.6092]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3817, -0.8344, -0.5521,  ..., -0.7371,  0.3680, -0.5489],\n",
            "        [-0.4226,  0.3995, -0.9495,  ..., -0.9488,  0.2319,  0.5708],\n",
            "        [-0.4142, -0.9945, -0.9651,  ..., -0.8966,  0.0154,  0.5502],\n",
            "        ...,\n",
            "        [-0.3953,  0.9867, -0.7889,  ..., -0.7944,  0.5804,  0.2696],\n",
            "        [-0.7259, -0.8741, -0.9170,  ..., -0.9367,  0.4609,  0.6988],\n",
            "        [-0.2579, -0.7282, -0.9317,  ..., -0.8718,  0.4044,  0.5806]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6775,  0.9994,  0.9276,  ...,  0.8312, -0.6045, -0.5426],\n",
            "        [-0.3573,  0.4397, -0.9194,  ..., -0.9156,  0.1666,  0.5730],\n",
            "        [-0.3258, -0.9581, -0.8558,  ..., -0.8815,  0.5557,  0.5262],\n",
            "        ...,\n",
            "        [ 0.1232,  0.9930,  0.3493,  ..., -0.4380,  0.5185, -0.8572],\n",
            "        [-0.6097,  0.4574, -0.8731,  ..., -0.8546,  0.2601,  0.3362],\n",
            "        [ 0.4646,  1.0000,  0.8841,  ...,  0.6021,  0.5207, -0.8742]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4096,  0.9709, -0.9248,  ..., -0.9215,  0.0590, -0.0653],\n",
            "        [ 0.6066,  1.0000,  0.9116,  ...,  0.8714, -0.6225, -0.7648],\n",
            "        [ 0.3665,  0.9998,  0.8872,  ...,  0.8210, -0.6910, -0.2807],\n",
            "        ...,\n",
            "        [-0.6757, -0.5671, -0.8986,  ..., -0.8687, -0.0493,  0.5478],\n",
            "        [-0.6087, -0.9522, -0.9031,  ..., -0.9183,  0.1395,  0.5420],\n",
            "        [-0.4387, -0.7460, -0.9347,  ..., -0.9097,  0.1858,  0.3345]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7364,  1.0000,  0.9635,  ...,  0.7888, -0.0713, -0.8752],\n",
            "        [ 0.4530,  0.9992,  0.9105,  ...,  0.8537, -0.7287, -0.3586],\n",
            "        [ 0.5222,  1.0000,  0.8750,  ...,  0.8324, -0.7444, -0.5986],\n",
            "        ...,\n",
            "        [-0.5517,  0.9928, -0.5213,  ..., -0.7647, -0.0488,  0.5170],\n",
            "        [ 0.5767,  1.0000,  0.9271,  ...,  0.7971, -0.7126, -0.6781],\n",
            "        [ 0.7730,  0.9997,  0.9048,  ...,  0.9135, -0.7568, -0.5278]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4657,  0.9343, -0.8895,  ..., -0.8151,  0.4971,  0.4219],\n",
            "        [ 0.6178,  0.9999,  0.8708,  ...,  0.8946, -0.7933, -0.3289],\n",
            "        [-0.7804,  0.3684, -0.8943,  ..., -0.9369,  0.4343,  0.4593],\n",
            "        ...,\n",
            "        [ 0.6059,  0.9998,  0.8600,  ...,  0.7639, -0.8155, -0.4490],\n",
            "        [ 0.7721,  0.9999,  0.8350,  ...,  0.8118, -0.8180, -0.7512],\n",
            "        [-0.5299, -0.9768, -0.9154,  ..., -0.8164,  0.0446,  0.6392]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5899,  1.0000,  0.8999,  ...,  0.8974, -0.6655, -0.5023],\n",
            "        [ 0.7202,  1.0000,  0.8434,  ...,  0.8060, -0.6248, -0.5336],\n",
            "        [-0.5756, -0.6012, -0.8806,  ..., -0.8806, -0.2556,  0.6337],\n",
            "        ...,\n",
            "        [-0.6128, -0.6103, -0.8016,  ..., -0.8366,  0.0786,  0.0731],\n",
            "        [ 0.6782,  1.0000,  0.9428,  ...,  0.8209, -0.5362, -0.7682],\n",
            "        [-0.7956, -0.8648, -0.9252,  ..., -0.8938,  0.0405,  0.5633]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.7656, -0.6246, -0.8928,  ..., -0.8966,  0.3020,  0.3479],\n",
            "        [-0.5306, -0.9861, -0.9380,  ..., -0.9201,  0.1148,  0.6312],\n",
            "        [-0.7316,  0.7614, -0.9545,  ..., -0.9215,  0.2460,  0.6829],\n",
            "        ...,\n",
            "        [ 0.7727,  1.0000,  0.9503,  ...,  0.8142, -0.4874, -0.8405],\n",
            "        [ 0.4800,  0.9999,  0.7108,  ...,  0.7637, -0.7062, -0.1295],\n",
            "        [ 0.7728,  1.0000,  0.9296,  ...,  0.8142, -0.4421, -0.7447]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.7244,  0.8650, -0.9332,  ..., -0.9078,  0.1888,  0.7165],\n",
            "        [-0.6440,  0.9904, -0.9196,  ..., -0.8329, -0.0705,  0.5859],\n",
            "        [ 0.7066,  1.0000,  0.9300,  ...,  0.1947,  0.5299, -0.9686],\n",
            "        ...,\n",
            "        [ 0.6776,  0.9999,  0.8440,  ...,  0.8418, -0.6992, -0.5990],\n",
            "        [-0.4572,  0.0332, -0.9395,  ..., -0.8625,  0.2080,  0.2615],\n",
            "        [ 0.7755,  1.0000,  0.8793,  ...,  0.8558, -0.5883, -0.6510]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6589,  1.0000,  0.8590,  ...,  0.8755, -0.7673, -0.6565],\n",
            "        [ 0.5419,  0.9997,  0.8691,  ...,  0.8074, -0.6753, -0.2180],\n",
            "        [ 0.4976,  1.0000,  0.9378,  ...,  0.8363, -0.5062, -0.6687],\n",
            "        ...,\n",
            "        [-0.4829,  0.7172, -0.6183,  ..., -0.8686,  0.3721,  0.3931],\n",
            "        [ 0.5940,  0.9999,  0.8833,  ...,  0.8327, -0.8082, -0.4819],\n",
            "        [-0.3923, -0.9107, -0.9325,  ..., -0.9081,  0.0721,  0.2928]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7468,  1.0000,  0.9549,  ...,  0.8754, -0.2184, -0.8798],\n",
            "        [ 0.3603,  1.0000,  0.7896,  ...,  0.1692, -0.3751, -0.7179],\n",
            "        [ 0.7064,  1.0000,  0.9567,  ...,  0.6967, -0.3141, -0.7872],\n",
            "        ...,\n",
            "        [ 0.6617,  1.0000,  0.8732,  ...,  0.9326, -0.5178, -0.7187],\n",
            "        [-0.6009, -0.5256, -0.9375,  ..., -0.8870,  0.1526,  0.6853],\n",
            "        [ 0.5442,  1.0000,  0.6771,  ...,  0.5103,  0.7279, -0.7615]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2140,  0.9040, -0.8159,  ..., -0.6966,  0.4620, -0.1741],\n",
            "        [-0.4736,  0.7840, -0.8878,  ..., -0.8943,  0.2247,  0.5977],\n",
            "        [-0.5634, -0.2031, -0.9119,  ..., -0.9189,  0.3131,  0.4831],\n",
            "        ...,\n",
            "        [ 0.8117,  0.9999,  0.9360,  ...,  0.9120, -0.8051, -0.4789],\n",
            "        [ 0.5807,  0.9999,  0.8834,  ...,  0.8262, -0.8661, -0.4508],\n",
            "        [ 0.7125,  0.9999,  0.8769,  ...,  0.8534, -0.7595, -0.5221]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4278, -0.9462, -0.9216,  ..., -0.8790, -0.2879,  0.4261],\n",
            "        [ 0.6932,  1.0000,  0.9076,  ...,  0.7625, -0.3992, -0.7452],\n",
            "        [-0.6438, -0.1357, -0.9311,  ..., -0.8668,  0.3403,  0.5461],\n",
            "        ...,\n",
            "        [-0.0988,  0.9999,  0.3950,  ..., -0.6697,  0.2432, -0.8762],\n",
            "        [-0.3944, -0.9578, -0.8122,  ..., -0.7098,  0.2496,  0.6784],\n",
            "        [ 0.7079,  0.9999,  0.8889,  ...,  0.9106, -0.6539, -0.4253]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5282,  0.9999,  0.8993,  ...,  0.6632, -0.3976, -0.8076],\n",
            "        [ 0.6358,  0.9999,  0.9244,  ...,  0.8900, -0.5909, -0.4630],\n",
            "        [ 0.5517,  1.0000,  0.8946,  ...,  0.7993, -0.4791, -0.7522],\n",
            "        ...,\n",
            "        [-0.4107,  0.2548, -0.8906,  ..., -0.9048,  0.4137,  0.3759],\n",
            "        [ 0.6641,  1.0000,  0.8747,  ...,  0.8951, -0.6764, -0.5611],\n",
            "        [ 0.6408,  0.9993,  0.8815,  ...,  0.8742, -0.6751, -0.5785]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5134, -0.5985, -0.9327,  ..., -0.8472,  0.0880,  0.5530],\n",
            "        [-0.2975, -0.9051, -0.9000,  ..., -0.9047,  0.0490,  0.4583],\n",
            "        [ 0.2200,  0.9993, -0.8194,  ..., -0.8226,  0.4678, -0.6449],\n",
            "        ...,\n",
            "        [-0.5841, -0.8791, -0.9551,  ..., -0.8625,  0.2134,  0.5305],\n",
            "        [ 0.6577,  0.9999,  0.8402,  ...,  0.8409, -0.6554, -0.4191],\n",
            "        [-0.3276, -0.9992, -0.9101,  ..., -0.8980,  0.2048,  0.4710]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5640,  1.0000,  0.0622,  ..., -0.8297,  0.5908, -0.8790],\n",
            "        [ 0.5118,  1.0000,  0.9319,  ...,  0.8342, -0.6117, -0.5273],\n",
            "        [-0.5286, -0.9825, -0.9625,  ..., -0.8857,  0.0382,  0.4460],\n",
            "        ...,\n",
            "        [ 0.7270,  1.0000,  0.9448,  ...,  0.8372, -0.2328, -0.8289],\n",
            "        [-0.8317,  0.5121, -0.9179,  ..., -0.7814, -0.0092,  0.6913],\n",
            "        [ 0.7067,  1.0000,  0.9145,  ...,  0.8307, -0.5350, -0.6404]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6404,  1.0000,  0.8508,  ...,  0.0827, -0.1092, -0.9527],\n",
            "        [-0.0766,  0.9998,  0.4223,  ..., -0.5476,  0.3946, -0.8379],\n",
            "        [-0.5743, -0.9841, -0.9144,  ..., -0.9086,  0.0569,  0.4086],\n",
            "        ...,\n",
            "        [ 0.5119,  0.9999,  0.9174,  ...,  0.9203, -0.7570, -0.4772],\n",
            "        [-0.3707, -0.3400, -0.9604,  ..., -0.8416, -0.1153,  0.2872],\n",
            "        [ 0.5931,  0.9999,  0.7505,  ...,  0.8159, -0.3142, -0.6517]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6428,  1.0000,  0.7250,  ...,  0.7059, -0.5845, -0.1836],\n",
            "        [ 0.6649,  0.9999,  0.8814,  ...,  0.8656, -0.8397, -0.4796],\n",
            "        [-0.4951, -0.9206, -0.9446,  ..., -0.9107,  0.0242,  0.7680],\n",
            "        ...,\n",
            "        [ 0.4227,  1.0000,  0.8418,  ...,  0.4435,  0.3924, -0.8169],\n",
            "        [ 0.7548,  0.9999,  0.8756,  ...,  0.9228, -0.7165, -0.6771],\n",
            "        [-0.6875,  0.3152, -0.9085,  ..., -0.8789,  0.3573,  0.5053]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4748,  0.9115, -0.9398,  ..., -0.8528,  0.1197,  0.5242],\n",
            "        [ 0.6815,  1.0000,  0.8931,  ...,  0.8309, -0.6909, -0.7497],\n",
            "        [ 0.4356,  1.0000,  0.8254,  ...,  0.1504,  0.5014, -0.9191],\n",
            "        ...,\n",
            "        [ 0.5245,  1.0000,  0.9149,  ...,  0.6981, -0.7638, -0.9070],\n",
            "        [ 0.7488,  1.0000,  0.8035,  ...,  0.8197, -0.7466, -0.8264],\n",
            "        [-0.5876,  0.9220, -0.9168,  ..., -0.9476,  0.0438,  0.5502]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5066, -0.9998, -0.9454,  ..., -0.8760,  0.1806,  0.6129],\n",
            "        [-0.4403, -0.9842, -0.9555,  ..., -0.9214,  0.5363,  0.5362],\n",
            "        [-0.5364, -0.4387, -0.9288,  ..., -0.9294, -0.1565,  0.4786],\n",
            "        ...,\n",
            "        [-0.7951,  0.9930, -0.7728,  ..., -0.9018,  0.2207,  0.1103],\n",
            "        [-0.5847, -0.5570, -0.7482,  ..., -0.9477,  0.2786,  0.3803],\n",
            "        [-0.6337, -0.9580, -0.9333,  ..., -0.8796,  0.5279,  0.6332]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4759, -0.9999, -0.9460,  ..., -0.8848,  0.1781,  0.5853],\n",
            "        [-0.6840, -0.8698, -0.9240,  ..., -0.8991,  0.2926,  0.0315],\n",
            "        [-0.6982, -0.9136, -0.9541,  ..., -0.9091,  0.0536,  0.6939],\n",
            "        ...,\n",
            "        [ 0.7159,  1.0000,  0.9232,  ...,  0.3280,  0.2562, -0.9800],\n",
            "        [-0.6355, -0.9755, -0.9537,  ..., -0.9330, -0.0338,  0.6467],\n",
            "        [ 0.5073,  1.0000,  0.9170,  ...,  0.4882,  0.5086, -0.9704]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6052, -0.9729, -0.9639,  ..., -0.8856, -0.0285,  0.4930],\n",
            "        [ 0.8128,  1.0000,  0.9303,  ...,  0.8702, -0.6331, -0.6707],\n",
            "        [-0.4431, -0.8675, -0.8852,  ..., -0.8226,  0.3495,  0.5163],\n",
            "        ...,\n",
            "        [-0.7716,  0.1954, -0.8887,  ..., -0.9219,  0.3715,  0.3075],\n",
            "        [ 0.3982,  0.9999,  0.8882,  ...,  0.8483, -0.7478, -0.6854],\n",
            "        [-0.5795, -0.7765, -0.8074,  ..., -0.8567,  0.1303,  0.5383]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4692,  0.8910, -0.7964,  ..., -0.9328,  0.2280,  0.5705],\n",
            "        [ 0.6278,  1.0000,  0.8379,  ...,  0.7023, -0.6590, -0.6834],\n",
            "        [ 0.7139,  1.0000,  0.8498,  ...,  0.9338, -0.7286, -0.5778],\n",
            "        ...,\n",
            "        [-0.6978,  0.3841, -0.9176,  ..., -0.9046,  0.4124,  0.6219],\n",
            "        [-0.7354, -0.9934, -0.9279,  ..., -0.9259, -0.2976,  0.7756],\n",
            "        [ 0.6054,  0.9995,  0.8875,  ...,  0.9250, -0.7420, -0.3509]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3363,  0.4532, -0.9127,  ..., -0.9090,  0.4479,  0.0776],\n",
            "        [-0.5372, -0.9999, -0.9265,  ..., -0.9290,  0.1122,  0.5890],\n",
            "        [ 0.7833,  1.0000,  0.3446,  ..., -0.6144,  0.7140, -0.9719],\n",
            "        ...,\n",
            "        [-0.3704,  1.0000, -0.1379,  ..., -0.6880,  0.0930, -0.5035],\n",
            "        [ 0.1447,  0.9999,  0.6246,  ...,  0.7120, -0.3501, -0.6071],\n",
            "        [ 0.6939,  0.9996,  0.8084,  ...,  0.8764, -0.7674, -0.3819]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7067,  0.9999,  0.8504,  ...,  0.8432, -0.7414, -0.3374],\n",
            "        [ 0.2184,  1.0000, -0.2677,  ..., -0.5599,  0.7302, -0.7527],\n",
            "        [-0.5275,  0.3443, -0.8984,  ..., -0.8876,  0.4253,  0.6074],\n",
            "        ...,\n",
            "        [-0.6897, -0.8454, -0.9266,  ..., -0.8893, -0.0715,  0.7083],\n",
            "        [-0.2830,  0.9990, -0.7879,  ..., -0.6497,  0.6519,  0.4569],\n",
            "        [ 0.7437,  1.0000,  0.8917,  ...,  0.9003, -0.7983, -0.5571]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6663,  0.9998,  0.8449,  ...,  0.7862, -0.8155, -0.2065],\n",
            "        [ 0.6738,  0.9999,  0.8785,  ...,  0.8559, -0.5924, -0.6741],\n",
            "        [ 0.7323,  1.0000,  0.9480,  ...,  0.7919, -0.4816, -0.8054],\n",
            "        ...,\n",
            "        [ 0.5926,  1.0000,  0.8990,  ...,  0.6988,  0.4058, -0.9582],\n",
            "        [ 0.6145,  0.9998,  0.9123,  ...,  0.8905, -0.7161, -0.5133],\n",
            "        [-0.7700,  0.9533, -0.8280,  ..., -0.7702,  0.4311,  0.6749]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4087,  0.9924, -0.9297,  ..., -0.9218,  0.2285,  0.4482],\n",
            "        [ 0.5619,  1.0000,  0.9486,  ...,  0.5500,  0.1168, -0.9452],\n",
            "        [ 0.6272,  1.0000,  0.8079,  ..., -0.0489, -0.4465, -0.8399],\n",
            "        ...,\n",
            "        [ 0.5581,  0.9996,  0.9196,  ...,  0.7842, -0.5560, -0.0406],\n",
            "        [ 0.7264,  1.0000,  0.9441,  ...,  0.8637, -0.4603, -0.7722],\n",
            "        [-0.3571, -0.7097, -0.8673,  ..., -0.8818, -0.0403,  0.6018]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5598,  1.0000,  0.8007,  ..., -0.2893,  0.3210, -0.9391],\n",
            "        [ 0.7368,  0.9996,  0.8751,  ...,  0.6447, -0.5667, -0.6576],\n",
            "        [-0.5382, -0.9810, -0.9468,  ..., -0.8939,  0.3088,  0.4889],\n",
            "        ...,\n",
            "        [-0.4093,  0.9607, -0.8995,  ..., -0.8801,  0.1769,  0.4377],\n",
            "        [ 0.4459,  0.9999,  0.9302,  ...,  0.8530, -0.7049, -0.5507],\n",
            "        [ 0.6093,  0.9999,  0.9311,  ...,  0.8475, -0.7177, -0.7267]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-3.1108e-04,  9.9179e-01, -8.5142e-01,  ..., -8.9393e-01,\n",
            "          5.9748e-01, -3.9398e-01],\n",
            "        [-6.2477e-01,  9.3147e-01, -8.8830e-01,  ..., -8.3551e-01,\n",
            "          2.8515e-01,  5.3397e-01],\n",
            "        [ 5.2904e-01,  9.9999e-01,  8.4352e-01,  ...,  5.1282e-01,\n",
            "         -1.3918e-02, -8.6646e-01],\n",
            "        ...,\n",
            "        [ 3.2102e-01,  9.9993e-01,  9.0678e-01,  ...,  7.1804e-01,\n",
            "         -6.6435e-01, -4.9929e-01],\n",
            "        [-6.8239e-01, -9.3395e-01, -9.2381e-01,  ..., -9.2741e-01,\n",
            "          1.1062e-01,  4.6808e-01],\n",
            "        [-2.7980e-01,  4.9388e-01, -8.6179e-01,  ..., -8.5409e-01,\n",
            "          2.6776e-01,  1.7965e-01]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3679, -0.9959, -0.9578,  ..., -0.8812,  0.0766,  0.3539],\n",
            "        [ 0.7396,  1.0000,  0.9199,  ...,  0.8801, -0.5704, -0.7069],\n",
            "        [-0.5811,  0.7200, -0.9600,  ..., -0.8821, -0.1079,  0.5431],\n",
            "        ...,\n",
            "        [ 0.5975,  0.9999,  0.9019,  ...,  0.8952, -0.7444, -0.5855],\n",
            "        [-0.3973, -0.8753, -0.9051,  ..., -0.8787,  0.2593,  0.4587],\n",
            "        [ 0.7585,  1.0000,  0.9011,  ...,  0.9417, -0.6387, -0.6585]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7125,  1.0000,  0.8506,  ...,  0.8803, -0.6247, -0.5720],\n",
            "        [ 0.4950,  0.9999,  0.9359,  ...,  0.9223, -0.6245, -0.5169],\n",
            "        [-0.6855, -0.8589, -0.9558,  ..., -0.9263,  0.1867,  0.7662],\n",
            "        ...,\n",
            "        [-0.7444, -0.9269, -0.7800,  ..., -0.8767, -0.1235,  0.4626],\n",
            "        [-0.6540,  0.2891, -0.9069,  ..., -0.7920,  0.1023,  0.6132],\n",
            "        [-0.2377, -0.8653, -0.9315,  ..., -0.8847,  0.4085,  0.4280]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5824, -0.9721, -0.9283,  ..., -0.8400,  0.5193,  0.6767],\n",
            "        [ 0.8136,  0.9995,  0.8388,  ...,  0.7898, -0.5224, -0.4758],\n",
            "        [ 0.6462,  0.9998,  0.8602,  ...,  0.9069, -0.7502, -0.2767],\n",
            "        ...,\n",
            "        [ 0.4689,  0.9999,  0.8377,  ...,  0.9184, -0.6931, -0.5695],\n",
            "        [ 0.4602,  0.9988,  0.9011,  ...,  0.8435, -0.8206, -0.5376],\n",
            "        [-0.6153,  0.4313, -0.9224,  ..., -0.8679,  0.0873,  0.4452]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7703,  0.9999,  0.8835,  ...,  0.8356, -0.7820, -0.3999],\n",
            "        [ 0.6118,  1.0000,  0.8446,  ...,  0.7140, -0.4605, -0.7148],\n",
            "        [ 0.5520,  1.0000,  0.9684,  ...,  0.6467,  0.0504, -0.9547],\n",
            "        ...,\n",
            "        [ 0.6198,  1.0000,  0.8655,  ...,  0.8335, -0.7763, -0.5250],\n",
            "        [ 0.2228,  0.9257, -0.9207,  ..., -0.7654,  0.4748, -0.1836],\n",
            "        [ 0.7296,  0.9999,  0.9240,  ...,  0.9138, -0.7552, -0.3688]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4677,  0.9660, -0.9113,  ..., -0.8951,  0.4828,  0.6773],\n",
            "        [ 0.5946,  0.9999,  0.8823,  ...,  0.9093, -0.6857, -0.4531],\n",
            "        [ 0.4735,  1.0000,  0.9501,  ...,  0.3985,  0.0559, -0.9431],\n",
            "        ...,\n",
            "        [-0.4933,  0.9236, -0.8896,  ..., -0.8988,  0.1313,  0.4797],\n",
            "        [-0.4333, -0.9718, -0.9631,  ..., -0.8708,  0.0847,  0.6494],\n",
            "        [-0.4978, -0.7793, -0.9321,  ..., -0.9247, -0.0986,  0.6306]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6190,  0.7082, -0.5694,  ..., -0.7170,  0.5019,  0.3172],\n",
            "        [-0.3236, -0.9945, -0.9505,  ..., -0.9009,  0.0105,  0.5616],\n",
            "        [ 0.6619,  0.9994,  0.7678,  ...,  0.8220, -0.6927, -0.6620],\n",
            "        ...,\n",
            "        [-0.4516, -0.8299, -0.9041,  ..., -0.8375,  0.2099,  0.6745],\n",
            "        [-0.5192,  0.9424, -0.9377,  ..., -0.8469,  0.2362,  0.6760],\n",
            "        [ 0.7777,  1.0000,  0.8871,  ...,  0.7996, -0.6222, -0.7771]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.7456,  0.6191, -0.8534,  ..., -0.7976,  0.2587,  0.5700],\n",
            "        [-0.6556, -0.9577, -0.8679,  ..., -0.9149, -0.0073,  0.5014],\n",
            "        [ 0.5973,  1.0000,  0.8445,  ...,  0.8255, -0.6718, -0.2917],\n",
            "        ...,\n",
            "        [-0.3338,  0.8258, -0.8404,  ..., -0.8748,  0.2103,  0.6548],\n",
            "        [ 0.7531,  1.0000,  0.9218,  ...,  0.8839, -0.7984, -0.5619],\n",
            "        [-0.2762,  0.9722, -0.8091,  ..., -0.7946,  0.4398, -0.2021]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5668, -0.9527, -0.8962,  ..., -0.8630,  0.3420,  0.6612],\n",
            "        [ 0.0101,  0.9992, -0.5452,  ..., -0.8844,  0.7817, -0.2989],\n",
            "        [ 0.3406,  0.9881, -0.7127,  ..., -0.8499,  0.4028, -0.4312],\n",
            "        ...,\n",
            "        [ 0.5755,  1.0000,  0.7652,  ...,  0.9210, -0.6695, -0.5450],\n",
            "        [ 0.1765,  0.8619, -0.9418,  ..., -0.6686,  0.7069,  0.2806],\n",
            "        [-0.5029, -0.8743, -0.9215,  ..., -0.8603,  0.2020,  0.5817]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6326, -0.4420, -0.5746,  ..., -0.8614,  0.2337,  0.1047],\n",
            "        [ 0.6938,  0.9991,  0.8789,  ...,  0.8703, -0.7513, -0.4539],\n",
            "        [ 0.5945,  1.0000,  0.9714,  ...,  0.8059, -0.1966, -0.8194],\n",
            "        ...,\n",
            "        [-0.4944,  0.6645, -0.9429,  ..., -0.9361,  0.2714,  0.4960],\n",
            "        [ 0.4981,  0.9995,  0.8804,  ...,  0.8952, -0.5366, -0.1580],\n",
            "        [-0.0640, -0.7538, -0.9290,  ..., -0.8400,  0.1693,  0.3338]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3998,  1.0000,  0.7676,  ..., -0.6862,  0.8327, -0.9168],\n",
            "        [ 0.7091,  1.0000,  0.7773,  ...,  0.8448, -0.5482, -0.5796],\n",
            "        [ 0.7648,  1.0000,  0.8229,  ...,  0.8577, -0.5437, -0.8098],\n",
            "        ...,\n",
            "        [ 0.6550,  1.0000,  0.9214,  ...,  0.8457, -0.5670, -0.6448],\n",
            "        [-0.4833,  0.9434, -0.9092,  ..., -0.8548,  0.0534,  0.6075],\n",
            "        [-0.4398,  0.9690, -0.9438,  ..., -0.8772,  0.0269,  0.4751]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7850,  1.0000,  0.8630,  ...,  0.7957, -0.6187, -0.5497],\n",
            "        [ 0.6409,  1.0000,  0.9691,  ...,  0.8652, -0.2456, -0.5948],\n",
            "        [ 0.6636,  1.0000,  0.9476,  ...,  0.8522,  0.0814, -0.9512],\n",
            "        ...,\n",
            "        [ 0.6801,  0.9998,  0.9246,  ...,  0.7579, -0.7218, -0.5225],\n",
            "        [ 0.6961,  0.9998,  0.6853,  ...,  0.8628, -0.7062, -0.3364],\n",
            "        [ 0.5267,  1.0000,  0.7314,  ...,  0.6838, -0.3605, -0.5796]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5786, -0.2989, -0.9434,  ..., -0.9264,  0.4354,  0.4155],\n",
            "        [ 0.5420,  0.9999,  0.8526,  ...,  0.9055, -0.6225, -0.2839],\n",
            "        [ 0.7037,  0.9999,  0.9613,  ...,  0.8753, -0.4537, -0.5812],\n",
            "        ...,\n",
            "        [ 0.5503,  0.9999,  0.7953,  ...,  0.7311, -0.7601,  0.1855],\n",
            "        [ 0.7513,  1.0000,  0.9360,  ...,  0.8658,  0.2286, -0.9354],\n",
            "        [ 0.4988,  0.9999,  0.9054,  ...,  0.9201, -0.5376, -0.5758]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7280,  1.0000,  0.9560,  ...,  0.5428,  0.5041, -0.9814],\n",
            "        [ 0.6566,  0.9997,  0.9172,  ...,  0.9092, -0.7443, -0.4785],\n",
            "        [-0.5033, -0.6793, -0.9324,  ..., -0.9462,  0.2124,  0.4479],\n",
            "        ...,\n",
            "        [-0.4667,  0.9592, -0.8847,  ..., -0.9246,  0.1884,  0.5933],\n",
            "        [-0.5190, -0.9979, -0.9505,  ..., -0.8777,  0.2265,  0.4942],\n",
            "        [-0.7191, -0.9908, -0.9346,  ..., -0.8769, -0.1632,  0.6222]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5532, -0.9952, -0.9670,  ..., -0.8888, -0.0125,  0.7172],\n",
            "        [ 0.6086,  1.0000,  0.8632,  ...,  0.6316, -0.4540, -0.7448],\n",
            "        [ 0.4159,  0.9976,  0.8206,  ...,  0.8521, -0.8510, -0.0733],\n",
            "        ...,\n",
            "        [-0.3619, -1.0000, -0.9275,  ..., -0.8728,  0.1065,  0.7461],\n",
            "        [-0.6855,  0.9945, -0.8138,  ..., -0.8097,  0.3976,  0.6761],\n",
            "        [-0.4020, -0.5303, -0.9455,  ..., -0.9286,  0.2328,  0.6495]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6880,  0.9998,  0.8922,  ...,  0.9032, -0.8306, -0.5218],\n",
            "        [ 0.8595,  1.0000,  0.5528,  ..., -0.3929,  0.5688, -0.9523],\n",
            "        [-0.2898,  0.8335, -0.9388,  ..., -0.9006,  0.1726,  0.2360],\n",
            "        ...,\n",
            "        [ 0.6971,  0.9999,  0.8354,  ...,  0.8480, -0.5094, -0.7092],\n",
            "        [-0.5220,  0.8960, -0.6551,  ..., -0.8208,  0.2441, -0.1908],\n",
            "        [-0.3949,  0.9996, -0.8486,  ..., -0.8717,  0.4097, -0.1330]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4205, -0.9701, -0.9358,  ..., -0.7685,  0.1372,  0.6968],\n",
            "        [ 0.5089,  0.9999,  0.9125,  ...,  0.8411, -0.5324, -0.5674],\n",
            "        [ 0.5537,  0.9999,  0.9136,  ...,  0.8831, -0.6120, -0.6411],\n",
            "        ...,\n",
            "        [ 0.8032,  1.0000,  0.9421,  ...,  0.6249, -0.4396, -0.9390],\n",
            "        [-0.5877, -0.4894, -0.8523,  ..., -0.8782,  0.2568,  0.0651],\n",
            "        [-0.4269, -0.2706, -0.9348,  ..., -0.9098, -0.2833,  0.8110]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5072, -0.9989, -0.8063,  ..., -0.8635, -0.0303,  0.3791],\n",
            "        [ 0.5863,  0.9981,  0.8021,  ...,  0.7508, -0.8195, -0.2692],\n",
            "        [ 0.5377,  0.9998,  0.8174,  ...,  0.9107, -0.7239, -0.2145],\n",
            "        ...,\n",
            "        [ 0.5447,  0.9988,  0.8407,  ...,  0.7252, -0.7843, -0.3181],\n",
            "        [ 0.6773,  0.9993,  0.7763,  ...,  0.9077, -0.7751, -0.2557],\n",
            "        [ 0.3253,  1.0000,  0.8824,  ...,  0.3599, -0.5840, -0.7434]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2458,  0.9348, -0.8592,  ..., -0.7479,  0.6228,  0.4416],\n",
            "        [-0.4113,  0.4224, -0.8944,  ..., -0.8005,  0.5801,  0.1051],\n",
            "        [ 0.5942,  0.9999,  0.9018,  ...,  0.8311, -0.7856, -0.5116],\n",
            "        ...,\n",
            "        [-0.0176,  0.9971, -0.6130,  ..., -0.8932,  0.3957,  0.2049],\n",
            "        [-0.2534,  0.4372, -0.9380,  ..., -0.8698,  0.5938,  0.2754],\n",
            "        [-0.2713,  0.5044, -0.8669,  ..., -0.8664,  0.3368,  0.2828]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3693,  0.9709, -0.9213,  ..., -0.9153,  0.4661,  0.2785],\n",
            "        [ 0.7715,  1.0000,  0.5831,  ..., -0.0015, -0.1651, -0.9101],\n",
            "        [ 0.7523,  1.0000,  0.4640,  ..., -0.3143, -0.4025, -0.5008],\n",
            "        ...,\n",
            "        [-0.7774,  0.9994, -0.7594,  ..., -0.6756,  0.1613,  0.6507],\n",
            "        [-0.0696,  0.9893, -0.8720,  ..., -0.8775,  0.1426,  0.0303],\n",
            "        [ 0.6309,  0.9998,  0.8524,  ...,  0.8967, -0.8238, -0.5974]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1525,  1.0000,  0.9121,  ...,  0.2636,  0.3137, -0.9147],\n",
            "        [-0.3991,  0.9999, -0.7212,  ..., -0.7525,  0.7185,  0.0195],\n",
            "        [-0.3630, -0.9908, -0.8770,  ..., -0.6561,  0.0226,  0.2779],\n",
            "        ...,\n",
            "        [-0.7296,  0.7627, -0.9393,  ..., -0.8169, -0.0648,  0.5985],\n",
            "        [ 0.7223,  0.9990,  0.8019,  ...,  0.9194, -0.8567, -0.5020],\n",
            "        [ 0.4873,  0.9953,  0.8200,  ...,  0.8033, -0.7083, -0.2522]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.7427, -0.9968, -0.9477,  ..., -0.9386,  0.0164,  0.6935],\n",
            "        [-0.6186,  0.9861, -0.7336,  ..., -0.9161,  0.3891,  0.0956],\n",
            "        [-0.5167, -0.8973, -0.9277,  ..., -0.9200,  0.3520,  0.6337],\n",
            "        ...,\n",
            "        [-0.7258, -0.5889, -0.9096,  ..., -0.8978,  0.2089,  0.4175],\n",
            "        [ 0.4464,  1.0000,  0.6887,  ..., -0.4049,  0.0184, -0.8558],\n",
            "        [-0.8152, -0.0511, -0.9056,  ..., -0.8857,  0.2006,  0.6546]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5096,  0.9999,  0.8678,  ...,  0.8829, -0.7183, -0.3154],\n",
            "        [ 0.7466,  1.0000,  0.8535,  ...,  0.8517, -0.8578, -0.6393],\n",
            "        [-0.2361,  0.9999, -0.7816,  ..., -0.9222,  0.6557, -0.2187],\n",
            "        ...,\n",
            "        [-0.6989, -0.9265, -0.9487,  ..., -0.9269,  0.1736,  0.3040],\n",
            "        [ 0.6535,  1.0000,  0.6992,  ...,  0.7773, -0.5323, -0.8127],\n",
            "        [ 0.6731,  0.9991,  0.7110,  ...,  0.8976, -0.8235, -0.2184]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5142,  0.6659, -0.9053,  ..., -0.8613,  0.0693,  0.0506],\n",
            "        [-0.4683,  0.6204, -0.9129,  ..., -0.8717,  0.2302,  0.2341],\n",
            "        [-0.5876, -0.9920, -0.9313,  ..., -0.9347,  0.0982,  0.5589],\n",
            "        ...,\n",
            "        [ 0.4235,  0.9998,  0.8855,  ...,  0.8527, -0.8076, -0.5352],\n",
            "        [-0.4072,  0.6607, -0.8579,  ..., -0.8936,  0.2427,  0.3979],\n",
            "        [-0.5067,  0.5422, -0.9349,  ..., -0.8616,  0.2405,  0.2517]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-5.9277e-01, -7.9537e-01, -9.3536e-01,  1.4922e-01,  2.9872e-01,\n",
            "         -8.9335e-01, -3.9670e-01, -7.3165e-01,  9.2385e-01,  6.7753e-01,\n",
            "         -8.0773e-01,  9.1434e-01, -5.2594e-01, -8.9654e-01, -3.2044e-02,\n",
            "          9.1100e-01, -6.5164e-01,  5.3898e-01,  2.6754e-01,  3.3743e-01,\n",
            "          2.2587e-01,  8.8572e-01,  3.0057e-01, -1.2332e-01, -7.4410e-01,\n",
            "         -8.1538e-01,  3.7223e-01,  2.5439e-01, -2.8182e-01, -5.8027e-01,\n",
            "          6.9930e-03,  6.9169e-01,  6.5329e-01,  4.5982e-01,  2.8240e-01,\n",
            "          4.5175e-01,  6.1503e-01,  7.4504e-01,  1.8390e-01,  4.9233e-01,\n",
            "          3.3090e-01,  4.9317e-01, -8.0083e-01, -7.2159e-01, -9.1473e-01,\n",
            "         -4.5294e-01,  1.0944e-01, -4.0467e-01,  4.2162e-01,  1.5208e-01,\n",
            "          4.4113e-01, -9.9478e-01,  3.2663e-01, -9.7086e-01, -2.3269e-01,\n",
            "         -9.0619e-01, -2.7142e-01,  4.9731e-01,  5.6600e-02,  7.5730e-01,\n",
            "         -1.7394e-01, -4.2385e-01,  9.1787e-01,  5.8938e-01,  9.3080e-01,\n",
            "          1.5221e-01,  4.2926e-01, -4.1105e-01,  8.5030e-01, -6.4695e-01,\n",
            "         -9.1043e-01,  4.1387e-01, -3.6019e-01, -5.3319e-01,  5.9509e-01,\n",
            "         -3.1225e-01,  6.2508e-01,  1.6608e-01, -2.7485e-01, -8.0179e-01,\n",
            "         -8.6707e-01,  3.6403e-01,  7.9662e-01,  6.1686e-01, -6.3917e-01,\n",
            "         -4.7370e-01, -3.1581e-01,  4.7428e-01,  7.0863e-01, -4.1056e-02,\n",
            "          7.3498e-02, -8.7276e-01, -7.9442e-01,  4.8853e-01,  2.3056e-01,\n",
            "         -5.7683e-01,  2.2531e-01, -7.9622e-01,  8.4129e-01,  4.0188e-01,\n",
            "          6.6629e-01,  5.1830e-01,  6.4435e-01,  2.4741e-01,  6.0438e-01,\n",
            "         -9.0014e-01,  4.2651e-01, -5.5987e-01,  9.1015e-01,  9.3883e-02,\n",
            "         -6.4900e-01,  1.9794e-01,  4.6836e-01, -7.3740e-01, -5.6883e-01,\n",
            "         -3.6887e-01, -8.6883e-01, -9.0159e-01,  9.1030e-01,  4.2484e-01,\n",
            "          3.0864e-01, -6.4085e-01,  4.7848e-01, -5.1000e-01, -4.2766e-01,\n",
            "         -4.6209e-01, -6.4122e-01,  9.5997e-01,  1.4787e-01,  4.3204e-01,\n",
            "         -1.6563e-01, -8.8306e-01, -7.6829e-01, -7.0191e-01,  5.2914e-01,\n",
            "         -4.3812e-01, -7.4665e-01,  3.8055e-01,  4.7205e-01,  7.3084e-01,\n",
            "          2.0108e-01,  2.2940e-01, -7.6642e-01, -1.8925e-01, -1.4438e-02,\n",
            "          3.4071e-01,  1.1713e-01,  5.4402e-01,  4.9676e-02, -7.4594e-01,\n",
            "          6.0771e-01, -5.1809e-01, -6.4122e-01,  2.9876e-01,  4.6370e-01,\n",
            "          5.8116e-01,  5.1979e-01,  5.4297e-01,  9.9087e-01, -8.6113e-01,\n",
            "          7.7782e-01,  9.7706e-01,  5.0706e-01,  5.2467e-01,  9.9699e-01,\n",
            "         -6.1866e-01,  1.1397e-01,  6.3718e-01,  8.2190e-01, -3.6785e-01,\n",
            "          2.7181e-01,  6.5364e-01,  5.3551e-01,  6.8570e-01,  9.9867e-01,\n",
            "         -3.8761e-01, -8.2885e-01,  1.7581e-01,  9.3361e-01,  8.8096e-01,\n",
            "         -7.0854e-01, -3.0596e-01, -9.6585e-01, -6.9795e-01,  8.5927e-01,\n",
            "         -6.4396e-01, -5.4226e-01,  9.4251e-01, -9.6267e-01,  5.8989e-01,\n",
            "         -5.1154e-01, -8.2993e-01, -4.0829e-01,  8.7382e-01,  1.6395e-01,\n",
            "         -2.4152e-01, -1.7667e-01,  5.1332e-01,  5.1844e-01,  1.2388e-01,\n",
            "          7.8745e-01,  8.5427e-01,  7.7196e-01, -9.5741e-01, -8.7146e-01,\n",
            "         -7.1222e-01,  1.1145e-02, -4.6159e-01,  4.0925e-01,  5.4067e-01,\n",
            "          5.4375e-01,  5.7580e-01,  3.2734e-01, -7.1016e-01,  2.9918e-02,\n",
            "          4.1017e-01,  8.1748e-01, -9.6331e-01,  5.5494e-01,  7.3084e-01,\n",
            "         -7.6116e-01, -8.2277e-01,  1.7597e-01, -7.5253e-01,  5.0141e-03,\n",
            "         -8.0844e-01, -1.5185e-01,  1.4573e-01, -6.6581e-01,  8.5942e-01,\n",
            "          1.1416e-01,  6.1592e-01,  3.6984e-01,  7.0143e-01,  9.0023e-01,\n",
            "          5.1977e-01, -7.6027e-01,  1.1165e-01,  9.6568e-01, -4.7426e-01,\n",
            "          7.9604e-01, -6.6098e-01,  8.5209e-01,  2.7197e-01, -9.8272e-01,\n",
            "          8.2487e-01, -9.5781e-01, -8.2107e-01,  3.6300e-02,  7.5190e-01,\n",
            "         -3.0714e-01, -2.9170e-01,  5.2988e-01,  6.5170e-01,  7.1451e-01,\n",
            "          5.3825e-01,  6.9766e-01, -5.8330e-01, -3.2573e-01,  2.1013e-01,\n",
            "         -1.3651e-01,  6.9316e-02, -9.5305e-01, -9.0019e-01, -6.7989e-01,\n",
            "         -3.5623e-01, -7.5364e-01,  7.3641e-03,  4.5389e-01,  2.0264e-01,\n",
            "          3.1246e-01,  9.4973e-01, -8.3283e-01, -2.3401e-01,  5.6772e-01,\n",
            "         -6.3172e-01, -5.6042e-01,  1.7806e-01, -9.0186e-01,  6.7148e-01,\n",
            "         -9.5890e-01,  9.9172e-01,  7.3730e-01,  4.3865e-01,  9.9510e-02,\n",
            "          1.4690e-01,  1.9528e-01,  9.8955e-01, -5.2045e-01,  6.0655e-01,\n",
            "          2.1411e-01,  7.2228e-01,  9.0288e-01,  2.1607e-01, -8.9280e-01,\n",
            "         -8.5190e-01,  7.3889e-01, -9.3580e-01,  2.0407e-01, -4.3150e-01,\n",
            "          2.7933e-01,  7.9129e-01,  7.7494e-01,  5.9750e-01,  2.2969e-01,\n",
            "          7.0120e-01, -9.8851e-01,  6.4451e-01, -6.6933e-01, -2.6404e-02,\n",
            "          4.1132e-01, -7.5602e-01, -7.9704e-01,  3.5321e-01, -3.2786e-01,\n",
            "         -7.5083e-01, -9.7360e-02,  9.2721e-01,  2.6731e-01,  1.5856e-01,\n",
            "          1.2186e-01,  1.8460e-01, -1.4189e-01, -5.7697e-01, -9.7584e-01,\n",
            "          1.3570e-01,  9.8107e-01, -7.8172e-01, -9.4322e-01,  5.3091e-01,\n",
            "         -2.1350e-01,  8.0005e-01, -3.6638e-01, -7.5426e-01,  5.3248e-01,\n",
            "         -2.2721e-01, -1.1782e-01,  9.7367e-01, -8.4652e-01,  6.0152e-01,\n",
            "          7.5416e-01,  3.5524e-01,  8.2404e-01,  6.7026e-01,  1.1475e-01,\n",
            "         -8.8012e-01,  6.7642e-01, -4.7674e-01,  8.4063e-01, -4.9427e-01,\n",
            "         -5.1475e-01, -4.1503e-02, -8.5041e-01, -9.4896e-01,  7.3546e-01,\n",
            "         -4.7045e-01,  6.4533e-01,  9.5875e-01, -7.4115e-01,  5.9387e-01,\n",
            "         -7.4749e-01,  1.3953e-01,  7.2185e-01, -4.9365e-01,  9.7907e-01,\n",
            "         -6.3460e-01,  3.0898e-01,  1.1543e-01, -9.8400e-01,  8.6612e-01,\n",
            "         -5.7212e-01,  7.4758e-01, -4.9652e-01,  9.1293e-01, -6.8879e-01,\n",
            "         -8.6064e-01, -8.8064e-01,  3.5137e-01,  8.1004e-01,  3.8241e-01,\n",
            "         -3.8515e-01,  3.0320e-01,  4.6455e-01,  3.7384e-01, -9.3043e-01,\n",
            "          3.0689e-01,  6.2511e-01, -8.5460e-01,  7.9153e-01,  2.8048e-01,\n",
            "          3.1963e-01,  3.1022e-01,  6.8242e-02, -9.2348e-01,  4.2715e-01,\n",
            "          8.8760e-01, -3.0714e-01, -3.6468e-01, -3.3840e-01, -5.6148e-01,\n",
            "         -3.4550e-01,  2.1532e-01, -9.1895e-01,  5.5081e-01,  5.7050e-01,\n",
            "         -7.0113e-01, -1.1609e-01, -8.9391e-02,  4.7373e-01, -8.8073e-01,\n",
            "          5.4556e-01,  7.2842e-01,  7.5718e-01,  2.9562e-01, -9.2359e-01,\n",
            "          2.6680e-01, -8.6445e-01, -2.9169e-01, -6.0884e-01, -2.7069e-01,\n",
            "          1.7908e-01, -2.0643e-01, -8.1670e-01, -9.4814e-01,  8.5880e-01,\n",
            "         -4.5014e-01,  8.6762e-01, -7.5702e-01, -6.2031e-01, -6.3195e-01,\n",
            "         -2.0178e-01,  3.1513e-01,  7.2149e-01, -2.6134e-01,  3.6077e-01,\n",
            "         -5.0786e-01,  1.8150e-01,  7.5195e-01,  6.9802e-01,  4.6253e-01,\n",
            "          4.8246e-01,  8.5930e-01,  7.6142e-01, -2.8771e-01,  5.0880e-01,\n",
            "          6.7831e-02, -7.6662e-01, -8.7928e-01,  3.0830e-01,  6.7285e-01,\n",
            "         -6.4655e-02,  8.5232e-01, -6.8362e-01,  7.9548e-02,  6.7982e-01,\n",
            "          3.3653e-01, -3.4263e-01, -1.5848e-01,  9.4763e-01,  2.0086e-01,\n",
            "         -3.8566e-01,  8.5200e-01, -6.3731e-01,  9.4259e-01,  2.4749e-01,\n",
            "         -1.3333e-01,  7.7772e-01,  7.6011e-01, -7.9375e-01, -8.1248e-04,\n",
            "          6.8254e-01,  4.2484e-01,  5.9125e-01, -9.8836e-01, -7.7680e-01,\n",
            "         -1.3036e-01,  1.2081e-02, -8.5756e-01, -4.4330e-01, -9.9873e-01,\n",
            "          8.3701e-01,  6.9984e-01, -8.7396e-01,  6.7179e-01,  7.0044e-02,\n",
            "         -9.7795e-02,  4.3114e-01,  5.5686e-01,  8.8540e-01, -9.1649e-01,\n",
            "         -3.2087e-01, -3.9356e-01,  5.8791e-02,  7.9965e-01,  7.1352e-01,\n",
            "          5.8753e-02, -8.6600e-01, -2.6282e-01,  7.8008e-01,  1.9098e-01,\n",
            "         -5.3723e-01, -7.9151e-01, -2.1669e-01,  5.5725e-01, -7.0302e-01,\n",
            "         -9.3920e-01, -6.3393e-01,  9.9734e-01,  1.8634e-01, -4.7814e-01,\n",
            "          6.4673e-01,  3.3575e-01, -1.0978e-01,  7.7377e-01, -1.9286e-01,\n",
            "          3.7837e-01,  8.0986e-01, -8.6114e-01, -4.7612e-01, -5.0897e-01,\n",
            "          6.0180e-01, -3.6425e-01,  3.1519e-01, -4.5520e-01, -7.8174e-01,\n",
            "         -9.3779e-01, -3.1480e-01,  1.7460e-01, -3.6842e-01,  1.1051e-01,\n",
            "          4.2356e-01,  4.9349e-01,  7.5998e-01, -6.3182e-01, -6.6289e-01,\n",
            "         -9.8846e-01, -4.3495e-01, -4.7484e-01, -4.8250e-01, -6.2055e-01,\n",
            "         -8.6039e-01,  5.1553e-01, -7.1093e-01,  8.7357e-02,  7.5508e-01,\n",
            "          7.0599e-01, -3.5336e-01, -4.2482e-01, -6.3779e-01,  6.2366e-01,\n",
            "          2.4265e-01, -3.1092e-02, -6.5728e-01,  6.9172e-01, -7.3738e-01,\n",
            "         -6.4140e-01, -8.2106e-01, -4.8231e-01, -6.7361e-02,  3.3329e-01,\n",
            "          2.8962e-01,  3.3285e-01,  2.2682e-01, -9.5013e-01,  4.0602e-01,\n",
            "         -4.3081e-01, -2.1321e-01, -5.2348e-01, -7.8794e-01, -9.1644e-01,\n",
            "          8.3325e-01,  9.7121e-01, -5.0795e-01, -8.8904e-01, -1.3546e-01,\n",
            "          5.7096e-01,  4.3437e-01, -6.0019e-01,  7.8923e-01,  9.0674e-01,\n",
            "          7.5468e-01,  6.2877e-01,  5.3349e-01, -4.6999e-01, -8.1153e-01,\n",
            "         -5.6299e-01, -5.1257e-01,  2.6949e-01, -6.2495e-01,  5.6320e-01,\n",
            "          5.3655e-02,  1.7388e-01,  5.1297e-01, -4.7309e-01,  9.4450e-01,\n",
            "          2.9727e-01, -4.3056e-01,  7.5366e-01, -6.2599e-01, -8.1943e-01,\n",
            "          4.2104e-01, -7.6556e-01,  8.8627e-01, -2.5850e-01, -8.7259e-01,\n",
            "          1.4601e-01, -2.0463e-01,  9.3196e-02,  2.5086e-01, -1.7789e-01,\n",
            "          6.5993e-01,  4.4397e-01,  1.7532e-01, -4.2490e-02,  3.9943e-01,\n",
            "          5.3930e-01,  4.6482e-01,  8.8085e-01,  2.3848e-01,  7.5799e-01,\n",
            "         -4.7246e-01,  6.3908e-01,  1.2626e-01,  5.1564e-01,  1.4914e-01,\n",
            "         -6.4412e-01,  3.2700e-02, -9.8733e-01,  5.8044e-01, -2.5262e-01,\n",
            "          4.7738e-01,  8.3384e-01, -5.1839e-01, -4.3836e-01, -5.6128e-01,\n",
            "         -8.2864e-01, -4.6066e-01, -6.7741e-01,  9.7524e-01, -2.5663e-01,\n",
            "         -9.2193e-01,  7.9375e-01,  6.8238e-01,  2.2885e-01,  5.7770e-01,\n",
            "         -8.2318e-01, -2.3566e-01, -4.4343e-01,  9.5819e-01,  5.5629e-01,\n",
            "         -1.9189e-01, -7.8566e-01, -5.5787e-02, -9.1408e-01, -5.8183e-01,\n",
            "          3.0692e-01, -2.4599e-01,  6.2857e-01, -7.1481e-01, -8.7544e-01,\n",
            "          9.2412e-02, -6.9231e-01,  3.6685e-01, -5.1266e-01,  4.3387e-01,\n",
            "          9.3595e-01, -7.2918e-01, -7.7823e-01,  8.8024e-01,  7.4912e-01,\n",
            "         -9.4321e-01,  9.4233e-01, -6.0663e-01, -3.4486e-01,  7.6431e-01,\n",
            "          3.8695e-01, -3.7981e-01,  3.6845e-01, -5.9111e-02,  2.3822e-01,\n",
            "         -1.1435e-02, -5.1915e-01,  9.4722e-01,  2.8984e-01, -2.9206e-01,\n",
            "          6.7717e-01, -2.0436e-01,  4.8024e-01,  3.0258e-01, -6.6775e-01,\n",
            "          5.1135e-01, -9.1304e-01, -5.6271e-01, -3.5859e-01, -4.5053e-01,\n",
            "          7.8481e-01,  9.8768e-01, -6.7019e-01,  3.7454e-01,  4.2312e-01,\n",
            "         -1.7825e-01,  7.7963e-01, -4.1179e-01,  3.8247e-01,  6.6324e-01,\n",
            "          6.9115e-02,  2.5175e-01, -3.6062e-01, -6.6243e-01,  2.6944e-01,\n",
            "          8.7282e-01, -9.6731e-01, -8.3284e-01,  5.1471e-01,  3.6014e-01,\n",
            "         -4.2347e-01, -5.9346e-01,  2.8207e-01,  3.9586e-01, -5.4620e-01,\n",
            "         -4.2240e-01,  5.7759e-01,  3.6955e-01,  9.1679e-01, -8.6434e-01,\n",
            "         -2.5065e-01,  4.2968e-01, -2.9947e-01,  7.3319e-01, -4.1854e-01,\n",
            "          9.8112e-01, -8.0720e-01,  4.8611e-01,  7.7993e-01, -6.3391e-01,\n",
            "         -8.8791e-01, -4.7558e-01,  4.7080e-01,  4.3645e-01, -2.8928e-01,\n",
            "         -8.1201e-01,  7.9132e-01, -8.7136e-01,  4.1390e-01,  1.5949e-01,\n",
            "          1.6704e-01,  3.9364e-01, -3.5927e-01,  2.9873e-01,  2.2269e-01,\n",
            "         -7.5325e-01,  8.6275e-01,  6.9239e-01, -2.0698e-01,  8.0434e-01,\n",
            "         -7.1457e-01,  5.9655e-01, -1.0048e-01, -5.3624e-01,  8.8908e-01,\n",
            "          6.2020e-01,  1.6523e-01, -6.2572e-01, -2.3514e-02,  5.5247e-01,\n",
            "         -8.8752e-01,  2.9997e-01,  5.7388e-01]], device='cuda:0',\n",
            "       grad_fn=<TanhBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluation... :   0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1b622bcbf364de69c9096d57f84dda8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7285,  0.9977,  0.8906,  ...,  0.8699, -0.7901, -0.4029],\n",
            "        [ 0.7440,  1.0000,  0.9566,  ...,  0.8238, -0.1099, -0.9306],\n",
            "        [ 0.8730,  1.0000,  0.5688,  ..., -0.4313,  0.6438, -0.9091],\n",
            "        ...,\n",
            "        [ 0.3713,  0.9998,  0.8018,  ...,  0.7944, -0.7781, -0.2543],\n",
            "        [-0.0739,  0.9696, -0.7419,  ..., -0.8791,  0.5438, -0.1392],\n",
            "        [-0.6764,  0.0041, -0.9110,  ..., -0.7564,  0.2908,  0.5679]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3809,  0.9997, -0.8276,  ..., -0.8893,  0.4923, -0.0364],\n",
            "        [ 0.7118,  1.0000,  0.7495,  ...,  0.4433, -0.7486, -0.4210],\n",
            "        [ 0.3090,  0.9999,  0.3749,  ..., -0.6390,  0.5709, -0.9198],\n",
            "        ...,\n",
            "        [-0.1676,  0.9981, -0.1747,  ..., -0.7044,  0.2387, -0.7704],\n",
            "        [-0.5773,  0.9999, -0.5088,  ..., -0.8635,  0.3327,  0.0366],\n",
            "        [ 0.4875,  1.0000,  0.7097,  ..., -0.6482,  0.6434, -0.9696]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5979,  1.0000,  0.9337,  ...,  0.8638, -0.6720, -0.5670],\n",
            "        [ 0.3168,  1.0000,  0.7996,  ...,  0.4383,  0.6554, -0.8330],\n",
            "        [ 0.5594,  1.0000,  0.8641,  ...,  0.8488, -0.6774, -0.6243],\n",
            "        ...,\n",
            "        [-0.1893,  1.0000,  0.1403,  ..., -0.8762,  0.5938, -0.8667],\n",
            "        [-0.7517,  0.0609, -0.8922,  ..., -0.9225,  0.2617,  0.3860],\n",
            "        [ 0.4931,  1.0000,  0.5254,  ..., -0.2029,  0.3702, -0.9638]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1208,  0.9996,  0.1144,  ..., -0.1464, -0.6090, -0.7321],\n",
            "        [-0.0077,  1.0000,  0.7772,  ..., -0.4948,  0.2989, -0.9614],\n",
            "        [ 0.0106,  0.9999, -0.3682,  ..., -0.8086,  0.3256, -0.8849],\n",
            "        ...,\n",
            "        [ 0.7103,  0.9999,  0.8925,  ...,  0.8781, -0.6612, -0.4867],\n",
            "        [-0.0949,  0.1787, -0.7951,  ..., -0.9087,  0.6572, -0.3124],\n",
            "        [ 0.6390,  0.9994,  0.8843,  ...,  0.8961, -0.8432, -0.3426]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6799,  1.0000,  0.7591,  ...,  0.7164, -0.4410, -0.3685],\n",
            "        [ 0.4242,  1.0000,  0.8398,  ...,  0.8579, -0.4634, -0.5437],\n",
            "        [-0.4524,  0.7837, -0.8611,  ..., -0.7466,  0.3671,  0.3637],\n",
            "        ...,\n",
            "        [ 0.5262,  1.0000,  0.5652,  ...,  0.6840, -0.4267, -0.8514],\n",
            "        [ 0.4998,  1.0000,  0.8727,  ...,  0.2288, -0.4558, -0.6938],\n",
            "        [ 0.7418,  0.9999,  0.9599,  ...,  0.5923, -0.3812, -0.7410]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5424,  0.9998,  0.8825,  ...,  0.8809, -0.7747, -0.4736],\n",
            "        [ 0.6785,  1.0000,  0.5508,  ...,  0.3118, -0.3647, -0.9011],\n",
            "        [-0.2824,  0.2214, -0.9625,  ..., -0.8796,  0.6040,  0.2717],\n",
            "        ...,\n",
            "        [ 0.8381,  1.0000, -0.1112,  ..., -0.5529,  0.7144, -0.8056],\n",
            "        [ 0.3409,  1.0000,  0.1815,  ...,  0.1728, -0.3534, -0.6902],\n",
            "        [-0.2368,  1.0000, -0.1444,  ..., -0.7929,  0.3508, -0.8565]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0431,  0.9839, -0.5934,  ..., -0.8061, -0.2210, -0.6035],\n",
            "        [-0.5377, -0.8094, -0.9461,  ..., -0.9343,  0.0558,  0.6898],\n",
            "        [ 0.6117,  0.9989,  0.8410,  ...,  0.8993, -0.7941, -0.3541],\n",
            "        ...,\n",
            "        [-0.2088,  1.0000, -0.2374,  ..., -0.7887, -0.3674, -0.5696],\n",
            "        [ 0.5871,  0.9992,  0.9076,  ...,  0.9077, -0.8451, -0.3316],\n",
            "        [-0.3676,  0.9733, -0.8117,  ..., -0.8225,  0.1261,  0.2726]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6478,  0.9999,  0.8889,  ...,  0.8825, -0.7674, -0.5132],\n",
            "        [ 0.6768,  0.9998,  0.9253,  ...,  0.9150, -0.7506, -0.5111],\n",
            "        [ 0.7091,  1.0000,  0.9439,  ...,  0.8187,  0.0146, -0.9164],\n",
            "        ...,\n",
            "        [ 0.5969,  0.9982,  0.8920,  ...,  0.8686, -0.8559, -0.2773],\n",
            "        [ 0.4388,  0.9998,  0.8015,  ...,  0.8159, -0.7320, -0.6529],\n",
            "        [ 0.5938,  1.0000,  0.7753,  ...,  0.5871, -0.4830, -0.6810]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7538,  1.0000,  0.9470,  ...,  0.8744, -0.5820, -0.7476],\n",
            "        [-0.1248,  0.9945, -0.8918,  ..., -0.8692,  0.3614, -0.0309],\n",
            "        [-0.8053, -0.8794, -0.8012,  ..., -0.8964,  0.0913,  0.1943],\n",
            "        ...,\n",
            "        [ 0.6680,  0.9999,  0.8865,  ...,  0.8592, -0.7119, -0.4423],\n",
            "        [-0.6522, -0.8266, -0.9249,  ..., -0.9032,  0.2072,  0.7615],\n",
            "        [ 0.5390,  0.9982,  0.8801,  ...,  0.8469, -0.8032, -0.2671]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4725, -0.4763, -0.9530,  ..., -0.8972,  0.1268,  0.4625],\n",
            "        [ 0.1473,  1.0000,  0.2828,  ..., -0.5839,  0.1747, -0.8631],\n",
            "        [ 0.5792,  0.9995,  0.8994,  ...,  0.8780, -0.8222, -0.4119],\n",
            "        ...,\n",
            "        [ 0.6954,  0.9994,  0.8227,  ...,  0.8856, -0.8299, -0.3526],\n",
            "        [ 0.5082,  0.9999,  0.8448,  ...,  0.7378, -0.6026, -0.1960],\n",
            "        [ 0.7077,  1.0000,  0.9313,  ...,  0.7260,  0.2479, -0.9603]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1288,  0.7622, -0.8863,  ..., -0.8652,  0.3518,  0.2328],\n",
            "        [-0.4807, -0.9425, -0.9094,  ..., -0.9390,  0.1475,  0.4494],\n",
            "        [-0.6735,  0.6485, -0.9655,  ..., -0.9471, -0.0755,  0.3593],\n",
            "        ...,\n",
            "        [ 0.6565,  1.0000,  0.8530,  ...,  0.6401, -0.5155, -0.8475],\n",
            "        [ 0.7410,  1.0000, -0.4494,  ..., -0.4918,  0.5275, -0.8535],\n",
            "        [ 0.4919,  0.9995,  0.9057,  ...,  0.8877, -0.8021, -0.2841]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0134,  1.0000,  0.5743,  ...,  0.0211,  0.5957, -0.8037],\n",
            "        [-0.4480, -0.8925, -0.9534,  ..., -0.9113,  0.2279,  0.5635],\n",
            "        [-0.6671,  0.9704, -0.9059,  ..., -0.9024,  0.2180, -0.0078],\n",
            "        ...,\n",
            "        [-0.5248,  0.9769, -0.9335,  ..., -0.9100,  0.3142,  0.4702],\n",
            "        [ 0.2168,  1.0000,  0.3187,  ..., -0.5128, -0.0916, -0.8217],\n",
            "        [-0.2054,  0.9999, -0.6824,  ..., -0.9124,  0.5587, -0.5146]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2667,  0.9987, -0.7180,  ..., -0.4036,  0.7274,  0.1225],\n",
            "        [ 0.3321,  1.0000,  0.6718,  ..., -0.0116, -0.0045, -0.8919],\n",
            "        [-0.6107, -0.9207, -0.8530,  ..., -0.9135,  0.4139,  0.3818],\n",
            "        ...,\n",
            "        [-0.7235,  0.9952, -0.9239,  ..., -0.7218,  0.6139,  0.2865],\n",
            "        [-0.1221,  0.9991, -0.9131,  ..., -0.8694,  0.4981, -0.2358],\n",
            "        [-0.5753,  1.0000, -0.6744,  ..., -0.7980,  0.4462, -0.7186]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7665,  1.0000,  0.9185,  ...,  0.5185, -0.4759, -0.7123],\n",
            "        [ 0.5717,  1.0000,  0.7775,  ...,  0.1268, -0.0937, -0.8708],\n",
            "        [-0.6432, -0.4756, -0.9327,  ..., -0.8517, -0.1446,  0.4962],\n",
            "        ...,\n",
            "        [ 0.4764,  1.0000,  0.5643,  ..., -0.1992, -0.4864, -0.7125],\n",
            "        [ 0.4125,  1.0000,  0.7654,  ...,  0.7504, -0.0792, -0.6754],\n",
            "        [-0.5738,  0.9973, -0.5514,  ..., -0.7586,  0.1344, -0.4776]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4690,  1.0000,  0.6377, -0.9657, -0.3489,  0.9218,  0.7241,  0.7649,\n",
            "         -0.9970, -0.6471,  0.7539, -0.4791,  0.4782,  0.9991,  0.3275,  0.1689,\n",
            "          0.7470, -0.9754,  0.7136, -0.3422,  0.3390, -0.7416,  0.8336, -0.4272,\n",
            "          0.8096,  0.6193, -0.4489,  0.6140, -0.2298,  0.2397, -0.6301, -0.3269,\n",
            "          0.9445,  0.6640,  0.8148, -0.9362, -0.3005, -0.9395, -0.9914, -0.9970,\n",
            "          0.2981, -0.4837,  0.9994, -0.8320,  0.9955, -0.9901,  0.4270, -0.3831,\n",
            "          0.6158,  0.4533, -0.7747,  0.8730,  0.8055,  0.7739, -0.5846, -0.8920,\n",
            "         -0.8524,  0.5556, -0.9067, -0.4642,  0.8218,  0.6971, -0.5483,  0.0034,\n",
            "         -0.8621, -0.3828,  0.6293,  0.4792, -0.6573, -0.9421,  0.8481, -0.9240,\n",
            "          0.7513,  0.1272, -0.2025,  0.8647, -0.8654,  0.8806, -0.7749,  0.9924,\n",
            "          0.5618,  0.4137,  0.7172, -0.9999,  0.6408, -0.9087,  0.9833, -0.9867,\n",
            "         -0.9621,  0.7131,  0.7564,  0.6511,  0.7415, -0.1858, -0.4065, -0.8584,\n",
            "         -0.6132,  0.5553, -0.9988,  0.7942,  0.7316,  0.8509, -0.6836, -0.6549,\n",
            "         -0.9991,  0.3317, -0.7219, -0.5289, -0.9999, -0.7189, -0.8229, -0.8056,\n",
            "         -0.1715,  0.8883,  0.5141,  0.9997,  0.8465,  0.9983, -0.9999, -0.9950,\n",
            "          0.1377,  0.9485, -0.6313, -0.1807,  0.5102, -0.9737,  0.5564, -0.9978,\n",
            "          0.8058, -0.9549, -0.5698,  0.7277,  0.8870,  0.3149, -0.6366,  0.6136,\n",
            "         -0.9996,  0.0877, -0.6599, -0.9914,  0.9938,  0.9054,  0.8118, -0.4014,\n",
            "         -0.3973,  0.8739,  0.8383, -0.6470,  0.0675, -0.3639, -0.8164,  0.8287,\n",
            "          0.3710, -0.5396, -1.0000,  0.5743, -0.6270,  0.9554, -0.9833,  0.9792,\n",
            "         -0.9543, -0.9999,  0.4093,  0.4350, -0.7415,  0.8192, -0.8483,  0.8724,\n",
            "         -0.6105,  0.7426,  0.7028,  0.7152,  0.3977, -0.3278,  0.5132, -0.7845,\n",
            "          0.7721, -0.7442, -0.5313, -0.9650,  0.9654, -0.5100,  0.9736, -0.9514,\n",
            "         -0.6485,  0.3561,  0.1017, -1.0000,  0.8835,  0.5394,  0.4480,  0.3450,\n",
            "          0.2575, -0.4084,  0.0572, -0.0181, -0.6028,  0.7924, -0.2267,  0.9169,\n",
            "          0.5134, -0.9993,  0.8187,  0.9933,  0.1760, -0.5541,  0.0375,  0.9823,\n",
            "         -0.9962, -0.7298,  0.2630, -0.5087,  0.5253,  0.3974, -0.5167, -0.7179,\n",
            "          0.7498,  0.2605,  0.0593, -0.3618,  0.1627,  0.5344, -0.3373,  0.4180,\n",
            "          0.8089,  0.9989, -0.4765, -0.5051,  0.5701, -0.9993,  0.8522,  0.5708,\n",
            "         -0.2737, -0.6932,  0.9913,  0.8371,  0.6513,  0.9883, -0.9357, -0.4062,\n",
            "         -0.5296,  0.8770, -0.2766,  0.0561,  0.9999, -0.9941,  0.9800,  0.9063,\n",
            "         -0.0089, -0.3501,  0.6200,  0.1525, -0.0911,  0.0944, -0.6179,  0.9933,\n",
            "         -0.6487, -0.9884,  0.4638, -0.0925, -0.9324, -0.8168,  0.7070, -0.6142,\n",
            "          0.9713,  0.9999,  0.6805,  0.4629,  0.7243,  0.5990,  0.8048, -0.9789,\n",
            "          0.9740,  1.0000, -0.9338,  0.3397,  0.9999,  0.6645, -0.3684, -0.4705,\n",
            "          0.2664, -0.9725, -0.0459, -0.4400, -0.3684, -0.4865, -0.0232, -0.9447,\n",
            "         -0.9993, -0.9864,  0.9773, -0.7282, -0.4976,  0.6177, -0.8164,  0.2679,\n",
            "         -0.5897,  0.9887, -0.7281,  0.9999,  0.6219, -0.5586, -0.9633, -0.2068,\n",
            "          0.5466,  0.2363,  0.9987,  0.2471, -0.7440,  0.8106,  0.6976,  0.2799,\n",
            "          0.8903, -0.5157,  0.6300,  0.2925,  0.0933, -0.9568, -0.3180, -0.8367,\n",
            "          0.8448,  0.9664,  0.7374, -0.0277,  0.9585,  0.8144, -1.0000,  0.9989,\n",
            "          0.9775, -0.9919,  0.8414, -0.0071,  0.8811, -0.2462,  0.5404, -0.8893,\n",
            "         -0.8325, -0.9707,  0.8043,  0.2889, -0.6607,  0.4790, -0.8895,  0.7886,\n",
            "          0.1227,  0.7463, -0.1918,  0.0120, -0.9958,  0.6850,  0.8894, -0.0788,\n",
            "          0.7105,  0.9841,  0.1212,  1.0000, -0.7529, -0.1322,  0.0676,  0.6505,\n",
            "          0.2448,  0.5743, -0.0561,  0.3871, -1.0000,  0.0970, -0.4507,  0.4084,\n",
            "          0.4738, -0.9816,  0.3522, -0.4966, -0.2046, -0.0310,  0.2607,  0.5533,\n",
            "          0.9986,  0.4451, -0.3979, -0.7204, -0.2131,  0.1000,  0.9233,  0.7871,\n",
            "          0.9928, -0.8304, -0.1441,  0.6772,  0.0027, -0.6531, -0.1010,  0.5794,\n",
            "          0.0719,  0.9187,  0.7713, -0.3757, -0.5913,  0.8264, -0.9983,  0.9999,\n",
            "          0.2522,  0.5073,  0.9511, -0.0953,  0.8239,  0.2703,  0.3649, -0.7537,\n",
            "          0.9744,  0.6739,  0.6161,  0.1547,  0.0429, -0.0705, -0.9302,  0.6353,\n",
            "          0.2267, -0.5306, -0.9848,  0.9878, -0.9857,  0.2233, -0.3775,  0.7660,\n",
            "          0.9672, -0.4304, -0.8231, -0.3478,  0.2083, -0.8144, -0.8526, -0.9936,\n",
            "         -0.0879, -0.9181,  0.9999, -0.9924,  0.5842, -0.9239, -0.8936,  0.7627,\n",
            "         -0.2495, -0.6312, -0.7929,  0.0106, -0.5152,  0.8266, -0.0826,  0.6989,\n",
            "         -0.3524,  0.3563,  0.7564,  0.2606,  0.3277,  0.8987, -0.6534, -0.9568,\n",
            "         -0.7395, -0.6264, -0.6553,  0.9598, -0.9402, -0.7595,  1.0000, -0.9818,\n",
            "          0.2977, -0.3040, -0.9960,  0.5532, -0.5424, -0.9475, -0.5884, -0.8016,\n",
            "          0.7239,  0.9275,  0.9992,  0.0878,  0.1518, -0.9737, -0.6340,  0.9964,\n",
            "         -0.9684, -0.2748,  0.1924, -0.9956,  0.9277,  0.3794, -0.5314,  0.8846,\n",
            "         -0.7093,  0.9623,  0.5918, -0.9964,  0.6871,  0.7680, -0.2437,  0.8704,\n",
            "          0.0556,  0.1672, -0.9527,  0.0652,  0.9994,  0.2682, -0.8505,  0.2941,\n",
            "          0.7840,  0.7501,  1.0000, -0.9478,  0.6314,  0.9996, -0.2991,  0.4546,\n",
            "          0.1969, -0.7521, -0.0319,  0.5633, -0.9800,  0.9998, -0.0882, -0.9878,\n",
            "         -0.9999,  0.3264, -0.7867,  0.7168,  0.9639,  0.4715,  0.8797,  0.2963,\n",
            "         -0.9984,  0.1390, -0.6510, -0.9997, -0.9992,  0.8194, -0.0576,  0.1817,\n",
            "          0.7906, -0.1056, -0.7895,  0.9996,  0.8650, -0.9999, -0.3855,  0.3386,\n",
            "          0.9551, -0.7491,  0.6838,  0.3295,  0.3058, -0.3955, -1.0000, -0.5974,\n",
            "          0.9749, -0.0488, -0.1189,  0.9993,  0.7253,  0.2942, -0.9569,  0.0660,\n",
            "          0.7655, -1.0000, -0.7355,  0.9997, -0.4301, -0.2919, -0.6694,  0.1255,\n",
            "          0.5718,  0.5754,  0.2408, -0.9969,  0.9949,  0.8534, -0.9167,  0.9979,\n",
            "         -0.4870, -0.7056, -0.7803, -0.5952,  0.7906, -0.7318,  0.6120, -0.4031,\n",
            "          0.9843,  0.9052, -0.4976,  0.8058,  0.8954, -0.7988, -0.4846,  0.8385,\n",
            "          0.6608,  0.3935,  0.9847, -0.3525, -0.7566, -0.3091,  0.6164,  0.9187,\n",
            "         -0.9999,  0.9195, -0.4406, -0.9071,  0.6061, -0.4999, -0.7696, -0.2211,\n",
            "         -0.4887, -0.6964,  0.3248,  0.9414,  0.7874,  0.8349, -0.9866, -0.9999,\n",
            "         -0.6225, -0.5252, -0.8343, -0.4640,  0.1361,  0.9584,  0.2886,  0.5503,\n",
            "          0.3939,  0.9998, -0.3872,  0.9881, -0.7584,  0.9401, -0.9870,  0.6735,\n",
            "          0.5517, -0.9747, -0.6639,  0.9443, -0.4913,  0.8433, -0.9683,  0.6899,\n",
            "          1.0000, -0.6994, -0.5047,  0.7066, -0.8752,  0.7801, -0.1002,  0.9951,\n",
            "         -0.9999,  0.9866,  0.0834,  0.4121,  0.6335,  0.5435,  0.5654, -0.6504,\n",
            "         -0.5788, -0.9893,  0.5107,  0.3439, -0.6216,  0.1706,  0.9456, -0.8269,\n",
            "         -0.9987, -0.5706,  0.4140,  0.9605, -0.3932, -0.9906,  0.9613, -0.1686,\n",
            "          0.9760, -0.0107, -0.6712, -0.5505, -0.2049, -0.5374,  0.5216,  0.7005,\n",
            "          0.7939,  0.3116, -0.8186, -0.4302, -0.0703, -0.7600,  0.7512, -0.1975,\n",
            "          0.0363,  0.6641,  0.8434,  0.9805,  0.3982,  0.0755,  0.7446, -0.7015,\n",
            "         -0.4327, -0.9997,  0.9990,  0.8678, -0.8383, -0.9997,  0.9415,  0.3777,\n",
            "         -0.2893,  0.7704, -0.1389, -0.7460,  0.0695,  0.7729, -1.0000, -0.5994,\n",
            "          0.1042, -0.4235, -0.5823, -0.9998, -0.5958,  0.2055, -0.2878,  0.1856,\n",
            "          0.9985, -0.4077, -0.9912, -0.9682, -0.2392,  0.6450,  0.2290, -0.9726,\n",
            "         -0.4717,  0.8703, -0.9979,  0.6243, -0.6130, -0.5261,  0.2046,  0.6645,\n",
            "          0.9179, -0.9999,  0.8851, -0.7512,  0.8782, -0.4379,  0.4747,  0.6426,\n",
            "          0.3946, -0.9984,  0.8624,  0.2750,  0.8645,  0.8026,  0.7489,  0.1371,\n",
            "         -0.8870, -0.7268,  0.9868,  0.9794, -0.6140,  0.7455,  0.9987, -0.5853,\n",
            "          0.5041,  0.5901, -0.1138, -0.9992, -0.8168, -0.3757, -0.5673, -0.8362]],\n",
            "       device='cuda:0')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training... :   0%|          | 0/127 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b701b766409f420f9e4ac66415582b78"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6535, -0.8173, -0.8803,  ..., -0.8442, -0.0167,  0.5881],\n",
            "        [ 0.6122,  1.0000,  0.9276,  ...,  0.8844, -0.0474, -0.8666],\n",
            "        [ 0.6945,  0.9988,  0.8805,  ...,  0.8619, -0.8043, -0.4048],\n",
            "        ...,\n",
            "        [-0.5533,  0.9980, -0.8852,  ..., -0.9308, -0.1406, -0.2682],\n",
            "        [ 0.8272,  1.0000,  0.3707,  ..., -0.3666,  0.6825, -0.8995],\n",
            "        [ 0.6830,  0.9991,  0.8358,  ...,  0.8746, -0.8192, -0.4052]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2743, -0.8631, -0.8904,  ..., -0.8771,  0.4934,  0.3005],\n",
            "        [ 0.6487,  1.0000,  0.9283,  ...,  0.7425, -0.6432, -0.6747],\n",
            "        [-0.3862,  0.9135, -0.8743,  ..., -0.9020,  0.4585,  0.4142],\n",
            "        ...,\n",
            "        [ 0.1084,  0.7311, -0.9094,  ..., -0.8698,  0.6045,  0.0505],\n",
            "        [ 0.8073,  0.9999,  0.8836,  ...,  0.8580, -0.7491, -0.5249],\n",
            "        [ 0.6134,  0.9999,  0.8424,  ...,  0.8421, -0.6265, -0.6433]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2675,  0.9962, -0.9319,  ..., -0.8417,  0.2782,  0.2513],\n",
            "        [ 0.4756,  1.0000,  0.9100,  ...,  0.8432, -0.5971, -0.6667],\n",
            "        [ 0.4992,  1.0000,  0.9655,  ...,  0.8870, -0.7253, -0.6189],\n",
            "        ...,\n",
            "        [ 0.5016,  0.9993,  0.9365,  ...,  0.8859, -0.7375, -0.2898],\n",
            "        [ 0.5933,  0.9986,  0.8931,  ...,  0.9161, -0.8397, -0.2743],\n",
            "        [ 0.5378,  0.9906,  0.7881,  ...,  0.8407, -0.8601, -0.4108]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5282,  0.9990,  0.8069,  ...,  0.8810, -0.8554, -0.5865],\n",
            "        [ 0.7986,  1.0000,  0.9426,  ...,  0.8757, -0.2651, -0.7473],\n",
            "        [ 0.7465,  0.9998,  0.7018,  ...,  0.6611, -0.4948, -0.4924],\n",
            "        ...,\n",
            "        [ 0.2014,  0.9937, -0.9007,  ..., -0.8833,  0.4387, -0.2838],\n",
            "        [ 0.6592,  0.9998,  0.7578,  ...,  0.7813, -0.7877, -0.5490],\n",
            "        [-0.3884, -0.9895, -0.9467,  ..., -0.9379,  0.0196,  0.1464]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3990, -0.5948, -0.9393,  ..., -0.8742,  0.2156,  0.5696],\n",
            "        [ 0.6778,  1.0000,  0.9691,  ...,  0.8679, -0.1372, -0.8929],\n",
            "        [-0.5389,  0.0969, -0.9463,  ..., -0.8751,  0.3452,  0.3249],\n",
            "        ...,\n",
            "        [ 0.4426,  0.9987,  0.8993,  ...,  0.7090, -0.4844, -0.8055],\n",
            "        [ 0.6162,  0.9998,  0.8510,  ...,  0.8319, -0.7400, -0.1674],\n",
            "        [ 0.4806,  1.0000,  0.9473,  ...,  0.8071, -0.2886, -0.5321]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5374,  0.9972,  0.9138,  ...,  0.7360, -0.7054, -0.3698],\n",
            "        [ 0.1765,  0.9996,  0.8735,  ..., -0.6295, -0.3207, -0.5584],\n",
            "        [-0.5125, -0.9440, -0.8463,  ..., -0.8926, -0.2176,  0.0054],\n",
            "        ...,\n",
            "        [ 0.7817,  0.9999,  0.6947,  ...,  0.8526, -0.6828, -0.3084],\n",
            "        [-0.4509,  0.9987, -0.6270,  ..., -0.7817, -0.0428, -0.1356],\n",
            "        [-0.5976, -0.9166, -0.9323,  ..., -0.9236,  0.5299,  0.6523]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5398,  0.8090, -0.9141,  ..., -0.8986,  0.2618,  0.3428],\n",
            "        [ 0.5700,  0.9997,  0.9268,  ...,  0.8621, -0.6826, -0.3927],\n",
            "        [ 0.4951,  0.9986,  0.8519,  ...,  0.8224, -0.8450, -0.2592],\n",
            "        ...,\n",
            "        [ 0.7123,  1.0000,  0.9284,  ...,  0.9023, -0.6075, -0.5345],\n",
            "        [ 0.7719,  0.9997,  0.7930,  ...,  0.9214, -0.6789, -0.1264],\n",
            "        [-0.4791, -0.1948, -0.9533,  ..., -0.8622,  0.4434,  0.5662]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0656,  0.9559, -0.9351,  ..., -0.8792, -0.1760,  0.0756],\n",
            "        [ 0.4286,  0.9996,  0.8373,  ...,  0.8812, -0.8731, -0.3367],\n",
            "        [ 0.3317,  0.9997,  0.8779,  ...,  0.8735, -0.7370, -0.4847],\n",
            "        ...,\n",
            "        [-0.6342, -0.3790, -0.9455,  ..., -0.9033,  0.0066,  0.5220],\n",
            "        [-0.6382,  0.6579, -0.8810,  ..., -0.8273, -0.0491,  0.4372],\n",
            "        [-0.2203, -0.9899, -0.9234,  ..., -0.8607,  0.4067,  0.0391]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5538,  0.9720, -0.8160,  ..., -0.7480, -0.0758, -0.2204],\n",
            "        [ 0.4254,  1.0000,  0.8655,  ...,  0.7064, -0.2457, -0.4988],\n",
            "        [-0.5724,  0.1029, -0.9456,  ..., -0.9137,  0.4578, -0.0884],\n",
            "        ...,\n",
            "        [-0.3890, -0.8868, -0.9702,  ..., -0.8832,  0.2629,  0.4743],\n",
            "        [ 0.7401,  0.9930,  0.8070,  ...,  0.8084, -0.6868, -0.2274],\n",
            "        [-0.5117, -0.0243, -0.9296,  ..., -0.8974, -0.1448,  0.5048]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6304,  0.9998,  0.8635,  ...,  0.8908, -0.7465, -0.4113],\n",
            "        [-0.3653, -0.9108, -0.9183,  ..., -0.8908,  0.3481,  0.2595],\n",
            "        [ 0.6892,  1.0000,  0.9415,  ...,  0.7916, -0.3905, -0.8460],\n",
            "        ...,\n",
            "        [ 0.7147,  0.9992,  0.8946,  ...,  0.8727, -0.6556, -0.5316],\n",
            "        [ 0.5987,  0.9998,  0.8817,  ...,  0.8850, -0.7490, -0.2801],\n",
            "        [ 0.7964,  1.0000,  0.7448,  ...,  0.7480, -0.5116, -0.5034]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5102, -0.9853, -0.9599,  ..., -0.9555,  0.1325,  0.7800],\n",
            "        [ 0.6300,  0.9936,  0.6556,  ...,  0.8869, -0.8451, -0.0880],\n",
            "        [-0.4104,  0.9921, -0.8429,  ..., -0.7484,  0.1008, -0.4994],\n",
            "        ...,\n",
            "        [ 0.6696,  1.0000,  0.9830,  ...,  0.8311,  0.0240, -0.7954],\n",
            "        [ 0.6183,  1.0000,  0.7656,  ...,  0.7727, -0.7277, -0.5603],\n",
            "        [-0.5270,  0.9048, -0.4385,  ..., -0.7939,  0.3406,  0.0652]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3158,  0.9398, -0.9295,  ..., -0.9276,  0.4453, -0.0045],\n",
            "        [-0.4732,  0.0485, -0.5143,  ..., -0.6036,  0.3778,  0.0744],\n",
            "        [ 0.5818,  0.9895, -0.8468,  ..., -0.7713,  0.6983, -0.4355],\n",
            "        ...,\n",
            "        [ 0.6959,  1.0000,  0.9352,  ...,  0.7866, -0.3302, -0.8589],\n",
            "        [ 0.6466,  0.9998,  0.7340,  ...,  0.8520, -0.8400, -0.3258],\n",
            "        [ 0.4198,  1.0000,  0.8608,  ...,  0.8048, -0.5755, -0.4463]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6802,  0.9997,  0.8244,  ...,  0.9013, -0.7455, -0.1960],\n",
            "        [ 0.0326, -0.9232, -0.9144,  ..., -0.8991,  0.2001,  0.5512],\n",
            "        [-0.6536, -0.9966, -0.9385,  ..., -0.8816,  0.1285,  0.6784],\n",
            "        ...,\n",
            "        [ 0.6446,  0.9998,  0.8483,  ...,  0.8423, -0.7720, -0.3443],\n",
            "        [ 0.8124,  0.9998,  0.9059,  ...,  0.7778, -0.7001, -0.6897],\n",
            "        [ 0.5988,  0.9938,  0.8330,  ...,  0.8396, -0.8450, -0.5312]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4954,  1.0000,  0.5466,  ...,  0.7771, -0.8787, -0.5314],\n",
            "        [-0.2264,  0.9999, -0.1882,  ..., -0.8651, -0.0933, -0.2166],\n",
            "        [-0.4804, -0.9989, -0.9376,  ..., -0.9467, -0.2002,  0.6257],\n",
            "        ...,\n",
            "        [ 0.5053,  0.9994,  0.9276,  ...,  0.9253, -0.7059, -0.2677],\n",
            "        [-0.4370,  0.7346, -0.8995,  ..., -0.9297,  0.4696,  0.0402],\n",
            "        [ 0.5486,  0.9976,  0.7880,  ...,  0.7703, -0.6907, -0.1620]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4679,  0.9994,  0.7024,  ...,  0.8619, -0.8871, -0.1778],\n",
            "        [-0.4930, -0.8282, -0.9681,  ..., -0.9146,  0.1321,  0.4302],\n",
            "        [ 0.7547,  0.9996,  0.8310,  ...,  0.8593, -0.7816, -0.2002],\n",
            "        ...,\n",
            "        [-0.3650, -0.6985, -0.9455,  ..., -0.8847,  0.4008,  0.4825],\n",
            "        [ 0.3111,  0.9996, -0.7055,  ..., -0.7093,  0.7378, -0.4566],\n",
            "        [ 0.7883,  0.9990,  0.9311,  ...,  0.8034, -0.7502, -0.6211]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5165,  0.9992,  0.8009,  ...,  0.8322, -0.6930, -0.2417],\n",
            "        [-0.4613, -0.4572, -0.9213,  ..., -0.9357,  0.2367,  0.5074],\n",
            "        [ 0.5086,  0.9978,  0.9020,  ...,  0.7344, -0.7347, -0.5017],\n",
            "        ...,\n",
            "        [-0.5348, -0.7800, -0.9357,  ..., -0.9415,  0.5235,  0.4381],\n",
            "        [-0.5714, -0.9652, -0.9584,  ..., -0.8513, -0.0615,  0.6416],\n",
            "        [-0.0193,  0.8396, -0.9151,  ..., -0.8173,  0.2766, -0.2564]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5723, -0.2992, -0.9110,  ..., -0.8703,  0.3712, -0.0198],\n",
            "        [ 0.6475,  1.0000, -0.6425,  ..., -0.8898,  0.7643, -0.7694],\n",
            "        [ 0.6690,  0.9982,  0.8181,  ...,  0.8781, -0.8937, -0.2467],\n",
            "        ...,\n",
            "        [ 0.7416,  0.9998,  0.9086,  ...,  0.8642, -0.6156, -0.6951],\n",
            "        [ 0.4813,  0.9965,  0.6255,  ...,  0.8807, -0.6974, -0.3559],\n",
            "        [ 0.5427,  1.0000,  0.8531,  ...,  0.5098,  0.6677, -0.8412]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4805,  0.9231, -0.9047,  ..., -0.7408,  0.6448,  0.0042],\n",
            "        [-0.4816, -0.2803, -0.8779,  ..., -0.7529,  0.5403, -0.0538],\n",
            "        [ 0.4553,  0.9967,  0.8368,  ...,  0.7538, -0.7203, -0.4492],\n",
            "        ...,\n",
            "        [-0.0864,  0.9995, -0.5746,  ..., -0.7021,  0.4104, -0.3906],\n",
            "        [ 0.4696,  0.9982,  0.9187,  ...,  0.8676, -0.8433, -0.3944],\n",
            "        [ 0.6104,  0.9989,  0.8753,  ...,  0.6859, -0.6845, -0.5788]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2724,  0.9992,  0.8553,  ...,  0.8300, -0.8128, -0.2242],\n",
            "        [ 0.6326,  0.9979,  0.9007,  ...,  0.9071, -0.8310, -0.3764],\n",
            "        [-0.6350, -0.9832, -0.8949,  ..., -0.9258,  0.1943,  0.7528],\n",
            "        ...,\n",
            "        [-0.1000,  1.0000,  0.7228,  ..., -0.0543, -0.0238, -0.7819],\n",
            "        [ 0.4247,  0.9994,  0.7699,  ...,  0.8135, -0.6953, -0.2087],\n",
            "        [ 0.7381,  0.9999,  0.8380,  ...,  0.8166, -0.4947, -0.5623]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4105, -0.7973, -0.9234,  ..., -0.7897,  0.0402,  0.4289],\n",
            "        [ 0.6401,  0.9999,  0.8897,  ...,  0.8723, -0.7165, -0.4902],\n",
            "        [ 0.6872,  1.0000,  0.9095,  ...,  0.8572, -0.5426, -0.2917],\n",
            "        ...,\n",
            "        [-0.3839, -0.4022, -0.9171,  ..., -0.8027,  0.0574,  0.2067],\n",
            "        [-0.2269, -0.9974, -0.9614,  ..., -0.8740,  0.5680,  0.3431],\n",
            "        [ 0.6315,  0.9998,  0.8478,  ...,  0.8293, -0.5659, -0.7471]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7023,  0.9990,  0.8748,  ...,  0.9159, -0.8335, -0.2272],\n",
            "        [ 0.6846,  0.9905,  0.8214,  ...,  0.8618, -0.8351, -0.1532],\n",
            "        [ 0.1701,  0.9922,  0.8498,  ...,  0.8272, -0.6851, -0.2642],\n",
            "        ...,\n",
            "        [-0.5522, -0.9885, -0.9363,  ..., -0.8844,  0.4353,  0.5751],\n",
            "        [-0.4549, -0.5497, -0.9702,  ..., -0.9271, -0.1063,  0.4772],\n",
            "        [ 0.6072,  1.0000,  0.9418,  ...,  0.8478, -0.2947, -0.8787]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4651,  0.9095, -0.9015,  ..., -0.9159,  0.5466,  0.1079],\n",
            "        [-0.0257,  1.0000, -0.0312,  ..., -0.7972,  0.4345, -0.7734],\n",
            "        [ 0.6621,  0.9993,  0.8815,  ...,  0.8326, -0.7956, -0.6226],\n",
            "        ...,\n",
            "        [-0.0413, -0.8822, -0.9567,  ..., -0.8478,  0.2841,  0.4638],\n",
            "        [ 0.4702,  0.9997,  0.9141,  ...,  0.8962, -0.6597, -0.4311],\n",
            "        [-0.5326,  0.9995, -0.4820,  ..., -0.8588,  0.1072, -0.6104]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4576,  0.9998,  0.7941,  ...,  0.8799, -0.6980, -0.5091],\n",
            "        [ 0.7658,  0.9972,  0.7842,  ...,  0.7435, -0.8726,  0.1164],\n",
            "        [ 0.2336,  1.0000, -0.6541,  ..., -0.8044,  0.8809, -0.7111],\n",
            "        ...,\n",
            "        [ 0.6311,  0.9998,  0.6268,  ...,  0.7265, -0.7220, -0.3344],\n",
            "        [ 0.0194,  0.7187, -0.8809,  ..., -0.8724,  0.2350, -0.1291],\n",
            "        [ 0.6466,  0.9995,  0.9085,  ...,  0.8696, -0.6534, -0.6254]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2403,  0.4230, -0.9033,  ..., -0.9240,  0.4105,  0.5845],\n",
            "        [ 0.3992,  0.9984,  0.8217,  ...,  0.8124, -0.8644, -0.1932],\n",
            "        [ 0.5446,  1.0000,  0.8807,  ...,  0.4596,  0.5155, -0.9695],\n",
            "        ...,\n",
            "        [-0.4066,  0.3887, -0.8847,  ..., -0.8515,  0.4306,  0.0656],\n",
            "        [ 0.3587,  0.9989,  0.7621,  ...,  0.8232, -0.8320,  0.1386],\n",
            "        [ 0.5868,  0.9999,  0.9093,  ...,  0.9317, -0.6481, -0.3876]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3893,  0.9955,  0.8358,  ...,  0.8311, -0.8360, -0.4166],\n",
            "        [ 0.5925,  0.9999,  0.8575,  ...,  0.8196, -0.8438, -0.3676],\n",
            "        [-0.5412, -0.9925, -0.9485,  ..., -0.8834,  0.2246,  0.6226],\n",
            "        ...,\n",
            "        [-0.2366, -0.5694, -0.9040,  ..., -0.8910,  0.5535,  0.6137],\n",
            "        [ 0.7799,  0.9999,  0.8767,  ...,  0.9096, -0.6531, -0.7034],\n",
            "        [ 0.2800,  0.9990,  0.7849,  ...,  0.9276, -0.7445, -0.2769]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2912,  0.8902, -0.9409,  ..., -0.8854,  0.2585,  0.0722],\n",
            "        [ 0.5175,  0.9992,  0.7711,  ...,  0.7588, -0.8393, -0.1760],\n",
            "        [ 0.6465,  0.9986,  0.7655,  ...,  0.8496, -0.8326, -0.1850],\n",
            "        ...,\n",
            "        [-0.5626,  0.2161, -0.8295,  ..., -0.8206,  0.5473, -0.1242],\n",
            "        [ 0.6382,  0.9998,  0.8410,  ...,  0.8519, -0.7990, -0.1023],\n",
            "        [-0.2215,  0.9866, -0.7789,  ..., -0.8897,  0.6070, -0.0142]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5247,  0.5685, -0.9494,  ..., -0.9046,  0.3233,  0.1566],\n",
            "        [ 0.4908,  0.9973,  0.8552,  ...,  0.8252, -0.7993, -0.3773],\n",
            "        [ 0.7244,  1.0000,  0.8746,  ...,  0.7866, -0.7428, -0.6636],\n",
            "        ...,\n",
            "        [-0.1512,  0.9999, -0.6394,  ..., -0.8412,  0.5670, -0.4954],\n",
            "        [-0.7043,  0.6865, -0.9299,  ..., -0.9017,  0.1426,  0.5326],\n",
            "        [-0.4212,  0.9668, -0.8035,  ..., -0.7899,  0.6570, -0.1605]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6200,  0.9968, -0.7392,  ..., -0.7997,  0.5504, -0.7124],\n",
            "        [-0.4896,  0.1705, -0.9098,  ..., -0.8309,  0.2401,  0.2667],\n",
            "        [-0.2639,  0.9789, -0.3516,  ..., -0.7519,  0.2445, -0.1448],\n",
            "        ...,\n",
            "        [ 0.6314,  0.9994,  0.8258,  ...,  0.9150, -0.7988, -0.1356],\n",
            "        [-0.3689,  0.1043, -0.8333,  ..., -0.7837,  0.6169, -0.3015],\n",
            "        [-0.5794,  0.4750, -0.9204,  ..., -0.8711,  0.3539,  0.2996]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0871,  0.9966,  0.8051,  ...,  0.7774, -0.7284,  0.1439],\n",
            "        [ 0.7902,  0.9998,  0.7987,  ...,  0.7066, -0.4025, -0.5034],\n",
            "        [ 0.4943,  0.9984,  0.8258,  ...,  0.8547, -0.8201, -0.4457],\n",
            "        ...,\n",
            "        [-0.3750,  0.8724, -0.9217,  ..., -0.8880,  0.0667,  0.2219],\n",
            "        [ 0.5812,  0.9927,  0.8756,  ...,  0.8426, -0.7604, -0.3605],\n",
            "        [ 0.5416,  0.9999,  0.7693,  ...,  0.7998, -0.7293, -0.5857]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3680,  0.9995,  0.7260,  ...,  0.6149, -0.6675, -0.6830],\n",
            "        [ 0.6352,  0.9937,  0.7873,  ...,  0.7291, -0.7502, -0.1984],\n",
            "        [ 0.4008,  0.9368, -0.9037,  ..., -0.8916,  0.4899, -0.2763],\n",
            "        ...,\n",
            "        [ 0.5485,  0.9969,  0.8915,  ...,  0.9059, -0.8318, -0.2625],\n",
            "        [-0.4803, -0.0524, -0.8283,  ..., -0.9258,  0.1918,  0.3252],\n",
            "        [ 0.6249,  1.0000,  0.9267,  ...,  0.7826, -0.0997, -0.6957]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6808, -0.9576, -0.9315,  ..., -0.9013,  0.1849,  0.5730],\n",
            "        [-0.5271, -0.8621, -0.9150,  ..., -0.9195, -0.1443,  0.1489],\n",
            "        [ 0.7812,  0.9999,  0.8937,  ...,  0.9015, -0.6249, -0.4585],\n",
            "        ...,\n",
            "        [-0.2882, -1.0000, -0.9329,  ..., -0.9201,  0.1159,  0.6617],\n",
            "        [ 0.6104,  0.9996,  0.8452,  ...,  0.8793, -0.8197, -0.4484],\n",
            "        [-0.7156, -0.6965, -0.9272,  ..., -0.8712, -0.1262,  0.6715]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5762,  0.9996,  0.8741,  ...,  0.9260, -0.8581, -0.2998],\n",
            "        [ 0.4427,  0.9994,  0.8619,  ...,  0.8579, -0.7595, -0.3979],\n",
            "        [ 0.0758,  0.4564, -0.9101,  ..., -0.9299,  0.2491,  0.5350],\n",
            "        ...,\n",
            "        [-0.2673,  0.9984, -0.8877,  ..., -0.6716,  0.5649, -0.3137],\n",
            "        [ 0.6940,  0.9979,  0.8801,  ...,  0.8338, -0.8500, -0.4899],\n",
            "        [ 0.7062,  0.9994,  0.9304,  ...,  0.8340, -0.7243, -0.4590]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6397,  0.9999,  0.8871,  ...,  0.8435, -0.7295, -0.4805],\n",
            "        [-0.0704,  0.9971, -0.8879,  ..., -0.7955,  0.2349,  0.2478],\n",
            "        [ 0.4556,  0.9992,  0.8941,  ...,  0.8831, -0.7663, -0.3046],\n",
            "        ...,\n",
            "        [ 0.8248,  1.0000,  0.8589,  ...,  0.8113, -0.6479, -0.2452],\n",
            "        [-0.3413,  0.7350, -0.9267,  ..., -0.9289,  0.2089,  0.5139],\n",
            "        [-0.4983, -0.6725, -0.9306,  ..., -0.9116,  0.2276,  0.4833]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.7237, -0.9965, -0.9106,  ..., -0.9135, -0.2837,  0.7343],\n",
            "        [-0.4144,  0.9407, -0.9014,  ..., -0.9180,  0.3638,  0.5361],\n",
            "        [ 0.4080,  0.9944,  0.8484,  ...,  0.9130, -0.8967, -0.3186],\n",
            "        ...,\n",
            "        [-0.3906, -0.9086, -0.9150,  ..., -0.9009,  0.0733,  0.3666],\n",
            "        [ 0.6370,  0.9982,  0.9290,  ...,  0.8288, -0.7776, -0.5897],\n",
            "        [ 0.3929,  0.9953,  0.7825,  ...,  0.8749, -0.7635,  0.1728]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6081,  0.9997,  0.9383,  ...,  0.8182, -0.5430, -0.4140],\n",
            "        [ 0.6964,  0.9995,  0.7586,  ...,  0.8876, -0.8228, -0.3761],\n",
            "        [ 0.7546,  0.9958,  0.7252,  ...,  0.8629, -0.8525, -0.2401],\n",
            "        ...,\n",
            "        [-0.6749,  0.0674, -0.9373,  ..., -0.9019,  0.3481,  0.7651],\n",
            "        [-0.0296,  0.9894, -0.9216,  ..., -0.8132,  0.5447, -0.0319],\n",
            "        [ 0.7417,  0.9994,  0.9069,  ...,  0.8891, -0.7799, -0.3462]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6440, -0.4468, -0.9691,  ..., -0.8745, -0.0556,  0.6184],\n",
            "        [-0.4056, -0.9325, -0.9589,  ..., -0.8986,  0.3950,  0.6481],\n",
            "        [ 0.6050,  0.9994,  0.8880,  ...,  0.8065, -0.5865, -0.4539],\n",
            "        ...,\n",
            "        [ 0.6970,  0.9993,  0.8451,  ...,  0.9189, -0.7936, -0.2636],\n",
            "        [-0.6285,  0.9861, -0.9124,  ..., -0.8851,  0.0700,  0.6172],\n",
            "        [-0.4398,  0.3958, -0.8874,  ..., -0.8561,  0.5913,  0.5346]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4096,  0.9676, -0.8984,  ..., -0.9394,  0.2511,  0.4742],\n",
            "        [ 0.8420,  0.9999,  0.8189,  ...,  0.7463, -0.4089, -0.6429],\n",
            "        [-0.3247,  0.9988, -0.8582,  ..., -0.8371,  0.6738, -0.0490],\n",
            "        ...,\n",
            "        [ 0.4683,  0.9968,  0.7951,  ...,  0.8000, -0.8600, -0.2703],\n",
            "        [ 0.4062,  0.9996,  0.8676,  ...,  0.8643, -0.5882, -0.7080],\n",
            "        [ 0.5854,  0.9996,  0.8781,  ...,  0.7897, -0.7837, -0.3297]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4289,  0.9979,  0.8438,  ...,  0.8891, -0.8567, -0.2810],\n",
            "        [ 0.5660,  0.9997,  0.7215,  ...,  0.7782, -0.7473, -0.4194],\n",
            "        [ 0.6277,  0.9976,  0.8415,  ...,  0.8449, -0.8931,  0.0336],\n",
            "        ...,\n",
            "        [-0.6595,  0.7685, -0.9260,  ..., -0.8804, -0.0843,  0.4973],\n",
            "        [-0.4395,  0.9763, -0.8458,  ..., -0.8638,  0.5697,  0.0244],\n",
            "        [-0.3437,  0.9992, -0.8830,  ..., -0.9188,  0.5451,  0.0980]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4224, -0.9572, -0.9600,  ..., -0.9266,  0.1986,  0.4096],\n",
            "        [-0.2653,  0.9991, -0.7347,  ..., -0.8527,  0.2171, -0.6021],\n",
            "        [ 0.5703,  0.9911,  0.7707,  ...,  0.8366, -0.8114, -0.3285],\n",
            "        ...,\n",
            "        [ 0.6724,  0.9864,  0.8892,  ...,  0.8947, -0.7473, -0.2677],\n",
            "        [ 0.5094,  0.9988,  0.8146,  ...,  0.8906, -0.7431, -0.2426],\n",
            "        [ 0.2372,  0.9999,  0.9110,  ...,  0.5210, -0.4768, -0.4150]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2958,  0.9999,  0.8447,  ...,  0.2917,  0.1704, -0.8607],\n",
            "        [ 0.7357,  0.9990,  0.8772,  ...,  0.8628, -0.7622, -0.0161],\n",
            "        [ 0.7047,  1.0000,  0.9373,  ...,  0.9199, -0.5423, -0.7978],\n",
            "        ...,\n",
            "        [-0.4630,  0.6000, -0.9172,  ..., -0.9525,  0.2790,  0.1453],\n",
            "        [ 0.3197,  0.9890,  0.7263,  ...,  0.9227, -0.8716, -0.1525],\n",
            "        [-0.4355, -0.9020, -0.9642,  ..., -0.9122,  0.2122,  0.6673]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6166,  0.9982,  0.9192,  ...,  0.9063, -0.8589, -0.2273],\n",
            "        [-0.4209, -0.9797, -0.9473,  ..., -0.8887,  0.1043,  0.3825],\n",
            "        [ 0.5225,  1.0000, -0.7219,  ..., -0.8937,  0.8652, -0.7324],\n",
            "        ...,\n",
            "        [ 0.5544,  1.0000,  0.9353,  ...,  0.6046, -0.4525, -0.8130],\n",
            "        [ 0.6491,  0.9998,  0.9207,  ...,  0.8413, -0.6497, -0.6911],\n",
            "        [ 0.4440,  0.9996,  0.8198,  ...,  0.8843, -0.7026, -0.0885]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.8455,  1.0000,  0.9068,  ...,  0.7399, -0.7521, -0.6233],\n",
            "        [ 0.2614,  0.9999, -0.2139,  ..., -0.4269,  0.3010, -0.3776],\n",
            "        [-0.2489, -0.9674, -0.9190,  ..., -0.8277,  0.4897,  0.2900],\n",
            "        ...,\n",
            "        [ 0.5396,  0.9875,  0.7148,  ...,  0.8627, -0.8294,  0.0636],\n",
            "        [ 0.7706,  0.9989,  0.7853,  ...,  0.8225, -0.8494, -0.7225],\n",
            "        [ 0.7467,  0.9997,  0.9041,  ...,  0.8617, -0.7792, -0.2739]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7070,  0.9996,  0.8669,  ...,  0.8530, -0.7630, -0.4778],\n",
            "        [ 0.5292,  0.9994,  0.7941,  ...,  0.7468, -0.8499, -0.4267],\n",
            "        [ 0.6145,  0.9999,  0.7777,  ...,  0.7714, -0.8524, -0.4584],\n",
            "        ...,\n",
            "        [ 0.4345,  0.9999, -0.7435,  ..., -0.6928,  0.4741, -0.6764],\n",
            "        [-0.4731, -0.9466, -0.9530,  ..., -0.9634,  0.0879,  0.5203],\n",
            "        [-0.3978, -0.9803, -0.9359,  ..., -0.8982,  0.0969,  0.5050]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5868,  1.0000,  0.6813,  ...,  0.7973, -0.4850, -0.5466],\n",
            "        [ 0.5344,  0.9997,  0.9440,  ...,  0.7387, -0.5732, -0.7493],\n",
            "        [ 0.4021,  1.0000,  0.8788,  ...,  0.8258, -0.6381, -0.6867],\n",
            "        ...,\n",
            "        [-0.3321, -0.8537, -0.9377,  ..., -0.8852, -0.1315,  0.5593],\n",
            "        [ 0.5582,  0.9997,  0.4861,  ...,  0.7820, -0.6623, -0.4497],\n",
            "        [-0.5678, -0.9424, -0.9519,  ..., -0.9523,  0.4539,  0.4839]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6815,  0.9995,  0.8863,  ...,  0.8948, -0.7704, -0.4301],\n",
            "        [ 0.8906,  1.0000,  0.9528,  ...,  0.4632,  0.1873, -0.8961],\n",
            "        [-0.5264, -0.9627, -0.9296,  ..., -0.8896,  0.3108,  0.5636],\n",
            "        ...,\n",
            "        [ 0.6179,  0.9998,  0.8463,  ...,  0.8337, -0.8194, -0.2057],\n",
            "        [-0.6243, -0.0061, -0.9276,  ..., -0.9007, -0.2553,  0.4454],\n",
            "        [ 0.4059,  0.9998,  0.7987,  ...,  0.5966, -0.7218, -0.5828]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4902, -0.9807, -0.9390,  ..., -0.7863,  0.2393,  0.5214],\n",
            "        [ 0.5420,  0.9985,  0.7431,  ...,  0.8561, -0.7969, -0.1931],\n",
            "        [ 0.5804,  0.9999,  0.9549,  ...,  0.8036, -0.5043, -0.6324],\n",
            "        ...,\n",
            "        [ 0.5246,  0.9997,  0.6987,  ...,  0.8639, -0.8467, -0.3612],\n",
            "        [-0.5198,  0.5750, -0.6672,  ..., -0.9223,  0.0865,  0.1045],\n",
            "        [-0.5942,  0.7488, -0.9305,  ..., -0.8721,  0.3704,  0.2624]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6331,  0.9992,  0.7926,  ...,  0.8550, -0.8354, -0.2205],\n",
            "        [ 0.5671,  0.9995,  0.8763,  ...,  0.9114, -0.6839, -0.2396],\n",
            "        [-0.4894, -0.9991, -0.9373,  ..., -0.8887,  0.1401,  0.5911],\n",
            "        ...,\n",
            "        [-0.6877, -0.6850, -0.9495,  ..., -0.9171,  0.0791,  0.5459],\n",
            "        [ 0.7096,  1.0000,  0.7805,  ...,  0.7167, -0.7169, -0.7429],\n",
            "        [-0.1580, -0.3554, -0.9005,  ..., -0.8333,  0.3998,  0.5404]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6042, -0.9917, -0.9585,  ..., -0.9381,  0.2017,  0.4868],\n",
            "        [ 0.7096,  0.9879,  0.8478,  ...,  0.8498, -0.8696, -0.2938],\n",
            "        [-0.5130, -0.9818, -0.9352,  ..., -0.8740,  0.3683,  0.5392],\n",
            "        ...,\n",
            "        [ 0.5205,  0.9988,  0.8647,  ...,  0.9008, -0.7921, -0.5440],\n",
            "        [ 0.3356,  0.9998,  0.8607,  ...,  0.8842, -0.8565, -0.4076],\n",
            "        [ 0.5633,  0.9997,  0.8469,  ...,  0.8615, -0.6411, -0.4085]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5378, -0.9222, -0.9326,  ..., -0.8388,  0.2759,  0.5780],\n",
            "        [ 0.6814,  0.9903,  0.8077,  ...,  0.8838, -0.8261, -0.0578],\n",
            "        [ 0.5954,  0.9999,  0.6401,  ...,  0.4044, -0.6132, -0.7865],\n",
            "        ...,\n",
            "        [ 0.5084,  0.9969,  0.8406,  ...,  0.8476, -0.7457, -0.5065],\n",
            "        [-0.3822, -0.9914, -0.8950,  ..., -0.7623,  0.1398,  0.7185],\n",
            "        [-0.3193,  0.2492, -0.9195,  ..., -0.9093,  0.1924,  0.3737]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.8571, -0.9978, -0.8358,  ..., -0.9057,  0.1851,  0.3881],\n",
            "        [ 0.6755,  0.9990,  0.7010,  ...,  0.8621, -0.7803, -0.5619],\n",
            "        [ 0.7416,  1.0000,  0.8356,  ...,  0.7790, -0.7154, -0.5614],\n",
            "        ...,\n",
            "        [ 0.8008,  0.9988,  0.6295,  ...,  0.8005, -0.6859, -0.5037],\n",
            "        [ 0.6022,  0.9990,  0.7453,  ...,  0.8176, -0.8929, -0.3802],\n",
            "        [ 0.6007,  0.9983,  0.9211,  ...,  0.8168, -0.8471, -0.5840]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6888,  0.5363, -0.7649,  ..., -0.7234, -0.0104,  0.7544],\n",
            "        [ 0.3597,  0.9987,  0.7851,  ...,  0.8265, -0.7480,  0.0317],\n",
            "        [-0.3879, -0.6147, -0.9131,  ..., -0.8618,  0.4847, -0.0064],\n",
            "        ...,\n",
            "        [-0.6978,  0.0025, -0.9218,  ..., -0.9094,  0.1802,  0.5500],\n",
            "        [-0.6566, -0.9947, -0.9650,  ..., -0.9142,  0.0263,  0.6159],\n",
            "        [-0.2177,  0.2277, -0.8881,  ..., -0.8487,  0.0186,  0.4581]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6252,  0.9992,  0.6984,  ...,  0.8146, -0.5091, -0.0105],\n",
            "        [-0.6610, -0.9768, -0.9274,  ..., -0.9320,  0.5821,  0.6374],\n",
            "        [-0.7300, -0.3758, -0.9492,  ..., -0.8975,  0.1647,  0.5671],\n",
            "        ...,\n",
            "        [-0.6383, -0.9753, -0.9389,  ..., -0.9207,  0.4493,  0.4643],\n",
            "        [ 0.5323,  0.9947,  0.7487,  ...,  0.8821, -0.8362, -0.0867],\n",
            "        [ 0.7030,  0.9991,  0.7929,  ...,  0.8980, -0.8328,  0.0809]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7964,  0.9992,  0.8728,  ...,  0.8619, -0.8118, -0.3992],\n",
            "        [ 0.4677,  0.9957,  0.7712,  ...,  0.8116, -0.8559, -0.3336],\n",
            "        [-0.4008, -0.7499, -0.8998,  ..., -0.8723,  0.7110,  0.3792],\n",
            "        ...,\n",
            "        [ 0.7743,  0.9970,  0.6279,  ...,  0.8405, -0.7741, -0.3181],\n",
            "        [-0.4875, -0.7273, -0.9453,  ..., -0.9167,  0.1454,  0.7094],\n",
            "        [-0.3877, -0.8352, -0.9126,  ..., -0.8644,  0.4243,  0.3757]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5222, -0.8659, -0.9456,  ..., -0.8998,  0.1798,  0.5528],\n",
            "        [ 0.7095,  0.9916,  0.8409,  ...,  0.8534, -0.7959, -0.1908],\n",
            "        [ 0.2967,  0.9967,  0.6873,  ...,  0.8572, -0.8588, -0.0847],\n",
            "        ...,\n",
            "        [ 0.7812,  1.0000,  0.8330,  ...,  0.8177, -0.5370, -0.7200],\n",
            "        [ 0.5500,  1.0000,  0.8694,  ...,  0.6062, -0.5617, -0.7078],\n",
            "        [-0.5782, -0.9642, -0.9475,  ..., -0.8980,  0.0597,  0.6077]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6203,  0.9936,  0.8108,  ...,  0.8182, -0.5606, -0.1513],\n",
            "        [ 0.4821,  1.0000,  0.9112,  ...,  0.4851, -0.2495, -0.7465],\n",
            "        [-0.2634,  0.9975, -0.9174,  ..., -0.8652,  0.5909,  0.2044],\n",
            "        ...,\n",
            "        [-0.5284, -0.9862, -0.9404,  ..., -0.9044, -0.0475,  0.5779],\n",
            "        [-0.5831, -0.9722, -0.9227,  ..., -0.8834, -0.0934,  0.5038],\n",
            "        [-0.5406, -0.9989, -0.9614,  ..., -0.9594,  0.1227,  0.6029]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6712,  0.9995,  0.9054,  ...,  0.8638, -0.8536, -0.5344],\n",
            "        [-0.3784,  0.1338, -0.9302,  ..., -0.9267,  0.2133,  0.5293],\n",
            "        [ 0.3363,  0.9957,  0.8677,  ...,  0.8135, -0.8250, -0.3717],\n",
            "        ...,\n",
            "        [ 0.7184,  0.9987,  0.7987,  ...,  0.5640, -0.5246, -0.2828],\n",
            "        [-0.6403, -0.9641, -0.9397,  ..., -0.9122, -0.0804,  0.6261],\n",
            "        [ 0.6626,  0.9999,  0.7441,  ...,  0.8883, -0.6940, -0.5079]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6666,  0.9960,  0.7632,  ...,  0.8699, -0.8062, -0.2984],\n",
            "        [ 0.6142,  0.9995,  0.7761,  ...,  0.8369, -0.8356, -0.2664],\n",
            "        [ 0.6856,  0.9999,  0.8907,  ...,  0.8039, -0.8413, -0.4206],\n",
            "        ...,\n",
            "        [ 0.5554,  1.0000,  0.7321,  ...,  0.8334, -0.7903, -0.3864],\n",
            "        [ 0.5317,  0.9946,  0.8152,  ...,  0.8500, -0.8285, -0.1564],\n",
            "        [-0.6306, -0.7069, -0.9542,  ..., -0.8627, -0.1533,  0.7948]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0211,  0.9941, -0.7549,  ..., -0.8008, -0.2534, -0.2160],\n",
            "        [ 0.6552,  0.9997,  0.8783,  ...,  0.8665, -0.7615, -0.4147],\n",
            "        [-0.2930, -0.9828, -0.9575,  ..., -0.9150,  0.1258,  0.4189],\n",
            "        ...,\n",
            "        [-0.6165, -0.7539, -0.9177,  ..., -0.9441, -0.1078,  0.4622],\n",
            "        [ 0.7446,  1.0000,  0.8902,  ...,  0.6677, -0.6467, -0.8242],\n",
            "        [ 0.3227,  1.0000,  0.9137,  ...,  0.1987, -0.1675, -0.9794]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1070, -0.2659, -0.8549,  ..., -0.8633,  0.4585, -0.2377],\n",
            "        [-0.5502, -0.7918, -0.9072,  ..., -0.8556,  0.2262,  0.5187],\n",
            "        [ 0.4791,  0.9957,  0.8991,  ...,  0.8709, -0.8639, -0.2423],\n",
            "        ...,\n",
            "        [-0.5476, -0.9889, -0.9686,  ..., -0.8975,  0.3178,  0.5568],\n",
            "        [ 0.6531,  1.0000,  0.8836,  ...,  0.7347, -0.4529, -0.8150],\n",
            "        [-0.2936, -0.9727, -0.9647,  ..., -0.9167,  0.2266,  0.4128]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3889,  1.0000,  0.8056,  ...,  0.2489,  0.3168, -0.7745],\n",
            "        [-0.2736, -0.1350, -0.8572,  ..., -0.9085,  0.4068,  0.4395],\n",
            "        [ 0.7028,  0.9996,  0.8777,  ...,  0.8387, -0.6771, -0.5221],\n",
            "        ...,\n",
            "        [ 0.5119,  1.0000,  0.8156,  ...,  0.7806, -0.6281, -0.4927],\n",
            "        [ 0.6204,  0.9999,  0.9320,  ...,  0.3613, -0.4559, -0.8391],\n",
            "        [ 0.5106,  0.9999,  0.7846,  ...,  0.5171, -0.8557, -0.7211]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7676,  0.9998,  0.6958,  ...,  0.7194, -0.5033, -0.7293],\n",
            "        [-0.6764, -0.9906, -0.9096,  ..., -0.9000, -0.0066,  0.6782],\n",
            "        [-0.7028,  0.3006, -0.9549,  ..., -0.9185, -0.0384,  0.6913],\n",
            "        ...,\n",
            "        [-0.0885,  0.9990, -0.7962,  ..., -0.7996,  0.5851, -0.1123],\n",
            "        [-0.3152, -0.9799, -0.9166,  ..., -0.8010,  0.1315,  0.6000],\n",
            "        [-0.6108, -0.0816, -0.8902,  ..., -0.9442,  0.2777,  0.1585]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1742,  0.9998, -0.7870,  ..., -0.8012,  0.1614, -0.7040],\n",
            "        [-0.6689, -0.9945, -0.9522,  ..., -0.8754,  0.5153,  0.6792],\n",
            "        [ 0.1858,  0.9994, -0.6291,  ..., -0.8542,  0.4539, -0.0034],\n",
            "        ...,\n",
            "        [ 0.7982,  1.0000,  0.7100,  ...,  0.6896, -0.5364, -0.3026],\n",
            "        [ 0.5000,  0.9985,  0.8112,  ...,  0.7101, -0.7163, -0.1738],\n",
            "        [-0.4071, -0.2446, -0.9315,  ..., -0.9325,  0.0479,  0.3846]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5468,  1.0000,  0.7299,  ...,  0.6730, -0.7393, -0.5372],\n",
            "        [-0.8120, -0.9676, -0.9280,  ..., -0.8570,  0.1705,  0.7956],\n",
            "        [ 0.6781,  0.9976,  0.8691,  ...,  0.5255, -0.5633, -0.6603],\n",
            "        ...,\n",
            "        [ 0.3522,  0.9417,  0.7054,  ...,  0.8569, -0.7848, -0.1555],\n",
            "        [-0.3392, -0.9893, -0.9242,  ..., -0.8658,  0.3897,  0.4455],\n",
            "        [ 0.4772,  0.9954,  0.8744,  ...,  0.8685, -0.6835, -0.3707]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5123,  0.9998,  0.8405,  ...,  0.8247, -0.7142, -0.4173],\n",
            "        [-0.5441, -0.6337, -0.9307,  ..., -0.8840,  0.4857, -0.1487],\n",
            "        [ 0.7975,  0.9999,  0.8470,  ...,  0.8877, -0.6683, -0.2618],\n",
            "        ...,\n",
            "        [ 0.7372,  1.0000,  0.9441,  ...,  0.6563, -0.4692, -0.5227],\n",
            "        [-0.5402, -0.8032, -0.9519,  ..., -0.9226,  0.2069,  0.5557],\n",
            "        [-0.3694, -0.4566, -0.8073,  ..., -0.9078,  0.2453,  0.5601]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5512,  0.9984,  0.7402,  ...,  0.7806, -0.4971, -0.5114],\n",
            "        [ 0.5404,  0.9998,  0.8644,  ...,  0.8707, -0.8492, -0.3034],\n",
            "        [-0.4765, -0.9426, -0.9137,  ..., -0.9264,  0.2595,  0.5611],\n",
            "        ...,\n",
            "        [-0.4600, -0.4418, -0.9659,  ..., -0.9242,  0.2095,  0.4843],\n",
            "        [-0.5946, -0.4445, -0.9274,  ..., -0.7795, -0.0953,  0.7095],\n",
            "        [ 0.6092,  1.0000,  0.7921,  ...,  0.7988, -0.5212, -0.6692]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4757,  0.9999,  0.9442,  ...,  0.9024, -0.5016, -0.4399],\n",
            "        [-0.3542, -0.8949, -0.9369,  ..., -0.9003,  0.3871,  0.5608],\n",
            "        [-0.4779, -0.4497, -0.8805,  ..., -0.9428,  0.3650,  0.7714],\n",
            "        ...,\n",
            "        [ 0.5624,  0.9994,  0.6530,  ...,  0.8259, -0.8273, -0.6165],\n",
            "        [ 0.6743,  0.9999,  0.8862,  ...,  0.7873, -0.4643, -0.6678],\n",
            "        [ 0.5457,  0.9996,  0.8860,  ...,  0.7569, -0.8063, -0.5603]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5924,  0.9984,  0.7972,  ...,  0.9049, -0.8085, -0.4391],\n",
            "        [ 0.3143,  1.0000,  0.7118,  ...,  0.1660, -0.2032, -0.8134],\n",
            "        [-0.7167, -0.9983, -0.9460,  ..., -0.9272,  0.1247,  0.5312],\n",
            "        ...,\n",
            "        [-0.3192,  0.9947, -0.9267,  ..., -0.8859,  0.4725,  0.2105],\n",
            "        [ 0.8223,  0.9998,  0.8361,  ...,  0.9038, -0.7195, -0.4832],\n",
            "        [ 0.5691,  1.0000,  0.8876,  ...,  0.8881, -0.3089, -0.8064]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6083, -0.0304, -0.9083,  ..., -0.9183,  0.3832,  0.2932],\n",
            "        [ 0.8657,  1.0000,  0.8156,  ...,  0.7243, -0.6101, -0.8032],\n",
            "        [-0.6584, -0.9613, -0.9136,  ..., -0.8625,  0.3044,  0.7518],\n",
            "        ...,\n",
            "        [ 0.6252,  1.0000,  0.9086,  ...,  0.8687, -0.5906, -0.6185],\n",
            "        [ 0.5760,  0.9996,  0.8219,  ...,  0.7724, -0.7881, -0.3929],\n",
            "        [ 0.5170,  0.9984,  0.5854,  ...,  0.6731, -0.7496, -0.3226]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4651,  0.6981, -0.7998,  ..., -0.8265,  0.1667, -0.0409],\n",
            "        [ 0.5549,  0.9992,  0.8162,  ...,  0.7641, -0.7472, -0.3658],\n",
            "        [-0.5367, -0.8287, -0.9603,  ..., -0.8409,  0.4388,  0.4164],\n",
            "        ...,\n",
            "        [ 0.7018,  0.9998,  0.8539,  ...,  0.9332, -0.6193, -0.3594],\n",
            "        [ 0.5719,  1.0000,  0.7154,  ...,  0.4928, -0.5548, -0.8514],\n",
            "        [-0.7013, -0.2805, -0.9445,  ..., -0.8872, -0.0754,  0.5226]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7553,  0.9997,  0.9173,  ...,  0.8904, -0.7564, -0.4303],\n",
            "        [ 0.3751,  1.0000,  0.7521,  ...,  0.2672,  0.5618, -0.8508],\n",
            "        [-0.6567,  0.5426, -0.9386,  ..., -0.9239,  0.2927,  0.4188],\n",
            "        ...,\n",
            "        [-0.7104, -0.9988, -0.9308,  ..., -0.8657,  0.2292,  0.7623],\n",
            "        [ 0.6720,  1.0000,  0.8273,  ...,  0.8316, -0.7507, -0.1632],\n",
            "        [-0.4855,  0.2372, -0.9515,  ..., -0.9306,  0.2175,  0.1831]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7872,  0.9995,  0.8756,  ...,  0.9184, -0.7224, -0.4714],\n",
            "        [ 0.6850,  0.9996,  0.8701,  ...,  0.8655, -0.7950, -0.2707],\n",
            "        [ 0.6957,  0.9998,  0.9131,  ...,  0.5807, -0.6909, -0.8188],\n",
            "        ...,\n",
            "        [-0.5581, -0.9921, -0.9197,  ..., -0.8890,  0.5780,  0.4052],\n",
            "        [-0.6047, -0.8576, -0.8865,  ..., -0.9439,  0.2855,  0.2854],\n",
            "        [ 0.6947,  0.9998,  0.8854,  ...,  0.8743, -0.4653, -0.6067]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7824,  1.0000, -0.3217,  ..., -0.8577,  0.5614, -0.7976],\n",
            "        [-0.6071, -0.5236, -0.8965,  ..., -0.9031, -0.0145,  0.5869],\n",
            "        [-0.2725,  0.7888, -0.8834,  ..., -0.8535,  0.1208,  0.0523],\n",
            "        ...,\n",
            "        [-0.5885, -0.9932, -0.9527,  ..., -0.8842,  0.4670,  0.5996],\n",
            "        [ 0.5607,  0.9996,  0.7587,  ...,  0.8441, -0.7134, -0.6824],\n",
            "        [-0.6843, -0.6485, -0.9208,  ..., -0.7736,  0.2628,  0.6806]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6900,  1.0000,  0.8423,  ...,  0.8995, -0.7545, -0.5843],\n",
            "        [ 0.6407,  0.9991,  0.8311,  ...,  0.8008, -0.8119, -0.6094],\n",
            "        [-0.4495,  0.8433, -0.9072,  ..., -0.8582, -0.0514,  0.4004],\n",
            "        ...,\n",
            "        [ 0.6129,  0.9998,  0.9034,  ...,  0.9161, -0.7306, -0.5682],\n",
            "        [ 0.7929,  0.9999,  0.8378,  ...,  0.9106, -0.7527, -0.2726],\n",
            "        [ 0.6483,  0.9998,  0.8751,  ...,  0.8551, -0.8362, -0.4441]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6587,  0.9999,  0.9222,  ...,  0.8833, -0.6595, -0.4402],\n",
            "        [-0.2144,  0.9839, -0.7954,  ..., -0.8420,  0.3092,  0.0381],\n",
            "        [ 0.4718,  0.9994,  0.7588,  ...,  0.9149, -0.6764, -0.2929],\n",
            "        ...,\n",
            "        [ 0.6832,  1.0000,  0.9190,  ...,  0.7743, -0.3701, -0.7807],\n",
            "        [ 0.6693,  1.0000,  0.8828,  ..., -0.0411, -0.4415, -0.8753],\n",
            "        [-0.1744, -0.5264, -0.8827,  ..., -0.8634,  0.3937, -0.0227]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6170, -0.8381, -0.9522,  ..., -0.8390, -0.1246,  0.8279],\n",
            "        [ 0.7072,  1.0000,  0.9001,  ...,  0.7836, -0.4931, -0.4940],\n",
            "        [-0.1802,  1.0000,  0.4997,  ..., -0.3830,  0.1722, -0.9169],\n",
            "        ...,\n",
            "        [ 0.4423,  0.9996,  0.8676,  ...,  0.8521, -0.7848, -0.0552],\n",
            "        [ 0.2571,  1.0000,  0.7061,  ...,  0.3154,  0.7528, -0.7701],\n",
            "        [ 0.6100,  0.9992,  0.8390,  ...,  0.8960, -0.8516, -0.4700]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4678, -0.8657, -0.7400,  ..., -0.5902,  0.5078, -0.4736],\n",
            "        [-0.2448,  0.5008, -0.9193,  ..., -0.9423,  0.4462,  0.5395],\n",
            "        [-0.1852, -0.5902, -0.9596,  ..., -0.9071,  0.3115,  0.5627],\n",
            "        ...,\n",
            "        [-0.2238,  0.9722, -0.8001,  ..., -0.8106,  0.5952,  0.2544],\n",
            "        [-0.4485,  0.0553, -0.9464,  ..., -0.8917,  0.3189,  0.4490],\n",
            "        [-0.3728, -0.9903, -0.9426,  ..., -0.9147,  0.3001,  0.6046]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7370,  0.9926,  0.8796,  ...,  0.7854, -0.7355, -0.5297],\n",
            "        [-0.4228, -0.8089, -0.9493,  ..., -0.9414,  0.4010,  0.4731],\n",
            "        [-0.5778, -0.8487, -0.9167,  ..., -0.8252,  0.5885,  0.4930],\n",
            "        ...,\n",
            "        [ 0.3628,  0.9945,  0.3422,  ..., -0.5051,  0.3815, -0.3298],\n",
            "        [-0.5900, -0.7048, -0.9041,  ..., -0.8010,  0.4990,  0.4187],\n",
            "        [ 0.5398,  1.0000,  0.9258,  ...,  0.7266,  0.7328, -0.8722]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4342,  0.6361, -0.8878,  ..., -0.8176,  0.3038,  0.4982],\n",
            "        [ 0.4485,  0.9994,  0.7571,  ...,  0.8535, -0.7457, -0.3868],\n",
            "        [ 0.6942,  0.9955,  0.7643,  ...,  0.7220, -0.7814, -0.3347],\n",
            "        ...,\n",
            "        [-0.4618, -0.0822, -0.9339,  ..., -0.8965,  0.2699,  0.3999],\n",
            "        [-0.6204, -0.8973, -0.8849,  ..., -0.9173, -0.1260,  0.6838],\n",
            "        [-0.3452, -0.3261, -0.9374,  ..., -0.9039,  0.2656,  0.2898]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7770,  1.0000,  0.9659,  ...,  0.8725, -0.3537, -0.7474],\n",
            "        [ 0.6476,  0.9766,  0.8151,  ...,  0.8354, -0.8004, -0.3931],\n",
            "        [ 0.6396,  0.9999,  0.8266,  ...,  0.8786, -0.6507, -0.4885],\n",
            "        ...,\n",
            "        [-0.7415, -0.5420, -0.8984,  ..., -0.8919,  0.1241,  0.6626],\n",
            "        [ 0.5385,  0.9999,  0.8960,  ...,  0.7388, -0.7379, -0.4904],\n",
            "        [ 0.6181,  0.9953,  0.8735,  ...,  0.8781, -0.8000, -0.2467]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1188,  0.9979, -0.9079,  ..., -0.8308,  0.7083,  0.0231],\n",
            "        [ 0.6460,  0.9983,  0.8782,  ...,  0.8578, -0.7557, -0.1668],\n",
            "        [-0.4929,  0.8656, -0.8927,  ..., -0.9576,  0.2871,  0.4360],\n",
            "        ...,\n",
            "        [ 0.6251,  0.9997,  0.8375,  ...,  0.8019, -0.8110, -0.3219],\n",
            "        [ 0.6059,  0.9988,  0.8334,  ...,  0.6056, -0.8675, -0.4608],\n",
            "        [-0.5455, -0.6362, -0.9371,  ..., -0.7331,  0.0253,  0.5806]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3380,  0.9962,  0.9146,  ...,  0.8404, -0.7681, -0.2202],\n",
            "        [ 0.7758,  0.9994,  0.8734,  ...,  0.8639, -0.6966, -0.7091],\n",
            "        [-0.4347, -0.9857, -0.9402,  ..., -0.9187,  0.0345,  0.5267],\n",
            "        ...,\n",
            "        [-0.4940,  0.2935, -0.8876,  ..., -0.6540,  0.1675,  0.2985],\n",
            "        [ 0.6817,  1.0000,  0.9566,  ...,  0.8294, -0.5890, -0.7467],\n",
            "        [-0.7047,  0.8517, -0.9166,  ..., -0.8907,  0.3994,  0.5581]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6562,  0.8778, -0.8920,  ..., -0.8942, -0.1948,  0.4135],\n",
            "        [-0.6068, -0.8348, -0.9327,  ..., -0.8958,  0.2399,  0.7217],\n",
            "        [-0.7251,  0.9169, -0.9352,  ..., -0.8999,  0.3072,  0.8412],\n",
            "        ...,\n",
            "        [ 0.6103,  0.9977,  0.9037,  ...,  0.8518, -0.8329, -0.3463],\n",
            "        [ 0.5701,  0.9998,  0.8368,  ...,  0.8757, -0.7608, -0.7560],\n",
            "        [ 0.7742,  1.0000,  0.9512,  ...,  0.8805, -0.4728, -0.7347]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6564,  0.5199, -0.9337,  ..., -0.8746,  0.1462,  0.7889],\n",
            "        [-0.3966,  0.7358, -0.8538,  ..., -0.8082,  0.2955,  0.0112],\n",
            "        [ 0.5155,  1.0000,  0.9110,  ...,  0.1753,  0.5976, -0.9738],\n",
            "        ...,\n",
            "        [ 0.4352,  0.9987,  0.7221,  ...,  0.8403, -0.7703, -0.1625],\n",
            "        [-0.4399, -0.8860, -0.9572,  ..., -0.8544,  0.1751,  0.3516],\n",
            "        [ 0.5745,  0.9999,  0.8926,  ...,  0.7863, -0.7341, -0.4042]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5060,  0.9996,  0.7047,  ...,  0.8294, -0.8772, -0.2934],\n",
            "        [ 0.6050,  0.9992,  0.8066,  ...,  0.8146, -0.8147, -0.2951],\n",
            "        [ 0.6000,  0.9999,  0.8869,  ...,  0.7973, -0.3669, -0.7609],\n",
            "        ...,\n",
            "        [-0.6315, -0.0109, -0.8451,  ..., -0.8637,  0.2782,  0.4272],\n",
            "        [ 0.7018,  0.9996,  0.9315,  ...,  0.8912, -0.7388, -0.4735],\n",
            "        [-0.3687, -0.6095, -0.9453,  ..., -0.8843,  0.1734,  0.5732]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.8513,  1.0000,  0.9634,  ...,  0.8450, -0.1659, -0.8774],\n",
            "        [ 0.5033,  1.0000,  0.7815,  ...,  0.7943, -0.6327, -0.5791],\n",
            "        [ 0.7125,  0.9999,  0.9084,  ...,  0.8202, -0.7447, -0.8386],\n",
            "        ...,\n",
            "        [ 0.7416,  0.9991,  0.8344,  ...,  0.8983, -0.8435, -0.4127],\n",
            "        [-0.6041, -0.7213, -0.8855,  ..., -0.8085,  0.0082,  0.7256],\n",
            "        [ 0.2723,  1.0000,  0.9126,  ...,  0.2449,  0.5746, -0.8310]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4669,  0.7292, -0.9378,  ..., -0.8456,  0.5330,  0.2675],\n",
            "        [-0.0782,  0.7191, -0.9030,  ..., -0.8557,  0.5778,  0.0288],\n",
            "        [-0.5707, -0.6713, -0.9057,  ..., -0.8284,  0.2783,  0.6390],\n",
            "        ...,\n",
            "        [ 0.6973,  0.9999,  0.9146,  ...,  0.9139, -0.7998, -0.5966],\n",
            "        [ 0.5436,  0.9990,  0.7096,  ...,  0.7987, -0.8407, -0.2579],\n",
            "        [ 0.8025,  0.9996,  0.9376,  ...,  0.9024, -0.8166, -0.5342]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3447, -0.9674, -0.9140,  ..., -0.6398,  0.1518,  0.6915],\n",
            "        [ 0.7534,  1.0000,  0.9245,  ...,  0.9076, -0.2896, -0.8625],\n",
            "        [-0.5827, -0.5627, -0.9694,  ..., -0.9046,  0.0339,  0.5062],\n",
            "        ...,\n",
            "        [-0.4382,  0.9998, -0.7677,  ..., -0.8950,  0.6297, -0.6126],\n",
            "        [-0.3811, -0.9164, -0.9141,  ..., -0.8107,  0.2565,  0.6151],\n",
            "        [ 0.5611,  0.9997,  0.8289,  ...,  0.9166, -0.7178, -0.1035]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6068,  0.9993,  0.9156,  ...,  0.8901, -0.7482, -0.5518],\n",
            "        [ 0.6193,  0.9998,  0.8543,  ...,  0.9032, -0.7172, -0.2875],\n",
            "        [ 0.8594,  1.0000,  0.8790,  ...,  0.8054, -0.4903, -0.7747],\n",
            "        ...,\n",
            "        [-0.5673, -0.6033, -0.9256,  ..., -0.8964,  0.3386,  0.3923],\n",
            "        [ 0.6708,  0.9995,  0.8570,  ...,  0.8505, -0.8074, -0.3650],\n",
            "        [ 0.6659,  0.9981,  0.8780,  ...,  0.8853, -0.7864, -0.2933]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4122, -0.1487, -0.9547,  ..., -0.8640,  0.2798,  0.6383],\n",
            "        [-0.0549, -0.9622, -0.9270,  ..., -0.8632,  0.2840,  0.5817],\n",
            "        [ 0.0449,  0.9975, -0.8619,  ..., -0.9250,  0.6374, -0.6970],\n",
            "        ...,\n",
            "        [-0.7349, -0.9928, -0.9443,  ..., -0.9015,  0.2114,  0.4937],\n",
            "        [ 0.5612,  0.9983,  0.8675,  ...,  0.8466, -0.7495, -0.4557],\n",
            "        [-0.4060, -0.9965, -0.9334,  ..., -0.9127,  0.2233,  0.6803]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4081,  1.0000, -0.0325,  ..., -0.8358,  0.5675, -0.8464],\n",
            "        [ 0.5278,  0.9990,  0.8582,  ...,  0.8804, -0.7967, -0.2132],\n",
            "        [-0.4460, -0.9475, -0.9529,  ..., -0.8374,  0.2297,  0.5793],\n",
            "        ...,\n",
            "        [ 0.6417,  1.0000,  0.9682,  ...,  0.8406, -0.5584, -0.8136],\n",
            "        [-0.4285,  0.8992, -0.9007,  ..., -0.7733,  0.2527,  0.6765],\n",
            "        [ 0.6249,  0.9996,  0.9298,  ...,  0.9084, -0.6108, -0.6012]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5694,  1.0000,  0.7892,  ..., -0.1834,  0.1966, -0.9057],\n",
            "        [ 0.1789,  0.9999,  0.7067,  ..., -0.5962,  0.4354, -0.8916],\n",
            "        [-0.5589, -0.9758, -0.9360,  ..., -0.8964,  0.1646,  0.4144],\n",
            "        ...,\n",
            "        [ 0.5544,  0.9980,  0.9167,  ...,  0.9087, -0.7592, -0.3454],\n",
            "        [-0.6016,  0.5337, -0.9141,  ..., -0.8994,  0.3001,  0.6219],\n",
            "        [ 0.6341,  0.9999,  0.8404,  ...,  0.9124, -0.7195, -0.6900]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6715,  1.0000,  0.8332,  ...,  0.7229, -0.7273, -0.5954],\n",
            "        [ 0.7162,  0.9998,  0.8848,  ...,  0.8539, -0.9131, -0.4185],\n",
            "        [-0.6063, -0.6318, -0.9205,  ..., -0.9472,  0.0200,  0.7320],\n",
            "        ...,\n",
            "        [ 0.4078,  1.0000,  0.6303,  ...,  0.6032,  0.6844, -0.6595],\n",
            "        [ 0.7239,  0.9989,  0.8748,  ...,  0.9021, -0.8093, -0.6146],\n",
            "        [-0.6876, -0.8465, -0.9441,  ..., -0.8673,  0.4594,  0.6639]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.7433, -0.8223, -0.9379,  ..., -0.9319,  0.1690,  0.7032],\n",
            "        [ 0.4963,  1.0000,  0.8097,  ...,  0.8240, -0.7968, -0.5132],\n",
            "        [ 0.6214,  0.9999,  0.9136,  ...,  0.6518, -0.1568, -0.7475],\n",
            "        ...,\n",
            "        [ 0.5552,  0.9995,  0.8827,  ...,  0.8039, -0.7392, -0.7333],\n",
            "        [ 0.5902,  1.0000,  0.8794,  ...,  0.8971, -0.8707, -0.6082],\n",
            "        [-0.6796,  0.8127, -0.8715,  ..., -0.9055,  0.3160,  0.5269]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4330, -0.9999, -0.9295,  ..., -0.9221,  0.0851,  0.6618],\n",
            "        [-0.7481, -0.9995, -0.9571,  ..., -0.9491,  0.4310,  0.6692],\n",
            "        [-0.5877, -0.8563, -0.9263,  ..., -0.8635,  0.5452,  0.6344],\n",
            "        ...,\n",
            "        [-0.7304,  0.7493, -0.9151,  ..., -0.8498,  0.3509,  0.0831],\n",
            "        [-0.6425, -0.8446, -0.9084,  ..., -0.9075, -0.1152,  0.6534],\n",
            "        [-0.5117, -0.8184, -0.9134,  ..., -0.8549,  0.5500,  0.5490]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4224, -0.8176, -0.8600,  ..., -0.8472, -0.0237,  0.5347],\n",
            "        [-0.4058, -0.6911, -0.9084,  ..., -0.8950,  0.1811, -0.0972],\n",
            "        [-0.3518, -0.9916, -0.9244,  ..., -0.9252,  0.1696,  0.5984],\n",
            "        ...,\n",
            "        [ 0.6871,  1.0000,  0.9340,  ...,  0.2651,  0.3333, -0.9829],\n",
            "        [-0.6106, -0.9932, -0.9411,  ..., -0.9101,  0.0692,  0.6463],\n",
            "        [ 0.5935,  1.0000,  0.8879,  ...,  0.2508,  0.3604, -0.9832]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6524, -0.4142, -0.9514,  ..., -0.8878,  0.2501,  0.4114],\n",
            "        [ 0.6874,  0.9998,  0.9249,  ...,  0.8574, -0.7902, -0.4194],\n",
            "        [-0.5927,  0.7785, -0.8868,  ..., -0.8348,  0.0708,  0.5983],\n",
            "        ...,\n",
            "        [-0.1702, -0.8877, -0.9266,  ..., -0.9154,  0.2518,  0.4406],\n",
            "        [ 0.6939,  0.9999,  0.9204,  ...,  0.8180, -0.6832, -0.6813],\n",
            "        [-0.6237, -0.7024, -0.8988,  ..., -0.8853,  0.3746,  0.3880]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4748,  0.2945, -0.9173,  ..., -0.8584,  0.3456,  0.4376],\n",
            "        [ 0.6482,  0.9999,  0.9343,  ...,  0.8335, -0.8097, -0.3910],\n",
            "        [ 0.6851,  0.9999,  0.9254,  ...,  0.9070, -0.8236, -0.3099],\n",
            "        ...,\n",
            "        [-0.5245, -0.3016, -0.9162,  ..., -0.8865, -0.0625,  0.8571],\n",
            "        [-0.5438, -0.9080, -0.9176,  ..., -0.8771, -0.0407,  0.6120],\n",
            "        [ 0.7000,  0.9987,  0.8678,  ...,  0.8649, -0.8452, -0.5438]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4979,  0.7551, -0.9287,  ..., -0.9467,  0.5118,  0.4537],\n",
            "        [-0.5237, -0.9925, -0.9093,  ..., -0.9296,  0.2329,  0.6961],\n",
            "        [ 0.6651,  1.0000, -0.1664,  ..., -0.8040,  0.7372, -0.9677],\n",
            "        ...,\n",
            "        [-0.5940,  0.9978, -0.6533,  ..., -0.5945,  0.2756, -0.1168],\n",
            "        [ 0.5343,  0.9994,  0.7507,  ...,  0.4482, -0.7316, -0.8235],\n",
            "        [ 0.7185,  0.9998,  0.9121,  ...,  0.8890, -0.6621, -0.5006]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7000,  0.9998,  0.8938,  ...,  0.8525, -0.7447, -0.4515],\n",
            "        [ 0.4719,  1.0000, -0.2840,  ..., -0.3151,  0.1785, -0.6657],\n",
            "        [-0.6083,  0.5584, -0.8540,  ..., -0.9113,  0.2187,  0.5940],\n",
            "        ...,\n",
            "        [-0.6289, -0.9730, -0.9339,  ..., -0.8635,  0.1601,  0.7346],\n",
            "        [-0.6383, -0.0459, -0.9292,  ..., -0.7868,  0.6295,  0.3986],\n",
            "        [ 0.7024,  0.9999,  0.9101,  ...,  0.7988, -0.6122, -0.5703]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7765,  0.9991,  0.8965,  ...,  0.8619, -0.8100, -0.3960],\n",
            "        [ 0.5328,  1.0000,  0.9135,  ...,  0.7806, -0.4975, -0.7697],\n",
            "        [ 0.7817,  1.0000,  0.9608,  ...,  0.8257, -0.4488, -0.7843],\n",
            "        ...,\n",
            "        [ 0.7941,  1.0000,  0.9402,  ...,  0.7684,  0.3957, -0.9703],\n",
            "        [ 0.6874,  0.9999,  0.8265,  ...,  0.8018, -0.6948, -0.2784],\n",
            "        [-0.5855, -0.2412, -0.6417,  ..., -0.7148, -0.1222,  0.5191]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4597,  0.9767, -0.9516,  ..., -0.8497,  0.2865,  0.5927],\n",
            "        [ 0.7458,  1.0000,  0.9364,  ...,  0.7008, -0.1676, -0.9185],\n",
            "        [ 0.5579,  1.0000,  0.9063,  ..., -0.0111, -0.0527, -0.9054],\n",
            "        ...,\n",
            "        [ 0.7233,  0.9978,  0.9048,  ...,  0.7663, -0.7584, -0.4205],\n",
            "        [ 0.7106,  1.0000,  0.9451,  ...,  0.8775, -0.5345, -0.7365],\n",
            "        [-0.2443, -0.8600, -0.9565,  ..., -0.7989,  0.3227,  0.4307]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2644,  1.0000,  0.4764,  ...,  0.1309, -0.1707, -0.8265],\n",
            "        [ 0.6787,  0.9998,  0.8513,  ...,  0.8066, -0.7669, -0.6654],\n",
            "        [-0.2607, -0.2872, -0.9650,  ..., -0.9090,  0.2454,  0.6476],\n",
            "        ...,\n",
            "        [-0.4361,  0.1766, -0.9354,  ..., -0.8706,  0.1583,  0.4641],\n",
            "        [ 0.5042,  0.9992,  0.8907,  ...,  0.9057, -0.6364, -0.4956],\n",
            "        [ 0.8973,  0.9999,  0.9380,  ...,  0.8149, -0.3832, -0.7783]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1962,  0.9984, -0.8441,  ..., -0.8372,  0.3101, -0.4566],\n",
            "        [ 0.7377,  0.9999, -0.7025,  ..., -0.5495,  0.4351, -0.6003],\n",
            "        [ 0.1054,  0.9999,  0.9059,  ...,  0.6417, -0.6061, -0.7647],\n",
            "        ...,\n",
            "        [ 0.7685,  0.9999,  0.8967,  ...,  0.8130, -0.5727, -0.6853],\n",
            "        [-0.5962, -0.9203, -0.9407,  ..., -0.9486, -0.1905,  0.5950],\n",
            "        [-0.2089, -0.7750, -0.9036,  ..., -0.7860,  0.1577,  0.2355]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3936, -0.9807, -0.9294,  ..., -0.8427,  0.1510,  0.5270],\n",
            "        [ 0.6165,  0.9999,  0.9421,  ...,  0.8624, -0.5745, -0.7192],\n",
            "        [-0.4818,  0.5662, -0.9216,  ..., -0.9068, -0.2680,  0.5928],\n",
            "        ...,\n",
            "        [ 0.6651,  0.9992,  0.8403,  ...,  0.8743, -0.7371, -0.5649],\n",
            "        [-0.4824, -0.8820, -0.9329,  ..., -0.8966,  0.1771,  0.5321],\n",
            "        [ 0.8012,  1.0000,  0.9381,  ...,  0.8842, -0.5227, -0.7310]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6478,  0.9986,  0.8347,  ...,  0.8850, -0.8140, -0.2210],\n",
            "        [ 0.5065,  0.9990,  0.8590,  ...,  0.8863, -0.7898, -0.2266],\n",
            "        [-0.7481, -0.9933, -0.9607,  ..., -0.9441,  0.2345,  0.8892],\n",
            "        ...,\n",
            "        [-0.6919, -0.9953, -0.9152,  ..., -0.9507, -0.0742,  0.4922],\n",
            "        [-0.6310,  0.8873, -0.8347,  ..., -0.8130, -0.0225,  0.0374],\n",
            "        [-0.3459, -0.2420, -0.9495,  ..., -0.8668,  0.3586,  0.2398]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6621, -0.9814, -0.9421,  ..., -0.9039,  0.3281,  0.7938],\n",
            "        [ 0.7974,  0.9939,  0.7992,  ...,  0.8102, -0.8396, -0.2851],\n",
            "        [ 0.4368,  0.9993,  0.7924,  ...,  0.8965, -0.7764, -0.0129],\n",
            "        ...,\n",
            "        [ 0.6494,  0.9997,  0.8602,  ...,  0.8579, -0.8062, -0.4070],\n",
            "        [ 0.4716,  0.9999,  0.8546,  ...,  0.7767, -0.7327, -0.7130],\n",
            "        [-0.5573, -0.6066, -0.9408,  ..., -0.9025,  0.2056,  0.7562]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5857,  0.9997,  0.8765,  ...,  0.8802, -0.8324, -0.3067],\n",
            "        [ 0.6412,  1.0000,  0.9145,  ...,  0.7270, -0.2278, -0.7634],\n",
            "        [ 0.7165,  1.0000,  0.9603,  ...,  0.7193,  0.1101, -0.9777],\n",
            "        ...,\n",
            "        [ 0.6548,  1.0000,  0.9205,  ...,  0.7545, -0.7481, -0.5493],\n",
            "        [-0.0097,  0.9805, -0.9375,  ..., -0.8483,  0.3251,  0.2159],\n",
            "        [ 0.7007,  0.9998,  0.9253,  ...,  0.9059, -0.7999, -0.4381]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5750, -0.9248, -0.9211,  ..., -0.9191,  0.5515,  0.5533],\n",
            "        [ 0.7728,  0.9996,  0.8553,  ...,  0.8748, -0.7604, -0.5505],\n",
            "        [ 0.4396,  1.0000,  0.8373,  ...,  0.2545,  0.3976, -0.9565],\n",
            "        ...,\n",
            "        [-0.4763, -0.5017, -0.8677,  ..., -0.9104,  0.1765,  0.4042],\n",
            "        [-0.6837, -0.9468, -0.9596,  ..., -0.7991,  0.1947,  0.6470],\n",
            "        [-0.6390, -0.9358, -0.9548,  ..., -0.9315, -0.2960,  0.5566]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2312, -0.6859, -0.8384,  ..., -0.8707, -0.2445,  0.7261],\n",
            "        [-0.3141, -0.8828, -0.9534,  ..., -0.9231,  0.0447,  0.4748],\n",
            "        [ 0.7145,  0.9975,  0.6169,  ...,  0.8375, -0.7540, -0.7063],\n",
            "        ...,\n",
            "        [-0.4513, -0.7071, -0.8100,  ..., -0.7953,  0.2471,  0.3808],\n",
            "        [-0.3547, -0.5141, -0.9074,  ..., -0.8899,  0.2825,  0.6581],\n",
            "        [ 0.7796,  1.0000,  0.8677,  ...,  0.8871, -0.5308, -0.7442]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6945,  0.0512, -0.8884,  ..., -0.7635, -0.0193,  0.8238],\n",
            "        [-0.7507, -0.9191, -0.9240,  ..., -0.8358,  0.4711,  0.3575],\n",
            "        [ 0.6261,  0.9997,  0.8207,  ...,  0.8328, -0.7222, -0.3503],\n",
            "        ...,\n",
            "        [-0.6496,  0.3292, -0.9306,  ..., -0.8854,  0.1997,  0.6080],\n",
            "        [ 0.7380,  0.9999,  0.9264,  ...,  0.9040, -0.7143, -0.6105],\n",
            "        [-0.6277,  0.4134, -0.9298,  ..., -0.8869,  0.1680,  0.7282]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4337, -0.9796, -0.9117,  ..., -0.8940,  0.2841,  0.6635],\n",
            "        [-0.3748,  0.9995, -0.1833,  ..., -0.5244,  0.6440, -0.5542],\n",
            "        [ 0.1424,  0.9785, -0.8749,  ..., -0.9137,  0.3634, -0.1585],\n",
            "        ...,\n",
            "        [ 0.7412,  1.0000,  0.8551,  ...,  0.8556, -0.6558, -0.6545],\n",
            "        [-0.0199,  0.9755, -0.8787,  ..., -0.7636,  0.6959,  0.2414],\n",
            "        [-0.5641,  0.9637, -0.8305,  ..., -0.8234,  0.6012, -0.1237]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluation... :   0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f267748ea5d4da1917de0ceb1af462f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7573,  0.9944,  0.8929,  ...,  0.8772, -0.8054, -0.4004],\n",
            "        [ 0.7848,  1.0000,  0.9641,  ...,  0.7786,  0.1939, -0.9662],\n",
            "        [ 0.8246,  1.0000, -0.0394,  ..., -0.7077,  0.6683, -0.8578],\n",
            "        ...,\n",
            "        [ 0.3859,  0.9994,  0.7983,  ...,  0.8209, -0.7904, -0.2453],\n",
            "        [-0.0564,  0.9865, -0.7072,  ..., -0.8595,  0.5607, -0.1889],\n",
            "        [-0.6940, -0.2959, -0.9169,  ..., -0.7557,  0.2989,  0.6281]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4222,  0.9960, -0.8678,  ..., -0.8885,  0.3816,  0.1913],\n",
            "        [ 0.7101,  1.0000,  0.7276,  ...,  0.4473, -0.7835, -0.3526],\n",
            "        [ 0.1452,  0.9964, -0.0258,  ..., -0.7270,  0.5894, -0.8234],\n",
            "        ...,\n",
            "        [-0.2664,  0.9927, -0.3662,  ..., -0.7255,  0.1976, -0.6935],\n",
            "        [-0.6129,  0.9999, -0.5320,  ..., -0.8739,  0.3508,  0.0036],\n",
            "        [ 0.4302,  1.0000,  0.5779,  ..., -0.7405,  0.6957, -0.9576]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6761,  1.0000,  0.9404,  ...,  0.8515, -0.5849, -0.7576],\n",
            "        [ 0.3483,  1.0000,  0.8039,  ...,  0.4155,  0.6799, -0.8653],\n",
            "        [ 0.5903,  1.0000,  0.8660,  ...,  0.8661, -0.7171, -0.5982],\n",
            "        ...,\n",
            "        [-0.1652,  1.0000,  0.0310,  ..., -0.8903,  0.5616, -0.8160],\n",
            "        [-0.7750, -0.3878, -0.9067,  ..., -0.9214,  0.2586,  0.4827],\n",
            "        [ 0.4669,  1.0000,  0.5946,  ..., -0.0272,  0.2216, -0.9512]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0587,  0.9988,  0.0145,  ..., -0.2339, -0.6203, -0.6989],\n",
            "        [-0.1352,  1.0000,  0.7420,  ..., -0.4552,  0.1895, -0.9565],\n",
            "        [-0.0799,  0.9999, -0.5036,  ..., -0.8226,  0.3959, -0.8498],\n",
            "        ...,\n",
            "        [ 0.7752,  1.0000,  0.9344,  ...,  0.8695, -0.3792, -0.7458],\n",
            "        [-0.1807, -0.3704, -0.8197,  ..., -0.9111,  0.6452, -0.2011],\n",
            "        [ 0.6602,  0.9987,  0.8878,  ...,  0.9038, -0.8508, -0.3646]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6990,  1.0000,  0.7431,  ...,  0.7209, -0.4320, -0.3428],\n",
            "        [ 0.4614,  1.0000,  0.8539,  ...,  0.8773, -0.4655, -0.5668],\n",
            "        [-0.5346,  0.3871, -0.8805,  ..., -0.7548,  0.3666,  0.4936],\n",
            "        ...,\n",
            "        [ 0.5456,  0.9999,  0.5652,  ...,  0.7110, -0.4646, -0.8431],\n",
            "        [ 0.5010,  1.0000,  0.8905,  ...,  0.3838, -0.5172, -0.6478],\n",
            "        [ 0.7591,  0.9998,  0.9573,  ...,  0.5844, -0.3366, -0.7705]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5642,  0.9995,  0.8928,  ...,  0.8903, -0.7906, -0.4646],\n",
            "        [ 0.7778,  1.0000,  0.6515,  ...,  0.5964, -0.5859, -0.8748],\n",
            "        [-0.0846, -0.0220, -0.9648,  ..., -0.9086,  0.6009,  0.1332],\n",
            "        ...,\n",
            "        [ 0.6960,  0.9994, -0.7415,  ..., -0.7583,  0.7152, -0.4343],\n",
            "        [ 0.3046,  1.0000,  0.1244,  ...,  0.1107, -0.3851, -0.6624],\n",
            "        [ 0.0797,  1.0000,  0.4578,  ..., -0.1273, -0.3730, -0.9019]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0625,  0.9826, -0.5764,  ..., -0.7960, -0.2671, -0.5999],\n",
            "        [-0.5734, -0.8125, -0.9489,  ..., -0.9327,  0.0984,  0.7187],\n",
            "        [ 0.6475,  0.9975,  0.8335,  ...,  0.9041, -0.8038, -0.3893],\n",
            "        ...,\n",
            "        [-0.2494,  1.0000, -0.3400,  ..., -0.8014, -0.3566, -0.5094],\n",
            "        [ 0.6454,  0.9991,  0.9273,  ...,  0.9137, -0.8272, -0.4296],\n",
            "        [-0.4206,  0.9043, -0.8533,  ..., -0.8329,  0.0977,  0.4016]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6616,  0.9998,  0.9010,  ...,  0.8961, -0.7717, -0.5207],\n",
            "        [ 0.7240,  0.9998,  0.9406,  ...,  0.9235, -0.7183, -0.6024],\n",
            "        [ 0.6995,  1.0000,  0.9346,  ...,  0.8159,  0.1226, -0.9410],\n",
            "        ...,\n",
            "        [ 0.6207,  0.9961,  0.8980,  ...,  0.8790, -0.8702, -0.2907],\n",
            "        [ 0.4593,  0.9996,  0.7918,  ...,  0.8362, -0.7776, -0.6311],\n",
            "        [ 0.5846,  1.0000,  0.7949,  ...,  0.6208, -0.5699, -0.6541]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.8161,  1.0000,  0.9589,  ...,  0.8506, -0.2265, -0.9021],\n",
            "        [-0.0866,  0.9961, -0.8839,  ..., -0.8340,  0.2611, -0.1497],\n",
            "        [-0.8301, -0.9743, -0.8297,  ..., -0.9093,  0.1167,  0.3268],\n",
            "        ...,\n",
            "        [ 0.6971,  0.9998,  0.8963,  ...,  0.8768, -0.7452, -0.4230],\n",
            "        [-0.6711, -0.7538, -0.9284,  ..., -0.9017,  0.2459,  0.7846],\n",
            "        [ 0.5592,  0.9971,  0.8887,  ...,  0.8637, -0.8090, -0.3109]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5353, -0.6313, -0.9532,  ..., -0.8866,  0.1492,  0.5139],\n",
            "        [ 0.1005,  1.0000,  0.1656,  ..., -0.5982,  0.1179, -0.8239],\n",
            "        [ 0.6557,  0.9998,  0.9266,  ...,  0.8982, -0.7464, -0.6108],\n",
            "        ...,\n",
            "        [ 0.7199,  0.9986,  0.8285,  ...,  0.8962, -0.8400, -0.3417],\n",
            "        [ 0.4922,  0.9999,  0.8644,  ...,  0.7415, -0.5522, -0.3013],\n",
            "        [ 0.7340,  1.0000,  0.9358,  ...,  0.7552,  0.2408, -0.9603]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2068,  0.4967, -0.9031,  ..., -0.8681,  0.3594,  0.3731],\n",
            "        [-0.5325, -0.9600, -0.9199,  ..., -0.9367,  0.1570,  0.5132],\n",
            "        [-0.6857,  0.7233, -0.9671,  ..., -0.9439, -0.0562,  0.3722],\n",
            "        ...,\n",
            "        [ 0.6761,  1.0000,  0.8567,  ...,  0.6925, -0.5900, -0.8284],\n",
            "        [ 0.7218,  1.0000, -0.5142,  ..., -0.5315,  0.5580, -0.8846],\n",
            "        [ 0.5332,  0.9991,  0.9075,  ...,  0.8932, -0.8056, -0.3255]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3559,  1.0000,  0.7470,  ..., -0.1547,  0.1508, -0.8647],\n",
            "        [-0.5150, -0.9073, -0.9549,  ..., -0.9051,  0.2519,  0.6247],\n",
            "        [-0.7075,  0.9186, -0.9263,  ..., -0.9025,  0.2346,  0.1452],\n",
            "        ...,\n",
            "        [-0.5876,  0.9310, -0.9417,  ..., -0.9094,  0.2735,  0.5790],\n",
            "        [ 0.1135,  1.0000,  0.1338,  ..., -0.6307, -0.0195, -0.8099],\n",
            "        [-0.2966,  0.9997, -0.7394,  ..., -0.9146,  0.5032, -0.3521]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1395,  0.9943, -0.7886,  ..., -0.4334,  0.7085,  0.3247],\n",
            "        [ 0.3564,  1.0000,  0.6758,  ...,  0.0746, -0.0484, -0.8864],\n",
            "        [-0.6428, -0.9454, -0.8694,  ..., -0.9129,  0.4225,  0.4530],\n",
            "        ...,\n",
            "        [-0.7480,  0.9903, -0.9302,  ..., -0.7428,  0.5960,  0.3594],\n",
            "        [-0.0757,  0.9961, -0.9279,  ..., -0.8603,  0.4351, -0.2377],\n",
            "        [-0.6427,  1.0000, -0.7492,  ..., -0.8179,  0.4399, -0.6071]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7831,  1.0000,  0.9216,  ...,  0.4682, -0.3481, -0.7664],\n",
            "        [ 0.5948,  1.0000,  0.8085,  ...,  0.2464, -0.1929, -0.8474],\n",
            "        [-0.6686, -0.4582, -0.9357,  ..., -0.8555, -0.1136,  0.5330],\n",
            "        ...,\n",
            "        [ 0.4399,  1.0000,  0.5565,  ..., -0.2323, -0.4078, -0.7376],\n",
            "        [ 0.5124,  1.0000,  0.7912,  ...,  0.8056, -0.3171, -0.6497],\n",
            "        [-0.5617,  0.9922, -0.6154,  ..., -0.7790,  0.1315, -0.4367]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4720,  1.0000,  0.7426, -0.9575, -0.4396,  0.9323,  0.7107,  0.7927,\n",
            "         -0.9976, -0.6089,  0.8101, -0.5701,  0.4251,  0.9992,  0.3841, -0.1206,\n",
            "          0.7225, -0.9739,  0.6842, -0.2587,  0.3024, -0.7835,  0.8248, -0.3888,\n",
            "          0.8088,  0.7381, -0.4996,  0.5542, -0.1967,  0.2721, -0.6238, -0.2438,\n",
            "          0.9339,  0.6440,  0.8074, -0.9416, -0.3270, -0.9565, -0.9842, -0.9971,\n",
            "          0.2061, -0.4339,  0.9996, -0.8267,  0.9960, -0.9901,  0.5309, -0.3483,\n",
            "          0.6081,  0.4533, -0.7215,  0.9368,  0.7833,  0.8491, -0.6237, -0.8470,\n",
            "         -0.8081,  0.4879, -0.8717, -0.4976,  0.7937,  0.7193, -0.5846, -0.0449,\n",
            "         -0.8746, -0.5146,  0.5788,  0.4752, -0.6918, -0.9388,  0.8469, -0.9285,\n",
            "          0.6660,  0.1618, -0.2790,  0.8310, -0.8712,  0.8951, -0.7839,  0.9917,\n",
            "          0.6695,  0.4334,  0.6550, -1.0000,  0.6796, -0.8960,  0.9856, -0.9839,\n",
            "         -0.9609,  0.7042,  0.7965,  0.6653,  0.7872, -0.1104, -0.4214, -0.9057,\n",
            "         -0.6469,  0.5495, -0.9987,  0.7849,  0.6619,  0.7719, -0.6793, -0.6161,\n",
            "         -0.9992,  0.4886, -0.6140, -0.5296, -0.9999, -0.7269, -0.8244, -0.8180,\n",
            "         -0.3271,  0.8947,  0.5309,  0.9997,  0.8671,  0.9984, -1.0000, -0.9935,\n",
            "          0.0695,  0.9365, -0.6358, -0.0475,  0.5732, -0.9689,  0.6242, -0.9982,\n",
            "          0.7091, -0.9343, -0.5194,  0.8119,  0.8878,  0.4590, -0.6354,  0.5535,\n",
            "         -0.9997,  0.0498, -0.7178, -0.9921,  0.9922,  0.8632,  0.8499, -0.4728,\n",
            "         -0.3718,  0.8509,  0.8545, -0.6828,  0.0897, -0.2349, -0.8187,  0.8117,\n",
            "          0.4265, -0.4619, -1.0000,  0.5075, -0.6795,  0.9469, -0.9871,  0.9753,\n",
            "         -0.9732, -1.0000,  0.4078,  0.3341, -0.7746,  0.7944, -0.8078,  0.8899,\n",
            "         -0.5994,  0.6875,  0.6624,  0.6548,  0.3956, -0.5245,  0.3272, -0.7340,\n",
            "          0.7751, -0.7478, -0.6032, -0.9601,  0.9704, -0.4605,  0.9802, -0.9501,\n",
            "         -0.7471,  0.5234,  0.2231, -1.0000,  0.9228,  0.4965,  0.3992,  0.5550,\n",
            "          0.3102, -0.4717,  0.0556,  0.0337, -0.5395,  0.6899, -0.3052,  0.9077,\n",
            "          0.3375, -0.9995,  0.8223,  0.9928,  0.1972, -0.4387,  0.0710,  0.9806,\n",
            "         -0.9969, -0.6722,  0.1878, -0.5360,  0.4604,  0.4293, -0.4670, -0.7562,\n",
            "          0.6528,  0.3150, -0.0933, -0.4687,  0.3231,  0.6029, -0.3477,  0.4386,\n",
            "          0.7538,  0.9992, -0.5206, -0.5681,  0.6169, -0.9996,  0.8214,  0.5209,\n",
            "         -0.3129, -0.6782,  0.9900,  0.7807,  0.6649,  0.9864, -0.9552, -0.2778,\n",
            "         -0.5995,  0.8553, -0.3929, -0.0736,  1.0000, -0.9939,  0.9850,  0.9091,\n",
            "         -0.0038, -0.4073,  0.6529,  0.3127, -0.2559, -0.0349, -0.6539,  0.9931,\n",
            "         -0.6492, -0.9834,  0.5354, -0.1272, -0.9213, -0.8428,  0.8054, -0.5875,\n",
            "          0.9786,  0.9999,  0.7471,  0.5005,  0.7153,  0.5798,  0.7842, -0.9836,\n",
            "          0.9649,  1.0000, -0.9476,  0.3855,  0.9999,  0.6802, -0.2751, -0.5713,\n",
            "          0.3125, -0.9795, -0.2014, -0.5163, -0.4485, -0.5325,  0.0044, -0.9420,\n",
            "         -0.9993, -0.9851,  0.9723, -0.7008, -0.6271,  0.5694, -0.7479,  0.4161,\n",
            "         -0.6779,  0.9910, -0.7403,  0.9999,  0.6397, -0.6575, -0.9634, -0.3394,\n",
            "          0.5662,  0.1399,  0.9991,  0.0783, -0.6630,  0.7692,  0.6667,  0.2816,\n",
            "          0.9290, -0.6246,  0.6503,  0.3959,  0.0906, -0.9544, -0.3561, -0.8514,\n",
            "          0.8062,  0.9670,  0.7083,  0.1877,  0.9637,  0.8263, -1.0000,  0.9990,\n",
            "          0.9790, -0.9923,  0.8243, -0.1477,  0.8914, -0.1606,  0.4751, -0.8880,\n",
            "         -0.8347, -0.9806,  0.7952,  0.2169, -0.6888,  0.3230, -0.9034,  0.8037,\n",
            "          0.1386,  0.8290, -0.2816,  0.0760, -0.9960,  0.6624,  0.8730, -0.1894,\n",
            "          0.7517,  0.9866,  0.0579,  1.0000, -0.7716, -0.3535,  0.1710,  0.6193,\n",
            "          0.4017,  0.5016, -0.2311,  0.4968, -1.0000,  0.2635, -0.5532,  0.3538,\n",
            "          0.6304, -0.9852,  0.4751, -0.4215, -0.0040, -0.1860,  0.2915,  0.5544,\n",
            "          0.9991,  0.4266, -0.4526, -0.7098, -0.0321,  0.0789,  0.9115,  0.6977,\n",
            "          0.9910, -0.8212, -0.2415,  0.6547,  0.0431, -0.6771, -0.0953,  0.6230,\n",
            "          0.0534,  0.9349,  0.7677, -0.4854, -0.5863,  0.8343, -0.9983,  0.9999,\n",
            "          0.3210,  0.5375,  0.9386, -0.3027,  0.7311,  0.4021,  0.3877, -0.7237,\n",
            "          0.9759,  0.7224,  0.6593,  0.1686, -0.0745, -0.1354, -0.9206,  0.5529,\n",
            "          0.3622, -0.5034, -0.9819,  0.9890, -0.9821,  0.3375, -0.2762,  0.8000,\n",
            "          0.9481, -0.4187, -0.8616, -0.2395,  0.3051, -0.7366, -0.8268, -0.9928,\n",
            "         -0.0882, -0.9115,  0.9999, -0.9914,  0.5573, -0.9194, -0.9023,  0.7574,\n",
            "         -0.4231, -0.6091, -0.8225, -0.1250, -0.5244,  0.7977,  0.0193,  0.7386,\n",
            "         -0.4382,  0.2608,  0.7516,  0.1749,  0.3028,  0.9038, -0.6344, -0.9553,\n",
            "         -0.7110, -0.5994, -0.6904,  0.9617, -0.9315, -0.8168,  1.0000, -0.9847,\n",
            "          0.1655, -0.3265, -0.9971,  0.5838, -0.4107, -0.9450, -0.6148, -0.8084,\n",
            "          0.6920,  0.9375,  0.9992,  0.1934,  0.1447, -0.9647, -0.6439,  0.9974,\n",
            "         -0.9679, -0.3936,  0.3386, -0.9955,  0.9330,  0.3570, -0.4780,  0.8442,\n",
            "         -0.6857,  0.9692,  0.5944, -0.9971,  0.6059,  0.7108, -0.2941,  0.8737,\n",
            "          0.2585,  0.1907, -0.9573,  0.0151,  0.9993,  0.4104, -0.8150,  0.1133,\n",
            "          0.8018,  0.7985,  1.0000, -0.9670,  0.6959,  0.9996, -0.3093,  0.5178,\n",
            "          0.2466, -0.7617,  0.0671,  0.5144, -0.9787,  0.9998, -0.0895, -0.9876,\n",
            "         -1.0000,  0.3256, -0.8268,  0.7751,  0.9711,  0.5955,  0.8753,  0.3315,\n",
            "         -0.9984, -0.0329, -0.5914, -0.9998, -0.9994,  0.8500,  0.1229,  0.1901,\n",
            "          0.7798, -0.1001, -0.7512,  0.9996,  0.9003, -0.9999, -0.2335,  0.3138,\n",
            "          0.9663, -0.7446,  0.6455,  0.3525,  0.3993, -0.3669, -1.0000, -0.5184,\n",
            "          0.9731, -0.0338, -0.0250,  0.9995,  0.7142,  0.3666, -0.9456, -0.0183,\n",
            "          0.7025, -1.0000, -0.7068,  0.9998, -0.3360, -0.1097, -0.5511,  0.3156,\n",
            "          0.6086,  0.6264,  0.1823, -0.9968,  0.9951,  0.8717, -0.9128,  0.9967,\n",
            "         -0.5316, -0.7146, -0.7844, -0.6456,  0.7642, -0.7145,  0.5465, -0.2994,\n",
            "          0.9850,  0.8927, -0.4147,  0.7741,  0.9063, -0.8156, -0.3907,  0.7994,\n",
            "          0.6248,  0.4013,  0.9817, -0.4682, -0.7495, -0.4216,  0.6640,  0.9176,\n",
            "         -0.9999,  0.9221, -0.5015, -0.8950,  0.6656, -0.5216, -0.6553, -0.2799,\n",
            "         -0.4366, -0.6760,  0.1817,  0.9520,  0.7517,  0.7866, -0.9865, -0.9999,\n",
            "         -0.6928, -0.5685, -0.8478, -0.4906,  0.2618,  0.9481,  0.2539,  0.5087,\n",
            "          0.3306,  0.9998, -0.4148,  0.9905, -0.8016,  0.9335, -0.9895,  0.5633,\n",
            "          0.5418, -0.9550, -0.5483,  0.9553, -0.3756,  0.8328, -0.9692,  0.6380,\n",
            "          1.0000, -0.7218, -0.6006,  0.7040, -0.8814,  0.7835, -0.0296,  0.9943,\n",
            "         -1.0000,  0.9892, -0.0582,  0.4099,  0.5832,  0.5766,  0.5539, -0.6532,\n",
            "         -0.5245, -0.9898,  0.6178,  0.4171, -0.6613,  0.2902,  0.9232, -0.7897,\n",
            "         -0.9986, -0.6256,  0.4818,  0.9552, -0.4539, -0.9909,  0.9671, -0.2280,\n",
            "          0.9685,  0.1563, -0.7103, -0.4540, -0.2166, -0.5700,  0.5771,  0.6923,\n",
            "          0.8128,  0.3142, -0.8733, -0.4812, -0.0019, -0.7883,  0.7428, -0.3115,\n",
            "         -0.0307,  0.7363,  0.8378,  0.9783,  0.4099,  0.1848,  0.7521, -0.7476,\n",
            "         -0.5906, -0.9997,  0.9991,  0.8603, -0.8480, -0.9997,  0.9384,  0.2507,\n",
            "         -0.3351,  0.7372, -0.1323, -0.7092,  0.2402,  0.7798, -1.0000, -0.4595,\n",
            "          0.1848, -0.4178, -0.6439, -0.9998, -0.5490,  0.1478, -0.2935,  0.2948,\n",
            "          0.9985, -0.4374, -0.9878, -0.9635, -0.0897,  0.6583,  0.2244, -0.9609,\n",
            "         -0.5349,  0.8563, -0.9985,  0.7224, -0.5698, -0.5143,  0.2555,  0.7145,\n",
            "          0.9211, -0.9999,  0.8780, -0.7123,  0.9097, -0.4850,  0.5419,  0.5278,\n",
            "          0.3476, -0.9977,  0.8325,  0.3344,  0.8207,  0.7489,  0.7781, -0.0442,\n",
            "         -0.8717, -0.6828,  0.9842,  0.9749, -0.6562,  0.6816,  0.9988, -0.6380,\n",
            "          0.5820,  0.6263,  0.0716, -0.9992, -0.8403, -0.2389, -0.5870, -0.8304]],\n",
            "       device='cuda:0')\n",
            "Epoch: 8/10...Step: 1000...Train Loss: 0.031416...Train Acc: 0.989...Valid Loss: 1.250418...Valid Acc: 0.707...\n",
            "Validation loss decreased (inf --> 1.250418).  Saving model ...\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6208, -0.9996, -0.8884,  ..., -0.8948,  0.0962,  0.5808],\n",
            "        [ 0.7163,  0.9984,  0.8591,  ...,  0.8672, -0.7578, -0.3129],\n",
            "        [ 0.6539,  1.0000,  0.9634,  ...,  0.7306, -0.0943, -0.9033],\n",
            "        ...,\n",
            "        [-0.5863, -0.3804, -0.9519,  ..., -0.9401,  0.2398,  0.6426],\n",
            "        [ 0.6379,  0.9931,  0.8553,  ...,  0.8918, -0.7673, -0.1000],\n",
            "        [-0.2799, -0.6936, -0.9370,  ..., -0.8635,  0.2028,  0.4605]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4574,  0.9995, -0.7573,  ..., -0.8127,  0.8075, -0.2388],\n",
            "        [ 0.7035,  0.9998,  0.8262,  ...,  0.8784, -0.7468, -0.4497],\n",
            "        [ 0.8037,  1.0000,  0.9248,  ...,  0.8954, -0.3710, -0.8666],\n",
            "        ...,\n",
            "        [ 0.5797,  0.9999,  0.9180,  ...,  0.8288, -0.7267, -0.5813],\n",
            "        [-0.7197, -0.6719, -0.9268,  ..., -0.8805,  0.2825,  0.7473],\n",
            "        [-0.6378,  0.3295, -0.9356,  ..., -0.8409,  0.0425,  0.6346]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7459,  0.9999,  0.7944,  ...,  0.8766, -0.6787, -0.4513],\n",
            "        [ 0.7749,  1.0000,  0.9722,  ...,  0.7993, -0.3493, -0.6998],\n",
            "        [ 0.6817,  1.0000,  0.9333,  ...,  0.7985,  0.0429, -0.9604],\n",
            "        ...,\n",
            "        [ 0.4796,  0.9996,  0.9222,  ...,  0.8800, -0.7833, -0.5129],\n",
            "        [ 0.6467,  0.9959,  0.7649,  ...,  0.8906, -0.8319, -0.0898],\n",
            "        [ 0.7234,  0.9999,  0.7251,  ...,  0.7842, -0.5630, -0.4388]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6034, -0.8830, -0.9539,  ..., -0.8889,  0.1396,  0.4854],\n",
            "        [ 0.6374,  0.9977,  0.8566,  ...,  0.9052, -0.8386, -0.2973],\n",
            "        [ 0.7779,  0.9995,  0.9284,  ...,  0.9194, -0.7769, -0.5410],\n",
            "        ...,\n",
            "        [ 0.6302,  0.9990,  0.7949,  ...,  0.8224, -0.8140,  0.0386],\n",
            "        [ 0.7175,  1.0000,  0.9445,  ...,  0.8342,  0.1091, -0.9340],\n",
            "        [ 0.6262,  0.9999,  0.9326,  ...,  0.9252, -0.6657, -0.6283]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5802,  1.0000,  0.9362,  ...,  0.3388,  0.4373, -0.9815],\n",
            "        [ 0.6249,  0.9988,  0.8927,  ...,  0.9161, -0.8362, -0.3108],\n",
            "        [-0.4421, -0.3935, -0.9537,  ..., -0.9461,  0.1678,  0.6720],\n",
            "        ...,\n",
            "        [-0.6457, -0.9916, -0.9607,  ..., -0.9312,  0.2126,  0.7145],\n",
            "        [-0.6069, -0.9962, -0.9472,  ..., -0.8886,  0.0299,  0.6719],\n",
            "        [-0.6479, -0.9946, -0.9500,  ..., -0.8771,  0.0948,  0.7307]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-6.1382e-01, -9.9437e-01, -9.4756e-01,  ..., -8.8424e-01,\n",
            "          1.6103e-01,  6.0142e-01],\n",
            "        [ 6.2473e-01,  9.9998e-01,  8.8939e-01,  ...,  8.6515e-01,\n",
            "         -7.1228e-01, -6.4651e-01],\n",
            "        [ 4.9228e-01,  9.7615e-01,  8.1178e-01,  ...,  9.0031e-01,\n",
            "         -8.5153e-01,  5.1053e-05],\n",
            "        ...,\n",
            "        [-5.3751e-01, -9.9928e-01, -9.6782e-01,  ..., -9.0150e-01,\n",
            "          2.5255e-01,  7.9604e-01],\n",
            "        [-7.5905e-01, -2.5935e-01, -8.6407e-01,  ..., -8.8075e-01,\n",
            "          3.9444e-01,  6.0457e-01],\n",
            "        [-6.1354e-01, -8.5492e-01, -9.4964e-01,  ..., -8.8920e-01,\n",
            "          2.2056e-01,  6.0002e-01]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6141,  0.9998,  0.9153,  ...,  0.9083, -0.7625, -0.5574],\n",
            "        [ 0.8165,  1.0000, -0.0287,  ..., -0.7481,  0.6649, -0.9462],\n",
            "        [-0.5353, -0.2839, -0.9548,  ..., -0.9194,  0.2101,  0.5565],\n",
            "        ...,\n",
            "        [ 0.6321,  0.9993,  0.8794,  ...,  0.8807, -0.8324, -0.5885],\n",
            "        [-0.6216,  0.9961, -0.8195,  ..., -0.6748,  0.2662,  0.4064],\n",
            "        [-0.7225,  0.8539, -0.8964,  ..., -0.8672,  0.0383,  0.5623]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5764, -0.9822, -0.9447,  ..., -0.7930,  0.0010,  0.7530],\n",
            "        [ 0.5718,  0.9992,  0.9207,  ...,  0.8721, -0.7040, -0.4024],\n",
            "        [ 0.6394,  0.9994,  0.8987,  ...,  0.9188, -0.7952, -0.5410],\n",
            "        ...,\n",
            "        [ 0.8361,  1.0000,  0.9491,  ...,  0.7653, -0.5495, -0.8972],\n",
            "        [-0.5977, -0.7268, -0.9450,  ..., -0.8964,  0.4417,  0.5397],\n",
            "        [-0.4860,  0.0858, -0.9516,  ..., -0.9068,  0.0882,  0.6642]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5447, -0.9848, -0.8852,  ..., -0.8718,  0.3193,  0.6820],\n",
            "        [ 0.3953,  0.9944,  0.8670,  ...,  0.7840, -0.8366, -0.1703],\n",
            "        [ 0.5471,  0.9985,  0.8218,  ...,  0.9190, -0.8050, -0.2051],\n",
            "        ...,\n",
            "        [ 0.6389,  0.9979,  0.7542,  ...,  0.8389, -0.7286, -0.4238],\n",
            "        [ 0.5539,  0.9958,  0.8159,  ...,  0.9232, -0.8118, -0.1526],\n",
            "        [ 0.5077,  1.0000,  0.8529,  ...,  0.6725, -0.6124, -0.6013]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5243,  0.5201, -0.9167,  ..., -0.7892,  0.4037,  0.7177],\n",
            "        [-0.7084, -0.9465, -0.9405,  ..., -0.8809,  0.4009,  0.6857],\n",
            "        [ 0.6767,  0.9987,  0.8974,  ...,  0.8879, -0.8123, -0.4529],\n",
            "        ...,\n",
            "        [-0.4811,  0.4629, -0.8979,  ..., -0.9097,  0.4080,  0.6010],\n",
            "        [-0.4669, -0.1179, -0.9421,  ..., -0.8800,  0.4698,  0.3310],\n",
            "        [-0.4258, -0.8531, -0.9026,  ..., -0.8885,  0.0704,  0.5498]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5982,  0.6126, -0.9296,  ..., -0.8972,  0.4972,  0.5154],\n",
            "        [ 0.7196,  0.9993,  0.8105,  ...,  0.8564, -0.7326, -0.5743],\n",
            "        [ 0.6943,  1.0000,  0.9490,  ...,  0.9011, -0.7452, -0.6132],\n",
            "        ...,\n",
            "        [-0.7479,  0.9873, -0.7859,  ..., -0.8382,  0.0558,  0.7752],\n",
            "        [-0.4445,  0.5287, -0.9382,  ..., -0.9143,  0.1747,  0.3585],\n",
            "        [ 0.5304,  0.9987,  0.8144,  ...,  0.9031, -0.8250, -0.3297]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2060,  1.0000,  0.4143,  ...,  0.3520,  0.7125, -0.8127],\n",
            "        [-0.6017,  0.9861, -0.8670,  ..., -0.7505,  0.5733,  0.4789],\n",
            "        [-0.6127, -0.9992, -0.9141,  ..., -0.8079,  0.1921,  0.5913],\n",
            "        ...,\n",
            "        [-0.7945, -0.8854, -0.9440,  ..., -0.8975,  0.0102,  0.7275],\n",
            "        [ 0.6556,  0.9992,  0.8768,  ...,  0.9330, -0.8166, -0.4787],\n",
            "        [ 0.2403,  0.9450,  0.7174,  ...,  0.8053, -0.7787, -0.0697]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.7175, -0.8017, -0.9587,  ..., -0.9167,  0.1230,  0.7508],\n",
            "        [-0.7004, -0.8762, -0.8976,  ..., -0.9051,  0.5259,  0.6702],\n",
            "        [-0.4288, -0.0851, -0.9414,  ..., -0.9257,  0.4369,  0.5063],\n",
            "        ...,\n",
            "        [-0.7434, -0.0659, -0.9553,  ..., -0.8832,  0.1605,  0.6420],\n",
            "        [ 0.6558,  0.9999,  0.8220,  ...,  0.7746, -0.6932, -0.6617],\n",
            "        [-0.7135, -0.2603, -0.9480,  ..., -0.9331,  0.1691,  0.6555]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6935,  0.9985,  0.8383,  ...,  0.8972, -0.8125, -0.2857],\n",
            "        [ 0.7500,  0.9999,  0.8759,  ...,  0.8747, -0.7803, -0.5810],\n",
            "        [-0.6598,  0.9376, -0.8595,  ..., -0.9325,  0.2961,  0.3424],\n",
            "        ...,\n",
            "        [-0.6631, -0.9930, -0.9574,  ..., -0.9037,  0.2486,  0.5556],\n",
            "        [ 0.5745,  1.0000,  0.7998,  ...,  0.8234, -0.7501, -0.7316],\n",
            "        [ 0.6672,  0.9964,  0.8376,  ...,  0.8588, -0.8910, -0.0367]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5951, -0.7530, -0.9490,  ..., -0.8659,  0.0088,  0.5483],\n",
            "        [-0.6309, -0.9554, -0.9540,  ..., -0.8945,  0.0604,  0.7246],\n",
            "        [-0.6449, -0.9932, -0.9431,  ..., -0.9260,  0.0972,  0.8020],\n",
            "        ...,\n",
            "        [ 0.4896,  0.9984,  0.8904,  ...,  0.9128, -0.8599, -0.3267],\n",
            "        [-0.6163,  0.5899, -0.9173,  ..., -0.8824,  0.2066,  0.4424],\n",
            "        [-0.6043,  0.5558, -0.9393,  ..., -0.9016,  0.3703,  0.4114]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-7.1663e-01, -3.1424e-01, -9.3246e-01, -2.9357e-01,  2.8162e-02,\n",
            "         -9.1733e-01, -4.5397e-01, -7.3377e-01,  9.2834e-01,  6.8818e-01,\n",
            "         -7.7027e-01,  9.2459e-01, -1.6364e-01, -7.8100e-01,  1.6989e-01,\n",
            "          9.1830e-01, -7.6077e-01,  4.3885e-01,  1.7894e-01,  4.5766e-01,\n",
            "          1.2945e-01,  8.6508e-01, -2.8628e-02,  3.0341e-02, -7.4094e-01,\n",
            "         -8.6114e-01,  4.3839e-01,  1.4550e-01,  1.0558e-01, -5.8434e-01,\n",
            "          4.0600e-02,  7.5770e-01,  4.8132e-01,  2.9689e-01,  1.1977e-01,\n",
            "          5.3171e-01,  7.0640e-01,  6.9153e-01, -5.1753e-01,  1.2613e-01,\n",
            "          9.3234e-01,  4.8150e-01, -3.5703e-01, -8.2004e-01, -8.4647e-01,\n",
            "         -5.1880e-01,  2.3203e-01, -5.6159e-01,  3.2018e-01,  1.2370e-01,\n",
            "          5.4371e-01, -9.9665e-01,  2.7646e-01, -9.6809e-01, -5.4708e-01,\n",
            "         -7.5607e-01, -1.5862e-01,  4.1566e-01,  1.3564e-02,  8.4970e-01,\n",
            "         -4.8772e-01, -4.7925e-01,  9.0823e-01,  3.4066e-01,  9.6959e-01,\n",
            "          2.1202e-01,  4.7463e-01, -2.1027e-01,  9.2038e-01, -6.7751e-01,\n",
            "         -8.6472e-01,  5.5272e-01, -2.9329e-01, -2.4433e-01,  4.3934e-01,\n",
            "         -4.5864e-01,  8.2189e-01, -3.8294e-01, -3.1057e-01, -2.7918e-01,\n",
            "         -8.3240e-01,  4.1394e-01,  7.5301e-01, -1.1210e-01, -8.1769e-01,\n",
            "         -5.2007e-01,  4.7195e-01,  1.1644e-01,  5.3313e-01,  9.1574e-02,\n",
            "         -1.6147e-01, -9.0358e-01, -7.8504e-01,  6.4105e-01,  4.3190e-01,\n",
            "         -5.1467e-01,  4.0743e-01, -8.4384e-01,  6.5739e-01,  9.4209e-02,\n",
            "          6.0855e-01,  5.0485e-01,  5.4737e-01,  2.1339e-01,  3.3182e-02,\n",
            "         -8.6743e-01,  4.4322e-01, -4.4109e-01,  8.2836e-01,  2.1116e-01,\n",
            "         -5.8573e-01,  9.2318e-03,  8.2175e-01, -7.1060e-01, -5.7051e-01,\n",
            "          3.9460e-01, -9.2935e-01, -8.6134e-01,  6.3541e-01,  1.7229e-01,\n",
            "         -1.6885e-01, -6.3418e-01,  4.9712e-01, -4.2671e-01, -4.8738e-01,\n",
            "         -5.7791e-01, -7.0603e-01,  9.0694e-01,  5.2721e-01,  3.1838e-01,\n",
            "         -7.8076e-02, -9.1719e-01, -8.3640e-01, -6.0174e-01,  7.0005e-01,\n",
            "         -3.6163e-01, -9.3910e-01,  4.1353e-01,  7.9422e-01,  7.8068e-01,\n",
            "          7.3670e-01,  8.4217e-02, -6.3199e-01, -1.3485e-01,  6.4237e-02,\n",
            "          3.8983e-01, -3.1018e-02,  6.7938e-01,  5.9491e-02, -8.2727e-01,\n",
            "          5.0070e-01, -6.4584e-01, -7.8139e-01,  1.9289e-01, -4.4889e-01,\n",
            "          4.9840e-01,  5.8537e-01,  5.7394e-01,  9.9243e-01, -8.9727e-01,\n",
            "          7.7171e-01,  9.1040e-01,  4.5768e-01,  3.3237e-01,  9.9881e-01,\n",
            "         -6.7916e-01,  2.0623e-01,  4.2258e-01,  8.9513e-01, -5.5022e-01,\n",
            "         -1.0986e-01,  6.8134e-01,  5.2631e-01,  5.1788e-01,  9.9404e-01,\n",
            "         -5.5252e-01, -7.1542e-01,  1.9797e-01,  9.0781e-01,  8.8622e-01,\n",
            "         -1.6506e-01, -1.1575e-02, -9.2996e-01, -8.0131e-01,  8.5788e-01,\n",
            "         -7.4194e-01, -4.6456e-01,  7.5645e-01, -9.6751e-01,  5.6001e-01,\n",
            "         -7.1114e-01, -8.1377e-01, -5.7364e-01,  8.7243e-01,  5.8248e-02,\n",
            "         -9.5190e-02, -1.5503e-01,  5.2165e-01,  5.7185e-01,  3.4401e-01,\n",
            "          7.0637e-01,  7.4783e-01,  4.9437e-01, -9.5555e-01, -8.6513e-01,\n",
            "         -6.3194e-01,  2.1151e-01,  1.6530e-02, -1.2283e-01,  6.9232e-01,\n",
            "          4.4068e-01,  6.8006e-01,  3.2848e-01, -8.2226e-01,  9.3624e-02,\n",
            "          5.6620e-01,  5.5523e-01, -9.4313e-01,  5.5023e-01,  8.4622e-01,\n",
            "         -8.5318e-01, -8.4309e-01,  4.6545e-01, -8.8701e-01, -1.3758e-01,\n",
            "         -6.7985e-01, -9.9038e-02,  1.2252e-01, -8.1300e-01,  6.2274e-01,\n",
            "          1.7079e-01,  6.5427e-01,  3.3136e-01,  8.5487e-01,  9.5133e-01,\n",
            "          1.7172e-01, -8.9203e-01,  3.4502e-01,  8.1201e-01, -4.8235e-01,\n",
            "          9.1015e-01, -5.9687e-01,  7.5807e-01,  2.7441e-01, -9.4421e-01,\n",
            "          7.1806e-01, -9.3045e-01, -8.0778e-01, -1.4943e-01,  6.5934e-01,\n",
            "         -2.0048e-01, -5.4192e-01,  4.7008e-01,  6.4043e-01,  6.8157e-01,\n",
            "          3.2097e-01,  8.5166e-01, -7.6959e-01, -4.1996e-01,  5.1414e-02,\n",
            "         -3.1312e-01,  2.4238e-01, -9.6932e-01, -8.1812e-01, -6.8946e-01,\n",
            "          5.1180e-01, -6.7885e-01, -2.6011e-01,  3.1030e-01,  2.2751e-01,\n",
            "          3.6977e-01,  8.3202e-01, -7.1622e-01,  6.7003e-01,  3.1292e-01,\n",
            "         -8.0087e-01,  1.7747e-01, -5.6302e-02, -8.5131e-01,  6.5462e-01,\n",
            "         -9.7595e-01,  9.5290e-01,  8.0729e-01,  5.4654e-01,  4.1435e-02,\n",
            "          3.8301e-01, -9.3926e-02,  9.3143e-01, -8.6132e-01,  5.2166e-01,\n",
            "          7.0362e-01,  8.2855e-01,  9.5127e-01,  1.2992e-01, -8.7881e-01,\n",
            "         -8.3242e-01,  7.0294e-01, -8.9304e-01,  2.0204e-01,  4.9624e-01,\n",
            "         -8.5456e-03,  6.9713e-01,  6.1820e-01,  6.3984e-01, -9.1717e-02,\n",
            "          7.4987e-01, -9.5974e-01,  7.0977e-01, -5.8322e-01, -8.6706e-03,\n",
            "          1.3482e-01, -7.1128e-01, -6.1454e-01,  4.8142e-01, -5.8006e-01,\n",
            "         -7.4611e-01, -4.1710e-01,  7.0422e-01,  2.9829e-01,  1.9249e-01,\n",
            "          1.4517e-01,  7.8999e-01, -6.7311e-01, -6.0842e-01, -8.8759e-01,\n",
            "          9.1641e-02,  8.9434e-01, -5.8536e-01, -8.1838e-01,  5.0430e-01,\n",
            "         -1.8309e-01,  8.9630e-01, -4.5223e-01, -7.8411e-01,  2.4197e-01,\n",
            "         -6.2144e-02, -2.9327e-01,  9.6572e-01, -9.3396e-01,  7.4044e-01,\n",
            "          7.9231e-01,  4.1104e-01,  8.6057e-01,  4.2213e-01, -4.3780e-02,\n",
            "         -8.9819e-01,  5.4617e-01, -3.0154e-01,  8.3394e-01, -4.6524e-01,\n",
            "         -3.9061e-01,  1.6063e-01, -8.3241e-01, -8.5781e-01,  7.7451e-01,\n",
            "          4.5900e-01,  6.9359e-01,  9.2252e-01, -6.0790e-01,  3.5637e-01,\n",
            "         -7.0356e-01, -3.3299e-02,  8.1254e-01, -5.3459e-01,  8.9841e-01,\n",
            "         -7.1501e-01,  4.0557e-01,  1.0195e-01, -9.5144e-01,  7.7554e-01,\n",
            "         -5.4024e-01,  7.4370e-01, -1.4170e-01,  9.4021e-01, -5.8230e-01,\n",
            "         -8.4190e-01, -6.5407e-01, -1.1091e-01,  8.6170e-01,  4.7247e-01,\n",
            "         -5.3746e-01,  9.4083e-02,  6.8308e-01,  4.7109e-01, -9.0982e-01,\n",
            "          4.3776e-01,  5.7085e-01, -8.1438e-01,  7.2595e-01,  5.4102e-01,\n",
            "          5.0153e-01,  2.0731e-01, -1.7229e-01, -9.1696e-01,  2.2094e-01,\n",
            "          7.8245e-01, -2.4782e-01, -6.6808e-01, -5.1400e-01,  4.9830e-01,\n",
            "         -7.2500e-01, -1.8439e-01, -7.9851e-01,  6.6899e-01,  5.8639e-01,\n",
            "         -4.5196e-01, -9.2844e-02, -2.8536e-02,  4.9680e-01, -9.2456e-01,\n",
            "          4.8805e-01,  6.5296e-01,  5.1573e-01,  6.4198e-01, -8.9691e-01,\n",
            "          1.2636e-01, -9.0198e-01, -5.4756e-02, -5.3394e-01,  2.8168e-01,\n",
            "         -2.5949e-01, -5.2585e-01, -6.3587e-01, -9.5809e-01,  8.1784e-01,\n",
            "         -3.5345e-01,  9.4059e-01, -6.6908e-01, -6.1190e-01, -4.8786e-01,\n",
            "         -1.5546e-01,  2.1832e-01,  7.5147e-01, -3.8136e-01,  8.6327e-01,\n",
            "         -7.2472e-01,  1.9178e-01,  6.3615e-01,  7.7714e-01,  2.1692e-01,\n",
            "          7.5930e-01,  8.7689e-01,  8.1834e-01, -1.8374e-01,  7.1505e-01,\n",
            "          2.7605e-02, -7.7091e-01, -8.9649e-01,  2.0812e-02,  8.0029e-01,\n",
            "         -1.9135e-01,  8.3088e-01, -7.3972e-01,  5.9424e-01,  7.8427e-01,\n",
            "          9.2787e-02,  7.7945e-02, -2.7753e-01,  9.2787e-01,  5.0331e-01,\n",
            "         -2.4811e-01,  8.9662e-01,  1.5731e-01,  9.2725e-01,  3.0042e-01,\n",
            "          2.0730e-02,  7.2764e-01,  5.4682e-01, -8.1018e-01, -1.9865e-01,\n",
            "          7.0777e-01,  5.2119e-01,  1.9213e-01, -9.6556e-01, -2.5023e-01,\n",
            "         -1.1520e-01, -1.7547e-02, -7.7764e-01, -1.6419e-01, -9.9688e-01,\n",
            "          6.1682e-01,  6.2499e-01, -9.3775e-01,  4.4963e-01,  8.8379e-02,\n",
            "          2.8056e-02,  5.0392e-01,  4.6041e-01,  8.9918e-01, -8.3467e-01,\n",
            "         -6.7218e-02, -1.4049e-01,  8.7323e-02,  6.7090e-01,  5.4679e-01,\n",
            "          9.3571e-02, -6.7564e-01, -2.0938e-01,  5.6011e-01,  1.1236e-01,\n",
            "         -1.0107e-01, -7.7497e-01, -4.2537e-02,  3.1383e-01, -7.5270e-01,\n",
            "         -9.2151e-01,  3.2876e-01,  9.8618e-01,  2.6362e-01,  1.1457e-02,\n",
            "          6.3885e-01,  1.6847e-01,  6.8150e-02,  8.3899e-01, -4.0641e-01,\n",
            "          3.3450e-01,  8.2634e-01, -4.4412e-01, -5.0082e-01, -6.7894e-01,\n",
            "         -2.6282e-01, -3.2173e-01,  5.1806e-01, -6.3668e-01, -8.2829e-01,\n",
            "         -9.2604e-01, -5.7528e-01, -2.5604e-01, -5.0405e-01, -5.0530e-02,\n",
            "          6.9943e-01, -2.2966e-01,  2.4486e-01, -7.7076e-01, -5.2636e-01,\n",
            "         -9.7612e-01, -4.3486e-01, -5.1248e-01, -5.5782e-01, -5.5217e-02,\n",
            "         -9.2118e-01, -2.5778e-01, -3.4760e-01, -1.2462e-01,  6.6902e-01,\n",
            "          7.9299e-01, -4.3318e-01, -3.9636e-01, -6.4827e-01,  7.3791e-01,\n",
            "         -6.6804e-01,  2.1572e-01, -5.8581e-01,  8.3965e-01, -8.2845e-01,\n",
            "         -9.6516e-02, -8.6462e-01, -4.5812e-01, -9.0032e-02,  3.9682e-01,\n",
            "          2.0913e-01, -5.7837e-01,  4.7108e-01, -8.7535e-01,  4.5844e-01,\n",
            "         -3.7179e-01, -4.5285e-01, -6.8958e-01, -8.6562e-01, -9.4589e-01,\n",
            "          8.5862e-01,  9.5672e-01, -4.2403e-04, -8.7731e-01, -4.8707e-01,\n",
            "          5.6456e-01,  7.8367e-02, -5.7872e-01,  8.1975e-01,  9.3028e-01,\n",
            "          6.7416e-01,  7.5287e-01,  2.9150e-01, -4.5423e-02, -8.4583e-01,\n",
            "         -4.6079e-01, -2.6464e-01,  1.3761e-01, -6.7506e-01,  6.3934e-01,\n",
            "          2.1451e-02,  2.1868e-01,  5.6327e-01, -5.0870e-01,  9.2893e-01,\n",
            "          5.2640e-01, -3.2058e-01,  8.9365e-01, -6.8106e-01, -8.5711e-01,\n",
            "         -3.8052e-01, -8.7877e-01,  8.9598e-01, -3.2907e-01, -8.8546e-01,\n",
            "          2.9239e-01, -2.2017e-01,  5.8816e-02,  4.6945e-03,  7.0972e-02,\n",
            "          7.1486e-01,  3.4482e-01,  4.1262e-01, -1.6354e-01, -1.7786e-01,\n",
            "         -1.8144e-01,  5.4869e-01,  8.9723e-01,  1.6879e-01,  6.8413e-01,\n",
            "         -3.4603e-01,  6.1039e-01,  1.9135e-01,  6.6494e-01,  1.1971e-01,\n",
            "         -9.3224e-02,  1.4835e-01, -9.8217e-01,  7.3014e-01, -3.5668e-01,\n",
            "          6.5302e-01,  7.5153e-01, -5.5416e-01, -7.4419e-01, -4.7872e-01,\n",
            "         -8.0136e-01, -3.6606e-01, -7.7751e-01,  9.7121e-01, -1.0183e-01,\n",
            "         -7.6244e-01,  8.4180e-01,  5.6397e-01,  7.6739e-02,  8.1620e-01,\n",
            "         -8.2261e-01, -7.5542e-03, -2.1120e-01,  8.2934e-01,  6.3734e-01,\n",
            "         -2.2883e-01, -7.9340e-01, -3.9124e-01, -9.0044e-01, -5.7487e-01,\n",
            "          2.6680e-01, -3.9599e-02,  4.1359e-01, -7.2254e-01, -9.0959e-01,\n",
            "          2.4008e-01, -8.6449e-01,  4.9862e-01, -4.7733e-01,  9.3463e-03,\n",
            "          9.3200e-01, -7.4173e-01, -4.3845e-01,  9.3463e-01,  7.6599e-01,\n",
            "         -8.8901e-01,  9.3383e-01, -3.3261e-01, -3.0577e-01,  8.5357e-01,\n",
            "          4.8669e-01, -2.6372e-01,  6.4834e-01, -1.1570e-01,  2.3566e-01,\n",
            "         -2.1410e-01, -5.4249e-01,  9.6542e-01,  5.9365e-01, -2.3837e-01,\n",
            "          8.3822e-01, -1.6269e-01,  3.6516e-01,  1.9167e-01, -7.0279e-01,\n",
            "          4.1023e-01, -6.8295e-01, -4.0949e-01, -4.1362e-01, -3.3804e-01,\n",
            "          7.5957e-01,  9.9346e-01, -9.3718e-01,  8.5954e-01,  3.7279e-01,\n",
            "          1.3614e-02,  4.4505e-01, -4.6506e-01,  1.0755e-01,  7.3611e-01,\n",
            "         -1.9132e-01,  5.8166e-01, -2.4483e-01, -6.3675e-01,  1.6140e-02,\n",
            "          6.0595e-01, -9.7239e-01, -8.9142e-01,  5.5911e-01,  3.5581e-01,\n",
            "         -8.0948e-01, -5.5077e-01,  2.2096e-01,  4.9222e-01, -5.7534e-01,\n",
            "         -8.3767e-03,  5.9496e-01, -4.8711e-02,  5.2710e-01, -9.2731e-01,\n",
            "         -2.5914e-01,  3.6286e-01, -2.8192e-01,  8.0041e-01, -6.9470e-01,\n",
            "          9.7793e-01, -7.8024e-01,  6.4822e-01,  8.1395e-01, -8.0244e-01,\n",
            "         -8.8639e-01, -5.8853e-01, -2.3957e-01,  3.5634e-01, -7.3271e-02,\n",
            "         -8.8934e-01,  7.3909e-01, -8.6823e-01,  4.2830e-01,  3.0785e-02,\n",
            "         -5.4289e-01,  5.1449e-01, -2.2131e-01,  2.1628e-01,  2.7134e-01,\n",
            "         -8.4137e-01,  8.6914e-01,  8.2564e-01,  1.3739e-01,  8.4174e-01,\n",
            "         -7.3202e-01,  6.4395e-01, -2.4555e-01,  1.4405e-01,  9.0854e-01,\n",
            "          3.4117e-01, -3.1406e-01, -7.4306e-01, -3.5302e-01,  7.8753e-01,\n",
            "         -8.4483e-01,  4.5091e-02,  7.5469e-01]], device='cuda:0',\n",
            "       grad_fn=<TanhBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluation... :   0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33403fd8abae4e149f34929ea89b70b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7517,  0.9917,  0.8870,  ...,  0.8758, -0.8146, -0.3723],\n",
            "        [ 0.7907,  1.0000,  0.9624,  ...,  0.8061,  0.0895, -0.9579],\n",
            "        [ 0.8411,  1.0000,  0.1219,  ..., -0.6725,  0.6586, -0.8815],\n",
            "        ...,\n",
            "        [ 0.3824,  0.9991,  0.7899,  ...,  0.8224, -0.8022, -0.2053],\n",
            "        [-0.0590,  0.9858, -0.7110,  ..., -0.8601,  0.5605, -0.1761],\n",
            "        [-0.6927, -0.2188, -0.9170,  ..., -0.7550,  0.3039,  0.6249]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4170,  0.9959, -0.8690,  ..., -0.8874,  0.3811,  0.1942],\n",
            "        [ 0.7092,  1.0000,  0.7263,  ...,  0.4637, -0.7920, -0.3276],\n",
            "        [ 0.2082,  0.9983,  0.0589,  ..., -0.7099,  0.5736, -0.8518],\n",
            "        ...,\n",
            "        [-0.2489,  0.9933, -0.3426,  ..., -0.7241,  0.1919, -0.7033],\n",
            "        [-0.6086,  0.9999, -0.5241,  ..., -0.8724,  0.3510, -0.0097],\n",
            "        [ 0.4424,  1.0000,  0.6032,  ..., -0.7272,  0.6799, -0.9599]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6605,  0.9999,  0.9290,  ...,  0.8585, -0.6680, -0.6637],\n",
            "        [ 0.3530,  1.0000,  0.7644,  ...,  0.3970,  0.7247, -0.8630],\n",
            "        [ 0.5828,  1.0000,  0.8596,  ...,  0.8667, -0.7347, -0.5655],\n",
            "        ...,\n",
            "        [-0.1396,  1.0000,  0.0360,  ..., -0.8871,  0.5406, -0.8127],\n",
            "        [-0.7735, -0.3022, -0.9063,  ..., -0.9210,  0.2642,  0.4751],\n",
            "        [ 0.4667,  1.0000,  0.6060,  ...,  0.0230,  0.1765, -0.9455]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0720,  0.9987,  0.0308,  ..., -0.2024, -0.6308, -0.6887],\n",
            "        [-0.0968,  1.0000,  0.7423,  ..., -0.4048,  0.1375, -0.9520],\n",
            "        [-0.0746,  0.9999, -0.4972,  ..., -0.8215,  0.3911, -0.8520],\n",
            "        ...,\n",
            "        [ 0.7642,  1.0000,  0.9261,  ...,  0.8762, -0.4880, -0.6718],\n",
            "        [-0.1778, -0.3339, -0.8210,  ..., -0.9111,  0.6464, -0.2010],\n",
            "        [ 0.6512,  0.9979,  0.8803,  ...,  0.9024, -0.8595, -0.3299]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6977,  0.9999,  0.7364,  ...,  0.7299, -0.4646, -0.3068],\n",
            "        [ 0.4562,  0.9999,  0.8437,  ...,  0.8791, -0.4994, -0.5238],\n",
            "        [-0.5331,  0.4451, -0.8808,  ..., -0.7538,  0.3729,  0.4896],\n",
            "        ...,\n",
            "        [ 0.5475,  0.9999,  0.5568,  ...,  0.7172, -0.4881, -0.8290],\n",
            "        [ 0.4942,  0.9999,  0.8871,  ...,  0.3936, -0.5432, -0.6122],\n",
            "        [ 0.7517,  0.9997,  0.9551,  ...,  0.5834, -0.3979, -0.7464]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5507,  0.9991,  0.8849,  ...,  0.8895, -0.8085, -0.4198],\n",
            "        [ 0.7754,  1.0000,  0.6468,  ...,  0.6040, -0.6084, -0.8670],\n",
            "        [-0.0356,  0.0848, -0.9642,  ..., -0.9114,  0.6227,  0.0869],\n",
            "        ...,\n",
            "        [ 0.7382,  0.9998, -0.6582,  ..., -0.7289,  0.7231, -0.5410],\n",
            "        [ 0.3162,  1.0000,  0.1264,  ...,  0.1314, -0.4045, -0.6488],\n",
            "        [ 0.2490,  1.0000,  0.6415,  ...,  0.2178, -0.5182, -0.8773]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0590,  0.9823, -0.5689,  ..., -0.7948, -0.2779, -0.6023],\n",
            "        [-0.5709, -0.7809, -0.9487,  ..., -0.9320,  0.1019,  0.7168],\n",
            "        [ 0.6383,  0.9961,  0.8226,  ...,  0.9019, -0.8156, -0.3488],\n",
            "        ...,\n",
            "        [-0.2427,  1.0000, -0.3369,  ..., -0.7972, -0.3711, -0.5127],\n",
            "        [ 0.6278,  0.9983,  0.9188,  ...,  0.9122, -0.8448, -0.3698],\n",
            "        [-0.4198,  0.9155, -0.8538,  ..., -0.8315,  0.1008,  0.3993]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6536,  0.9996,  0.8929,  ...,  0.8942, -0.7857, -0.4750],\n",
            "        [ 0.7119,  0.9996,  0.9334,  ...,  0.9229, -0.7457, -0.5457],\n",
            "        [ 0.6981,  1.0000,  0.9370,  ...,  0.8477, -0.0697, -0.9157],\n",
            "        ...,\n",
            "        [ 0.6054,  0.9934,  0.8884,  ...,  0.8749, -0.8796, -0.2362],\n",
            "        [ 0.4522,  0.9995,  0.7855,  ...,  0.8380, -0.7895, -0.6134],\n",
            "        [ 0.5771,  1.0000,  0.7863,  ...,  0.6291, -0.5985, -0.6235]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.8063,  1.0000,  0.9550,  ...,  0.8647, -0.3656, -0.8636],\n",
            "        [-0.0218,  0.9974, -0.8802,  ..., -0.8483,  0.3601, -0.2503],\n",
            "        [-0.8295, -0.9721, -0.8297,  ..., -0.9086,  0.1168,  0.3239],\n",
            "        ...,\n",
            "        [ 0.6975,  0.9997,  0.8915,  ...,  0.8737, -0.7593, -0.3826],\n",
            "        [-0.6692, -0.7070, -0.9285,  ..., -0.9010,  0.2525,  0.7828],\n",
            "        [ 0.5419,  0.9940,  0.8773,  ...,  0.8618, -0.8277, -0.2457]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5275, -0.5547, -0.9531,  ..., -0.8848,  0.1649,  0.5038],\n",
            "        [ 0.0872,  1.0000,  0.1431,  ..., -0.6119,  0.1247, -0.8188],\n",
            "        [ 0.6344,  0.9995,  0.9169,  ...,  0.8951, -0.7849, -0.5401],\n",
            "        ...,\n",
            "        [ 0.7128,  0.9980,  0.8226,  ...,  0.8946, -0.8472, -0.3132],\n",
            "        [ 0.4793,  0.9998,  0.8518,  ...,  0.7371, -0.5873, -0.2260],\n",
            "        [ 0.7458,  1.0000,  0.9383,  ...,  0.8017,  0.0639, -0.9484]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2091,  0.5785, -0.9021,  ..., -0.8658,  0.3605,  0.3814],\n",
            "        [-0.5267, -0.9534, -0.9194,  ..., -0.9360,  0.1690,  0.5051],\n",
            "        [-0.6826,  0.7585, -0.9669,  ..., -0.9431, -0.0537,  0.3656],\n",
            "        ...,\n",
            "        [ 0.6772,  1.0000,  0.8513,  ...,  0.7032, -0.6139, -0.8114],\n",
            "        [ 0.7673,  1.0000, -0.4679,  ..., -0.5728,  0.5034, -0.9097],\n",
            "        [ 0.5132,  0.9985,  0.9017,  ...,  0.8916, -0.8162, -0.2752]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0822,  0.9999,  0.7076,  ..., -0.1864,  0.3536, -0.8351],\n",
            "        [-0.5109, -0.8888, -0.9547,  ..., -0.9042,  0.2652,  0.6201],\n",
            "        [-0.7037,  0.9201, -0.9273,  ..., -0.9023,  0.2464,  0.1348],\n",
            "        ...,\n",
            "        [-0.5898,  0.9350, -0.9415,  ..., -0.9087,  0.2836,  0.5763],\n",
            "        [ 0.1240,  1.0000,  0.1429,  ..., -0.6140, -0.0427, -0.8038],\n",
            "        [-0.2866,  0.9998, -0.7302,  ..., -0.9131,  0.5184, -0.3787]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1206,  0.9932, -0.7977,  ..., -0.4331,  0.6984,  0.3571],\n",
            "        [ 0.3561,  1.0000,  0.6788,  ...,  0.0953, -0.0869, -0.8773],\n",
            "        [-0.6428, -0.9390, -0.8692,  ..., -0.9124,  0.4268,  0.4502],\n",
            "        ...,\n",
            "        [-0.7434,  0.9910, -0.9298,  ..., -0.7378,  0.6023,  0.3492],\n",
            "        [ 0.0819,  0.9973, -0.9113,  ..., -0.8552,  0.4331, -0.4030],\n",
            "        [-0.6413,  1.0000, -0.7492,  ..., -0.8159,  0.4407, -0.6079]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7802,  1.0000,  0.9169,  ...,  0.4881, -0.4168, -0.7339],\n",
            "        [ 0.6029,  1.0000,  0.8157,  ...,  0.2979, -0.2366, -0.8371],\n",
            "        [-0.6678, -0.4217, -0.9360,  ..., -0.8550, -0.1108,  0.5315],\n",
            "        ...,\n",
            "        [ 0.4409,  1.0000,  0.5647,  ..., -0.2044, -0.4460, -0.7213],\n",
            "        [ 0.5156,  1.0000,  0.7857,  ...,  0.8083, -0.3377, -0.6299],\n",
            "        [-0.5562,  0.9935, -0.6079,  ..., -0.7669,  0.1118, -0.4476]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 4.6325e-01,  9.9996e-01,  7.4325e-01, -9.5115e-01, -4.6481e-01,\n",
            "          9.3190e-01,  7.0011e-01,  7.9800e-01, -9.9700e-01, -6.1165e-01,\n",
            "          8.0774e-01, -5.8394e-01,  4.5804e-01,  9.9899e-01,  3.8997e-01,\n",
            "         -1.2163e-01,  7.1828e-01, -9.6940e-01,  6.4890e-01, -2.2678e-01,\n",
            "          3.2252e-01, -7.8622e-01,  8.1199e-01, -3.3234e-01,  8.0302e-01,\n",
            "          7.5694e-01, -4.9904e-01,  5.1565e-01, -1.6140e-01,  2.4769e-01,\n",
            "         -6.1390e-01, -2.4566e-01,  9.1638e-01,  6.3031e-01,  7.9696e-01,\n",
            "         -9.3670e-01, -3.0413e-01, -9.5381e-01, -9.8058e-01, -9.9636e-01,\n",
            "          2.3217e-01, -4.2128e-01,  9.9944e-01, -8.1206e-01,  9.9552e-01,\n",
            "         -9.8825e-01,  5.1855e-01, -3.2467e-01,  5.9170e-01,  4.2522e-01,\n",
            "         -6.9796e-01,  9.3966e-01,  7.7261e-01,  8.4157e-01, -6.0189e-01,\n",
            "         -8.2160e-01, -7.9245e-01,  4.5174e-01, -8.5599e-01, -4.9967e-01,\n",
            "          7.8603e-01,  7.5222e-01, -5.7270e-01, -6.9859e-02, -8.7089e-01,\n",
            "         -5.5659e-01,  5.6446e-01,  4.6507e-01, -6.8876e-01, -9.2947e-01,\n",
            "          8.4952e-01, -9.2720e-01,  6.3772e-01,  1.9831e-01, -3.1366e-01,\n",
            "          8.1551e-01, -8.6950e-01,  9.0400e-01, -7.7735e-01,  9.8973e-01,\n",
            "          6.5622e-01,  4.2796e-01,  6.2986e-01, -9.9994e-01,  6.7291e-01,\n",
            "         -8.8412e-01,  9.8380e-01, -9.7974e-01, -9.5443e-01,  6.9619e-01,\n",
            "          7.8888e-01,  6.5746e-01,  8.0707e-01, -1.2896e-01, -4.3043e-01,\n",
            "         -8.9967e-01, -6.6137e-01,  5.4304e-01, -9.9831e-01,  7.7172e-01,\n",
            "          6.3145e-01,  7.5681e-01, -6.8126e-01, -5.9192e-01, -9.9887e-01,\n",
            "          5.0474e-01, -6.1841e-01, -4.9635e-01, -9.9993e-01, -7.1631e-01,\n",
            "         -8.1418e-01, -8.0510e-01, -3.4050e-01,  8.8512e-01,  5.3595e-01,\n",
            "          9.9965e-01,  8.7057e-01,  9.9799e-01, -9.9994e-01, -9.9206e-01,\n",
            "          4.8276e-02,  9.3393e-01, -6.1993e-01,  1.7829e-02,  5.4379e-01,\n",
            "         -9.6486e-01,  6.7312e-01, -9.9786e-01,  6.6964e-01, -9.2810e-01,\n",
            "         -4.9149e-01,  7.8978e-01,  8.8623e-01,  5.1728e-01, -6.2140e-01,\n",
            "          5.4877e-01, -9.9959e-01,  2.2419e-02, -7.1925e-01, -9.9092e-01,\n",
            "          9.9083e-01,  8.3709e-01,  8.4830e-01, -4.5481e-01, -3.3236e-01,\n",
            "          8.3300e-01,  8.4781e-01, -6.9311e-01,  1.1501e-01, -1.8545e-01,\n",
            "         -8.1225e-01,  8.0096e-01,  4.1843e-01, -4.5735e-01, -9.9993e-01,\n",
            "          4.9494e-01, -6.8335e-01,  9.4012e-01, -9.8689e-01,  9.7256e-01,\n",
            "         -9.7286e-01, -9.9995e-01,  3.5275e-01,  2.9518e-01, -7.7465e-01,\n",
            "          7.9588e-01, -7.9140e-01,  8.7979e-01, -5.9211e-01,  6.8068e-01,\n",
            "          6.3353e-01,  6.4216e-01,  3.7498e-01, -5.5453e-01,  3.1585e-01,\n",
            "         -7.0744e-01,  7.9397e-01, -7.3971e-01, -6.3888e-01, -9.5418e-01,\n",
            "          9.6574e-01, -4.3829e-01,  9.7713e-01, -9.4402e-01, -7.4475e-01,\n",
            "          5.0326e-01,  2.3046e-01, -9.9999e-01,  9.1563e-01,  4.8099e-01,\n",
            "          4.0825e-01,  6.1476e-01,  3.0077e-01, -4.5932e-01,  3.2278e-02,\n",
            "          2.6422e-02, -5.1289e-01,  6.6672e-01, -3.0079e-01,  8.9380e-01,\n",
            "          3.2089e-01, -9.9939e-01,  7.9817e-01,  9.9225e-01,  1.6291e-01,\n",
            "         -4.1816e-01,  8.3198e-02,  9.7669e-01, -9.9617e-01, -6.5009e-01,\n",
            "          1.4750e-01, -5.5527e-01,  4.4702e-01,  4.3490e-01, -4.3752e-01,\n",
            "         -7.4767e-01,  6.1300e-01,  3.6045e-01, -1.6791e-01, -4.9490e-01,\n",
            "          3.0151e-01,  5.9119e-01, -3.0712e-01,  4.3418e-01,  7.4379e-01,\n",
            "          9.9913e-01, -5.0820e-01, -5.9085e-01,  6.2389e-01, -9.9943e-01,\n",
            "          8.1105e-01,  4.9588e-01, -3.5333e-01, -6.8457e-01,  9.8853e-01,\n",
            "          7.6152e-01,  6.7587e-01,  9.8424e-01, -9.4867e-01, -2.4201e-01,\n",
            "         -5.9655e-01,  8.6143e-01, -4.3681e-01, -8.7476e-02,  9.9995e-01,\n",
            "         -9.9257e-01,  9.8273e-01,  9.0545e-01, -1.8539e-02, -4.3269e-01,\n",
            "          6.8452e-01,  2.9704e-01, -2.9684e-01, -6.4877e-02, -6.4739e-01,\n",
            "          9.9224e-01, -6.5498e-01, -9.7899e-01,  5.3162e-01, -1.8159e-01,\n",
            "         -9.0494e-01, -8.4310e-01,  8.1477e-01, -5.4108e-01,  9.7490e-01,\n",
            "          9.9986e-01,  7.6954e-01,  4.7824e-01,  6.8851e-01,  5.4506e-01,\n",
            "          7.5624e-01, -9.8122e-01,  9.6118e-01,  9.9995e-01, -9.4518e-01,\n",
            "          4.4306e-01,  9.9988e-01,  6.6100e-01, -2.2436e-01, -5.8677e-01,\n",
            "          3.1790e-01, -9.7680e-01, -2.0319e-01, -5.0207e-01, -4.6643e-01,\n",
            "         -5.4895e-01,  1.4852e-02, -9.3538e-01, -9.9922e-01, -9.8243e-01,\n",
            "          9.6709e-01, -6.9272e-01, -6.4252e-01,  5.5762e-01, -7.5061e-01,\n",
            "          4.5103e-01, -7.0201e-01,  9.8977e-01, -7.2304e-01,  9.9991e-01,\n",
            "          5.9558e-01, -6.3749e-01, -9.5841e-01, -3.0953e-01,  5.3845e-01,\n",
            "          1.2135e-01,  9.9898e-01,  6.6110e-02, -6.1886e-01,  7.5072e-01,\n",
            "          6.3009e-01,  2.5572e-01,  9.2113e-01, -6.0581e-01,  6.3921e-01,\n",
            "          3.8211e-01,  6.3994e-02, -9.4585e-01, -3.3391e-01, -8.5205e-01,\n",
            "          7.8247e-01,  9.6260e-01,  7.0128e-01,  2.2494e-01,  9.5755e-01,\n",
            "          8.2359e-01, -9.9996e-01,  9.9874e-01,  9.7559e-01, -9.9113e-01,\n",
            "          8.2054e-01, -1.4401e-01,  8.8845e-01, -1.9714e-01,  4.5756e-01,\n",
            "         -8.8317e-01, -8.3010e-01, -9.7794e-01,  7.7279e-01,  2.1177e-01,\n",
            "         -7.0242e-01,  2.8371e-01, -9.0601e-01,  7.9078e-01,  1.4206e-01,\n",
            "          8.2147e-01, -2.9330e-01,  1.5776e-01, -9.9514e-01,  6.6640e-01,\n",
            "          8.6625e-01, -2.2891e-01,  7.6030e-01,  9.8492e-01,  1.2397e-02,\n",
            "          9.9995e-01, -7.5657e-01, -4.3909e-01,  2.1417e-01,  5.8535e-01,\n",
            "          4.1636e-01,  4.6286e-01, -2.4972e-01,  5.3900e-01, -9.9997e-01,\n",
            "          2.9093e-01, -5.3573e-01,  3.0061e-01,  6.5023e-01, -9.8294e-01,\n",
            "          5.0988e-01, -4.3966e-01,  4.0073e-02, -2.0322e-01,  3.1804e-01,\n",
            "          5.7537e-01,  9.9885e-01,  3.9047e-01, -4.7970e-01, -6.8395e-01,\n",
            "          2.2667e-02,  6.6318e-02,  9.0268e-01,  6.7334e-01,  9.8966e-01,\n",
            "         -8.1081e-01, -2.7774e-01,  6.6673e-01,  2.8919e-02, -6.7084e-01,\n",
            "         -1.0019e-01,  6.1569e-01,  5.6727e-02,  9.2400e-01,  7.4733e-01,\n",
            "         -5.5383e-01, -5.5992e-01,  8.3209e-01, -9.9801e-01,  9.9990e-01,\n",
            "          3.0318e-01,  5.2609e-01,  9.3364e-01, -3.0925e-01,  7.0966e-01,\n",
            "          4.3806e-01,  3.6433e-01, -7.0125e-01,  9.7363e-01,  7.3360e-01,\n",
            "          6.3359e-01,  1.4868e-01, -1.1568e-01, -8.4800e-02, -9.1797e-01,\n",
            "          5.3530e-01,  3.7703e-01, -4.7281e-01, -9.7927e-01,  9.8694e-01,\n",
            "         -9.7867e-01,  3.8118e-01, -2.2201e-01,  8.1186e-01,  9.3937e-01,\n",
            "         -3.8134e-01, -8.6818e-01, -2.0066e-01,  3.7834e-01, -7.1581e-01,\n",
            "         -8.1956e-01, -9.9157e-01, -8.9763e-02, -8.9320e-01,  9.9984e-01,\n",
            "         -9.8997e-01,  5.3547e-01, -9.1095e-01, -9.0064e-01,  7.4911e-01,\n",
            "         -4.3489e-01, -5.8093e-01, -8.2237e-01, -1.4492e-01, -5.0940e-01,\n",
            "          7.7270e-01,  2.1855e-02,  7.4315e-01, -4.7054e-01,  2.7788e-01,\n",
            "          7.5233e-01,  1.4970e-01,  2.6622e-01,  9.0050e-01, -6.3052e-01,\n",
            "         -9.5118e-01, -7.0355e-01, -5.8882e-01, -7.0272e-01,  9.5563e-01,\n",
            "         -9.2106e-01, -8.2531e-01,  9.9997e-01, -9.8227e-01,  1.7674e-01,\n",
            "         -3.3133e-01, -9.9657e-01,  5.6743e-01, -3.5556e-01, -9.4055e-01,\n",
            "         -6.1850e-01, -7.9947e-01,  6.7324e-01,  9.3117e-01,  9.9895e-01,\n",
            "          2.2328e-01,  2.0422e-01, -9.5499e-01, -6.3326e-01,  9.9713e-01,\n",
            "         -9.5869e-01, -4.2836e-01,  3.6366e-01, -9.9456e-01,  9.2621e-01,\n",
            "          3.0850e-01, -4.6078e-01,  8.3735e-01, -6.9728e-01,  9.6365e-01,\n",
            "          6.0351e-01, -9.9697e-01,  5.8235e-01,  7.0267e-01, -2.9481e-01,\n",
            "          8.6205e-01,  2.7417e-01,  2.3550e-01, -9.5050e-01, -9.9852e-03,\n",
            "          9.9909e-01,  4.2910e-01, -7.9246e-01,  5.0441e-02,  8.0392e-01,\n",
            "          8.0132e-01,  9.9995e-01, -9.6316e-01,  6.7538e-01,  9.9942e-01,\n",
            "         -2.9673e-01,  4.9495e-01,  2.7555e-01, -7.6467e-01,  6.1305e-02,\n",
            "          5.0735e-01, -9.7683e-01,  9.9980e-01, -4.2464e-02, -9.8650e-01,\n",
            "         -9.9993e-01,  3.2590e-01, -8.1750e-01,  7.6122e-01,  9.7037e-01,\n",
            "          6.1523e-01,  8.6939e-01,  3.1763e-01, -9.9832e-01, -3.9387e-02,\n",
            "         -5.7568e-01, -9.9970e-01, -9.9922e-01,  8.4216e-01,  1.6967e-01,\n",
            "          2.0318e-01,  7.8291e-01, -8.4466e-02, -7.4389e-01,  9.9956e-01,\n",
            "          9.0460e-01, -9.9989e-01, -1.9930e-01,  2.6901e-01,  9.6409e-01,\n",
            "         -7.2786e-01,  6.2521e-01,  3.9646e-01,  4.2518e-01, -3.6701e-01,\n",
            "         -9.9994e-01, -5.0808e-01,  9.6987e-01, -5.9767e-02,  7.1824e-03,\n",
            "          9.9936e-01,  7.0330e-01,  4.0746e-01, -9.4488e-01, -6.0444e-02,\n",
            "          6.8784e-01, -9.9994e-01, -7.0624e-01,  9.9972e-01, -2.7199e-01,\n",
            "         -8.8287e-02, -5.1532e-01,  3.5720e-01,  6.0747e-01,  6.0057e-01,\n",
            "          1.2754e-01, -9.9640e-01,  9.9403e-01,  8.7612e-01, -9.1162e-01,\n",
            "          9.9631e-01, -5.3461e-01, -6.8849e-01, -7.5828e-01, -6.5626e-01,\n",
            "          7.5129e-01, -7.2466e-01,  5.2524e-01, -2.4599e-01,  9.8244e-01,\n",
            "          8.8809e-01, -3.8600e-01,  7.5930e-01,  9.0970e-01, -8.0849e-01,\n",
            "         -3.5777e-01,  7.8568e-01,  6.0335e-01,  4.3253e-01,  9.7828e-01,\n",
            "         -4.4833e-01, -7.3325e-01, -4.4175e-01,  6.5826e-01,  9.1982e-01,\n",
            "         -9.9985e-01,  9.2416e-01, -5.1173e-01, -8.8472e-01,  6.6779e-01,\n",
            "         -5.4486e-01, -6.1307e-01, -2.6004e-01, -5.0494e-01, -6.6979e-01,\n",
            "          1.6188e-01,  9.4624e-01,  7.3144e-01,  7.6537e-01, -9.8414e-01,\n",
            "         -9.9987e-01, -6.9584e-01, -5.7386e-01, -8.2255e-01, -4.9935e-01,\n",
            "          2.8344e-01,  9.4007e-01,  2.2772e-01,  4.8478e-01,  2.8857e-01,\n",
            "          9.9975e-01, -4.1730e-01,  9.9014e-01, -8.0068e-01,  9.3184e-01,\n",
            "         -9.8847e-01,  5.2456e-01,  5.5298e-01, -9.4684e-01, -5.1584e-01,\n",
            "          9.5665e-01, -3.5212e-01,  8.3186e-01, -9.6768e-01,  6.3560e-01,\n",
            "          9.9996e-01, -7.3167e-01, -6.2255e-01,  6.8193e-01, -8.7559e-01,\n",
            "          7.8197e-01,  1.9089e-03,  9.9332e-01, -9.9995e-01,  9.8791e-01,\n",
            "         -8.9602e-02,  4.3755e-01,  5.5762e-01,  5.9613e-01,  5.7099e-01,\n",
            "         -6.2960e-01, -5.0711e-01, -9.8906e-01,  6.3553e-01,  4.1983e-01,\n",
            "         -6.5952e-01,  2.9647e-01,  9.1355e-01, -7.7676e-01, -9.9806e-01,\n",
            "         -6.3466e-01,  4.7963e-01,  9.4579e-01, -4.7625e-01, -9.9010e-01,\n",
            "          9.6030e-01, -2.2614e-01,  9.6638e-01,  2.1523e-01, -7.0550e-01,\n",
            "         -4.3888e-01, -1.8470e-01, -5.8920e-01,  5.5779e-01,  6.8406e-01,\n",
            "          8.1468e-01,  3.2851e-01, -8.7380e-01, -4.8078e-01,  3.0203e-02,\n",
            "         -7.7988e-01,  7.4010e-01, -3.1987e-01, -9.7272e-02,  7.3188e-01,\n",
            "          8.2593e-01,  9.7436e-01,  4.0424e-01,  2.0614e-01,  7.5194e-01,\n",
            "         -7.3709e-01, -5.9697e-01, -9.9963e-01,  9.9890e-01,  8.5599e-01,\n",
            "         -8.4115e-01, -9.9967e-01,  9.3546e-01,  2.3029e-01, -3.4748e-01,\n",
            "          7.2783e-01, -9.3813e-02, -6.8581e-01,  2.6785e-01,  7.6094e-01,\n",
            "         -9.9996e-01, -4.4429e-01,  1.7248e-01, -3.9806e-01, -6.7044e-01,\n",
            "         -9.9972e-01, -5.3791e-01,  1.1638e-01, -2.7282e-01,  3.0108e-01,\n",
            "          9.9802e-01, -4.0686e-01, -9.8621e-01, -9.5739e-01, -6.3622e-02,\n",
            "          6.3673e-01,  2.0747e-01, -9.5419e-01, -5.4263e-01,  8.3691e-01,\n",
            "         -9.9827e-01,  7.2061e-01, -5.7262e-01, -5.1185e-01,  2.5483e-01,\n",
            "          7.2988e-01,  9.1171e-01, -9.9992e-01,  8.7016e-01, -6.8954e-01,\n",
            "          9.0024e-01, -4.9717e-01,  5.3782e-01,  5.0000e-01,  3.1083e-01,\n",
            "         -9.9685e-01,  8.1939e-01,  3.1607e-01,  8.0403e-01,  7.4146e-01,\n",
            "          7.7939e-01,  7.4635e-04, -8.7338e-01, -6.6957e-01,  9.8117e-01,\n",
            "          9.7249e-01, -6.5285e-01,  6.5531e-01,  9.9849e-01, -6.3204e-01,\n",
            "          5.5268e-01,  6.4574e-01,  1.1830e-01, -9.9899e-01, -8.2887e-01,\n",
            "         -2.1791e-01, -6.1376e-01, -8.1695e-01]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training... :   0%|          | 0/127 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "967af0dfa87e4eac911e6f0ab7415312"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5370,  0.3897, -0.9473,  ..., -0.8892,  0.1864,  0.4975],\n",
            "        [ 0.6979,  1.0000,  0.9445,  ...,  0.7215, -0.4887, -0.8946],\n",
            "        [ 0.7789,  0.9976,  0.8937,  ...,  0.7679, -0.8599, -0.4299],\n",
            "        ...,\n",
            "        [-0.6656,  0.9999, -0.8943,  ..., -0.8766,  0.1574, -0.2785],\n",
            "        [ 0.2916,  0.9694, -0.8235,  ..., -0.7666,  0.3746, -0.1648],\n",
            "        [ 0.7410,  0.9943,  0.7442,  ...,  0.8705, -0.6802, -0.4182]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5275, -0.9455, -0.9042,  ..., -0.8812,  0.1350,  0.4963],\n",
            "        [ 0.6322,  1.0000,  0.9801,  ...,  0.7473, -0.2277, -0.8785],\n",
            "        [-0.6006, -0.8679, -0.9497,  ..., -0.9335,  0.1625,  0.7704],\n",
            "        ...,\n",
            "        [-0.0651, -0.1687, -0.9244,  ..., -0.8737,  0.2775,  0.5141],\n",
            "        [ 0.6081,  0.9978,  0.6726,  ...,  0.9143, -0.8014, -0.2878],\n",
            "        [ 0.6186,  0.9995,  0.8483,  ...,  0.9600, -0.7324, -0.4591]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2151,  0.9965, -0.9271,  ..., -0.8771,  0.6528, -0.4290],\n",
            "        [ 0.5801,  0.9997,  0.7670,  ...,  0.8554, -0.7291, -0.7280],\n",
            "        [ 0.6706,  0.9995,  0.9167,  ...,  0.8003, -0.6525, -0.7787],\n",
            "        ...,\n",
            "        [ 0.7000,  1.0000,  0.9688,  ...,  0.8636, -0.2247, -0.8712],\n",
            "        [ 0.6651,  0.9993,  0.9078,  ...,  0.9153, -0.7510, -0.0959],\n",
            "        [ 0.6858,  0.9989,  0.8331,  ...,  0.8360, -0.8258, -0.3051]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5621,  0.9940,  0.7917,  ...,  0.9156, -0.7517, -0.3111],\n",
            "        [ 0.7037,  0.9998,  0.9177,  ...,  0.8240, -0.2756, -0.8080],\n",
            "        [ 0.6471,  0.9944,  0.7422,  ...,  0.8714, -0.6480, -0.2557],\n",
            "        ...,\n",
            "        [-0.1715,  0.9484, -0.9330,  ..., -0.8728,  0.4800, -0.2036],\n",
            "        [ 0.7354,  0.9999,  0.8362,  ...,  0.7240, -0.7281, -0.4872],\n",
            "        [-0.5214, -0.7704, -0.9328,  ..., -0.9403,  0.2280,  0.6264]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4854, -0.9944, -0.9645,  ..., -0.8808,  0.0700,  0.4918],\n",
            "        [ 0.7318,  1.0000,  0.9565,  ...,  0.7498, -0.0663, -0.8923],\n",
            "        [-0.6132, -0.7581, -0.9471,  ..., -0.9313,  0.3065,  0.6528],\n",
            "        ...,\n",
            "        [ 0.5034,  0.9999,  0.9194,  ...,  0.7826, -0.7562, -0.8045],\n",
            "        [ 0.6657,  0.9974,  0.7964,  ...,  0.8801, -0.7046, -0.1208],\n",
            "        [ 0.6113,  0.9999,  0.9179,  ...,  0.8548, -0.4411, -0.7488]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6972,  1.0000,  0.9451,  ...,  0.8089, -0.7076, -0.4937],\n",
            "        [ 0.2550,  0.9690,  0.8701,  ...,  0.6883, -0.7917, -0.1997],\n",
            "        [-0.5532, -0.2068, -0.8037,  ..., -0.9194,  0.2278,  0.2980],\n",
            "        ...,\n",
            "        [ 0.6294,  0.9984,  0.8289,  ...,  0.8452, -0.7887,  0.0109],\n",
            "        [-0.6352,  0.9828, -0.8829,  ..., -0.8638, -0.1111,  0.6316],\n",
            "        [-0.6693, -0.8995, -0.9285,  ..., -0.8814,  0.5998,  0.3045]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4836,  0.7586, -0.9608,  ..., -0.9290,  0.1276,  0.2667],\n",
            "        [ 0.7591,  0.9996,  0.9266,  ...,  0.8919, -0.6511, -0.6385],\n",
            "        [ 0.6858,  0.9992,  0.7764,  ...,  0.8995, -0.8096, -0.2853],\n",
            "        ...,\n",
            "        [ 0.7657,  1.0000,  0.9723,  ...,  0.8565, -0.4803, -0.7395],\n",
            "        [ 0.6463,  0.9971,  0.7679,  ...,  0.8898, -0.7999,  0.1801],\n",
            "        [-0.5302, -0.9625, -0.9538,  ..., -0.9357,  0.5023,  0.3407]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5397,  0.4297, -0.9594,  ..., -0.8532,  0.0061,  0.5066],\n",
            "        [ 0.6260,  0.9999,  0.8786,  ...,  0.8731, -0.8849, -0.4469],\n",
            "        [ 0.7430,  0.9998,  0.9207,  ...,  0.8587, -0.6795, -0.8146],\n",
            "        ...,\n",
            "        [-0.6209, -0.1888, -0.9595,  ..., -0.8726,  0.1597,  0.2449],\n",
            "        [-0.5763, -0.4253, -0.8822,  ..., -0.8660,  0.0866,  0.5639],\n",
            "        [-0.5417, -0.8991, -0.9507,  ..., -0.9069,  0.3693,  0.2749]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.7137, -0.6904, -0.9179,  ..., -0.8303,  0.0041,  0.3599],\n",
            "        [ 0.0270,  0.9993,  0.7524,  ...,  0.4681, -0.6027, -0.4412],\n",
            "        [-0.4046,  0.5730, -0.9017,  ..., -0.9424,  0.3953,  0.3308],\n",
            "        ...,\n",
            "        [-0.3117, -0.9305, -0.9642,  ..., -0.9008,  0.4596,  0.6004],\n",
            "        [ 0.6506,  0.9925,  0.8426,  ...,  0.8208, -0.7576, -0.2009],\n",
            "        [-0.4582, -0.9213, -0.9427,  ..., -0.8840,  0.2143,  0.4192]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7166,  0.9999,  0.8330,  ...,  0.7535, -0.6746, -0.6231],\n",
            "        [-0.1983,  0.8235, -0.9304,  ..., -0.7787,  0.5078,  0.3340],\n",
            "        [ 0.6585,  1.0000,  0.9432,  ...,  0.8265, -0.2739, -0.8225],\n",
            "        ...,\n",
            "        [ 0.6919,  0.9993,  0.8438,  ...,  0.7948, -0.5283, -0.6906],\n",
            "        [ 0.5450,  0.9983,  0.9121,  ...,  0.8710, -0.8659, -0.3552],\n",
            "        [ 0.8173,  1.0000,  0.8876,  ...,  0.8730, -0.6675, -0.5087]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5229, -1.0000, -0.9098,  ..., -0.8818,  0.1272,  0.7240],\n",
            "        [ 0.5592,  0.9985,  0.7600,  ...,  0.8458, -0.8282, -0.0851],\n",
            "        [-0.2446, -0.6428, -0.7500,  ..., -0.7535, -0.1686, -0.1831],\n",
            "        ...,\n",
            "        [ 0.7982,  1.0000,  0.9512,  ...,  0.8464,  0.2275, -0.9409],\n",
            "        [ 0.7620,  0.9998,  0.8466,  ...,  0.8727, -0.6772, -0.5270],\n",
            "        [-0.6681, -0.8556, -0.7549,  ..., -0.8248,  0.4100,  0.0355]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5634,  0.7417, -0.9150,  ..., -0.9265,  0.3271, -0.0651],\n",
            "        [-0.5044,  0.9991, -0.5866,  ..., -0.6919,  0.4524,  0.0421],\n",
            "        [-0.0522,  0.9257, -0.9008,  ..., -0.7130,  0.4355, -0.3633],\n",
            "        ...,\n",
            "        [ 0.4749,  1.0000,  0.8984,  ...,  0.6692, -0.2141, -0.7719],\n",
            "        [ 0.6758,  0.9993,  0.7286,  ...,  0.8467, -0.8403, -0.2698],\n",
            "        [ 0.7926,  0.9999,  0.8591,  ...,  0.8965, -0.6875, -0.3574]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6280,  0.9918,  0.7494,  ...,  0.9085, -0.8746, -0.0036],\n",
            "        [-0.0907,  0.6356, -0.9065,  ..., -0.8524,  0.1353,  0.4631],\n",
            "        [-0.5264, -0.2413, -0.9031,  ..., -0.8494,  0.3481,  0.6966],\n",
            "        ...,\n",
            "        [ 0.6969,  0.9999,  0.9192,  ...,  0.8894, -0.5886, -0.5554],\n",
            "        [ 0.8067,  0.9988,  0.8922,  ...,  0.8856, -0.7977, -0.6182],\n",
            "        [ 0.7214,  0.9844,  0.8906,  ...,  0.8832, -0.8058, -0.5796]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4689,  0.9998,  0.7004,  ...,  0.8492, -0.7910, -0.2209],\n",
            "        [ 0.1361,  0.9999, -0.6776,  ..., -0.8991,  0.4985, -0.3824],\n",
            "        [-0.4623, -0.9958, -0.9613,  ..., -0.9188,  0.0435,  0.5307],\n",
            "        ...,\n",
            "        [ 0.7657,  0.9982,  0.8525,  ...,  0.8821, -0.7574, -0.2362],\n",
            "        [-0.4388, -0.4543, -0.9496,  ..., -0.9188,  0.4763,  0.4736],\n",
            "        [ 0.8128,  0.9984,  0.8556,  ...,  0.7767, -0.5317, -0.3181]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6637,  0.9982,  0.7707,  ...,  0.8879, -0.7722, -0.2601],\n",
            "        [-0.2638, -0.9386, -0.9423,  ..., -0.8944,  0.2679,  0.5420],\n",
            "        [ 0.5774,  0.9978,  0.8399,  ...,  0.8605, -0.9256, -0.1320],\n",
            "        ...,\n",
            "        [-0.5600, -0.9731, -0.9251,  ..., -0.8777,  0.3397,  0.4731],\n",
            "        [-0.0771,  0.9936, -0.8377,  ..., -0.8174,  0.7562, -0.2799],\n",
            "        [ 0.5593,  0.9995,  0.9471,  ...,  0.8549, -0.7954, -0.7201]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5296,  0.9993,  0.8869,  ...,  0.8849, -0.7008, -0.3873],\n",
            "        [-0.4309,  0.9777, -0.9547,  ..., -0.8678,  0.1802,  0.5498],\n",
            "        [ 0.6427,  1.0000,  0.9609,  ...,  0.7582, -0.5929, -0.7790],\n",
            "        ...,\n",
            "        [-0.6238, -0.9966, -0.9604,  ..., -0.8904,  0.4319,  0.5735],\n",
            "        [-0.4042, -0.7381, -0.9411,  ..., -0.8695,  0.2230,  0.6757],\n",
            "        [-0.6841, -0.0919, -0.8736,  ..., -0.8147,  0.1723,  0.3559]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6758,  0.2692, -0.9147,  ..., -0.8108,  0.1595,  0.4000],\n",
            "        [ 0.7846,  0.9999, -0.6546,  ..., -0.5721,  0.6644, -0.7312],\n",
            "        [ 0.5951,  0.9818,  0.8592,  ...,  0.9451, -0.8145, -0.4527],\n",
            "        ...,\n",
            "        [ 0.7907,  0.9978,  0.8962,  ...,  0.8466, -0.7919, -0.4562],\n",
            "        [ 0.5250,  0.9852,  0.6775,  ...,  0.8522, -0.7068, -0.5517],\n",
            "        [ 0.0883,  1.0000,  0.5743,  ...,  0.1194,  0.6008, -0.7947]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4555,  0.9999, -0.7877,  ..., -0.7633,  0.6941, -0.5625],\n",
            "        [-0.6320, -0.9469, -0.9127,  ..., -0.8651,  0.5095,  0.2019],\n",
            "        [ 0.5220,  0.9955,  0.8805,  ...,  0.8858, -0.7136, -0.2146],\n",
            "        ...,\n",
            "        [-0.3489,  1.0000, -0.3617,  ..., -0.7280,  0.5676, -0.8753],\n",
            "        [ 0.3109,  0.9924,  0.9389,  ...,  0.8563, -0.8286, -0.1909],\n",
            "        [ 0.5866,  0.9989,  0.8867,  ...,  0.8775, -0.7985, -0.4479]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4032,  0.9947,  0.9098,  ...,  0.8572, -0.8196, -0.0128],\n",
            "        [ 0.6589,  0.9905,  0.8868,  ...,  0.8420, -0.8054, -0.1341],\n",
            "        [-0.4751, -0.4992, -0.8715,  ..., -0.9341, -0.0357,  0.6570],\n",
            "        ...,\n",
            "        [-0.4972,  0.9998,  0.1969,  ..., -0.7731,  0.1819, -0.8245],\n",
            "        [ 0.6799,  0.9996,  0.8593,  ...,  0.9115, -0.8089, -0.3233],\n",
            "        [ 0.8022,  0.9999,  0.6903,  ...,  0.7939, -0.6252, -0.7285]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6752, -0.3746, -0.9332,  ..., -0.8118,  0.1432,  0.4882],\n",
            "        [ 0.6463,  0.9976,  0.8662,  ...,  0.8577, -0.7841, -0.1464],\n",
            "        [ 0.5757,  0.9990,  0.8441,  ...,  0.8421, -0.8101, -0.3151],\n",
            "        ...,\n",
            "        [-0.3676, -0.0792, -0.8797,  ..., -0.7890,  0.4589,  0.4088],\n",
            "        [-0.3951,  0.9695, -0.9227,  ..., -0.6176,  0.2440,  0.3709],\n",
            "        [ 0.6292,  0.9852,  0.8894,  ...,  0.8773, -0.6936, -0.6088]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5997,  0.9963,  0.9022,  ...,  0.8953, -0.7984, -0.0806],\n",
            "        [ 0.4489,  0.9991,  0.8327,  ...,  0.8550, -0.8140, -0.3282],\n",
            "        [ 0.5371,  0.9958,  0.7737,  ...,  0.8637, -0.6443, -0.1235],\n",
            "        ...,\n",
            "        [-0.5330, -0.9935, -0.9299,  ..., -0.9170,  0.2769,  0.6807],\n",
            "        [-0.4893, -0.1598, -0.9605,  ..., -0.9530,  0.1409,  0.7020],\n",
            "        [ 0.8103,  1.0000,  0.9309,  ...,  0.8734, -0.4322, -0.8511]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5573,  0.2183, -0.9471,  ..., -0.8036,  0.4397,  0.5724],\n",
            "        [-0.5951,  0.9918, -0.9092,  ..., -0.8354,  0.6033, -0.2814],\n",
            "        [ 0.7096,  0.9996,  0.9257,  ...,  0.8492, -0.6998, -0.2399],\n",
            "        ...,\n",
            "        [-0.4059,  0.7773, -0.9067,  ..., -0.8740,  0.5155,  0.0284],\n",
            "        [ 0.5777,  0.9979,  0.8644,  ...,  0.8746, -0.7433, -0.1721],\n",
            "        [-0.5336,  0.1977, -0.8063,  ..., -0.8181,  0.2731, -0.1400]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7428,  0.9997,  0.8250,  ...,  0.8141, -0.7530, -0.3780],\n",
            "        [ 0.8176,  0.9946,  0.8558,  ...,  0.7937, -0.7025,  0.0524],\n",
            "        [ 0.7289,  1.0000, -0.2397,  ..., -0.6453,  0.7158, -0.5003],\n",
            "        ...,\n",
            "        [ 0.7321,  0.9998,  0.7843,  ...,  0.7308, -0.8544, -0.2598],\n",
            "        [-0.3232, -0.9202, -0.8924,  ..., -0.8354,  0.3183, -0.1855],\n",
            "        [ 0.4244,  0.9997,  0.7882,  ...,  0.8330, -0.7802, -0.5495]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2504,  0.0275, -0.9026,  ..., -0.8921,  0.2696,  0.4335],\n",
            "        [ 0.4591,  0.9967,  0.8449,  ...,  0.8487, -0.8111, -0.2756],\n",
            "        [ 0.5970,  1.0000,  0.9154,  ...,  0.2344,  0.4026, -0.9791],\n",
            "        ...,\n",
            "        [-0.3953, -0.6487, -0.8749,  ..., -0.7614,  0.4463,  0.1642],\n",
            "        [ 0.4879,  0.9985,  0.8845,  ...,  0.8344, -0.7842, -0.2520],\n",
            "        [ 0.5909,  0.9988,  0.9002,  ...,  0.9152, -0.7173, -0.4600]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1761,  0.9413,  0.8211,  ...,  0.7727, -0.8482, -0.2010],\n",
            "        [ 0.6951,  0.9995,  0.9427,  ...,  0.8715, -0.6050, -0.4963],\n",
            "        [-0.6505, -0.9853, -0.9478,  ..., -0.8865,  0.0630,  0.6810],\n",
            "        ...,\n",
            "        [-0.2520, -0.7260, -0.6445,  ..., -0.8789,  0.5589,  0.0886],\n",
            "        [ 0.7366,  0.9996,  0.8579,  ...,  0.8452, -0.7757, -0.2625],\n",
            "        [ 0.5144,  0.9978,  0.8310,  ...,  0.9234, -0.8498, -0.2326]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6044,  0.9196, -0.9388,  ..., -0.9293,  0.0883,  0.2584],\n",
            "        [ 0.6927,  0.9992,  0.8555,  ...,  0.8988, -0.8068, -0.2258],\n",
            "        [ 0.5833,  0.9988,  0.7805,  ...,  0.8284, -0.7679, -0.3577],\n",
            "        ...,\n",
            "        [-0.6793,  0.3172, -0.8095,  ..., -0.6605,  0.0147, -0.4111],\n",
            "        [ 0.5674,  0.9996,  0.9251,  ...,  0.8428, -0.7903, -0.4883],\n",
            "        [-0.1687,  0.9021, -0.8414,  ..., -0.8873,  0.5957,  0.4344]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4920, -0.8963, -0.9627,  ..., -0.9212,  0.2078,  0.6291],\n",
            "        [ 0.5240,  0.9881,  0.8331,  ...,  0.9008, -0.8655, -0.2167],\n",
            "        [ 0.6572,  0.9999,  0.8741,  ...,  0.7202, -0.7446, -0.3227],\n",
            "        ...,\n",
            "        [-0.0362,  0.9996, -0.6843,  ..., -0.5472,  0.2419, -0.4430],\n",
            "        [-0.7452,  0.0125, -0.9358,  ..., -0.9413,  0.2843,  0.4569],\n",
            "        [-0.6402,  0.9933, -0.8673,  ..., -0.8420,  0.3949,  0.5719]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6406,  0.4597, -0.8344,  ..., -0.7879,  0.2318,  0.1684],\n",
            "        [-0.6910, -0.9715, -0.9415,  ..., -0.9042,  0.3679,  0.4284],\n",
            "        [ 0.1065,  0.9883, -0.4242,  ..., -0.8067,  0.4030, -0.6907],\n",
            "        ...,\n",
            "        [ 0.4002,  0.9756,  0.8379,  ...,  0.8941, -0.8012,  0.0257],\n",
            "        [-0.3498, -0.9415, -0.8533,  ..., -0.8222,  0.6842,  0.2976],\n",
            "        [-0.4810,  0.9347, -0.9025,  ..., -0.8415,  0.1198,  0.5214]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4995,  0.9934,  0.8155,  ...,  0.8546, -0.6401, -0.0515],\n",
            "        [ 0.5979,  0.9981,  0.8540,  ...,  0.7959, -0.7820, -0.2834],\n",
            "        [ 0.5181,  0.9964,  0.8501,  ...,  0.8585, -0.8465, -0.3172],\n",
            "        ...,\n",
            "        [-0.7584, -0.7690, -0.9260,  ..., -0.9289,  0.2146,  0.7173],\n",
            "        [ 0.4642,  0.9986,  0.9014,  ...,  0.9167, -0.7941, -0.5111],\n",
            "        [ 0.5188,  0.9992,  0.8824,  ...,  0.9007, -0.6075, -0.2527]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6147,  0.9998,  0.8051,  ...,  0.8560, -0.8006, -0.3728],\n",
            "        [ 0.6179,  0.9984,  0.8020,  ...,  0.7780, -0.8605, -0.2817],\n",
            "        [ 0.2570,  0.9977, -0.8662,  ..., -0.9210,  0.5092, -0.4219],\n",
            "        ...,\n",
            "        [ 0.7467,  0.9996,  0.9110,  ...,  0.8965, -0.7889, -0.6240],\n",
            "        [-0.6194, -0.9736, -0.9247,  ..., -0.9065,  0.3194,  0.4199],\n",
            "        [ 0.7852,  1.0000,  0.9096,  ...,  0.8492, -0.0440, -0.9074]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5832, -0.9947, -0.9572,  ..., -0.9290,  0.2830,  0.6273],\n",
            "        [-0.2906, -0.3825, -0.8857,  ..., -0.8047,  0.0126,  0.3244],\n",
            "        [ 0.7883,  0.9999,  0.8640,  ...,  0.9170, -0.6283, -0.5293],\n",
            "        ...,\n",
            "        [-0.6255, -0.9969, -0.9187,  ..., -0.9405,  0.2008,  0.7403],\n",
            "        [ 0.7928,  0.9979,  0.9238,  ...,  0.9186, -0.7017, -0.5152],\n",
            "        [-0.7217, -0.6001, -0.9260,  ..., -0.9170,  0.1923,  0.5959]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4621,  0.9949,  0.8510,  ...,  0.8999, -0.8843, -0.1192],\n",
            "        [ 0.6034,  0.9991,  0.9072,  ...,  0.8948, -0.6961, -0.2756],\n",
            "        [-0.1355,  0.9238, -0.8325,  ..., -0.9176,  0.5211,  0.2774],\n",
            "        ...,\n",
            "        [-0.5585,  0.9976, -0.8780,  ..., -0.6028,  0.4352,  0.1158],\n",
            "        [ 0.3886,  0.9965,  0.8606,  ...,  0.8335, -0.7793, -0.3003],\n",
            "        [ 0.7618,  0.9984,  0.9317,  ...,  0.8800, -0.6972, -0.5751]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6708,  0.9997,  0.8766,  ...,  0.8526, -0.7461, -0.3332],\n",
            "        [-0.4207,  0.8895, -0.9472,  ..., -0.8644,  0.3272,  0.5132],\n",
            "        [ 0.5961,  0.9988,  0.9259,  ...,  0.8842, -0.7676, -0.3975],\n",
            "        ...,\n",
            "        [ 0.8010,  0.9999,  0.8468,  ...,  0.8912, -0.6655, -0.5256],\n",
            "        [-0.2018,  0.4186, -0.9165,  ..., -0.8821,  0.2469,  0.1975],\n",
            "        [-0.5042, -0.1870, -0.9641,  ..., -0.9013,  0.2654,  0.6347]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3545, -0.8112, -0.9528,  ..., -0.8796, -0.1948,  0.7880],\n",
            "        [-0.7065, -0.9631, -0.9173,  ..., -0.8328,  0.1035,  0.6914],\n",
            "        [ 0.6732,  0.9982,  0.8143,  ...,  0.9115, -0.7749, -0.3524],\n",
            "        ...,\n",
            "        [-0.5345,  0.2216, -0.8573,  ..., -0.9142,  0.5034,  0.1952],\n",
            "        [ 0.7747,  0.9999,  0.9408,  ...,  0.8816, -0.7617, -0.6467],\n",
            "        [ 0.4143,  0.9923,  0.8155,  ...,  0.8331, -0.8702, -0.0808]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5361,  0.9985,  0.9018,  ...,  0.8746, -0.8465, -0.6108],\n",
            "        [ 0.6854,  0.9997,  0.8687,  ...,  0.8659, -0.7704, -0.3325],\n",
            "        [ 0.8105,  0.9988,  0.7875,  ...,  0.9179, -0.8333, -0.4583],\n",
            "        ...,\n",
            "        [-0.6628, -0.9895, -0.9558,  ..., -0.8982, -0.0129,  0.8007],\n",
            "        [-0.0979,  0.9990, -0.7604,  ..., -0.8066,  0.7634, -0.0526],\n",
            "        [ 0.7895,  0.9999,  0.9218,  ...,  0.8514, -0.6212, -0.6189]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4780, -0.7773, -0.9429,  ..., -0.8655,  0.1067,  0.4970],\n",
            "        [-0.4041, -0.4520, -0.9282,  ..., -0.8842,  0.4819,  0.7291],\n",
            "        [ 0.6978,  0.9973,  0.8450,  ...,  0.8135, -0.8148, -0.5187],\n",
            "        ...,\n",
            "        [ 0.7677,  0.9972,  0.9014,  ...,  0.8883, -0.7452, -0.0734],\n",
            "        [-0.5575,  0.9909, -0.9439,  ..., -0.9181, -0.0951,  0.6388],\n",
            "        [-0.6477, -0.9455, -0.9683,  ..., -0.8588,  0.4994,  0.5243]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6270,  0.9689, -0.8304,  ..., -0.8568,  0.4703,  0.4957],\n",
            "        [ 0.7523,  0.9969,  0.8422,  ...,  0.9118, -0.8311, -0.4657],\n",
            "        [-0.6052,  0.9998, -0.7696,  ..., -0.7476,  0.4310,  0.0137],\n",
            "        ...,\n",
            "        [ 0.7279,  0.9992,  0.8717,  ...,  0.9326, -0.7489, -0.3711],\n",
            "        [ 0.6535,  0.9985,  0.8490,  ...,  0.8148, -0.8229, -0.4660],\n",
            "        [ 0.7541,  0.9995,  0.8442,  ...,  0.8608, -0.4784, -0.4033]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6389,  0.9640,  0.8780,  ...,  0.8245, -0.8782, -0.0705],\n",
            "        [ 0.5581,  0.9996,  0.7644,  ...,  0.8547, -0.7973, -0.1804],\n",
            "        [ 0.6412,  0.9994,  0.8458,  ...,  0.8340, -0.7981, -0.4646],\n",
            "        ...,\n",
            "        [-0.6128, -0.9381, -0.9349,  ..., -0.9189,  0.1352,  0.6236],\n",
            "        [ 0.3509,  0.9797, -0.8674,  ..., -0.9136,  0.7887, -0.1298],\n",
            "        [-0.2564,  0.9972, -0.9195,  ..., -0.9372,  0.1590, -0.0786]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2863, -0.8083, -0.9630,  ..., -0.9227,  0.4556, -0.0717],\n",
            "        [-0.3054,  0.9999, -0.4004,  ..., -0.8213, -0.0649, -0.4307],\n",
            "        [ 0.5646,  0.9904,  0.8986,  ...,  0.9106, -0.8150, -0.2948],\n",
            "        ...,\n",
            "        [ 0.7318,  0.9988,  0.8996,  ...,  0.8720, -0.7785, -0.3560],\n",
            "        [ 0.6521,  0.9990,  0.8474,  ...,  0.8801, -0.8232, -0.2968],\n",
            "        [ 0.3282,  0.9982,  0.8990,  ...,  0.8166, -0.8023, -0.3922]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7769,  1.0000,  0.9351,  ...,  0.7448, -0.1931, -0.9102],\n",
            "        [ 0.5727,  0.9919,  0.8984,  ...,  0.8329, -0.8487,  0.0790],\n",
            "        [ 0.4324,  0.9796,  0.9260,  ...,  0.8503, -0.7283, -0.3150],\n",
            "        ...,\n",
            "        [-0.5622,  0.6405, -0.9466,  ..., -0.9321,  0.3180,  0.0740],\n",
            "        [ 0.7125,  0.9982,  0.8791,  ...,  0.9017, -0.7705, -0.2688],\n",
            "        [-0.3487, -0.8870, -0.9697,  ..., -0.9189,  0.2817,  0.4717]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5863,  0.9997,  0.9058,  ...,  0.8921, -0.6162, -0.6602],\n",
            "        [-0.2718, -0.9384, -0.9603,  ..., -0.8712,  0.3569,  0.4061],\n",
            "        [ 0.6806,  0.9995, -0.7896,  ..., -0.8834,  0.8287, -0.5768],\n",
            "        ...,\n",
            "        [ 0.6962,  0.9999,  0.9441,  ...,  0.7870, -0.6419, -0.5946],\n",
            "        [ 0.4638,  0.9988,  0.9148,  ...,  0.9265, -0.6771, -0.4050],\n",
            "        [ 0.3866,  0.9990,  0.8061,  ...,  0.8846, -0.7209, -0.0361]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7210,  0.9999,  0.9525,  ...,  0.8527, -0.6157, -0.6034],\n",
            "        [ 0.2055,  0.9999, -0.3973,  ..., -0.3471,  0.3805, -0.4354],\n",
            "        [-0.3006, -0.9878, -0.8945,  ..., -0.8553,  0.4710,  0.2035],\n",
            "        ...,\n",
            "        [ 0.6688,  0.9632,  0.7640,  ...,  0.8734, -0.8617, -0.1943],\n",
            "        [ 0.5807,  0.9939,  0.7786,  ...,  0.8660, -0.9056, -0.2196],\n",
            "        [ 0.6278,  0.9998,  0.9285,  ...,  0.8151, -0.8358, -0.3960]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6373,  0.9988,  0.8468,  ...,  0.8499, -0.8105, -0.3904],\n",
            "        [ 0.5279,  0.9943,  0.8612,  ...,  0.8266, -0.8733, -0.5149],\n",
            "        [ 0.5521,  0.9979,  0.8759,  ...,  0.7180, -0.6807, -0.3481],\n",
            "        ...,\n",
            "        [ 0.5640,  0.9990, -0.6243,  ..., -0.6344,  0.7095, -0.3899],\n",
            "        [-0.5892, -0.9277, -0.9490,  ..., -0.9172,  0.0885,  0.6151],\n",
            "        [-0.5267, -0.9969, -0.9425,  ..., -0.8532,  0.2459,  0.6809]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5425,  0.9993,  0.7246,  ...,  0.7722, -0.7048, -0.3801],\n",
            "        [ 0.7514,  0.9991,  0.9201,  ...,  0.8027, -0.7757, -0.6834],\n",
            "        [ 0.5397,  0.9992,  0.8747,  ...,  0.8302, -0.6532, -0.5724],\n",
            "        ...,\n",
            "        [-0.6430, -0.1457, -0.9140,  ..., -0.8661,  0.3331,  0.4338],\n",
            "        [ 0.6958,  0.9989,  0.7115,  ...,  0.8514, -0.8218, -0.1616],\n",
            "        [-0.4726, -0.2783, -0.8966,  ..., -0.8939,  0.2749,  0.3843]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6932,  0.9996,  0.9218,  ...,  0.9102, -0.7414, -0.3882],\n",
            "        [ 0.8644,  1.0000,  0.9459,  ...,  0.5212,  0.2428, -0.8467],\n",
            "        [-0.4720, -0.9541, -0.9288,  ..., -0.9257,  0.4282,  0.4130],\n",
            "        ...,\n",
            "        [ 0.5880,  0.9962,  0.7795,  ...,  0.8555, -0.8377, -0.3389],\n",
            "        [-0.6494, -0.3542, -0.9555,  ..., -0.9215, -0.0819,  0.5552],\n",
            "        [ 0.5736,  0.9947,  0.8383,  ...,  0.8760, -0.7013, -0.2424]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6110, -0.9397, -0.9484,  ..., -0.8677,  0.2364,  0.5776],\n",
            "        [ 0.5372,  0.9523,  0.7641,  ...,  0.8395, -0.8765, -0.2766],\n",
            "        [ 0.5036,  0.9999,  0.9225,  ...,  0.6067, -0.6686, -0.0505],\n",
            "        ...,\n",
            "        [ 0.5504,  0.9997,  0.7911,  ...,  0.8168, -0.6291, -0.6569],\n",
            "        [-0.6187,  0.8055, -0.8425,  ..., -0.9174,  0.0564, -0.0037],\n",
            "        [-0.1844,  0.9808, -0.9443,  ..., -0.7626,  0.4163, -0.0100]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5564,  0.9916,  0.8549,  ...,  0.7961, -0.8438,  0.1472],\n",
            "        [ 0.5603,  0.9980,  0.8625,  ...,  0.8909, -0.8784, -0.1092],\n",
            "        [-0.6494, -0.9984, -0.9642,  ..., -0.9098,  0.0103,  0.7328],\n",
            "        ...,\n",
            "        [-0.6456, -0.6856, -0.8958,  ..., -0.9247,  0.2529,  0.5055],\n",
            "        [ 0.5713,  0.9977,  0.8442,  ...,  0.8448, -0.8630, -0.3507],\n",
            "        [-0.1316, -0.0873, -0.8886,  ..., -0.8317,  0.2655,  0.3043]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4605, -0.9973, -0.9298,  ..., -0.9458,  0.1232,  0.5140],\n",
            "        [ 0.6724,  0.8952,  0.8403,  ...,  0.8805, -0.8601, -0.3576],\n",
            "        [-0.4001, -0.9231, -0.9484,  ..., -0.9080,  0.2888,  0.5428],\n",
            "        ...,\n",
            "        [ 0.4989,  0.9962,  0.8196,  ...,  0.9005, -0.8836, -0.4170],\n",
            "        [ 0.6113,  0.9989,  0.8621,  ...,  0.8667, -0.7827, -0.5063],\n",
            "        [ 0.5976,  0.9997,  0.9071,  ...,  0.9070, -0.8051, -0.3987]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6442, -0.9055, -0.9317,  ..., -0.8539,  0.1585,  0.7246],\n",
            "        [ 0.6651,  0.9579,  0.7658,  ...,  0.9236, -0.8647, -0.1745],\n",
            "        [ 0.6025,  0.9977,  0.8110,  ...,  0.7941, -0.8260, -0.4117],\n",
            "        ...,\n",
            "        [ 0.6166,  0.9643,  0.8914,  ...,  0.8308, -0.7931, -0.3482],\n",
            "        [-0.7496, -0.9133, -0.9113,  ..., -0.7639,  0.1708,  0.7687],\n",
            "        [-0.4576,  0.9502, -0.9058,  ..., -0.9305,  0.3885,  0.5585]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.8287, -0.5456, -0.8808,  ..., -0.8985,  0.2177,  0.5101],\n",
            "        [ 0.4707,  0.9768,  0.7311,  ...,  0.8983, -0.8635, -0.2438],\n",
            "        [ 0.7198,  0.9997,  0.8266,  ...,  0.8397, -0.7153, -0.1829],\n",
            "        ...,\n",
            "        [ 0.7542,  0.9987,  0.9092,  ...,  0.9269, -0.7558, -0.4243],\n",
            "        [ 0.7425,  0.9986,  0.6971,  ...,  0.8510, -0.8816, -0.5466],\n",
            "        [ 0.6414,  0.9984,  0.8898,  ...,  0.9004, -0.7856, -0.5087]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.8417,  0.5280, -0.7959,  ..., -0.7276,  0.1505,  0.8513],\n",
            "        [ 0.2528,  0.9985,  0.7097,  ...,  0.7863, -0.8641, -0.1932],\n",
            "        [-0.5692,  0.9012, -0.9071,  ..., -0.8824,  0.3726,  0.2262],\n",
            "        ...,\n",
            "        [-0.5153, -0.3862, -0.9203,  ..., -0.8746,  0.3385,  0.4715],\n",
            "        [-0.4480, -0.9005, -0.9651,  ..., -0.9070,  0.2283,  0.6573],\n",
            "        [-0.5143, -0.9485, -0.9187,  ..., -0.8289,  0.0804,  0.5802]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7525,  0.9965,  0.7245,  ...,  0.8185, -0.6473, -0.4535],\n",
            "        [-0.5875, -0.9994, -0.9565,  ..., -0.8884,  0.3746,  0.6353],\n",
            "        [-0.6791,  0.3912, -0.9324,  ..., -0.8729,  0.2338,  0.5221],\n",
            "        ...,\n",
            "        [-0.7015, -0.9623, -0.9273,  ..., -0.8819,  0.3855,  0.6738],\n",
            "        [ 0.6523,  0.9939,  0.8334,  ...,  0.9136, -0.8108, -0.0990],\n",
            "        [ 0.4491,  0.9983,  0.8942,  ...,  0.9200, -0.7791, -0.1213]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6111,  0.9910,  0.8719,  ...,  0.9164, -0.7665, -0.2494],\n",
            "        [ 0.6535,  0.9995,  0.8463,  ...,  0.9353, -0.8251, -0.2293],\n",
            "        [ 0.0634,  0.9659, -0.9001,  ..., -0.8591,  0.5442,  0.0581],\n",
            "        ...,\n",
            "        [ 0.6714,  0.9810,  0.8594,  ...,  0.8994, -0.8340, -0.3932],\n",
            "        [-0.5360, -0.1599, -0.9066,  ..., -0.8568,  0.3744,  0.7219],\n",
            "        [-0.6351, -0.4422, -0.9370,  ..., -0.8655,  0.2760,  0.5497]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6029, -0.5510, -0.9533,  ..., -0.8992,  0.0738,  0.6573],\n",
            "        [ 0.6499,  0.9941,  0.8341,  ...,  0.9078, -0.8195, -0.3343],\n",
            "        [ 0.5886,  0.9934,  0.7561,  ...,  0.8496, -0.8383, -0.2104],\n",
            "        ...,\n",
            "        [ 0.4584,  0.9999,  0.7967,  ...,  0.6020, -0.8864, -0.5254],\n",
            "        [ 0.6747,  0.9887,  0.8641,  ...,  0.8407, -0.7546, -0.2467],\n",
            "        [-0.6061, -0.8888, -0.9489,  ..., -0.8939,  0.1859,  0.6446]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6499,  0.9988,  0.8544,  ...,  0.7815, -0.8216, -0.6069],\n",
            "        [ 0.6734,  0.9705,  0.7728,  ...,  0.8729, -0.8130, -0.3792],\n",
            "        [-0.6679, -0.7381, -0.9534,  ..., -0.8753,  0.1973,  0.6999],\n",
            "        ...,\n",
            "        [-0.3831, -0.9565, -0.9377,  ..., -0.8349,  0.0425,  0.6049],\n",
            "        [-0.7137, -0.9910, -0.8875,  ..., -0.8978,  0.0835,  0.6050],\n",
            "        [-0.4984, -0.9983, -0.9504,  ..., -0.8743,  0.2145,  0.6688]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6002,  0.9753,  0.8984,  ...,  0.8259, -0.8371, -0.3166],\n",
            "        [-0.5519,  0.1898, -0.8878,  ..., -0.9361,  0.2399,  0.2977],\n",
            "        [ 0.4052,  0.9864,  0.8072,  ...,  0.8589, -0.8666, -0.1388],\n",
            "        ...,\n",
            "        [ 0.6511,  0.9992,  0.8139,  ...,  0.7400, -0.7927, -0.5563],\n",
            "        [-0.7174, -0.8981, -0.9043,  ..., -0.8776,  0.1262,  0.6757],\n",
            "        [ 0.5300,  0.9976,  0.7239,  ...,  0.8883, -0.8054, -0.3969]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6076,  0.9969,  0.7849,  ...,  0.8761, -0.9011, -0.1763],\n",
            "        [ 0.7301,  0.9980,  0.7094,  ...,  0.9201, -0.8597, -0.2638],\n",
            "        [ 0.5194,  0.9971,  0.8627,  ...,  0.8727, -0.8137, -0.3897],\n",
            "        ...,\n",
            "        [ 0.4851,  1.0000,  0.8940,  ...,  0.8504, -0.7010, -0.5037],\n",
            "        [ 0.6391,  0.9919,  0.7797,  ...,  0.9193, -0.8249, -0.1383],\n",
            "        [-0.5173,  0.5067, -0.9488,  ..., -0.8638,  0.2548,  0.3609]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0623,  0.9967, -0.8398,  ..., -0.8649,  0.1092, -0.1018],\n",
            "        [ 0.6462,  0.9962,  0.9259,  ...,  0.9007, -0.8197, -0.5226],\n",
            "        [-0.5234, -0.7450, -0.9604,  ..., -0.8434,  0.2237,  0.6410],\n",
            "        ...,\n",
            "        [-0.6496,  0.6514, -0.9503,  ..., -0.9079, -0.1985,  0.6854],\n",
            "        [ 0.7164,  0.9974,  0.8305,  ...,  0.6285, -0.8657, -0.4866],\n",
            "        [ 0.5850,  1.0000,  0.9389,  ...,  0.4802, -0.0405, -0.9747]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0747,  0.2861, -0.7502,  ..., -0.7369,  0.6045,  0.1695],\n",
            "        [-0.4047,  0.8597, -0.9312,  ..., -0.8755,  0.0563,  0.5631],\n",
            "        [ 0.4217,  0.9865,  0.7453,  ...,  0.8923, -0.9166, -0.0502],\n",
            "        ...,\n",
            "        [-0.6034, -0.8898, -0.9190,  ..., -0.9067,  0.0411,  0.5454],\n",
            "        [ 0.6880,  0.9998,  0.8380,  ...,  0.7954, -0.6537, -0.2624],\n",
            "        [-0.3441, -0.5196, -0.9377,  ..., -0.9041,  0.3972,  0.4313]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3918,  1.0000,  0.8844,  ...,  0.7942, -0.4869, -0.5006],\n",
            "        [-0.5062, -0.4336, -0.9025,  ..., -0.9254, -0.1889,  0.5395],\n",
            "        [ 0.3785,  0.9999,  0.7710,  ...,  0.8406, -0.7556, -0.4924],\n",
            "        ...,\n",
            "        [ 0.6890,  0.9927,  0.7483,  ...,  0.8972, -0.8166, -0.2230],\n",
            "        [ 0.6150,  0.9999,  0.8947,  ...,  0.8374, -0.5128, -0.5724],\n",
            "        [ 0.7099,  0.9995,  0.9127,  ...,  0.7800, -0.7922, -0.6664]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.8544,  0.9987,  0.6788,  ...,  0.9197, -0.7249, -0.6134],\n",
            "        [-0.7718, -0.8996, -0.8693,  ..., -0.8264, -0.0509,  0.6820],\n",
            "        [-0.7878, -0.7268, -0.9275,  ..., -0.9099, -0.0792,  0.6705],\n",
            "        ...,\n",
            "        [-0.2489,  0.9057, -0.8459,  ..., -0.8851,  0.1923,  0.1930],\n",
            "        [-0.5298, -0.9397, -0.9603,  ..., -0.8071,  0.1688,  0.6710],\n",
            "        [-0.6175,  0.2385, -0.9307,  ..., -0.9258,  0.2188,  0.6726]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5257,  0.9757, -0.6336,  ..., -0.8749,  0.1501, -0.6283],\n",
            "        [-0.6788, -0.9996, -0.9279,  ..., -0.8506,  0.2173,  0.7839],\n",
            "        [-0.4335,  0.8235, -0.9331,  ..., -0.9074,  0.0605,  0.4189],\n",
            "        ...,\n",
            "        [ 0.7531,  0.9985,  0.8393,  ...,  0.8203, -0.8196, -0.1443],\n",
            "        [ 0.5356,  0.9991,  0.8382,  ...,  0.8652, -0.8604, -0.3977],\n",
            "        [-0.4097, -0.7264, -0.9623,  ..., -0.9181, -0.2110,  0.3311]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4993,  0.9941,  0.8580,  ...,  0.8873, -0.8685, -0.1091],\n",
            "        [-0.6001, -0.8115, -0.9380,  ..., -0.9006,  0.3041,  0.6708],\n",
            "        [ 0.6521,  0.9894,  0.7820,  ...,  0.8556, -0.7659, -0.3141],\n",
            "        ...,\n",
            "        [ 0.6142,  0.9964,  0.8721,  ...,  0.8728, -0.7472, -0.2652],\n",
            "        [-0.5319, -0.9231, -0.9032,  ..., -0.7897,  0.3092,  0.4695],\n",
            "        [ 0.6818,  0.9893,  0.9084,  ...,  0.8825, -0.8033, -0.2117]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6098,  1.0000,  0.9421,  ...,  0.9076, -0.5276, -0.6408],\n",
            "        [-0.5416,  0.4027, -0.9282,  ..., -0.7436,  0.5631, -0.1726],\n",
            "        [ 0.7059,  0.9984,  0.8564,  ...,  0.8828, -0.7497, -0.3583],\n",
            "        ...,\n",
            "        [ 0.7195,  0.9998,  0.9503,  ...,  0.8430, -0.6254, -0.6774],\n",
            "        [-0.3491, -0.0923, -0.9532,  ..., -0.8867,  0.4411,  0.4703],\n",
            "        [ 0.1834, -0.1834, -0.7642,  ..., -0.8463,  0.3992,  0.2062]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5738,  0.9989,  0.8080,  ...,  0.8621, -0.7576, -0.6717],\n",
            "        [ 0.6858,  0.9994,  0.8795,  ...,  0.8954, -0.8562, -0.3543],\n",
            "        [-0.7580, -0.7727, -0.9348,  ..., -0.9005,  0.1433,  0.5390],\n",
            "        ...,\n",
            "        [-0.6109, -0.6188, -0.9540,  ..., -0.9118,  0.0906,  0.5801],\n",
            "        [-0.4140, -0.6481, -0.9382,  ..., -0.8749,  0.2785,  0.5933],\n",
            "        [ 0.6567,  1.0000,  0.7555,  ...,  0.3888, -0.3460, -0.7956]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6604,  0.9979,  0.8799,  ...,  0.9295, -0.7401, -0.4132],\n",
            "        [-0.5518,  0.5689, -0.9228,  ..., -0.8914, -0.1207,  0.6248],\n",
            "        [-0.6150, -0.9598, -0.9106,  ..., -0.9445,  0.3188,  0.8394],\n",
            "        ...,\n",
            "        [ 0.5653,  0.9901,  0.8151,  ...,  0.7719, -0.7763, -0.4317],\n",
            "        [ 0.7474,  0.9996,  0.8882,  ...,  0.9243, -0.6572, -0.6459],\n",
            "        [ 0.7404,  0.9976,  0.8523,  ...,  0.8452, -0.6909, -0.5194]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5639,  0.9905,  0.8138,  ...,  0.8871, -0.8484, -0.1848],\n",
            "        [ 0.3609,  0.9994,  0.8647,  ...,  0.8875, -0.6732, -0.4699],\n",
            "        [-0.7284,  0.4323, -0.9212,  ..., -0.9181,  0.4336,  0.4020],\n",
            "        ...,\n",
            "        [-0.4939,  0.9114, -0.9095,  ..., -0.7660,  0.2976,  0.6499],\n",
            "        [ 0.7800,  0.9983,  0.7012,  ...,  0.8726, -0.6526, -0.2717],\n",
            "        [ 0.7193,  1.0000,  0.9098,  ...,  0.9211, -0.3982, -0.8655]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.7079,  0.9782, -0.9237,  ..., -0.9299,  0.4017,  0.1638],\n",
            "        [ 0.7825,  1.0000,  0.7319,  ...,  0.8374, -0.7293, -0.4240],\n",
            "        [-0.6318, -0.9876, -0.9178,  ..., -0.8716,  0.0817,  0.8017],\n",
            "        ...,\n",
            "        [ 0.7128,  0.9997,  0.9106,  ...,  0.8800, -0.7471, -0.5809],\n",
            "        [ 0.6415,  0.9998,  0.7929,  ...,  0.8093, -0.7816, -0.5720],\n",
            "        [ 0.5438,  0.9898,  0.7651,  ...,  0.8587, -0.8341, -0.1459]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5322, -0.4283, -0.8746,  ..., -0.8812,  0.2448,  0.2954],\n",
            "        [ 0.5182,  0.9978,  0.7617,  ...,  0.7888, -0.8387, -0.5184],\n",
            "        [-0.7109, -0.0228, -0.8946,  ..., -0.8382,  0.5471,  0.6284],\n",
            "        ...,\n",
            "        [ 0.4719,  0.9997,  0.9124,  ...,  0.8506, -0.8114, -0.4242],\n",
            "        [ 0.5546,  0.9999,  0.7556,  ...,  0.6096, -0.5037, -0.7965],\n",
            "        [-0.6213, -0.0541, -0.9472,  ..., -0.9105,  0.2960,  0.4992]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7362,  0.9724,  0.8912,  ...,  0.9290, -0.7794, -0.2989],\n",
            "        [ 0.6884,  1.0000,  0.9612,  ...,  0.7756, -0.3279, -0.8789],\n",
            "        [-0.5835,  0.5765, -0.9246,  ..., -0.8889,  0.5082,  0.4925],\n",
            "        ...,\n",
            "        [-0.5326, -0.5844, -0.9189,  ..., -0.7914,  0.1160,  0.7676],\n",
            "        [ 0.5971,  0.9924,  0.5642,  ...,  0.7482, -0.8455,  0.1245],\n",
            "        [-0.6479, -0.4228, -0.9294,  ..., -0.8469,  0.1228,  0.4879]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7464,  0.9861,  0.9109,  ...,  0.7744, -0.7523, -0.6583],\n",
            "        [ 0.7413,  0.9969,  0.8725,  ...,  0.9242, -0.8206, -0.2382],\n",
            "        [ 0.5815,  0.9999,  0.9430,  ...,  0.7613, -0.5471, -0.6552],\n",
            "        ...,\n",
            "        [-0.4218, -0.9848, -0.8868,  ..., -0.8400,  0.6667,  0.1985],\n",
            "        [-0.5101,  0.8098, -0.9310,  ..., -0.9057,  0.3893,  0.2083],\n",
            "        [ 0.6342,  0.9985,  0.8392,  ...,  0.8186, -0.7222, -0.5906]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6866,  1.0000, -0.7640,  ..., -0.7002,  0.7905, -0.7842],\n",
            "        [-0.7448, -0.5023, -0.9374,  ..., -0.8833,  0.1695,  0.8395],\n",
            "        [-0.4194,  0.6551, -0.8908,  ..., -0.9019,  0.4343,  0.4742],\n",
            "        ...,\n",
            "        [-0.1425, -0.6784, -0.9420,  ..., -0.8813,  0.5687,  0.4973],\n",
            "        [ 0.4041,  0.9746,  0.8041,  ...,  0.8018, -0.8540, -0.2956],\n",
            "        [-0.7990, -0.7596, -0.9173,  ..., -0.8926, -0.0968,  0.8442]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7183,  0.9942,  0.8661,  ...,  0.8831, -0.8193, -0.2402],\n",
            "        [ 0.6407,  0.9974,  0.7985,  ...,  0.9071, -0.8260, -0.1970],\n",
            "        [-0.3324,  0.1275, -0.9017,  ..., -0.8665,  0.1042,  0.7107],\n",
            "        ...,\n",
            "        [ 0.6924,  0.9998,  0.8581,  ...,  0.8051, -0.6405, -0.2705],\n",
            "        [ 0.5367,  0.9995,  0.7923,  ...,  0.8738, -0.8100, -0.2265],\n",
            "        [ 0.5439,  0.9973,  0.8351,  ...,  0.8214, -0.7675, -0.3008]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7773,  0.9977,  0.9119,  ...,  0.8723, -0.7383, -0.2627],\n",
            "        [-0.1944,  0.9977, -0.7789,  ..., -0.8663,  0.3642, -0.4956],\n",
            "        [ 0.6693,  0.9975,  0.7794,  ...,  0.9053, -0.8711, -0.0782],\n",
            "        ...,\n",
            "        [ 0.5348,  1.0000,  0.9172,  ...,  0.8871, -0.4975, -0.7824],\n",
            "        [ 0.6150,  0.9997,  0.7591,  ...,  0.5862, -0.6289, -0.6546],\n",
            "        [-0.4064, -0.4815, -0.8556,  ..., -0.7637,  0.3539,  0.1894]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4940, -0.8793, -0.9346,  ..., -0.8166,  0.1536,  0.7446],\n",
            "        [ 0.4792,  0.9996,  0.8710,  ...,  0.7969, -0.7780, -0.5972],\n",
            "        [ 0.5406,  0.9988,  0.7837,  ...,  0.8797, -0.7693, -0.5218],\n",
            "        ...,\n",
            "        [ 0.4528,  0.9882,  0.8652,  ...,  0.9170, -0.8388,  0.0476],\n",
            "        [ 0.5548,  1.0000,  0.8777,  ...,  0.5555,  0.1603, -0.8361],\n",
            "        [ 0.5385,  0.9942,  0.8881,  ...,  0.8701, -0.8666, -0.6015]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0370, -0.8892, -0.7692,  ..., -0.6023,  0.3211,  0.0077],\n",
            "        [-0.2714, -0.7900, -0.9067,  ..., -0.9405,  0.3608,  0.3936],\n",
            "        [-0.4605, -0.9256, -0.9300,  ..., -0.9214,  0.3433,  0.5637],\n",
            "        ...,\n",
            "        [-0.3393,  0.6569, -0.7915,  ..., -0.6463,  0.4344,  0.4480],\n",
            "        [-0.6658,  0.8783, -0.9325,  ..., -0.8109,  0.4165,  0.6280],\n",
            "        [-0.3468, -0.6411, -0.9428,  ..., -0.8982,  0.5467,  0.1194]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7495,  0.9965,  0.8322,  ...,  0.8700, -0.7308, -0.5701],\n",
            "        [-0.4440, -0.4111, -0.9177,  ..., -0.8425,  0.4016,  0.2643],\n",
            "        [-0.3205, -0.1697, -0.9291,  ..., -0.8607,  0.6570,  0.4483],\n",
            "        ...,\n",
            "        [ 0.6271,  0.9998, -0.0412,  ..., -0.4589,  0.7326, -0.6859],\n",
            "        [-0.6239,  0.8329, -0.8623,  ..., -0.8520,  0.1644,  0.1654],\n",
            "        [ 0.7826,  0.9979,  0.9345,  ...,  0.5653, -0.6037, -0.7885]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2254,  0.6451, -0.9162,  ..., -0.8842,  0.2342,  0.3509],\n",
            "        [ 0.5710,  0.9997,  0.8609,  ...,  0.7736, -0.5520, -0.3850],\n",
            "        [ 0.5872,  0.9947,  0.7617,  ...,  0.7235, -0.7829, -0.1909],\n",
            "        ...,\n",
            "        [-0.5087, -0.9760, -0.9533,  ..., -0.8736,  0.1408,  0.6374],\n",
            "        [-0.4481, -0.9298, -0.9267,  ..., -0.8510,  0.2856,  0.5556],\n",
            "        [-0.5826, -0.2079, -0.9513,  ..., -0.9235,  0.1367,  0.2993]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7422,  0.9999,  0.9301,  ...,  0.9042, -0.5704, -0.7309],\n",
            "        [ 0.2113,  0.9792,  0.8385,  ...,  0.8774, -0.8203, -0.2984],\n",
            "        [ 0.6526,  0.9999,  0.8476,  ...,  0.8821, -0.8010, -0.3279],\n",
            "        ...,\n",
            "        [-0.5926, -0.1849, -0.9125,  ..., -0.8883,  0.1781,  0.7406],\n",
            "        [ 0.5040,  1.0000,  0.8935,  ...,  0.8523, -0.4647, -0.7863],\n",
            "        [ 0.4980,  0.9828,  0.8108,  ...,  0.9131, -0.8178, -0.1863]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3878,  0.9987, -0.8886,  ..., -0.7736,  0.3745, -0.0818],\n",
            "        [ 0.6020,  0.9706,  0.8051,  ...,  0.8955, -0.8255, -0.1931],\n",
            "        [-0.3196,  0.9383, -0.7076,  ..., -0.9103,  0.6025, -0.0951],\n",
            "        ...,\n",
            "        [ 0.4360,  0.9977,  0.8167,  ...,  0.8386, -0.8432, -0.3629],\n",
            "        [ 0.6064,  0.9967,  0.8085,  ...,  0.7256, -0.7483, -0.6147],\n",
            "        [-0.4669,  0.4369, -0.8852,  ..., -0.8423,  0.1505,  0.5688]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6467,  0.9960,  0.8512,  ...,  0.8811, -0.7844, -0.2818],\n",
            "        [ 0.8266,  0.9995,  0.8571,  ...,  0.8603, -0.8635, -0.4046],\n",
            "        [-0.6998, -0.9322, -0.9189,  ..., -0.9007,  0.1123,  0.5241],\n",
            "        ...,\n",
            "        [-0.7330, -0.8031, -0.9139,  ..., -0.9172,  0.0129,  0.6947],\n",
            "        [ 0.7124,  0.9998,  0.9580,  ...,  0.8699, -0.5646, -0.7237],\n",
            "        [-0.7886,  0.1748, -0.9218,  ..., -0.8864,  0.4204,  0.8059]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5502, -0.9740, -0.9039,  ..., -0.9059,  0.3971,  0.2997],\n",
            "        [-0.6186, -0.9928, -0.9512,  ..., -0.9443,  0.1489,  0.6958],\n",
            "        [-0.3603,  0.9340, -0.9362,  ..., -0.8964,  0.2497,  0.5221],\n",
            "        ...,\n",
            "        [ 0.7028,  0.9998,  0.9252,  ...,  0.8423, -0.7544, -0.5695],\n",
            "        [ 0.6584,  0.9970,  0.8663,  ...,  0.8827, -0.8254, -0.4340],\n",
            "        [ 0.6998,  1.0000,  0.9559,  ...,  0.8450, -0.3834, -0.8632]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5484,  0.7115, -0.9720,  ..., -0.9137,  0.4951,  0.5026],\n",
            "        [-0.7858, -0.0898, -0.9361,  ..., -0.8280,  0.0402,  0.5889],\n",
            "        [ 0.6142,  1.0000,  0.8689,  ...,  0.0792,  0.4581, -0.9745],\n",
            "        ...,\n",
            "        [ 0.5553,  0.9993,  0.6673,  ...,  0.7681, -0.7649, -0.2504],\n",
            "        [-0.5725, -0.6301, -0.9376,  ..., -0.8834,  0.1729,  0.4190],\n",
            "        [ 0.7293,  0.9987,  0.7354,  ...,  0.8773, -0.6549, -0.1465]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6485,  0.9983,  0.8042,  ...,  0.9008, -0.8373, -0.5810],\n",
            "        [ 0.4439,  0.9968,  0.8377,  ...,  0.7425, -0.8051, -0.1575],\n",
            "        [ 0.4686,  0.9981,  0.8373,  ...,  0.8852, -0.7715, -0.5302],\n",
            "        ...,\n",
            "        [-0.4642,  0.7551, -0.8810,  ..., -0.8031, -0.1189,  0.6158],\n",
            "        [ 0.4334,  0.9990,  0.9101,  ...,  0.8609, -0.7750, -0.4342],\n",
            "        [-0.0913, -0.7547, -0.9303,  ..., -0.9070,  0.0809,  0.6397]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.8172,  1.0000,  0.9532,  ...,  0.7855, -0.2573, -0.9105],\n",
            "        [ 0.5598,  1.0000,  0.8656,  ...,  0.8900, -0.5855, -0.5063],\n",
            "        [ 0.6587,  1.0000,  0.9137,  ...,  0.8495, -0.8436, -0.5011],\n",
            "        ...,\n",
            "        [ 0.4711,  0.9985,  0.8649,  ...,  0.9307, -0.8215, -0.0373],\n",
            "        [-0.4183, -0.5458, -0.9189,  ..., -0.7833,  0.0181,  0.5714],\n",
            "        [ 0.5886,  0.9999,  0.9186,  ...,  0.8164, -0.7281, -0.5966]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4301,  0.4558, -0.9395,  ..., -0.8795,  0.2853,  0.2617],\n",
            "        [-0.5486,  0.1263, -0.9087,  ..., -0.8980,  0.1407,  0.2789],\n",
            "        [-0.5327, -0.9774, -0.9130,  ..., -0.8699,  0.1485,  0.7057],\n",
            "        ...,\n",
            "        [ 0.5985,  0.9992,  0.9245,  ...,  0.9475, -0.8320, -0.4972],\n",
            "        [ 0.5774,  0.9933,  0.6951,  ...,  0.8705, -0.7666, -0.3374],\n",
            "        [ 0.4617,  0.9986,  0.8123,  ...,  0.8784, -0.7986, -0.2923]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5014, -0.9904, -0.9100,  ..., -0.9078, -0.0879,  0.6463],\n",
            "        [ 0.6363,  1.0000,  0.9302,  ...,  0.8873, -0.4951, -0.8084],\n",
            "        [-0.5723, -0.6263, -0.8543,  ..., -0.8395,  0.0334,  0.6817],\n",
            "        ...,\n",
            "        [-0.4620,  0.9991, -0.8352,  ..., -0.8991,  0.4745, -0.5789],\n",
            "        [-0.2756, -0.9813, -0.9388,  ..., -0.7799,  0.4480,  0.5324],\n",
            "        [ 0.7363,  0.9917,  0.8106,  ...,  0.9108, -0.7917, -0.1603]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6106,  0.9960,  0.9110,  ...,  0.8055, -0.8092, -0.5970],\n",
            "        [ 0.7694,  0.9995,  0.8497,  ...,  0.9079, -0.8198, -0.3081],\n",
            "        [ 0.6985,  1.0000,  0.9251,  ...,  0.5270,  0.4389, -0.9565],\n",
            "        ...,\n",
            "        [-0.5253, -0.4342, -0.8627,  ..., -0.9348,  0.2550,  0.3451],\n",
            "        [ 0.5975,  0.9993,  0.7609,  ...,  0.8730, -0.8254, -0.2629],\n",
            "        [ 0.6808,  0.9886,  0.7376,  ...,  0.8126, -0.8095, -0.2331]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5686, -0.8390, -0.9529,  ..., -0.8562,  0.4249,  0.5532],\n",
            "        [-0.4073, -0.9675, -0.9455,  ..., -0.8636,  0.3032,  0.6374],\n",
            "        [-0.1126,  0.8843, -0.7819,  ..., -0.8840,  0.6507, -0.4914],\n",
            "        ...,\n",
            "        [-0.7250, -0.9840, -0.9405,  ..., -0.8537,  0.3457,  0.6407],\n",
            "        [ 0.6714,  0.9989,  0.7679,  ...,  0.8831, -0.8366, -0.2057],\n",
            "        [-0.6452, -0.9869, -0.9013,  ..., -0.8789,  0.3946,  0.7608]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.7908,  0.9997, -0.0872,  ..., -0.6694,  0.4362, -0.4290],\n",
            "        [ 0.6347,  0.9629,  0.8664,  ...,  0.8841, -0.8708, -0.0726],\n",
            "        [-0.4669, -0.9602, -0.9639,  ..., -0.8987,  0.2701,  0.6103],\n",
            "        ...,\n",
            "        [ 0.7901,  1.0000,  0.9645,  ...,  0.6856, -0.1657, -0.9392],\n",
            "        [-0.4876,  0.8968, -0.7835,  ..., -0.6471,  0.5909,  0.1278],\n",
            "        [ 0.6655,  0.9996,  0.9400,  ...,  0.8435, -0.6396, -0.5645]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6821,  1.0000,  0.8055,  ..., -0.0448,  0.4236, -0.9385],\n",
            "        [-0.2924,  0.9991,  0.0468,  ..., -0.7142,  0.3370, -0.8174],\n",
            "        [-0.5576, -0.9655, -0.9651,  ..., -0.9131,  0.1799,  0.4991],\n",
            "        ...,\n",
            "        [ 0.5572,  0.9971,  0.9128,  ...,  0.9291, -0.8104, -0.5689],\n",
            "        [-0.2772,  0.2120, -0.9622,  ..., -0.8190,  0.2759,  0.4898],\n",
            "        [ 0.5571,  0.9991,  0.8029,  ...,  0.8920, -0.7137, -0.2578]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6341,  0.9998,  0.8243,  ...,  0.8337, -0.7589, -0.1548],\n",
            "        [ 0.5787,  0.9980,  0.8320,  ...,  0.8923, -0.8764, -0.3676],\n",
            "        [-0.6368,  0.6750, -0.9468,  ..., -0.9405,  0.1455,  0.8329],\n",
            "        ...,\n",
            "        [ 0.0696,  1.0000,  0.4464,  ...,  0.4089,  0.8023, -0.7525],\n",
            "        [ 0.6557,  0.9632,  0.8223,  ...,  0.9075, -0.8844, -0.3954],\n",
            "        [-0.7641,  0.7089, -0.9275,  ..., -0.8279,  0.4883,  0.3970]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4908,  0.9649, -0.9323,  ..., -0.9009,  0.3999,  0.4930],\n",
            "        [ 0.6394,  0.9999,  0.8358,  ...,  0.8753, -0.8550, -0.6863],\n",
            "        [ 0.3504,  1.0000,  0.9487,  ...,  0.3129, -0.0697, -0.9139],\n",
            "        ...,\n",
            "        [ 0.1475,  0.9743,  0.8695,  ...,  0.7136, -0.6236, -0.7327],\n",
            "        [ 0.6869,  0.9991,  0.8105,  ...,  0.8491, -0.8313, -0.4146],\n",
            "        [-0.7336,  0.9691, -0.9082,  ..., -0.9245,  0.2075,  0.4843]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6464, -0.9993, -0.9068,  ..., -0.7722,  0.3637,  0.7185],\n",
            "        [-0.5590, -0.9792, -0.9572,  ..., -0.8876,  0.4430,  0.6227],\n",
            "        [-0.7372, -0.8572, -0.9360,  ..., -0.8941,  0.2504,  0.8056],\n",
            "        ...,\n",
            "        [-0.6792,  0.9092, -0.9164,  ..., -0.8454,  0.3518,  0.1184],\n",
            "        [-0.3936,  0.0655, -0.8453,  ..., -0.9382,  0.1608,  0.4617],\n",
            "        [-0.5748, -0.6820, -0.9174,  ..., -0.8472,  0.6615,  0.4715]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.7559, -0.9902, -0.9301,  ..., -0.9044,  0.4276,  0.7346],\n",
            "        [-0.1763,  0.8831, -0.8102,  ..., -0.8684,  0.2048, -0.4374],\n",
            "        [-0.5300, -0.9860, -0.8885,  ..., -0.8124,  0.0498,  0.6916],\n",
            "        ...,\n",
            "        [ 0.4825,  1.0000,  0.9337,  ...,  0.2389,  0.6226, -0.9725],\n",
            "        [-0.5431, -0.9613, -0.9344,  ..., -0.9023,  0.2287,  0.6605],\n",
            "        [ 0.4648,  1.0000,  0.9358,  ...,  0.3641,  0.4806, -0.9791]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2681,  0.2178, -0.9429,  ..., -0.8866,  0.4859,  0.4525],\n",
            "        [ 0.8505,  0.9999,  0.8668,  ...,  0.8937, -0.6655, -0.6627],\n",
            "        [-0.5722, -0.0647, -0.8921,  ..., -0.7356,  0.3300,  0.5571],\n",
            "        ...,\n",
            "        [-0.3712, -0.8234, -0.8948,  ..., -0.8168,  0.3928, -0.0303],\n",
            "        [ 0.7210,  0.9999,  0.9260,  ...,  0.8662, -0.8042, -0.8157],\n",
            "        [-0.6848, -0.6574, -0.9114,  ..., -0.8695,  0.2278,  0.4535]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5308,  0.0193, -0.9439,  ..., -0.8628,  0.1059,  0.6578],\n",
            "        [ 0.6505,  0.9996,  0.7935,  ...,  0.7041, -0.7367, -0.0857],\n",
            "        [ 0.6983,  0.9986,  0.7858,  ...,  0.8706, -0.8261, -0.4049],\n",
            "        ...,\n",
            "        [-0.5642, -0.5907, -0.8935,  ..., -0.9108,  0.3378,  0.7996],\n",
            "        [-0.5774, -0.6091, -0.9347,  ..., -0.9169,  0.2305,  0.6831],\n",
            "        [ 0.5056,  0.9875,  0.8448,  ...,  0.8963, -0.8916, -0.1858]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2345, -0.2142, -0.9451,  ..., -0.8886,  0.2201,  0.3357],\n",
            "        [-0.3459, -0.9876, -0.9273,  ..., -0.9292,  0.2859,  0.6300],\n",
            "        [ 0.8027,  1.0000,  0.3836,  ..., -0.7492,  0.7192, -0.9762],\n",
            "        ...,\n",
            "        [-0.4987,  0.9890, -0.7513,  ..., -0.7490,  0.3189, -0.1701],\n",
            "        [ 0.4241,  0.9992,  0.7504,  ...,  0.6984, -0.6833, -0.5160],\n",
            "        [ 0.5999,  0.9978,  0.9001,  ...,  0.9307, -0.7466, -0.4991]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3517,  0.9975,  0.8448,  ...,  0.8540, -0.8255, -0.3782],\n",
            "        [ 0.8089,  1.0000,  0.3088,  ..., -0.5032,  0.6307, -0.9462],\n",
            "        [-0.4798,  0.9014, -0.9337,  ..., -0.8803, -0.0336,  0.6419],\n",
            "        ...,\n",
            "        [-0.6370, -0.6942, -0.9312,  ..., -0.9005,  0.1437,  0.6082],\n",
            "        [-0.3884,  0.9421, -0.8852,  ..., -0.6414,  0.6502,  0.1369],\n",
            "        [ 0.6533,  0.9999,  0.8921,  ...,  0.8429, -0.6974, -0.5881]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5257,  0.9985,  0.8644,  ...,  0.8742, -0.7852, -0.0746],\n",
            "        [ 0.6862,  1.0000,  0.8721,  ...,  0.8718, -0.6242, -0.6140],\n",
            "        [ 0.7287,  0.9999,  0.9511,  ...,  0.8829, -0.5472, -0.6921],\n",
            "        ...,\n",
            "        [ 0.6207,  1.0000,  0.9311,  ...,  0.7845,  0.3182, -0.9615],\n",
            "        [ 0.6671,  0.9999,  0.9391,  ...,  0.8733, -0.6654, -0.6596],\n",
            "        [-0.4913,  0.9998, -0.8156,  ..., -0.7879,  0.0291,  0.3412]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4240,  0.8174, -0.9781,  ..., -0.8679,  0.3783,  0.5802],\n",
            "        [ 0.5604,  1.0000,  0.9301,  ...,  0.7566,  0.1655, -0.9127],\n",
            "        [ 0.6192,  1.0000,  0.8376,  ...,  0.2140, -0.3142, -0.9354],\n",
            "        ...,\n",
            "        [ 0.6459,  0.9964,  0.8428,  ...,  0.8444, -0.6527, -0.2991],\n",
            "        [ 0.7071,  1.0000,  0.9605,  ...,  0.8771, -0.4451, -0.8489],\n",
            "        [ 0.0119,  0.9450, -0.9399,  ..., -0.8253,  0.1053,  0.2945]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5743,  1.0000,  0.7374,  ...,  0.0090,  0.0354, -0.8861],\n",
            "        [ 0.5787,  0.9996,  0.8167,  ...,  0.7981, -0.8474, -0.5219],\n",
            "        [-0.6468, -0.9860, -0.9206,  ..., -0.9076,  0.2047,  0.7585],\n",
            "        ...,\n",
            "        [-0.0574,  0.9848, -0.9464,  ..., -0.8791,  0.0702,  0.4686],\n",
            "        [ 0.5147,  0.9987,  0.9275,  ...,  0.7765, -0.5712, -0.6609],\n",
            "        [ 0.7636,  0.9940,  0.8772,  ...,  0.7463, -0.6832, -0.4942]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2847,  0.9654, -0.9011,  ..., -0.9056,  0.6685, -0.1140],\n",
            "        [ 0.1348,  0.8874, -0.9475,  ..., -0.9383,  0.6026,  0.5784],\n",
            "        [ 0.4921,  0.9997,  0.8704,  ...,  0.8728, -0.7062, -0.6914],\n",
            "        ...,\n",
            "        [ 0.6044,  0.9999,  0.8992,  ...,  0.5709, -0.6568, -0.7237],\n",
            "        [-0.5088, -0.8190, -0.9109,  ..., -0.9285, -0.0954,  0.4344],\n",
            "        [-0.2500,  0.2297, -0.8866,  ..., -0.8189,  0.4394,  0.4232]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4055, -0.7916, -0.9469,  ..., -0.9180,  0.3829,  0.6303],\n",
            "        [ 0.7526,  0.9999,  0.9309,  ...,  0.8650, -0.7684, -0.6012],\n",
            "        [-0.5349,  0.3520, -0.9468,  ..., -0.8932,  0.2832,  0.3731],\n",
            "        ...,\n",
            "        [ 0.5473,  0.9819,  0.8901,  ...,  0.8566, -0.8882, -0.4098],\n",
            "        [-0.5234, -0.4864, -0.9357,  ..., -0.8949,  0.2863,  0.5982],\n",
            "        [ 0.5621,  0.9964,  0.8880,  ...,  0.9099, -0.8441, -0.3631]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5083,  0.9972,  0.9061,  ...,  0.8686, -0.8000, -0.2570],\n",
            "        [ 0.5852,  0.9973,  0.9094,  ...,  0.9182, -0.7960, -0.4363],\n",
            "        [-0.6433, -0.8978, -0.9422,  ..., -0.9080,  0.2081,  0.7548],\n",
            "        ...,\n",
            "        [-0.5505, -0.7986, -0.8054,  ..., -0.8612,  0.4719,  0.4540],\n",
            "        [-0.4715,  0.9992, -0.8496,  ..., -0.7829,  0.6373,  0.0787],\n",
            "        [-0.2327, -0.9827, -0.9283,  ..., -0.9097,  0.3078,  0.0609]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6774, -0.9371, -0.9481,  ..., -0.9005,  0.2265,  0.7663],\n",
            "        [ 0.6553,  0.9944,  0.7111,  ...,  0.9136, -0.7710, -0.3026],\n",
            "        [ 0.7078,  0.9904,  0.8451,  ...,  0.9271, -0.8341, -0.3036],\n",
            "        ...,\n",
            "        [ 0.6564,  0.9999,  0.9071,  ...,  0.9006, -0.7573, -0.5516],\n",
            "        [ 0.6588,  0.9995,  0.8894,  ...,  0.8538, -0.7937, -0.4512],\n",
            "        [-0.7843, -0.9972, -0.9426,  ..., -0.8868, -0.1138,  0.6990]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4909,  0.9991,  0.7922,  ...,  0.8278, -0.8467, -0.1236],\n",
            "        [ 0.8578,  1.0000,  0.8696,  ...,  0.8853, -0.4550, -0.7769],\n",
            "        [ 0.7664,  1.0000,  0.9723,  ...,  0.8390,  0.0666, -0.9034],\n",
            "        ...,\n",
            "        [ 0.5328,  1.0000,  0.8381,  ...,  0.8075, -0.5970, -0.4913],\n",
            "        [ 0.0371,  0.9814, -0.8804,  ..., -0.7595,  0.5273,  0.2075],\n",
            "        [ 0.7490,  0.9975,  0.8833,  ...,  0.8836, -0.8982, -0.5259]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5435,  0.1024, -0.8723,  ..., -0.8476,  0.7142,  0.6342],\n",
            "        [ 0.5183,  0.9992,  0.9339,  ...,  0.7004, -0.8308, -0.6854],\n",
            "        [ 0.0326,  1.0000,  0.8311,  ..., -0.0984,  0.3648, -0.8511],\n",
            "        ...,\n",
            "        [-0.4769,  0.7605, -0.8892,  ..., -0.8922,  0.3578,  0.4369],\n",
            "        [-0.6782, -0.9414, -0.9495,  ..., -0.8992, -0.1349,  0.7036],\n",
            "        [-0.5370,  0.3230, -0.9226,  ..., -0.8543,  0.0181,  0.5274]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5914, -0.8956, -0.7064,  ..., -0.8081,  0.2994,  0.5040],\n",
            "        [-0.3275, -0.9988, -0.9033,  ..., -0.9141,  0.2408,  0.6014],\n",
            "        [ 0.7644,  0.9989,  0.8764,  ...,  0.8096, -0.7064, -0.5414],\n",
            "        ...,\n",
            "        [-0.5968, -0.8723, -0.8892,  ..., -0.8532,  0.3435,  0.4258],\n",
            "        [-0.7114, -0.7229, -0.9260,  ..., -0.9171,  0.2405,  0.7992],\n",
            "        [ 0.7106,  1.0000,  0.8946,  ...,  0.7838, -0.4995, -0.6694]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.7499,  0.7551, -0.9089,  ..., -0.7768,  0.1582,  0.7544],\n",
            "        [-0.4836, -0.5079, -0.8846,  ..., -0.9011,  0.2130,  0.3155],\n",
            "        [ 0.4225,  0.9985,  0.7803,  ...,  0.7609, -0.7988, -0.2006],\n",
            "        ...,\n",
            "        [-0.3369,  0.8850, -0.8889,  ..., -0.8778,  0.4974,  0.6041],\n",
            "        [ 0.6880,  0.9998,  0.8742,  ...,  0.8932, -0.8419, -0.4707],\n",
            "        [-0.4558,  0.0099, -0.9000,  ..., -0.9251,  0.5174,  0.6297]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4401, -0.5972, -0.8595,  ..., -0.7330,  0.6010,  0.5343],\n",
            "        [-0.5209,  0.0395, -0.8823,  ..., -0.9271,  0.6157,  0.2824],\n",
            "        [-0.0420,  0.9628, -0.8377,  ..., -0.8756,  0.5529,  0.0670],\n",
            "        ...,\n",
            "        [ 0.6029,  0.9998,  0.8578,  ...,  0.8856, -0.5117, -0.3877],\n",
            "        [-0.4148,  0.9062, -0.9383,  ..., -0.7094,  0.5601,  0.4908],\n",
            "        [-0.6915,  0.0026, -0.8905,  ..., -0.8893,  0.0424,  0.2797]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5948, -0.9877, -0.7658,  ..., -0.8106,  0.3685,  0.3694],\n",
            "        [ 0.8183,  0.9974,  0.8029,  ...,  0.8826, -0.7483, -0.5417],\n",
            "        [ 0.2826,  1.0000,  0.9560,  ...,  0.8473, -0.4588, -0.8180],\n",
            "        ...,\n",
            "        [-0.6238,  0.7036, -0.9582,  ..., -0.9440,  0.1411,  0.6260],\n",
            "        [ 0.6145,  0.9923,  0.8556,  ...,  0.8562, -0.6780, -0.2322],\n",
            "        [-0.2284, -0.9693, -0.9333,  ..., -0.8470,  0.3318,  0.4228]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5530,  0.9996, -0.7286,  ..., -0.7804,  0.9144, -0.7615],\n",
            "        [ 0.5472,  0.9999,  0.7377,  ...,  0.7920, -0.6867, -0.4053],\n",
            "        [ 0.7115,  1.0000,  0.9311,  ...,  0.8048, -0.2018, -0.9494],\n",
            "        ...,\n",
            "        [ 0.5937,  0.9998,  0.9131,  ...,  0.8268, -0.7319, -0.7960],\n",
            "        [-0.5932, -0.1319, -0.8896,  ..., -0.8124,  0.4192,  0.6454],\n",
            "        [-0.5629, -0.0977, -0.9252,  ..., -0.7395,  0.2901,  0.5062]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6692,  0.9998,  0.7380,  ...,  0.7533, -0.4459, -0.4216],\n",
            "        [ 0.6950,  1.0000,  0.9767,  ...,  0.8240, -0.5710, -0.5900],\n",
            "        [ 0.6207,  1.0000,  0.9492,  ...,  0.7035, -0.1425, -0.9686],\n",
            "        ...,\n",
            "        [ 0.6114,  1.0000,  0.9522,  ...,  0.8463, -0.5791, -0.6843],\n",
            "        [ 0.7301,  0.9953,  0.7086,  ...,  0.9200, -0.8275, -0.1953],\n",
            "        [ 0.8080,  0.9999,  0.7668,  ...,  0.8282, -0.5345, -0.4109]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2515,  0.0300, -0.9486,  ..., -0.8204,  0.2699,  0.3796],\n",
            "        [ 0.6746,  0.9865,  0.7978,  ...,  0.8338, -0.8356, -0.1938],\n",
            "        [ 0.6755,  0.9947,  0.8385,  ...,  0.8762, -0.8532, -0.5512],\n",
            "        ...,\n",
            "        [ 0.6367,  0.9989,  0.7548,  ...,  0.8121, -0.8705,  0.0559],\n",
            "        [ 0.7351,  1.0000,  0.9245,  ...,  0.8216, -0.4058, -0.7808],\n",
            "        [ 0.6838,  1.0000,  0.9385,  ...,  0.8918, -0.5308, -0.6944]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5211,  1.0000,  0.8702,  ...,  0.0232,  0.3870, -0.9752],\n",
            "        [ 0.7428,  0.9971,  0.8728,  ...,  0.9127, -0.6921, -0.5317],\n",
            "        [-0.5011,  0.7746, -0.9502,  ..., -0.9344,  0.2186,  0.4999],\n",
            "        ...,\n",
            "        [-0.5419, -0.9995, -0.9371,  ..., -0.8972, -0.0271,  0.7038],\n",
            "        [-0.5581, -0.9551, -0.9368,  ..., -0.8489, -0.0351,  0.6850],\n",
            "        [-0.6537, -0.9911, -0.9499,  ..., -0.8352,  0.1275,  0.8240]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5084, -0.9274, -0.9451,  ..., -0.8557,  0.1630,  0.3947],\n",
            "        [ 0.7233,  1.0000,  0.7442,  ...,  0.7467, -0.7520, -0.6537],\n",
            "        [ 0.5870,  0.9264,  0.8065,  ...,  0.8668, -0.8048,  0.0955],\n",
            "        ...,\n",
            "        [-0.4478, -0.9990, -0.9489,  ..., -0.8752,  0.2368,  0.6872],\n",
            "        [-0.6579,  0.9697, -0.8762,  ..., -0.9139,  0.1772,  0.2502],\n",
            "        [-0.6125, -0.7669, -0.9369,  ..., -0.8774,  0.2315,  0.6777]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6225,  0.9997,  0.8502,  ...,  0.8503, -0.7101, -0.6912],\n",
            "        [ 0.5349,  1.0000, -0.4612,  ..., -0.4920,  0.5846, -0.8494],\n",
            "        [-0.4633, -0.2063, -0.9358,  ..., -0.9123,  0.1994,  0.5896],\n",
            "        ...,\n",
            "        [ 0.6585,  0.9982,  0.9418,  ...,  0.8735, -0.8618, -0.5351],\n",
            "        [-0.7674,  0.9995, -0.8455,  ..., -0.6234,  0.1975, -0.2965],\n",
            "        [-0.7275,  0.9594, -0.8352,  ..., -0.8925,  0.2491,  0.2460]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6198,  0.7588, -0.9186,  ..., -0.8192, -0.0339,  0.6393],\n",
            "        [ 0.6046,  0.9986,  0.8962,  ...,  0.8113, -0.7753, -0.4146],\n",
            "        [ 0.6563,  0.9995,  0.8654,  ...,  0.8659, -0.6650, -0.7581],\n",
            "        ...,\n",
            "        [ 0.8158,  1.0000,  0.9016,  ...,  0.7986, -0.5441, -0.9424],\n",
            "        [-0.6483, -0.2757, -0.9365,  ..., -0.8955,  0.3801,  0.4911],\n",
            "        [-0.6490,  0.6279, -0.9517,  ..., -0.9413,  0.2689,  0.6824]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6696, -0.2592, -0.7760,  ..., -0.8667,  0.3991,  0.3745],\n",
            "        [ 0.3259,  0.9896,  0.8687,  ...,  0.7246, -0.7944, -0.3484],\n",
            "        [ 0.3014,  0.9664,  0.7673,  ...,  0.8974, -0.8775,  0.0900],\n",
            "        ...,\n",
            "        [ 0.5888,  0.9995,  0.8790,  ...,  0.8441, -0.6173, -0.6099],\n",
            "        [ 0.6388,  0.9945,  0.8981,  ...,  0.9489, -0.7342, -0.1341],\n",
            "        [ 0.2042,  0.9999,  0.8079,  ..., -0.0504, -0.2152, -0.7897]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5249,  0.9734, -0.8207,  ..., -0.8195,  0.3893,  0.5987],\n",
            "        [-0.5817,  0.0998, -0.9341,  ..., -0.8999,  0.3639,  0.3471],\n",
            "        [ 0.7593,  0.9993,  0.9089,  ...,  0.8996, -0.7663, -0.5557],\n",
            "        ...,\n",
            "        [-0.4339,  0.8421, -0.8468,  ..., -0.9067,  0.1767,  0.3993],\n",
            "        [-0.4656,  0.3516, -0.9378,  ..., -0.8853,  0.3216,  0.2747],\n",
            "        [-0.4638, -0.4549, -0.9434,  ..., -0.9038,  0.1762,  0.5215]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4780,  0.7030, -0.9115,  ..., -0.8227,  0.4103,  0.5587],\n",
            "        [ 0.6234,  0.9999,  0.8422,  ...,  0.8355, -0.6859, -0.7304],\n",
            "        [ 0.5869,  0.9982,  0.9059,  ...,  0.8576, -0.8315, -0.2405],\n",
            "        ...,\n",
            "        [-0.6696,  0.9944, -0.8210,  ..., -0.7241, -0.1708,  0.5003],\n",
            "        [-0.3560,  0.9136, -0.9435,  ..., -0.9161,  0.3157,  0.1989],\n",
            "        [ 0.5854,  0.9927,  0.8050,  ...,  0.8731, -0.8497, -0.2301]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1381,  0.9997,  0.3998,  ..., -0.1817,  0.1857, -0.6649],\n",
            "        [-0.6690,  0.9991, -0.9284,  ..., -0.8345,  0.4961,  0.2644],\n",
            "        [-0.6126, -0.9581, -0.8579,  ..., -0.6129,  0.3074,  0.4224],\n",
            "        ...,\n",
            "        [-0.7191, -0.8018, -0.9136,  ..., -0.8810,  0.1015,  0.6694],\n",
            "        [ 0.6909,  0.9946,  0.8568,  ...,  0.8909, -0.8360, -0.3889],\n",
            "        [ 0.5855,  0.9895,  0.6365,  ...,  0.7795, -0.7746, -0.5414]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6739,  0.4789, -0.9561,  ..., -0.9352,  0.1209,  0.5747],\n",
            "        [-0.7307, -0.8136, -0.8222,  ..., -0.8875,  0.5944,  0.5753],\n",
            "        [-0.3231,  0.1817, -0.9204,  ..., -0.9206,  0.4781,  0.4016],\n",
            "        ...,\n",
            "        [-0.6985,  0.9740, -0.9367,  ..., -0.7784,  0.3622,  0.4942],\n",
            "        [ 0.7809,  0.9999,  0.8328,  ...,  0.8396, -0.6754, -0.5914],\n",
            "        [-0.7584,  0.9722, -0.9064,  ..., -0.9161,  0.0129,  0.4245]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7250,  0.9999,  0.8770,  ...,  0.8914, -0.6853, -0.4197],\n",
            "        [ 0.6358,  1.0000,  0.8849,  ...,  0.7885, -0.5724, -0.7048],\n",
            "        [-0.6719,  0.8917, -0.8289,  ..., -0.9576,  0.4423,  0.3755],\n",
            "        ...,\n",
            "        [-0.6602, -0.7902, -0.9512,  ..., -0.8231,  0.5084,  0.2038],\n",
            "        [ 0.5720,  1.0000,  0.8490,  ...,  0.6190, -0.6676, -0.6825],\n",
            "        [ 0.5340,  0.9680,  0.7577,  ...,  0.8601, -0.9072,  0.0420]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4007, -0.8431, -0.9317,  ..., -0.8034,  0.5055, -0.0166],\n",
            "        [-0.4555, -0.8413, -0.9580,  ..., -0.8927,  0.0404,  0.6848],\n",
            "        [-0.4550, -0.9855, -0.9588,  ..., -0.9382,  0.0462,  0.7080],\n",
            "        ...,\n",
            "        [ 0.5346,  0.9996,  0.7960,  ...,  0.8996, -0.8611, -0.2623],\n",
            "        [-0.6199,  0.5452, -0.9035,  ..., -0.9117,  0.2426,  0.4040],\n",
            "        [-0.6531,  0.9613, -0.9436,  ..., -0.9092,  0.4000,  0.5970]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-6.2036e-01,  7.2709e-01, -8.9400e-01, -4.6706e-01,  1.1492e-01,\n",
            "         -9.0317e-01, -4.1001e-01, -7.3791e-01,  8.4599e-01,  6.0540e-01,\n",
            "         -6.3578e-01,  8.8565e-01, -1.1049e-01, -8.5248e-02,  2.1874e-01,\n",
            "          9.7445e-01, -7.3529e-01, -1.5939e-01,  1.7606e-01,  5.4367e-01,\n",
            "         -9.2898e-02,  8.8982e-01, -3.7205e-01,  1.0282e-02, -7.3271e-01,\n",
            "         -8.7145e-01,  3.3355e-01, -3.8752e-04, -8.7681e-03, -6.9994e-01,\n",
            "         -5.1900e-03,  8.6183e-01,  7.5650e-01,  1.2760e-01,  6.0206e-02,\n",
            "          2.4901e-01,  6.8628e-01,  4.2298e-01, -6.0472e-01, -5.1704e-01,\n",
            "          9.7584e-01,  5.6888e-01,  4.5870e-01, -8.5090e-01, -3.9591e-01,\n",
            "         -6.3264e-01,  4.9420e-02, -4.1204e-01, -1.0669e-01,  1.6185e-01,\n",
            "          6.6767e-01, -9.9748e-01,  4.6559e-01, -8.9570e-01, -3.9390e-01,\n",
            "         -8.2432e-01, -1.9918e-01,  4.4894e-01,  3.9791e-02,  8.5010e-01,\n",
            "         -5.2850e-01, -3.1151e-01,  8.5984e-01,  1.3304e-01,  9.7593e-01,\n",
            "         -6.2390e-02,  4.6208e-01, -2.8788e-01,  9.2136e-01, -6.4093e-01,\n",
            "         -9.1145e-01,  5.7409e-01, -3.5542e-01,  8.4940e-03,  5.0819e-01,\n",
            "         -4.8879e-01,  9.0190e-01, -1.5655e-01, -1.8970e-01,  3.4787e-01,\n",
            "         -8.6459e-01,  4.0557e-01,  7.2728e-01, -8.6475e-01, -7.7916e-01,\n",
            "         -1.8446e-01,  6.6531e-01, -3.6452e-01,  3.9103e-01,  2.1319e-02,\n",
            "         -3.1082e-01, -9.1599e-01, -6.5125e-01,  6.7289e-01,  2.4329e-01,\n",
            "         -5.1543e-01,  2.9221e-01, -7.5467e-01,  9.9042e-03, -2.0144e-01,\n",
            "          5.5646e-01,  4.8963e-01,  5.8208e-01,  5.3453e-02, -6.7688e-01,\n",
            "         -8.2232e-01,  4.9374e-01, -2.9948e-01, -2.7620e-02,  3.9087e-01,\n",
            "         -5.3802e-01,  1.3358e-01,  8.0461e-01, -2.5188e-01, -4.3055e-01,\n",
            "          8.1269e-01, -9.4401e-01, -7.5229e-01, -4.2656e-01,  5.0466e-02,\n",
            "         -3.5946e-01, -5.7126e-01,  5.5536e-01, -5.3539e-01, -3.8965e-01,\n",
            "         -7.0114e-01, -2.7877e-01,  7.1232e-01,  3.1762e-01,  4.1231e-01,\n",
            "          2.3714e-01, -8.5568e-01, -7.6147e-01, -5.1233e-01,  8.0450e-01,\n",
            "         -4.0411e-01, -9.8356e-01,  5.6790e-01,  7.5192e-01,  5.8392e-01,\n",
            "          9.1906e-01,  5.3295e-01, -6.8881e-01,  3.1243e-01,  1.4979e-01,\n",
            "          6.2810e-01,  3.7278e-02,  7.9626e-01, -1.6220e-01, -7.6432e-01,\n",
            "          4.4151e-01, -6.6774e-01, -8.1625e-01,  2.8826e-01, -9.4942e-01,\n",
            "          3.2391e-01,  7.2687e-01,  6.1114e-01,  9.7807e-01, -8.8383e-01,\n",
            "          4.5539e-01,  4.3712e-01,  2.8777e-01,  3.2454e-01,  9.9267e-01,\n",
            "         -7.8959e-01,  2.4892e-01,  6.7037e-01,  8.9113e-01, -3.4870e-01,\n",
            "         -1.0891e-01,  6.9915e-01,  4.4485e-01,  4.9131e-01,  9.8039e-01,\n",
            "         -6.8852e-01, -5.0524e-01,  1.4795e-01,  8.7469e-01,  5.6921e-01,\n",
            "          2.4266e-01,  1.6553e-01, -8.1543e-01, -8.7478e-01,  7.3837e-01,\n",
            "         -7.7083e-01, -4.6055e-01, -1.6535e-01, -9.4904e-01,  4.8640e-01,\n",
            "         -7.8331e-01, -7.5185e-01, -7.1646e-01,  8.6166e-01, -1.8329e-01,\n",
            "         -2.5620e-01, -2.3876e-01,  1.1267e-01,  6.8038e-01,  5.3469e-01,\n",
            "          7.7277e-01,  4.0292e-01,  5.1869e-01, -9.7021e-01, -8.8926e-01,\n",
            "         -4.2128e-01,  3.7758e-01,  4.4983e-01, -6.8995e-01,  6.3379e-01,\n",
            "          4.5290e-01,  6.9328e-01,  3.3264e-01, -8.2975e-01,  1.7699e-01,\n",
            "          4.4842e-01,  6.0111e-01, -9.3591e-01,  4.8648e-01,  8.4545e-01,\n",
            "         -8.6548e-01, -7.5076e-01,  5.6605e-01, -9.0108e-01, -2.6735e-01,\n",
            "         -1.9098e-01, -1.7639e-01,  2.5235e-01, -7.4086e-01, -1.7662e-01,\n",
            "          9.2003e-02,  5.3836e-01,  3.3635e-01,  8.3976e-01,  8.9272e-01,\n",
            "          1.6342e-01, -8.9838e-01,  4.2616e-01,  5.1889e-01, -2.8345e-01,\n",
            "          9.0909e-01, -7.2998e-01,  6.0299e-01,  2.2706e-01, -3.2882e-01,\n",
            "          1.2156e-01, -7.2401e-01, -7.5933e-01, -2.5209e-01,  5.2344e-01,\n",
            "         -1.2080e-01, -4.8313e-01,  3.0359e-01,  7.2178e-01,  6.7580e-01,\n",
            "          4.0818e-01,  8.7874e-01, -8.7019e-01, -4.4488e-01,  1.3707e-01,\n",
            "         -4.2947e-01,  1.0596e-01, -9.7213e-01, -6.7656e-01,  7.0111e-03,\n",
            "          9.4509e-01, -6.6720e-01, -5.8425e-01,  2.5925e-01,  4.0213e-02,\n",
            "          2.8144e-01,  5.5810e-01, -5.7774e-01,  9.7713e-01,  4.0032e-02,\n",
            "         -7.7331e-01,  8.4836e-01,  1.9722e-02, -7.9493e-01,  7.5401e-01,\n",
            "         -9.7447e-01,  8.2209e-01,  8.0537e-01,  6.4144e-01,  1.0260e-01,\n",
            "          3.7652e-01, -2.0204e-01,  7.6324e-01, -9.5314e-01,  9.6114e-02,\n",
            "          7.2368e-01,  8.0845e-01,  9.6715e-01,  3.5881e-01, -6.1942e-01,\n",
            "         -7.7118e-01,  6.2898e-01, -7.0618e-01, -1.7231e-01,  9.3741e-01,\n",
            "         -2.8112e-01,  7.2519e-01,  4.2592e-01,  6.0386e-01, -2.2637e-01,\n",
            "          7.4121e-01, -7.3578e-01,  7.0960e-01, -5.5891e-01, -9.2199e-03,\n",
            "          1.3902e-01, -6.0666e-01, -4.0993e-01,  4.9118e-01, -7.0949e-01,\n",
            "         -8.0276e-01, -5.5388e-01,  3.1693e-01,  5.3203e-01,  1.5163e-01,\n",
            "          1.8161e-01,  8.1647e-01, -7.2307e-01, -4.0656e-01, -4.7566e-01,\n",
            "          2.2934e-01,  2.8428e-01,  2.9547e-02, -3.5982e-01,  3.2731e-02,\n",
            "         -3.5409e-01,  9.2052e-01, -5.0506e-01, -6.4075e-01,  1.2515e-01,\n",
            "         -1.0336e-01, -1.9623e-01,  9.5848e-01, -8.7405e-01,  5.9844e-01,\n",
            "          8.0774e-01,  3.9240e-01,  8.5597e-01,  2.8889e-01, -2.1025e-01,\n",
            "         -8.5710e-01,  4.5301e-01, -1.2669e-01,  2.9621e-01, -5.0190e-01,\n",
            "         -4.5498e-01,  4.2295e-02, -7.7671e-01, -6.1772e-01,  6.9115e-01,\n",
            "          9.3947e-01,  7.0919e-01,  9.2670e-01, -4.1273e-01,  1.9477e-01,\n",
            "         -6.8916e-01, -2.4224e-01,  7.4670e-01, -5.3757e-01,  3.1239e-01,\n",
            "         -5.9760e-01,  3.9551e-01,  1.1996e-01, -8.8292e-01,  4.6790e-01,\n",
            "         -4.9970e-01,  6.6311e-01,  1.4337e-01,  9.0046e-01, -5.4054e-01,\n",
            "         -8.2187e-01,  2.0858e-02, -2.7275e-01,  8.7696e-01,  4.6532e-01,\n",
            "         -5.0403e-01, -1.7409e-01,  8.7904e-01,  4.5257e-01, -5.9047e-01,\n",
            "          5.6256e-01,  5.4740e-01, -7.9799e-01,  5.7220e-01,  7.0983e-01,\n",
            "          5.1632e-01,  1.0911e-01, -2.9465e-01, -8.0478e-01,  1.6406e-01,\n",
            "          6.2810e-01, -8.9871e-02, -7.3228e-01, -1.7486e-01,  9.4525e-01,\n",
            "         -7.5876e-01, -4.7133e-01, -4.8007e-01,  6.0062e-01,  5.5428e-01,\n",
            "         -4.6230e-01, -9.2562e-02,  6.0539e-02,  4.2252e-01, -9.0355e-01,\n",
            "          4.2019e-01,  5.4874e-01,  5.2651e-01,  7.4607e-01, -9.3523e-01,\n",
            "         -7.1909e-02, -9.0494e-01,  4.0574e-02, -7.7164e-01,  5.5314e-01,\n",
            "         -5.9570e-01, -1.9736e-01, -6.3476e-01, -9.4746e-01,  8.7730e-01,\n",
            "         -3.8075e-01,  9.3906e-01, -5.9050e-01, -5.2463e-01, -2.7223e-01,\n",
            "          3.2891e-02, -2.5711e-01,  7.8459e-01, -6.9136e-01,  9.5865e-01,\n",
            "         -8.3592e-01,  8.0003e-02,  1.4920e-01,  7.6257e-01,  3.9460e-01,\n",
            "          7.7861e-01,  9.1360e-01,  8.2172e-01, -1.8601e-01,  7.1367e-01,\n",
            "         -6.9225e-02, -7.6730e-01, -8.8512e-01, -4.8760e-02,  8.1058e-01,\n",
            "         -3.1695e-01,  7.2102e-01, -6.7839e-01,  8.3752e-01,  8.2786e-01,\n",
            "         -4.0580e-02,  1.4410e-01, -2.4162e-01,  9.1514e-01,  6.4476e-01,\n",
            "         -2.3762e-01,  8.3377e-01,  8.9439e-01,  7.5909e-01,  2.8318e-01,\n",
            "         -6.5057e-02,  1.9250e-01,  4.5207e-01, -7.5249e-01, -5.4379e-01,\n",
            "          7.8910e-01,  5.1832e-01,  8.5838e-02, -8.3051e-01,  3.4841e-01,\n",
            "         -3.2322e-02, -7.9956e-03, -8.7600e-01, -1.0835e-01, -9.9144e-01,\n",
            "          7.4197e-02,  7.1618e-01, -9.1263e-01, -2.4355e-01,  3.6333e-01,\n",
            "          1.5991e-01,  6.2534e-01,  3.5825e-01,  9.1086e-01, -8.8859e-02,\n",
            "         -1.0560e-01, -1.4238e-01,  1.3362e-01,  4.6050e-01,  4.7220e-01,\n",
            "          8.1288e-02, -7.1480e-01, -3.7842e-01,  3.3248e-01,  1.1598e-01,\n",
            "          6.6245e-01, -7.9648e-01,  1.6184e-01,  1.5478e-01, -8.1340e-01,\n",
            "         -8.5326e-01,  9.1268e-01,  9.1226e-01,  1.1400e-01,  7.4156e-01,\n",
            "          7.1773e-01,  1.7492e-01,  2.0966e-01,  6.8165e-01, -3.8825e-01,\n",
            "         -3.8668e-02,  3.9809e-01,  3.5612e-01, -4.9960e-01, -8.5633e-01,\n",
            "         -9.1609e-01, -4.3917e-01,  6.5632e-01, -6.4342e-01, -8.4699e-01,\n",
            "         -9.4739e-01, -4.8999e-01, -2.0971e-01, -6.8875e-01,  6.6522e-02,\n",
            "          7.6231e-01, -7.4491e-01, -6.5997e-01, -8.5239e-01, -3.1131e-01,\n",
            "         -9.8396e-01, -4.9307e-01, -5.4032e-01, -4.0346e-01,  6.8055e-01,\n",
            "         -9.3016e-01, -8.9120e-01, -3.6931e-01,  1.4717e-01,  7.2933e-01,\n",
            "          8.8718e-01, -1.7912e-01, -3.1768e-01, -5.1575e-01,  7.5388e-01,\n",
            "         -9.7141e-01,  4.3644e-01, -1.1248e-01,  7.6504e-01, -8.7610e-01,\n",
            "          5.8189e-01, -8.8246e-01, -2.3706e-01, -7.9353e-02,  3.9407e-01,\n",
            "         -1.2523e-01, -9.5119e-01,  3.0861e-01, -4.6498e-01,  4.7007e-01,\n",
            "         -5.0084e-01, -7.1692e-01, -5.3017e-01, -9.0953e-01, -9.4338e-01,\n",
            "          7.2462e-01,  9.6143e-01,  4.9670e-01, -8.7420e-01, -6.9850e-01,\n",
            "          6.2526e-01,  1.6182e-01, -2.4064e-01,  8.8558e-01,  9.3060e-01,\n",
            "          4.6624e-01,  7.0646e-01,  2.0871e-01,  8.0430e-02, -7.2498e-01,\n",
            "         -3.0211e-01,  1.9303e-01, -1.1105e-01, -6.9992e-01,  6.0126e-01,\n",
            "         -1.7077e-01,  4.6057e-01,  4.6444e-01, -2.8926e-01,  9.7999e-01,\n",
            "          5.1894e-01, -1.5439e-01,  8.7222e-01, -7.1865e-01, -8.9861e-01,\n",
            "         -9.1840e-01, -9.1582e-01,  8.4479e-01,  8.2155e-02, -8.7840e-01,\n",
            "          4.5959e-01,  2.2556e-02,  2.6050e-01, -1.7551e-01,  2.4856e-01,\n",
            "          7.2170e-01,  6.4424e-01,  3.3360e-01,  5.7134e-02, -6.4022e-01,\n",
            "         -8.1604e-01,  6.1071e-01,  9.1523e-01, -2.6994e-01,  7.1776e-01,\n",
            "         -3.4085e-01,  7.4413e-01,  8.9470e-02,  7.1021e-01,  1.4933e-01,\n",
            "          7.4840e-01,  4.2603e-01, -9.2029e-01,  7.2220e-01, -3.6204e-01,\n",
            "          7.1353e-01,  7.0193e-01, -6.2408e-01, -6.5219e-01, -5.1893e-01,\n",
            "         -7.0597e-01, -4.3183e-01, -6.9964e-01,  9.1825e-01, -1.7689e-01,\n",
            "          2.2900e-01,  9.0779e-01,  4.2301e-01,  1.8059e-01,  7.7989e-01,\n",
            "         -8.7136e-01,  1.9058e-01,  5.4797e-01,  2.1181e-01,  4.2421e-01,\n",
            "         -2.8446e-01, -6.4088e-01, -4.5530e-01, -9.2318e-01, -5.6407e-01,\n",
            "          3.7886e-01,  1.3715e-01,  1.0556e-01, -7.1878e-01, -8.5671e-01,\n",
            "          2.8905e-01, -8.6839e-01,  2.6588e-01, -5.0383e-01, -7.3191e-01,\n",
            "          9.4298e-01, -6.5463e-01, -1.7020e-01,  9.0452e-01,  2.3158e-01,\n",
            "         -6.8602e-01,  9.0494e-01,  6.0452e-02, -4.0854e-01,  8.2445e-01,\n",
            "          5.1680e-01, -1.9503e-01,  7.5795e-01,  2.5841e-01,  1.1214e-01,\n",
            "         -2.3750e-01, -3.1934e-01,  9.6957e-01,  7.3448e-01, -4.2579e-01,\n",
            "          8.6627e-01, -3.2670e-01,  4.0886e-01,  6.8499e-02, -7.6191e-01,\n",
            "          5.0978e-01, -2.3192e-01, -4.2473e-01, -2.5696e-01, -2.7309e-01,\n",
            "          7.8952e-01,  9.5041e-01, -9.8209e-01,  9.4982e-01,  4.1172e-01,\n",
            "         -3.5807e-02, -2.8833e-01, -3.2704e-01,  2.3685e-01,  8.6239e-01,\n",
            "         -2.0351e-01,  6.6008e-01, -1.2866e-01, -5.9548e-01,  3.0764e-01,\n",
            "         -3.8548e-01, -9.8817e-01, -8.8285e-01,  7.4273e-01,  4.8853e-01,\n",
            "         -9.6975e-01, -4.1928e-01,  3.1138e-01,  6.5370e-01, -5.9919e-01,\n",
            "          6.4541e-01,  5.3178e-01, -3.1308e-01, -1.1022e-01, -8.9149e-01,\n",
            "         -1.0587e-01,  3.7972e-01, -6.5726e-01,  7.0786e-01, -2.8029e-01,\n",
            "          8.8183e-01, -7.9503e-01,  6.1045e-01,  8.1947e-01, -8.4650e-01,\n",
            "         -8.4679e-01, -6.5217e-01, -9.0594e-01, -8.3325e-03,  1.9046e-01,\n",
            "         -8.8250e-01,  6.2331e-01, -8.2976e-01,  1.7721e-01, -9.2903e-02,\n",
            "         -9.0665e-01,  5.9260e-01,  4.1739e-02,  2.3324e-01,  2.4455e-01,\n",
            "         -8.6704e-01,  8.5698e-01,  8.6013e-01,  9.4168e-02,  9.0674e-01,\n",
            "         -5.6926e-01,  6.9634e-01, -2.3412e-01,  5.8006e-01,  9.0176e-01,\n",
            "          3.1547e-01, -2.1996e-01, -7.5503e-01, -4.8466e-01,  6.5480e-01,\n",
            "         -7.7477e-01,  1.7570e-01,  7.9876e-01]], device='cuda:0',\n",
            "       grad_fn=<TanhBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluation... :   0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "699381678de5446392cd7d2b13d3c83e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7478,  0.9743,  0.8809,  ...,  0.8767, -0.8303, -0.3323],\n",
            "        [ 0.8070,  1.0000,  0.9637,  ...,  0.7609,  0.3263, -0.9726],\n",
            "        [ 0.6447,  0.9998, -0.7743,  ..., -0.8431,  0.7137, -0.5891],\n",
            "        ...,\n",
            "        [ 0.4062,  0.9978,  0.7878,  ...,  0.8337, -0.8111, -0.1877],\n",
            "        [-0.0765,  0.9870, -0.7108,  ..., -0.8566,  0.5708, -0.1543],\n",
            "        [-0.7061, -0.1952, -0.9168,  ..., -0.7489,  0.3124,  0.6542]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4327,  0.9975, -0.8679,  ..., -0.8847,  0.4075,  0.2111],\n",
            "        [ 0.6982,  0.9999,  0.7310,  ...,  0.5270, -0.8144, -0.2510],\n",
            "        [ 0.2358,  0.9970,  0.0657,  ..., -0.6837,  0.5087, -0.8525],\n",
            "        ...,\n",
            "        [-0.2273,  0.9943, -0.2855,  ..., -0.7211,  0.2010, -0.7153],\n",
            "        [-0.6256,  0.9999, -0.5580,  ..., -0.8731,  0.3467,  0.0684],\n",
            "        [ 0.4565,  1.0000,  0.6523,  ..., -0.6769,  0.6395, -0.9634]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6669,  1.0000,  0.9415,  ...,  0.8271, -0.5067, -0.8245],\n",
            "        [ 0.3647,  1.0000,  0.7374,  ...,  0.3656,  0.7647, -0.8666],\n",
            "        [ 0.5912,  0.9999,  0.8546,  ...,  0.8708, -0.7599, -0.5309],\n",
            "        ...,\n",
            "        [-0.1681,  1.0000,  0.0316,  ..., -0.8817,  0.5201, -0.8110],\n",
            "        [-0.7891, -0.3132, -0.9108,  ..., -0.9220,  0.2705,  0.5238],\n",
            "        [ 0.4813,  1.0000,  0.6538,  ...,  0.1839,  0.0510, -0.9295]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1066,  0.9975,  0.0830,  ..., -0.0730, -0.6691, -0.6399],\n",
            "        [-0.0102,  1.0000,  0.7329,  ..., -0.2818, -0.0081, -0.9399],\n",
            "        [-0.1038,  0.9998, -0.4979,  ..., -0.8184,  0.3824, -0.8446],\n",
            "        ...,\n",
            "        [ 0.7972,  1.0000,  0.9318,  ...,  0.8560, -0.3211, -0.7628],\n",
            "        [-0.1880, -0.3814, -0.8265,  ..., -0.9094,  0.6551, -0.1807],\n",
            "        [ 0.6512,  0.9942,  0.8739,  ...,  0.9037, -0.8699, -0.3114]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7092,  0.9999,  0.7304,  ...,  0.7538, -0.5234, -0.2410],\n",
            "        [ 0.4758,  0.9998,  0.8330,  ...,  0.8939, -0.5497, -0.4565],\n",
            "        [-0.5640,  0.3146, -0.8897,  ..., -0.7608,  0.3777,  0.5335],\n",
            "        ...,\n",
            "        [ 0.5739,  0.9999,  0.5702,  ...,  0.7564, -0.5486, -0.7937],\n",
            "        [ 0.4881,  0.9999,  0.8873,  ...,  0.4220, -0.5710, -0.5630],\n",
            "        [ 0.7400,  0.9996,  0.9459,  ...,  0.4391, -0.3136, -0.7386]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5446,  0.9972,  0.8767,  ...,  0.8897, -0.8291, -0.3755],\n",
            "        [ 0.7962,  1.0000,  0.6649,  ...,  0.6864, -0.6745, -0.8425],\n",
            "        [-0.3332, -0.4021, -0.9661,  ..., -0.8799,  0.5456,  0.3938],\n",
            "        ...,\n",
            "        [ 0.3760,  0.9512, -0.9108,  ..., -0.8352,  0.6929,  0.1513],\n",
            "        [ 0.3564,  1.0000,  0.1078,  ...,  0.2114, -0.4523, -0.6049],\n",
            "        [ 0.4423,  1.0000,  0.7593,  ...,  0.5896, -0.6901, -0.7908]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0358,  0.9834, -0.5480,  ..., -0.7961, -0.2963, -0.6173],\n",
            "        [-0.5867, -0.7299, -0.9487,  ..., -0.9287,  0.1273,  0.7289],\n",
            "        [ 0.6338,  0.9903,  0.8194,  ...,  0.9029, -0.8292, -0.3051],\n",
            "        ...,\n",
            "        [-0.2573,  1.0000, -0.3754,  ..., -0.7962, -0.3797, -0.4803],\n",
            "        [ 0.6456,  0.9973,  0.9234,  ...,  0.9089, -0.8357, -0.3978],\n",
            "        [-0.4417,  0.9153, -0.8609,  ..., -0.8311,  0.0990,  0.4237]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6500,  0.9990,  0.8866,  ...,  0.8956, -0.8044, -0.4341],\n",
            "        [ 0.7144,  0.9993,  0.9331,  ...,  0.9244, -0.7507, -0.5460],\n",
            "        [ 0.6733,  1.0000,  0.9302,  ...,  0.8300,  0.0608, -0.9166],\n",
            "        ...,\n",
            "        [ 0.6003,  0.9798,  0.8774,  ...,  0.8744, -0.8917, -0.1775],\n",
            "        [ 0.4701,  0.9983,  0.7738,  ...,  0.8497, -0.8145, -0.5778],\n",
            "        [ 0.5640,  1.0000,  0.7742,  ...,  0.6386, -0.6234, -0.6108]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.8197,  1.0000,  0.9570,  ...,  0.8214, -0.0177, -0.9305],\n",
            "        [-0.2973,  0.9781, -0.9090,  ..., -0.8471,  0.2124,  0.1680],\n",
            "        [-0.8354, -0.9631, -0.8407,  ..., -0.9097,  0.1204,  0.3685],\n",
            "        ...,\n",
            "        [ 0.7050,  0.9994,  0.8843,  ...,  0.8743, -0.7845, -0.3389],\n",
            "        [-0.6851, -0.6800, -0.9302,  ..., -0.8991,  0.2643,  0.7969],\n",
            "        [ 0.5262,  0.9860,  0.8693,  ...,  0.8606, -0.8366, -0.2137]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5865, -0.6625, -0.9516,  ..., -0.8795,  0.1436,  0.5659],\n",
            "        [ 0.0911,  1.0000,  0.1720,  ..., -0.5830,  0.0368, -0.8000],\n",
            "        [ 0.6651,  0.9995,  0.9240,  ...,  0.8910, -0.7448, -0.5998],\n",
            "        ...,\n",
            "        [ 0.7081,  0.9936,  0.8133,  ...,  0.8942, -0.8615, -0.2691],\n",
            "        [ 0.4846,  0.9998,  0.8513,  ...,  0.7336, -0.5766, -0.2534],\n",
            "        [ 0.7256,  1.0000,  0.9294,  ...,  0.7700,  0.1522, -0.9537]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2510,  0.4934, -0.9075,  ..., -0.8635,  0.3508,  0.4342],\n",
            "        [-0.5626, -0.9536, -0.9212,  ..., -0.9345,  0.1531,  0.5502],\n",
            "        [-0.7028,  0.7515, -0.9670,  ..., -0.9418, -0.0416,  0.3932],\n",
            "        ...,\n",
            "        [ 0.6822,  1.0000,  0.8493,  ...,  0.7216, -0.6446, -0.7885],\n",
            "        [ 0.5969,  1.0000, -0.6445,  ..., -0.7696,  0.6049, -0.8584],\n",
            "        [ 0.4990,  0.9965,  0.9007,  ...,  0.8932, -0.8283, -0.2474]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1702,  0.9999,  0.6586,  ..., -0.3328,  0.2606, -0.8359],\n",
            "        [-0.5527, -0.8965, -0.9561,  ..., -0.8997,  0.2678,  0.6642],\n",
            "        [-0.7171,  0.9141, -0.9302,  ..., -0.9006,  0.2432,  0.1982],\n",
            "        ...,\n",
            "        [-0.6361,  0.8977, -0.9433,  ..., -0.9073,  0.2720,  0.6379],\n",
            "        [ 0.1741,  1.0000,  0.1825,  ..., -0.5248, -0.1140, -0.7821],\n",
            "        [-0.3931,  0.9994, -0.7444,  ..., -0.9146,  0.4829, -0.2488]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0677,  0.9907, -0.8074,  ..., -0.4533,  0.6921,  0.4011],\n",
            "        [ 0.3369,  1.0000,  0.6587,  ...,  0.0900, -0.1078, -0.8674],\n",
            "        [-0.6636, -0.9384, -0.8741,  ..., -0.9119,  0.4269,  0.4866],\n",
            "        ...,\n",
            "        [-0.7402,  0.9912, -0.9290,  ..., -0.7367,  0.6106,  0.3425],\n",
            "        [-0.3350,  0.9761, -0.9392,  ..., -0.8784,  0.4078,  0.1170],\n",
            "        [-0.6568,  1.0000, -0.7474,  ..., -0.8144,  0.4437, -0.5827]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7973,  1.0000,  0.9145,  ...,  0.4812, -0.4395, -0.7149],\n",
            "        [ 0.6186,  1.0000,  0.8288,  ...,  0.4100, -0.3210, -0.8136],\n",
            "        [-0.6801, -0.3396, -0.9354,  ..., -0.8549, -0.0924,  0.5484],\n",
            "        ...,\n",
            "        [ 0.4635,  1.0000,  0.5603,  ..., -0.1695, -0.4697, -0.6980],\n",
            "        [ 0.5006,  1.0000,  0.7783,  ...,  0.8103, -0.3773, -0.6213],\n",
            "        [-0.5247,  0.9947, -0.5990,  ..., -0.7529,  0.1080, -0.4749]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 4.7261e-01,  9.9994e-01,  7.4043e-01, -9.4355e-01, -4.7757e-01,\n",
            "          9.3322e-01,  6.8218e-01,  7.8296e-01, -9.9627e-01, -5.8649e-01,\n",
            "          7.9439e-01, -5.7601e-01,  4.8598e-01,  9.9872e-01,  4.1817e-01,\n",
            "         -1.0248e-01,  6.9686e-01, -9.6031e-01,  5.9779e-01, -1.6998e-01,\n",
            "          3.0671e-01, -7.8580e-01,  7.8909e-01, -2.9007e-01,  7.9638e-01,\n",
            "          7.5065e-01, -5.0592e-01,  4.6583e-01, -1.2240e-01,  2.1105e-01,\n",
            "         -5.8468e-01, -1.8461e-01,  8.9451e-01,  6.0737e-01,  7.6234e-01,\n",
            "         -9.2200e-01, -2.6497e-01, -9.5013e-01, -9.7655e-01, -9.9472e-01,\n",
            "          2.8953e-01, -3.8575e-01,  9.9929e-01, -7.9938e-01,  9.9472e-01,\n",
            "         -9.8639e-01,  5.2647e-01, -3.0159e-01,  5.3552e-01,  4.0845e-01,\n",
            "         -6.7001e-01,  9.4277e-01,  7.5545e-01,  8.2118e-01, -6.0190e-01,\n",
            "         -7.5948e-01, -7.7051e-01,  4.3117e-01, -8.3294e-01, -5.0889e-01,\n",
            "          7.7152e-01,  7.7410e-01, -5.6457e-01, -9.5389e-02, -8.5963e-01,\n",
            "         -5.7596e-01,  5.6216e-01,  4.3086e-01, -6.6877e-01, -9.1093e-01,\n",
            "          8.3707e-01, -9.2642e-01,  5.9401e-01,  2.5982e-01, -3.2078e-01,\n",
            "          7.8579e-01, -8.6614e-01,  9.1048e-01, -7.6186e-01,  9.8667e-01,\n",
            "          6.3732e-01,  3.9959e-01,  6.0190e-01, -9.9990e-01,  6.4714e-01,\n",
            "         -8.7153e-01,  9.8034e-01, -9.7094e-01, -9.3719e-01,  6.6592e-01,\n",
            "          7.7286e-01,  6.2594e-01,  8.0045e-01, -1.0999e-01, -4.0174e-01,\n",
            "         -8.9714e-01, -6.6291e-01,  5.2660e-01, -9.9781e-01,  7.4626e-01,\n",
            "          5.8506e-01,  7.2560e-01, -6.8914e-01, -5.5773e-01, -9.9850e-01,\n",
            "          5.0808e-01, -6.2108e-01, -4.5987e-01, -9.9990e-01, -6.9988e-01,\n",
            "         -8.1112e-01, -7.7879e-01, -3.1398e-01,  8.5692e-01,  5.4797e-01,\n",
            "          9.9950e-01,  8.6308e-01,  9.9749e-01, -9.9992e-01, -9.9015e-01,\n",
            "          1.8574e-02,  9.2341e-01, -5.9476e-01,  8.8125e-02,  5.2863e-01,\n",
            "         -9.5623e-01,  7.2789e-01, -9.9739e-01,  6.2696e-01, -9.1707e-01,\n",
            "         -4.2911e-01,  7.6370e-01,  8.7824e-01,  5.5909e-01, -6.1495e-01,\n",
            "          5.4767e-01, -9.9944e-01, -7.0372e-03, -6.7876e-01, -9.8947e-01,\n",
            "          9.8931e-01,  7.8445e-01,  8.4466e-01, -4.0759e-01, -2.8306e-01,\n",
            "          7.9632e-01,  8.3033e-01, -6.8488e-01,  1.6753e-01, -1.7009e-01,\n",
            "         -8.0049e-01,  7.9127e-01,  3.8231e-01, -4.3462e-01, -9.9989e-01,\n",
            "          4.9338e-01, -7.1773e-01,  9.2467e-01, -9.8665e-01,  9.6608e-01,\n",
            "         -9.7289e-01, -9.9993e-01,  3.1228e-01,  2.6238e-01, -7.7506e-01,\n",
            "          7.8754e-01, -7.7176e-01,  8.5923e-01, -5.6801e-01,  6.7474e-01,\n",
            "          5.8117e-01,  6.0810e-01,  3.4737e-01, -5.6039e-01,  2.9207e-01,\n",
            "         -6.5830e-01,  8.0190e-01, -7.2512e-01, -6.4799e-01, -9.3857e-01,\n",
            "          9.5876e-01, -3.7818e-01,  9.7260e-01, -9.3745e-01, -7.2905e-01,\n",
            "          4.9593e-01,  2.4775e-01, -9.9998e-01,  8.9982e-01,  4.7725e-01,\n",
            "          3.6653e-01,  6.4887e-01,  2.6405e-01, -4.5069e-01, -4.8835e-02,\n",
            "          4.1834e-02, -4.8272e-01,  6.2776e-01, -2.5886e-01,  8.5579e-01,\n",
            "          2.9485e-01, -9.9928e-01,  7.4393e-01,  9.9139e-01,  1.2843e-01,\n",
            "         -3.7487e-01,  9.0123e-02,  9.7019e-01, -9.9497e-01, -5.8433e-01,\n",
            "          1.4114e-01, -5.2977e-01,  4.2894e-01,  4.1958e-01, -3.9006e-01,\n",
            "         -7.4749e-01,  5.6284e-01,  3.3615e-01, -2.4928e-01, -5.0048e-01,\n",
            "          2.4111e-01,  5.4383e-01, -2.4388e-01,  4.0221e-01,  7.1511e-01,\n",
            "          9.9896e-01, -4.5143e-01, -5.9775e-01,  6.1959e-01, -9.9923e-01,\n",
            "          7.8377e-01,  4.8619e-01, -3.8917e-01, -6.7536e-01,  9.8694e-01,\n",
            "          7.1964e-01,  6.5640e-01,  9.8142e-01, -9.4379e-01, -1.8191e-01,\n",
            "         -5.8409e-01,  8.7541e-01, -4.5942e-01, -9.9618e-02,  9.9993e-01,\n",
            "         -9.9085e-01,  9.8005e-01,  9.0318e-01, -4.7249e-02, -4.6202e-01,\n",
            "          7.1848e-01,  3.1064e-01, -3.3730e-01, -9.5232e-02, -6.2851e-01,\n",
            "          9.9087e-01, -6.3538e-01, -9.7460e-01,  5.2020e-01, -2.3308e-01,\n",
            "         -8.8089e-01, -8.2764e-01,  8.0750e-01, -4.8363e-01,  9.6763e-01,\n",
            "          9.9978e-01,  7.7498e-01,  4.7279e-01,  6.5965e-01,  5.1020e-01,\n",
            "          7.2253e-01, -9.7847e-01,  9.5835e-01,  9.9993e-01, -9.3706e-01,\n",
            "          4.7240e-01,  9.9981e-01,  6.2450e-01, -1.8596e-01, -5.9254e-01,\n",
            "          3.0358e-01, -9.7411e-01, -1.6149e-01, -4.9915e-01, -4.7170e-01,\n",
            "         -5.5056e-01,  2.3369e-04, -9.2700e-01, -9.9906e-01, -9.7683e-01,\n",
            "          9.6028e-01, -6.5162e-01, -6.3006e-01,  5.0747e-01, -7.4318e-01,\n",
            "          5.0955e-01, -7.1836e-01,  9.8822e-01, -6.8005e-01,  9.9986e-01,\n",
            "          5.5192e-01, -5.9563e-01, -9.5079e-01, -2.7486e-01,  4.7514e-01,\n",
            "          9.4638e-02,  9.9881e-01,  4.9422e-02, -5.7663e-01,  7.1369e-01,\n",
            "          5.9679e-01,  2.3072e-01,  9.1189e-01, -5.8589e-01,  6.1566e-01,\n",
            "          3.7521e-01,  3.9302e-02, -9.3405e-01, -3.0689e-01, -8.3895e-01,\n",
            "          7.4137e-01,  9.5281e-01,  6.8151e-01,  3.1604e-01,  9.5049e-01,\n",
            "          8.0552e-01, -9.9995e-01,  9.9835e-01,  9.7317e-01, -9.8881e-01,\n",
            "          8.0507e-01, -1.2433e-01,  8.7962e-01, -2.1942e-01,  4.1349e-01,\n",
            "         -8.7130e-01, -8.0553e-01, -9.7147e-01,  7.5035e-01,  1.8264e-01,\n",
            "         -7.0195e-01,  2.4712e-01, -8.9971e-01,  7.7182e-01,  1.1831e-01,\n",
            "          8.1519e-01, -3.1514e-01,  2.1641e-01, -9.9365e-01,  6.5229e-01,\n",
            "          8.5989e-01, -2.4646e-01,  7.4322e-01,  9.8286e-01,  7.3883e-04,\n",
            "          9.9993e-01, -7.3414e-01, -5.4252e-01,  2.1559e-01,  5.4374e-01,\n",
            "          3.8904e-01,  4.3567e-01, -2.8474e-01,  5.7850e-01, -9.9996e-01,\n",
            "          2.9347e-01, -5.0950e-01,  2.5852e-01,  6.7417e-01, -9.8027e-01,\n",
            "          5.5228e-01, -4.4316e-01,  7.8106e-02, -2.0686e-01,  3.0465e-01,\n",
            "          5.6190e-01,  9.9842e-01,  3.5024e-01, -4.7536e-01, -6.5695e-01,\n",
            "          6.3726e-02,  1.6997e-02,  8.8884e-01,  6.1654e-01,  9.8684e-01,\n",
            "         -7.9998e-01, -3.2079e-01,  6.3948e-01,  1.1214e-02, -6.4881e-01,\n",
            "         -1.1722e-01,  6.1000e-01,  2.1283e-02,  9.0694e-01,  7.2808e-01,\n",
            "         -5.7801e-01, -5.3803e-01,  8.2629e-01, -9.9767e-01,  9.9984e-01,\n",
            "          2.6038e-01,  4.9828e-01,  9.2118e-01, -2.8828e-01,  6.7181e-01,\n",
            "          4.8489e-01,  3.0160e-01, -6.8107e-01,  9.6970e-01,  7.2137e-01,\n",
            "          5.9895e-01,  1.0460e-01, -1.6091e-01, -3.3352e-02, -9.2051e-01,\n",
            "          4.9631e-01,  3.7809e-01, -4.1101e-01, -9.7323e-01,  9.8372e-01,\n",
            "         -9.7479e-01,  4.0588e-01, -1.7507e-01,  8.0101e-01,  9.2096e-01,\n",
            "         -2.8864e-01, -8.6239e-01, -1.4254e-01,  4.5124e-01, -6.6349e-01,\n",
            "         -7.9460e-01, -9.8953e-01, -8.2049e-02, -8.6278e-01,  9.9978e-01,\n",
            "         -9.8645e-01,  5.0360e-01, -8.9247e-01, -8.9967e-01,  7.3026e-01,\n",
            "         -4.6160e-01, -5.5703e-01, -8.1929e-01, -1.4253e-01, -4.7874e-01,\n",
            "          7.4178e-01,  1.9313e-02,  7.2322e-01, -4.7167e-01,  2.8211e-01,\n",
            "          7.3565e-01,  1.5179e-01,  2.4365e-01,  9.0405e-01, -6.1203e-01,\n",
            "         -9.4053e-01, -6.7303e-01, -5.4305e-01, -7.0743e-01,  9.4885e-01,\n",
            "         -9.0873e-01, -8.2646e-01,  9.9996e-01, -9.7867e-01,  1.8594e-01,\n",
            "         -3.5437e-01, -9.9559e-01,  5.6625e-01, -2.7463e-01, -9.3038e-01,\n",
            "         -6.1901e-01, -7.9923e-01,  6.3967e-01,  9.2039e-01,  9.9869e-01,\n",
            "          2.3760e-01,  2.6597e-01, -9.3846e-01, -6.3629e-01,  9.9678e-01,\n",
            "         -9.4381e-01, -4.4642e-01,  3.5891e-01, -9.9301e-01,  9.2233e-01,\n",
            "          2.5370e-01, -4.5245e-01,  8.2270e-01, -6.8292e-01,  9.5797e-01,\n",
            "          6.2427e-01, -9.9665e-01,  5.6074e-01,  6.6644e-01, -3.2676e-01,\n",
            "          8.4652e-01,  2.9479e-01,  2.6446e-01, -9.4273e-01, -6.0343e-02,\n",
            "          9.9866e-01,  4.2664e-01, -7.6401e-01, -1.4735e-02,  7.9020e-01,\n",
            "          7.7230e-01,  9.9992e-01, -9.5747e-01,  6.4892e-01,  9.9920e-01,\n",
            "         -2.7466e-01,  4.4836e-01,  3.0314e-01, -7.4714e-01,  7.4231e-02,\n",
            "          4.6690e-01, -9.7386e-01,  9.9972e-01,  3.1964e-02, -9.8620e-01,\n",
            "         -9.9988e-01,  2.7911e-01, -8.0426e-01,  7.5702e-01,  9.6785e-01,\n",
            "          6.1130e-01,  8.6147e-01,  2.5340e-01, -9.9824e-01, -7.2256e-02,\n",
            "         -5.4478e-01, -9.9959e-01, -9.9890e-01,  8.3065e-01,  1.7731e-01,\n",
            "          1.7836e-01,  7.7010e-01, -2.9439e-02, -7.3985e-01,  9.9941e-01,\n",
            "          9.0011e-01, -9.9984e-01, -1.2131e-01,  2.2313e-01,  9.6122e-01,\n",
            "         -7.0715e-01,  5.7873e-01,  4.2281e-01,  4.0845e-01, -3.7201e-01,\n",
            "         -9.9991e-01, -4.5825e-01,  9.6335e-01, -1.4013e-02, -1.6942e-02,\n",
            "          9.9908e-01,  6.7378e-01,  4.4004e-01, -9.3608e-01, -1.2752e-01,\n",
            "          6.4073e-01, -9.9991e-01, -7.0770e-01,  9.9962e-01, -1.8979e-01,\n",
            "         -1.9191e-02, -4.7641e-01,  3.4130e-01,  5.7211e-01,  5.9144e-01,\n",
            "          3.8332e-02, -9.9548e-01,  9.9283e-01,  8.6785e-01, -9.1745e-01,\n",
            "          9.9590e-01, -5.5083e-01, -6.8359e-01, -7.3714e-01, -6.5193e-01,\n",
            "          7.1237e-01, -7.2200e-01,  4.7711e-01, -2.0061e-01,  9.7753e-01,\n",
            "          8.7439e-01, -3.6056e-01,  7.3130e-01,  9.0739e-01, -7.8657e-01,\n",
            "         -2.9736e-01,  7.3927e-01,  5.7955e-01,  4.4139e-01,  9.7642e-01,\n",
            "         -4.3327e-01, -7.0940e-01, -4.3040e-01,  6.2356e-01,  9.1769e-01,\n",
            "         -9.9978e-01,  9.1783e-01, -4.8238e-01, -8.6726e-01,  6.3506e-01,\n",
            "         -5.4287e-01, -5.6807e-01, -2.3853e-01, -5.8673e-01, -6.3828e-01,\n",
            "          1.4194e-01,  9.4102e-01,  7.0616e-01,  7.3113e-01, -9.8167e-01,\n",
            "         -9.9981e-01, -6.8812e-01, -5.6243e-01, -7.9296e-01, -5.1031e-01,\n",
            "          3.0331e-01,  9.3002e-01,  1.8297e-01,  4.7623e-01,  2.2843e-01,\n",
            "          9.9964e-01, -4.0166e-01,  9.8973e-01, -7.8241e-01,  9.2462e-01,\n",
            "         -9.8666e-01,  4.8373e-01,  5.4115e-01, -9.2689e-01, -4.5715e-01,\n",
            "          9.5196e-01, -3.0058e-01,  8.1676e-01, -9.6498e-01,  6.1138e-01,\n",
            "          9.9994e-01, -7.1196e-01, -6.4835e-01,  6.4139e-01, -8.6439e-01,\n",
            "          7.5104e-01,  3.2810e-02,  9.9137e-01, -9.9992e-01,  9.8700e-01,\n",
            "         -1.5012e-01,  4.3237e-01,  5.4413e-01,  5.7631e-01,  5.9343e-01,\n",
            "         -5.9193e-01, -4.7221e-01, -9.8651e-01,  6.4524e-01,  3.7315e-01,\n",
            "         -6.4624e-01,  2.7494e-01,  9.0311e-01, -7.5458e-01, -9.9684e-01,\n",
            "         -5.9401e-01,  4.7177e-01,  9.3451e-01, -4.7129e-01, -9.8869e-01,\n",
            "          9.5173e-01, -1.8587e-01,  9.6360e-01,  2.4864e-01, -7.0269e-01,\n",
            "         -4.4153e-01, -1.1882e-01, -5.7789e-01,  5.2852e-01,  6.7922e-01,\n",
            "          7.9422e-01,  3.0424e-01, -8.7264e-01, -4.7856e-01,  1.0447e-01,\n",
            "         -7.5603e-01,  7.1169e-01, -3.6212e-01, -1.8261e-01,  7.2362e-01,\n",
            "          8.2394e-01,  9.6938e-01,  3.8906e-01,  2.0759e-01,  7.4169e-01,\n",
            "         -7.2725e-01, -6.2328e-01, -9.9951e-01,  9.9856e-01,  8.4134e-01,\n",
            "         -8.3141e-01, -9.9956e-01,  9.2747e-01,  1.6642e-01, -3.2134e-01,\n",
            "          7.0544e-01, -2.2227e-02, -6.5300e-01,  3.2338e-01,  7.0392e-01,\n",
            "         -9.9994e-01, -4.3879e-01,  1.4222e-01, -3.8053e-01, -6.9283e-01,\n",
            "         -9.9966e-01, -5.6093e-01,  7.2067e-02, -2.5457e-01,  2.7474e-01,\n",
            "          9.9737e-01, -3.9358e-01, -9.8487e-01, -9.4774e-01, -8.3131e-02,\n",
            "          6.0320e-01,  1.6480e-01, -9.3894e-01, -5.4692e-01,  8.0390e-01,\n",
            "         -9.9783e-01,  7.0519e-01, -5.5182e-01, -5.0000e-01,  2.0700e-01,\n",
            "          7.1960e-01,  8.9781e-01, -9.9988e-01,  8.5524e-01, -6.4054e-01,\n",
            "          8.9081e-01, -4.9517e-01,  5.2264e-01,  4.3705e-01,  2.3700e-01,\n",
            "         -9.9516e-01,  7.9200e-01,  2.9624e-01,  7.8375e-01,  7.3540e-01,\n",
            "          7.6820e-01,  3.3546e-02, -8.5844e-01, -6.4866e-01,  9.7795e-01,\n",
            "          9.6690e-01, -6.3113e-01,  6.2995e-01,  9.9796e-01, -6.0320e-01,\n",
            "          5.1353e-01,  6.4023e-01,  1.4416e-01, -9.9873e-01, -8.2406e-01,\n",
            "         -1.7917e-01, -6.3300e-01, -8.0789e-01]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training... :   0%|          | 0/127 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f3243dfd90014c449a91e5e3826c00a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.8346,  0.9570, -0.8885,  ..., -0.9063, -0.1653,  0.6487],\n",
            "        [ 0.8393,  1.0000,  0.9727,  ...,  0.8009, -0.1464, -0.9095],\n",
            "        [ 0.6321,  0.9884,  0.8732,  ...,  0.7666, -0.8030, -0.4701],\n",
            "        ...,\n",
            "        [-0.4189,  1.0000, -0.5436,  ..., -0.7384, -0.0113, -0.7250],\n",
            "        [-0.0257,  0.9251, -0.8862,  ..., -0.8306,  0.5875,  0.0625],\n",
            "        [ 0.6647,  0.9409,  0.7963,  ...,  0.8454, -0.8301, -0.3942]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4462, -0.2235, -0.9075,  ..., -0.8832,  0.3004,  0.3871],\n",
            "        [ 0.7688,  1.0000,  0.9661,  ...,  0.6445, -0.6540, -0.8041],\n",
            "        [-0.6591, -0.8556, -0.9174,  ..., -0.9101,  0.1681,  0.5977],\n",
            "        ...,\n",
            "        [ 0.1276,  0.9991, -0.8902,  ..., -0.9089,  0.6450, -0.0875],\n",
            "        [ 0.7395,  0.9973,  0.8198,  ...,  0.9128, -0.8174, -0.3475],\n",
            "        [ 0.4415,  0.9993,  0.8086,  ...,  0.8365, -0.7663, -0.2545]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1474,  0.9817, -0.8428,  ..., -0.8955,  0.7440,  0.2241],\n",
            "        [ 0.5587,  0.9993,  0.9247,  ...,  0.6735, -0.4397, -0.6279],\n",
            "        [ 0.7348,  1.0000,  0.9453,  ...,  0.9061, -0.5636, -0.8274],\n",
            "        ...,\n",
            "        [ 0.6861,  0.9998,  0.9130,  ...,  0.8536, -0.5565, -0.6146],\n",
            "        [ 0.6151,  0.9987,  0.8709,  ...,  0.8477, -0.8743, -0.5346],\n",
            "        [ 0.7221,  0.9934,  0.8601,  ...,  0.9164, -0.8727, -0.2172]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7501,  0.9881,  0.8372,  ...,  0.9072, -0.7963, -0.5904],\n",
            "        [ 0.4002,  0.9998,  0.9218,  ...,  0.5711, -0.2342, -0.8456],\n",
            "        [ 0.4610,  0.9947,  0.7908,  ...,  0.7147, -0.6741, -0.1240],\n",
            "        ...,\n",
            "        [-0.4116,  0.7331, -0.9127,  ..., -0.7919,  0.4713, -0.0146],\n",
            "        [ 0.7149,  0.9998,  0.8160,  ...,  0.8543, -0.7384, -0.4144],\n",
            "        [-0.3225, -0.9606, -0.9575,  ..., -0.9400,  0.1451,  0.2682]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3424, -0.2938, -0.9471,  ..., -0.8845,  0.2544,  0.5754],\n",
            "        [ 0.6708,  1.0000,  0.9436,  ...,  0.7888, -0.0313, -0.9204],\n",
            "        [-0.5785, -0.8445, -0.9270,  ..., -0.8721,  0.2019,  0.7229],\n",
            "        ...,\n",
            "        [ 0.3953,  0.9999,  0.9472,  ...,  0.8343, -0.6520, -0.7903],\n",
            "        [ 0.6961,  0.9926,  0.8105,  ...,  0.8666, -0.8558, -0.1106],\n",
            "        [ 0.7344,  0.9999,  0.9309,  ...,  0.8525, -0.3513, -0.7176]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6073,  0.9975,  0.9485,  ...,  0.8292, -0.7524, -0.1354],\n",
            "        [ 0.2891,  0.9553,  0.8744,  ...,  0.5872, -0.8652, -0.2855],\n",
            "        [-0.6125, -0.9518, -0.8656,  ..., -0.8725, -0.1368,  0.4948],\n",
            "        ...,\n",
            "        [ 0.6436,  0.9906,  0.7391,  ...,  0.8578, -0.7504,  0.0076],\n",
            "        [-0.3241,  0.9922, -0.7523,  ..., -0.6977,  0.3437, -0.1338],\n",
            "        [-0.6614, -0.9223, -0.9357,  ..., -0.8580,  0.4947,  0.4957]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6357, -0.8313, -0.9196,  ..., -0.9250,  0.0504,  0.8260],\n",
            "        [ 0.6572,  0.9998,  0.9043,  ...,  0.8778, -0.4396, -0.7111],\n",
            "        [ 0.6771,  0.9986,  0.8765,  ...,  0.8615, -0.8417, -0.3452],\n",
            "        ...,\n",
            "        [ 0.7389,  1.0000,  0.9361,  ...,  0.9182, -0.5156, -0.6427],\n",
            "        [ 0.7253,  0.9983,  0.8368,  ...,  0.9202, -0.6930, -0.2330],\n",
            "        [-0.6537,  0.9157, -0.9175,  ..., -0.9268,  0.3620,  0.0107]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2614,  0.6029, -0.9198,  ..., -0.7910,  0.3592,  0.2061],\n",
            "        [ 0.7124,  0.9998,  0.8393,  ...,  0.9109, -0.7602, -0.4721],\n",
            "        [ 0.7699,  0.9999,  0.8713,  ...,  0.9197, -0.7373, -0.6370],\n",
            "        ...,\n",
            "        [-0.7392,  0.1837, -0.9437,  ..., -0.9004,  0.0855,  0.4781],\n",
            "        [-0.7220, -0.9220, -0.9314,  ..., -0.8689,  0.2386,  0.5994],\n",
            "        [-0.3177, -0.9598, -0.9399,  ..., -0.8672,  0.5864,  0.2986]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.7085,  0.4856, -0.8906,  ..., -0.8489,  0.0290,  0.5281],\n",
            "        [ 0.6758,  0.9899,  0.6265,  ...,  0.8050, -0.7830, -0.4501],\n",
            "        [-0.5101, -0.1637, -0.9010,  ..., -0.8852,  0.5659,  0.5367],\n",
            "        ...,\n",
            "        [-0.5239, -0.3408, -0.9545,  ..., -0.8847,  0.4188,  0.6141],\n",
            "        [ 0.3496,  0.9844,  0.7701,  ...,  0.8567, -0.7251, -0.1290],\n",
            "        [-0.4740, -0.5400, -0.9497,  ..., -0.8727,  0.1262,  0.5205]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6739,  1.0000,  0.8598,  ...,  0.7452, -0.5279, -0.7094],\n",
            "        [-0.4772, -0.0099, -0.9405,  ..., -0.8836,  0.2533,  0.3842],\n",
            "        [ 0.7160,  1.0000,  0.9434,  ...,  0.7054, -0.2893, -0.8505],\n",
            "        ...,\n",
            "        [ 0.6733,  1.0000,  0.8969,  ...,  0.9284, -0.3920, -0.6939],\n",
            "        [ 0.4306,  0.9939,  0.8927,  ...,  0.8558, -0.8547, -0.5234],\n",
            "        [ 0.7811,  0.9999,  0.8278,  ...,  0.9248, -0.7171, -0.5246]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4402, -0.9997, -0.9484,  ..., -0.8507,  0.2433,  0.7037],\n",
            "        [ 0.6699,  0.9991,  0.7662,  ...,  0.8297, -0.7816, -0.0337],\n",
            "        [-0.4133, -0.5805, -0.8405,  ..., -0.7865,  0.2196, -0.2394],\n",
            "        ...,\n",
            "        [ 0.8339,  1.0000,  0.9691,  ...,  0.6573,  0.0481, -0.9169],\n",
            "        [ 0.5573,  0.9998,  0.8773,  ...,  0.8112, -0.7801, -0.4482],\n",
            "        [-0.5653,  0.9966, -0.7389,  ..., -0.8833,  0.1151, -0.1948]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4480,  0.7559, -0.9291,  ..., -0.9395,  0.1009,  0.0429],\n",
            "        [-0.6988,  0.9814, -0.8073,  ..., -0.5783,  0.2603,  0.5193],\n",
            "        [ 0.0017,  0.9070, -0.8981,  ..., -0.8638,  0.4583,  0.0081],\n",
            "        ...,\n",
            "        [ 0.5119,  1.0000,  0.9263,  ...,  0.7400, -0.1078, -0.8922],\n",
            "        [ 0.7490,  0.9994,  0.8177,  ...,  0.7964, -0.7572, -0.5105],\n",
            "        [ 0.5430,  1.0000,  0.7908,  ...,  0.6972, -0.4892, -0.4222]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7675,  0.9961,  0.8375,  ...,  0.9140, -0.7809, -0.3417],\n",
            "        [-0.3091, -0.5925, -0.8789,  ..., -0.9425,  0.3788,  0.2604],\n",
            "        [-0.4513,  0.3376, -0.9587,  ..., -0.8148,  0.4285,  0.6557],\n",
            "        ...,\n",
            "        [ 0.3792,  0.9969,  0.8834,  ...,  0.8597, -0.7926, -0.3057],\n",
            "        [ 0.7582,  0.9978,  0.6853,  ...,  0.8443, -0.5466, -0.6674],\n",
            "        [ 0.7368,  0.9977,  0.8493,  ...,  0.8417, -0.8176, -0.5403]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6481,  0.9957,  0.5795,  ...,  0.9077, -0.8849, -0.4794],\n",
            "        [-0.1216,  0.9998, -0.6199,  ..., -0.8456,  0.2727, -0.4615],\n",
            "        [-0.5102, -0.9923, -0.9353,  ..., -0.9209,  0.1552,  0.5814],\n",
            "        ...,\n",
            "        [ 0.7575,  0.9994,  0.9339,  ...,  0.8549, -0.6217, -0.5687],\n",
            "        [-0.3008, -0.7576, -0.9544,  ..., -0.9119,  0.3487,  0.4459],\n",
            "        [ 0.6191,  0.9856,  0.7622,  ...,  0.7163, -0.7498, -0.2976]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5873,  0.9913,  0.6693,  ...,  0.8710, -0.8287, -0.1108],\n",
            "        [-0.4802, -0.9517, -0.9069,  ..., -0.8648,  0.3356,  0.3617],\n",
            "        [ 0.5481,  0.9690,  0.8790,  ...,  0.8874, -0.8829, -0.1834],\n",
            "        ...,\n",
            "        [-0.6195, -0.8775, -0.9368,  ..., -0.8956,  0.4577,  0.4941],\n",
            "        [-0.2962,  0.9999, -0.7660,  ..., -0.8232,  0.7777, -0.5591],\n",
            "        [ 0.5889,  0.9997,  0.9628,  ...,  0.7687, -0.6582, -0.5864]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6693,  0.9974,  0.8739,  ...,  0.9274, -0.7289, -0.2941],\n",
            "        [-0.3848, -0.4243, -0.9146,  ..., -0.8461,  0.1430,  0.4121],\n",
            "        [ 0.7468,  1.0000,  0.9762,  ...,  0.8292, -0.5625, -0.8304],\n",
            "        ...,\n",
            "        [-0.5650, -0.9884, -0.9258,  ..., -0.8965,  0.6733,  0.4403],\n",
            "        [-0.4519, -0.9415, -0.9372,  ..., -0.8971,  0.2313,  0.6115],\n",
            "        [-0.7114,  0.1757, -0.9267,  ..., -0.7480, -0.0459,  0.5801]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.7903,  0.5218, -0.9417,  ..., -0.8393,  0.2896,  0.4350],\n",
            "        [ 0.3503,  0.9897, -0.9076,  ..., -0.8292,  0.6684, -0.1586],\n",
            "        [ 0.3482,  0.9978,  0.8394,  ...,  0.8193, -0.9104, -0.2874],\n",
            "        ...,\n",
            "        [ 0.5700,  0.9976,  0.8807,  ...,  0.7724, -0.8534, -0.3775],\n",
            "        [ 0.7617,  0.9993,  0.7417,  ...,  0.9174, -0.8388, -0.4137],\n",
            "        [ 0.0068,  0.9997,  0.7466,  ...,  0.0897,  0.4109, -0.8010]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4213,  0.9883, -0.8620,  ..., -0.8918,  0.6121,  0.2247],\n",
            "        [-0.5634, -0.9192, -0.8744,  ..., -0.8680,  0.4275,  0.2518],\n",
            "        [ 0.4894,  0.9989,  0.8867,  ...,  0.8190, -0.8237, -0.4246],\n",
            "        ...,\n",
            "        [-0.1994,  0.9972, -0.6783,  ..., -0.6890,  0.5609, -0.4038],\n",
            "        [ 0.5363,  0.9700,  0.9195,  ...,  0.8897, -0.7958, -0.1632],\n",
            "        [ 0.6980,  0.9738,  0.8848,  ...,  0.8198, -0.7670, -0.5301]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6178,  0.9957,  0.8128,  ...,  0.8950, -0.8478, -0.2198],\n",
            "        [ 0.6357,  0.9934,  0.9135,  ...,  0.8948, -0.8372, -0.3672],\n",
            "        [-0.7340, -0.4586, -0.9270,  ..., -0.9142, -0.0601,  0.6269],\n",
            "        ...,\n",
            "        [-0.3170,  0.9962,  0.2523,  ..., -0.3685,  0.2572, -0.6864],\n",
            "        [ 0.7239,  0.9914,  0.7657,  ...,  0.8973, -0.7680, -0.3774],\n",
            "        [ 0.8286,  1.0000,  0.5222,  ...,  0.7291, -0.5471, -0.3776]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5060, -0.7041, -0.9253,  ..., -0.8369,  0.4474,  0.5320],\n",
            "        [ 0.6600,  0.9998,  0.9402,  ...,  0.8799, -0.5097, -0.7218],\n",
            "        [ 0.7435,  0.9991,  0.9439,  ...,  0.8659, -0.7347, -0.3374],\n",
            "        ...,\n",
            "        [-0.2893,  0.8156, -0.7956,  ..., -0.8132,  0.5278,  0.3581],\n",
            "        [-0.2315, -0.9985, -0.9146,  ..., -0.8233,  0.3954,  0.0189],\n",
            "        [ 0.6994,  0.9971,  0.9115,  ...,  0.9020, -0.7386, -0.5363]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7916,  0.9999,  0.9359,  ...,  0.9221, -0.6447, -0.5355],\n",
            "        [ 0.6172,  0.9990,  0.9053,  ...,  0.8926, -0.6592, -0.5604],\n",
            "        [ 0.3441,  0.9998,  0.6901,  ...,  0.7365, -0.5602, -0.3664],\n",
            "        ...,\n",
            "        [-0.5702, -0.9372, -0.9511,  ..., -0.8547,  0.2801,  0.4215],\n",
            "        [-0.4883, -0.7244, -0.9484,  ..., -0.9506, -0.2468,  0.5446],\n",
            "        [ 0.7554,  1.0000,  0.9412,  ...,  0.6564,  0.2143, -0.9025]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5595,  0.9880, -0.9445,  ..., -0.8979,  0.3624,  0.5002],\n",
            "        [-0.8259,  0.9097, -0.8756,  ..., -0.8982,  0.0530,  0.3524],\n",
            "        [ 0.7579,  0.9999,  0.9333,  ...,  0.8701, -0.7113, -0.6104],\n",
            "        ...,\n",
            "        [-0.2717, -0.4876, -0.9314,  ..., -0.8316,  0.5415,  0.3111],\n",
            "        [ 0.6374,  0.9998,  0.8653,  ...,  0.8594, -0.5793, -0.7086],\n",
            "        [-0.6097,  0.4182, -0.9151,  ..., -0.6387,  0.1303,  0.3675]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7278,  0.9989,  0.8234,  ...,  0.8569, -0.7607, -0.3741],\n",
            "        [ 0.7017,  0.9406,  0.7764,  ...,  0.8686, -0.8583,  0.0451],\n",
            "        [ 0.1845,  0.9875, -0.7935,  ..., -0.9240,  0.5879, -0.3814],\n",
            "        ...,\n",
            "        [ 0.4880,  0.9996,  0.8257,  ...,  0.8221, -0.6606, -0.3148],\n",
            "        [-0.2491, -0.7516, -0.8390,  ..., -0.8555,  0.4931, -0.2146],\n",
            "        [ 0.8101,  1.0000,  0.9285,  ...,  0.7512, -0.5494, -0.8807]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3391, -0.9196, -0.8958,  ..., -0.8880,  0.3554,  0.6254],\n",
            "        [ 0.5464,  0.9864,  0.8209,  ...,  0.8601, -0.8405, -0.0954],\n",
            "        [ 0.7157,  1.0000,  0.9355,  ...,  0.3515,  0.4919, -0.9826],\n",
            "        ...,\n",
            "        [-0.2494,  0.9866, -0.8727,  ..., -0.9250,  0.1006, -0.0860],\n",
            "        [ 0.6090,  0.9968,  0.8939,  ...,  0.8627, -0.8179, -0.1344],\n",
            "        [ 0.7438,  0.9998,  0.8496,  ...,  0.9327, -0.7631, -0.5358]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5262,  0.9999,  0.9073,  ...,  0.7869, -0.4932, -0.8035],\n",
            "        [ 0.6241,  0.9990,  0.9205,  ...,  0.8833, -0.7901, -0.5261],\n",
            "        [-0.6655, -0.9852, -0.9417,  ..., -0.9254,  0.0253,  0.8229],\n",
            "        ...,\n",
            "        [-0.6643, -0.6251, -0.8732,  ..., -0.8795,  0.5441,  0.5906],\n",
            "        [ 0.6830,  0.9990,  0.7738,  ...,  0.7703, -0.5508, -0.4294],\n",
            "        [ 0.2029,  0.9976,  0.8745,  ...,  0.8726, -0.7973, -0.3730]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4542,  0.0353, -0.9109,  ..., -0.8712,  0.3176,  0.5521],\n",
            "        [ 0.5911,  0.9948,  0.8252,  ...,  0.7869, -0.7875, -0.2815],\n",
            "        [ 0.7309,  0.9969,  0.8357,  ...,  0.8350, -0.8900, -0.0783],\n",
            "        ...,\n",
            "        [-0.7175, -0.9998, -0.8417,  ..., -0.8211,  0.2042,  0.0104],\n",
            "        [ 0.6682,  0.9981,  0.9125,  ...,  0.8692, -0.7465, -0.6166],\n",
            "        [-0.3092,  0.9504, -0.7840,  ..., -0.8331,  0.7085,  0.1488]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6438, -0.8677, -0.9408,  ..., -0.9126,  0.2115,  0.6145],\n",
            "        [ 0.6316,  0.9978,  0.9118,  ...,  0.9133, -0.8080, -0.5103],\n",
            "        [ 0.4985,  1.0000,  0.9006,  ...,  0.7659, -0.5679, -0.7261],\n",
            "        ...,\n",
            "        [-0.4737,  0.9839, -0.8376,  ..., -0.8598,  0.4625, -0.3210],\n",
            "        [-0.5613, -0.9412, -0.9551,  ..., -0.9249,  0.1395,  0.8091],\n",
            "        [-0.3574,  0.9828, -0.8905,  ..., -0.8284,  0.3846,  0.3705]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6536,  0.6916, -0.7035,  ..., -0.8580,  0.3476, -0.2145],\n",
            "        [-0.5493, -0.8889, -0.9358,  ..., -0.9181,  0.0843,  0.6355],\n",
            "        [-0.0074,  0.9921, -0.6452,  ..., -0.7456,  0.3035, -0.3663],\n",
            "        ...,\n",
            "        [ 0.7734,  0.9998,  0.9013,  ...,  0.9244, -0.7253, -0.3467],\n",
            "        [-0.5508, -0.9311, -0.8660,  ..., -0.7829,  0.2912,  0.2635],\n",
            "        [-0.3329, -0.6510, -0.9243,  ..., -0.8516,  0.1647,  0.6088]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2636,  0.9758,  0.7515,  ...,  0.8299, -0.7577,  0.0559],\n",
            "        [ 0.5688,  0.9946,  0.8496,  ...,  0.6676, -0.5749, -0.2923],\n",
            "        [ 0.6902,  0.9959,  0.8330,  ...,  0.9134, -0.7442, -0.4475],\n",
            "        ...,\n",
            "        [-0.5904, -0.9458, -0.9479,  ..., -0.8252,  0.0895,  0.6468],\n",
            "        [ 0.6752,  0.9927,  0.8824,  ...,  0.8793, -0.8537, -0.4723],\n",
            "        [ 0.6707,  0.9983,  0.8501,  ...,  0.8068, -0.7038, -0.1430]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6259,  0.9997,  0.8843,  ...,  0.8787, -0.7493, -0.2716],\n",
            "        [ 0.7322,  0.9975,  0.7906,  ...,  0.8635, -0.8955, -0.3921],\n",
            "        [ 0.0161,  0.8371, -0.9540,  ..., -0.9056,  0.3353,  0.0335],\n",
            "        ...,\n",
            "        [ 0.6725,  0.9941,  0.8572,  ...,  0.8528, -0.8057, -0.4364],\n",
            "        [-0.6122, -0.7663, -0.9087,  ..., -0.9249,  0.3184,  0.4766],\n",
            "        [ 0.4661,  1.0000,  0.9472,  ...,  0.1835,  0.2456, -0.9630]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6997, -0.9701, -0.9452,  ..., -0.9158,  0.1969,  0.8412],\n",
            "        [-0.5668, -0.9972, -0.9372,  ..., -0.9008,  0.2003,  0.2902],\n",
            "        [ 0.7794,  0.9998,  0.8844,  ...,  0.8894, -0.6650, -0.3427],\n",
            "        ...,\n",
            "        [-0.5695,  0.5199, -0.9215,  ..., -0.8896,  0.3861,  0.7113],\n",
            "        [ 0.6460,  0.9969,  0.8699,  ...,  0.8860, -0.7995, -0.3463],\n",
            "        [-0.7662, -0.2371, -0.9390,  ..., -0.9288,  0.1036,  0.5035]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5188,  0.9988,  0.8232,  ...,  0.8626, -0.8540, -0.1048],\n",
            "        [ 0.6433,  0.9880,  0.8860,  ...,  0.9005, -0.8286, -0.1351],\n",
            "        [-0.5107,  0.2963, -0.7673,  ..., -0.9029,  0.4053,  0.0904],\n",
            "        ...,\n",
            "        [-0.3017,  0.9952, -0.8102,  ..., -0.8255,  0.2827, -0.2110],\n",
            "        [ 0.7623,  0.9902,  0.9234,  ...,  0.8612, -0.7592, -0.2643],\n",
            "        [ 0.8164,  1.0000,  0.9427,  ...,  0.7280, -0.1983, -0.8970]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6940,  1.0000,  0.8949,  ...,  0.9184, -0.7032, -0.7155],\n",
            "        [-0.2646,  0.8489, -0.9283,  ..., -0.7805,  0.4618,  0.1309],\n",
            "        [ 0.4184,  0.9992,  0.8459,  ...,  0.8580, -0.7718, -0.2656],\n",
            "        ...,\n",
            "        [ 0.8509,  1.0000,  0.7052,  ...,  0.8548, -0.8212, -0.7195],\n",
            "        [-0.5193, -0.9263, -0.9279,  ..., -0.8944,  0.3342,  0.5943],\n",
            "        [-0.5487, -0.8210, -0.9490,  ..., -0.8623,  0.2545,  0.6305]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2847, -0.3339, -0.7004,  ..., -0.8386, -0.5258,  0.6209],\n",
            "        [-0.3979, -0.2956, -0.9228,  ..., -0.7891,  0.5903,  0.4933],\n",
            "        [ 0.5770,  0.9938,  0.8128,  ...,  0.8643, -0.8810, -0.4248],\n",
            "        ...,\n",
            "        [-0.2317,  0.9525, -0.9123,  ..., -0.8227,  0.3547,  0.0872],\n",
            "        [ 0.6335,  0.9867,  0.8730,  ...,  0.8461, -0.8346, -0.4797],\n",
            "        [ 0.5970,  0.9888,  0.8317,  ...,  0.9124, -0.8799, -0.2513]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6586,  0.9990,  0.8906,  ...,  0.8580, -0.8285, -0.3366],\n",
            "        [ 0.4997,  0.9997,  0.8495,  ...,  0.9052, -0.8195, -0.5069],\n",
            "        [ 0.4220,  0.9937,  0.7743,  ...,  0.9120, -0.8255, -0.2151],\n",
            "        ...,\n",
            "        [-0.7035, -0.9377, -0.8875,  ..., -0.8153,  0.2053,  0.7709],\n",
            "        [-0.4300,  0.9575, -0.9004,  ..., -0.8030,  0.5371,  0.1838],\n",
            "        [ 0.7626,  1.0000,  0.9578,  ...,  0.8950, -0.4537, -0.7862]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6061, -0.8624, -0.9626,  ..., -0.9087,  0.3090,  0.7204],\n",
            "        [-0.4505, -0.4965, -0.9593,  ..., -0.9180,  0.3114,  0.5249],\n",
            "        [ 0.6566,  0.9230,  0.8698,  ...,  0.8853, -0.8070, -0.2412],\n",
            "        ...,\n",
            "        [ 0.6558,  0.9998,  0.8752,  ...,  0.8845, -0.6400, -0.3374],\n",
            "        [-0.5118,  0.9816, -0.8935,  ..., -0.8127, -0.1003,  0.6152],\n",
            "        [-0.7638, -0.8410, -0.9523,  ..., -0.9153,  0.5596,  0.6029]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5653, -0.0124, -0.9324,  ..., -0.9082,  0.4072,  0.0121],\n",
            "        [ 0.6523,  0.9936,  0.8466,  ...,  0.8661, -0.7768, -0.3756],\n",
            "        [ 0.0645,  0.9951, -0.7806,  ..., -0.5271,  0.5834, -0.3057],\n",
            "        ...,\n",
            "        [ 0.6890,  0.9993,  0.9473,  ...,  0.8872, -0.7829, -0.6978],\n",
            "        [ 0.6118,  0.9992,  0.8416,  ...,  0.7698, -0.7022, -0.6196],\n",
            "        [ 0.7930,  0.9945,  0.9002,  ...,  0.8876, -0.7478, -0.4109]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5075,  0.9872,  0.8936,  ...,  0.8458, -0.8227, -0.2779],\n",
            "        [ 0.2095,  0.9997,  0.7921,  ...,  0.8085, -0.5206, -0.4691],\n",
            "        [ 0.6439,  0.9992,  0.8929,  ...,  0.8576, -0.8172, -0.4569],\n",
            "        ...,\n",
            "        [-0.7777, -0.0229, -0.9461,  ..., -0.8356,  0.4312,  0.6990],\n",
            "        [-0.3396,  0.9722, -0.8723,  ..., -0.8743,  0.7283,  0.1219],\n",
            "        [-0.3218,  0.9759, -0.8927,  ..., -0.8820,  0.3893,  0.1052]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4653, -0.9167, -0.9433,  ..., -0.8896,  0.3420,  0.2803],\n",
            "        [-0.1226,  0.9985, -0.7481,  ..., -0.7816,  0.5681, -0.6623],\n",
            "        [ 0.8092,  0.9975,  0.8935,  ...,  0.8981, -0.7605, -0.5045],\n",
            "        ...,\n",
            "        [ 0.7252,  0.9925,  0.9232,  ...,  0.9246, -0.7929, -0.2787],\n",
            "        [ 0.5828,  0.9898,  0.7577,  ...,  0.8055, -0.8342, -0.3374],\n",
            "        [ 0.6610,  0.9948,  0.9567,  ...,  0.8595, -0.6934, -0.5535]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5834,  1.0000,  0.9470,  ...,  0.4635,  0.5712, -0.9552],\n",
            "        [ 0.6840,  0.9891,  0.8316,  ...,  0.8702, -0.8331, -0.0378],\n",
            "        [ 0.6831,  0.9864,  0.9152,  ...,  0.8931, -0.7135, -0.3521],\n",
            "        ...,\n",
            "        [-0.6288, -0.8856, -0.9551,  ..., -0.9451, -0.0041,  0.6296],\n",
            "        [ 0.3211,  0.9878,  0.7966,  ...,  0.9181, -0.8226, -0.3303],\n",
            "        [-0.4793, -0.9904, -0.9625,  ..., -0.9091,  0.2200,  0.6148]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6968,  0.9951,  0.9020,  ...,  0.8588, -0.7956, -0.4366],\n",
            "        [-0.5260, -0.6300, -0.9578,  ..., -0.8541,  0.1940,  0.5844],\n",
            "        [ 0.6178,  0.9985, -0.6994,  ..., -0.8648,  0.8978, -0.7305],\n",
            "        ...,\n",
            "        [ 0.6263,  0.9999,  0.9407,  ...,  0.8495, -0.4524, -0.7357],\n",
            "        [ 0.6098,  0.9986,  0.9333,  ...,  0.9151, -0.6700, -0.5310],\n",
            "        [ 0.5341,  0.9970,  0.6845,  ...,  0.8842, -0.8264, -0.3085]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.9193,  1.0000,  0.9307,  ...,  0.7494, -0.5037, -0.8590],\n",
            "        [ 0.1174,  1.0000, -0.3280,  ..., -0.2778,  0.2786, -0.6637],\n",
            "        [-0.3424, -0.6696, -0.9049,  ..., -0.8829,  0.4903,  0.3563],\n",
            "        ...,\n",
            "        [ 0.7750,  0.9832,  0.8203,  ...,  0.9083, -0.8491, -0.0184],\n",
            "        [ 0.6010,  0.9496,  0.8541,  ...,  0.7133, -0.9053, -0.1807],\n",
            "        [ 0.7360,  0.9998,  0.9105,  ...,  0.8147, -0.8646, -0.3682]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7616,  0.9985,  0.8361,  ...,  0.7972, -0.8384, -0.4216],\n",
            "        [ 0.5194,  0.9939,  0.8438,  ...,  0.8442, -0.8306, -0.3600],\n",
            "        [ 0.6100,  0.9998,  0.8744,  ...,  0.8510, -0.8408, -0.4416],\n",
            "        ...,\n",
            "        [-0.0551,  0.9864, -0.8740,  ..., -0.8352,  0.3417,  0.0593],\n",
            "        [-0.5094, -0.9582, -0.9412,  ..., -0.9195,  0.1028,  0.7436],\n",
            "        [-0.4808, -0.9679, -0.9337,  ..., -0.7911,  0.4585,  0.5711]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6671,  0.9999,  0.8650,  ...,  0.8441, -0.6940, -0.3275],\n",
            "        [ 0.6236,  1.0000,  0.9067,  ...,  0.7820, -0.7082, -0.8042],\n",
            "        [ 0.1955,  0.9954,  0.7838,  ...,  0.8542, -0.8822, -0.1558],\n",
            "        ...,\n",
            "        [-0.6130, -0.9736, -0.9600,  ..., -0.9273,  0.0185,  0.6700],\n",
            "        [ 0.8406,  1.0000,  0.6733,  ...,  0.8248, -0.5394, -0.7684],\n",
            "        [-0.6544, -0.7751, -0.9507,  ..., -0.9449,  0.2945,  0.3538]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6837,  0.9999,  0.9432,  ...,  0.8966, -0.7487, -0.5397],\n",
            "        [ 0.7988,  1.0000,  0.8959,  ...,  0.1387,  0.0953, -0.8336],\n",
            "        [-0.6179, -0.6095, -0.9225,  ..., -0.8610,  0.3328,  0.4301],\n",
            "        ...,\n",
            "        [ 0.7519,  0.9647,  0.8136,  ...,  0.8902, -0.8481,  0.0066],\n",
            "        [-0.6132,  0.7790, -0.9509,  ..., -0.8415,  0.3390,  0.4752],\n",
            "        [ 0.5904,  0.9902,  0.8365,  ...,  0.8604, -0.7856, -0.2896]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5480, -0.6853, -0.9060,  ..., -0.8415,  0.3272,  0.6194],\n",
            "        [ 0.7703,  0.9388,  0.8773,  ...,  0.8018, -0.8108, -0.3724],\n",
            "        [ 0.7567,  0.9999,  0.8916,  ...,  0.7859, -0.6393, -0.5846],\n",
            "        ...,\n",
            "        [ 0.5235,  0.9968,  0.7474,  ...,  0.8152, -0.8084, -0.1698],\n",
            "        [-0.7822, -0.7777, -0.8228,  ..., -0.9318, -0.0408,  0.2284],\n",
            "        [-0.6030,  0.4279, -0.9247,  ..., -0.8424,  0.4097,  0.6313]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6607,  0.9835,  0.8258,  ...,  0.8743, -0.8323, -0.0095],\n",
            "        [ 0.6448,  0.9994,  0.8290,  ...,  0.9158, -0.8416, -0.5922],\n",
            "        [-0.5735, -0.9778, -0.9367,  ..., -0.9255,  0.0494,  0.6484],\n",
            "        ...,\n",
            "        [-0.6679,  0.8325, -0.9182,  ..., -0.9026,  0.5666,  0.2904],\n",
            "        [ 0.5091,  0.9996,  0.7902,  ...,  0.8096, -0.8977, -0.5261],\n",
            "        [-0.1830, -0.9586, -0.8654,  ..., -0.8501,  0.1624,  0.5047]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6362, -0.8710, -0.9591,  ..., -0.9051,  0.2210,  0.5694],\n",
            "        [ 0.6180,  0.9932,  0.9172,  ...,  0.8992, -0.8734, -0.4270],\n",
            "        [-0.1613,  0.9611, -0.9408,  ..., -0.8455,  0.6440,  0.2984],\n",
            "        ...,\n",
            "        [ 0.7162,  0.9989,  0.8913,  ...,  0.8903, -0.8133, -0.5436],\n",
            "        [ 0.7267,  0.9994,  0.8485,  ...,  0.8548, -0.8230, -0.5841],\n",
            "        [ 0.6979,  0.9992,  0.9155,  ...,  0.9276, -0.6412, -0.6053]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6214, -0.4867, -0.9126,  ..., -0.7971,  0.2095,  0.7335],\n",
            "        [ 0.5808,  0.9946,  0.7944,  ...,  0.9000, -0.8525, -0.3696],\n",
            "        [ 0.6536,  0.9961,  0.7503,  ...,  0.7434, -0.8384, -0.1699],\n",
            "        ...,\n",
            "        [ 0.4347,  0.9907,  0.8626,  ...,  0.8590, -0.8250, -0.5298],\n",
            "        [-0.6341, -0.9646, -0.9055,  ..., -0.7992, -0.0189,  0.6472],\n",
            "        [-0.5683,  0.0808, -0.8578,  ..., -0.8954,  0.4688,  0.1731]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6716, -0.9655, -0.8903,  ..., -0.8604,  0.2525,  0.5270],\n",
            "        [ 0.8115,  1.0000,  0.4415,  ...,  0.5898, -0.7563, -0.8244],\n",
            "        [ 0.4827,  0.9897,  0.8966,  ...,  0.8353, -0.7732, -0.5413],\n",
            "        ...,\n",
            "        [ 0.3627,  0.9982,  0.7070,  ...,  0.8500, -0.8708, -0.1854],\n",
            "        [ 0.7456,  0.9848,  0.8570,  ...,  0.8529, -0.8636, -0.3726],\n",
            "        [ 0.7053,  0.9950,  0.9290,  ...,  0.8944, -0.6231, -0.5672]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.8210,  0.7893, -0.7365,  ..., -0.7302,  0.1280,  0.8157],\n",
            "        [ 0.4531,  0.9791,  0.5114,  ...,  0.7079, -0.7227,  0.2355],\n",
            "        [-0.7394, -0.7900, -0.9244,  ..., -0.8797,  0.2917,  0.5765],\n",
            "        ...,\n",
            "        [-0.6259,  0.8955, -0.9262,  ..., -0.9274,  0.1521,  0.3643],\n",
            "        [-0.5056, -0.9418, -0.9567,  ..., -0.9161,  0.1397,  0.6162],\n",
            "        [-0.5109,  0.8449, -0.9174,  ..., -0.8393,  0.0881,  0.4602]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7754,  0.9799,  0.7247,  ...,  0.9245, -0.7555, -0.5140],\n",
            "        [-0.4518, -0.9989, -0.9555,  ..., -0.8982,  0.4237,  0.7421],\n",
            "        [-0.7765, -0.8063, -0.9591,  ..., -0.9009,  0.1345,  0.7365],\n",
            "        ...,\n",
            "        [-0.8013, -0.8061, -0.9625,  ..., -0.9108,  0.3396,  0.7438],\n",
            "        [ 0.3449,  0.9911,  0.8127,  ...,  0.8675, -0.8794,  0.2243],\n",
            "        [ 0.6800,  0.9996,  0.9081,  ...,  0.8938, -0.7551, -0.2634]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7600,  0.9790,  0.8462,  ...,  0.8958, -0.8126, -0.2999],\n",
            "        [ 0.6388,  0.9897,  0.6841,  ...,  0.8716, -0.8747, -0.2549],\n",
            "        [-0.4728,  0.6288, -0.9343,  ..., -0.6388,  0.4857,  0.5684],\n",
            "        ...,\n",
            "        [ 0.6459,  0.9542,  0.8469,  ...,  0.8823, -0.7704, -0.2071],\n",
            "        [-0.4564, -0.7713, -0.9032,  ..., -0.9038,  0.2247,  0.6409],\n",
            "        [-0.2786, -0.8236, -0.9496,  ..., -0.8379,  0.4204,  0.5209]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4730, -0.9016, -0.9365,  ..., -0.9232,  0.2907,  0.6251],\n",
            "        [ 0.7537,  0.9970,  0.8628,  ...,  0.9081, -0.8155, -0.2507],\n",
            "        [ 0.4604,  0.9855,  0.6830,  ...,  0.7981, -0.9009,  0.0567],\n",
            "        ...,\n",
            "        [ 0.4823,  0.9994,  0.8295,  ...,  0.9124, -0.9011, -0.4339],\n",
            "        [ 0.7209,  0.9992,  0.8505,  ...,  0.9101, -0.7819, -0.5455],\n",
            "        [-0.6482, -0.9348, -0.9531,  ..., -0.9299,  0.1344,  0.5160]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4575,  0.9955,  0.8501,  ...,  0.7485, -0.7727, -0.3313],\n",
            "        [ 0.7462,  0.9994,  0.8895,  ...,  0.8683, -0.4030, -0.7317],\n",
            "        [-0.6567, -0.2588, -0.9301,  ..., -0.8368,  0.2840,  0.7340],\n",
            "        ...,\n",
            "        [-0.5929, -0.8457, -0.9433,  ..., -0.8821,  0.3441,  0.6833],\n",
            "        [-0.7889, -0.9442, -0.9152,  ..., -0.8735,  0.1968,  0.7166],\n",
            "        [-0.5510, -0.9972, -0.9466,  ..., -0.9138,  0.3984,  0.5857]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.8165,  0.9991,  0.9443,  ...,  0.8037, -0.6244, -0.5777],\n",
            "        [-0.4617,  0.2716, -0.9259,  ..., -0.9428,  0.3013,  0.1369],\n",
            "        [ 0.1614,  0.8664,  0.7857,  ...,  0.8627, -0.8211,  0.0373],\n",
            "        ...,\n",
            "        [ 0.6581,  0.9745,  0.7586,  ...,  0.7452, -0.8276, -0.4447],\n",
            "        [-0.6898, -0.9804, -0.9236,  ..., -0.8970,  0.3969,  0.7460],\n",
            "        [ 0.5085,  0.9901,  0.6495,  ...,  0.8756, -0.7648, -0.2679]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 4.1612e-01,  9.9069e-01,  8.2587e-01,  ...,  8.7055e-01,\n",
            "         -8.6552e-01, -1.0144e-04],\n",
            "        [ 6.9561e-01,  9.9788e-01,  7.4154e-01,  ...,  9.1221e-01,\n",
            "         -7.7192e-01, -3.6059e-01],\n",
            "        [ 6.2651e-01,  9.9767e-01,  8.8371e-01,  ...,  8.6148e-01,\n",
            "         -7.8981e-01, -2.8959e-01],\n",
            "        ...,\n",
            "        [ 4.5235e-01,  9.9920e-01,  7.8865e-01,  ...,  7.3101e-01,\n",
            "         -7.6843e-01, -5.4078e-01],\n",
            "        [ 5.9588e-01,  9.9801e-01,  8.7666e-01,  ...,  8.8159e-01,\n",
            "         -7.9292e-01, -1.2420e-01],\n",
            "        [-5.3820e-01, -2.2919e-01, -9.5537e-01,  ..., -7.5603e-01,\n",
            "          3.2823e-01,  4.8032e-01]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5942,  0.9997, -0.5358,  ..., -0.6763,  0.1587, -0.5280],\n",
            "        [ 0.6179,  0.9998,  0.9264,  ...,  0.8482, -0.7233, -0.5549],\n",
            "        [-0.2991, -0.7599, -0.9196,  ..., -0.8823,  0.2512,  0.6867],\n",
            "        ...,\n",
            "        [-0.5967,  0.9170, -0.8618,  ..., -0.9047,  0.2521,  0.4657],\n",
            "        [ 0.5022,  0.9951,  0.8444,  ...,  0.8076, -0.8300, -0.3074],\n",
            "        [ 0.4042,  1.0000,  0.9400,  ...,  0.1707,  0.1988, -0.9869]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1995,  0.7800, -0.8214,  ..., -0.7731,  0.6628,  0.0512],\n",
            "        [-0.4823,  0.1382, -0.9353,  ..., -0.9012,  0.3170,  0.3873],\n",
            "        [ 0.6044,  0.9580,  0.8460,  ...,  0.9015, -0.8685, -0.0897],\n",
            "        ...,\n",
            "        [-0.5298, -0.9194, -0.9526,  ..., -0.9215,  0.2787,  0.4907],\n",
            "        [ 0.5349,  0.9998,  0.7955,  ...,  0.7592, -0.8291, -0.0182],\n",
            "        [-0.3371, -0.2229, -0.9200,  ..., -0.9096,  0.3033,  0.3307]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1131,  1.0000,  0.8942,  ...,  0.6798, -0.2047, -0.7404],\n",
            "        [-0.4253, -0.3857, -0.9084,  ..., -0.8996,  0.0869,  0.4050],\n",
            "        [ 0.5746,  0.9987,  0.8192,  ...,  0.8584, -0.7589, -0.3290],\n",
            "        ...,\n",
            "        [ 0.5768,  0.9991,  0.8728,  ...,  0.8792, -0.8462, -0.4494],\n",
            "        [ 0.7338,  0.9999,  0.9396,  ...,  0.7328, -0.6018, -0.8508],\n",
            "        [ 0.6379,  1.0000,  0.9534,  ...,  0.8321, -0.7798, -0.8389]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.8341,  0.9982,  0.7142,  ...,  0.8421, -0.6948, -0.6047],\n",
            "        [-0.7895, -0.9861, -0.9585,  ..., -0.9197,  0.2947,  0.6642],\n",
            "        [-0.6278, -0.6840, -0.9460,  ..., -0.9270,  0.1857,  0.5903],\n",
            "        ...,\n",
            "        [-0.1353,  0.9608, -0.8477,  ..., -0.9126,  0.5378,  0.4216],\n",
            "        [-0.3525, -0.9619, -0.9264,  ..., -0.8260,  0.3165,  0.6946],\n",
            "        [-0.6228, -0.7938, -0.9311,  ..., -0.9347,  0.4607,  0.1888]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0989,  0.9973, -0.7135,  ..., -0.8711,  0.4057, -0.6654],\n",
            "        [-0.7125, -0.9856, -0.9450,  ..., -0.8966,  0.1685,  0.7570],\n",
            "        [-0.2812,  0.9891, -0.8256,  ..., -0.9150,  0.1805,  0.0813],\n",
            "        ...,\n",
            "        [ 0.8019,  1.0000,  0.6374,  ...,  0.7744, -0.7817, -0.0671],\n",
            "        [ 0.6284,  0.9928,  0.8500,  ...,  0.8343, -0.8795, -0.3146],\n",
            "        [-0.4447, -0.9510, -0.9337,  ..., -0.8609, -0.1188,  0.7088]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5628,  0.9999,  0.8590,  ...,  0.9035, -0.7756, -0.4934],\n",
            "        [-0.6721, -0.9763, -0.9623,  ..., -0.9207,  0.3262,  0.7905],\n",
            "        [ 0.3001,  0.9776,  0.7994,  ...,  0.7609, -0.8908, -0.5222],\n",
            "        ...,\n",
            "        [ 0.5520,  0.9937,  0.9296,  ...,  0.8168, -0.7359, -0.4612],\n",
            "        [-0.4597, -0.9726, -0.8835,  ..., -0.8169,  0.3173,  0.3959],\n",
            "        [ 0.5377,  0.9421,  0.8270,  ...,  0.8880, -0.7587, -0.2836]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7350,  0.9999,  0.9244,  ...,  0.8644, -0.4673, -0.5996],\n",
            "        [-0.5789,  0.4639, -0.9124,  ..., -0.6995,  0.4003,  0.2518],\n",
            "        [ 0.6864,  0.8827,  0.7953,  ...,  0.7937, -0.8555, -0.2128],\n",
            "        ...,\n",
            "        [ 0.6276,  0.9991,  0.9058,  ...,  0.8549, -0.7030, -0.4909],\n",
            "        [-0.5786, -0.6890, -0.9355,  ..., -0.8362,  0.3092,  0.6439],\n",
            "        [-0.1758, -0.8987, -0.8801,  ..., -0.8121,  0.3766,  0.2264]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7089,  0.9698,  0.8634,  ...,  0.9097, -0.7066, -0.0366],\n",
            "        [ 0.6905,  0.9912,  0.8222,  ...,  0.9083, -0.8768, -0.3403],\n",
            "        [-0.5052, -0.8596, -0.9594,  ..., -0.9070,  0.3187,  0.4158],\n",
            "        ...,\n",
            "        [-0.5712, -0.6199, -0.9573,  ..., -0.8436,  0.1125,  0.6908],\n",
            "        [-0.6145, -0.9375, -0.9387,  ..., -0.8730,  0.1229,  0.4493],\n",
            "        [ 0.8005,  1.0000,  0.8685,  ...,  0.7973, -0.6371, -0.6173]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3990,  0.9967,  0.8906,  ...,  0.8814, -0.7559, -0.1065],\n",
            "        [-0.4082, -0.9878, -0.9267,  ..., -0.8704,  0.2334,  0.5921],\n",
            "        [-0.6500, -0.9970, -0.9242,  ..., -0.9207,  0.0914,  0.7419],\n",
            "        ...,\n",
            "        [ 0.6179,  0.9936,  0.7413,  ...,  0.8978, -0.8253, -0.5237],\n",
            "        [ 0.6428,  0.9999,  0.8664,  ...,  0.7236, -0.6553, -0.6341],\n",
            "        [ 0.6837,  0.9957,  0.8930,  ...,  0.8634, -0.8025, -0.4980]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5044,  0.9609,  0.7763,  ...,  0.8840, -0.8709, -0.2001],\n",
            "        [ 0.4124,  0.9995,  0.8377,  ...,  0.8627, -0.7960, -0.4915],\n",
            "        [-0.6504, -0.3249, -0.8764,  ..., -0.8059,  0.5688,  0.2362],\n",
            "        ...,\n",
            "        [-0.4200,  0.9064, -0.9244,  ..., -0.8395,  0.2432,  0.1902],\n",
            "        [ 0.7057,  0.9991,  0.8740,  ...,  0.8728, -0.7769, -0.2055],\n",
            "        [ 0.5797,  1.0000,  0.9391,  ...,  0.8914, -0.5692, -0.8029]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4976,  0.9636, -0.9045,  ..., -0.8710,  0.4585, -0.2857],\n",
            "        [ 0.8622,  1.0000,  0.8589,  ...,  0.7383, -0.4195, -0.8253],\n",
            "        [-0.6827, -0.9878, -0.9476,  ..., -0.9023,  0.2689,  0.6361],\n",
            "        ...,\n",
            "        [ 0.6863,  0.9989,  0.8719,  ...,  0.8819, -0.5679, -0.4176],\n",
            "        [ 0.7604,  0.9997,  0.7289,  ...,  0.8595, -0.7975, -0.5329],\n",
            "        [ 0.6215,  0.9884,  0.7145,  ...,  0.8650, -0.8350, -0.1668]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2538,  0.1593, -0.8255,  ..., -0.9232,  0.2890, -0.1047],\n",
            "        [ 0.5784,  0.9955,  0.7264,  ...,  0.9052, -0.8710, -0.0776],\n",
            "        [-0.5200, -0.9978, -0.9577,  ..., -0.8258,  0.1002,  0.5861],\n",
            "        ...,\n",
            "        [ 0.7691,  0.9997,  0.8944,  ...,  0.8530, -0.5684, -0.6497],\n",
            "        [ 0.5625,  0.9953,  0.6737,  ...,  0.7404, -0.8184, -0.3538],\n",
            "        [-0.7800,  0.5143, -0.9169,  ..., -0.8711, -0.1927,  0.3841]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5748,  0.9859,  0.8901,  ...,  0.8838, -0.8648, -0.0749],\n",
            "        [ 0.2058,  1.0000,  0.8874,  ...,  0.3594, -0.3563, -0.9276],\n",
            "        [-0.5684,  0.3988, -0.9272,  ..., -0.8746,  0.5366,  0.3679],\n",
            "        ...,\n",
            "        [-0.7788, -0.7154, -0.9378,  ..., -0.8782,  0.4813,  0.6233],\n",
            "        [ 0.5715,  0.9142,  0.7496,  ...,  0.8226, -0.8958,  0.2336],\n",
            "        [-0.5232,  0.8333, -0.9310,  ..., -0.8668,  0.6177,  0.1745]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7535,  0.9923,  0.8321,  ...,  0.9277, -0.8429, -0.5714],\n",
            "        [ 0.6601,  0.9926,  0.7731,  ...,  0.8638, -0.8614,  0.1013],\n",
            "        [ 0.5555,  0.9976,  0.7939,  ...,  0.8518, -0.8557, -0.5547],\n",
            "        ...,\n",
            "        [-0.4288, -0.0521, -0.9050,  ..., -0.8044,  0.6734,  0.1415],\n",
            "        [-0.2855,  0.5671, -0.8901,  ..., -0.9243,  0.2343,  0.3618],\n",
            "        [ 0.5112,  0.9902,  0.7108,  ...,  0.8308, -0.8344, -0.2610]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1230,  0.9740, -0.8789,  ..., -0.8215,  0.6708, -0.2732],\n",
            "        [-0.6655,  0.9765, -0.8729,  ..., -0.9185,  0.2498,  0.6637],\n",
            "        [-0.4389,  0.7421, -0.8532,  ..., -0.9153,  0.6586, -0.0038],\n",
            "        ...,\n",
            "        [-0.4093, -0.9769, -0.9356,  ..., -0.8873,  0.4140,  0.5384],\n",
            "        [ 0.4074,  0.9851,  0.8914,  ...,  0.8234, -0.9034, -0.1885],\n",
            "        [-0.6508, -0.9099, -0.9188,  ..., -0.7389,  0.1249,  0.7917]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5068,  0.9975,  0.8097,  ...,  0.8403, -0.8191, -0.1684],\n",
            "        [ 0.5673,  0.9509,  0.6574,  ...,  0.8812, -0.8906, -0.1683],\n",
            "        [-0.4550,  0.9009, -0.9598,  ..., -0.9103,  0.3037,  0.6350],\n",
            "        ...,\n",
            "        [ 0.6933,  1.0000,  0.8062,  ...,  0.7080, -0.7033, -0.8031],\n",
            "        [ 0.6961,  0.9983,  0.8595,  ...,  0.9285, -0.8353, -0.0827],\n",
            "        [ 0.6159,  0.9954,  0.8636,  ...,  0.8949, -0.7343, -0.1095]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7510,  0.9965,  0.8039,  ...,  0.8634, -0.8089, -0.2892],\n",
            "        [ 0.4008,  0.9991, -0.6192,  ..., -0.8790,  0.5130, -0.6616],\n",
            "        [ 0.6718,  0.9881,  0.7332,  ...,  0.8653, -0.7533, -0.2115],\n",
            "        ...,\n",
            "        [ 0.5202,  0.9999,  0.9006,  ...,  0.8243, -0.5788, -0.7077],\n",
            "        [ 0.7937,  1.0000,  0.6630,  ...,  0.4993, -0.4658, -0.7425],\n",
            "        [-0.4236,  0.9086, -0.7843,  ..., -0.8283,  0.5239,  0.3505]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5337, -0.9072, -0.9371,  ..., -0.8818,  0.1356,  0.7848],\n",
            "        [ 0.4284,  0.8976,  0.8477,  ...,  0.7825, -0.7587,  0.1500],\n",
            "        [ 0.7533,  0.9995,  0.8138,  ...,  0.8442, -0.8200, -0.6004],\n",
            "        ...,\n",
            "        [ 0.4643,  0.9034,  0.8834,  ...,  0.8660, -0.8482, -0.2063],\n",
            "        [ 0.5975,  1.0000,  0.9478,  ...,  0.1873,  0.1723, -0.8490],\n",
            "        [ 0.5010,  0.9901,  0.8628,  ...,  0.8809, -0.8908, -0.4113]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0485, -0.9274, -0.5707,  ..., -0.5571,  0.5236, -0.2968],\n",
            "        [ 0.1058,  0.9931, -0.8449,  ..., -0.8900,  0.6046,  0.1858],\n",
            "        [-0.5253, -0.9889, -0.9355,  ..., -0.9153,  0.3311,  0.6754],\n",
            "        ...,\n",
            "        [-0.0884,  0.9929, -0.4139,  ..., -0.6193,  0.7874, -0.2155],\n",
            "        [-0.5680,  0.9657, -0.9157,  ..., -0.8757,  0.4300,  0.7332],\n",
            "        [-0.1674,  0.0536, -0.9040,  ..., -0.8692,  0.2927,  0.7183]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6173,  0.9905,  0.8715,  ...,  0.8364, -0.7596, -0.3661],\n",
            "        [-0.3607, -0.1115, -0.9458,  ..., -0.9102,  0.4460,  0.3751],\n",
            "        [-0.5099, -0.0591, -0.9043,  ..., -0.8799,  0.7278,  0.2485],\n",
            "        ...,\n",
            "        [ 0.1751,  1.0000,  0.4411,  ..., -0.5421,  0.3936, -0.8575],\n",
            "        [-0.7340, -0.9526, -0.9364,  ..., -0.8360,  0.5125,  0.4257],\n",
            "        [ 0.8708,  0.9999,  0.9421,  ...,  0.8897, -0.5934, -0.8129]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6101, -0.9717, -0.9256,  ..., -0.8962,  0.3122,  0.3018],\n",
            "        [ 0.5610,  0.9973,  0.8320,  ...,  0.8167, -0.8359, -0.5129],\n",
            "        [ 0.6671,  0.9665,  0.7933,  ...,  0.7898, -0.7518,  0.1517],\n",
            "        ...,\n",
            "        [-0.4979,  0.2668, -0.9068,  ..., -0.8562,  0.0379,  0.4686],\n",
            "        [-0.4120, -0.9321, -0.9359,  ..., -0.8986,  0.1122,  0.4639],\n",
            "        [-0.5296, -0.2352, -0.9185,  ..., -0.8178,  0.0164,  0.5798]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6639,  0.9999,  0.9122,  ...,  0.8460, -0.5052, -0.5813],\n",
            "        [ 0.5480,  0.9750,  0.8764,  ...,  0.8322, -0.8142, -0.4909],\n",
            "        [ 0.6977,  0.9996,  0.8859,  ...,  0.9197, -0.7566, -0.2445],\n",
            "        ...,\n",
            "        [-0.7007,  0.9486, -0.8678,  ..., -0.7535,  0.2700,  0.7418],\n",
            "        [ 0.6002,  0.9965,  0.8537,  ...,  0.8951, -0.7561, -0.2847],\n",
            "        [ 0.4822,  0.9065,  0.7210,  ...,  0.9152, -0.8235, -0.2972]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1739,  0.7322, -0.9472,  ..., -0.8362,  0.6175,  0.2123],\n",
            "        [ 0.6112,  0.9834,  0.8058,  ...,  0.8885, -0.8158, -0.1659],\n",
            "        [-0.6703,  0.9606, -0.7713,  ..., -0.8203,  0.3537,  0.2038],\n",
            "        ...,\n",
            "        [ 0.5214,  0.9766,  0.8539,  ...,  0.6994, -0.8868, -0.2385],\n",
            "        [ 0.8063,  0.9922,  0.8426,  ...,  0.8499, -0.8561, -0.5631],\n",
            "        [-0.6065, -0.7965, -0.9141,  ..., -0.8462,  0.4083,  0.6775]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5803,  0.9955,  0.8964,  ...,  0.8897, -0.7886, -0.2063],\n",
            "        [ 0.7788,  0.9947,  0.8790,  ...,  0.8555, -0.8263, -0.3680],\n",
            "        [-0.6647, -0.3792, -0.9052,  ..., -0.8568,  0.4433,  0.6567],\n",
            "        ...,\n",
            "        [-0.5538,  0.4663, -0.8959,  ..., -0.8277,  0.2856,  0.5488],\n",
            "        [ 0.5237,  0.9998,  0.9132,  ...,  0.7849, -0.6931, -0.7881],\n",
            "        [-0.7905, -0.5568, -0.9390,  ..., -0.8861,  0.1794,  0.7194]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.7747, -0.7737, -0.9309,  ..., -0.9265,  0.0270,  0.5337],\n",
            "        [-0.5744, -0.9248, -0.9387,  ..., -0.9159,  0.2995,  0.6172],\n",
            "        [-0.6829,  0.6979, -0.9272,  ..., -0.9407,  0.2738,  0.7264],\n",
            "        ...,\n",
            "        [ 0.7135,  0.9876,  0.9179,  ...,  0.8763, -0.8410, -0.3078],\n",
            "        [ 0.5042,  0.9969,  0.8125,  ...,  0.8743, -0.8054, -0.3304],\n",
            "        [ 0.8657,  0.9999,  0.9556,  ...,  0.8302, -0.4291, -0.8223]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-6.1757e-01,  4.9727e-05, -9.6236e-01,  ..., -8.8404e-01,\n",
            "          2.1352e-01,  5.0119e-01],\n",
            "        [-6.2679e-01,  4.3269e-01, -9.3601e-01,  ..., -8.3214e-01,\n",
            "          2.5699e-01,  4.1265e-01],\n",
            "        [ 2.7540e-01,  1.0000e+00,  9.3150e-01,  ..., -1.8288e-01,\n",
            "          1.5877e-01, -9.5885e-01],\n",
            "        ...,\n",
            "        [ 5.8264e-01,  9.6923e-01,  8.5797e-01,  ...,  8.5607e-01,\n",
            "         -8.4724e-01,  6.9535e-02],\n",
            "        [-4.0807e-01, -4.9222e-01, -9.2524e-01,  ..., -8.5542e-01,\n",
            "          1.2453e-01,  4.8311e-01],\n",
            "        [ 5.6761e-01,  9.8835e-01,  7.4529e-01,  ...,  8.7091e-01,\n",
            "         -7.5142e-01, -3.4457e-02]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6774,  0.9827,  0.8303,  ...,  0.8859, -0.8785, -0.3475],\n",
            "        [ 0.6184,  0.9969,  0.8803,  ...,  0.9142, -0.8142,  0.0035],\n",
            "        [ 0.6549,  0.9927,  0.8299,  ...,  0.8915, -0.7875, -0.2563],\n",
            "        ...,\n",
            "        [-0.6672, -0.4212, -0.9217,  ..., -0.8741,  0.1122,  0.5288],\n",
            "        [ 0.5069,  0.9985,  0.8480,  ...,  0.7495, -0.7401, -0.2360],\n",
            "        [-0.4212, -0.6519, -0.9440,  ..., -0.9098,  0.0161,  0.5805]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7148,  1.0000,  0.9490,  ...,  0.8258, -0.4054, -0.7490],\n",
            "        [ 0.6464,  0.9939,  0.7944,  ...,  0.8758, -0.8449, -0.3950],\n",
            "        [ 0.6794,  0.9992,  0.8907,  ...,  0.7985, -0.8075, -0.3787],\n",
            "        ...,\n",
            "        [ 0.5308,  0.8951,  0.8183,  ...,  0.8843, -0.8740, -0.1239],\n",
            "        [-0.5483, -0.9064, -0.9298,  ..., -0.8714,  0.0651,  0.4433],\n",
            "        [ 0.6850,  0.9997,  0.9327,  ...,  0.8116, -0.7603, -0.4459]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3977,  0.6679, -0.9282,  ..., -0.8794,  0.3802,  0.2559],\n",
            "        [-0.5705,  0.2287, -0.9089,  ..., -0.8086,  0.2566,  0.5253],\n",
            "        [-0.7042, -0.9721, -0.9069,  ..., -0.8531,  0.3041,  0.8079],\n",
            "        ...,\n",
            "        [ 0.6905,  0.9983,  0.9285,  ...,  0.8909, -0.7737, -0.5244],\n",
            "        [ 0.4487,  0.9128,  0.6943,  ...,  0.7968, -0.8801,  0.1509],\n",
            "        [ 0.7126,  0.9932,  0.8960,  ...,  0.8557, -0.8532, -0.2825]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5698, -0.9916, -0.9454,  ..., -0.7838,  0.0663,  0.7050],\n",
            "        [ 0.7235,  1.0000,  0.8790,  ...,  0.8209, -0.7694, -0.5626],\n",
            "        [-0.7958, -0.7009, -0.9571,  ..., -0.8932, -0.0760,  0.5590],\n",
            "        ...,\n",
            "        [-0.0884,  0.9997, -0.6544,  ..., -0.9132,  0.6482, -0.6280],\n",
            "        [-0.4053, -0.4786, -0.8651,  ..., -0.8554,  0.4385,  0.5466],\n",
            "        [ 0.6746,  0.9969,  0.7477,  ...,  0.9092, -0.7793, -0.0530]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6969,  0.9997,  0.8924,  ...,  0.7852, -0.4803, -0.7044],\n",
            "        [ 0.7772,  0.9916,  0.8777,  ...,  0.9021, -0.8442, -0.1281],\n",
            "        [ 0.6586,  0.9991,  0.9122,  ...,  0.8418, -0.6994, -0.3988],\n",
            "        ...,\n",
            "        [-0.6605, -0.8699, -0.9343,  ..., -0.9055,  0.5243,  0.6834],\n",
            "        [ 0.6374,  0.9782,  0.8418,  ...,  0.9145, -0.7932, -0.2943],\n",
            "        [ 0.7182,  0.9497,  0.8647,  ...,  0.8853, -0.7709, -0.0444]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4572, -0.5764, -0.9500,  ..., -0.8497,  0.0674,  0.4433],\n",
            "        [-0.4704, -0.8419, -0.9382,  ..., -0.9117,  0.3084,  0.5691],\n",
            "        [ 0.2116,  0.9914, -0.6577,  ..., -0.9067,  0.7518, -0.8288],\n",
            "        ...,\n",
            "        [-0.6164,  0.9562, -0.8249,  ..., -0.8343,  0.3406,  0.3556],\n",
            "        [ 0.5853,  0.9935,  0.8453,  ...,  0.9219, -0.8200, -0.1725],\n",
            "        [-0.5559, -0.9946, -0.9306,  ..., -0.8768,  0.4394,  0.6534]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5269,  0.9999, -0.4801,  ..., -0.8777,  0.6472, -0.6312],\n",
            "        [ 0.2688,  0.9884,  0.8738,  ...,  0.8689, -0.8813, -0.0668],\n",
            "        [-0.6152, -0.9819, -0.9455,  ..., -0.7704,  0.4150,  0.5464],\n",
            "        ...,\n",
            "        [ 0.8046,  0.9966,  0.9160,  ...,  0.8259, -0.7596, -0.4085],\n",
            "        [-0.6054, -0.5900, -0.9098,  ..., -0.6903,  0.4429,  0.5808],\n",
            "        [ 0.7631,  0.9942,  0.8949,  ...,  0.8653, -0.6834, -0.5495]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6232,  0.9994,  0.7034,  ...,  0.0869,  0.2126, -0.8586],\n",
            "        [-0.2610,  0.9998,  0.4660,  ..., -0.5673,  0.6258, -0.6233],\n",
            "        [-0.4963, -0.8978, -0.9577,  ..., -0.8856,  0.2893,  0.4329],\n",
            "        ...,\n",
            "        [ 0.6286,  0.9969,  0.8059,  ...,  0.9155, -0.7356, -0.6014],\n",
            "        [-0.4791,  0.4220, -0.9197,  ..., -0.8958,  0.1064,  0.4586],\n",
            "        [ 0.6415,  0.9988,  0.8459,  ...,  0.9355, -0.7974, -0.3635]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7790,  0.9998,  0.7798,  ...,  0.7671, -0.7375, -0.2060],\n",
            "        [ 0.5891,  0.9973,  0.8427,  ...,  0.8525, -0.8433, -0.1484],\n",
            "        [-0.7411, -0.9578, -0.9536,  ..., -0.9477,  0.1683,  0.7727],\n",
            "        ...,\n",
            "        [ 0.3057,  1.0000,  0.3428,  ..., -0.0124,  0.6622, -0.7170],\n",
            "        [ 0.6381,  0.9969,  0.8885,  ...,  0.8944, -0.7514, -0.3190],\n",
            "        [-0.5303,  0.2420, -0.8837,  ..., -0.8256,  0.6263,  0.3378]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.7149,  0.4158, -0.9226,  ..., -0.8956,  0.1121,  0.7450],\n",
            "        [ 0.5651,  0.9985,  0.8596,  ...,  0.7840, -0.8612, -0.3185],\n",
            "        [ 0.1724,  1.0000,  0.7028,  ...,  0.2222,  0.5076, -0.7534],\n",
            "        ...,\n",
            "        [ 0.4664,  0.9652,  0.8295,  ...,  0.8220, -0.7635, -0.2797],\n",
            "        [ 0.6699,  0.9997,  0.7879,  ...,  0.8347, -0.8505, -0.5093],\n",
            "        [-0.7684,  0.4022, -0.9126,  ..., -0.9338,  0.1504,  0.7058]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6321, -0.9999, -0.9616,  ..., -0.8221,  0.2933,  0.7684],\n",
            "        [-0.4852, -0.7496, -0.9808,  ..., -0.9212,  0.4291,  0.5644],\n",
            "        [-0.6283, -0.7932, -0.9184,  ..., -0.8508,  0.2378,  0.6484],\n",
            "        ...,\n",
            "        [-0.6234,  0.9134, -0.8682,  ..., -0.8393,  0.0951, -0.0467],\n",
            "        [-0.4395,  0.2668, -0.8927,  ..., -0.9323, -0.0605,  0.5891],\n",
            "        [-0.5411,  0.7586, -0.9293,  ..., -0.9251,  0.5104,  0.5372]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5959, -0.9992, -0.9096,  ..., -0.8786,  0.1467,  0.5535],\n",
            "        [-0.4230,  0.2298, -0.9009,  ..., -0.9022,  0.2532, -0.1841],\n",
            "        [-0.6599, -0.8316, -0.9401,  ..., -0.8602,  0.2291,  0.5381],\n",
            "        ...,\n",
            "        [ 0.6300,  1.0000,  0.9347,  ...,  0.3729,  0.4472, -0.9595],\n",
            "        [-0.6096, -0.9370, -0.9261,  ..., -0.9030,  0.0224,  0.5832],\n",
            "        [ 0.5438,  1.0000,  0.9070,  ...,  0.1461,  0.3817, -0.9550]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4916, -0.3585, -0.9615,  ..., -0.8779,  0.3159,  0.5692],\n",
            "        [ 0.5879,  0.9891,  0.6746,  ...,  0.8835, -0.9087, -0.2250],\n",
            "        [-0.4242, -0.9077, -0.9405,  ..., -0.6268,  0.3640,  0.5037],\n",
            "        ...,\n",
            "        [-0.1211, -0.3516, -0.9136,  ..., -0.8868,  0.5967,  0.1984],\n",
            "        [ 0.6966,  0.9989,  0.8841,  ...,  0.8400, -0.7916, -0.4622],\n",
            "        [-0.7304,  0.2498, -0.8762,  ..., -0.8274,  0.5703,  0.5684]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5484, -0.0469, -0.8901,  ..., -0.8657,  0.4404,  0.4897],\n",
            "        [ 0.4685,  0.9457,  0.8212,  ...,  0.8306, -0.8841, -0.1733],\n",
            "        [ 0.6251,  0.9965,  0.8519,  ...,  0.8611, -0.7874, -0.3791],\n",
            "        ...,\n",
            "        [-0.5911,  0.8141, -0.9535,  ..., -0.9378,  0.6015,  0.6861],\n",
            "        [-0.5957, -0.9437, -0.9277,  ..., -0.8901,  0.1052,  0.7046],\n",
            "        [ 0.5722,  0.9976,  0.8088,  ...,  0.9407, -0.8585, -0.5550]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1917,  0.8380, -0.9041,  ..., -0.8973,  0.3827,  0.2727],\n",
            "        [-0.5202, -0.9977, -0.9098,  ..., -0.8851,  0.1088,  0.5660],\n",
            "        [ 0.7963,  1.0000,  0.2734,  ..., -0.7662,  0.6322, -0.9676],\n",
            "        ...,\n",
            "        [-0.6307,  0.9978, -0.6907,  ..., -0.6761,  0.3317,  0.1386],\n",
            "        [ 0.4158,  0.9945,  0.6837,  ...,  0.7345, -0.8297, -0.1016],\n",
            "        [ 0.7067,  0.9907,  0.8532,  ...,  0.9085, -0.7130, -0.1724]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5540,  0.8267,  0.8340,  ...,  0.8336, -0.7195,  0.1244],\n",
            "        [ 0.7683,  1.0000,  0.8935,  ...,  0.0916,  0.5998, -0.8852],\n",
            "        [-0.2800,  0.9490, -0.9341,  ..., -0.8519,  0.4289,  0.6780],\n",
            "        ...,\n",
            "        [-0.4531, -0.9794, -0.9377,  ..., -0.9038,  0.0858,  0.7744],\n",
            "        [-0.4364, -0.8589, -0.9456,  ..., -0.8632,  0.5092, -0.0394],\n",
            "        [ 0.6633,  0.9918,  0.8504,  ...,  0.9071, -0.8835, -0.5389]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5942,  0.9896,  0.8003,  ...,  0.8230, -0.7476, -0.0667],\n",
            "        [ 0.6800,  0.9981,  0.8833,  ...,  0.7314, -0.6899, -0.3968],\n",
            "        [ 0.8473,  0.9999,  0.9508,  ...,  0.9160, -0.4596, -0.7652],\n",
            "        ...,\n",
            "        [ 0.7370,  1.0000,  0.9264,  ...,  0.8107,  0.0152, -0.9619],\n",
            "        [ 0.6759,  0.9983,  0.8678,  ...,  0.9030, -0.7902, -0.2529],\n",
            "        [-0.3671,  0.9826, -0.6657,  ..., -0.7919,  0.0881,  0.5346]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3558, -0.4747, -0.9084,  ..., -0.7810,  0.3924,  0.7139],\n",
            "        [ 0.7304,  1.0000,  0.9449,  ...,  0.6848, -0.1536, -0.8676],\n",
            "        [ 0.7001,  0.9996,  0.7997,  ...,  0.5299, -0.6212, -0.7675],\n",
            "        ...,\n",
            "        [ 0.5439,  0.9719,  0.8407,  ...,  0.8764, -0.8560, -0.2965],\n",
            "        [ 0.6190,  0.9946,  0.8662,  ...,  0.8923, -0.8682, -0.3941],\n",
            "        [-0.5914, -0.5228, -0.9463,  ..., -0.8567,  0.5777,  0.6279]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1867,  1.0000,  0.7355,  ...,  0.2588,  0.0920, -0.7448],\n",
            "        [ 0.6220,  0.9997,  0.7609,  ...,  0.6648, -0.6285, -0.3948],\n",
            "        [-0.6058, -0.8232, -0.9446,  ..., -0.8413,  0.3599,  0.5684],\n",
            "        ...,\n",
            "        [-0.2884,  0.9624, -0.9404,  ..., -0.8525,  0.3077,  0.5110],\n",
            "        [ 0.5125,  0.9620,  0.9164,  ...,  0.9026, -0.7882, -0.1833],\n",
            "        [ 0.7411,  0.9994,  0.9215,  ...,  0.6748, -0.8014, -0.5534]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1932,  0.9991, -0.6957,  ..., -0.9263,  0.6846, -0.4280],\n",
            "        [-0.0446,  0.9929, -0.9344,  ..., -0.8831,  0.4862,  0.1808],\n",
            "        [ 0.4751,  0.9999,  0.8789,  ...,  0.7324, -0.5578, -0.6382],\n",
            "        ...,\n",
            "        [ 0.5809,  0.9998,  0.8535,  ...,  0.8414, -0.7847, -0.3776],\n",
            "        [-0.6108, -0.9809, -0.9418,  ..., -0.9374,  0.1307,  0.6397],\n",
            "        [-0.2380, -0.9844, -0.9283,  ..., -0.8805,  0.3019,  0.2271]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1454, -0.9931, -0.9355,  ..., -0.8931,  0.3018,  0.4506],\n",
            "        [ 0.6721,  0.9981,  0.9174,  ...,  0.8806, -0.8000, -0.2462],\n",
            "        [-0.5684, -0.5474, -0.9344,  ..., -0.9100,  0.3433,  0.4185],\n",
            "        ...,\n",
            "        [ 0.6751,  0.9935,  0.8860,  ...,  0.8228, -0.8238, -0.2137],\n",
            "        [-0.5794, -0.9409, -0.8850,  ..., -0.8648,  0.2814,  0.4209],\n",
            "        [ 0.7308,  0.9920,  0.8288,  ...,  0.8948, -0.8103, -0.5437]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5470,  0.9919,  0.8491,  ...,  0.8996, -0.8342, -0.2764],\n",
            "        [ 0.6747,  0.9912,  0.8802,  ...,  0.8807, -0.8138, -0.1960],\n",
            "        [-0.6412, -0.9628, -0.9457,  ..., -0.8998,  0.3163,  0.7631],\n",
            "        ...,\n",
            "        [-0.7546, -0.8826, -0.9014,  ..., -0.9149,  0.2013,  0.4584],\n",
            "        [-0.5459,  0.9291, -0.8929,  ..., -0.7564,  0.1626,  0.5929],\n",
            "        [-0.2714, -0.8848, -0.9179,  ..., -0.8699,  0.3973,  0.3341]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5054, -0.9104, -0.9286,  ..., -0.8480,  0.4439,  0.5899],\n",
            "        [ 0.7298,  0.9664,  0.6868,  ...,  0.9130, -0.6977, -0.4884],\n",
            "        [ 0.3970,  0.9879,  0.7696,  ...,  0.8884, -0.7613, -0.0340],\n",
            "        ...,\n",
            "        [ 0.4249,  0.9997,  0.8963,  ...,  0.8413, -0.7689, -0.4460],\n",
            "        [ 0.3974,  0.9837,  0.8652,  ...,  0.8754, -0.7558, -0.1503],\n",
            "        [-0.4678, -0.9779, -0.9635,  ..., -0.8536,  0.0413,  0.6801]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5909,  0.9988,  0.8914,  ...,  0.9174, -0.8331, -0.2902],\n",
            "        [ 0.7693,  0.9999,  0.7368,  ...,  0.7491, -0.6733, -0.6431],\n",
            "        [ 0.5938,  1.0000,  0.9264,  ...,  0.8305, -0.4298, -0.8714],\n",
            "        ...,\n",
            "        [ 0.5516,  0.9996,  0.8887,  ...,  0.8527, -0.7815, -0.5118],\n",
            "        [-0.3060,  0.3097, -0.9556,  ..., -0.7311,  0.6786, -0.1475],\n",
            "        [ 0.6813,  0.9990,  0.8792,  ...,  0.8487, -0.7817, -0.4434]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4968, -0.9795, -0.9195,  ..., -0.8246,  0.4541,  0.6770],\n",
            "        [ 0.7332,  0.9978,  0.9004,  ...,  0.8445, -0.8168, -0.5157],\n",
            "        [ 0.0942,  1.0000,  0.3356,  ..., -0.1151,  0.7144, -0.8376],\n",
            "        ...,\n",
            "        [-0.4871,  0.6977, -0.9071,  ..., -0.8913,  0.0477,  0.5206],\n",
            "        [-0.6258, -0.9894, -0.9184,  ..., -0.8595,  0.1898,  0.6701],\n",
            "        [-0.6410, -0.8475, -0.9404,  ..., -0.8619, -0.1967,  0.6125]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5817,  0.8977, -0.8888,  ..., -0.9265,  0.3215,  0.4767],\n",
            "        [-0.5044, -0.9926, -0.9373,  ..., -0.9018,  0.2429,  0.6098],\n",
            "        [ 0.4990,  0.9398,  0.7406,  ...,  0.8386, -0.8473, -0.4015],\n",
            "        ...,\n",
            "        [-0.6756, -0.5356, -0.8949,  ..., -0.7627,  0.2131,  0.6079],\n",
            "        [-0.5598,  0.8915, -0.9061,  ..., -0.9147,  0.2866,  0.6334],\n",
            "        [ 0.7514,  0.9998,  0.8790,  ...,  0.8441, -0.6861, -0.6996]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6926,  0.9482, -0.8985,  ..., -0.8268,  0.1416,  0.7086],\n",
            "        [-0.4758, -0.9931, -0.9283,  ..., -0.9386,  0.2195,  0.2132],\n",
            "        [ 0.5483,  0.9939,  0.8491,  ...,  0.7601, -0.7892, -0.2197],\n",
            "        ...,\n",
            "        [-0.6611, -0.8931, -0.9278,  ..., -0.8689,  0.1624,  0.6622],\n",
            "        [ 0.6559,  0.9975,  0.8364,  ...,  0.8600, -0.7621, -0.3554],\n",
            "        [-0.5979, -0.0824, -0.8812,  ..., -0.8851,  0.2919,  0.5558]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5286, -0.3223, -0.8373,  ..., -0.8017,  0.4568,  0.6825],\n",
            "        [-0.4523,  0.9575, -0.8118,  ..., -0.8323,  0.8031,  0.2277],\n",
            "        [-0.4646,  0.4070, -0.8827,  ..., -0.8252,  0.5278,  0.3451],\n",
            "        ...,\n",
            "        [ 0.6000,  0.9977,  0.6968,  ...,  0.8657, -0.8805, -0.2784],\n",
            "        [-0.4450, -0.5181, -0.9317,  ..., -0.8054,  0.5547,  0.4940],\n",
            "        [-0.4061, -0.0040, -0.8507,  ..., -0.7771,  0.4065,  0.4681]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5932, -0.9999, -0.8386,  ..., -0.9010, -0.1504,  0.3108],\n",
            "        [ 0.7573,  0.9871,  0.8039,  ...,  0.9059, -0.7636, -0.2543],\n",
            "        [ 0.5709,  0.9998,  0.8956,  ...,  0.8127, -0.6174, -0.5814],\n",
            "        ...,\n",
            "        [-0.6777,  0.3871, -0.9498,  ..., -0.9253,  0.2986,  0.6265],\n",
            "        [ 0.6861,  0.9578,  0.8326,  ...,  0.8464, -0.7228, -0.0943],\n",
            "        [-0.5054, -0.7504, -0.9530,  ..., -0.9147,  0.1623,  0.4326]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3317,  0.9958, -0.8069,  ..., -0.8184,  0.7717, -0.1766],\n",
            "        [ 0.6928,  0.9987,  0.8369,  ...,  0.8693, -0.8400, -0.1608],\n",
            "        [ 0.7186,  0.9997,  0.8826,  ...,  0.8125, -0.5395, -0.7724],\n",
            "        ...,\n",
            "        [ 0.5321,  0.9997,  0.7073,  ...,  0.7448, -0.7187, -0.4336],\n",
            "        [-0.6405,  0.5828, -0.9317,  ..., -0.8580,  0.2791,  0.7111],\n",
            "        [-0.6294,  0.9657, -0.9262,  ..., -0.8712, -0.0020,  0.6299]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6235,  0.9998,  0.6986,  ...,  0.7773, -0.7811, -0.2566],\n",
            "        [ 0.5613,  0.9996,  0.9738,  ...,  0.8385, -0.6489, -0.4289],\n",
            "        [ 0.7430,  1.0000,  0.9411,  ...,  0.8262, -0.1484, -0.9206],\n",
            "        ...,\n",
            "        [ 0.2979,  0.9862,  0.8647,  ...,  0.8205, -0.7722, -0.2827],\n",
            "        [ 0.5652,  0.9944,  0.7959,  ...,  0.8913, -0.8059, -0.0921],\n",
            "        [ 0.7031,  0.9996,  0.7046,  ...,  0.7993, -0.7020, -0.3849]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5136, -0.8787, -0.9478,  ..., -0.8647,  0.2744,  0.4384],\n",
            "        [ 0.5269,  0.9944,  0.8305,  ...,  0.7820, -0.8294,  0.0282],\n",
            "        [ 0.8034,  0.9987,  0.9387,  ...,  0.8444, -0.6826, -0.7847],\n",
            "        ...,\n",
            "        [ 0.6581,  0.9944,  0.8283,  ...,  0.7630, -0.8045,  0.0022],\n",
            "        [ 0.8031,  0.9999,  0.9294,  ...,  0.8055, -0.4767, -0.8531],\n",
            "        [ 0.5283,  0.9990,  0.8898,  ...,  0.9159, -0.6909, -0.5032]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6474,  1.0000,  0.9291,  ...,  0.3941,  0.5050, -0.9702],\n",
            "        [ 0.6312,  0.9957,  0.9256,  ...,  0.8724, -0.7934, -0.3146],\n",
            "        [-0.3256,  0.3764, -0.9100,  ..., -0.9047,  0.3545,  0.6175],\n",
            "        ...,\n",
            "        [-0.5526, -0.9749, -0.9375,  ..., -0.8817,  0.5928,  0.5809],\n",
            "        [-0.5696, -0.9716, -0.9478,  ..., -0.9060,  0.1141,  0.4488],\n",
            "        [-0.7235, -0.9651, -0.9472,  ..., -0.8954,  0.1102,  0.5933]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6510, -0.9994, -0.9502,  ..., -0.8659,  0.2210,  0.7042],\n",
            "        [ 0.6483,  1.0000,  0.9134,  ...,  0.7787, -0.4790, -0.8966],\n",
            "        [ 0.4954,  0.9396,  0.7477,  ...,  0.8667, -0.7706, -0.0139],\n",
            "        ...,\n",
            "        [-0.5169, -0.9979, -0.9669,  ..., -0.8399,  0.3593,  0.6640],\n",
            "        [-0.7608,  0.5645, -0.8554,  ..., -0.8628,  0.0119,  0.2018],\n",
            "        [-0.6668, -0.4157, -0.9560,  ..., -0.8378,  0.3867,  0.5979]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6689,  0.9988,  0.8214,  ...,  0.9062, -0.7212, -0.5398],\n",
            "        [ 0.6266,  1.0000, -0.5824,  ..., -0.7175,  0.6125, -0.8611],\n",
            "        [-0.4183, -0.2560, -0.9566,  ..., -0.8944,  0.1953,  0.4924],\n",
            "        ...,\n",
            "        [ 0.5035,  0.9558,  0.8836,  ...,  0.8465, -0.8986, -0.0317],\n",
            "        [-0.5855,  0.9959, -0.7918,  ..., -0.6458,  0.0249, -0.0312],\n",
            "        [-0.6393,  0.9855, -0.7985,  ..., -0.8453,  0.3376,  0.2871]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6339, -0.9938, -0.9021,  ..., -0.7791,  0.2929,  0.6287],\n",
            "        [ 0.3513,  0.9987,  0.8904,  ...,  0.8442, -0.6943, -0.4436],\n",
            "        [ 0.5970,  1.0000,  0.9580,  ...,  0.8882, -0.4486, -0.7085],\n",
            "        ...,\n",
            "        [ 0.7674,  1.0000,  0.9341,  ...,  0.6957, -0.5834, -0.8357],\n",
            "        [-0.6850,  0.5129, -0.9360,  ..., -0.9058,  0.5145,  0.3805],\n",
            "        [-0.5691, -0.4679, -0.9091,  ..., -0.9377,  0.0461,  0.5687]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6073, -0.9972, -0.9083,  ..., -0.8857,  0.3316,  0.6505],\n",
            "        [ 0.4037,  0.9529,  0.8815,  ...,  0.8276, -0.8703,  0.0593],\n",
            "        [ 0.4596,  0.9844,  0.8020,  ...,  0.8957, -0.8554,  0.0168],\n",
            "        ...,\n",
            "        [ 0.4823,  0.9641,  0.7241,  ...,  0.8791, -0.8920, -0.4647],\n",
            "        [ 0.4831,  0.9796,  0.7995,  ...,  0.8917, -0.8151,  0.0242],\n",
            "        [ 0.4412,  1.0000,  0.8458,  ...,  0.2859, -0.5523, -0.6556]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1595,  0.9993, -0.7075,  ..., -0.6238,  0.7692, -0.5085],\n",
            "        [-0.7755, -0.9839, -0.9576,  ..., -0.9085,  0.5448,  0.3868],\n",
            "        [ 0.4563,  0.9906,  0.8321,  ...,  0.8164, -0.8409, -0.4313],\n",
            "        ...,\n",
            "        [-0.4391,  0.5654, -0.8820,  ..., -0.9240,  0.1467,  0.5030],\n",
            "        [-0.5084,  0.9044, -0.8609,  ..., -0.7798,  0.6854,  0.0139],\n",
            "        [-0.4131, -0.9967, -0.9022,  ..., -0.9116,  0.1991,  0.5538]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5170,  0.9642, -0.8813,  ..., -0.8205,  0.6373,  0.4367],\n",
            "        [ 0.8632,  0.9971,  0.8322,  ...,  0.9296, -0.4752, -0.6505],\n",
            "        [ 0.7550,  1.0000,  0.9229,  ...,  0.8199, -0.6841, -0.7063],\n",
            "        ...,\n",
            "        [-0.6747,  0.9939, -0.7506,  ..., -0.7840,  0.2819,  0.7729],\n",
            "        [-0.1293,  0.9729, -0.9407,  ..., -0.9396,  0.6455,  0.0766],\n",
            "        [ 0.4658,  0.9938,  0.7863,  ...,  0.9011, -0.8707, -0.3655]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 2.3286e-01,  9.9988e-01,  2.9940e-01,  ...,  1.0978e-01,\n",
            "          5.4538e-01, -7.2549e-01],\n",
            "        [-4.2109e-01,  9.9750e-01, -7.9453e-01,  ..., -7.5837e-01,\n",
            "          7.3258e-01,  5.8657e-04],\n",
            "        [-5.9010e-01, -9.9999e-01, -9.1917e-01,  ..., -7.9677e-01,\n",
            "          4.3118e-01,  4.8878e-01],\n",
            "        ...,\n",
            "        [-6.9917e-01, -9.6679e-01, -9.3252e-01,  ..., -9.0402e-01,\n",
            "         -7.7240e-02,  6.4058e-01],\n",
            "        [ 5.6247e-01,  9.9343e-01,  8.2145e-01,  ...,  9.1634e-01,\n",
            "         -8.8966e-01, -4.7480e-01],\n",
            "        [ 2.3767e-01,  9.5789e-01,  7.0639e-01,  ...,  8.6181e-01,\n",
            "         -8.3650e-01, -8.2763e-02]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6749, -0.5884, -0.9542,  ..., -0.9383, -0.0081,  0.7173],\n",
            "        [-0.7027, -0.9854, -0.8921,  ..., -0.9355,  0.5524,  0.6607],\n",
            "        [-0.6342, -0.5760, -0.9362,  ..., -0.9021,  0.2398,  0.6901],\n",
            "        ...,\n",
            "        [-0.7161,  0.7206, -0.9473,  ..., -0.8634,  0.1601,  0.5922],\n",
            "        [ 0.7256,  0.9998,  0.8192,  ...,  0.6679, -0.3752, -0.7395],\n",
            "        [-0.5450, -0.1646, -0.9544,  ..., -0.8893,  0.3599,  0.6541]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6620,  0.9934,  0.8289,  ...,  0.8669, -0.7815, -0.2879],\n",
            "        [ 0.7931,  1.0000,  0.8774,  ...,  0.8112, -0.6818, -0.7401],\n",
            "        [-0.6112,  0.9997, -0.6225,  ..., -0.8551,  0.0985, -0.4122],\n",
            "        ...,\n",
            "        [-0.5469, -0.9612, -0.9514,  ..., -0.9152,  0.3256,  0.5783],\n",
            "        [ 0.5511,  1.0000,  0.6873,  ...,  0.3021, -0.6029, -0.8797],\n",
            "        [ 0.6523,  0.9632,  0.8044,  ...,  0.8294, -0.7791, -0.1333]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4849,  0.9432, -0.8733,  ..., -0.8551,  0.2889,  0.4043],\n",
            "        [-0.6624,  0.2774, -0.9094,  ..., -0.8638,  0.0494,  0.5199],\n",
            "        [-0.7311, -0.9797, -0.9391,  ..., -0.9199,  0.0727,  0.7376],\n",
            "        ...,\n",
            "        [ 0.5704,  0.9976,  0.8706,  ...,  0.8999, -0.8621, -0.3847],\n",
            "        [-0.5490,  0.8431, -0.9092,  ..., -0.9297,  0.1354,  0.3097],\n",
            "        [-0.5827,  0.3779, -0.9203,  ..., -0.8968,  0.4987,  0.4901]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6451,  0.2128, -0.9385, -0.5130,  0.0088, -0.9171, -0.5244, -0.7710,\n",
            "          0.8316,  0.6362, -0.7008,  0.8766, -0.2146, -0.4909,  0.1861,  0.8858,\n",
            "         -0.6897,  0.1350,  0.4551,  0.4946, -0.0270,  0.8531,  0.1660, -0.2204,\n",
            "         -0.7410, -0.8668,  0.4049,  0.3016,  0.2472, -0.5416,  0.0921,  0.8486,\n",
            "          0.6478,  0.2023,  0.2933,  0.3569,  0.6216,  0.3848, -0.7552, -0.2316,\n",
            "          0.9380,  0.3844, -0.0431, -0.7573, -0.6913, -0.3796,  0.0920, -0.5861,\n",
            "          0.2306,  0.3993,  0.3758, -0.9948,  0.2694, -0.9355, -0.6591, -0.8622,\n",
            "         -0.3983,  0.4181,  0.0965,  0.7580, -0.4786, -0.5332,  0.8729,  0.3024,\n",
            "          0.9704,  0.2271,  0.5611, -0.2706,  0.9246, -0.6664, -0.8795,  0.8244,\n",
            "         -0.1744, -0.2708,  0.5081, -0.4231,  0.8585, -0.7255, -0.3211,  0.3445,\n",
            "         -0.7656,  0.4775,  0.8186, -0.6180, -0.7042, -0.5027,  0.6844, -0.3910,\n",
            "          0.3254, -0.2687, -0.1704, -0.8902, -0.6964,  0.7615,  0.5533, -0.3331,\n",
            "          0.3934, -0.8848,  0.4201,  0.0799,  0.6934,  0.5566,  0.5693,  0.1247,\n",
            "         -0.2687, -0.8798,  0.5264, -0.5487,  0.5239,  0.2464, -0.6071, -0.1593,\n",
            "          0.8911, -0.6792, -0.4869,  0.7727, -0.9142, -0.6457,  0.2351,  0.1754,\n",
            "         -0.2510, -0.6302,  0.5118, -0.5296, -0.5605, -0.8024, -0.7511,  0.8436,\n",
            "          0.4480,  0.1572, -0.0777, -0.9257, -0.8217, -0.7986,  0.5958, -0.4588,\n",
            "         -0.9659,  0.2186,  0.7068,  0.6522,  0.8223,  0.5946, -0.5157,  0.1315,\n",
            "          0.1216,  0.5062, -0.0382,  0.6016, -0.0910, -0.8552,  0.2782, -0.5530,\n",
            "         -0.7790,  0.1405, -0.8110,  0.5340,  0.6028,  0.4539,  0.9741, -0.9089,\n",
            "          0.7326,  0.7344,  0.4283,  0.1911,  0.9974, -0.6849,  0.2718,  0.7019,\n",
            "          0.8765, -0.4479, -0.0613,  0.6781,  0.3505,  0.6648,  0.9913, -0.7515,\n",
            "         -0.6804,  0.2381,  0.9134,  0.7619,  0.0417,  0.1005, -0.8629, -0.8722,\n",
            "          0.7543, -0.6054, -0.5350,  0.3739, -0.9319,  0.5628, -0.6771, -0.7956,\n",
            "         -0.6662,  0.8387,  0.2048, -0.2498, -0.2971,  0.5742,  0.6782,  0.3937,\n",
            "          0.6923,  0.2900,  0.5892, -0.9496, -0.8536, -0.6501,  0.2359,  0.0209,\n",
            "         -0.4926,  0.5921,  0.4245,  0.7074,  0.2172, -0.8136, -0.1161,  0.6056,\n",
            "          0.6796, -0.9437,  0.7068,  0.8834, -0.7645, -0.7899,  0.5033, -0.8871,\n",
            "         -0.2091, -0.5669, -0.1882,  0.3679, -0.8310,  0.3414,  0.2244,  0.6789,\n",
            "          0.3905,  0.8565,  0.9517,  0.2585, -0.9023,  0.2948,  0.6985, -0.4849,\n",
            "          0.8956, -0.3895,  0.8607,  0.2567, -0.8552,  0.3353, -0.8110, -0.7371,\n",
            "         -0.1538,  0.7622, -0.1918, -0.4122,  0.6075,  0.6658,  0.6572,  0.3785,\n",
            "          0.9014, -0.9344, -0.6668,  0.0370, -0.5631,  0.2501, -0.9513, -0.8388,\n",
            "         -0.4712,  0.8642, -0.7666, -0.2972,  0.4886,  0.4169,  0.3850,  0.7257,\n",
            "         -0.3532,  0.8916,  0.3193, -0.7767,  0.7111,  0.0705, -0.8228,  0.6655,\n",
            "         -0.9830,  0.9142,  0.7191,  0.6130,  0.0066,  0.5761, -0.2282,  0.8009,\n",
            "         -0.9289,  0.0966,  0.7792,  0.8227,  0.9574,  0.1479, -0.8514, -0.8075,\n",
            "          0.6987, -0.7365,  0.2212,  0.8113,  0.1423,  0.6081,  0.4398,  0.7031,\n",
            "         -0.0153,  0.7441, -0.9307,  0.6563, -0.6749,  0.1948,  0.1312, -0.6231,\n",
            "         -0.6295,  0.4277, -0.4729, -0.7158, -0.4927,  0.4839,  0.2578,  0.0933,\n",
            "          0.2359,  0.8376, -0.5553, -0.6498, -0.7131, -0.0963,  0.7228, -0.3338,\n",
            "         -0.6820,  0.4054, -0.0469,  0.9055, -0.4235, -0.7859, -0.1413, -0.4144,\n",
            "         -0.2763,  0.9550, -0.8844,  0.6487,  0.8342,  0.4978,  0.8610,  0.4858,\n",
            "         -0.2469, -0.7856,  0.4787, -0.2762,  0.7470, -0.3702, -0.4506,  0.2871,\n",
            "         -0.8979, -0.6931,  0.7969,  0.7484,  0.7620,  0.9146, -0.7641,  0.4668,\n",
            "         -0.6553, -0.0504,  0.8054, -0.6485,  0.7642, -0.7393,  0.4397,  0.3568,\n",
            "         -0.9404,  0.5920, -0.7039,  0.6906, -0.3481,  0.9409, -0.6299, -0.8429,\n",
            "         -0.4976,  0.0971,  0.8212,  0.2690, -0.5615, -0.0384,  0.7622,  0.3238,\n",
            "         -0.5917,  0.5104,  0.6423, -0.8737,  0.7213,  0.7010,  0.5214, -0.0089,\n",
            "         -0.2402, -0.8383,  0.2878,  0.8010, -0.2920, -0.5325, -0.4345,  0.8343,\n",
            "         -0.7581, -0.0237, -0.5326,  0.4720,  0.6350, -0.5314,  0.1202, -0.1290,\n",
            "          0.1300, -0.9380,  0.6439,  0.5803,  0.4346,  0.3776, -0.8767,  0.0467,\n",
            "         -0.8908, -0.2113, -0.7261,  0.4685, -0.3576, -0.6416, -0.7099, -0.9678,\n",
            "          0.9064, -0.1562,  0.9483, -0.5869, -0.7370, -0.3639, -0.2317, -0.1322,\n",
            "          0.7249, -0.5372,  0.9600, -0.7258,  0.0911,  0.4174,  0.6674,  0.2052,\n",
            "          0.7318,  0.8212,  0.7551,  0.1072,  0.6218,  0.0011, -0.8059, -0.9065,\n",
            "          0.3896,  0.6747, -0.1328,  0.8357, -0.6030,  0.7395,  0.8553, -0.0486,\n",
            "          0.0387, -0.3433,  0.9464,  0.6285, -0.1812,  0.8649,  0.7285,  0.8679,\n",
            "          0.2223,  0.0469,  0.5160,  0.5534, -0.8237, -0.3040,  0.7649,  0.5080,\n",
            "          0.2381, -0.9241,  0.2928, -0.3481, -0.2656, -0.8840, -0.1783, -0.9890,\n",
            "          0.3334,  0.6335, -0.9062,  0.1104,  0.0829,  0.1363,  0.2049,  0.4084,\n",
            "          0.9146, -0.6711,  0.1129, -0.1467,  0.0997,  0.5232,  0.3943,  0.1896,\n",
            "         -0.7057, -0.3739,  0.1993,  0.3230,  0.3863, -0.8160, -0.2071,  0.4758,\n",
            "         -0.8242, -0.8981,  0.7292,  0.9678,  0.3677,  0.6511,  0.5175,  0.0822,\n",
            "         -0.1609,  0.8751, -0.3048,  0.3173,  0.8332,  0.0342, -0.5708, -0.5212,\n",
            "         -0.7373, -0.4058,  0.3677, -0.3714, -0.8478, -0.9359, -0.5002, -0.4266,\n",
            "         -0.4476, -0.0842,  0.6815, -0.6331,  0.0426, -0.7680, -0.5330, -0.9669,\n",
            "         -0.5091, -0.4176, -0.6447,  0.2980, -0.9335, -0.7617, -0.5625,  0.0082,\n",
            "          0.5929,  0.8598, -0.3764, -0.4287, -0.6555,  0.7189, -0.8934,  0.3615,\n",
            "         -0.4784,  0.8308, -0.9180,  0.3530, -0.8421, -0.5188, -0.0828,  0.3649,\n",
            "          0.1463, -0.9138,  0.3667, -0.6852,  0.1984, -0.2424, -0.5409, -0.6935,\n",
            "         -0.8840, -0.9268,  0.7851,  0.9490,  0.1958, -0.8276, -0.6532,  0.6230,\n",
            "          0.2144, -0.6500,  0.7753,  0.8957,  0.7237,  0.7666,  0.2718, -0.2409,\n",
            "         -0.7377, -0.2503, -0.2887, -0.0368, -0.5950,  0.5329, -0.1854,  0.4180,\n",
            "          0.6692, -0.5663,  0.9319,  0.5317, -0.3450,  0.8928, -0.7427, -0.8561,\n",
            "         -0.7871, -0.9040,  0.9027, -0.3503, -0.8807,  0.3191, -0.3220, -0.0861,\n",
            "         -0.0460,  0.1830,  0.6618,  0.5328,  0.4130,  0.1074, -0.4540, -0.5724,\n",
            "          0.5390,  0.8518, -0.1233,  0.6800, -0.3605,  0.7678,  0.1140,  0.6555,\n",
            "          0.3868,  0.4920,  0.1960, -0.9566,  0.7144, -0.3398,  0.6020,  0.8414,\n",
            "         -0.4490, -0.8426, -0.4446, -0.8196, -0.2745, -0.8173,  0.9442, -0.1627,\n",
            "         -0.4783,  0.8669,  0.7192,  0.3007,  0.7953, -0.7801, -0.3076,  0.1674,\n",
            "          0.5514,  0.8112, -0.2759, -0.8566, -0.1028, -0.9190, -0.5817, -0.0828,\n",
            "         -0.0417,  0.2986, -0.5005, -0.9251,  0.1609, -0.8811,  0.5627, -0.4385,\n",
            "         -0.4991,  0.9074, -0.6071, -0.1722,  0.9428,  0.7164, -0.8231,  0.9417,\n",
            "         -0.2252, -0.3199,  0.7840,  0.4340, -0.4424,  0.6513,  0.2141,  0.1589,\n",
            "         -0.3060, -0.7417,  0.9458,  0.6402, -0.3176,  0.8120, -0.0377,  0.2665,\n",
            "          0.5286, -0.7583,  0.5132, -0.3419, -0.2742, -0.5630, -0.4646,  0.7630,\n",
            "          0.9896, -0.9769,  0.9327,  0.2453, -0.1252,  0.0510, -0.3972,  0.0012,\n",
            "          0.8280,  0.1481,  0.5549, -0.4592, -0.5682, -0.1790,  0.1224, -0.9368,\n",
            "         -0.8790,  0.6222,  0.4630, -0.9417, -0.4636,  0.4149,  0.5509, -0.5895,\n",
            "          0.2035,  0.5841, -0.4095,  0.2032, -0.9153, -0.0784,  0.4742, -0.2906,\n",
            "          0.8641, -0.5337,  0.9441, -0.6600,  0.6994,  0.7558, -0.7179, -0.8838,\n",
            "         -0.2810, -0.7330,  0.2327, -0.1315, -0.7804,  0.7066, -0.8438,  0.2653,\n",
            "         -0.3182, -0.8139,  0.3754, -0.3833,  0.4114,  0.2811, -0.8137,  0.7933,\n",
            "          0.8550,  0.1148,  0.9200, -0.6530,  0.6329,  0.0644,  0.5046,  0.7951,\n",
            "          0.5222, -0.1988, -0.8532, -0.4653,  0.6633, -0.7754,  0.2238,  0.6651]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluation... :   0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aeebdb00c47c4e588897f4853757d9e5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7346,  0.9386,  0.8684,  ...,  0.8738, -0.8459, -0.2806],\n",
            "        [ 0.8268,  1.0000,  0.9613,  ...,  0.8307,  0.1113, -0.9526],\n",
            "        [ 0.6059,  0.9996, -0.8182,  ..., -0.8513,  0.7073, -0.5245],\n",
            "        ...,\n",
            "        [ 0.4170,  0.9943,  0.7714,  ...,  0.8391, -0.8297, -0.1261],\n",
            "        [-0.1091,  0.9793, -0.7369,  ..., -0.8616,  0.5627, -0.1041],\n",
            "        [-0.7109, -0.1942, -0.9178,  ..., -0.7500,  0.3131,  0.6596]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4312,  0.9983, -0.8670,  ..., -0.8851,  0.4213,  0.2098],\n",
            "        [ 0.6995,  0.9997,  0.7264,  ...,  0.5648, -0.8303, -0.2063],\n",
            "        [ 0.3261,  0.9993,  0.2494,  ..., -0.6160,  0.3847, -0.8948],\n",
            "        ...,\n",
            "        [-0.2294,  0.9930, -0.2964,  ..., -0.7273,  0.1948, -0.7123],\n",
            "        [-0.6244,  0.9999, -0.5537,  ..., -0.8736,  0.3399,  0.0659],\n",
            "        [ 0.4842,  1.0000,  0.7003,  ..., -0.6341,  0.5965, -0.9662]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6488,  0.9999,  0.9260,  ...,  0.8548, -0.6765, -0.6765],\n",
            "        [ 0.3602,  1.0000,  0.6908,  ...,  0.3312,  0.7634, -0.8405],\n",
            "        [ 0.5880,  0.9998,  0.8428,  ...,  0.8713, -0.7800, -0.4780],\n",
            "        ...,\n",
            "        [-0.1427,  1.0000,  0.0708,  ..., -0.8762,  0.4886, -0.8169],\n",
            "        [-0.7915, -0.3247, -0.9113,  ..., -0.9233,  0.2732,  0.5295],\n",
            "        [ 0.4819,  1.0000,  0.6575,  ...,  0.2269, -0.0167, -0.9170]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1519,  0.9966,  0.1570,  ...,  0.0476, -0.7056, -0.6008],\n",
            "        [ 0.0288,  1.0000,  0.7252,  ..., -0.2459, -0.0702, -0.9317],\n",
            "        [-0.1015,  0.9998, -0.4927,  ..., -0.8156,  0.3628, -0.8435],\n",
            "        ...,\n",
            "        [ 0.7799,  0.9999,  0.9136,  ...,  0.8745, -0.5582, -0.6081],\n",
            "        [-0.1712, -0.3560, -0.8246,  ..., -0.9101,  0.6572, -0.1842],\n",
            "        [ 0.6350,  0.9824,  0.8574,  ...,  0.9011, -0.8831, -0.2428]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7040,  0.9997,  0.7105,  ...,  0.7691, -0.5716, -0.1692],\n",
            "        [ 0.4619,  0.9993,  0.8132,  ...,  0.8931, -0.5994, -0.3774],\n",
            "        [-0.5643,  0.2805, -0.8910,  ..., -0.7616,  0.3772,  0.5396],\n",
            "        ...,\n",
            "        [ 0.5742,  0.9997,  0.5576,  ...,  0.7628, -0.5904, -0.7593],\n",
            "        [ 0.5063,  0.9995,  0.8862,  ...,  0.4909, -0.6186, -0.4620],\n",
            "        [ 0.7434,  0.9989,  0.9453,  ...,  0.4739, -0.4202, -0.6892]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5245,  0.9913,  0.8615,  ...,  0.8882, -0.8484, -0.2994],\n",
            "        [ 0.8003,  1.0000,  0.6697,  ...,  0.7389, -0.7263, -0.8101],\n",
            "        [-0.4182, -0.4504, -0.9677,  ..., -0.8715,  0.5467,  0.4583],\n",
            "        ...,\n",
            "        [ 0.3140,  0.9106, -0.9208,  ..., -0.8428,  0.6793,  0.2314],\n",
            "        [ 0.3867,  1.0000,  0.1210,  ...,  0.2808, -0.5077, -0.5599],\n",
            "        [ 0.4903,  0.9998,  0.7655,  ...,  0.7251, -0.7767, -0.6674]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0220,  0.9793, -0.5437,  ..., -0.7940, -0.3262, -0.6162],\n",
            "        [-0.5887, -0.7176, -0.9489,  ..., -0.9281,  0.1327,  0.7322],\n",
            "        [ 0.6189,  0.9760,  0.8007,  ...,  0.8989, -0.8471, -0.2352],\n",
            "        ...,\n",
            "        [-0.2548,  1.0000, -0.3706,  ..., -0.7895, -0.4075, -0.4770],\n",
            "        [ 0.6068,  0.9870,  0.9027,  ...,  0.9067, -0.8683, -0.2763],\n",
            "        [-0.4426,  0.9250, -0.8609,  ..., -0.8300,  0.0993,  0.4206]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6463,  0.9969,  0.8704,  ...,  0.8935, -0.8245, -0.3534],\n",
            "        [ 0.6904,  0.9964,  0.9142,  ...,  0.9205, -0.8038, -0.4240],\n",
            "        [ 0.7574,  1.0000,  0.9367,  ...,  0.8635, -0.4312, -0.7603],\n",
            "        ...,\n",
            "        [ 0.5821,  0.9508,  0.8600,  ...,  0.8685, -0.9013, -0.1087],\n",
            "        [ 0.4705,  0.9954,  0.7574,  ...,  0.8530, -0.8344, -0.5355],\n",
            "        [ 0.5500,  1.0000,  0.7563,  ...,  0.6609, -0.6668, -0.5497]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.8230,  1.0000,  0.9546,  ...,  0.8505, -0.3244, -0.8719],\n",
            "        [-0.3350,  0.9667, -0.9129,  ..., -0.8535,  0.2330,  0.2369],\n",
            "        [-0.8333, -0.9647, -0.8389,  ..., -0.9080,  0.1112,  0.3655],\n",
            "        ...,\n",
            "        [ 0.6850,  0.9972,  0.8683,  ...,  0.8767, -0.8213, -0.2511],\n",
            "        [-0.6828, -0.6119, -0.9299,  ..., -0.8990,  0.2701,  0.7945],\n",
            "        [ 0.4907,  0.9362,  0.8460,  ...,  0.8617, -0.8670, -0.1077]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5963, -0.6783, -0.9515,  ..., -0.8794,  0.1433,  0.5784],\n",
            "        [ 0.1591,  1.0000,  0.3074,  ..., -0.5003, -0.1483, -0.7954],\n",
            "        [ 0.6204,  0.9967,  0.9030,  ...,  0.8876, -0.8231, -0.4505],\n",
            "        ...,\n",
            "        [ 0.6912,  0.9843,  0.7983,  ...,  0.8888, -0.8738, -0.2090],\n",
            "        [ 0.4823,  0.9990,  0.8278,  ...,  0.7593, -0.6595, -0.1259],\n",
            "        [ 0.7366,  1.0000,  0.9307,  ...,  0.8266, -0.0796, -0.9327]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2704,  0.5440, -0.9078,  ..., -0.8641,  0.3358,  0.4652],\n",
            "        [-0.5704, -0.9554, -0.9212,  ..., -0.9344,  0.1453,  0.5619],\n",
            "        [-0.7065,  0.7401, -0.9674,  ..., -0.9423, -0.0426,  0.4136],\n",
            "        ...,\n",
            "        [ 0.6823,  1.0000,  0.8389,  ...,  0.7306, -0.6767, -0.7574],\n",
            "        [ 0.5466,  1.0000, -0.6533,  ..., -0.8159,  0.5960, -0.8506],\n",
            "        [ 0.4841,  0.9900,  0.8881,  ...,  0.8924, -0.8503, -0.1683]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0519,  0.9999,  0.6095,  ..., -0.1650,  0.5093, -0.8233],\n",
            "        [-0.5590, -0.8966, -0.9569,  ..., -0.8988,  0.2697,  0.6727],\n",
            "        [-0.7108,  0.9196, -0.9301,  ..., -0.9010,  0.2398,  0.1935],\n",
            "        ...,\n",
            "        [-0.6475,  0.8834, -0.9449,  ..., -0.9081,  0.2698,  0.6494],\n",
            "        [ 0.2025,  1.0000,  0.2061,  ..., -0.4594, -0.1782, -0.7611],\n",
            "        [-0.4114,  0.9993, -0.7443,  ..., -0.9150,  0.4787, -0.2261]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0392,  0.9875, -0.8162,  ..., -0.4670,  0.6761,  0.4328],\n",
            "        [ 0.3325,  1.0000,  0.6491,  ...,  0.0868, -0.1612, -0.8533],\n",
            "        [-0.6657, -0.9471, -0.8743,  ..., -0.9128,  0.4267,  0.4964],\n",
            "        ...,\n",
            "        [-0.7343,  0.9913, -0.9291,  ..., -0.7372,  0.6088,  0.3330],\n",
            "        [-0.4095,  0.9579, -0.9410,  ..., -0.8821,  0.3930,  0.2544],\n",
            "        [-0.6602,  1.0000, -0.7497,  ..., -0.8138,  0.4384, -0.5668]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7816,  0.9999,  0.9098,  ...,  0.5398, -0.5645, -0.6410],\n",
            "        [ 0.6195,  1.0000,  0.8276,  ...,  0.4597, -0.3929, -0.7879],\n",
            "        [-0.6838, -0.3657, -0.9371,  ..., -0.8557, -0.0900,  0.5592],\n",
            "        ...,\n",
            "        [ 0.4827,  1.0000,  0.6082,  ..., -0.0798, -0.5628, -0.6571],\n",
            "        [ 0.5079,  1.0000,  0.7639,  ...,  0.8134, -0.4200, -0.5856],\n",
            "        [-0.3975,  0.9995, -0.4735,  ..., -0.5852, -0.0917, -0.6373]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4681,  0.9999,  0.7399, -0.9221, -0.5180,  0.9327,  0.6469,  0.7940,\n",
            "         -0.9941, -0.5832,  0.7812, -0.5990,  0.5436,  0.9977,  0.4372, -0.1140,\n",
            "          0.6987, -0.9408,  0.5161, -0.1406,  0.3267, -0.7871,  0.7575, -0.1907,\n",
            "          0.7895,  0.7748, -0.5150,  0.3854, -0.0572,  0.1918, -0.5591, -0.1895,\n",
            "          0.8364,  0.5767,  0.7365, -0.9012, -0.2302, -0.9376, -0.9634, -0.9907,\n",
            "          0.2975, -0.3724,  0.9987, -0.7626,  0.9927, -0.9796,  0.5076, -0.2526,\n",
            "          0.5170,  0.3658, -0.6262,  0.9461,  0.7371,  0.7960, -0.5647, -0.6831,\n",
            "         -0.7381,  0.3733, -0.7962, -0.5170,  0.7654,  0.8196, -0.5540, -0.1372,\n",
            "         -0.8567, -0.6397,  0.5388,  0.4212, -0.6711, -0.8906,  0.8460, -0.9263,\n",
            "          0.5354,  0.2971, -0.3829,  0.7547, -0.8670,  0.9259, -0.7499,  0.9793,\n",
            "          0.6109,  0.3931,  0.5569, -0.9998,  0.6371, -0.8460,  0.9737, -0.9522,\n",
            "         -0.9049,  0.6559,  0.7565,  0.6154,  0.8273, -0.1385, -0.4214, -0.8890,\n",
            "         -0.6823,  0.5260, -0.9963,  0.7164,  0.5160,  0.6822, -0.6957, -0.5061,\n",
            "         -0.9972,  0.5308, -0.6212, -0.3928, -0.9998, -0.6844, -0.7928, -0.7569,\n",
            "         -0.3520,  0.8236,  0.5565,  0.9990,  0.8721,  0.9958, -0.9998, -0.9846,\n",
            "          0.0065,  0.9173, -0.5662,  0.1978,  0.4883, -0.9399,  0.7804, -0.9959,\n",
            "          0.5393, -0.9059, -0.3770,  0.7080,  0.8775,  0.6295, -0.6011,  0.5384,\n",
            "         -0.9991, -0.0558, -0.6770, -0.9849,  0.9844,  0.6900,  0.8449, -0.3817,\n",
            "         -0.2109,  0.7308,  0.8213, -0.7101,  0.2011, -0.0941, -0.7833,  0.7742,\n",
            "          0.3622, -0.4301, -0.9997,  0.4496, -0.7282,  0.9113, -0.9854,  0.9573,\n",
            "         -0.9712, -0.9999,  0.2258,  0.1966, -0.7711,  0.7917, -0.7364,  0.8383,\n",
            "         -0.5577,  0.6615,  0.5266,  0.5819,  0.3248, -0.6153,  0.3039, -0.5841,\n",
            "          0.8307, -0.7054, -0.7038, -0.9138,  0.9418, -0.3624,  0.9631, -0.9229,\n",
            "         -0.7133,  0.4606,  0.2547, -1.0000,  0.8755,  0.4376,  0.3932,  0.7289,\n",
            "          0.2482, -0.4294, -0.0776,  0.0382, -0.4298,  0.5866, -0.2610,  0.8047,\n",
            "          0.2745, -0.9990,  0.6827,  0.9895,  0.0911, -0.3015,  0.1184,  0.9564,\n",
            "         -0.9917, -0.5251,  0.0798, -0.5566,  0.4118,  0.4476, -0.3380, -0.7397,\n",
            "          0.4761,  0.4146, -0.3624, -0.5517,  0.2208,  0.5121, -0.1814,  0.4056,\n",
            "          0.6933,  0.9988, -0.4245, -0.6302,  0.6438, -0.9985,  0.7674,  0.4508,\n",
            "         -0.4545, -0.6896,  0.9823,  0.6763,  0.6794,  0.9735, -0.9233, -0.1095,\n",
            "         -0.5933,  0.8767, -0.5349, -0.1158,  0.9999, -0.9852,  0.9719,  0.8956,\n",
            "         -0.0644, -0.4996,  0.7591,  0.2924, -0.4170, -0.1489, -0.6241,  0.9888,\n",
            "         -0.6489, -0.9592,  0.5251, -0.3231, -0.8262, -0.8263,  0.8276, -0.3978,\n",
            "          0.9511,  0.9995,  0.8010,  0.4258,  0.6155,  0.4507,  0.6574, -0.9702,\n",
            "          0.9499,  0.9998, -0.9289,  0.5510,  0.9996,  0.5834, -0.0974, -0.6233,\n",
            "          0.3316, -0.9635, -0.1637, -0.4801, -0.5025, -0.5804,  0.0211, -0.9032,\n",
            "         -0.9986, -0.9637,  0.9423, -0.6369, -0.6723,  0.4864, -0.7580,  0.5562,\n",
            "         -0.7506,  0.9847, -0.6214,  0.9997,  0.4710, -0.5285, -0.9321, -0.2360,\n",
            "          0.4213,  0.0616,  0.9983,  0.0246, -0.4921,  0.6706,  0.5131,  0.2020,\n",
            "          0.8858, -0.5565,  0.6096,  0.3581,  0.0052, -0.9030, -0.2518, -0.8366,\n",
            "          0.6813,  0.9352,  0.6734,  0.3677,  0.9304,  0.8020, -0.9999,  0.9973,\n",
            "          0.9618, -0.9843,  0.7946, -0.1437,  0.8738, -0.2751,  0.3899, -0.8639,\n",
            "         -0.7938, -0.9612,  0.6821,  0.1563, -0.7273,  0.1759, -0.9055,  0.7463,\n",
            "          0.1379,  0.8028, -0.3258,  0.3372, -0.9898,  0.6567,  0.8452, -0.3023,\n",
            "          0.7561,  0.9783, -0.0635,  0.9998, -0.7183, -0.6455,  0.2818,  0.4675,\n",
            "          0.4155,  0.3635, -0.3235,  0.6371, -0.9999,  0.3611, -0.4794,  0.1703,\n",
            "          0.6824, -0.9729,  0.6172, -0.4794,  0.1479, -0.2376,  0.3357,  0.5934,\n",
            "          0.9973,  0.2802, -0.5190, -0.6088,  0.1440, -0.0132,  0.8648,  0.5560,\n",
            "          0.9813, -0.7824, -0.3823,  0.6476, -0.0269, -0.6374, -0.1126,  0.5825,\n",
            "          0.0347,  0.8754,  0.6906, -0.6651, -0.4784,  0.8239, -0.9966,  0.9996,\n",
            "          0.2334,  0.4777,  0.8988, -0.3056,  0.6339,  0.5274,  0.2647, -0.6384,\n",
            "          0.9655,  0.7480,  0.5337,  0.0718, -0.2132,  0.0479, -0.9195,  0.4632,\n",
            "          0.4118, -0.3472, -0.9651,  0.9783, -0.9628,  0.4810, -0.0684,  0.8223,\n",
            "          0.8972, -0.2012, -0.8728, -0.0878,  0.5507, -0.6106, -0.7825, -0.9846,\n",
            "         -0.0925, -0.7924,  0.9996, -0.9813,  0.4607, -0.8666, -0.8957,  0.7120,\n",
            "         -0.4826, -0.5102, -0.8196, -0.1776, -0.4673,  0.6806,  0.0499,  0.7312,\n",
            "         -0.5269,  0.2966,  0.7376,  0.0954,  0.2051,  0.8961, -0.6182, -0.9308,\n",
            "         -0.6560, -0.5317, -0.7326,  0.9276, -0.8796, -0.8418,  0.9999, -0.9707,\n",
            "          0.1899, -0.3594, -0.9932,  0.5369, -0.1752, -0.9147, -0.6376, -0.7871,\n",
            "          0.6080,  0.8953,  0.9978,  0.2843,  0.3511, -0.8965, -0.6226,  0.9959,\n",
            "         -0.9070, -0.4992,  0.4078, -0.9887,  0.9078,  0.1619, -0.4276,  0.8076,\n",
            "         -0.7102,  0.9366,  0.6305, -0.9964,  0.5212,  0.6474, -0.3255,  0.8208,\n",
            "          0.3169,  0.3326, -0.9245, -0.1007,  0.9972,  0.4581, -0.7131, -0.1326,\n",
            "          0.8017,  0.7629,  0.9998, -0.9436,  0.6149,  0.9984, -0.2601,  0.4355,\n",
            "          0.3376, -0.7541,  0.0529,  0.4496, -0.9702,  0.9995,  0.1134, -0.9830,\n",
            "         -0.9997,  0.2807, -0.7870,  0.7367,  0.9673,  0.6488,  0.8500,  0.2418,\n",
            "         -0.9978, -0.0794, -0.5306, -0.9992, -0.9980,  0.8227,  0.2575,  0.1660,\n",
            "          0.7754, -0.0068, -0.7191,  0.9989,  0.9086, -0.9996, -0.0647,  0.1286,\n",
            "          0.9584, -0.6815,  0.5541,  0.4768,  0.4471, -0.3835, -0.9998, -0.4507,\n",
            "          0.9501, -0.0474,  0.0411,  0.9983,  0.6675,  0.4960, -0.9313, -0.1856,\n",
            "          0.6162, -0.9998, -0.7035,  0.9993, -0.0840,  0.0116, -0.4132,  0.4079,\n",
            "          0.5782,  0.5544, -0.0119, -0.9938,  0.9887,  0.8800, -0.9186,  0.9947,\n",
            "         -0.5489, -0.6400, -0.6857, -0.6782,  0.6718, -0.7436,  0.4385, -0.1033,\n",
            "          0.9680,  0.8650, -0.3146,  0.6982,  0.9105, -0.7708, -0.2266,  0.7019,\n",
            "          0.5290,  0.4763,  0.9659, -0.4040, -0.6755, -0.4694,  0.6169,  0.9219,\n",
            "         -0.9995,  0.9226, -0.5048, -0.8518,  0.6346, -0.5747, -0.4857, -0.2190,\n",
            "         -0.6929, -0.6333,  0.1019,  0.9259,  0.6737,  0.6894, -0.9738, -0.9996,\n",
            "         -0.6934, -0.5914, -0.7477, -0.5258,  0.3455,  0.9024,  0.1404,  0.4146,\n",
            "          0.1495,  0.9993, -0.4051,  0.9873, -0.7830,  0.9219, -0.9851,  0.3919,\n",
            "          0.5616, -0.8911, -0.3864,  0.9550, -0.2704,  0.8179, -0.9604,  0.5990,\n",
            "          0.9999, -0.7328, -0.6768,  0.5955, -0.8514,  0.7565,  0.0842,  0.9873,\n",
            "         -0.9998,  0.9838, -0.2103,  0.4830,  0.5038,  0.6091,  0.6246, -0.5457,\n",
            "         -0.4504, -0.9838,  0.6598,  0.3904, -0.6418,  0.3057,  0.8813, -0.7254,\n",
            "         -0.9934, -0.6141,  0.4694,  0.9061, -0.5227, -0.9870,  0.9334, -0.2040,\n",
            "          0.9583,  0.3420, -0.6966, -0.4450, -0.0672, -0.6143,  0.4806,  0.6582,\n",
            "          0.7986,  0.3173, -0.8769, -0.4927,  0.1458, -0.7416,  0.7137, -0.3689,\n",
            "         -0.3038,  0.7308,  0.8068,  0.9563,  0.3866,  0.2407,  0.7449, -0.7066,\n",
            "         -0.6206, -0.9992,  0.9977,  0.8365, -0.8195, -0.9992,  0.9203,  0.1286,\n",
            "         -0.3380,  0.6791,  0.0286, -0.6091,  0.3484,  0.6358, -0.9999, -0.4340,\n",
            "          0.1443, -0.3527, -0.7255, -0.9995, -0.5388,  0.0135, -0.2177,  0.2897,\n",
            "          0.9954, -0.3377, -0.9806, -0.9253, -0.0403,  0.5585,  0.1208, -0.9157,\n",
            "         -0.5615,  0.7472, -0.9967,  0.6959, -0.5544, -0.5168,  0.2176,  0.7492,\n",
            "          0.8665, -0.9997,  0.8408, -0.5970,  0.8762, -0.5153,  0.5189,  0.3912,\n",
            "          0.1730, -0.9902,  0.7601,  0.2680,  0.7506,  0.7237,  0.7743,  0.0847,\n",
            "         -0.8625, -0.6262,  0.9695,  0.9574, -0.6262,  0.5790,  0.9962, -0.6027,\n",
            "          0.4491,  0.6646,  0.2213, -0.9981, -0.8017, -0.1401, -0.6707, -0.7850]],\n",
            "       device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "for epoch in tqdm(range(1, EPOCHS + 1), desc=\"Epochs... \"):\n",
        "\n",
        "    # Define train_y, train_loss, step, eval_loss_min using train_op\n",
        "    ##############################################################################################\n",
        "    #                                       Your Code                                            #\n",
        "    ##############################################################################################\n",
        "    train_y, train_loss, step, eval_loss_min = train_op(\n",
        "        model=pt_model, \n",
        "        data_loader=train_data_loader, \n",
        "        loss_fn=loss_fn, \n",
        "        optimizer=optimizer, \n",
        "        scheduler=scheduler, \n",
        "        step=step, \n",
        "        print_every_step=EEVERY_EPOCH, \n",
        "        eval=True,\n",
        "        eval_cb=eval_callback(epoch, EPOCHS, OUTPUT_PATH),\n",
        "        eval_loss_min=eval_loss_min,\n",
        "        eval_data_loader=valid_data_loader, \n",
        "        clip=CLIP)    \n",
        "    \n",
        "    # Define train_score using acc_and_f1\n",
        "    ##############################################################################################\n",
        "    #                                       Your Code                                            #\n",
        "    ##############################################################################################\n",
        "    train_score = acc_and_f1(train_y[0], train_y[1], average='weighted')\n",
        "\n",
        "    # Define eval_y, eval_loss using eval_op\n",
        "    ##############################################################################################\n",
        "    #                                       Your Code                                            #\n",
        "    ##############################################################################################\n",
        "    eval_y, eval_loss = eval_op(\n",
        "        model=pt_model, \n",
        "        data_loader=valid_data_loader, \n",
        "        loss_fn=loss_fn)\n",
        "    \n",
        "    # Define eval_score using acc_and_f1\n",
        "    ##############################################################################################\n",
        "    #                                       Your Code                                            #\n",
        "    ##############################################################################################\n",
        "    eval_score = acc_and_f1(eval_y[0], eval_y[1], average='weighted')\n",
        "\n",
        "    # Save Accuracy and Loss values\n",
        "    ##############################################################################################\n",
        "    #                                       Your Code                                            #\n",
        "    ##############################################################################################\n",
        "    history['train_acc'].append(train_score['acc'])\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['val_acc'].append(eval_score['acc'])\n",
        "    history['val_loss'].append(eval_loss)\n",
        "\n",
        "# Diagram\n",
        "##############################################################################################\n",
        "#                                       Your Code                                            #\n",
        "##############################################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-ZvVuRsoYRK"
      },
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "iterarions = [i for i in range(10)]\n",
        "xpoints = np.array(iterarions)\n",
        "train_ypoints = np.array(history[\"train_loss\"])\n",
        "val_ypoints = np.array(history[\"val_loss\"])\n",
        "\n",
        "plt.plot(iterarions, train_ypoints, label = \"train loss\")\n",
        "plt.plot(iterarions, val_ypoints, label = \"validation loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "tzVjE3tnH4iK",
        "outputId": "28af1ba4-3bfb-4874-d255-4bbca72de49e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "iterarions = [i for i in range(10)]\n",
        "xpoints = np.array(iterarions)\n",
        "train_ypoints = np.array(history[\"train_acc\"])\n",
        "val_ypoints = np.array(history[\"val_acc\"])\n",
        "\n",
        "plt.plot(iterarions, train_ypoints, label = \"train acc\")\n",
        "plt.plot(iterarions, val_ypoints, label = \"validation acc\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "reFsi7a6VARq",
        "outputId": "d6cc410e-76e0-4ceb-e262-12c4d39a2bed"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4rSonLZjzrL"
      },
      "source": [
        "\n",
        "**<font color=red> Complete function</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "dlpDbg0wDqKP"
      },
      "outputs": [],
      "source": [
        "def predict(model, comments, tokenizer, max_len=128, batch_size=32):\n",
        "    data_loader = create_data_loader(comments, None, tokenizer, max_len, batch_size, None)\n",
        "    \n",
        "    predictions = []\n",
        "    prediction_probs = []\n",
        "\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for dl in tqdm(data_loader, position=0):\n",
        "\n",
        "            # Define input_ids, attention_mask, token_type_ids\n",
        "            ##############################################################################################\n",
        "            #                                       Your Code                                            #\n",
        "            ##############################################################################################\n",
        "            input_ids = dl['input_ids']\n",
        "            attention_mask = dl['attention_mask']\n",
        "            token_type_ids = dl['token_type_ids']\n",
        "            \n",
        "            # move tensors to GPU if CUDA is available\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            token_type_ids = token_type_ids.to(device)\n",
        "            \n",
        "            # compute predicted outputs by passing inputs to the model\n",
        "            ##############################################################################################\n",
        "            #                                       Your Code                                            #\n",
        "            ##############################################################################################\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                token_type_ids=token_type_ids)\n",
        "            # convert output probabilities to predicted class\n",
        "            ##############################################################################################\n",
        "            #                                       Your Code                                            #\n",
        "            ##############################################################################################\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "            predictions.extend(preds)\n",
        "            prediction_probs.extend(F.softmax(outputs, dim=1))\n",
        "\n",
        "    predictions = torch.stack(predictions).cpu().detach().numpy()\n",
        "    prediction_probs = torch.stack(prediction_probs).cpu().detach().numpy()\n",
        "\n",
        "    return predictions, prediction_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "RRpWTfwdoWoS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f9214e44a5aa4fb5ac252acb463925f1",
            "72b3e66d4c8b4421b4ee464af1f7d1f9",
            "e6e21363e9a444a6ab31fdd94a8922e5",
            "3da2a692295c4c4b95d604aaae8ad0b7",
            "e5743cd6e7e04deab6c06e228cd12553",
            "4b0fb2d13901413eac9efffecfd5b35e",
            "47d78132d74a4361be7784661e75ffae",
            "7b8304c29b2a457fb2fa9ac164e88d1e",
            "4da9adc5d47d4be8976fc76faf06f53f",
            "9b02b589e30d416e941abf0cf4642e58",
            "e9c919e53a984340a6cf47a594d64eeb"
          ]
        },
        "outputId": "48ea5a65-0bdc-4b5e-ba8c-cc012ab40c20"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/8 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f9214e44a5aa4fb5ac252acb463925f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5397,  0.9971, -0.8262,  ..., -0.9400,  0.6882, -0.3887],\n",
            "        [-0.7155,  0.9767, -0.8576,  ..., -0.7841,  0.5919,  0.7095],\n",
            "        [ 0.4905,  0.9273,  0.8241,  ...,  0.9015, -0.7864, -0.0895],\n",
            "        ...,\n",
            "        [-0.4293,  0.8832, -0.9012,  ..., -0.8577,  0.5271, -0.0243],\n",
            "        [-0.3067,  1.0000, -0.3072,  ..., -0.7203,  0.4499, -0.7601],\n",
            "        [-0.5749, -0.8885, -0.9168,  ..., -0.8994,  0.3939,  0.6602]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5766,  0.9697,  0.7474,  ...,  0.8574, -0.8210, -0.0675],\n",
            "        [ 0.6546,  1.0000,  0.9599,  ...,  0.8036, -0.4736, -0.8428],\n",
            "        [-0.0221,  1.0000, -0.3561,  ..., -0.4641,  0.4911, -0.6556],\n",
            "        ...,\n",
            "        [-0.5436,  0.9486, -0.9064,  ..., -0.9188,  0.1940,  0.0546],\n",
            "        [ 0.6469,  0.9855,  0.7892,  ...,  0.8926, -0.8726, -0.1249],\n",
            "        [ 0.0672,  0.8829, -0.5460,  ..., -0.5072,  0.0400, -0.2964]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6566,  0.1393, -0.9669,  ..., -0.8987,  0.1618,  0.6743],\n",
            "        [-0.7139, -0.1553, -0.9182,  ..., -0.9361,  0.1219,  0.3830],\n",
            "        [-0.1865,  0.9683, -0.6402,  ..., -0.4915,  0.6467, -0.3909],\n",
            "        ...,\n",
            "        [ 0.1351,  1.0000,  0.4008,  ..., -0.6264,  0.2274, -0.6943],\n",
            "        [ 0.1256,  1.0000, -0.2499,  ..., -0.7332, -0.0479, -0.6575],\n",
            "        [ 0.5326,  0.9989,  0.8703,  ...,  0.8499, -0.7738, -0.4856]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3144,  0.9999,  0.1953,  ..., -0.3952, -0.1964, -0.5735],\n",
            "        [ 0.5596,  0.9981,  0.8792,  ...,  0.8867, -0.8222, -0.2135],\n",
            "        [-0.5222,  0.9583, -0.9409,  ..., -0.8674,  0.2637, -0.0490],\n",
            "        ...,\n",
            "        [-0.2706,  0.6369, -0.9375,  ..., -0.7407,  0.2341,  0.3835],\n",
            "        [ 0.6354,  0.9964,  0.6126,  ...,  0.8334, -0.8282, -0.4855],\n",
            "        [-0.7303, -0.7213, -0.9308,  ..., -0.8912,  0.1862,  0.7535]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.7907,  0.0095, -0.9632,  ..., -0.9007,  0.2741,  0.7188],\n",
            "        [ 0.5473,  1.0000,  0.7878,  ...,  0.4029, -0.5866, -0.8898],\n",
            "        [-0.3890,  0.9995, -0.8203,  ..., -0.7898,  0.4756,  0.0988],\n",
            "        ...,\n",
            "        [ 0.6317,  0.9826,  0.8640,  ...,  0.8682, -0.8779, -0.2708],\n",
            "        [ 0.5286,  0.9188,  0.8444,  ...,  0.9163, -0.8577, -0.1242],\n",
            "        [ 0.7908,  0.9997,  0.8034,  ...,  0.8092, -0.8343, -0.3355]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7608,  0.9996,  0.9174,  ...,  0.8884, -0.6542, -0.5975],\n",
            "        [-0.7214,  0.8767, -0.9153,  ..., -0.8968,  0.2652,  0.6245],\n",
            "        [ 0.5677,  0.9963,  0.6478,  ...,  0.7623, -0.8079, -0.1168],\n",
            "        ...,\n",
            "        [ 0.6705,  0.9887,  0.7450,  ...,  0.8821, -0.8502, -0.3566],\n",
            "        [ 0.6785,  0.9976, -0.2001,  ...,  0.2878, -0.5548, -0.6418],\n",
            "        [ 0.5891,  1.0000,  0.8747,  ...,  0.5052, -0.4287, -0.6177]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1696,  0.9987, -0.8603,  ..., -0.9320,  0.5765, -0.6073],\n",
            "        [ 0.4588,  0.8609,  0.8003,  ...,  0.8852, -0.8965, -0.1702],\n",
            "        [ 0.5143,  0.9990,  0.7198,  ...,  0.5875, -0.7492, -0.2430],\n",
            "        ...,\n",
            "        [-0.4486,  1.0000, -0.4990,  ..., -0.8831,  0.7567, -0.5737],\n",
            "        [-0.2432,  0.9978, -0.5342,  ..., -0.5214,  0.4936,  0.1037],\n",
            "        [ 0.6099,  0.9973,  0.8534,  ...,  0.8872, -0.8521, -0.3552]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2094,  0.9995, -0.7758,  ..., -0.8072,  0.4128, -0.5068],\n",
            "        [ 0.0327,  1.0000,  0.4060,  ..., -0.7778,  0.0462, -0.7141],\n",
            "        [-0.7134,  0.9985, -0.3804,  ..., -0.8037,  0.2955,  0.0632],\n",
            "        ...,\n",
            "        [-0.6921, -0.9355, -0.9427,  ..., -0.9132,  0.2240,  0.6744],\n",
            "        [ 0.4857,  0.9995,  0.8913,  ...,  0.8253, -0.7444, -0.3217],\n",
            "        [ 0.5250,  0.9999,  0.4121,  ...,  0.4299, -0.3904, -0.7184]],\n",
            "       device='cuda:0')\n",
            "(250,) (250, 2)\n"
          ]
        }
      ],
      "source": [
        "test_comments = test['comment'].to_numpy()\n",
        "preds, probs = predict(pt_model, test_comments, tokenizer, max_len=128)\n",
        "\n",
        "print(preds.shape, probs.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJ_GfqNck5he"
      },
      "source": [
        "**<font color=red> Evaluate Your Model using f1-score & Precision & Recall</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "ZRL2bgDDpUG0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23da443c-5712-4043-c04f-7c741892deb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1: 0.7358478483606556\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.71      0.73       125\n",
            "           1       0.73      0.76      0.74       125\n",
            "\n",
            "    accuracy                           0.74       250\n",
            "   macro avg       0.74      0.74      0.74       250\n",
            "weighted avg       0.74      0.74      0.74       250\n",
            "\n"
          ]
        }
      ],
      "source": [
        "##############################################################################################\n",
        "#                                       Your Code                                            #\n",
        "##############################################################################################\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_test, y_pred = [label_list.index(label) for label in test['label'].values], preds\n",
        "\n",
        "print(f'F1: {f1_score(y_test, y_pred, average=\"weighted\")}')\n",
        "print()\n",
        "print(classification_report(y_test, y_pred, target_names=label_list))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Obt_Bt3vUqyc"
      },
      "execution_count": 37,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "assignment3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "499f74de07764d43a4164df19b1a0ccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f125474f707f48a589eb3d21da4a95f2",
              "IPY_MODEL_43eff8ce43dd4056b7898a22179aa812",
              "IPY_MODEL_e6bc9ed89a274f88bdbf192d3e2eaddb"
            ],
            "layout": "IPY_MODEL_04e5a3fce56b4ca09f3e2b3af8067623"
          }
        },
        "f125474f707f48a589eb3d21da4a95f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a5bb13585944ef69718c9f3b7fad322",
            "placeholder": "​",
            "style": "IPY_MODEL_c942290c8bd14ec6b8644a83504b2aa2",
            "value": "Downloading: 100%"
          }
        },
        "43eff8ce43dd4056b7898a22179aa812": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12a3210bbb864414ae7cb9d3361351e3",
            "max": 1198122,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_42cc91115efa47e6bf6121e1e1550731",
            "value": 1198122
          }
        },
        "e6bc9ed89a274f88bdbf192d3e2eaddb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a4d0d26defe40f5b06ee4f901289647",
            "placeholder": "​",
            "style": "IPY_MODEL_bd891371cd304c81a62be55c2f388a6c",
            "value": " 1.14M/1.14M [00:00&lt;00:00, 4.07MB/s]"
          }
        },
        "04e5a3fce56b4ca09f3e2b3af8067623": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a5bb13585944ef69718c9f3b7fad322": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c942290c8bd14ec6b8644a83504b2aa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12a3210bbb864414ae7cb9d3361351e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42cc91115efa47e6bf6121e1e1550731": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a4d0d26defe40f5b06ee4f901289647": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd891371cd304c81a62be55c2f388a6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ff4ae5966814bc89dc823fdda0f7ce6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d8080f487384783a2aec63391331610",
              "IPY_MODEL_09f8f12214bb4675800dbfee6cd2038c",
              "IPY_MODEL_33ec7bccf44d40e195b90861f561bd4b"
            ],
            "layout": "IPY_MODEL_b6da6ffdece54ea69fff9929fdf467ad"
          }
        },
        "1d8080f487384783a2aec63391331610": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf2995046fad4709ac48cbcc42d1c394",
            "placeholder": "​",
            "style": "IPY_MODEL_7d87c212aa1c48c3b666af39e794547c",
            "value": "Downloading: 100%"
          }
        },
        "09f8f12214bb4675800dbfee6cd2038c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2939d19010ba4caeb56e973373bfc80f",
            "max": 440,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a61c30e0a3a64185939b9fa537355712",
            "value": 440
          }
        },
        "33ec7bccf44d40e195b90861f561bd4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36bc92e1736a48faa3174c5ba6994c10",
            "placeholder": "​",
            "style": "IPY_MODEL_a44e0a294e7648fa995c326f66950342",
            "value": " 440/440 [00:00&lt;00:00, 5.16kB/s]"
          }
        },
        "b6da6ffdece54ea69fff9929fdf467ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf2995046fad4709ac48cbcc42d1c394": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d87c212aa1c48c3b666af39e794547c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2939d19010ba4caeb56e973373bfc80f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a61c30e0a3a64185939b9fa537355712": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "36bc92e1736a48faa3174c5ba6994c10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a44e0a294e7648fa995c326f66950342": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b37ce85d0ba4f74a75d65deb066614a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_999dd428264d447093b79a430cf006a9",
              "IPY_MODEL_fa84b3deee9a449499955067e565cf48",
              "IPY_MODEL_376d97cf555949e2847ba49c741aff5d"
            ],
            "layout": "IPY_MODEL_1ee8ce0c6edd402f8b0d4a96fe8466e9"
          }
        },
        "999dd428264d447093b79a430cf006a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d894ebbcafd14e2a957365a250eb6a54",
            "placeholder": "​",
            "style": "IPY_MODEL_73f690b312e142a9ba59fff9adefc5b7",
            "value": "Downloading: 100%"
          }
        },
        "fa84b3deee9a449499955067e565cf48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1258cddfc7244ad8b472519a1518ed5c",
            "max": 654226731,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_09839934638340d09ffaa0e1876b7656",
            "value": 654226731
          }
        },
        "376d97cf555949e2847ba49c741aff5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67b127d30cc843bf9274617c948e3d3f",
            "placeholder": "​",
            "style": "IPY_MODEL_ad4641dc3143436cbdd6f64bfe65626a",
            "value": " 624M/624M [00:11&lt;00:00, 59.3MB/s]"
          }
        },
        "1ee8ce0c6edd402f8b0d4a96fe8466e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d894ebbcafd14e2a957365a250eb6a54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73f690b312e142a9ba59fff9adefc5b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1258cddfc7244ad8b472519a1518ed5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09839934638340d09ffaa0e1876b7656": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "67b127d30cc843bf9274617c948e3d3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad4641dc3143436cbdd6f64bfe65626a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "849a0c5397714e728f4a0feb8abcaf18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a47c8af7a843479c8abd62902ab6ff1f",
              "IPY_MODEL_9ba1f0d92cfb4520aebd5c2fb02c575d",
              "IPY_MODEL_162d8d89f37e48b9ad775a6e88e66cca"
            ],
            "layout": "IPY_MODEL_a456d87324ed4acd9f5c70f27719fa88"
          }
        },
        "a47c8af7a843479c8abd62902ab6ff1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1c14ec7f1f74963a3d766611d3a615d",
            "placeholder": "​",
            "style": "IPY_MODEL_a130a78d20434c2898297db8835ae3f0",
            "value": "Epochs... : 100%"
          }
        },
        "9ba1f0d92cfb4520aebd5c2fb02c575d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74e68e302692433eb0f3735b78adfeb4",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed05b03884a942ccb7800218093cce49",
            "value": 10
          }
        },
        "162d8d89f37e48b9ad775a6e88e66cca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b9c9c3bb07a4ca692149936f3c688ea",
            "placeholder": "​",
            "style": "IPY_MODEL_51b0ffdbd4484d6db43405b57b042c50",
            "value": " 10/10 [08:53&lt;00:00, 53.76s/it]"
          }
        },
        "a456d87324ed4acd9f5c70f27719fa88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1c14ec7f1f74963a3d766611d3a615d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a130a78d20434c2898297db8835ae3f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74e68e302692433eb0f3735b78adfeb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed05b03884a942ccb7800218093cce49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b9c9c3bb07a4ca692149936f3c688ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51b0ffdbd4484d6db43405b57b042c50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5c90b77d0b442f380d7c3d183a5300c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c2926082540d4dfc90cf557cf6db1144",
              "IPY_MODEL_109267bf737e431884382b7d31fd7852",
              "IPY_MODEL_8601eb8ad82545abaf747999a1a8f657"
            ],
            "layout": "IPY_MODEL_ba841ab64e6f4c66ac56ea5a715a679d"
          }
        },
        "c2926082540d4dfc90cf557cf6db1144": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff2338148b274857bc23c13145e0c906",
            "placeholder": "​",
            "style": "IPY_MODEL_9a8013942fe24daf9b0e4df1f1f33981",
            "value": "Training... : 100%"
          }
        },
        "109267bf737e431884382b7d31fd7852": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1ca07b00b0446e2a553925a7950fe32",
            "max": 127,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf09c769b2254724a902808b07eed392",
            "value": 127
          }
        },
        "8601eb8ad82545abaf747999a1a8f657": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32ac88fd5ad942b19740d67d74915362",
            "placeholder": "​",
            "style": "IPY_MODEL_2aadadb679b64dc7b951a63de7e0466f",
            "value": " 127/127 [00:49&lt;00:00,  3.08it/s]"
          }
        },
        "ba841ab64e6f4c66ac56ea5a715a679d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff2338148b274857bc23c13145e0c906": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a8013942fe24daf9b0e4df1f1f33981": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1ca07b00b0446e2a553925a7950fe32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf09c769b2254724a902808b07eed392": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "32ac88fd5ad942b19740d67d74915362": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2aadadb679b64dc7b951a63de7e0466f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f4f054c4ceb4eb4b22900a1439698fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a99a0c08e9db47d7990e7bcc00d83df6",
              "IPY_MODEL_b53c5194051c4ff981d924ab0a3a8efc",
              "IPY_MODEL_57bb996901ef458e94496afa5f16bbbb"
            ],
            "layout": "IPY_MODEL_0c6081ba8ca6434d858b85fb6efd325a"
          }
        },
        "a99a0c08e9db47d7990e7bcc00d83df6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24a1ca4632b7490097060ed08b08cc99",
            "placeholder": "​",
            "style": "IPY_MODEL_19bf4ef60dce4fbe93dffcb6bdc9a929",
            "value": "Evaluation... : 100%"
          }
        },
        "b53c5194051c4ff981d924ab0a3a8efc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_659f3f0df94d46f6ac775ff04d21f84c",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f7fb1d381cff47ae8eee16df8d1208dd",
            "value": 15
          }
        },
        "57bb996901ef458e94496afa5f16bbbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f207df9a1384cf1ad4b36645946aa6e",
            "placeholder": "​",
            "style": "IPY_MODEL_e96d3c3ed39d4897ad3a9d617a7bbe6a",
            "value": " 15/15 [00:02&lt;00:00,  7.04it/s]"
          }
        },
        "0c6081ba8ca6434d858b85fb6efd325a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24a1ca4632b7490097060ed08b08cc99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19bf4ef60dce4fbe93dffcb6bdc9a929": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "659f3f0df94d46f6ac775ff04d21f84c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7fb1d381cff47ae8eee16df8d1208dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8f207df9a1384cf1ad4b36645946aa6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e96d3c3ed39d4897ad3a9d617a7bbe6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82592d0ddb6f4667848b15d4ddf63edb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_02ce970aebf74b179f170ff8c20b2bc1",
              "IPY_MODEL_a5266057ae3342a0a9b3ac78a4f9c236",
              "IPY_MODEL_c5061ba32c754d82a42c9fffaeef3b1a"
            ],
            "layout": "IPY_MODEL_cc82c3ab83a34da3a89a672757bfb3d2"
          }
        },
        "02ce970aebf74b179f170ff8c20b2bc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edefb16f58bf44bfbd549e9696798074",
            "placeholder": "​",
            "style": "IPY_MODEL_f47e3e38804e4555811860c0293e956a",
            "value": "Training... : 100%"
          }
        },
        "a5266057ae3342a0a9b3ac78a4f9c236": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67840bd1888941f891211ea901ad00f5",
            "max": 127,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06955744027840e8bce23fea9c1c26ff",
            "value": 127
          }
        },
        "c5061ba32c754d82a42c9fffaeef3b1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcbdc9cc99e14477ad7463d13a594a44",
            "placeholder": "​",
            "style": "IPY_MODEL_1a002b68a0fc42e49f86d517175b421b",
            "value": " 127/127 [00:50&lt;00:00,  3.23it/s]"
          }
        },
        "cc82c3ab83a34da3a89a672757bfb3d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edefb16f58bf44bfbd549e9696798074": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f47e3e38804e4555811860c0293e956a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67840bd1888941f891211ea901ad00f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06955744027840e8bce23fea9c1c26ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dcbdc9cc99e14477ad7463d13a594a44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a002b68a0fc42e49f86d517175b421b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "893286436692404194cfef6c856cdc67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eda97d34774b432d9204c3729f7e1d9a",
              "IPY_MODEL_825a285ac309419f97b9a2bcef4f7751",
              "IPY_MODEL_ce3fe39bef414eafab7d1a89280b0c86"
            ],
            "layout": "IPY_MODEL_40ba3eb4005f4f80ab0529d13d2aeb2a"
          }
        },
        "eda97d34774b432d9204c3729f7e1d9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17ac8f3fe5524703be485d2524772a14",
            "placeholder": "​",
            "style": "IPY_MODEL_004e35587f8747acbaa4719545a49d5a",
            "value": "Evaluation... : 100%"
          }
        },
        "825a285ac309419f97b9a2bcef4f7751": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a4e3283bbf2426cb9ae5ea0db7a1f3a",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_adc152c76b2841b185988d26eb7fd58b",
            "value": 15
          }
        },
        "ce3fe39bef414eafab7d1a89280b0c86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8eafef2060da49cbad827c9f1b072f5e",
            "placeholder": "​",
            "style": "IPY_MODEL_6ef7e897435642dda7bc0ad1b71d9e12",
            "value": " 15/15 [00:01&lt;00:00,  7.37it/s]"
          }
        },
        "40ba3eb4005f4f80ab0529d13d2aeb2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17ac8f3fe5524703be485d2524772a14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "004e35587f8747acbaa4719545a49d5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a4e3283bbf2426cb9ae5ea0db7a1f3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adc152c76b2841b185988d26eb7fd58b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8eafef2060da49cbad827c9f1b072f5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ef7e897435642dda7bc0ad1b71d9e12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d4d8827789e41f8be80a443f1a15bdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8fd982099f054498b548e70ba915952d",
              "IPY_MODEL_6442cf2047d14730b6679df5acb66860",
              "IPY_MODEL_a04497d7247b402f926ab46dedec7b45"
            ],
            "layout": "IPY_MODEL_66f6ebb3a25143bcb40bc3ee9fa10c09"
          }
        },
        "8fd982099f054498b548e70ba915952d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_580b60de18404ed3a6cb53bce4f8f710",
            "placeholder": "​",
            "style": "IPY_MODEL_df24d290e37b41a4bb02a774cbd86697",
            "value": "Training... : 100%"
          }
        },
        "6442cf2047d14730b6679df5acb66860": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2a50148d417445e859d6f184af3d560",
            "max": 127,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d54d3d1c36cb4d058d90f29fde59eced",
            "value": 127
          }
        },
        "a04497d7247b402f926ab46dedec7b45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b91117a0c541458cbf5eb53c646f3a8b",
            "placeholder": "​",
            "style": "IPY_MODEL_c7034328b49b4211a0f02a2211cbbda9",
            "value": " 127/127 [00:50&lt;00:00,  3.15it/s]"
          }
        },
        "66f6ebb3a25143bcb40bc3ee9fa10c09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "580b60de18404ed3a6cb53bce4f8f710": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df24d290e37b41a4bb02a774cbd86697": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2a50148d417445e859d6f184af3d560": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d54d3d1c36cb4d058d90f29fde59eced": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b91117a0c541458cbf5eb53c646f3a8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7034328b49b4211a0f02a2211cbbda9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "270a2e26ad054a649f5169562e1326a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2a6b2cd2d54a4bc59a0da8a5bc629eea",
              "IPY_MODEL_bb949fc263ff406cbfe018fcfdd37085",
              "IPY_MODEL_89323f4b0f014299a98393ab07512664"
            ],
            "layout": "IPY_MODEL_b2dc9a16147b4a28a5c90557119f7962"
          }
        },
        "2a6b2cd2d54a4bc59a0da8a5bc629eea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b518b3e487db4191aac7a08f533cec28",
            "placeholder": "​",
            "style": "IPY_MODEL_df334dc9cb7041388b1450d44e0618a2",
            "value": "Evaluation... : 100%"
          }
        },
        "bb949fc263ff406cbfe018fcfdd37085": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f3a1158935745a8a9483afe4726546b",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_905b216e2e584e1cb904ba72aa8a3477",
            "value": 15
          }
        },
        "89323f4b0f014299a98393ab07512664": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de357ed73f024a6a8971b0f3e266f9d0",
            "placeholder": "​",
            "style": "IPY_MODEL_ed863aedc9f94162a64653b76f15450f",
            "value": " 15/15 [00:02&lt;00:00,  7.15it/s]"
          }
        },
        "b2dc9a16147b4a28a5c90557119f7962": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b518b3e487db4191aac7a08f533cec28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df334dc9cb7041388b1450d44e0618a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f3a1158935745a8a9483afe4726546b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "905b216e2e584e1cb904ba72aa8a3477": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de357ed73f024a6a8971b0f3e266f9d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed863aedc9f94162a64653b76f15450f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9210640196204e76b9afb46e09bc612e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c64014fae4041ebbc3220d8f14e19c1",
              "IPY_MODEL_5db0bae4bd0e4b49a6d492cdac896ebe",
              "IPY_MODEL_689889ea9ee744bbade7c64ce451e1b6"
            ],
            "layout": "IPY_MODEL_b350843193504592a810440cddd04c22"
          }
        },
        "7c64014fae4041ebbc3220d8f14e19c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_871ab8105fd247a1ab25eda16976b5b1",
            "placeholder": "​",
            "style": "IPY_MODEL_d4bb601e87d54588b920a1d6ada019af",
            "value": "Training... : 100%"
          }
        },
        "5db0bae4bd0e4b49a6d492cdac896ebe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ed7b6c303824311b481ae3d6b47f252",
            "max": 127,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c786b8ae89a4cfdb949a77339d8048a",
            "value": 127
          }
        },
        "689889ea9ee744bbade7c64ce451e1b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73c8bb0f9b474300b6caf8db7627b3df",
            "placeholder": "​",
            "style": "IPY_MODEL_008fcaf16170441db8d07fcad4f8f039",
            "value": " 127/127 [00:51&lt;00:00,  2.67it/s]"
          }
        },
        "b350843193504592a810440cddd04c22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "871ab8105fd247a1ab25eda16976b5b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4bb601e87d54588b920a1d6ada019af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ed7b6c303824311b481ae3d6b47f252": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c786b8ae89a4cfdb949a77339d8048a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "73c8bb0f9b474300b6caf8db7627b3df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "008fcaf16170441db8d07fcad4f8f039": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0811f59155e945598ab2daf8db337ea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4bde0af3b5f2479f80374035ef7e945e",
              "IPY_MODEL_17d4a00ab6934a35aa628aa059eea6e5",
              "IPY_MODEL_68ece3a48eb84cfba024bdc49760582c"
            ],
            "layout": "IPY_MODEL_7c137e0929d0476585ac3f2af2f3180b"
          }
        },
        "4bde0af3b5f2479f80374035ef7e945e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4c799a68343416cbfbc57be1de6f8a4",
            "placeholder": "​",
            "style": "IPY_MODEL_baee5ef17b8540cb9b67bd7adb737d5c",
            "value": "Evaluation... : 100%"
          }
        },
        "17d4a00ab6934a35aa628aa059eea6e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5a300352c7a44f0bcd173fe4b507862",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f7803fadc58e486a8457d2f238f16f98",
            "value": 15
          }
        },
        "68ece3a48eb84cfba024bdc49760582c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba1f8ed4c2d748ad80233229b45d768e",
            "placeholder": "​",
            "style": "IPY_MODEL_d22725e0be734a57af5fe276c88a4945",
            "value": " 15/15 [00:02&lt;00:00,  7.02it/s]"
          }
        },
        "7c137e0929d0476585ac3f2af2f3180b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4c799a68343416cbfbc57be1de6f8a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baee5ef17b8540cb9b67bd7adb737d5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5a300352c7a44f0bcd173fe4b507862": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7803fadc58e486a8457d2f238f16f98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba1f8ed4c2d748ad80233229b45d768e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d22725e0be734a57af5fe276c88a4945": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9aed995118b443409667bc495b4e25df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_292ef6272db9499696072df7e307ea90",
              "IPY_MODEL_07a0d2af5bff44f486dd2e3621184b67",
              "IPY_MODEL_7a220e989fb64beca2d5abdecbb30c07"
            ],
            "layout": "IPY_MODEL_132edba0bbdd49a686439c5c42668973"
          }
        },
        "292ef6272db9499696072df7e307ea90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9db67726b5054c0fa4bfeb168ad8cebf",
            "placeholder": "​",
            "style": "IPY_MODEL_12477f9b808f44ae807ba8e35921b14f",
            "value": "Training... : 100%"
          }
        },
        "07a0d2af5bff44f486dd2e3621184b67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd6e2f37e195447a9af47be38f9bd3d4",
            "max": 127,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_16727ff7d8f649b59503d5b314cf84e8",
            "value": 127
          }
        },
        "7a220e989fb64beca2d5abdecbb30c07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8ee4f6383eb400197d522480a82c033",
            "placeholder": "​",
            "style": "IPY_MODEL_5d28acfb8458487c986b4c9dc4d511d2",
            "value": " 127/127 [00:50&lt;00:00,  3.15it/s]"
          }
        },
        "132edba0bbdd49a686439c5c42668973": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9db67726b5054c0fa4bfeb168ad8cebf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12477f9b808f44ae807ba8e35921b14f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd6e2f37e195447a9af47be38f9bd3d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16727ff7d8f649b59503d5b314cf84e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a8ee4f6383eb400197d522480a82c033": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d28acfb8458487c986b4c9dc4d511d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02f80e5f64814c3082ae935a9072716c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e693d92fe71742d09397264c4d99001b",
              "IPY_MODEL_b8ec11b81aaa4247b30d6250a83ccc94",
              "IPY_MODEL_d2d03889b7aa46888abdac0edc526ad4"
            ],
            "layout": "IPY_MODEL_596bd130a9cf4693b6977d7bc4839af6"
          }
        },
        "e693d92fe71742d09397264c4d99001b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96c5531de4764a05873f69da3847b853",
            "placeholder": "​",
            "style": "IPY_MODEL_1c137234cdea4bd5a34b2cff9c5e1f47",
            "value": "Evaluation... : 100%"
          }
        },
        "b8ec11b81aaa4247b30d6250a83ccc94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_748c02a6382743e88f79ddea63b34c16",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_17494a17b06547ddaa03d72ef8782044",
            "value": 15
          }
        },
        "d2d03889b7aa46888abdac0edc526ad4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_270f3ad8f39e4c1583546cbedd4644f1",
            "placeholder": "​",
            "style": "IPY_MODEL_d887b730ae944f3bbaf310183d2bc40b",
            "value": " 15/15 [00:02&lt;00:00,  7.04it/s]"
          }
        },
        "596bd130a9cf4693b6977d7bc4839af6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96c5531de4764a05873f69da3847b853": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c137234cdea4bd5a34b2cff9c5e1f47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "748c02a6382743e88f79ddea63b34c16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17494a17b06547ddaa03d72ef8782044": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "270f3ad8f39e4c1583546cbedd4644f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d887b730ae944f3bbaf310183d2bc40b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86e0e04f92c34c38b98de2716e28e376": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1450abf5cd1549709badb72b0bac9728",
              "IPY_MODEL_e2946ebcb3244438a391aba94cb44e21",
              "IPY_MODEL_0adbf2ac679e45a0bda05b679d0e830c"
            ],
            "layout": "IPY_MODEL_177cee6c3eda4b4eab4a2529cfdc7b7c"
          }
        },
        "1450abf5cd1549709badb72b0bac9728": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ff4520a721445cfaf5cc20fe279468d",
            "placeholder": "​",
            "style": "IPY_MODEL_19bb820d169a4de1936e49e7f08df1a1",
            "value": "Training... : 100%"
          }
        },
        "e2946ebcb3244438a391aba94cb44e21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79637fbcc5444cfd825373e0ee4780d5",
            "max": 127,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c9a8966752c94e1e909f77aa4425aeef",
            "value": 127
          }
        },
        "0adbf2ac679e45a0bda05b679d0e830c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cc5c9813d80411fa37dff15005ecb6d",
            "placeholder": "​",
            "style": "IPY_MODEL_a4c9df2b59f445cf8a4e5809c2b3a431",
            "value": " 127/127 [00:50&lt;00:00,  3.12it/s]"
          }
        },
        "177cee6c3eda4b4eab4a2529cfdc7b7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ff4520a721445cfaf5cc20fe279468d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19bb820d169a4de1936e49e7f08df1a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79637fbcc5444cfd825373e0ee4780d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9a8966752c94e1e909f77aa4425aeef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5cc5c9813d80411fa37dff15005ecb6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4c9df2b59f445cf8a4e5809c2b3a431": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7f309d5689f49c39dbc1e9cd8f6d6a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bc12ea29b25646ef8a580244d08bddee",
              "IPY_MODEL_70c8ae9dd3064c2098f0e60f8777f147",
              "IPY_MODEL_ce3460e415dc4e64ab47124646438448"
            ],
            "layout": "IPY_MODEL_f93eae4aed3b4761b65ad6e82512b5cf"
          }
        },
        "bc12ea29b25646ef8a580244d08bddee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bd127bfc7f04f0a8f5f22eaed5eb1fe",
            "placeholder": "​",
            "style": "IPY_MODEL_b420d0c66c1b492a85b11cc48c655dcb",
            "value": "Evaluation... : 100%"
          }
        },
        "70c8ae9dd3064c2098f0e60f8777f147": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47504834cd7f40fa95815e7db77c595a",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_62d34ee221184081ba83758c7cf83168",
            "value": 15
          }
        },
        "ce3460e415dc4e64ab47124646438448": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90a14ef808df4a6980416bdc0a061137",
            "placeholder": "​",
            "style": "IPY_MODEL_efd6d60eb98b47d2a81a0599a316035d",
            "value": " 15/15 [00:02&lt;00:00,  6.95it/s]"
          }
        },
        "f93eae4aed3b4761b65ad6e82512b5cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bd127bfc7f04f0a8f5f22eaed5eb1fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b420d0c66c1b492a85b11cc48c655dcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47504834cd7f40fa95815e7db77c595a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62d34ee221184081ba83758c7cf83168": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "90a14ef808df4a6980416bdc0a061137": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efd6d60eb98b47d2a81a0599a316035d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb70fdbcdc9d4d36a8aa15a5047d5374": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_097eb548449d407480c1d6a2bee7b729",
              "IPY_MODEL_da0faebd99384bb19ac94167f625a43b",
              "IPY_MODEL_5a3dc56a790a4768a1d4e106a1f7c230"
            ],
            "layout": "IPY_MODEL_ccd0898d21c147dca8b93213f288ecbb"
          }
        },
        "097eb548449d407480c1d6a2bee7b729": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b80fa8fa8b264cd09b72597bf9d40963",
            "placeholder": "​",
            "style": "IPY_MODEL_657ca5ecd14d4b8c984c8ac1d628e827",
            "value": "Training... : 100%"
          }
        },
        "da0faebd99384bb19ac94167f625a43b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cea64c8c4b2f44919e653bb78d637478",
            "max": 127,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39ae8603d3a6414a987a669bf1e71d5d",
            "value": 127
          }
        },
        "5a3dc56a790a4768a1d4e106a1f7c230": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a07341aa17841a7884cc2f77a229c73",
            "placeholder": "​",
            "style": "IPY_MODEL_7fc9045d679d4187b005ba5e9f47c564",
            "value": " 127/127 [00:51&lt;00:00,  3.11it/s]"
          }
        },
        "ccd0898d21c147dca8b93213f288ecbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b80fa8fa8b264cd09b72597bf9d40963": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "657ca5ecd14d4b8c984c8ac1d628e827": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cea64c8c4b2f44919e653bb78d637478": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39ae8603d3a6414a987a669bf1e71d5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a07341aa17841a7884cc2f77a229c73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fc9045d679d4187b005ba5e9f47c564": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1b622bcbf364de69c9096d57f84dda8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e06275da28e04b73a5b2a4d65f6ced24",
              "IPY_MODEL_8eb45b00a6634c69ae88d3d5cf727ecf",
              "IPY_MODEL_8a47a54439c64ef5bf8a1b32265ffde5"
            ],
            "layout": "IPY_MODEL_670f02ea804446d984e0b1b060104cf2"
          }
        },
        "e06275da28e04b73a5b2a4d65f6ced24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24cf6bdc462d43ed8cd930fec703c5ad",
            "placeholder": "​",
            "style": "IPY_MODEL_23f5f89e1db0434e95c4e41643e5117c",
            "value": "Evaluation... : 100%"
          }
        },
        "8eb45b00a6634c69ae88d3d5cf727ecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_084d2597c7524dc786dfb87b858c4b82",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bcb1bb491e40493380fd038a9ef77401",
            "value": 15
          }
        },
        "8a47a54439c64ef5bf8a1b32265ffde5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a82aae66f2b4303a8a7405cbc96bdf5",
            "placeholder": "​",
            "style": "IPY_MODEL_2ef6fdeeb916463b930433fda0f70ccc",
            "value": " 15/15 [00:02&lt;00:00,  7.07it/s]"
          }
        },
        "670f02ea804446d984e0b1b060104cf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24cf6bdc462d43ed8cd930fec703c5ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23f5f89e1db0434e95c4e41643e5117c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "084d2597c7524dc786dfb87b858c4b82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcb1bb491e40493380fd038a9ef77401": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a82aae66f2b4303a8a7405cbc96bdf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ef6fdeeb916463b930433fda0f70ccc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b701b766409f420f9e4ac66415582b78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_046f059594864439b2178641641e51e5",
              "IPY_MODEL_0e605e2232bd4dd9b97367e2da30e923",
              "IPY_MODEL_02631f3903bf4ece8764b84baf7ce838"
            ],
            "layout": "IPY_MODEL_44cad2dff63543c88ee1d8e6ee8f4073"
          }
        },
        "046f059594864439b2178641641e51e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d95c58e9fd84a7c8c0bdbf91e5784b8",
            "placeholder": "​",
            "style": "IPY_MODEL_ac77bddf75d44950b932c408535dc2a6",
            "value": "Training... : 100%"
          }
        },
        "0e605e2232bd4dd9b97367e2da30e923": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28b51df6499d4bde8cecaa88d223c980",
            "max": 127,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc33e0ded05d42978be7facb9a67d482",
            "value": 127
          }
        },
        "02631f3903bf4ece8764b84baf7ce838": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_907a5e1e362c4731857e10ee22b52c35",
            "placeholder": "​",
            "style": "IPY_MODEL_cd1d10c42bb9446191e247c271fc9c17",
            "value": " 127/127 [00:55&lt;00:00,  3.09it/s]"
          }
        },
        "44cad2dff63543c88ee1d8e6ee8f4073": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d95c58e9fd84a7c8c0bdbf91e5784b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac77bddf75d44950b932c408535dc2a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28b51df6499d4bde8cecaa88d223c980": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc33e0ded05d42978be7facb9a67d482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "907a5e1e362c4731857e10ee22b52c35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd1d10c42bb9446191e247c271fc9c17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f267748ea5d4da1917de0ceb1af462f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_82f505c824364c7c997c5bc5cf174183",
              "IPY_MODEL_9c0363e2117245c9a22fb4de2f35e6db",
              "IPY_MODEL_2616c8c2e7b24d6abe73144f07575842"
            ],
            "layout": "IPY_MODEL_ac6c266425a24051a80c1a6a112a83da"
          }
        },
        "82f505c824364c7c997c5bc5cf174183": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e4b9c15d1dc44cf9290527e69983ae5",
            "placeholder": "​",
            "style": "IPY_MODEL_e3f46ed90b4942759a68a499c18b6b97",
            "value": "Evaluation... : 100%"
          }
        },
        "9c0363e2117245c9a22fb4de2f35e6db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb12f34dca574a1da206cf71d055785e",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e72082b305dc4ad7a794fb439cbd7fcd",
            "value": 15
          }
        },
        "2616c8c2e7b24d6abe73144f07575842": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e95fb3fd5c04c4f975be892a81b238f",
            "placeholder": "​",
            "style": "IPY_MODEL_f6a07473f1e8475a8fae818c29f4ba08",
            "value": " 15/15 [00:02&lt;00:00,  7.12it/s]"
          }
        },
        "ac6c266425a24051a80c1a6a112a83da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e4b9c15d1dc44cf9290527e69983ae5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3f46ed90b4942759a68a499c18b6b97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb12f34dca574a1da206cf71d055785e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e72082b305dc4ad7a794fb439cbd7fcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e95fb3fd5c04c4f975be892a81b238f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6a07473f1e8475a8fae818c29f4ba08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33403fd8abae4e149f34929ea89b70b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a202287e0714bc49148cbf81739bb6f",
              "IPY_MODEL_f08f3bc8fc234b809b02978b477f54cd",
              "IPY_MODEL_091f3c7c1ce7486aacdef75f3c414725"
            ],
            "layout": "IPY_MODEL_71ed124f595d482eb95d9ee172a29e39"
          }
        },
        "5a202287e0714bc49148cbf81739bb6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d41d51bf67c46ffb50b443821473a1b",
            "placeholder": "​",
            "style": "IPY_MODEL_e30d4bd707234b8b8ca501989e358b16",
            "value": "Evaluation... : 100%"
          }
        },
        "f08f3bc8fc234b809b02978b477f54cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d95a46f733264b428619021b72614002",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_74b60563e7c742f7adb8487a409cb6d3",
            "value": 15
          }
        },
        "091f3c7c1ce7486aacdef75f3c414725": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b2835053b7842cfa5e2dca6a8bf9726",
            "placeholder": "​",
            "style": "IPY_MODEL_0bb9ff8bf78b4c89b371bf45ebf83753",
            "value": " 15/15 [00:02&lt;00:00,  7.00it/s]"
          }
        },
        "71ed124f595d482eb95d9ee172a29e39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d41d51bf67c46ffb50b443821473a1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e30d4bd707234b8b8ca501989e358b16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d95a46f733264b428619021b72614002": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74b60563e7c742f7adb8487a409cb6d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b2835053b7842cfa5e2dca6a8bf9726": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bb9ff8bf78b4c89b371bf45ebf83753": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "967af0dfa87e4eac911e6f0ab7415312": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f9dbc51c012f4708bfc4ba68621e2505",
              "IPY_MODEL_b95e26d3560f433db8c77db9e1d27616",
              "IPY_MODEL_40d5010dbed2473dbe7e0429b41b5461"
            ],
            "layout": "IPY_MODEL_029183ecdc644903996e50d665ce198f"
          }
        },
        "f9dbc51c012f4708bfc4ba68621e2505": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ad6d9c69a0b46e6b8e5876df0b26f81",
            "placeholder": "​",
            "style": "IPY_MODEL_aa16ace50b74488d9559b0dba579ca4a",
            "value": "Training... : 100%"
          }
        },
        "b95e26d3560f433db8c77db9e1d27616": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96a851951e7c4e6e96dc9e10f99b6f22",
            "max": 127,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6ceb86f21f864739a0fa111259e41b7e",
            "value": 127
          }
        },
        "40d5010dbed2473dbe7e0429b41b5461": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e6b0bd439894917b0d56c4b61733766",
            "placeholder": "​",
            "style": "IPY_MODEL_5baf55b049bb4725aaced06f75e30136",
            "value": " 127/127 [00:50&lt;00:00,  3.09it/s]"
          }
        },
        "029183ecdc644903996e50d665ce198f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ad6d9c69a0b46e6b8e5876df0b26f81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa16ace50b74488d9559b0dba579ca4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96a851951e7c4e6e96dc9e10f99b6f22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ceb86f21f864739a0fa111259e41b7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7e6b0bd439894917b0d56c4b61733766": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5baf55b049bb4725aaced06f75e30136": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "699381678de5446392cd7d2b13d3c83e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5b18a0216274ec3a8df4273d47d732f",
              "IPY_MODEL_7f6f7e2499b84b8ca5456e2827a3e807",
              "IPY_MODEL_af2bdf284b4c4a8aa950f64867445823"
            ],
            "layout": "IPY_MODEL_b9a37eaa91984bb9ad78cda52cab0557"
          }
        },
        "c5b18a0216274ec3a8df4273d47d732f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b136c6ff6204661a50531262017e0e4",
            "placeholder": "​",
            "style": "IPY_MODEL_fef5fee962c64e358ec02dc84ad9e690",
            "value": "Evaluation... : 100%"
          }
        },
        "7f6f7e2499b84b8ca5456e2827a3e807": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f5d9efbf78a495d8fd20a879bf344c5",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fb777dbe75334091a0477971da471c04",
            "value": 15
          }
        },
        "af2bdf284b4c4a8aa950f64867445823": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19ac036ed63643509d0c2f337468860d",
            "placeholder": "​",
            "style": "IPY_MODEL_9b471f92f09f4ee69b900ee0ba59170f",
            "value": " 15/15 [00:02&lt;00:00,  6.48it/s]"
          }
        },
        "b9a37eaa91984bb9ad78cda52cab0557": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b136c6ff6204661a50531262017e0e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fef5fee962c64e358ec02dc84ad9e690": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f5d9efbf78a495d8fd20a879bf344c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb777dbe75334091a0477971da471c04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "19ac036ed63643509d0c2f337468860d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b471f92f09f4ee69b900ee0ba59170f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3243dfd90014c449a91e5e3826c00a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_555bcd7ed31f4aa7951e6f6c4d987a30",
              "IPY_MODEL_3e90e7ec33c34861837d8be88aebadd1",
              "IPY_MODEL_6981b6c5ecee4c5fbae1bafe68d6ae45"
            ],
            "layout": "IPY_MODEL_dbf683a521624767830719b3b9422220"
          }
        },
        "555bcd7ed31f4aa7951e6f6c4d987a30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86edd78334fb44e69dd9028957d6b856",
            "placeholder": "​",
            "style": "IPY_MODEL_5a9f098974fb494da092cc4e99e7fd63",
            "value": "Training... : 100%"
          }
        },
        "3e90e7ec33c34861837d8be88aebadd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bbdd0af72984ed285a3250ed217f558",
            "max": 127,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1f76220efd04b2c81bd385b404c0752",
            "value": 127
          }
        },
        "6981b6c5ecee4c5fbae1bafe68d6ae45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e88156e2b0e460a84448b21a691e65a",
            "placeholder": "​",
            "style": "IPY_MODEL_17d796277d014aca97f7b5ffcddbc01b",
            "value": " 127/127 [00:50&lt;00:00,  3.12it/s]"
          }
        },
        "dbf683a521624767830719b3b9422220": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86edd78334fb44e69dd9028957d6b856": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a9f098974fb494da092cc4e99e7fd63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0bbdd0af72984ed285a3250ed217f558": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1f76220efd04b2c81bd385b404c0752": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8e88156e2b0e460a84448b21a691e65a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17d796277d014aca97f7b5ffcddbc01b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aeebdb00c47c4e588897f4853757d9e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7bbe10ca6ad44295bcc215443725d29d",
              "IPY_MODEL_320f2ab606874d3782b9e247049ec017",
              "IPY_MODEL_dbe505d579f34f5f8cc1b1b6fb35562e"
            ],
            "layout": "IPY_MODEL_c84ed20948244c48b74bba18edd4a7f4"
          }
        },
        "7bbe10ca6ad44295bcc215443725d29d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b21338a7b4544cd3a01e2ab686fc5ee4",
            "placeholder": "​",
            "style": "IPY_MODEL_b852f703a61845efbe2df771a49eca88",
            "value": "Evaluation... : 100%"
          }
        },
        "320f2ab606874d3782b9e247049ec017": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7598a304ccb94c42b623936c8f28769b",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2acd1337f8904501afda98640be3ffc5",
            "value": 15
          }
        },
        "dbe505d579f34f5f8cc1b1b6fb35562e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29d3f41ab12544efb7088dff79d3a732",
            "placeholder": "​",
            "style": "IPY_MODEL_1210392c1a894b1ea96e22ab6339926a",
            "value": " 15/15 [00:02&lt;00:00,  7.11it/s]"
          }
        },
        "c84ed20948244c48b74bba18edd4a7f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b21338a7b4544cd3a01e2ab686fc5ee4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b852f703a61845efbe2df771a49eca88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7598a304ccb94c42b623936c8f28769b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2acd1337f8904501afda98640be3ffc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "29d3f41ab12544efb7088dff79d3a732": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1210392c1a894b1ea96e22ab6339926a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9214e44a5aa4fb5ac252acb463925f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_72b3e66d4c8b4421b4ee464af1f7d1f9",
              "IPY_MODEL_e6e21363e9a444a6ab31fdd94a8922e5",
              "IPY_MODEL_3da2a692295c4c4b95d604aaae8ad0b7"
            ],
            "layout": "IPY_MODEL_e5743cd6e7e04deab6c06e228cd12553"
          }
        },
        "72b3e66d4c8b4421b4ee464af1f7d1f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b0fb2d13901413eac9efffecfd5b35e",
            "placeholder": "​",
            "style": "IPY_MODEL_47d78132d74a4361be7784661e75ffae",
            "value": "100%"
          }
        },
        "e6e21363e9a444a6ab31fdd94a8922e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b8304c29b2a457fb2fa9ac164e88d1e",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4da9adc5d47d4be8976fc76faf06f53f",
            "value": 8
          }
        },
        "3da2a692295c4c4b95d604aaae8ad0b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b02b589e30d416e941abf0cf4642e58",
            "placeholder": "​",
            "style": "IPY_MODEL_e9c919e53a984340a6cf47a594d64eeb",
            "value": " 8/8 [00:02&lt;00:00,  3.75it/s]"
          }
        },
        "e5743cd6e7e04deab6c06e228cd12553": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b0fb2d13901413eac9efffecfd5b35e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47d78132d74a4361be7784661e75ffae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b8304c29b2a457fb2fa9ac164e88d1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4da9adc5d47d4be8976fc76faf06f53f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9b02b589e30d416e941abf0cf4642e58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9c919e53a984340a6cf47a594d64eeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}