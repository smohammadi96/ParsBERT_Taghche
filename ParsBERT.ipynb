{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atct38o_s3ZB"
      },
      "source": [
        "# Sentiment Analysis with ParsBERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9Nvlm0tAwGc"
      },
      "source": [
        "## The NVIDIA System Management Interface (nvidia-smi) is a command line utility, based on top of the NVIDIA Management Library (NVML), intended to aid in the management and monitoring of NVIDIA GPU devices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9HbUK_disBly",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75afd754-35ec-4cce-fe11-e5f588b8d70a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jun 14 18:30:41 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   69C    P8    12W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZ7ugLdoA9-7"
      },
      "source": [
        "## Install & import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iB2TDd3asGTx"
      },
      "outputs": [],
      "source": [
        "# Import required packages (If You Need Any More Packages, You Can Add them HERE.)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import os\n",
        "import re\n",
        "import collections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnGajnQGQIIX"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8Au1yJ8bMzj",
        "outputId": "4f5dc7ee-0f64-4564-c324-89697fcd0cc0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data1 = pd.read_csv('/content/drive/MyDrive/project-3/taghche_5000.csv', encoding='utf-8')\n",
        "data1.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FmbHKTl0u0vE",
        "outputId": "9189ac67-c6b2-4ee2-e030-79ced5e4700f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         date                                            comment  \\\n",
              "0  1395/11/14  ุงุณู ฺฉุชุงุจ   No one writes to the Colonel\\nุชุฑุฌูุด...   \n",
              "1  1395/11/14  ุทุงูฺู ุนุฒุฒุูุงู ฺฉุชุงุจ\"ฺฉุณ ุจู ุณุฑููฺฏ ูุงูู ููููุณุฏ...   \n",
              "2  1394/06/06  ุจูุธุฑู ุงู ุงุซุฑ ูุงุฑฺฉุฒ ุฎู ุงุฒ ุตุฏ ุณุงู ุชููุง ฺฉู ุจ...   \n",
              "3  1393/09/02  ุจู ูุธุฑ ฺฉุชุงุจ ุฎูุจ ูููุฏ ุงูุง ูู ุงุฒ ุชุฑุฌูุด ุฎูุดู ู...   \n",
              "4  1393/06/29                                      ฺฉุชุงุจ ุฎูุจ ุงุณุช   \n",
              "\n",
              "                            bookname  rate  bookID  like  \n",
              "0  ุณุฑููฺฏ ฺฉุณ ูุฏุงุฑุฏ ุจุฑุงุด ูุงูู ุจููุณุฏ     0       3     2  \n",
              "1  ุณุฑููฺฏ ฺฉุณ ูุฏุงุฑุฏ ุจุฑุงุด ูุงูู ุจููุณุฏ     5       3     2  \n",
              "2  ุณุฑููฺฏ ฺฉุณ ูุฏุงุฑุฏ ุจุฑุงุด ูุงูู ุจููุณุฏ     5       3     0  \n",
              "3  ุณุฑููฺฏ ฺฉุณ ูุฏุงุฑุฏ ุจุฑุงุด ูุงูู ุจููุณุฏ     2       3     0  \n",
              "4  ุณุฑููฺฏ ฺฉุณ ูุฏุงุฑุฏ ุจุฑุงุด ูุงูู ุจููุณุฏ     3       3     0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fc26447d-a896-4e35-b4ad-a789db91f29c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>comment</th>\n",
              "      <th>bookname</th>\n",
              "      <th>rate</th>\n",
              "      <th>bookID</th>\n",
              "      <th>like</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1395/11/14</td>\n",
              "      <td>ุงุณู ฺฉุชุงุจ   No one writes to the Colonel\\nุชุฑุฌูุด...</td>\n",
              "      <td>ุณุฑููฺฏ ฺฉุณ ูุฏุงุฑุฏ ุจุฑุงุด ูุงูู ุจููุณุฏ</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1395/11/14</td>\n",
              "      <td>ุทุงูฺู ุนุฒุฒุูุงู ฺฉุชุงุจ\"ฺฉุณ ุจู ุณุฑููฺฏ ูุงูู ููููุณุฏ...</td>\n",
              "      <td>ุณุฑููฺฏ ฺฉุณ ูุฏุงุฑุฏ ุจุฑุงุด ูุงูู ุจููุณุฏ</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1394/06/06</td>\n",
              "      <td>ุจูุธุฑู ุงู ุงุซุฑ ูุงุฑฺฉุฒ ุฎู ุงุฒ ุตุฏ ุณุงู ุชููุง ฺฉู ุจ...</td>\n",
              "      <td>ุณุฑููฺฏ ฺฉุณ ูุฏุงุฑุฏ ุจุฑุงุด ูุงูู ุจููุณุฏ</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1393/09/02</td>\n",
              "      <td>ุจู ูุธุฑ ฺฉุชุงุจ ุฎูุจ ูููุฏ ุงูุง ูู ุงุฒ ุชุฑุฌูุด ุฎูุดู ู...</td>\n",
              "      <td>ุณุฑููฺฏ ฺฉุณ ูุฏุงุฑุฏ ุจุฑุงุด ูุงูู ุจููุณุฏ</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1393/06/29</td>\n",
              "      <td>ฺฉุชุงุจ ุฎูุจ ุงุณุช</td>\n",
              "      <td>ุณุฑููฺฏ ฺฉุณ ูุฏุงุฑุฏ ุจุฑุงุด ูุงูู ุจููุณุฏ</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc26447d-a896-4e35-b4ad-a789db91f29c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fc26447d-a896-4e35-b4ad-a789db91f29c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fc26447d-a896-4e35-b4ad-a789db91f29c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCTKvthyQlOG"
      },
      "source": [
        "### Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DNx25HZyQI8H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "7b541e63-0974-4198-ca31-eb32162d793a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             comment  rate\n",
              "0  ุงุณู ฺฉุชุงุจ   No one writes to the Colonel\\nุชุฑุฌูุด...     0\n",
              "1  ุทุงูฺู ุนุฒุฒุูุงู ฺฉุชุงุจ\"ฺฉุณ ุจู ุณุฑููฺฏ ูุงูู ููููุณุฏ...     5\n",
              "2  ุจูุธุฑู ุงู ุงุซุฑ ูุงุฑฺฉุฒ ุฎู ุงุฒ ุตุฏ ุณุงู ุชููุง ฺฉู ุจ...     5\n",
              "3  ุจู ูุธุฑ ฺฉุชุงุจ ุฎูุจ ูููุฏ ุงูุง ูู ุงุฒ ุชุฑุฌูุด ุฎูุดู ู...     2\n",
              "4                                      ฺฉุชุงุจ ุฎูุจ ุงุณุช     3"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c4b397c5-58e4-46ee-be1b-0494fce2fb7a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ุงุณู ฺฉุชุงุจ   No one writes to the Colonel\\nุชุฑุฌูุด...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ุทุงูฺู ุนุฒุฒุูุงู ฺฉุชุงุจ\"ฺฉุณ ุจู ุณุฑููฺฏ ูุงูู ููููุณุฏ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ุจูุธุฑู ุงู ุงุซุฑ ูุงุฑฺฉุฒ ุฎู ุงุฒ ุตุฏ ุณุงู ุชููุง ฺฉู ุจ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ุจู ูุธุฑ ฺฉุชุงุจ ุฎูุจ ูููุฏ ุงูุง ูู ุงุฒ ุชุฑุฌูุด ุฎูุดู ู...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ฺฉุชุงุจ ุฎูุจ ุงุณุช</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c4b397c5-58e4-46ee-be1b-0494fce2fb7a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c4b397c5-58e4-46ee-be1b-0494fce2fb7a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c4b397c5-58e4-46ee-be1b-0494fce2fb7a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/project-3/taghche_5000.csv', encoding='utf-8')\n",
        "data = data[['comment', 'rate']]\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YjjHSjyeQvqb"
      },
      "outputs": [],
      "source": [
        "# handle some conflicts with the dataset structure\n",
        "# you can find a reliable solution, for the sake of the simplicity\n",
        "# I just remove these bad combinations!\n",
        "data['rate'] = data['rate'].apply(lambda r: r if r < 6 else None)\n",
        "\n",
        "data = data.dropna(subset=['rate'])\n",
        "data = data.dropna(subset=['comment'])\n",
        "data = data.drop_duplicates(subset=['comment'], keep='first')\n",
        "data = data.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWmMbGFCQ1Rf"
      },
      "source": [
        "### Normalization / Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMn63nr5RCz2"
      },
      "source": [
        "**<font color=red> For simplicity, Transform the rate in a range of 0.0 to 5.0 to a binary form of negative (0) or positive (1) with a threshold. If the rate is less than 3.0, it labeled as negative otherwise specified as positive.</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OlqXeDLwLWx5"
      },
      "outputs": [],
      "source": [
        "##############################################################################################\n",
        "#                                       Your Code                                            #\n",
        "##############################################################################################"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = data[\"comment\"]\n",
        "import re\n",
        "\n",
        "pattern = re.compile('\\S*@\\S*\\s?')\n",
        "cleaning = []\n",
        "# pattern.sub('', s) \n",
        "# print(text) # with emoji\n",
        "def remove_emojis(data):\n",
        "    emoj = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "        u\"\\U0001f926-\\U0001f937\"\n",
        "        u\"\\U00010000-\\U0010ffff\"\n",
        "        u\"\\u2640-\\u2642\" \n",
        "        u\"\\u2600-\\u2B55\"\n",
        "        u\"\\u200d\"\n",
        "        u\"\\u23cf\"\n",
        "        u\"\\u23e9\"\n",
        "        u\"\\u231a\"\n",
        "        u\"\\ufe0f\"  # dingbats\n",
        "        u\"\\u3030\"\n",
        "                      \"]+\", re.UNICODE)\n",
        "    return re.sub(emoj, '', data)\n",
        "\n",
        "for item in text:\n",
        "    # print(item)\n",
        "    ss = remove_emojis(item)\n",
        "    print(item)\n",
        "    # s3 = pattern.sub('', s3) \n",
        "    print(ss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_E115NPJiI40",
        "outputId": "360a1851-47e4-4ca7-feed-5e528b58173f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "ูุงูุนุงู ุงุญุณูุช ุจุฑ ุขูุง ุณุฑุดุงุฑ.. ุนุงู ุจูุฏ.. ุฎุฏุงููุช.\n",
            "ูุงูุนุงู ุงุญุณูุช ุจุฑ ุขูุง ุณุฑุดุงุฑ.. ุนุงู ุจูุฏ.. ุฎุฏุงููุช.\n",
            "ููู ุงูุนุงุฏู ุจูุฏ.\n",
            "ฺฉ ฺฉุชุงุจ ุฎููุฏู...\n",
            "ุจุฑุง ูู ฺฉู ูุซู ฺฉ ููุงู ุขุจ ุฎูฺฉ ุชู ุชุดูฺฏ ุชุงุจุณุชูู ุจูุฏุุุูููููุฏุฑ ฺฏูุงุฑุง...\n",
            "ูู ุฏููู ุจุฑุง ุจูู ูู ุงูุทูุฑ ุจูุฏู ุง ููุูู ุชุตูุฑ ูู ุงุฒ ูพุงูุจุฑ ู ูุฑุฏ ุจุง ูุจุงุณ ุนุฑุจ ฺฉ ุฏุณุช ุณูุฏ ุจูุฏุฺฉ ูุฑุฏ ููุฏุณุุฎู ูุณุจุช ุจูุดูู ุญุณ ูุญุจุช ูุฏุงุดุชูุุจุดุชุฑ ุญุงูุช ุงุญุชุฑุงู ู ุชูุฏุณ...\n",
            "ูู ุจุง ุฎููุฏู ุงู ฺฉุชุงุจ ูพุงูุจุฑ ุจุฑุง ูู ฺฉ ุดุฎุตุช ุงูุณุงู ฺฏููู(ุฌุฏุง ุงุฒ ุงูู ุญุงูุช ุชูุฏุณ ู ูุฑุดุชู ูุงููุฏ) ูพุฏุง ฺฉุฑุฏูุฏุุดุฎุตุช ฺฉู ูุซู ููู ุขุฏูุง ู ุณุฑ ูุงุฒ ูุง ุฏุงุฑูุู ุณุฑ ุฏุบุฏุบู ูุง ุฏุงุฑู...\n",
            "ุญุณ ฺฉู ฺฉุชุงุจ ุงุฒ ูพุงูุจุฑ ู ุฎุงููุงุฏู ู ุงุทุฑุงูุงูุดูู ุงุฌุงุฏ ฺฉุฑุฏ ุจู ูฺ ูุฌู ุจุง ููู ยซูุญูุฏ ุฑุณูู ุงููู(ุต)ยป ุจุฑุง ูู ุงุฌุงุฏ ูุดุฏุู ุงูู ุญุฌู ุงุฒ ุงุชูุงูุงุช ูุงูุฑุง ููู ูู ุฏุฑ ฺฉุชุงุจ ูุจูุฏ.\n",
            "ฺฉุชุงุจ ุงุฒ ูุจู ุงุฒ ุชููุฏ ูพุงูุจุฑ ู ุงุฒ ุฒูุฏฺฏ ุนุจุฏุงููุทุจ ูพุฏุฑุจุฒุฑฺฏ ูพุงูุจุฑ ุขุบุงุฒ ูุดู ู ุชุง ุฒูุงู ูุจุนุซ ูพุงูุจุฑ ูพุด ูุฑูุูุซุฑ ฺฉุชุงุจ ุจู ุฒุจุงู ูุงุฑุณ ฺฉููู(ูู ฺฉุงููุงู ูุงุจู ููู ู ุจุณุงุฑ ุดุฑู),ฺฏุงู ุงุชูุงู ูุง ุงุฒ ุฒุจุงู ููุณูุฏู ุงุณุช ฺฏุงู ุงุฒ ุฒุจุงู ุงุทุฑุงูุงู ูพุงูุจุฑุฺฏุงู ูู ุฑููุฏ ุฏุงุณุชุงู ุถูู ูฺฉุงููู ูุง ูพุด ูโุฑู.\n",
            "ุงุตูุฃ ุจุง ฺฉุชุงุจ ุงุญุณุงุณ ุฎุณุชฺฏ ูฺฉุฑุฏู.\n",
            "ุจุฑุง ูุนุฑู ูพุงูุจุฑ ุจู ููุฌูุงู ูุง ุฎู ููุงุณุจู.\n",
            "ู ฺฉูุง ฺฏุฒูู ุฎูุจู ุจุฑุง ูุฏู ุฏุงุฏู.\n",
            "ุงุฒ ููุณูุฏู ูุญุชุฑู ฺฉุชุงุจ ุจุณุงุฑ ุชุดฺฉุฑ ู ฺฉูู(ุงฺฏู ู ุฑูุฒ ุญุถูุฑ ุจุจููุดูู ุญุชูุง ุญุถูุฑ ูู ุชุดฺฉุฑ ุฎูุงูู ฺฉุฑุฏ) ู ุงูุฏูุงุฑู ุฏุฑ ุขูุฏู ุขุซุงุฑ ุจุดุชุฑ ุงุฒ ุงุดูู ุจุจูู.\n",
            "ููู ุงูุนุงุฏู ุจูุฏ.\n",
            "ฺฉ ฺฉุชุงุจ ุฎููุฏู...\n",
            "ุจุฑุง ูู ฺฉู ูุซู ฺฉ ููุงู ุขุจ ุฎูฺฉ ุชู ุชุดูฺฏ ุชุงุจุณุชูู ุจูุฏุุุูููููุฏุฑ ฺฏูุงุฑุง...\n",
            "ูู ุฏููู ุจุฑุง ุจูู ูู ุงูุทูุฑ ุจูุฏู ุง ููุูู ุชุตูุฑ ูู ุงุฒ ูพุงูุจุฑ ู ูุฑุฏ ุจุง ูุจุงุณ ุนุฑุจ ฺฉ ุฏุณุช ุณูุฏ ุจูุฏุฺฉ ูุฑุฏ ููุฏุณุุฎู ูุณุจุช ุจูุดูู ุญุณ ูุญุจุช ูุฏุงุดุชูุุจุดุชุฑ ุญุงูุช ุงุญุชุฑุงู ู ุชูุฏุณ...\n",
            "ูู ุจุง ุฎููุฏู ุงู ฺฉุชุงุจ ูพุงูุจุฑ ุจุฑุง ูู ฺฉ ุดุฎุตุช ุงูุณุงู ฺฏููู(ุฌุฏุง ุงุฒ ุงูู ุญุงูุช ุชูุฏุณ ู ูุฑุดุชู ูุงููุฏ) ูพุฏุง ฺฉุฑุฏูุฏุุดุฎุตุช ฺฉู ูุซู ููู ุขุฏูุง ู ุณุฑ ูุงุฒ ูุง ุฏุงุฑูุู ุณุฑ ุฏุบุฏุบู ูุง ุฏุงุฑู...\n",
            "ุญุณ ฺฉู ฺฉุชุงุจ ุงุฒ ูพุงูุจุฑ ู ุฎุงููุงุฏู ู ุงุทุฑุงูุงูุดูู ุงุฌุงุฏ ฺฉุฑุฏ ุจู ูฺ ูุฌู ุจุง ููู ยซูุญูุฏ ุฑุณูู ุงููู(ุต)ยป ุจุฑุง ูู ุงุฌุงุฏ ูุดุฏุู ุงูู ุญุฌู ุงุฒ ุงุชูุงูุงุช ูุงูุฑุง ููู ูู ุฏุฑ ฺฉุชุงุจ ูุจูุฏ.\n",
            "ฺฉุชุงุจ ุงุฒ ูุจู ุงุฒ ุชููุฏ ูพุงูุจุฑ ู ุงุฒ ุฒูุฏฺฏ ุนุจุฏุงููุทุจ ูพุฏุฑุจุฒุฑฺฏ ูพุงูุจุฑ ุขุบุงุฒ ูุดู ู ุชุง ุฒูุงู ูุจุนุซ ูพุงูุจุฑ ูพุด ูุฑูุูุซุฑ ฺฉุชุงุจ ุจู ุฒุจุงู ูุงุฑุณ ฺฉููู(ูู ฺฉุงููุงู ูุงุจู ููู ู ุจุณุงุฑ ุดุฑู),ฺฏุงู ุงุชูุงู ูุง ุงุฒ ุฒุจุงู ููุณูุฏู ุงุณุช ฺฏุงู ุงุฒ ุฒุจุงู ุงุทุฑุงูุงู ูพุงูุจุฑุฺฏุงู ูู ุฑููุฏ ุฏุงุณุชุงู ุถูู ูฺฉุงููู ูุง ูพุด ูโุฑู.\n",
            "ุงุตูุฃ ุจุง ฺฉุชุงุจ ุงุญุณุงุณ ุฎุณุชฺฏ ูฺฉุฑุฏู.\n",
            "ุจุฑุง ูุนุฑู ูพุงูุจุฑ ุจู ููุฌูุงู ูุง ุฎู ููุงุณุจู.\n",
            "ู ฺฉูุง ฺฏุฒูู ุฎูุจู ุจุฑุง ูุฏู ุฏุงุฏู.\n",
            "ุงุฒ ููุณูุฏู ูุญุชุฑู ฺฉุชุงุจ ุจุณุงุฑ ุชุดฺฉุฑ ู ฺฉูู(ุงฺฏู ู ุฑูุฒ ุญุถูุฑ ุจุจููุดูู ุญุชูุง ุญุถูุฑ ูู ุชุดฺฉุฑ ุฎูุงูู ฺฉุฑุฏ) ู ุงูุฏูุงุฑู ุฏุฑ ุขูุฏู ุขุซุงุฑ ุจุดุชุฑ ุงุฒ ุงุดูู ุจุจูู.\n",
            "ุณุฎุช ุฎูุงู ุจูุฏ\n",
            "ูู ุฎูุจ ุจูุฏ\n",
            "ุณุฎุช ุฎูุงู ุจูุฏ\n",
            "ูู ุฎูุจ ุจูุฏ\n",
            "ูุณุฎู ฺุงูพ ฺฉุชุงุจ ุฑู ุฎููุฏู. ูุงูุนุง ุฏููุดู ู ุฏููพุฐุฑ ุจูุฏ\n",
            "ูุณุฎู ฺุงูพ ฺฉุชุงุจ ุฑู ุฎููุฏู. ูุงูุนุง ุฏููุดู ู ุฏููพุฐุฑ ุจูุฏ\n",
            "ุจุฏูู ุดฺฉ ฺฉ ุงุฒ ุจูุชุฑู ุฑูุงู ูุง ูุงุฑุณ ุณุช...\n",
            "ุจุฑุง ุงูุชุญุงู ููููู ฺฉุชุงุจ ุฑู ุจุฎููู\n",
            "ุจุฏูู ุดฺฉ ฺฉ ุงุฒ ุจูุชุฑู ุฑูุงู ูุง ูุงุฑุณ ุณุช...\n",
            "ุจุฑุง ุงูุชุญุงู ููููู ฺฉุชุงุจ ุฑู ุจุฎููู\n",
            "ฺฉุชุงุจ ุจุณุงุฑ ุฒุจุง ฺฉู ุจุง ูุชู ุฏููุดู ููุงุน ุฏูู ุชุงุฑุฎ ุฑู ุจุงู ฺฉุฑุฏู.\n",
            "ูุงูุนุง ุงุฑุฒุด ฺูุฏ ุจุงุฑ ุฎูุงูุฏู ุฑู ุฏุงุฑู.\n",
            "ฺฉุชุงุจ ุจุณุงุฑ ุฒุจุง ฺฉู ุจุง ูุชู ุฏููุดู ููุงุน ุฏูู ุชุงุฑุฎ ุฑู ุจุงู ฺฉุฑุฏู.\n",
            "ูุงูุนุง ุงุฑุฒุด ฺูุฏ ุจุงุฑ ุฎูุงูุฏู ุฑู ุฏุงุฑู.\n",
            "๐ุงุญุงุฏุซ ุงุฒ ุญุถุฑุช ูุญูุฏ ุตู ุงููู ุนูู ู ุขูู ู ุณูู :\n",
            "\n",
            "๐ธุจู ฺฉุฏฺฏุฑ ูุฏู ุฏูุฏ ุชุง ุฏูุณุช ุชุงู ุงูุฒูู ุดูุฏ .\n",
            "\n",
            "๐นุญุง ุ ุฌุฒ ูฺฉ ุจู ุจุงุฑ ูู ุขูุฑุฏ .\n",
            "\n",
            "๐ธุจูุชุฑูู ุดูุง ฺฉุณ ุงุณุช ฺฉู ุจู ุฎุฑุด ุงูุฏ ู ุฑูุฏ ู ุงุฒ ุดุฑูุด ุงูู ูุณุช .\n",
            "\n",
            "๐นูพุงุฑุณุง ุฏุฑ ุฏูุง ุ ูุงู ุขุณุงุด ุฏู ู ุชู ุงุณุช .\n",
            "\n",
            "๐ธูฺฉ ุจุฎุช ุ ุขู ุงุณุช ฺฉู ุงุฒ [ุณุฑููุดุช] ุฏฺฏุฑุงู ูพูุฏ ุจฺฏุฑุฏ .  \n",
            "\n",
            "๐นุขุณุงู ฺฏุฑูุชู ุ ูุงู ุณูุฏููุฏ ุงุณุช ู ุณุฎุช ฺฏุฑูุชู ุ ุณุจุจ ุดูุฑุจุฎุช .  \n",
            "\n",
            "๐ธุฏุฑ ุฌุณุชุฌู ุฑูุฒู ุญูุงู ุจูุฏู ุ ุฌูุงุฏ ุงุณุช .  \n",
            "\n",
            "๐นุฎูุดุง ุขู ฺฉู ฺฉุณุจุด ูพุงฺฉ ุ ููุงูุด ุจุณุงูุงู ู ุขุดฺฉุงุฑุด ูฺฉ ุจุงุดุฏ ู ุดุฑู ุฎูุฏ ุฑุง ุงุฒ ูุฑุฏู ุ ุจุงุฒ ุฏุงุฑุฏ !  \n",
            " \n",
            "๐ธุฎุฏุงููุฏ ุ ุฑุญูุช ูู ุขููุฑูุฏ ุจุฑ ฺฉุณ ฺฉู ุจู ูุฑุฏู ุ ุฑุญู ูู ฺฉูุฏ .  \n",
            "\n",
            "๐นุงูุงู ุจูุฏู ุฑุงุณุช ูุดูุฏ ุ ูฺฏุฑ ุขู ฺฉู ุฏูุด ุฑุงุณุช ุดูุฏ ุ ู ุฏูุด ุฑุงุณุช ูุดูุฏ ุ ูฺฏุฑ ุขู ฺฉู ุฒุจุงูุด ุฑุงุณุช ุดูุฏ .  \n",
            "\n",
            "๐ธุฎุฏุง ุฑุง ุณูพุงุณ ูู ฺฏุฒุงุฑุฏ ุ ุขู ฺฉู ุณูพุงุณฺฏุฒุงุฑ ูุฑุฏู ูุจุงุดุฏ .  \n",
            "\n",
            "๐นุจูุฏู ุงูุงู ูู ุขูุฑูุฏ ุ ูฺฏุฑ ุขู ฺฉู ูฺฉ ุง ุฑุง ฺฉู ุจุฑุง ุฎูุฏ ุฏูุณุช ุฏุงุฑุฏ ุ ุจุฑุง ุจุฑุงุฏุฑุด ูุฒ ุฏูุณุช ุฏุงุดุชู ุจุงุดุฏ .  \n",
            " \n",
            "๐ธุงุฒ ูุง ูุณุช ุขู ฺฉู ุฎุฏุง ูุฏุงู ุฑูุฒ ุงุด ุฑุง ูุฑุงุฎ ฺฉุฑุฏู ุจุงุดุฏ ู ุงู ุจุฑ ุฎุงููุงุฏู ุงุด ุชูฺฏ ฺฏุฑุฏ .  \n",
            "\n",
            "๐นุขู ฺฉู ุฎูุงูุงู ุฎุฑ ุจุงุดุฏ ุ ุฒุงู ูู ุจูุฏ ุ ู ุขู ฺฉู ูุดูุฑุช ฺฉูุฏ ุ ูพุดูุงู ูู ุดูุฏ .  \n",
            "\n",
            "๐ธ  ุญฺฉุงุช ุดูุง   ุง ูุฑุฏู  ููุงููุฏ ุณูพุงู ุงุณุช ฺฉู ุงุจุชุฏุง ุขู ุฑูุชู ู ูุฏุง ฺฉูฺ ุฏุฑ ุขูุ ุณุฑ ุฏุงุฏู ุดุฏู ุงุณุช . ูพุณ ุ ฺู ุฒูุฏ ุขุฎุฑ ุขู ุณูพุงู ุจู ุงูููุด ู ุฑุณุฏ! ุจู ุฎุฏุง ุณูฺฏูุฏ ุ ุฏูุง ุฏุฑ ุจุฑุงุจุฑ ุขุฎุฑุช ุ ุฌุฒ ุจู ูุงููุฏ ฺฉ ููููุณ (ุฌูุด)  ุฎุฑฺฏูุด ูุณุช . ุจฺฉูุดุฏ ุ ุจฺฉูุดุฏ ุง ุจูุฏฺฏุงู ุฎุฏุง  ู ุงุฒ ุฎุฏุงููุฏ ุ ูพุฑูุฑุฏฺฏุงุฑุชุงู ุ ฺฉูฺฉ ุจุฌูุฏ.  \n",
            "\n",
            "๐นุฎุฏุงููุฏ ุจู ฺุฒ ุจุฑุชุฑ ุงุฒ ุดูุงุฎุช ุนุงููุงูู ุฏู ุ ุนุจุงุฏุช ูุดุฏ.\n",
            "\n",
            "\n",
            ".\n",
            "ุงุญุงุฏุซ ุงุฒ ุญุถุฑุช ูุญูุฏ ุตู ุงููู ุนูู ู ุขูู ู ุณูู :\n",
            "\n",
            "ุจู ฺฉุฏฺฏุฑ ูุฏู ุฏูุฏ ุชุง ุฏูุณุช ุชุงู ุงูุฒูู ุดูุฏ .\n",
            "\n",
            "ุญุง ุ ุฌุฒ ูฺฉ ุจู ุจุงุฑ ูู ุขูุฑุฏ .\n",
            "\n",
            "ุจูุชุฑูู ุดูุง ฺฉุณ ุงุณุช ฺฉู ุจู ุฎุฑุด ุงูุฏ ู ุฑูุฏ ู ุงุฒ ุดุฑูุด ุงูู ูุณุช .\n",
            "\n",
            "ูพุงุฑุณุง ุฏุฑ ุฏูุง ุ ูุงู ุขุณุงุด ุฏู ู ุชู ุงุณุช .\n",
            "\n",
            "ูฺฉ ุจุฎุช ุ ุขู ุงุณุช ฺฉู ุงุฒ [ุณุฑููุดุช] ุฏฺฏุฑุงู ูพูุฏ ุจฺฏุฑุฏ .  \n",
            "\n",
            "ุขุณุงู ฺฏุฑูุชู ุ ูุงู ุณูุฏููุฏ ุงุณุช ู ุณุฎุช ฺฏุฑูุชู ุ ุณุจุจ ุดูุฑุจุฎุช .  \n",
            "\n",
            "ุฏุฑ ุฌุณุชุฌู ุฑูุฒู ุญูุงู ุจูุฏู ุ ุฌูุงุฏ ุงุณุช .  \n",
            "\n",
            "ุฎูุดุง ุขู ฺฉู ฺฉุณุจุด ูพุงฺฉ ุ ููุงูุด ุจุณุงูุงู ู ุขุดฺฉุงุฑุด ูฺฉ ุจุงุดุฏ ู ุดุฑู ุฎูุฏ ุฑุง ุงุฒ ูุฑุฏู ุ ุจุงุฒ ุฏุงุฑุฏ !  \n",
            " \n",
            "ุฎุฏุงููุฏ ุ ุฑุญูุช ูู ุขููุฑูุฏ ุจุฑ ฺฉุณ ฺฉู ุจู ูุฑุฏู ุ ุฑุญู ูู ฺฉูุฏ .  \n",
            "\n",
            "ุงูุงู ุจูุฏู ุฑุงุณุช ูุดูุฏ ุ ูฺฏุฑ ุขู ฺฉู ุฏูุด ุฑุงุณุช ุดูุฏ ุ ู ุฏูุด ุฑุงุณุช ูุดูุฏ ุ ูฺฏุฑ ุขู ฺฉู ุฒุจุงูุด ุฑุงุณุช ุดูุฏ .  \n",
            "\n",
            "ุฎุฏุง ุฑุง ุณูพุงุณ ูู ฺฏุฒุงุฑุฏ ุ ุขู ฺฉู ุณูพุงุณฺฏุฒุงุฑ ูุฑุฏู ูุจุงุดุฏ .  \n",
            "\n",
            "ุจูุฏู ุงูุงู ูู ุขูุฑูุฏ ุ ูฺฏุฑ ุขู ฺฉู ูฺฉ ุง ุฑุง ฺฉู ุจุฑุง ุฎูุฏ ุฏูุณุช ุฏุงุฑุฏ ุ ุจุฑุง ุจุฑุงุฏุฑุด ูุฒ ุฏูุณุช ุฏุงุดุชู ุจุงุดุฏ .  \n",
            " \n",
            "ุงุฒ ูุง ูุณุช ุขู ฺฉู ุฎุฏุง ูุฏุงู ุฑูุฒ ุงุด ุฑุง ูุฑุงุฎ ฺฉุฑุฏู ุจุงุดุฏ ู ุงู ุจุฑ ุฎุงููุงุฏู ุงุด ุชูฺฏ ฺฏุฑุฏ .  \n",
            "\n",
            "ุขู ฺฉู ุฎูุงูุงู ุฎุฑ ุจุงุดุฏ ุ ุฒุงู ูู ุจูุฏ ุ ู ุขู ฺฉู ูุดูุฑุช ฺฉูุฏ ุ ูพุดูุงู ูู ุดูุฏ .  \n",
            "\n",
            "  ุญฺฉุงุช ุดูุง   ุง ูุฑุฏู  ููุงููุฏ ุณูพุงู ุงุณุช ฺฉู ุงุจุชุฏุง ุขู ุฑูุชู ู ูุฏุง ฺฉูฺ ุฏุฑ ุขูุ ุณุฑ ุฏุงุฏู ุดุฏู ุงุณุช . ูพุณ ุ ฺู ุฒูุฏ ุขุฎุฑ ุขู ุณูพุงู ุจู ุงูููุด ู ุฑุณุฏ! ุจู ุฎุฏุง ุณูฺฏูุฏ ุ ุฏูุง ุฏุฑ ุจุฑุงุจุฑ ุขุฎุฑุช ุ ุฌุฒ ุจู ูุงููุฏ ฺฉ ููููุณ (ุฌูุด)  ุฎุฑฺฏูุด ูุณุช . ุจฺฉูุดุฏ ุ ุจฺฉูุดุฏ ุง ุจูุฏฺฏุงู ุฎุฏุง  ู ุงุฒ ุฎุฏุงููุฏ ุ ูพุฑูุฑุฏฺฏุงุฑุชุงู ุ ฺฉูฺฉ ุจุฌูุฏ.  \n",
            "\n",
            "ุฎุฏุงููุฏ ุจู ฺุฒ ุจุฑุชุฑ ุงุฒ ุดูุงุฎุช ุนุงููุงูู ุฏู ุ ุนุจุงุฏุช ูุดุฏ.\n",
            "\n",
            "\n",
            ".\n",
            "ุจูุชุฑู ฺฉุชุงุจ ฺฉู ุฎูุงูุฏู.\n",
            "ุจูุชุฑู ฺฉุชุงุจ ฺฉู ุฎูุงูุฏู.\n",
            "ุนุงู ุจูุฏ....ุญุชูุง ุจุฎููุฏ.\n",
            "ุนุงู ุจูุฏ....ุญุชูุง ุจุฎููุฏ.\n",
            "ุณูุงูุุนุงู ุจูุฏ ูุฐุช ุจุฑุฏู ุฌุฒู ุจูุชุฑู ฺฉุชุงุจูุง ุจูุฏ ฺฉู ุชุงุจุญุงู ุฎููุฏูุุฎุฏุง ููุณูุฏู ุฑุง ุฎุฑ ุจุฏู\n",
            "ุณูุงูุุนุงู ุจูุฏ ูุฐุช ุจุฑุฏู ุฌุฒู ุจูุชุฑู ฺฉุชุงุจูุง ุจูุฏ ฺฉู ุชุงุจุญุงู ุฎููุฏูุุฎุฏุง ููุณูุฏู ุฑุง ุฎุฑ ุจุฏู\n",
            "ุงู ฺฉุชุงุจ ุจู ฺูุฏ ุฒุจุงู ูุซู ุนุฑุจุ ุชุฑฺฉ ุงุณุชุงูุจููุ ุงูฺฏูุณ ุชุฑุฌูู ุดุฏูุ ู ุฎู ุฎูุจู ฺฉู ููฺู ฺฉุชุงุจ ุฑู ูุชููู ุจู ุฒุจุงู ุงุตูุด ุจุฎููู\n",
            "ุงู ฺฉุชุงุจ ุจู ฺูุฏ ุฒุจุงู ูุซู ุนุฑุจุ ุชุฑฺฉ ุงุณุชุงูุจููุ ุงูฺฏูุณ ุชุฑุฌูู ุดุฏูุ ู ุฎู ุฎูุจู ฺฉู ููฺู ฺฉุชุงุจ ุฑู ูุชููู ุจู ุฒุจุงู ุงุตูุด ุจุฎููู\n",
            "ฺฉุชุงุจ ูุซุฑ ุฌุงูุจ ุฏุงุฑู ุทูุฑ ฺฉู ฺฏุงู ูุถุงุณุงุฒ ุงูู ุจุงุนุซ ูุดู ุงุญุณุงุณ ฺฉูู ุฏุฑ ุญุงู ุชูุงุดุง ููู ุขูฺฉ ุขู ุชู ูุธุฑ ฺฉุฑุฏู ูุณุชู ุง ุญุช ฺฏุงู ุงููุงุช ุฎูุฏู ุฑู ุฏุฑ ุฒูุงู ฺฉุชุงุจ ุชุตูุฑ ฺฉูู.\n",
            "ฺฉุชุงุจ ูุซุฑ ุฌุงูุจ ุฏุงุฑู ุทูุฑ ฺฉู ฺฏุงู ูุถุงุณุงุฒ ุงูู ุจุงุนุซ ูุดู ุงุญุณุงุณ ฺฉูู ุฏุฑ ุญุงู ุชูุงุดุง ููู ุขูฺฉ ุขู ุชู ูุธุฑ ฺฉุฑุฏู ูุณุชู ุง ุญุช ฺฏุงู ุงููุงุช ุฎูุฏู ุฑู ุฏุฑ ุฒูุงู ฺฉุชุงุจ ุชุตูุฑ ฺฉูู.\n",
            "ู ุขููุง ุฑุง ฺฉู ุฏุงุณุชุงู ููุณ ูู ุฏุงูู ุจุฑููุฏ ดฐ ุจุงุฑ ุงุฒ ุฏุงุณุชุงู ฺฏุฏุง ุณุงุนุฏ ูุดู ฺฉููุฏ. ุณุฎูุฑุงู ุฌูุงููุฑฺฏ ุฏุฑ ูุซุฑ ูุนุงุตุฑ ูุงุฑุณ ููุดูฺฏ ฺฏูุดุฑ ุฏุฑ ุงูุฌูู ุฏุงุณุชุงู ููุณุงู ุขููุงู ู ุงุฑุงู\n",
            "ู ุขููุง ุฑุง ฺฉู ุฏุงุณุชุงู ููุณ ูู ุฏุงูู ุจุฑููุฏ ดฐ ุจุงุฑ ุงุฒ ุฏุงุณุชุงู ฺฏุฏุง ุณุงุนุฏ ูุดู ฺฉููุฏ. ุณุฎูุฑุงู ุฌูุงููุฑฺฏ ุฏุฑ ูุซุฑ ูุนุงุตุฑ ูุงุฑุณ ููุดูฺฏ ฺฏูุดุฑ ุฏุฑ ุงูุฌูู ุฏุงุณุชุงู ููุณุงู ุขููุงู ู ุงุฑุงู\n",
            "ููุด ฺฉู ุงูู ฺฏูุฏุงู\n",
            "ููุด ฺฉู ุงูู ฺฏูุฏุงู\n",
            "ุณูุงู ูู ุณุงู ูุงุณุช ุจฺฉุงุฑ ูโ ุจ ูพููู ฺฉู ูู ฺฉุชุงุจ ฺฉุณุจ ู ฺฉุงุฑ ุฎุฑุฏู ุจู ุงูุฏ ฺฉุงุฑ ู ูพูู ุงูุง ูฺ ูุงุฏู ูุฏุงุฑู ูุงูุนุง ุฏุงุบูู ู ุฎู ุดุฏู ูฺ ฺฉุณู ฺฉูฺฉู ูฺฉุฑุฏู ฺฉุงุด ฺฉู ูพูู ุฏุงุดุชู ูุถุนุชู ุงู ุทูุฑ ูู ูููุฏ ุขุฎุฑุด ููุฏููู ฺู ุจูุง ุณุฑู ูุงุฏ ุฏุฑ ุญุฏ ูุฑฺฏ ู ุฌููู ุงุฐุชู ฺฉุฑุฏู ูพุดููุงุฏ ู ุชูุตู ุชูู ฺู ุ\n",
            "ุณูุงู ูู ุณุงู ูุงุณุช ุจฺฉุงุฑ ูโ ุจ ูพููู ฺฉู ูู ฺฉุชุงุจ ฺฉุณุจ ู ฺฉุงุฑ ุฎุฑุฏู ุจู ุงูุฏ ฺฉุงุฑ ู ูพูู ุงูุง ูฺ ูุงุฏู ูุฏุงุฑู ูุงูุนุง ุฏุงุบูู ู ุฎู ุดุฏู ูฺ ฺฉุณู ฺฉูฺฉู ูฺฉุฑุฏู ฺฉุงุด ฺฉู ูพูู ุฏุงุดุชู ูุถุนุชู ุงู ุทูุฑ ูู ูููุฏ ุขุฎุฑุด ููุฏููู ฺู ุจูุง ุณุฑู ูุงุฏ ุฏุฑ ุญุฏ ูุฑฺฏ ู ุฌููู ุงุฐุชู ฺฉุฑุฏู ูพุดููุงุฏ ู ุชูุตู ุชูู ฺู ุ\n",
            "ุงููุง ฺฏุฏุงู ุดููุง\n",
            "ุงููุง ฺฏุฏุงู ุดููุง\n",
            "ฺฏุงู ุงููุงุช ุจู ููุทู ุง ูุฑุณ ฺฉู ุฌุฒ ฺฏูู ุฒุฏู ุฎูุฏุช ฺฏุฒูู ุฏฺฏุฑ ูุฏุงุฑุูุฌุจูุฑ ู ุฌูุฑ ุฎูุฏุชู ุขุฑูู ฺฉู ฺฉู ุฏูุช ูุชุฑฺฉูุูุฌุจูุฑ ุจู ุฎูุฏุช ุจูุจูููู ฺฏุฏุง ุซูุงุจ ุฏุงุฑู...\n",
            "ฺฏุงู ุงููุงุช ุจู ููุทู ุง ูุฑุณ ฺฉู ุฌุฒ ฺฏูู ุฒุฏู ุฎูุฏุช ฺฏุฒูู ุฏฺฏุฑ ูุฏุงุฑุูุฌุจูุฑ ู ุฌูุฑ ุฎูุฏุชู ุขุฑูู ฺฉู ฺฉู ุฏูุช ูุชุฑฺฉูุูุฌุจูุฑ ุจู ุฎูุฏุช ุจูุจูููู ฺฏุฏุง ุซูุงุจ ุฏุงุฑู...\n",
            "ุงูู ฺฏุฏุงู\n",
            "ุงูู ฺฏุฏุงู\n",
            "ฺฉุชุงุจุง ุณุงุนุฏ ููุดู ฺฏุฑุงุณุช ู ุงุฏู ู ูุจุฑู ุชู ูุถุง ุฏุงุณุชุงู\n",
            "ฺฉุชุงุจุง ุณุงุนุฏ ููุดู ฺฏุฑุงุณุช ู ุงุฏู ู ูุจุฑู ุชู ูุถุง ุฏุงุณุชุงู\n",
            "ุฎููุฏู ุงู ุฏุงุณุชุงู ูพุดููุงุฏ ูุดู.\n",
            "ุฎููุฏู ุงู ุฏุงุณุชุงู ูพุดููุงุฏ ูุดู.\n",
            "ุฎู ุบู ุงูฺฏุฒ ุจูุฏ\n",
            "ููุชุงุณูุงูู ูุงูุนุช ุฏุงุฑู ู ุฎู ุชูุฎู.ุงูฺฉู ู ุนูุฑ ุจุง ุฎูู ุฏู ุฒุญูุช ุจฺฉุด ู ุจฺู ุจุฒุฑฺฏ ฺฉู ู ุขุฎุฑุดู ูฺ ุจู ูฺ.ูุฑ ฺฉ ุจุฑู ุฏูุจุงู ุฒูุฏฺฏ ุฎูุฏุด....\n",
            "ุฎู ุบู ุงูฺฏุฒ ุจูุฏ\n",
            "ููุชุงุณูุงูู ูุงูุนุช ุฏุงุฑู ู ุฎู ุชูุฎู.ุงูฺฉู ู ุนูุฑ ุจุง ุฎูู ุฏู ุฒุญูุช ุจฺฉุด ู ุจฺู ุจุฒุฑฺฏ ฺฉู ู ุขุฎุฑุดู ูฺ ุจู ูฺ.ูุฑ ฺฉ ุจุฑู ุฏูุจุงู ุฒูุฏฺฏ ุฎูุฏุด....\n",
            "ฺ ูุดู ฺฉู ููุช ุจฺู ูุง ุจุฒุฑฺฏ ูุดูุ ูพุฏุฑููุงุฏุฑ ุชู ฺุดูุดูู ฺฉูฺฺฉ ู ุง ุญุช ุจ ุงุฑุฒุด ูุดูุ\n",
            "ุจ ุชูุฌูุ ุจ ุงุญุชุฑุงูุู...\n",
            "ุงูุฏูุงุฑู ูู ูพุฏุฑ ูุงุฏุฑ ูุญุชุงุฌ ูุฑุฒูุฏุด ุจุงุดูุ ูู ูุฑุฒูุฏ ูุฑุงููุด ฺฉุงุฑ ู ูพุฏุฑููุงุฏุฑุด.\n",
            "ฺ ูุดู ฺฉู ููุช ุจฺู ูุง ุจุฒุฑฺฏ ูุดูุ ูพุฏุฑููุงุฏุฑ ุชู ฺุดูุดูู ฺฉูฺฺฉ ู ุง ุญุช ุจ ุงุฑุฒุด ูุดูุ\n",
            "ุจ ุชูุฌูุ ุจ ุงุญุชุฑุงูุู...\n",
            "ุงูุฏูุงุฑู ูู ูพุฏุฑ ูุงุฏุฑ ูุญุชุงุฌ ูุฑุฒูุฏุด ุจุงุดูุ ูู ูุฑุฒูุฏ ูุฑุงููุด ฺฉุงุฑ ู ูพุฏุฑููุงุฏุฑุด.\n",
            "ุนุฌุจ ู ุบุฑ ูุงุจู ุฏุฑฺฉ\n",
            "ุนุฌุจ ู ุบุฑ ูุงุจู ุฏุฑฺฉ\n",
            "ุจูุธุฑู ุจุฏ ูุจูุฏ ุฏุงุณุชุงู ุฏุฑ ุฒูุงู ุฎูุฏุด ููููุณ ุชุฑ ุจูุฏู ูุทุนุง\n",
            "ุจูุธุฑู ุจุฏ ูุจูุฏ ุฏุงุณุชุงู ุฏุฑ ุฒูุงู ุฎูุฏุด ููููุณ ุชุฑ ุจูุฏู ูุทุนุง\n",
            "ูพุฑุฒูู ุฎู ูุธููู ุจูุฏ ุจฺู ูุงุด ููุท ููุชุธุฑุจูุฏู ุจูุฑู ูุงุชุฑฺฉุดู ุชูุณู ฺฉูู ุงูุง ุจุฑุฏุงุดุช ูู ุงุฒุซูุงุจ ุฏุงุดุชู ฺฏุฏุงุด ุงู ุจูุฏ ฺฉู ...ุฎุงููู ุจุฒุฑฺฏ ูุตุฏู ูุชุด ุงู ุจูุฏ ฺฉู ุจุง ฺฏุฏุง ุจู ุงูููุง ฺฉู ูุฎูุงู ุตุฏูู ุจูุด ุจุฏู ู ุซูุงุจ ุจุฑุณู ฺูู ุตุฏูู ุฏุงุฏู ุชูุงุณูุงู ุฎู ุซูุงุจ ุฏุงุฑู ุดุงุฏ ููุณูุฏู ุจู ุฏูุจุงู ุงู ุจูุฏู ฺฉู ุฏุฑุนู ูุดุงู ุฏุงุฏู ูุธูููุช ุฎุงููู ุจุฒุฑฺฏ ุงููู ุดุฎุตุช ูุดุงู ุจุฏู ฺฉู ููู ุจู ูุฑุฎ ุฑูุฒ ูุฎูุฑู ูุซู ุฎู ุงุฒุขุฏูุง ฺฉู ููู ุงูุงูุดู ุชู ุฌุงูุนู ููู ฺฉู ูุณุชูุฏ ุนู ู ุฌูุฑุง ูุงุณู ููู ุฎูุฑุฏู ุฎูุฏุด ุงุฒ ุงุนุชูุงุฏุงุช ูุฑุฏู ุณุคุก ุงุณุชูุงุฏู ูฺฉุฑุฏ ู ุชฺฉุฏ ฺฏุฑ ุฑู ุจุง ุงู ุงุณุชุฏูุงูุด ฺฉู ุซูุงุจ ุฏุงุฑู ุชูุฌู ูฺฉุฑุฏ ...\n",
            "ูพุฑุฒูู ุฎู ูุธููู ุจูุฏ ุจฺู ูุงุด ููุท ููุชุธุฑุจูุฏู ุจูุฑู ูุงุชุฑฺฉุดู ุชูุณู ฺฉูู ุงูุง ุจุฑุฏุงุดุช ูู ุงุฒุซูุงุจ ุฏุงุดุชู ฺฏุฏุงุด ุงู ุจูุฏ ฺฉู ...ุฎุงููู ุจุฒุฑฺฏ ูุตุฏู ูุชุด ุงู ุจูุฏ ฺฉู ุจุง ฺฏุฏุง ุจู ุงูููุง ฺฉู ูุฎูุงู ุตุฏูู ุจูุด ุจุฏู ู ุซูุงุจ ุจุฑุณู ฺูู ุตุฏูู ุฏุงุฏู ุชูุงุณูุงู ุฎู ุซูุงุจ ุฏุงุฑู ุดุงุฏ ููุณูุฏู ุจู ุฏูุจุงู ุงู ุจูุฏู ฺฉู ุฏุฑุนู ูุดุงู ุฏุงุฏู ูุธูููุช ุฎุงููู ุจุฒุฑฺฏ ุงููู ุดุฎุตุช ูุดุงู ุจุฏู ฺฉู ููู ุจู ูุฑุฎ ุฑูุฒ ูุฎูุฑู ูุซู ุฎู ุงุฒุขุฏูุง ฺฉู ููู ุงูุงูุดู ุชู ุฌุงูุนู ููู ฺฉู ูุณุชูุฏ ุนู ู ุฌูุฑุง ูุงุณู ููู ุฎูุฑุฏู ุฎูุฏุด ุงุฒ ุงุนุชูุงุฏุงุช ูุฑุฏู ุณุคุก ุงุณุชูุงุฏู ูฺฉุฑุฏ ู ุชฺฉุฏ ฺฏุฑ ุฑู ุจุง ุงู ุงุณุชุฏูุงูุด ฺฉู ุซูุงุจ ุฏุงุฑู ุชูุฌู ูฺฉุฑุฏ ...\n",
            "ฺูุฏุฑ ุบูฺฏู!!! ูุงูุนุง ฺฏุฑู ฺฏุฑูุช...\n",
            "ฺูุฏุฑ ุบูฺฏู!!! ูุงูุนุง ฺฏุฑู ฺฏุฑูุช...\n",
            "ฺฉุชุงุจ ุฎู ูพฺุฏู ุง ูุจูุฏ..ุฎู ูู ุฑู ุชุญุช ุชุงุซุฑ ูุฑุงุฑ ูุฏุงุฏ..ูู ููุช ุจูฺฏุฑุงู ุฏฺฉุชุฑ ุฑู ุฎููุฏู ูุชููุณุชู ุงุฒ ฺฉ ุฎุท ฺฉุชุงุจ ุจฺฏุฐุฑู..ู ูฺฏู ฺฉู ูพุฑุฒู ุจู ุญูุด ุฑุณุฏ..ุจุง ุชุดฺฉุฑ ุงุฒ ุทุงูฺู\n",
            "ฺฉุชุงุจ ุฎู ูพฺุฏู ุง ูุจูุฏ..ุฎู ูู ุฑู ุชุญุช ุชุงุซุฑ ูุฑุงุฑ ูุฏุงุฏ..ูู ููุช ุจูฺฏุฑุงู ุฏฺฉุชุฑ ุฑู ุฎููุฏู ูุชููุณุชู ุงุฒ ฺฉ ุฎุท ฺฉุชุงุจ ุจฺฏุฐุฑู..ู ูฺฏู ฺฉู ูพุฑุฒู ุจู ุญูุด ุฑุณุฏ..ุจุง ุชุดฺฉุฑ ุงุฒ ุทุงูฺู\n",
            "ุจุงุงู ุชุนุฏุงุฏ ุงุฒ ูุฑุฒูุฏ ูู ุจุงุฒู ูุฌุจูุฑ ุจุงุด ฺฏุฏุง ฺฉู ุ\n",
            "ุจฺู ูุง ฺฉู ุงูฺฏุงุฑ ุญุฑุต ูุงูู ู ุญุช ฺุดู ุจู ุจูฺู ูุงุฏุฑุดูู ุฏุงุฑู .\n",
            "ุฌุงฺฏุงู ู ุงุฑุฒุด ูุงุฏุฑ ูู ูุซู ุงูฺฉู ุชุนุฑู ูุฏุงุดุช ุจุฑุงุดูู..\n",
            "ุจุงุงู ุชุนุฏุงุฏ ุงุฒ ูุฑุฒูุฏ ูู ุจุงุฒู ูุฌุจูุฑ ุจุงุด ฺฏุฏุง ฺฉู ุ\n",
            "ุจฺู ูุง ฺฉู ุงูฺฏุงุฑ ุญุฑุต ูุงูู ู ุญุช ฺุดู ุจู ุจูฺู ูุงุฏุฑุดูู ุฏุงุฑู .\n",
            "ุฌุงฺฏุงู ู ุงุฑุฒุด ูุงุฏุฑ ูู ูุซู ุงูฺฉู ุชุนุฑู ูุฏุงุดุช ุจุฑุงุดูู..\n",
            "ุฎู ูุงุฑุงุญุช ฺฉููุฏู ุงุณุช๐\n",
            "ุฎู ูุงุฑุงุญุช ฺฉููุฏู ุงุณุช\n",
            "ุนุงู ุจูุฏ ุจ ูุธุฑ ุจูุฏ ูุงูุนุง ุฏุณุช ููุณูุฏู ุฏุฑุฏ ูฺฉูู\n",
            "ุนุงู ุจูุฏ ุจ ูุธุฑ ุจูุฏ ูุงูุนุง ุฏุณุช ููุณูุฏู ุฏุฑุฏ ูฺฉูู\n",
            "ฺฏุฏุง ุจุฑุง ุณุงุฏุงุช ุญุฑุงู ุงุณุช. ุดุงุฏ ููุณูุฏู ูพุฏุง ฺฉุฑุฏู ุฏูู ูุฎุงููุช ุจฺู ูุง ุฑู ุจู ุนูุฏู ุฎูุงููุฏู ฺฏุฐุงุดุชู.\n",
            "ฺฏุฏุง ุจุฑุง ุณุงุฏุงุช ุญุฑุงู ุงุณุช. ุดุงุฏ ููุณูุฏู ูพุฏุง ฺฉุฑุฏู ุฏูู ูุฎุงููุช ุจฺู ูุง ุฑู ุจู ุนูุฏู ุฎูุงููุฏู ฺฏุฐุงุดุชู.\n",
            "ุฏุงุณุชุงู ฺฏุฑุง ุฎูุจ ุฏุงุดุช ูู ุงุตูุงู ูุชููุณุชู ุฏุฑฺฉุด ฺฉูู ุนู ฺฉู ฺ ฺฏุฏุง ุซูุงุจ ุฏุงุฑู !\n",
            "ุฏุงุณุชุงู ฺฏุฑุง ุฎูุจ ุฏุงุดุช ูู ุงุตูุงู ูุชููุณุชู ุฏุฑฺฉุด ฺฉูู ุนู ฺฉู ฺ ฺฏุฏุง ุซูุงุจ ุฏุงุฑู !\n",
            "ฺฉุงุด ุงู ูุตู ูุงูุน ูุจุงุดุฏ...\n",
            "ฺฉุงุด ูฺ \"ุณุฏ ุฎุงูู\" ูุจุงุดุฏ.\n",
            "ุญุช ุฎูุงูุฏู ุฏุงุณุชุงูุด ูู ุณุฎุช ุงุณุชุฺู ุจุฑุณุฏ ุจู...\n",
            "ฺฉุงุด ุงู ูุตู ูุงูุน ูุจุงุดุฏ...\n",
            "ฺฉุงุด ูฺ \"ุณุฏ ุฎุงูู\" ูุจุงุดุฏ.\n",
            "ุญุช ุฎูุงูุฏู ุฏุงุณุชุงูุด ูู ุณุฎุช ุงุณุชุฺู ุจุฑุณุฏ ุจู...\n",
            "ุฎู ุบูฺฏู ุจูุฏ๐\n",
            "ุฎู ุบูฺฏู ุจูุฏ\n",
            "ุจู ุดุฏุช ุชุฑุณุฏูุ ุงู ููู ุจ ููุง ุจู ูุงุฏุฑ ูุงูุนุง ูุญุดุชูุงฺฉู.\n",
            "ุจู ุดุฏุช ุชุฑุณุฏูุ ุงู ููู ุจ ููุง ุจู ูุงุฏุฑ ูุงูุนุง ูุญุดุชูุงฺฉู.\n",
            "ุฎู ุบู ุงูฺฏุฒ ุจูุฏ ู ุชุงุซุฑ ฺฏุฐุงุฑ๐ข๐ข\n",
            "ุฎู ุบู ุงูฺฏุฒ ุจูุฏ ู ุชุงุซุฑ ฺฏุฐุงุฑ\n",
            "ุณูุงู ู ูุฏุช ุจู ูู ุชุญูุช ูุฒุฏู ุงุฒ ุจฺู ูุง ุงุฏุงุฑู .ููู ููุน ุชููุช ฺฉู ูุงู ุฎูุฏุดูู ุจูุฏ ุจู ูู ูฺฏูุชู .ุจุนุฏุงุฒ ูุฏุชูุง ฺฏุฐุดุช ุฏุฑ ุทุฑุดุช ฺฉูฺู ูุฑุฒูุงู ูพูุงฺฉ 14ุจุงุบ ุจูุฏ ุฏุงุฎูุด ุชุนูุฑฺฏุงู ุจูุฏ ุงูุฑุงุฏ ฺฉู ุจุณุงุฑ ุนุดู ฺุดู ุชู ฺุดู ุฏุงุดุชู ุจุง ูุงููุฑุงู ูุงู ุฏุงุฎู ุจุงุบ ฺฉู ฺฉุณุฑุน ูุนุชุงุฏ ููุตุฑู ฺฉููุฏู ุจฺฏุฑู ููููู ุทุฑู ฺฉู ฺุดู ุฏุฑฺุดู ุฎู ุฏูุณุช ุฏุงุฑู ุจุง ูุงููุฑูุง ูุงุฏ ุนู ุงูู ูุงููุฑูุง ุฑู ูุงุฑู ุฎูุฏุดู ูุดูู ุจู ูุตุฑู ุจุง ุฒุฑ ูุฑู ุงูุฑุงุฏ ุฏุณุชฺฏุฑ ูุดู ููุงู ุจุฑูู ุงุฒ ฺฉู ุจุฑู ุณูุงุฑูุงุดู ุจุดู ฺุดู ุฏุฑฺุดู ุงุฒุงุฏ ูุดู ูู ุจุงู ุงูุฑุงุฏ ูุจุฑู ุจุนุฏ ุจู ุฏฺฏุฑูู ูฺฏู ุงุฏู ูุฑูุด ุงููฺฏ ุดุงุฏููุฑ ุนูู ุงุฏู ูุฑูุด ุงููฺฏ ูุดูฺฏู\n",
            "ุณูุงู ู ูุฏุช ุจู ูู ุชุญูุช ูุฒุฏู ุงุฒ ุจฺู ูุง ุงุฏุงุฑู .ููู ููุน ุชููุช ฺฉู ูุงู ุฎูุฏุดูู ุจูุฏ ุจู ูู ูฺฏูุชู .ุจุนุฏุงุฒ ูุฏุชูุง ฺฏุฐุดุช ุฏุฑ ุทุฑุดุช ฺฉูฺู ูุฑุฒูุงู ูพูุงฺฉ 14ุจุงุบ ุจูุฏ ุฏุงุฎูุด ุชุนูุฑฺฏุงู ุจูุฏ ุงูุฑุงุฏ ฺฉู ุจุณุงุฑ ุนุดู ฺุดู ุชู ฺุดู ุฏุงุดุชู ุจุง ูุงููุฑุงู ูุงู ุฏุงุฎู ุจุงุบ ฺฉู ฺฉุณุฑุน ูุนุชุงุฏ ููุตุฑู ฺฉููุฏู ุจฺฏุฑู ููููู ุทุฑู ฺฉู ฺุดู ุฏุฑฺุดู ุฎู ุฏูุณุช ุฏุงุฑู ุจุง ูุงููุฑูุง ูุงุฏ ุนู ุงูู ูุงููุฑูุง ุฑู ูุงุฑู ุฎูุฏุดู ูุดูู ุจู ูุตุฑู ุจุง ุฒุฑ ูุฑู ุงูุฑุงุฏ ุฏุณุชฺฏุฑ ูุดู ููุงู ุจุฑูู ุงุฒ ฺฉู ุจุฑู ุณูุงุฑูุงุดู ุจุดู ฺุดู ุฏุฑฺุดู ุงุฒุงุฏ ูุดู ูู ุจุงู ุงูุฑุงุฏ ูุจุฑู ุจุนุฏ ุจู ุฏฺฏุฑูู ูฺฏู ุงุฏู ูุฑูุด ุงููฺฏ ุดุงุฏููุฑ ุนูู ุงุฏู ูุฑูุด ุงููฺฏ ูุดูฺฏู\n",
            "ุงุฑุฒุด ุฎููุฏู ูุฏุงุฑู!\n",
            "ุงุฑุฒุด ุฎููุฏู ูุฏุงุฑู!\n",
            "ุงฺฏุฑ ุงู ุฏุงุณุชุงู ุฑูุงุช ูุตุงุฆุจ ูพุฑ ู ุจ ุนุฏุงูุช ุฏุฑ ุญู ุฒูุงู ุจุงุดู ูู ุฏุฑฺฉุด ูโฺฉูู.\n",
            "ุงูุง ุฏุงุณุชุงู ูพุฑ ุจูุฏ ุงุฒ ููุงุฏูุง ฺฉู ูู ูุชููุณุชู ุฏุฑฺฉ ฺฉูู..\n",
            "ูุซูุงู ุซูุงุจ ฺฏุฏุง ุจูุงุฎุต ฺฉู ุฏุฑ ุฌุง ูพุฑุช ู ุชุงุฑฺฉ ุจุงุดู..\n",
            "ุญูุงู ฺฉู ุฎุงฺฉ ุฒูู ุฑู ูุณ ูุฒุฏ...\n",
            "ุดูุงู ุญุถุฑุช ู....\n",
            "ุฏุงุณุชุงู ฺฏุฑุง ุจูุฏ ูู ููุชููู ุจฺฏู ุฎูุจ ุจูุฏ ฺูู ุงุฒ ุฏุงุณุชุงูโูุง ฺฉู ุงุจูุงู ุขููุฏ ุจุงุดู ูุฐุช ููโุจุฑู\n",
            "ุงฺฏุฑ ุงู ุฏุงุณุชุงู ุฑูุงุช ูุตุงุฆุจ ูพุฑ ู ุจ ุนุฏุงูุช ุฏุฑ ุญู ุฒูุงู ุจุงุดู ูู ุฏุฑฺฉุด ูโฺฉูู.\n",
            "ุงูุง ุฏุงุณุชุงู ูพุฑ ุจูุฏ ุงุฒ ููุงุฏูุง ฺฉู ูู ูุชููุณุชู ุฏุฑฺฉ ฺฉูู..\n",
            "ูุซูุงู ุซูุงุจ ฺฏุฏุง ุจูุงุฎุต ฺฉู ุฏุฑ ุฌุง ูพุฑุช ู ุชุงุฑฺฉ ุจุงุดู..\n",
            "ุญูุงู ฺฉู ุฎุงฺฉ ุฒูู ุฑู ูุณ ูุฒุฏ...\n",
            "ุดูุงู ุญุถุฑุช ู....\n",
            "ุฏุงุณุชุงู ฺฏุฑุง ุจูุฏ ูู ููุชููู ุจฺฏู ุฎูุจ ุจูุฏ ฺูู ุงุฒ ุฏุงุณุชุงูโูุง ฺฉู ุงุจูุงู ุขููุฏ ุจุงุดู ูุฐุช ููโุจุฑู\n",
            "ุนุงู ุจูุฏ\n",
            "ูุงูุนุง ุงูู ูพุฑุฒู ฺูุฏ ุจฺุงุฑู ุจูุฏ. ฺู ุจฺู ูุง ุจ ุงุญุณุงุณ๐ข\n",
            "ุนุงู ุจูุฏ\n",
            "ูุงูุนุง ุงูู ูพุฑุฒู ฺูุฏ ุจฺุงุฑู ุจูุฏ. ฺู ุจฺู ูุง ุจ ุงุญุณุงุณ\n",
            "ุฎู ูพุฑ ุฏุฑุฏ ู ุบูฺฏู....\n",
            "ุฎู ูพุฑ ุฏุฑุฏ ู ุบูฺฏู....\n",
            "ุฎู ุฒุจุง ุชูุตู ุดุฏู ุจูุฏ ู ุจุณุงุงุงุงุงุงุงุงุงุงุฑ ุบู ุงูฺฏุฒ ุจูุฏ...ุฏู ุขุฏู ุฑู ุจู ุฏุฑุฏ ูุงุฑู\n",
            "ุฎู ุฒุจุง ุชูุตู ุดุฏู ุจูุฏ ู ุจุณุงุงุงุงุงุงุงุงุงุงุฑ ุบู ุงูฺฏุฒ ุจูุฏ...ุฏู ุขุฏู ุฑู ุจู ุฏุฑุฏ ูุงุฑู\n",
            "ูุงูุนุง ุนุงู ุจูุฏ\n",
            "ููุท ูู ููููุฏู ฺุฑุง ฺฏุฏุง ุซูุงุจ ุฏุงุดุช ุงุฒ ูุธุฑุด!\n",
            "ฺูุฏุฑ ุชูุฎ ุจูุฏ..ุฏูู ุณูุฎุช\n",
            "ูุงูุนุง ุนุงู ุจูุฏ\n",
            "ููุท ูู ููููุฏู ฺุฑุง ฺฏุฏุง ุซูุงุจ ุฏุงุดุช ุงุฒ ูุธุฑุด!\n",
            "ฺูุฏุฑ ุชูุฎ ุจูุฏ..ุฏูู ุณูุฎุช\n",
            "ุฏุงุณุชุงู ุจู ุฎูุจ ุชุนุฑู ุดุฏูุ ุชูุตู ูุง ุนุงู ูุณุชู ูู ููุถูุน ุฏุงุณุชุงู ุนุตุจู ฺฉุฑุฏุ ุขุฎู ฺุฑุง ุจุงุฏ ฺฉ ุฎูุดุด ุจุงุฏ ฺฏุฏุง ฺฉูู\n",
            "ุฏุงุณุชุงู ุจู ุฎูุจ ุชุนุฑู ุดุฏูุ ุชูุตู ูุง ุนุงู ูุณุชู ูู ููุถูุน ุฏุงุณุชุงู ุนุตุจู ฺฉุฑุฏุ ุขุฎู ฺุฑุง ุจุงุฏ ฺฉ ุฎูุดุด ุจุงุฏ ฺฏุฏุง ฺฉูู\n",
            "ุจู ูุธุฑู (ููุท ุฏุฑ ุญุฏ ู ูุธุฑ) ุขุดูุชฺฏ ุฏุงุณุชุงู ู ูพุฑุด ุดุฎุตุช ุจุงุนุซ ูุดุฏ ุขุดูุชฺฏ ุงูุถุงุน ูพุฑุฒู ู ูุดูุด ุจูุฏู ุฐููุด ู ุงูฺฉู ูุฑ ูุญุธู ุงุฒ ฺฉ ู ุชุฑุณู ููููุณ ุชุฑ ุจุดู ู ูุงุจู ุชุตูุฑ ุชุฑ ุจุงุดู. ุฏุฑ ฺฉู ุจู ูุธุฑู ุฒุจุง ุจูุฏ.\n",
            "ุจู ูุธุฑู (ููุท ุฏุฑ ุญุฏ ู ูุธุฑ) ุขุดูุชฺฏ ุฏุงุณุชุงู ู ูพุฑุด ุดุฎุตุช ุจุงุนุซ ูุดุฏ ุขุดูุชฺฏ ุงูุถุงุน ูพุฑุฒู ู ูุดูุด ุจูุฏู ุฐููุด ู ุงูฺฉู ูุฑ ูุญุธู ุงุฒ ฺฉ ู ุชุฑุณู ููููุณ ุชุฑ ุจุดู ู ูุงุจู ุชุตูุฑ ุชุฑ ุจุงุดู. ุฏุฑ ฺฉู ุจู ูุธุฑู ุฒุจุง ุจูุฏ.\n",
            "ูุงูุนุง ฺฏุฑู ุงู ฺฏุฑูุช\n",
            "ูุงูุนุง ฺฏุฑู ุงู ฺฏุฑูุช\n",
            "ุจูุธุฑ ูู ููู ุงุซุงุฑ ุฏฺฉุชุฑ ุณุงุนุฏ ุจุง ุงุฑุฒุด ูุฎูุงูุฏู ุงุณุช ูุฑฺฉุณ ฺฉู ุงุซุงุฑ ุฏฺฉุชุฑ ุฑุง ุจุฎููู ุจูุธุฑู ููุชุด ุจููุฏู ูฺฏุฐุดุชู ุงุณุช ุงุฑุฒุด ุฎููุฏู ุฏุงุฑู ุุฑูุญุด ุดุงุฏ\n",
            "ุจูุธุฑ ูู ููู ุงุซุงุฑ ุฏฺฉุชุฑ ุณุงุนุฏ ุจุง ุงุฑุฒุด ูุฎูุงูุฏู ุงุณุช ูุฑฺฉุณ ฺฉู ุงุซุงุฑ ุฏฺฉุชุฑ ุฑุง ุจุฎููู ุจูุธุฑู ููุชุด ุจููุฏู ูฺฏุฐุดุชู ุงุณุช ุงุฑุฒุด ุฎููุฏู ุฏุงุฑู ุุฑูุญุด ุดุงุฏ\n",
            "ุงุตูุง ุฎูุดู ูููุฏ ูพุฑุฒูู ุงุฒ ฺฏุฏุง ุฎูุดุด ูููุฏ ๐\n",
            "ุงุตูุง ุฎูุดู ูููุฏ ูพุฑุฒูู ุงุฒ ฺฏุฏุง ุฎูุดุด ูููุฏ \n",
            "che dardnak\n",
            "che dardnak\n",
            "ููุท ูุชููู ุจฺฏู ุงูุฏูุงุฑู ุฏุฑ ุขูุฏู ููฺู ูุฑุฒูุฏ ูุงุณู ูพุฏุฑ ู ูุงุฏุฑู ูุจุงุดู\n",
            "ููุท ูุชููู ุจฺฏู ุงูุฏูุงุฑู ุฏุฑ ุขูุฏู ููฺู ูุฑุฒูุฏ ูุงุณู ูพุฏุฑ ู ูุงุฏุฑู ูุจุงุดู\n",
            "ุฎู ุนุงู ุจูุฏ ู ุบู ุงูฺฏุฒ\n",
            "ุฎู ุนุงู ุจูุฏ ู ุบู ุงูฺฏุฒ\n",
            "ูู ุตูุชุดู ฺฏูุด ฺฉุฑุฏู.. ุฎู ุบูฺฏู ุจูุฏ ู ุฏูู ุจุฑุง ูพุฑุฒูู ูุณูุฎุช.. ุชูุตู ูุงุด ุฎู ุฎูุจ ุจูุฏู ู ุขุฏู ุชูุงู ุงูู ูุง ุฑู ุฑุงุญุช ุชุตูุฑ ูฺฉุฑุฏ..\n",
            "ูู ุตูุชุดู ฺฏูุด ฺฉุฑุฏู.. ุฎู ุบูฺฏู ุจูุฏ ู ุฏูู ุจุฑุง ูพุฑุฒูู ูุณูุฎุช.. ุชูุตู ูุงุด ุฎู ุฎูุจ ุจูุฏู ู ุขุฏู ุชูุงู ุงูู ูุง ุฑู ุฑุงุญุช ุชุตูุฑ ูฺฉุฑุฏ..\n",
            "ุฎู ุบู ุงูฺฏุฒ ุงูุง ูุงูุน ...\n",
            "ุฎู ุบู ุงูฺฏุฒ ุงูุง ูุงูุน ...\n",
            "ูุดูฺฏ ุจูุฏ ู ุฎู ุบูฺฏู\n",
            "ูุดูฺฏ ุจูุฏ ู ุฎู ุบูฺฏู\n",
            "ูุดูฺฏ ุงูุง ูุงุฑุงุญุช ฺฉููุฏู ุชูุฎ ุงูุง ูุงูุน\n",
            "ูุดูฺฏ ุงูุง ูุงุฑุงุญุช ฺฉููุฏู ุชูุฎ ุงูุง ูุงูุน\n",
            "ุชุงูู ุจุฑุงูฺฏุฒ ุฒุจุงุงุงุงุงุง โค๏ธโค๏ธโค๏ธ\n",
            "ุชุงูู ุจุฑุงูฺฏุฒ ุฒุจุงุงุงุงุงุง \n",
            "ุฌุฐุงุจุุบู ุงูฺฏุฒุุชุงุซุฑ ฺฏุฐุงุฑ ู ...\n",
            "ุงุดฺฉ ุขุฏูู ุฏุฑูุงุฑู.. ุบุฑุจ ุงู ูพุฑุฒู...\n",
            "ุฌุฐุงุจุุบู ุงูฺฏุฒุุชุงุซุฑ ฺฏุฐุงุฑ ู ...\n",
            "ุงุดฺฉ ุขุฏูู ุฏุฑูุงุฑู.. ุบุฑุจ ุงู ูพุฑุฒู...\n",
            "ุบู ุงูฺฏุฒ , ุฒุจุง , ุชุงุซุฑฺฏุฐุงุฑ\n",
            "ุบู ุงูฺฏุฒ , ุฒุจุง , ุชุงุซุฑฺฏุฐุงุฑ\n",
            "ุจุณุงุฑ ุบูฺฏู ู ุงูุฑุงู ุขูุฒ\n",
            "ุจุณุงุฑ ุบูฺฏู ู ุงูุฑุงู ุขูุฒ\n",
            "ุฎู ูุดูฺฏ ุจูุฏ .\n",
            "ุฎู ูุดูฺฏ ุจูุฏ .\n",
            "ูุดูฺฏ ุจูุฏ...\n",
            "ูุดูฺฏ ุจูุฏ...\n",
            "ุจู ูุธุฑ ูู ุฌุฏุง ุงุฒ ุฑุงุจุทู ูุงุฏุฑ ู ูุฑุฒูุฏ ู ุจ ููุง ุจฺู ูุงุด ุจุดุชุฑ ูุดูู ุฏููุฏู ูููุนุช ุฒู ุชู ุฌุงูุนู ุงุณ ุฏุฑูู ุฒูุงู ููุช ฺฉู ูุงุฏุฑ ุงุฌุงุฒู ูุฏุงุฑู ูุณุงู ุฎูุฏุดู ุงุณุชูุงุฏู ฺฉูู ู ููุท ุจุงุฏ ุฌุง ุจูููู ุชุง ููุช ูุฑุฏ ุชูุณู ุจุดู . ููุช ุดููุฑ ุฒู ููุฑู ุงูู ูฺ ูพุดุชูุงูู ุง ูุฏุงุฑู ู ุฏุฎุชุฑุด ุงุฒ ุชุฑุณ ุดููุฑุด ููุท ุจุงุฏ ุชู ุฎููู ุฒุงุฑ ุจุฒูู ู ูุฏุฑุช ูฺ ุญูุงุช ุงุฒ ูุงุฏุฑุดู ูุฏุงุฑู\n",
            "ุจู ูุธุฑ ูู ุฌุฏุง ุงุฒ ุฑุงุจุทู ูุงุฏุฑ ู ูุฑุฒูุฏ ู ุจ ููุง ุจฺู ูุงุด ุจุดุชุฑ ูุดูู ุฏููุฏู ูููุนุช ุฒู ุชู ุฌุงูุนู ุงุณ ุฏุฑูู ุฒูุงู ููุช ฺฉู ูุงุฏุฑ ุงุฌุงุฒู ูุฏุงุฑู ูุณุงู ุฎูุฏุดู ุงุณุชูุงุฏู ฺฉูู ู ููุท ุจุงุฏ ุฌุง ุจูููู ุชุง ููุช ูุฑุฏ ุชูุณู ุจุดู . ููุช ุดููุฑ ุฒู ููุฑู ุงูู ูฺ ูพุดุชูุงูู ุง ูุฏุงุฑู ู ุฏุฎุชุฑุด ุงุฒ ุชุฑุณ ุดููุฑุด ููุท ุจุงุฏ ุชู ุฎููู ุฒุงุฑ ุจุฒูู ู ูุฏุฑุช ูฺ ุญูุงุช ุงุฒ ูุงุฏุฑุดู ูุฏุงุฑู\n",
            "ููฺฉู ุฎูุดู ูููุฏ...ุฑุงู ฺฉู ุฎูุฏ ฺฏุฏุงุณ ุจูุธุฑ ุฎูุจ ุนุงููู  ููู ฺ ุฑู ููููู ุงูุง ุจู ุฏูฺฏ ุนุงุฏุช ฺฉุฑุฏู ู ููุชููู ุฏุณุช ุงุฒ ฺฏุฏุง ุจุฑุฏุงุฑู....ุงู ููุฌูุฏ ุงููุฏ ุชูุงูุง ุฏุงุฑู ูุชููุณ ุชู ุฎููู ุฏฺฏุฑุงู ฺฉุงุฑ ฺฉูู  ูุดุฑุงูุชููุฏุงูู ุฒูุฏฺฏ ฺฉูู ู ุจฺู ูุงุด ูู ุจุดุชุฑ ููุงุดู ุฏุงุดุชู ุงูุง ุขุจุฑู ุจุฑุง  ุจฺู ูุงุด ูุฐุงุดุชู ุจูุฏ ูุงุณู  ููู ุจฺู ูุง ุงุฒุด ุฏูุฑ ูฺฉุฑุฏู.\n",
            "ููฺฉู ุฎูุดู ูููุฏ...ุฑุงู ฺฉู ุฎูุฏ ฺฏุฏุงุณ ุจูุธุฑ ุฎูุจ ุนุงููู  ููู ฺ ุฑู ููููู ุงูุง ุจู ุฏูฺฏ ุนุงุฏุช ฺฉุฑุฏู ู ููุชููู ุฏุณุช ุงุฒ ฺฏุฏุง ุจุฑุฏุงุฑู....ุงู ููุฌูุฏ ุงููุฏ ุชูุงูุง ุฏุงุฑู ูุชููุณ ุชู ุฎููู ุฏฺฏุฑุงู ฺฉุงุฑ ฺฉูู  ูุดุฑุงูุชููุฏุงูู ุฒูุฏฺฏ ฺฉูู ู ุจฺู ูุงุด ูู ุจุดุชุฑ ููุงุดู ุฏุงุดุชู ุงูุง ุขุจุฑู ุจุฑุง  ุจฺู ูุงุด ูุฐุงุดุชู ุจูุฏ ูุงุณู  ููู ุจฺู ูุง ุงุฒุด ุฏูุฑ ูฺฉุฑุฏู.\n",
            "ุจู ูุธุฑู  ุญฺฉุงุช ูพุฑ ู ุจฺู ูุง ุจ ุงูุตุงู ุฑู ุฎู ุฎูุจ ุจุงู ฺฉุฑุฏ. ุจู ูุธุฑุชุงู ุจฺู ูุง ูุง ุจุง ูุง ฺุทูุฑ ุฑูุชุงุฑ ูฺฉููุฏ ุ\n",
            "ุจู ูุธุฑู  ุญฺฉุงุช ูพุฑ ู ุจฺู ูุง ุจ ุงูุตุงู ุฑู ุฎู ุฎูุจ ุจุงู ฺฉุฑุฏ. ุจู ูุธุฑุชุงู ุจฺู ูุง ูุง ุจุง ูุง ฺุทูุฑ ุฑูุชุงุฑ ูฺฉููุฏ ุ\n",
            "ุฎู ุนุงู ุจูุฏ . ูุง ุจุงุฏ ูุฏุฑ ูุงุฏุฑุงูููู ุจุฏููู . ุงูู ูพุฑุฒู ุจฺู ุฒุงุฏ ุฏุงุดุช ุงูุง ุฎู ุชููุง ุจูุฏ ู ุฌุฒ ุจูฺู ู ุดูุงูุด ุฏฺฏู ฺุฒ ูุฏุงุดุช . ูุฑ ุฌููู  ุงู ฺฉุชุงุจ ุ ุฏุฑุณ ุงุณุช ุจุฑุง ููู  ูุง ฺฉู ุงุญุชุฑุงู ุงู ูุฑุดุชู  ููุฑุจุงู ุฑู ูฺฏู ุฏุงุฑู . ุจุงุฏ ุณุน ฺฉูู ฺฉู ูู ุงุญุชุฑุงู ูุงุฏุฑ ุฑู ูฺฏู ุฏุงุฑู ู ูู ุนู ูพุฑูุงูู ุฏูุฑุด ุจฺุฑุฎู ฺฉู ุฎุฏุง ูฺฉุฑุฏู ุญุณุงุณ ุชููุง ูฺฉูู .\n",
            "ุฎู ุนุงู ุจูุฏ . ูุง ุจุงุฏ ูุฏุฑ ูุงุฏุฑุงูููู ุจุฏููู . ุงูู ูพุฑุฒู ุจฺู ุฒุงุฏ ุฏุงุดุช ุงูุง ุฎู ุชููุง ุจูุฏ ู ุฌุฒ ุจูฺู ู ุดูุงูุด ุฏฺฏู ฺุฒ ูุฏุงุดุช . ูุฑ ุฌููู  ุงู ฺฉุชุงุจ ุ ุฏุฑุณ ุงุณุช ุจุฑุง ููู  ูุง ฺฉู ุงุญุชุฑุงู ุงู ูุฑุดุชู  ููุฑุจุงู ุฑู ูฺฏู ุฏุงุฑู . ุจุงุฏ ุณุน ฺฉูู ฺฉู ูู ุงุญุชุฑุงู ูุงุฏุฑ ุฑู ูฺฏู ุฏุงุฑู ู ูู ุนู ูพุฑูุงูู ุฏูุฑุด ุจฺุฑุฎู ฺฉู ุฎุฏุง ูฺฉุฑุฏู ุญุณุงุณ ุชููุง ูฺฉูู .\n",
            "ู ุฎูุฑุฏู ุจุด ุงุฒ ุญุฏ ุฎุงู ูุจูุฏุ ุงููุฏุฑ ุจุฏู ูพุฏุง ูุดู\n",
            "ู ุฎูุฑุฏู ุจุด ุงุฒ ุญุฏ ุฎุงู ูุจูุฏุ ุงููุฏุฑ ุจุฏู ูพุฏุง ูุดู\n",
            "๐ข๐ข๐ข๐ข๐ข๐ข๐ข๐ข๐ข๐ข๐ข๐ข๐ข๐ข๐ข\n",
            "ูุฏุฑ ูุงุฏุฑุงูููู ุจุฏููู\n",
            "๐ข๐ข๐ข๐ข๐ข๐ข\n",
            "\n",
            "ูุฏุฑ ูุงุฏุฑุงูููู ุจุฏููู\n",
            "\n",
            "ุฎู ุบู ุงูฺฏุฒ ...\n",
            "ูุฑ ุณุทุฑ ุงู ฺฉุชุงุจ ุฑู ฺฉู ู ุฎููุ ฺู ูุงุฏุฑุช ุฏุฑ ูุฏ ุญุงุช ุจุงุดูุ ฺู ุงุฒ ุฏุณุชุด ุฏุงุฏู ุจุงุดุ ุงุฏุด ููุช ู ูฺฏ ุจุงูุงุด ุจุฏ ฺฉุฑุฏู :(\n",
            "ุฎู ุบู ุงูฺฏุฒ ...\n",
            "ูุฑ ุณุทุฑ ุงู ฺฉุชุงุจ ุฑู ฺฉู ู ุฎููุ ฺู ูุงุฏุฑุช ุฏุฑ ูุฏ ุญุงุช ุจุงุดูุ ฺู ุงุฒ ุฏุณุชุด ุฏุงุฏู ุจุงุดุ ุงุฏุด ููุช ู ูฺฏ ุจุงูุงุด ุจุฏ ฺฉุฑุฏู :(\n",
            "ุณูุงู\n",
            "ุณูุงู\n",
            "ุนุงู ุจูุฏ.\n",
            "ุนุงู ุจูุฏ.\n",
            "ูุตู ุงุฒ ุฏุฑุฏ ู ุฑูุฌ ู ูุญูุช ุทุจูุงุช ูุญุฑูู ู ุขุณุจ ุฏุฏู ุงุณุช (ูุถุง ุญุฒู ุขููุฏ ุญุงฺฉู ุจุฑ ุงู ุฏุงุณุชุงูุ ููู ุงุฏ ุจ ุณุฑูพุฑุณุชุงู ' ูุฏุณ ูุตุฑ' ุงูุฏุงุฎุช). ูุตู ุงุฒ ุฌูู ู ูุงุฏุงู ูุฑุฏูุงูุ ุงุฒ ุจ ุงุนุชูุง ูุฑุฒูุฏุงู ูุณุจุช ุจู ูุงุฏุฑู ฺฉู ูุงุฒ ุจู ุขูุฑุฏู ูุซุงู ู ูุตุฏุงู ูุฏุงุฑู ู ุฏุฑ ุฌุง ุฌุง ุฏุงุณุชุงู ุจู ฺุดู ูุฎูุฑูุ ุงุฒ ุจ ุงุนุชูุง ูุฑุฏูุงู ูุณุจุช ุจู ูู ูุซูุง ุฌุง ฺฉู ูพุฑุฒู ุฑูุถู ูุฎููู ู ฺฏุฑู ูฺฉููุ ูุฑุฏู ุฏูุฑุด ุญููู ูุฒูู ู ุจู ุฌุง ฺฉูฺฉ ุง ุญุฏุงูู ุชุงุซุฑุ ุจู ูพุฑุฒู  ูุฎูุฏู! ุจ ุงุนุชูุง ูุณุจุช ุจู ุฑูุฌ ฺฉุดุฏฺฏุงู ู ุฏุฑุฏููุฏุงู ูุซูุง  ุฌุง ฺฉู ูพุฑุฒู ฺฉูุด ูุงุดู ฺฏู ูฺฉูู ู ฺฉุณ ูุณุช ฺฉู ุจูพุฑุณู ูพุงุจุฑููู ฺุทูุฑ ุฑุงู ูุฑุ!  ุงุฒ ูููุนุช ุทูุจ ุฏุฑ ูุฑ ุดุฑุงุท ูุซูุง ุฌุง ฺฉู ุงููู ุฏุฑ ุขู ูุฑู ูุฑ ุฒุงุฑ ุฒุงุฑ ฺฏุฑู ูฺฉูู ฺฉู ฺุฑุง ฺุฒ ุจูุด ูุฑุณุฏู! ุง ูพุฑูุฑุฏ ุฌูู ุฏุฑ ฺฏุฏุงุฎุงููุ ฺฉู ูุตู ฺฉุชู ู ูพุงุฒ ูพุฑุฒู ุฑู ุจุฑูุฏุงุฑู. \n",
            " ู ูู ุจู ุดุฎุตู ุนูุงูู ุฒุงุฏ ุจู ุงู ุทุฑุฒ ุฑูุงุช ุงุฒ ุฌุงูุนู ู ูุงูุน ุจู ููุฌูุฏ ุฏุฑ ุงูู -ุญุฏุงูู ุจุฎุด ุงุฒ ุฌุงูุนู- ุฏุงุฑูุ ุจู ุชููฺฏุฑ ฺฉู ููุณูุฏู ุจู ุทูุฑ ูุงูุฑุงูู ุง ุฏุฑ ูุงูุจ ฺฉ ุฏุงุณุชุงู ุจู ุธุงูุฑ ุณุงุฏู ุจู ูุฑุฏู ู ุฎูุงููุฏฺฏุงู ุฏุงุณุชุงูุด ูุฒูู.\n",
            "ุจู ูุธุฑ ููุ ุฏุฑ ุงู ุฏุงุณุชุงู ูพุฑุฒู ููุงุฏ ู ููุงูุฏู ุง ูุดู ุชุง ููู ุฌุง ุณุฑฺฉ ุจฺฉุดู ู ุงู ุฏุฑุฏูุง ุฑู ุฑูุงุช ฺฉูู. ูพุฑุฒู ุจูุงูู ุง ูุดู ุชุง ุจุง ุงู ุจู ุดูุฑุ ุฏูุ ุญุฑูุ ฺฏูุฑุณุชุงู ู ฺฏุฏุงุฎุงูู ู... ุจุฑู ู ุจุง ุงูุฑุงุฏ ูุฎุชูู ฺฉู ุจุง ูพุฑุฒู ุฑูุจุฑู ูุดู ุขุดูุง ุจุดู.\n",
            "\n",
            "ุจุฑุฎ ุงุฒ ููุชูุฏู \"ฺฏุฏุง\" ุฑู ุจุง ุงุตูู ูฺฉุชุจ ููุณู ุงฺฏุฒุณุชุงูุณุงูุณู (ุชูุฏู ูุฌูุฏ ุจุฑ ูุงูุช) ู ููุงูู ูุฑุชุจุท ุจุง ุงูู ูุงููุฏ ุขุฒุงุฏุ ุขูุงุฑฺฏุ ุฏููุฑู ู ููุณุชุงูฺ ููุฑุฏ ุจุฑุฑุณ ูุฑุงุฑ ุฏุงุฏู ฺฉู ูุทุงูุนู ุด ุฎุงู ุงุฒ ูุทู ูุณุช.\n",
            "\n",
            "ุงุฒ ุทุงูฺู ูู ูููููู.\n",
            "ูุตู ุงุฒ ุฏุฑุฏ ู ุฑูุฌ ู ูุญูุช ุทุจูุงุช ูุญุฑูู ู ุขุณุจ ุฏุฏู ุงุณุช (ูุถุง ุญุฒู ุขููุฏ ุญุงฺฉู ุจุฑ ุงู ุฏุงุณุชุงูุ ููู ุงุฏ ุจ ุณุฑูพุฑุณุชุงู ' ูุฏุณ ูุตุฑ' ุงูุฏุงุฎุช). ูุตู ุงุฒ ุฌูู ู ูุงุฏุงู ูุฑุฏูุงูุ ุงุฒ ุจ ุงุนุชูุง ูุฑุฒูุฏุงู ูุณุจุช ุจู ูุงุฏุฑู ฺฉู ูุงุฒ ุจู ุขูุฑุฏู ูุซุงู ู ูุตุฏุงู ูุฏุงุฑู ู ุฏุฑ ุฌุง ุฌุง ุฏุงุณุชุงู ุจู ฺุดู ูุฎูุฑูุ ุงุฒ ุจ ุงุนุชูุง ูุฑุฏูุงู ูุณุจุช ุจู ูู ูุซูุง ุฌุง ฺฉู ูพุฑุฒู ุฑูุถู ูุฎููู ู ฺฏุฑู ูฺฉููุ ูุฑุฏู ุฏูุฑุด ุญููู ูุฒูู ู ุจู ุฌุง ฺฉูฺฉ ุง ุญุฏุงูู ุชุงุซุฑุ ุจู ูพุฑุฒู  ูุฎูุฏู! ุจ ุงุนุชูุง ูุณุจุช ุจู ุฑูุฌ ฺฉุดุฏฺฏุงู ู ุฏุฑุฏููุฏุงู ูุซูุง  ุฌุง ฺฉู ูพุฑุฒู ฺฉูุด ูุงุดู ฺฏู ูฺฉูู ู ฺฉุณ ูุณุช ฺฉู ุจูพุฑุณู ูพุงุจุฑููู ฺุทูุฑ ุฑุงู ูุฑุ!  ุงุฒ ูููุนุช ุทูุจ ุฏุฑ ูุฑ ุดุฑุงุท ูุซูุง ุฌุง ฺฉู ุงููู ุฏุฑ ุขู ูุฑู ูุฑ ุฒุงุฑ ุฒุงุฑ ฺฏุฑู ูฺฉูู ฺฉู ฺุฑุง ฺุฒ ุจูุด ูุฑุณุฏู! ุง ูพุฑูุฑุฏ ุฌูู ุฏุฑ ฺฏุฏุงุฎุงููุ ฺฉู ูุตู ฺฉุชู ู ูพุงุฒ ูพุฑุฒู ุฑู ุจุฑูุฏุงุฑู. \n",
            " ู ูู ุจู ุดุฎุตู ุนูุงูู ุฒุงุฏ ุจู ุงู ุทุฑุฒ ุฑูุงุช ุงุฒ ุฌุงูุนู ู ูุงูุน ุจู ููุฌูุฏ ุฏุฑ ุงูู -ุญุฏุงูู ุจุฎุด ุงุฒ ุฌุงูุนู- ุฏุงุฑูุ ุจู ุชููฺฏุฑ ฺฉู ููุณูุฏู ุจู ุทูุฑ ูุงูุฑุงูู ุง ุฏุฑ ูุงูุจ ฺฉ ุฏุงุณุชุงู ุจู ุธุงูุฑ ุณุงุฏู ุจู ูุฑุฏู ู ุฎูุงููุฏฺฏุงู ุฏุงุณุชุงูุด ูุฒูู.\n",
            "ุจู ูุธุฑ ููุ ุฏุฑ ุงู ุฏุงุณุชุงู ูพุฑุฒู ููุงุฏ ู ููุงูุฏู ุง ูุดู ุชุง ููู ุฌุง ุณุฑฺฉ ุจฺฉุดู ู ุงู ุฏุฑุฏูุง ุฑู ุฑูุงุช ฺฉูู. ูพุฑุฒู ุจูุงูู ุง ูุดู ุชุง ุจุง ุงู ุจู ุดูุฑุ ุฏูุ ุญุฑูุ ฺฏูุฑุณุชุงู ู ฺฏุฏุงุฎุงูู ู... ุจุฑู ู ุจุง ุงูุฑุงุฏ ูุฎุชูู ฺฉู ุจุง ูพุฑุฒู ุฑูุจุฑู ูุดู ุขุดูุง ุจุดู.\n",
            "\n",
            "ุจุฑุฎ ุงุฒ ููุชูุฏู \"ฺฏุฏุง\" ุฑู ุจุง ุงุตูู ูฺฉุชุจ ููุณู ุงฺฏุฒุณุชุงูุณุงูุณู (ุชูุฏู ูุฌูุฏ ุจุฑ ูุงูุช) ู ููุงูู ูุฑุชุจุท ุจุง ุงูู ูุงููุฏ ุขุฒุงุฏุ ุขูุงุฑฺฏุ ุฏููุฑู ู ููุณุชุงูฺ ููุฑุฏ ุจุฑุฑุณ ูุฑุงุฑ ุฏุงุฏู ฺฉู ูุทุงูุนู ุด ุฎุงู ุงุฒ ูุทู ูุณุช.\n",
            "\n",
            "ุงุฒ ุทุงูฺู ูู ูููููู.\n",
            "ุจุฏฺฉ ูุจูุฏ\n",
            "ุจุฏฺฉ ูุจูุฏ\n",
            "ุบูฺฏู ุจูุฏ ๐\n",
            "ุชูุด ฺฉุงุด ุจูุชุฑ ุชููู ูุดุฏ\n",
            "ุบูฺฏู ุจูุฏ \n",
            "ุชูุด ฺฉุงุด ุจูุชุฑ ุชููู ูุดุฏ\n",
            "ุชุง ุงููุฏู ุจูููู ฺ ุจู ฺู ุชููู ุดุฏ! ๐\n",
            "ุชุง ุงููุฏู ุจูููู ฺ ุจู ฺู ุชููู ุดุฏ! \n",
            "ุนุงู ุจูุฏูุฐุช ุจุฑุฏู๐\n",
            "ุนุงู ุจูุฏูุฐุช ุจุฑุฏู\n",
            "ฺุฑุง ุขุฎุฑุด ุงู ุทูุฑ ุดุฏุ ๐\n",
            "ฺุฑุง ุขุฎุฑุด ุงู ุทูุฑ ุดุฏุ \n",
            "ุบู ุงูฺฏุฒ...\n",
            "ุนู ุงูู ุฏูุฑู ูุฑุฏูุง ุงูุทูุฑ ุฒูุงุดูู ุฑู ุจู ูุงุฏุฑุดูู ุชุฑุฌุญ ูุฏุงุฏูุุ!\n",
            "ุบู ุงูฺฏุฒ...\n",
            "ุนู ุงูู ุฏูุฑู ูุฑุฏูุง ุงูุทูุฑ ุฒูุงุดูู ุฑู ุจู ูุงุฏุฑุดูู ุชุฑุฌุญ ูุฏุงุฏูุุ!\n",
            "ูุงููููู.ุจุฏ.ุจ ูุญุชูุง.ูพุงุงู ุจุงุฒ ูุซู ูุตู ูุง ุงุตุบุฑ ูุฑูุงุฏ\n",
            "ูุงููููู.ุจุฏ.ุจ ูุญุชูุง.ูพุงุงู ุจุงุฒ ูุซู ูุตู ูุง ุงุตุบุฑ ูุฑูุงุฏ\n",
            "ุงุตูุง ู ุฌูุฑ ุจูุฏุ ูู ุณุฑ ุฏุงุดุช ูู ุชู\n",
            "ุงุตูุง ู ุฌูุฑ ุจูุฏุ ูู ุณุฑ ุฏุงุดุช ูู ุชู\n",
            "ุฎูุจ ุจูุฏ ู ุงูุจุชู ูุงุฑุงุญุช ฺฉููุฏู...\n",
            "ุฎูุจ ุจูุฏ ู ุงูุจุชู ูุงุฑุงุญุช ฺฉููุฏู...\n",
            "ฺฉุฌุงุด ุฎูุจ ุจูุฏ\n",
            "ฺฉุฌุงุด ุฎูุจ ุจูุฏ\n",
            "ุฎูุจู ูู ุฎูุดู ุงููุฏ ูู ุจุฑุง ฺฉูฺฺฉุง ุฏุฑฺฉุด ููฺฉูู\n",
            "ุฎูุจู ูู ุฎูุดู ุงููุฏ ูู ุจุฑุง ฺฉูฺฺฉุง ุฏุฑฺฉุด ููฺฉูู\n",
            "ุฎููููุจ\n",
            "ุฎููููุจ\n",
            "ุฎู ฺฉุชุงุจ ุฎูุจ ุจูุฏ\n",
            "ุฎู ฺฉุชุงุจ ุฎูุจ ุจูุฏ\n",
            "ุจุณุงุฑ ฺฉุงุฑ ุฎูุจ ุจูุฏ ุงูุง ูุดู ฺฏูุช ฺฉุงุฑ ุฌุฏุฏ ุชู ุงูู ุฏูุฑู ูุจูุฏู ู ุฏุงุฑุง ุงุดฺฉุงูุงุช ุฒุงุฏ ูุณุช ุงูุง ูฺฉุชู ุงุตู ุฏุงุณุชุงู ุฑุงู ูุณุชุด ฺฉู ุจู ููู ุงุณุชุงุฏ ุณุงุนุฏ ุจุณุงุฑ ุฑูุงู ู ุณุงุฏู ูฺฏุงุดุชู ู ุฑูุงุช ุดุฏู ู ฺฉุงุฑ ุขุณุงู ูุจูุฏู ููููุทูุฑ ุจุฑุง ุชูุงู ุณูู ุฌุฐุงุจ ู ุขููุฒูุฏู ุณุช  ูุตู  ุฏุงุณุชุงู ูู ุฒุฎู ุฎูุจ ุจู ุฎูุงููุฏู ูุฒูู ู ุงุญุณุงุณุงุช ุงููู ุชุง ุญุฏ ุฌุฑูู ุฏุงุฑ ูฺฉูู ุงูุง ุงูุชูุง ุฏุงุณุชุงู ูุชููุณุช ุจู ุทุฑุฒ ุจูุชุฑ ุจู ุงุชูุงู ุจุฑุณู ุฏุฑ ฺฉู ู ฺฉุงุฑ ุฎูุจ ุฏฺฏู ุงุฒ ุฏฺฉุชุฑ ุณุงุนุฏ ุฎููุฏู ู ุฎูุดุญุงูู ...\n",
            "ุจุณุงุฑ ฺฉุงุฑ ุฎูุจ ุจูุฏ ุงูุง ูุดู ฺฏูุช ฺฉุงุฑ ุฌุฏุฏ ุชู ุงูู ุฏูุฑู ูุจูุฏู ู ุฏุงุฑุง ุงุดฺฉุงูุงุช ุฒุงุฏ ูุณุช ุงูุง ูฺฉุชู ุงุตู ุฏุงุณุชุงู ุฑุงู ูุณุชุด ฺฉู ุจู ููู ุงุณุชุงุฏ ุณุงุนุฏ ุจุณุงุฑ ุฑูุงู ู ุณุงุฏู ูฺฏุงุดุชู ู ุฑูุงุช ุดุฏู ู ฺฉุงุฑ ุขุณุงู ูุจูุฏู ููููุทูุฑ ุจุฑุง ุชูุงู ุณูู ุฌุฐุงุจ ู ุขููุฒูุฏู ุณุช  ูุตู  ุฏุงุณุชุงู ูู ุฒุฎู ุฎูุจ ุจู ุฎูุงููุฏู ูุฒูู ู ุงุญุณุงุณุงุช ุงููู ุชุง ุญุฏ ุฌุฑูู ุฏุงุฑ ูฺฉูู ุงูุง ุงูุชูุง ุฏุงุณุชุงู ูุชููุณุช ุจู ุทุฑุฒ ุจูุชุฑ ุจู ุงุชูุงู ุจุฑุณู ุฏุฑ ฺฉู ู ฺฉุงุฑ ุฎูุจ ุฏฺฏู ุงุฒ ุฏฺฉุชุฑ ุณุงุนุฏ ุฎููุฏู ู ุฎูุดุญุงูู ...\n",
            "ูุงุณู ุณู ฑธุณุงู ฺฉุชุงุจ ููุงุณุจูุ!\n",
            "ูุงุณู ุณู ฑธุณุงู ฺฉุชุงุจ ููุงุณุจูุ!\n",
            "ูุงูุนุง ูุง ุงูุณุงูุง ุฏุงุฑู ฺฉุฌุง ูุฑู ุงูู ุดุฏ ุฒูุฏฺฏ ูู ฺฉู ุงุฏู ูุดูุงุณู ฺฉู ูุซ ุงู ุฎุงูู ุจุง ุจุฏุจุฎุช ุฏุงุฑู ุฒูุฏฺฏ ูฺฉููุชุฑู ุฎุฏุง ุจุงุฏ ุจู ูุงุฏุฑ ูพุฏุฑุงููู ุงุญุชุฑุงู ุจุฒุงุฑู ูุญุจุช ฺฉูู ฺ ูุดู ุงููุง ุจูุฏู ฺฉู ู ุนูุฑ ุจุง ุฎูู ุฏู ูุง ุฑู ุจุฒุฑฺฏ ฺฉุฑุฏู \n",
            "\n",
            "ูุจููุงูุฏู ุงุญุณุงูุง ู ุงูุณูุงู ูุงูู ุชูุงู\n",
            "ูุงูุนุง ูุง ุงูุณุงูุง ุฏุงุฑู ฺฉุฌุง ูุฑู ุงูู ุดุฏ ุฒูุฏฺฏ ูู ฺฉู ุงุฏู ูุดูุงุณู ฺฉู ูุซ ุงู ุฎุงูู ุจุง ุจุฏุจุฎุช ุฏุงุฑู ุฒูุฏฺฏ ูฺฉููุชุฑู ุฎุฏุง ุจุงุฏ ุจู ูุงุฏุฑ ูพุฏุฑุงููู ุงุญุชุฑุงู ุจุฒุงุฑู ูุญุจุช ฺฉูู ฺ ูุดู ุงููุง ุจูุฏู ฺฉู ู ุนูุฑ ุจุง ุฎูู ุฏู ูุง ุฑู ุจุฒุฑฺฏ ฺฉุฑุฏู \n",
            "\n",
            "ูุจููุงูุฏู ุงุญุณุงูุง ู ุงูุณูุงู ูุงูู ุชูุงู\n",
            "ุฎูุจ ุจูุฏ!!!!\n",
            "ุฎูุจ ุจูุฏ!!!!\n",
            "ูุดูฺฏ ุจูุฏ ุุุุุุ\n",
            "ูุดูฺฏ ุจูุฏ ุุุุุุ\n",
            "ุฏุงุบููู ฺฉุฑุฏ\n",
            "ุฏุงุบููู ฺฉุฑุฏ\n",
            "ุณูุงู ุงู ฺฉุชุงุจ ุฌุฒู ูุณุงุจูู ูุณุช ุงูู ุุ\n",
            "ุณูุงู ุงู ฺฉุชุงุจ ุฌุฒู ูุณุงุจูู ูุณุช ุงูู ุุ\n",
            "ูุงุงุงุงุงูุนุง ุฒุจุง ุจูุฏ. ฺฉุณุงู ฺฉู ุงุฒ ุฏุงุณุชุงู ุฎูุดุดูู ูููุฏ ุจุงุฏ ุจุดุชุฑ ูุทุงูุนู ฺฉูู ู ููุฏ ุฏุงุณุชุงู ูุง ุฑู ูู ุจุฎููู ุชุง ูุณุจุช ุจู ุณุจฺฉ ูุง ููุณูุฏฺฏ ุนูู ุชุฑ ุจุดู.\n",
            "ูุงุงุงุงุงูุนุง ุฒุจุง ุจูุฏ. ฺฉุณุงู ฺฉู ุงุฒ ุฏุงุณุชุงู ุฎูุดุดูู ูููุฏ ุจุงุฏ ุจุดุชุฑ ูุทุงูุนู ฺฉูู ู ููุฏ ุฏุงุณุชุงู ูุง ุฑู ูู ุจุฎููู ุชุง ูุณุจุช ุจู ุณุจฺฉ ูุง ููุณูุฏฺฏ ุนูู ุชุฑ ุจุดู.\n",
            "ุจูุงูฺฏุฐุงุฑ ูุงูุน ุฑุงูุณู ุฌุงุฏู ุงุดูู ูุณุชูุฏ\n",
            "ูุฏููู ุฏุฑ ฺฉูุงุฑ ูุจุฑ ุตุงุฏู ูุฏุงุช\n",
            "ุจูุงูฺฏุฐุงุฑ ูุงูุน ุฑุงูุณู ุฌุงุฏู ุงุดูู ูุณุชูุฏ\n",
            "ูุฏููู ุฏุฑ ฺฉูุงุฑ ูุจุฑ ุตุงุฏู ูุฏุงุช\n",
            "ููุช ฺฉู ูุฎููุฏูุด ุฌูุฑ ูุดุฏู ุณุฑุฏู ุจ ุฑูุญ...ุฒูุฏฺฏ ุงูุฌูุฑ ุงุฏูุง ุงุตู ูุนููู ูุณ ฺุทูุฑ ุชููู ูุดู ูุซู ุงุฎุฑ ุฎูุฏ ุฏุงุณุชุงู.ยก!\n",
            "ููุช ฺฉู ูุฎููุฏูุด ุฌูุฑ ูุดุฏู ุณุฑุฏู ุจ ุฑูุญ...ุฒูุฏฺฏ ุงูุฌูุฑ ุงุฏูุง ุงุตู ูุนููู ูุณ ฺุทูุฑ ุชููู ูุดู ูุซู ุงุฎุฑ ุฎูุฏ ุฏุงุณุชุงู.ยก!\n",
            "ุฎู ุจุฎูุฏ ุจูุฏ ุฎู\n",
            "ุฎู ุจุฎูุฏ ุจูุฏ ุฎู\n",
            "ฺฉูุชุงู ู ุฎู ุฏุฑุฏูุงฺฉ ู ุบู ุงูฺฏุฒ. ุฏุงุณุชุงู ูุงุฏุฑุง ฺฉู ููู  ุนูุฑ ู ุชูุงูุดููู ุตุฑู ุจฺู ูุงุดูู ูฺฉูู ูู ุงููุทูุฑ ฺฉู ุดุงุณุชุด ูุณุชู ุจุงูุงุดูู ุจุฑุฎูุฑุฏ ููุดู ู ุชูุณุท ูููู ุจฺู ูุง ุจ ุฑุญูุงูู ุทุฑุฏ ูุดู.\n",
            "ฺฉูุชุงู ู ุฎู ุฏุฑุฏูุงฺฉ ู ุบู ุงูฺฏุฒ. ุฏุงุณุชุงู ูุงุฏุฑุง ฺฉู ููู  ุนูุฑ ู ุชูุงูุดููู ุตุฑู ุจฺู ูุงุดูู ูฺฉูู ูู ุงููุทูุฑ ฺฉู ุดุงุณุชุด ูุณุชู ุจุงูุงุดูู ุจุฑุฎูุฑุฏ ููุดู ู ุชูุณุท ูููู ุจฺู ูุง ุจ ุฑุญูุงูู ุทุฑุฏ ูุดู.\n",
            "ูุดฺฉ ุฏุฑฺฉุด ูฺฉุฑุฏุฺฉุณ ฺฉ ุนูุฑุดู ุจุฑุง ุฏุฑฺฉ ุงููุง ฺฏุฐุงุดุช....\n",
            "ฺุฑุง ูุงุฏุฑุง ุชุง ูุญู ุขุฎุฑ ุฑุงุนุงุช ุจฺู ูุงุฑู ูฺฉูู...๐ข\n",
            "ูุดฺฉ ุฏุฑฺฉุด ูฺฉุฑุฏุฺฉุณ ฺฉ ุนูุฑุดู ุจุฑุง ุฏุฑฺฉ ุงููุง ฺฏุฐุงุดุช....\n",
            "ฺุฑุง ูุงุฏุฑุง ุชุง ูุญู ุขุฎุฑ ุฑุงุนุงุช ุจฺู ูุงุฑู ูฺฉูู...\n",
            "ููุถูุนุด ฺฉู ุงุญุชุฑุงู ุจู ูุงูุฏู ุจูุฏ ูุงุจู ุงุญุชุฑุงูู ูู ุฎูุฏ ุฏุงุณุชุงู ุงูุชุถุงุญ ุจูุฏ ุ ุงู ุจุง ุงู ุฏุงุณุชุงูุง ูุนุฑูู ุดุฏู ุ ุนุฌุจุง\n",
            "ููุถูุนุด ฺฉู ุงุญุชุฑุงู ุจู ูุงูุฏู ุจูุฏ ูุงุจู ุงุญุชุฑุงูู ูู ุฎูุฏ ุฏุงุณุชุงู ุงูุชุถุงุญ ุจูุฏ ุ ุงู ุจุง ุงู ุฏุงุณุชุงูุง ูุนุฑูู ุดุฏู ุ ุนุฌุจุง\n",
            "ุบูฺฏู ู ฺฉูุชุงู\n",
            "ุบูฺฏู ู ฺฉูุชุงู\n",
            "ูุฏุฑ ูพุฏุฑ ู ูุงุฏุฑ ูุงููู ุฑู ุจุฏููู ููุช  ฺฉู ูุณุชูุฏ . ููุช ฺฉู ุฑูุชูุฏ ฺู ูุงุฏู ฺฏุฑู ู ุฒุงุฑ\n",
            "ูุฏุฑ ูพุฏุฑ ู ูุงุฏุฑ ูุงููู ุฑู ุจุฏููู ููุช  ฺฉู ูุณุชูุฏ . ููุช ฺฉู ุฑูุชูุฏ ฺู ูุงุฏู ฺฏุฑู ู ุฒุงุฑ\n",
            "ุบู ุงูฺฏุฒ ุจูุฏ ู ุงุฑุฒุด ุฎูุงูุฏู ุฏุงุดุช\n",
            "ุบู ุงูฺฏุฒ ุจูุฏ ู ุงุฑุฒุด ุฎูุงูุฏู ุฏุงุดุช\n",
            "ุฏุงุณุชุงู ุฎูุจู.  ููุถูุนุด ู ูพุฑุฒู ฺฏุฏุงุณุช ุงูุง ูุถูููุด ุฏุฑ ุงุฑุชุจุงุท ุจุง ูุงูุฏูู\n",
            "ุฏุงุณุชุงู ุฎูุจู.  ููุถูุนุด ู ูพุฑุฒู ฺฏุฏุงุณุช ุงูุง ูุถูููุด ุฏุฑ ุงุฑุชุจุงุท ุจุง ูุงูุฏูู\n",
            "๏บง๏ปด๏ป๏ปฒ ๏บ๏บช ๏บ๏ปฎ๏บฉ!  ุง๏บป๏ปผ ๏ญผ๏ปฒ ๏ปฃ๏ปด๏บจ๏ปฎุง๏บณ๏บ ๏บ๏ฎ๏ปช!  ๏ป๏บ๏ป๏ญฝ๏ปช ๏บ๏ปด๏บธ๏บ๏บฎ ๏บฉ๏ป๏บ ๏ป๏ปฆ.  ๏ปฃ๏บฎ๏บณ๏ปฒ ุง๏ปฉ\n",
            "  !  ุง  ุง !     .   ุง\n",
            "ุญุฑฺฉุช ฺฉููุงุฎุช ุฏุฑ ุฑูุงุช ุฏุงุณุชุงู ู ุจุงู ุฏุฑุณุช ุงุญุณุงุณุงุช ุทูุฑ ฺฉู ุดุฎุตุช ฺฉุงููุง ูพุฑุฏุงุฎุชู ู ุดูุฏ ู ุญุฑฺฉุงุช ุงู ฺฉุงููุง ูุดุงู ุงุฒ ฺฉ ุดุฎุตุช ูุงุญุฏ ุฏุงุฑุฏ ู ุถุฏ ูููุถ ูุณุช. ูู ุฏุงูู ฺุฑุง ูุฑุง ุจู ุฎุงูู ุณุงูููุฏุงู ุจุฑุฏ ุจู ุงุฏ ุณุงูููุฏุงู ฺฉู ุฏุงุณุชุงู ูุง ฺฏููุงฺฏููุดุงู ุฒุจุงุณุช ูุงููุฏ ฺู ู ฺุฑูฺฉ ูุง ููุงุฌ ฺูุฑู ุดุงู ู ฺู ุฏุฑุฏูุงฺฉ ุงุณุช ุงุดฺฉ ูุง ฺฉู ุฏุฑ ุงู ุฎุทูุท ู ูุบุฒุฏ ููฺฏุงู ฺฉู ุงุฒ ฺฏุฐุดุชู ู ฺฏููุฏ ู ฺฏุงู ุจุนุถ ูุงุดุงู ุญุฑู ูู ุฒููุฏ ูุซู ูพุฑุฒู ูุตู ููุท ุชุงุจ ู ุขูุฑูุฏ ุชุง ูพุฑ ุจฺฉุดูุฏ\n",
            "ุญุฑฺฉุช ฺฉููุงุฎุช ุฏุฑ ุฑูุงุช ุฏุงุณุชุงู ู ุจุงู ุฏุฑุณุช ุงุญุณุงุณุงุช ุทูุฑ ฺฉู ุดุฎุตุช ฺฉุงููุง ูพุฑุฏุงุฎุชู ู ุดูุฏ ู ุญุฑฺฉุงุช ุงู ฺฉุงููุง ูุดุงู ุงุฒ ฺฉ ุดุฎุตุช ูุงุญุฏ ุฏุงุฑุฏ ู ุถุฏ ูููุถ ูุณุช. ูู ุฏุงูู ฺุฑุง ูุฑุง ุจู ุฎุงูู ุณุงูููุฏุงู ุจุฑุฏ ุจู ุงุฏ ุณุงูููุฏุงู ฺฉู ุฏุงุณุชุงู ูุง ฺฏููุงฺฏููุดุงู ุฒุจุงุณุช ูุงููุฏ ฺู ู ฺุฑูฺฉ ูุง ููุงุฌ ฺูุฑู ุดุงู ู ฺู ุฏุฑุฏูุงฺฉ ุงุณุช ุงุดฺฉ ูุง ฺฉู ุฏุฑ ุงู ุฎุทูุท ู ูุบุฒุฏ ููฺฏุงู ฺฉู ุงุฒ ฺฏุฐุดุชู ู ฺฏููุฏ ู ฺฏุงู ุจุนุถ ูุงุดุงู ุญุฑู ูู ุฒููุฏ ูุซู ูพุฑุฒู ูุตู ููุท ุชุงุจ ู ุขูุฑูุฏ ุชุง ูพุฑ ุจฺฉุดูุฏ\n",
            "ูุธุฑุงุช ุฎู ุชูุฌู ููู ุฌูุจ ฺฉุฑุฏ\n",
            "ุฏุฑุญุงู ฺฉู ููุฑ ุฑุงุถ ุจูุฏ ููุฑ ุจุนุฏ ฺฏูุช ูุฒุฎุฑู\n",
            "ุฏุงุณุชุงู ู ุชุฎู ุง ู ููุดุชู ุณุงุฏู ูุจูุฏ\n",
            "ุฏุงุณุชุงู ฺฉ ุฎููุฏู ูุงูุนุช ุงู ฺฉ ุชู ุฌุงูุนู ุงุฒ ููููู ุงุด ุจู ุฑุงุญุช ูพุฏุง ูุดู(ุจุฌุฒ ฺฏุฏุงููุงูุง)\n",
            "ุงฺฏ ูุฑฺฉุณ ููุง ูพุฏุฑ ู ูุงุฏุฑ ุฎูุฏุด ุฑู ุฏุงุดุชู ุจุงุดู ...\n",
            "ูุธุฑุงุช ุฎู ุชูุฌู ููู ุฌูุจ ฺฉุฑุฏ\n",
            "ุฏุฑุญุงู ฺฉู ููุฑ ุฑุงุถ ุจูุฏ ููุฑ ุจุนุฏ ฺฏูุช ูุฒุฎุฑู\n",
            "ุฏุงุณุชุงู ู ุชุฎู ุง ู ููุดุชู ุณุงุฏู ูุจูุฏ\n",
            "ุฏุงุณุชุงู ฺฉ ุฎููุฏู ูุงูุนุช ุงู ฺฉ ุชู ุฌุงูุนู ุงุฒ ููููู ุงุด ุจู ุฑุงุญุช ูพุฏุง ูุดู(ุจุฌุฒ ฺฏุฏุงููุงูุง)\n",
            "ุงฺฏ ูุฑฺฉุณ ููุง ูพุฏุฑ ู ูุงุฏุฑ ุฎูุฏุด ุฑู ุฏุงุดุชู ุจุงุดู ...\n",
            "ุฒุจุงุงูุงุบู ุงูฺฏุฒ ุฏุฑฺฉู ุฎูุจู.\n",
            "ุฒุจุงุงูุงุบู ุงูฺฏุฒ ุฏุฑฺฉู ุฎูุจู.\n",
            "ูุดูฺฏ ุจูุฏุุงุฑุฒุด ู ุจุงุฑ ุฎููุฏู ุฑุง ุจู ูุธุฑ ูู ุฏุงุฑู.\n",
            "ูุดูฺฏ ุจูุฏุุงุฑุฒุด ู ุจุงุฑ ุฎููุฏู ุฑุง ุจู ูุธุฑ ูู ุฏุงุฑู.\n",
            "ุจุง ุณูุงู ู ุฎุณุชู ูุจุงุดุฏ.\n",
            "ุถูู ุชุดฺฉุฑ ุงุฒ ูุฑุงุฑ ุฏุงุฏู ุงู ูุจู ฺฉุชุงุจ ูุง ุชุงุฑุฎ ุฎุตูุตุง ุชุงุฑุฎ ูุนุงุตุฑุููููู ฺฉุชุงุจ ุฑุง ุฏุงูููุฏ ฺฉุฑุฏู ู ูุทุงูุนู ูููุฏู.ููู ฺุฒ ุนุงู ุจูุฏ ุจู ุฌุฒ ุจุฑุฎ ุงุดุชุจุงูุงุช ุชุงูพ ฺฉู ุงูุฏูุงุฑู ุจู ุฒูุฏ ูุฑุชูุน ฺฏุฑุฏุฏ.\n",
            "ูููู ุจุงุดุฏ.\n",
            "ุจุง ุณูุงู ู ุฎุณุชู ูุจุงุดุฏ.\n",
            "ุถูู ุชุดฺฉุฑ ุงุฒ ูุฑุงุฑ ุฏุงุฏู ุงู ูุจู ฺฉุชุงุจ ูุง ุชุงุฑุฎ ุฎุตูุตุง ุชุงุฑุฎ ูุนุงุตุฑุููููู ฺฉุชุงุจ ุฑุง ุฏุงูููุฏ ฺฉุฑุฏู ู ูุทุงูุนู ูููุฏู.ููู ฺุฒ ุนุงู ุจูุฏ ุจู ุฌุฒ ุจุฑุฎ ุงุดุชุจุงูุงุช ุชุงูพ ฺฉู ุงูุฏูุงุฑู ุจู ุฒูุฏ ูุฑุชูุน ฺฏุฑุฏุฏ.\n",
            "ูููู ุจุงุดุฏ.\n",
            "ุฎู ุนุงูู ูุงูุนุฃ ุงุฒุชูู ูููููู\n",
            "ุฎู ุนุงูู ูุงูุนุฃ ุงุฒุชูู ูููููู\n",
            "ุจู ูุธุฑ ูู ุงุตู ูุทูุจ ุฏุฑ ฺฉุชุงุจ ุงุฏุง ูุดุฏู ุงุณุช! ุงุณุงู ุฎู ุงุฒ ูุฑูุงูุฏู ูุง ู ูุนุงููุงู ุฏูุงูุฑ ุงูู ุฑูุฒูุง ู ุฑุดุงุฏุช ูุงุดุงู ุฐฺฉุฑ ูุดุฏู! ู ุงูู ฺูุฏ ููุฑ ูู ฺฉู ุฐฺฉุฑ ุดุฏู ุฎู ุณุฑุณุฑ ุงุฒุด ฺฏุฐุดุชู ุดุฏู!\n",
            "ุจู ูุธุฑ ูู ุงุตู ูุทูุจ ุฏุฑ ฺฉุชุงุจ ุงุฏุง ูุดุฏู ุงุณุช! ุงุณุงู ุฎู ุงุฒ ูุฑูุงูุฏู ูุง ู ูุนุงููุงู ุฏูุงูุฑ ุงูู ุฑูุฒูุง ู ุฑุดุงุฏุช ูุงุดุงู ุฐฺฉุฑ ูุดุฏู! ู ุงูู ฺูุฏ ููุฑ ูู ฺฉู ุฐฺฉุฑ ุดุฏู ุฎู ุณุฑุณุฑ ุงุฒุด ฺฏุฐุดุชู ุดุฏู!\n",
            "ฺฉุชุงุจ ูุตุงุญุจู ุงุณุช ฺฉู ุจุง ุดูุฏ ุตุงุฏ ุดุฑุงุฒ ุฏุฑ ุจุงุฑู  ุขุฒุงุฏุณุงุฒ ุฎุฑูุดูุฑ ุตูุฑุช ฺฏุฑูุชู ู ุงุดุงุฑู ุจู ุงู ููุถูุน ฺฉู ุณุฎุช ุชุฑู ุนููุงุช ูุง ูุฑุจูุท ุจู ุนุจูุฑ ุงุฒ ุฑูุฏุฎุงูู ูุดูุฏ ฺฉู ุฏุฑ ุนููุงุช ุจุช ุงูููุฏุณ ูู ููู ุงุชูุงู ุงูุชุงุฏ ู ุนุจูุฑ ุงุฒ ฺฉุงุฑูู ู ฺฉุฑุฎู ู ...ู ุณุงุฎุชู ูพู ูุง ุดูุงูุฑ ุจุฑุง ุนุจูุฑ ูฺุณุชฺฉ ู ูุฑููุง ฺฉุงุฑ ุจุณุงุฑ ุทุงูุช ูุฑุณุง ุจูุฏ ฺฉู ุจุง ููุช ู ุนุฒู ูุฑููุง ุงุฑุชุด ู ุณูพุงู ุงู ฺฉุงุฑ ุณุฎุช ููฺฉู ุดุฏ ูููุฌุฑ ุจู ุขุฒุงุฏ ุณุงุฒ ุฎุฑูุดูุฑ ุดุฏ ุชูุฑุจุง ุจู ุงูุงุณุท ฺฉุชุงุจ ฺฉู ูุฑุณู ูุฌุงู ุจุฑุง ุฑุณุฏู ุจู ุงู ุงุชูุงู ุชุงุฑุฎ ุฏุฑ ุฎูุงููุฏู ุฑุฎ ูุฏู ุจุฎุตูุต ููุช ฺฉู ุฎูุจุงู ูู ฺฉููพุชุฑ ุจุฑุง ุจุฑุฑุณ ุงูุถุงุน ู ุชุนุฏุงุฏ ุงุณุฑุง ูุฑุงุฏ ูุฒูู ฺฉู ฺูุฏุฑ ุงุณุฑ ุนุฑุงู ! ุจุง ุงูุฏุงุฏ ุฎุฏุงููุฏ 14500ุงุณุฑ ุจุฏุณุช ูุฑููุง ูุง ุจู ุงุณุงุฑุช ุฏุฑ ู ุขูุฏ ุฏุฑ ุญุงูฺฉู ุชุนุฏุงุฏ ูุฑููุง ุฎูุฏ ุจุณุงุฑ ฺฉูุชุฑ ุจูุฏูุฏ ูฺููุช ุตุญูู ูุง ุงุณุงุฑุช ุขููุง ุฑุง ฺฉู ุงุฒ ุชููุฒูู ููุงุด ุฏุงุฏู ู ุดุฏ ุฑุง ูุฑุงููุด ููฺฉูู ูุงูุนุง ุงฺฏุฑ ูุฎูุงุณุชูุฏ ุจุง ุฏุณุช ุฎุงู ูู ูุชููุณุชู ุจุฑ ูุฑููุง ูุง ุบุงูุจ ุจุดููุฏ ุงูุง ุฎูุงุณุช ุฎุฏุงููุฏ ุจุฑ ุงุฑ ูุง ูุฑุงุฑ ุฏุงุดุช ู ุฎููู ุดูุฑ ุจู ุขุบูุด ูุทู ุจุงุฒ ฺฏุดุช.\n",
            "ฺฉุชุงุจ ูุตุงุญุจู ุงุณุช ฺฉู ุจุง ุดูุฏ ุตุงุฏ ุดุฑุงุฒ ุฏุฑ ุจุงุฑู  ุขุฒุงุฏุณุงุฒ ุฎุฑูุดูุฑ ุตูุฑุช ฺฏุฑูุชู ู ุงุดุงุฑู ุจู ุงู ููุถูุน ฺฉู ุณุฎุช ุชุฑู ุนููุงุช ูุง ูุฑุจูุท ุจู ุนุจูุฑ ุงุฒ ุฑูุฏุฎุงูู ูุดูุฏ ฺฉู ุฏุฑ ุนููุงุช ุจุช ุงูููุฏุณ ูู ููู ุงุชูุงู ุงูุชุงุฏ ู ุนุจูุฑ ุงุฒ ฺฉุงุฑูู ู ฺฉุฑุฎู ู ...ู ุณุงุฎุชู ูพู ูุง ุดูุงูุฑ ุจุฑุง ุนุจูุฑ ูฺุณุชฺฉ ู ูุฑููุง ฺฉุงุฑ ุจุณุงุฑ ุทุงูุช ูุฑุณุง ุจูุฏ ฺฉู ุจุง ููุช ู ุนุฒู ูุฑููุง ุงุฑุชุด ู ุณูพุงู ุงู ฺฉุงุฑ ุณุฎุช ููฺฉู ุดุฏ ูููุฌุฑ ุจู ุขุฒุงุฏ ุณุงุฒ ุฎุฑูุดูุฑ ุดุฏ ุชูุฑุจุง ุจู ุงูุงุณุท ฺฉุชุงุจ ฺฉู ูุฑุณู ูุฌุงู ุจุฑุง ุฑุณุฏู ุจู ุงู ุงุชูุงู ุชุงุฑุฎ ุฏุฑ ุฎูุงููุฏู ุฑุฎ ูุฏู ุจุฎุตูุต ููุช ฺฉู ุฎูุจุงู ูู ฺฉููพุชุฑ ุจุฑุง ุจุฑุฑุณ ุงูุถุงุน ู ุชุนุฏุงุฏ ุงุณุฑุง ูุฑุงุฏ ูุฒูู ฺฉู ฺูุฏุฑ ุงุณุฑ ุนุฑุงู ! ุจุง ุงูุฏุงุฏ ุฎุฏุงููุฏ 14500ุงุณุฑ ุจุฏุณุช ูุฑููุง ูุง ุจู ุงุณุงุฑุช ุฏุฑ ู ุขูุฏ ุฏุฑ ุญุงูฺฉู ุชุนุฏุงุฏ ูุฑููุง ุฎูุฏ ุจุณุงุฑ ฺฉูุชุฑ ุจูุฏูุฏ ูฺููุช ุตุญูู ูุง ุงุณุงุฑุช ุขููุง ุฑุง ฺฉู ุงุฒ ุชููุฒูู ููุงุด ุฏุงุฏู ู ุดุฏ ุฑุง ูุฑุงููุด ููฺฉูู ูุงูุนุง ุงฺฏุฑ ูุฎูุงุณุชูุฏ ุจุง ุฏุณุช ุฎุงู ูู ูุชููุณุชู ุจุฑ ูุฑููุง ูุง ุบุงูุจ ุจุดููุฏ ุงูุง ุฎูุงุณุช ุฎุฏุงููุฏ ุจุฑ ุงุฑ ูุง ูุฑุงุฑ ุฏุงุดุช ู ุฎููู ุดูุฑ ุจู ุขุบูุด ูุทู ุจุงุฒ ฺฏุดุช.\n",
            "ุณูุงู ฺฉุชุงุจ ุฎูุจ ุงุณุช. ููููู\n",
            "ุณูุงู ฺฉุชุงุจ ุฎูุจ ุงุณุช. ููููู\n",
            "ุจุณุงุฑ ุฒุจุง ู ุณุฑุดุงุฑ ุงุฒ ูฺฉุงุช ุฒุจุง ู ูุนุงู ุนูู\n",
            "ุจุณุงุฑ ุฒุจุง ู ุณุฑุดุงุฑ ุงุฒ ูฺฉุงุช ุฒุจุง ู ูุนุงู ุนูู\n",
            "ฺฉุชุงุจ ุฎูุจ ุจูุฏ ุงูุง ูู ฺฉูุฑ ุฑู ุชุฑุฌุญ ูุฏู ุชูุฑุจุง ุฏุงุณุชุงู ฺฉู\n",
            "ฺฉุชุงุจ ุฎูุจ ุจูุฏ ุงูุง ูู ฺฉูุฑ ุฑู ุชุฑุฌุญ ูุฏู ุชูุฑุจุง ุฏุงุณุชุงู ฺฉู\n",
            "ูููุฒ ุชูููุด ูฺฉุฑุฏู ุงูุง ุฏุฑ ฺฉู ุฌุงูุจู\n",
            "ูููุฒ ุชูููุด ูฺฉุฑุฏู ุงูุง ุฏุฑ ฺฉู ุฌุงูุจู\n",
            "ูู ููุชููู ุฏุฑุงูุชุด ฺฉูู ุฑู ููููู ุง ฺฏุฒูู ูพุงู ฺฉ ูุฒูู ูููุณู ุงุฑุชุจุงุท ุจุฑูุฑุงุฑ ูุดุฏ\n",
            "ูู ููุชููู ุฏุฑุงูุชุด ฺฉูู ุฑู ููููู ุง ฺฏุฒูู ูพุงู ฺฉ ูุฒูู ูููุณู ุงุฑุชุจุงุท ุจุฑูุฑุงุฑ ูุดุฏ\n",
            "ุฌูุงู ุขู ุงุญูุฏ ุฏุฑ ุบุฑุจ ุฒุฏฺฏ ฺฏูุชู ููุธูุฑ ฺฉุงูู ุงุฒ ุทุงุนูู ูุงุดูุณู ุงุณุช\n",
            "ุฌูุงู ุขู ุงุญูุฏ ุฏุฑ ุบุฑุจ ุฒุฏฺฏ ฺฏูุชู ููุธูุฑ ฺฉุงูู ุงุฒ ุทุงุนูู ูุงุดูุณู ุงุณุช\n",
            "ฺฉุชุงุจ ุจุณุงุฑ ุฎูุจ ุจูุฏ.ูุงูุนุง ุนุงู ุจูุฏ.ููููู ุงุฒ ุทุงูฺู.\n",
            "ฺฉุชุงุจ ุจุณุงุฑ ุฎูุจ ุจูุฏ.ูุงูุนุง ุนุงู ุจูุฏ.ููููู ุงุฒ ุทุงูฺู.\n",
            "ุชุนุฏุงุฏ ฺฉุชุงุจูุงุฑู ุจุดุชุฑ ฺฉูุฏ\n",
            "ุชุนุฏุงุฏ ฺฉุชุงุจูุงุฑู ุจุดุชุฑ ฺฉูุฏ\n",
            "ููุงุณุจ ููุชูุฏุงู ู ููุณูุฏฺฏุงู ุจู ููุฑุงู ุงูุฏุด โูุง ุฏุฑ ุจุงุจ ุฑุฆุงูุณู\n",
            "ููุงุณุจ ููุชูุฏุงู ู ููุณูุฏฺฏุงู ุจู ููุฑุงู ุงูุฏุด โูุง ุฏุฑ ุจุงุจ ุฑุฆุงูุณู\n",
            "ฺฉุชุงุจ ุฎูุจ ูุณุช ู ุชุฑุฌูู ุฎูุจ ูู ุฏุงุฑู. ูฺฉุงุช ุฌุงูุจ ุฏุงุฑู ฺฉู ูุชููู ุชู ุจูุชุฑ ุดุฏู ฺฉูุช ุฒูุฏฺฏ ุชุงุซุฑ ูุซุจุช ุจุฐุงุฑู. ๐\n",
            "ฺฉุชุงุจ ุฎูุจ ูุณุช ู ุชุฑุฌูู ุฎูุจ ูู ุฏุงุฑู. ูฺฉุงุช ุฌุงูุจ ุฏุงุฑู ฺฉู ูุชููู ุชู ุจูุชุฑ ุดุฏู ฺฉูุช ุฒูุฏฺฏ ุชุงุซุฑ ูุซุจุช ุจุฐุงุฑู. \n",
            "ูู ุงู ฺฉุชุงุจู ุฏุงุฑู ู ุจุงุฑูุง ุจุง ุฏูุช ุฎููุฏู.ุนุงูู\n",
            "ูู ุงู ฺฉุชุงุจู ุฏุงุฑู ู ุจุงุฑูุง ุจุง ุฏูุช ุฎููุฏู.ุนุงูู\n",
            "ุงู ฺฉุชุงุจ ุฑู 7 ูุงู ูพุด ุฎููุฏู ู ุนุงู ุจูุฏ. ู ูุงูุนุง ุฏุฑุณุชู ุนุดู ุจู ูุฑฺุฒ ุงูู ุฑู ุฎูู ูฺฉูู.\n",
            "ุงู ฺฉุชุงุจ ุฑู 7 ูุงู ูพุด ุฎููุฏู ู ุนุงู ุจูุฏ. ู ูุงูุนุง ุฏุฑุณุชู ุนุดู ุจู ูุฑฺุฒ ุงูู ุฑู ุฎูู ูฺฉูู.\n",
            "ฺ ุจฺฏู ูุงูุง ู ุฎุจ ู ุจุฏ\n",
            "ฺ ุจฺฏู ูุงูุง ู ุฎุจ ู ุจุฏ\n",
            "ุงุจุชุฏุง ุจุงุฏ ููุงุท ุถุนู ูููุช ุฎูุฏ ุฑุง ูพุฏุง ฺฉุฑุฏ ู ุจุนุฏููุถูุนุงุช ูพุดููุงุฏ ฺฉุชุงุจ ุฑุง ุชูุฑู ุจุฑุง ุฐูู  ูุฑุงุฑ ุฏุงุฏ ุชุง  ุฏุฑ ุฐูู  ููุงุฏูู ุดูุฏ. ฺฉุชุงุจ ููุฏ ุจูุฏ.\n",
            "ุงุจุชุฏุง ุจุงุฏ ููุงุท ุถุนู ูููุช ุฎูุฏ ุฑุง ูพุฏุง ฺฉุฑุฏ ู ุจุนุฏููุถูุนุงุช ูพุดููุงุฏ ฺฉุชุงุจ ุฑุง ุชูุฑู ุจุฑุง ุฐูู  ูุฑุงุฑ ุฏุงุฏ ุชุง  ุฏุฑ ุฐูู  ููุงุฏูู ุดูุฏ. ฺฉุชุงุจ ููุฏ ุจูุฏ.\n",
            "ุนุงูู ุูุชุดฺฉุฑู\n",
            "ุนุงูู ุูุชุดฺฉุฑู\n",
            "ุจู ูุณุจุช ฺฉุชุงุจูุง ุฏฺฏุฑ ุงู ููุณูุฏู ุ ุฌุฐุงุจุชุฑ ุงุณุช.\n",
            "ูู ุจู ุงูุฏุงุฒู ุง ฺฉู ุงุฒ ุงูู ุชุนุฑู ุดุฏู ุจูุฏ ููู ุฌุฐุจ ูฺฉุฑุฏ.\n",
            "ุจู ูุณุจุช ฺฉุชุงุจูุง ุฏฺฏุฑ ุงู ููุณูุฏู ุ ุฌุฐุงุจุชุฑ ุงุณุช.\n",
            "ูู ุจู ุงูุฏุงุฒู ุง ฺฉู ุงุฒ ุงูู ุชุนุฑู ุดุฏู ุจูุฏ ููู ุฌุฐุจ ูฺฉุฑุฏ.\n",
            "ูุงูุนุง ุฒุจุง ุจูุฏ...ูู ุขุฏู ููุดู ูุฑุงููุด ฺฉุงุฑ ูุณุช . ุงูุฏูุงุฑู ููู ุจู ุญุฏุซ ุฎูุดุชู ุจุฑุณู ู ุจุง ุงูู ุฒูุฏฺฏ ฺฉูู.\n",
            "ูุงูุนุง ุฒุจุง ุจูุฏ...ูู ุขุฏู ููุดู ูุฑุงููุด ฺฉุงุฑ ูุณุช . ุงูุฏูุงุฑู ููู ุจู ุญุฏุซ ุฎูุดุชู ุจุฑุณู ู ุจุง ุงูู ุฒูุฏฺฏ ฺฉูู.\n",
            "ู ุฑูุงู ูุดุงุจู ฺฉูุงฺฏุฑ ูุฎูุงู ูุชุงุณูุงุชู ุงูู ุฎููุฏู ูฺฏุฑูู ุจุงุฒ ูููู ูุฎููุฏู\n",
            "ู ุฑูุงู ูุดุงุจู ฺฉูุงฺฏุฑ ูุฎูุงู ูุชุงุณูุงุชู ุงูู ุฎููุฏู ูฺฏุฑูู ุจุงุฒ ูููู ูุฎููุฏู\n",
            "ุงู ฺฉุชุงุจ ุฑูุงู ูุณุช ุงูู\n",
            "ุงู ฺฉุชุงุจ ุฑูุงู ูุณุช ุงูู\n",
            "ุณูุงู. ูู ุงู ฺฉุชุงุจ ุฑู ูุจูุง ุฎููุฏู. ุฎู ูุดูฺฏู. ุงุญุชูุงูุง ุชุฑุฌูุด ุฎูุจ ูุจูุฏู ฺฉู ุฌุฐุจ ูุดุฏู. ุงูุจุชู ุจุงุฏ ุนุฑูุงู ุฏูุณุช ุฏุงุดุชู ุจุงุดู ุชุง ุฌุฐุจ ุจุดู.\n",
            "ุณูุงู. ูู ุงู ฺฉุชุงุจ ุฑู ูุจูุง ุฎููุฏู. ุฎู ูุดูฺฏู. ุงุญุชูุงูุง ุชุฑุฌูุด ุฎูุจ ูุจูุฏู ฺฉู ุฌุฐุจ ูุดุฏู. ุงูุจุชู ุจุงุฏ ุนุฑูุงู ุฏูุณุช ุฏุงุดุชู ุจุงุดู ุชุง ุฌุฐุจ ุจุดู.\n",
            "ูู ูุชููุณุชู ุชูููุด ฺฉูู๐ ููุถูุนุด ุจุฏ ูุจูุฏ ูู ุงุตูุง ุฌุฐุจู ูฺฉุฑุฏ ุ ุดุงุฏู ุชุฑุฌูุด ุฌุงูุจ ูุจูุฏ๐ฉ\n",
            "ูู ูุชููุณุชู ุชูููุด ฺฉูู ููุถูุนุด ุจุฏ ูุจูุฏ ูู ุงุตูุง ุฌุฐุจู ูฺฉุฑุฏ ุ ุดุงุฏู ุชุฑุฌูุด ุฌุงูุจ ูุจูุฏ\n",
            "ฺฉ ฺฉุฏ ุนุถูุช ุฏุงุฑู ูุทูุง ุจู ูู ูู ุจุฏู\n",
            "ฺฉ ฺฉุฏ ุนุถูุช ุฏุงุฑู ูุทูุง ุจู ูู ูู ุจุฏู\n",
            "ููู ุงูุนุงุฏู ุงุณุช โค๏ธ\n",
            "ููู ุงูุนุงุฏู ุงุณุช \n",
            "ุฒูุงู ฺฉู ุฎููุฏูุด ูพุฑุงุฒ ุญุณูุง ุฎูุจ ุดุฏู\n",
            "ุฒูุงู ฺฉู ุฎููุฏูุด ูพุฑุงุฒ ุญุณูุง ุฎูุจ ุดุฏู\n",
            "ฺฉุชุงุจ ูุง ูพุงุฆููู ููุดู ฺฏุฑุง ุฎุงุต ุจุฑุงู ุฏุงุดุช ู ุฏุงุฑู.ุจุนุฏ ุงุฒ ุฎููุฏู ฺูุฏุชุง ุงุฒ ฺฉุชุงุจ ูุงุด ูุงุฎูุฏุขฺฏุงู ุฏูุจุงู ูุดุงูู ูฺฏุฑุฏ ุชู ุฏูุง ุงุทุฑุงู ู ุฒูุฏฺฏ ุงุช ูู ููุฏููู ฺุฑุง ฺฉุชุงุจ ุฎุงูุช ุงุด ุฑู ุญุฐู ฺฉุฑุฏูุฏ ุงุฒ ุทุงูฺู\n",
            "ฺฉุชุงุจ ูุง ูพุงุฆููู ููุดู ฺฏุฑุง ุฎุงุต ุจุฑุงู ุฏุงุดุช ู ุฏุงุฑู.ุจุนุฏ ุงุฒ ุฎููุฏู ฺูุฏุชุง ุงุฒ ฺฉุชุงุจ ูุงุด ูุงุฎูุฏุขฺฏุงู ุฏูุจุงู ูุดุงูู ูฺฏุฑุฏ ุชู ุฏูุง ุงุทุฑุงู ู ุฒูุฏฺฏ ุงุช ูู ููุฏููู ฺุฑุง ฺฉุชุงุจ ุฎุงูุช ุงุด ุฑู ุญุฐู ฺฉุฑุฏูุฏ ุงุฒ ุทุงูฺู\n",
            "ุจุง ุงุนุชูุงุฏ ุจู ูุธุฑุงุช ุฎููุฏู ู ุงุฒ ูุงุฌุฑุงุด ุฎูุดูุงู ุขูุฏ :) ูุทูุฆูุง ูุฑฺฉุณ ู ฺฏูุฌ ุฏุงุฑู ฺฉู ุจุด ูุฑุณุฏู ู ููุงูุน ุฌููุดููู ฺฏุฑูุชู ฺฉู ุฏู ฺฉูุฏู ุงุฒุดูู ุณุฎุชู ูุซู ุฎุงููุงุฏูุุฏุฑุงูุฏุุนุดูุุฌุงฺฏุงู ุงุฌุชูุงุน ูู ุญุชูุง ูุดู ุจุง  ุณุฑูุฎุง ุฑุดุฏ ฺฉุฑุฏ ู ุจูุดูู ุฑุณุฏ... ูุณุทุงุดู ุฌููู ูุง ูุดูฺฏ ุฏุฏู.ูพุดููุงุฏ ูุดู\n",
            "ุจุง ุงุนุชูุงุฏ ุจู ูุธุฑุงุช ุฎููุฏู ู ุงุฒ ูุงุฌุฑุงุด ุฎูุดูุงู ุขูุฏ :) ูุทูุฆูุง ูุฑฺฉุณ ู ฺฏูุฌ ุฏุงุฑู ฺฉู ุจุด ูุฑุณุฏู ู ููุงูุน ุฌููุดููู ฺฏุฑูุชู ฺฉู ุฏู ฺฉูุฏู ุงุฒุดูู ุณุฎุชู ูุซู ุฎุงููุงุฏูุุฏุฑุงูุฏุุนุดูุุฌุงฺฏุงู ุงุฌุชูุงุน ูู ุญุชูุง ูุดู ุจุง  ุณุฑูุฎุง ุฑุดุฏ ฺฉุฑุฏ ู ุจูุดูู ุฑุณุฏ... ูุณุทุงุดู ุฌููู ูุง ูุดูฺฏ ุฏุฏู.ูพุดููุงุฏ ูุดู\n",
            "ุขุฎุฑู ุงุฎุจุงุฑ\n",
            "ุดูุจู ฒ ุขุฐุฑ ฑณนธ - ฑด:ดน GMT 11:19\n",
            "ุดูุจู / ฒ ุขุฐุฑ ฑณนธ / ฑด:ฒถ ุฏุณุชูโุจูุฏ: ุงุฑุชุจุงุทุงุช ู ููุงูุฑ ุงุทูุงุนุงุช ฺฉุฏ ุฎุจุฑ: 98090200823 ุฎุจุฑูฺฏุงุฑ : 71088\n",
            "ุงูุชุฑูุช ุฎุงูฺฏ ุงุฒ ุฏูุงู ุฏฺฏุฑ ูุตู ูโุดูุฏ\n",
            "ุงูุชุฑูุช\n",
            "ุงูุชุฑูุช ุฎุงูฺฏ ุชูุฑุงู ู ฺฉูุงูุดูุฑูุง ฺฉุดูุฑ ุชุง ุฏูุงู ุฏฺฏุฑ ุจุฑูุฑุงุฑ ูโุดูุฏ.\n",
            "ฺฉ ููุจุน ุขฺฏุงู ุฏุฑ ูุฒุงุฑุช ุงุฑุชุจุงุทุงุช ุฏุฑ ฺฏูุชโูฺฏู ุจุง ุงุณูุง ุชุงุฏ ฺฉุฑุฏ ฺฉู ุจุง ุฏุฑุงูุช ูุฌูุฒูุง ูุงุฒูุ ุงูุชุฑูุช ุฎุงูฺฏ ุชูุฑุงู ู ุชุนุฏุงุฏ ุฒุงุฏ ุงุฒ ฺฉูุงูุดูุฑูุง ฺฉุดูุฑ ุชุง ุฏูุงู ุฏฺฏุฑ ุจุฑูุฑุงุฑ ุฎูุงูุฏ ุดุฏ.\n",
            "ุงูุชุฑูุช ุฎุงูฺฏ ฺูุฏ ุงุณุชุงู ุจุฑูุฑุงุฑ ุดุฏ\n",
            "ุจุฑุฑุณโูุง ุงุณูุง ูุดุงู ูโุฏูุฏ ุฑูุฒ ฺฏุฐุดุชู ุงูุชุฑูุช ุฎุงูฺฏ ุฏุฑ ฺูุฏ ุงุณุชุงู ฺฉุดูุฑ ุจุฑูุฑุงุฑ ุดุฏู ุงุณุช.\n",
            "ฺฏุฒุงุฑุด ูุงุตูู ุงุฒ ุฎุจุฑูฺฏุงุฑุงู ุงุณูุง ุฏุฑ ุงุณุชุงูโูุง ุฎุฑุงุณุงู ุดูุงูุ ุฎุฑุงุณุงู ุฌููุจุ ฺฏูุณุชุงูุ ุณููุงูุ ุฒุฏุ ููุฏุงูุ ฺูุงุฑูุญุงู ู ุจุฎุชุงุฑุ ุงุฑุฏุจูุ ุฒูุฌุงู ู ุงูุงู ุญุงฺฉ ุงุฒ ุจุฑูุฑุงุฑ ุงูุชุฑูุชโูุง ุฎุงูฺฏ ุฏุฑ ุงู ุงุณุชุงูโูุงุณุช.\n",
            "ุงูุฑูุฒ ููฺูู ฺฉ ุงุฒ ุฑุณุงููโูุง ุฏุงุฎู ุงุนูุงู ฺฉุฑุฏ ฺฉู ุงูุชุฑูุช ููุฑุงู ูุฒ ุงุญุชูุงูุง ุชุง ุตุจุญ ูุฑุฏุง ฺฉุดูุจู ณ ุขุฐุฑ ูุตู ูโุดูุฏ.\n",
            "ุงุณูุง ุฏุฑ ุชูุงุด ุงุณุช ุฏุฑ ุฎุตูุต ุงู ููุถูุน ุงุทูุงุนุงุช ุจุดุชุฑ ฺฉุณุจ ฺฉูุฏ.\n",
            "ุขุฎุฑู ุงุฎุจุงุฑ\n",
            "ุดูุจู ฒ ุขุฐุฑ ฑณนธ - ฑด:ดน GMT 11:19\n",
            "ุดูุจู / ฒ ุขุฐุฑ ฑณนธ / ฑด:ฒถ ุฏุณุชูโุจูุฏ: ุงุฑุชุจุงุทุงุช ู ููุงูุฑ ุงุทูุงุนุงุช ฺฉุฏ ุฎุจุฑ: 98090200823 ุฎุจุฑูฺฏุงุฑ : 71088\n",
            "ุงูุชุฑูุช ุฎุงูฺฏ ุงุฒ ุฏูุงู ุฏฺฏุฑ ูุตู ูโุดูุฏ\n",
            "ุงูุชุฑูุช\n",
            "ุงูุชุฑูุช ุฎุงูฺฏ ุชูุฑุงู ู ฺฉูุงูุดูุฑูุง ฺฉุดูุฑ ุชุง ุฏูุงู ุฏฺฏุฑ ุจุฑูุฑุงุฑ ูโุดูุฏ.\n",
            "ฺฉ ููุจุน ุขฺฏุงู ุฏุฑ ูุฒุงุฑุช ุงุฑุชุจุงุทุงุช ุฏุฑ ฺฏูุชโูฺฏู ุจุง ุงุณูุง ุชุงุฏ ฺฉุฑุฏ ฺฉู ุจุง ุฏุฑุงูุช ูุฌูุฒูุง ูุงุฒูุ ุงูุชุฑูุช ุฎุงูฺฏ ุชูุฑุงู ู ุชุนุฏุงุฏ ุฒุงุฏ ุงุฒ ฺฉูุงูุดูุฑูุง ฺฉุดูุฑ ุชุง ุฏูุงู ุฏฺฏุฑ ุจุฑูุฑุงุฑ ุฎูุงูุฏ ุดุฏ.\n",
            "ุงูุชุฑูุช ุฎุงูฺฏ ฺูุฏ ุงุณุชุงู ุจุฑูุฑุงุฑ ุดุฏ\n",
            "ุจุฑุฑุณโูุง ุงุณูุง ูุดุงู ูโุฏูุฏ ุฑูุฒ ฺฏุฐุดุชู ุงูุชุฑูุช ุฎุงูฺฏ ุฏุฑ ฺูุฏ ุงุณุชุงู ฺฉุดูุฑ ุจุฑูุฑุงุฑ ุดุฏู ุงุณุช.\n",
            "ฺฏุฒุงุฑุด ูุงุตูู ุงุฒ ุฎุจุฑูฺฏุงุฑุงู ุงุณูุง ุฏุฑ ุงุณุชุงูโูุง ุฎุฑุงุณุงู ุดูุงูุ ุฎุฑุงุณุงู ุฌููุจุ ฺฏูุณุชุงูุ ุณููุงูุ ุฒุฏุ ููุฏุงูุ ฺูุงุฑูุญุงู ู ุจุฎุชุงุฑุ ุงุฑุฏุจูุ ุฒูุฌุงู ู ุงูุงู ุญุงฺฉ ุงุฒ ุจุฑูุฑุงุฑ ุงูุชุฑูุชโูุง ุฎุงูฺฏ ุฏุฑ ุงู ุงุณุชุงูโูุงุณุช.\n",
            "ุงูุฑูุฒ ููฺูู ฺฉ ุงุฒ ุฑุณุงููโูุง ุฏุงุฎู ุงุนูุงู ฺฉุฑุฏ ฺฉู ุงูุชุฑูุช ููุฑุงู ูุฒ ุงุญุชูุงูุง ุชุง ุตุจุญ ูุฑุฏุง ฺฉุดูุจู ณ ุขุฐุฑ ูุตู ูโุดูุฏ.\n",
            "ุงุณูุง ุฏุฑ ุชูุงุด ุงุณุช ุฏุฑ ุฎุตูุต ุงู ููุถูุน ุงุทูุงุนุงุช ุจุดุชุฑ ฺฉุณุจ ฺฉูุฏ.\n",
            "ฺฉุชุงุจ ุฎูุจ ุจูุฏ.\n",
            "ุจูุธุฑู ูุง ฺฉุชุงุจ. ูุฎููู ฺฉู ฺุฒูุง ุฌุฏุฏ ุงุฒ ุงูุณุงู ูุง ููุฑููฺฏ ูฺฉุดูุฑูุง ุฏฺฏู ุงุฏุจฺฏุฑู ูุจุชููู ุจุงูู ููุงุณู ฺฉูู ูุจุนุฏ ูุชุฌู ฺฏุฑ ฺฉูู.ุดุฎุต ฺฏูุชู ุจูุฏู ฺฉู ุงู ฺฉุชุงุจ ููุงูู ููพุงุฆููู ุงูุฌูุฑ.\n",
            "ูุง ฺฉุชุงุจ ุฑู ูุฎููู ููฺฉุฑ ูฺฉูู ูู ุงูฺฉู ููุดู ูุจูู ุฏุงุดุชู ุจุงุดู.\n",
            "ูุชุฌู ุง ฺฉู ูู ุงุฒุงู ฺฉุชุงุจ ฺฏุฑูุชู ุงูู ฺฉู ุจุงุฏุงุตู ุฎูุฏูููู ูุงุฏุฏู ูฺฏุฑู.\n",
            "ฺฉุชุงุจ ุฎูุจ ุจูุฏ.\n",
            "ุจูุธุฑู ูุง ฺฉุชุงุจ. ูุฎููู ฺฉู ฺุฒูุง ุฌุฏุฏ ุงุฒ ุงูุณุงู ูุง ููุฑููฺฏ ูฺฉุดูุฑูุง ุฏฺฏู ุงุฏุจฺฏุฑู ูุจุชููู ุจุงูู ููุงุณู ฺฉูู ูุจุนุฏ ูุชุฌู ฺฏุฑ ฺฉูู.ุดุฎุต ฺฏูุชู ุจูุฏู ฺฉู ุงู ฺฉุชุงุจ ููุงูู ููพุงุฆููู ุงูุฌูุฑ.\n",
            "ูุง ฺฉุชุงุจ ุฑู ูุฎููู ููฺฉุฑ ูฺฉูู ูู ุงูฺฉู ููุดู ูุจูู ุฏุงุดุชู ุจุงุดู.\n",
            "ูุชุฌู ุง ฺฉู ูู ุงุฒุงู ฺฉุชุงุจ ฺฏุฑูุชู ุงูู ฺฉู ุจุงุฏุงุตู ุฎูุฏูููู ูุงุฏุฏู ูฺฏุฑู.\n",
            "ูู ุฎูุฏู ฺฉุชุงุจ ู ุฏุงุฑู ู ุฎููุฏู ูุงูุนุง ฺฉ ุงุฒ ุจูุชุฑู ฺฉุชุงุจุงู ฺฉ ูุดู ุฎููุฏ\n",
            "ูู ุฎูุฏู ฺฉุชุงุจ ู ุฏุงุฑู ู ุฎููุฏู ูุงูุนุง ฺฉ ุงุฒ ุจูุชุฑู ฺฉุชุงุจุงู ฺฉ ูุดู ุฎููุฏ\n",
            "ุฏูุณุชุงู ูุช ูุฎุงุจุฑุงุช ุชู ุชูุฑุงู ฺฉุณ ูุตู ุดุฏูุุุุุ\n",
            "ุฏูุณุชุงู ูุช ูุฎุงุจุฑุงุช ุชู ุชูุฑุงู ฺฉุณ ูุตู ุดุฏูุุุุุ\n",
            "ุฑูุงู ุจุณุงุฑ ุชุงุซุฑ ฺฏุฐุงุฑ\n",
            "ุฑูุงู ุจุณุงุฑ ุชุงุซุฑ ฺฏุฐุงุฑ\n",
            "ุงู ฺฉุชุงุจ ุจุงุนุซ ุจูุฌูุฏ ุงููุฏู ุงูุณุงู ุฏฺฏู ูุดู ุฏุฑ ููู ุฎูุงููุฏฺฏุงู\n",
            "ุงู ฺฉุชุงุจ ุจุงุนุซ ุจูุฌูุฏ ุงููุฏู ุงูุณุงู ุฏฺฏู ูุดู ุฏุฑ ููู ุฎูุงููุฏฺฏุงู\n",
            "ุฏุงุฑู ู ูุฑู ุงุฒ ุจ ูุช ุฎุฏุงุงุงุงุงุง ุชุง ฺฉ ุขุฎู๐ญ๐ญ๐ญ\n",
            "ุฏุงุฑู ู ูุฑู ุงุฒ ุจ ูุช ุฎุฏุงุงุงุงุงุง ุชุง ฺฉ ุขุฎู\n",
            "ูู ุตูุชุดู ูุจูุง ฺฏูุด ุฏุงุฏู ุฎู ูุฐุช ุจุฑุฏู ูุงูุนุง ุนุงูู\n",
            "ูู ุตูุชุดู ูุจูุง ฺฏูุด ุฏุงุฏู ุฎู ูุฐุช ุจุฑุฏู ูุงูุนุง ุนุงูู\n",
            "ุจูุชุฑูู ู ุจุณ\n",
            "ุจุงุฏ ุนูู ู ุจุง ุญูุตูู ุจุฎููุฏุด ุุณุฑุณุฑ ุงุฒุด ูฺฏุฐุฑุฏ\n",
            "ููู ุงูุนุงุฏุณุช ุจู ูุนูุง ูุงูุน ฺฉููู\n",
            "ุจูุชุฑูู ู ุจุณ\n",
            "ุจุงุฏ ุนูู ู ุจุง ุญูุตูู ุจุฎููุฏุด ุุณุฑุณุฑ ุงุฒุด ูฺฏุฐุฑุฏ\n",
            "ููู ุงูุนุงุฏุณุช ุจู ูุนูุง ูุงูุน ฺฉููู\n",
            "ุจุง ููู ุณุฎุช ูุง ู ูุดฺฉูุงุช ุจู ุฑุงูุช ุงุฏุงูู ุจุฏู ุชุง ุจู ุขุฑุฒู ู ุฎูุงุณุชู ุงุช ุจุฑุณ.\n",
            "ุจู ูุธุฑู ุฎู ุชุงุชุฑ ุฏุงุฑู ุจุฑุง ุฑูุด ุฒูุฏฺฏุ ูุฎุตูุตุง ุจุฑุง ููุฌูุงู ูุง.\n",
            "ุจุง ููู ุณุฎุช ูุง ู ูุดฺฉูุงุช ุจู ุฑุงูุช ุงุฏุงูู ุจุฏู ุชุง ุจู ุขุฑุฒู ู ุฎูุงุณุชู ุงุช ุจุฑุณ.\n",
            "ุจู ูุธุฑู ุฎู ุชุงุชุฑ ุฏุงุฑู ุจุฑุง ุฑูุด ุฒูุฏฺฏุ ูุฎุตูุตุง ุจุฑุง ููุฌูุงู ูุง.\n",
            "ุงููุด ฺฉู ูุฎูู ุฌุฐุจุช ูฺฉูู ุงูุง ูุฑ ฺ ูุฑู ุฌููุชุฑ ุญุณ ูฺฉู ุฎุจุฑ ุงุฒ ุงูู ูพุงู ูุง ูุซุจุช ูุณุช ู ุญุช ู ุณุฑ ูฺฉุงุช ุงุดุชุจุงู ูู ุฏุงุฑู ู ูุดู ฺฏูุช ูุญุชูุง ฺฉุงููุง ุดุนุงุฑ ุฏุงุฑู.\n",
            "ุงุฒูฺฉู ุงุฒ ูุณููุงู ูุง ู ุงุณูุงู ูู ุตุญุจุช ุดุฏ ุฏุฑ ุงู ฺฉุชุงุจ ุฎู ุฎูุดู ูููุฏ ุจู ูฺฉุงุช ูุซุจุช ุงุดุงุฑู ูุดุฏู ุจูุฏ.\n",
            "ุงููุด ฺฉู ูุฎูู ุฌุฐุจุช ูฺฉูู ุงูุง ูุฑ ฺ ูุฑู ุฌููุชุฑ ุญุณ ูฺฉู ุฎุจุฑ ุงุฒ ุงูู ูพุงู ูุง ูุซุจุช ูุณุช ู ุญุช ู ุณุฑ ูฺฉุงุช ุงุดุชุจุงู ูู ุฏุงุฑู ู ูุดู ฺฏูุช ูุญุชูุง ฺฉุงููุง ุดุนุงุฑ ุฏุงุฑู.\n",
            "ุงุฒูฺฉู ุงุฒ ูุณููุงู ูุง ู ุงุณูุงู ูู ุตุญุจุช ุดุฏ ุฏุฑ ุงู ฺฉุชุงุจ ุฎู ุฎูุดู ูููุฏ ุจู ูฺฉุงุช ูุซุจุช ุงุดุงุฑู ูุดุฏู ุจูุฏ.\n",
            "ูู ุตูุชุด ุฑู ฺฏูุด ุฏุงุฏู ุจุง ุตุฏุง ูุญุณู ูุงูุฌู ุนุฒุฒ ุนุงู\n",
            "ูู ุตูุชุด ุฑู ฺฏูุด ุฏุงุฏู ุจุง ุตุฏุง ูุญุณู ูุงูุฌู ุนุฒุฒ ุนุงู\n",
            "ุนุงู ุจูุฏ ุจู ูุนูุง ูุงูุน ฺฉููู.\n",
            "ุนุงู ุจูุฏ ุจู ูุนูุง ูุงูุน ฺฉููู.\n",
            "ุงููุง ฺฉุชุงุจ ุฑู ุจุง ุชุฑุฌูู ุขุฑุด ุญุฌุงุฒ ุจุฎููุฏ. ุฏููุง ุฏุฑ ูุธุฑ ุงูู ฺฉุชุงุจ ุจุณุงุฑ ูพุฑ ูุบุฒ ู ุนุงู ุจู ูุธุฑ ูุงุฏ ฺฉู ุดูุง ุฑู ูุฌุจูุฑ ูฺฉูู ุณุงุนุช ูุง ุจู ุงูู ูฺฉุฑ ฺฉูุฏ ูู ุจุง ฺฉู ุชุงูู ูุชูุฌู ูุดุฏ ฺฉู ููุถูุนุงุช ุฏุฑ ฺฉุชุงุจ ฺฏูุชู ุดุฏู ฺฉู ููุฏูุง ุฌุฏ ุจู ุขู ูุงุฑุฏู.\n",
            "ุงููุง ฺฉุชุงุจ ุฑู ุจุง ุชุฑุฌูู ุขุฑุด ุญุฌุงุฒ ุจุฎููุฏ. ุฏููุง ุฏุฑ ูุธุฑ ุงูู ฺฉุชุงุจ ุจุณุงุฑ ูพุฑ ูุบุฒ ู ุนุงู ุจู ูุธุฑ ูุงุฏ ฺฉู ุดูุง ุฑู ูุฌุจูุฑ ูฺฉูู ุณุงุนุช ูุง ุจู ุงูู ูฺฉุฑ ฺฉูุฏ ูู ุจุง ฺฉู ุชุงูู ูุชูุฌู ูุดุฏ ฺฉู ููุถูุนุงุช ุฏุฑ ฺฉุชุงุจ ฺฏูุชู ุดุฏู ฺฉู ููุฏูุง ุฌุฏ ุจู ุขู ูุงุฑุฏู.\n",
            "ุชูุตู ูฺฉูู ูุณุฎู ุตูุช ุงู ฺฉุชุงุจ ุจุง ุตุฏุง ูุงูุฌู ุฑู ฺฏูุด ุจุฏุฏ. ุงุฌุฑุง ุนุงู ุฏุงุฑู ููุฑุงู ุจุง ูพุณ ุฒููู ูุง ุตูุช ุฒุจุง.\n",
            "ุชูุตู ูฺฉูู ูุณุฎู ุตูุช ุงู ฺฉุชุงุจ ุจุง ุตุฏุง ูุงูุฌู ุฑู ฺฏูุด ุจุฏุฏ. ุงุฌุฑุง ุนุงู ุฏุงุฑู ููุฑุงู ุจุง ูพุณ ุฒููู ูุง ุตูุช ุฒุจุง.\n",
            "ูู ุงู ฺฉุชุงุจ ุฑู ุฏุงุฑู\n",
            "ุฎู ุฎูุจ ุจูุฏ\n",
            "ุชูุด ูุดู ูฺฉุชู ููู ุฒุงุฏ ูพุฏุง ฺฉุฑุฏ ูุงุณู ุฒูุฏฺฏ\n",
            "ุจุฎูููุด...\n",
            "ูู ุงู ฺฉุชุงุจ ุฑู ุฏุงุฑู\n",
            "ุฎู ุฎูุจ ุจูุฏ\n",
            "ุชูุด ูุดู ูฺฉุชู ููู ุฒุงุฏ ูพุฏุง ฺฉุฑุฏ ูุงุณู ุฒูุฏฺฏ\n",
            "ุจุฎูููุด...\n",
            "ุงู ฺฉุชุงุจ ู ฺฉูพ ุงุฒ ุฏูุชุฑ ุดุดู ูููู ูุณุช.\n",
            "ุงู ฺฉุชุงุจ ู ฺฉูพ ุงุฒ ุฏูุชุฑ ุดุดู ูููู ูุณุช.\n",
            "ฺฉุชุงุจ ุฎูุจู ุญุชูุง ุจุฎูููุด\n",
            "ฺฉุชุงุจ ุฎูุจู ุญุชูุง ุจุฎูููุด\n",
            "ูู ุตูุช ุงู ฺฉุชุงุจ ุฑู ฺฏูุด ุฏุงุฏู.ฺฉูุง ุฎู ุงุฒ ฺฉุชุงุจุง ูพุงุฆููู ฺฉูุฆูู ุฎูุดู ููุงุฏ ูู ุงู ฺฉ ุนุงู ุจูุฏ ูุงูุนุง ุจุง ูุฐุช ฺฏูุด ุฏุงุฏู ูุดู ฺฏูุช ู ุฑูุด ุฒูุฏฺฏู\n",
            "ูู ุตูุช ุงู ฺฉุชุงุจ ุฑู ฺฏูุด ุฏุงุฏู.ฺฉูุง ุฎู ุงุฒ ฺฉุชุงุจุง ูพุงุฆููู ฺฉูุฆูู ุฎูุดู ููุงุฏ ูู ุงู ฺฉ ุนุงู ุจูุฏ ูุงูุนุง ุจุง ูุฐุช ฺฏูุด ุฏุงุฏู ูุดู ฺฏูุช ู ุฑูุด ุฒูุฏฺฏู\n",
            "ุจูุชุฑู ฺฉุชุงุจ ฺฉู ุชุง ุญุงูุง ุฎููุฏู ุณุงู ฺฉุจุงุฑ ุจุงุฏ ุฎููุฏู ุจุดู ุจู ุดุฎุตู ููู ุนุงุดู ุตุญุฑุง ู ูุงุฌุฑุงุฌู ฺฉุฑุฏ :)\n",
            "ุจูุชุฑู ุชุฑุฌูู ูู ูุชุนูู ุจู ุขูุง ุขุฑุด ุญุฌุงุฒ ูุณุช ุงู ุดุงุงููู ุงฺฉุซุฑ ุงููุง ฺฉู ุฏุฑฺฉ ุฎูุจ ุงุฒ ฺฉุชุงุจ ุฏุงุดุชู ุงูุณุงูู ุดุฎุต ุดูู ุฑู ุฌุณุชุฌู ฺฉูู ู ูููู ุจุงุดู :)\n",
            "ุจูุชุฑู ฺฉุชุงุจ ฺฉู ุชุง ุญุงูุง ุฎููุฏู ุณุงู ฺฉุจุงุฑ ุจุงุฏ ุฎููุฏู ุจุดู ุจู ุดุฎุตู ููู ุนุงุดู ุตุญุฑุง ู ูุงุฌุฑุงุฌู ฺฉุฑุฏ :)\n",
            "ุจูุชุฑู ุชุฑุฌูู ูู ูุชุนูู ุจู ุขูุง ุขุฑุด ุญุฌุงุฒ ูุณุช ุงู ุดุงุงููู ุงฺฉุซุฑ ุงููุง ฺฉู ุฏุฑฺฉ ุฎูุจ ุงุฒ ฺฉุชุงุจ ุฏุงุดุชู ุงูุณุงูู ุดุฎุต ุดูู ุฑู ุฌุณุชุฌู ฺฉูู ู ูููู ุจุงุดู :)\n",
            "ุฒูุฏฺฏ ู ูุดุงูู ูุง\n",
            "ุจุฏูุจุงู ูุดุงูู ูุง ุฑูุชู ฺฉ ฺุฒู ู ุฏุฑฺฉ ุฏุฑุณุช ุงุฒ ูุดุงูู ูุง ฺฉ ฺุฒ ุฏฺฏุฑ\n",
            "ุฒูุฏฺฏ ู ูุดุงูู ูุง\n",
            "ุจุฏูุจุงู ูุดุงูู ูุง ุฑูุชู ฺฉ ฺุฒู ู ุฏุฑฺฉ ุฏุฑุณุช ุงุฒ ูุดุงูู ูุง ฺฉ ฺุฒ ุฏฺฏุฑ\n",
            "ุฌุงูุจ ูุจูุฏ... .\n",
            "ุฌุงูุจ ูุจูุฏ... .\n",
            "ฺฉูุง ููุดุชู ูุง ูพุงุฆููู ฺฉูุฆูู ุณููู ูู ูุณุช ุงูุง ูุณุฎู ุตูุช ฺฉูุงฺฏุฑ ุฑู ฺฏูุด ุฏุงุฏู ู ูุงูุนุง ุฏูุณุชุด ุฏุงุดุชู. ุฌุฒ ฺฉุชุงุจูุง ูุณุช ฺฉู ูพุดููุงุฏ ูฺฉูู ุฏุฑ ุฎููุฏูุด ุดฺฉ ูฺฉูุฏ. ูู ูุนู ู ููููู ุนูู ุฏุงุฑู ู ูู ุฎู ุฎูุงูุงูู ุฑูุงุช ุดุฏู. ูพุดููุงุฏ ูฺฉูู ูุณุฎู ุตูุช ุจุง ุตุฏุง ูุญุณู ูุงูุฌู ุฑู ฺฏูุด ฺฉูุฏ.\n",
            "ฺฉูุง ููุดุชู ูุง ูพุงุฆููู ฺฉูุฆูู ุณููู ูู ูุณุช ุงูุง ูุณุฎู ุตูุช ฺฉูุงฺฏุฑ ุฑู ฺฏูุด ุฏุงุฏู ู ูุงูุนุง ุฏูุณุชุด ุฏุงุดุชู. ุฌุฒ ฺฉุชุงุจูุง ูุณุช ฺฉู ูพุดููุงุฏ ูฺฉูู ุฏุฑ ุฎููุฏูุด ุดฺฉ ูฺฉูุฏ. ูู ูุนู ู ููููู ุนูู ุฏุงุฑู ู ูู ุฎู ุฎูุงูุงูู ุฑูุงุช ุดุฏู. ูพุดููุงุฏ ูฺฉูู ูุณุฎู ุตูุช ุจุง ุตุฏุง ูุญุณู ูุงูุฌู ุฑู ฺฏูุด ฺฉูุฏ.\n",
            "ุฏุฑ ูุฏุช ฺฉูุชุฑ ุงุฒ ฺฉ ุฑูุฒ ุชูุงูุด ฺฉุฑุฏูุุฒุจุง ุจูุฏุุจู ุขุฏู ุงูฺฏุฒู ูุฏู\n",
            "ุฏุฑ ูุฏุช ฺฉูุชุฑ ุงุฒ ฺฉ ุฑูุฒ ุชูุงูุด ฺฉุฑุฏูุุฒุจุง ุจูุฏุุจู ุขุฏู ุงูฺฏุฒู ูุฏู\n",
            "ุจุณุงุฑฺฉุชุงุจ ุข ูู ุฒูุฏู ุง ุจูุฏ\n",
            "ุจุณุงุฑฺฉุชุงุจ ุข ูู ุฒูุฏู ุง ุจูุฏ\n",
            "ุนุงู ุจูุฏ๐๐๐\n",
            "ุนุงู ุจูุฏ\n",
            "ุฌุง ุฏุงุฑู ฺฉุจุงุฑ ุฏฺฏู ูู ุจุฎูููุด\n",
            "ุฌุง ุฏุงุฑู ฺฉุจุงุฑ ุฏฺฏู ูู ุจุฎูููุด\n",
            "ุฎุจ ุฏุฑุณุชู ูพูุฌ ุชููู ูพูู ูุณ ูู ู ฺ ฺฉู ูุณุฎู ุงูฺฉุชุฑููฺฉ ู ฺุงูพุด ููุชุด ฺฉ ุจุงุดูุ\n",
            "ุฎุจ ุฏุฑุณุชู ูพูุฌ ุชููู ูพูู ูุณ ูู ู ฺ ฺฉู ูุณุฎู ุงูฺฉุชุฑููฺฉ ู ฺุงูพุด ููุชุด ฺฉ ุจุงุดูุ\n",
            "ุนุงู ุฎู ูุดูฺฏ ู ุงููุฒูุฏู ูุงูุนุง ุฏุฑฺฉ ุจุงูุง ูุฎูุงุฏ ูููุฏู ุงู ฺฉุชุงุจ\n",
            "ุนุงู ุฎู ูุดูฺฏ ู ุงููุฒูุฏู ูุงูุนุง ุฏุฑฺฉ ุจุงูุง ูุฎูุงุฏ ูููุฏู ุงู ฺฉุชุงุจ\n",
            "ูุงูุนุง ฺฉุณู ฺฉููุฏู ุงุณ ุจุฒูุฑ ุชุง ุตูุญู  ฑตฐ ุฎููุฏู ููุฏููู ฺุฑุง ุงููุฏ ุงู ฺฉุชุงุจ ูุนุฑูู ู ูพุฑูุฑูุด ุจูุฏู!!! ุง ุชุฑุฌูู ูุดฺฉู ุฏุงุฑู ุง ุฎูุฏ ฺฉุชุงุจ ูุฏูุด ุงูู ฺฉ ุฎูุดู ูููุฏ\n",
            "ูุงูุนุง ฺฉุณู ฺฉููุฏู ุงุณ ุจุฒูุฑ ุชุง ุตูุญู  ฑตฐ ุฎููุฏู ููุฏููู ฺุฑุง ุงููุฏ ุงู ฺฉุชุงุจ ูุนุฑูู ู ูพุฑูุฑูุด ุจูุฏู!!! ุง ุชุฑุฌูู ูุดฺฉู ุฏุงุฑู ุง ุฎูุฏ ฺฉุชุงุจ ูุฏูุด ุงูู ฺฉ ุฎูุดู ูููุฏ\n",
            "ูู ุงู ฺฉุชุงุจ ุฑู ุฑุงูููุง ุจูุฏู ุดุฑูุน ฺฉุฑุฏู ุจู ุฎููุฏู\n",
            "ุงููุฏุฑ ุจุฏู ุงููุฏ ููุด ฺฉุฑุฏู ๐\n",
            "ู ูููุฒ ูู ููููุฏู ฺุฑุง ุงูููู ูุนุฑููู ู ุทุฑูุฏุงุฑ ุฏุงุฑูุ!\n",
            "ููุฏููู ุณู ููุงุณุจ ูุจูุฏ ุง ุชุฑุฌูู ุจุฏ ุจูุฏุ ูู ุฏฺฏู ุฏูุณุช ูุฏุงุดุชู ุณูุชุด ุจุฑู!\n",
            "ูู ุงู ฺฉุชุงุจ ุฑู ุฑุงูููุง ุจูุฏู ุดุฑูุน ฺฉุฑุฏู ุจู ุฎููุฏู\n",
            "ุงููุฏุฑ ุจุฏู ุงููุฏ ููุด ฺฉุฑุฏู \n",
            "ู ูููุฒ ูู ููููุฏู ฺุฑุง ุงูููู ูุนุฑููู ู ุทุฑูุฏุงุฑ ุฏุงุฑูุ!\n",
            "ููุฏููู ุณู ููุงุณุจ ูุจูุฏ ุง ุชุฑุฌูู ุจุฏ ุจูุฏุ ูู ุฏฺฏู ุฏูุณุช ูุฏุงุดุชู ุณูุชุด ุจุฑู!\n",
            "ฺุฒ ฺฉู ูู ุงุฒ ุงู ฺฉุชุงุจ ูููุฏู ุงูู ฺฉู ููุช ุจู ุฏูุจุงู ุงุฑุฒู ูุง ูุฑู ู ุงุฏู ูุฑุฏู ุจู ุญุณุงุจ ูุงู ูุฑู ููฺฉูู ูุฏูููู ฺูุฏุฑ ุฎุทุฑูุงฺฉ ุจุงุดู ู ุญุช ุฌููููู ูู ุจู ุฎุทุฑ ุจูุฏุงุฒู ุฏุฑ ูุฑ ุตูุฑุช ุจุงุฏ ุฏูุจุงู ฺุฒ ฺฉู ูุฎูุงู ุจุงุดู. ุฏุงุณุชุงู ุฏุฑ ุทูู ฺฉุชุงุจ ุจู ุฎูุจ ฺฏูุชู ุดุฏู ู ุฌุง ุงุจูุงู ููุฒุงุฑู ูู ุงุฎุฑ ฺฉุชุงุจ ูุงูุนุง ุนุงู ุชููู ูุดู ุงุตูุง ุงูุชุธุงุฑ ููฺู ูพุงุงู ุฑู ูุฏุงุดุชู.\n",
            "ฺุฒ ฺฉู ูู ุงุฒ ุงู ฺฉุชุงุจ ูููุฏู ุงูู ฺฉู ููุช ุจู ุฏูุจุงู ุงุฑุฒู ูุง ูุฑู ู ุงุฏู ูุฑุฏู ุจู ุญุณุงุจ ูุงู ูุฑู ููฺฉูู ูุฏูููู ฺูุฏุฑ ุฎุทุฑูุงฺฉ ุจุงุดู ู ุญุช ุฌููููู ูู ุจู ุฎุทุฑ ุจูุฏุงุฒู ุฏุฑ ูุฑ ุตูุฑุช ุจุงุฏ ุฏูุจุงู ฺุฒ ฺฉู ูุฎูุงู ุจุงุดู. ุฏุงุณุชุงู ุฏุฑ ุทูู ฺฉุชุงุจ ุจู ุฎูุจ ฺฏูุชู ุดุฏู ู ุฌุง ุงุจูุงู ููุฒุงุฑู ูู ุงุฎุฑ ฺฉุชุงุจ ูุงูุนุง ุนุงู ุชููู ูุดู ุงุตูุง ุงูุชุธุงุฑ ููฺู ูพุงุงู ุฑู ูุฏุงุดุชู.\n",
            "ูู ุงู ฺฉุชุงุจ ุฑู ุงุฒ ุฑู ูุงู pdf ุฎููุฏู ฺฉู ูู ูุงู ูุงุดุฑ ุฏุงุดุช ู ูู ูุชุฑุฌู. ฺฉุชุงุจ ุงุฒ ูุธุฑ ุฑูุง ุฒุจุง ููุดุชู ุดุฏู ุจูุฏ. ุชููุณุช ฺฉ ูุซู ูู ุฑู ฺฉู ูุณุจุช ุจู ฺฉุชุงุจูุง ุนุฑูุงู ู ูุนูู ููุถุน ุฏุงุฑู ุฑู ุฑุงุญุช ุจู ุฏูุจุงู ุฎูุฏุด ุจฺฉุดู. ุงุฒ ูพุงุฆููู ฺฉููู ุฎูุดู ูู ุงููุฏ ุจุฎุงุทุฑ ุชูุตู ฺฉู ุฏฺฏุฑุงู ุงุฒ ฺฉุงุฑุงุด ุฏุงุดุชู. ูฺฏูุชู ุฏุฑุจุงุฑู ุนุฑูุงู ูููุณู. ุงูฺฉู ุฎูุฏู ุฑู ูุฌุจูุฑ ุจู ุฎููุฏู ฺฉ ุงุฒ ุขุซุงุฑุด ฺฉูู ุจุฑุงู ฺุงูุด ุจุฑุงูฺฏุฒ ุจูุฏ. ุงูุง ุงุฒ ฺฉุชุงุจุด ูุฐุช ุจุฑุฏู. ุงุญุชูุงูุง ุจุงุฒ ูู ุงุฒ ฺฉุงุฑุงุด ุฎูุงูู ุฎููุฏ.\n",
            "ฺฉุชุงุจุด ูู ุฑู ุงุฏ ฺฉุชุงุจ \"ุดุจ ุขุชุดู\" ุงุซุฑ \"ุงุฑฺฉ ุงูุงููุฆู ุงุดูุช\" ุงูุฏุงุฎุช. ู ุฌูุฑุง ุญุงู ู ููุง ุงูู ุฑู ุฏุงุดุช.\n",
            "ูู ุงู ฺฉุชุงุจ ุฑู ุงุฒ ุฑู ูุงู pdf ุฎููุฏู ฺฉู ูู ูุงู ูุงุดุฑ ุฏุงุดุช ู ูู ูุชุฑุฌู. ฺฉุชุงุจ ุงุฒ ูุธุฑ ุฑูุง ุฒุจุง ููุดุชู ุดุฏู ุจูุฏ. ุชููุณุช ฺฉ ูุซู ูู ุฑู ฺฉู ูุณุจุช ุจู ฺฉุชุงุจูุง ุนุฑูุงู ู ูุนูู ููุถุน ุฏุงุฑู ุฑู ุฑุงุญุช ุจู ุฏูุจุงู ุฎูุฏุด ุจฺฉุดู. ุงุฒ ูพุงุฆููู ฺฉููู ุฎูุดู ูู ุงููุฏ ุจุฎุงุทุฑ ุชูุตู ฺฉู ุฏฺฏุฑุงู ุงุฒ ฺฉุงุฑุงุด ุฏุงุดุชู. ูฺฏูุชู ุฏุฑุจุงุฑู ุนุฑูุงู ูููุณู. ุงูฺฉู ุฎูุฏู ุฑู ูุฌุจูุฑ ุจู ุฎููุฏู ฺฉ ุงุฒ ุขุซุงุฑุด ฺฉูู ุจุฑุงู ฺุงูุด ุจุฑุงูฺฏุฒ ุจูุฏ. ุงูุง ุงุฒ ฺฉุชุงุจุด ูุฐุช ุจุฑุฏู. ุงุญุชูุงูุง ุจุงุฒ ูู ุงุฒ ฺฉุงุฑุงุด ุฎูุงูู ุฎููุฏ.\n",
            "ฺฉุชุงุจุด ูู ุฑู ุงุฏ ฺฉุชุงุจ \"ุดุจ ุขุชุดู\" ุงุซุฑ \"ุงุฑฺฉ ุงูุงููุฆู ุงุดูุช\" ุงูุฏุงุฎุช. ู ุฌูุฑุง ุญุงู ู ููุง ุงูู ุฑู ุฏุงุดุช.\n",
            "ฺฉุชุงุจ ุฏู ููุงุฒ ูู ุฏุฑ ูุจุงุญุซ ูุงุฑุฏ ูุดู ฺฉู ุฑุดู ุฏุฑ ูุณุญุช ุฏุงุฑู ฺฏุงูู\n",
            "ฺฉุชุงุจ ุฏู ููุงุฒ ูู ุฏุฑ ูุจุงุญุซ ูุงุฑุฏ ูุดู ฺฉู ุฑุดู ุฏุฑ ูุณุญุช ุฏุงุฑู ฺฏุงูู\n",
            "ุฎู ุฏูุณุชุด ุฏุงุดุชู ูู ููุช ูููุฏู ฺฉุชุงุจ  ูุดฺฉูุงุช ุฏุงุฑู ููุจู ุดฺฉุณุช๐\n",
            "ุฎู ุฏูุณุชุด ุฏุงุดุชู ูู ููุช ูููุฏู ฺฉุชุงุจ  ูุดฺฉูุงุช ุฏุงุฑู ููุจู ุดฺฉุณุช\n",
            "ูู ฺฉู ฺุฒ ุงุฒ ุงู ฺฉุชุงุจ ุฏุณุชฺฏุฑู ูุดุฏุ ุฏูุณุชุงู ุจุฑุฏุงุดุช ุฎูุฏุดุงู ุฑุง ุจูุฑูุงูุฏ ุงุณุชูุงุฏู ฺฉูู\n",
            "ูู ฺฉู ฺุฒ ุงุฒ ุงู ฺฉุชุงุจ ุฏุณุชฺฏุฑู ูุดุฏุ ุฏูุณุชุงู ุจุฑุฏุงุดุช ุฎูุฏุดุงู ุฑุง ุจูุฑูุงูุฏ ุงุณุชูุงุฏู ฺฉูู\n",
            "ุงูุจุชู ฺฉู ุจุงุฏ ุจุง ุฏุฏ ุจุงุฒ ูุฐูุจ ุฎููุฏู ุจุดู ุ ฺูู ููฺฉูู ุงุนุชูุงุฏุงุช ุชุฎุฑุจ ุจุดู ุ ูู ุฏุฑ ุนู ุญุงู ฺฉุชุงุจู ฺฉู ููุถูุน ุงุตูุด ุนู ุจุงุฒฺฏุดุช ุจู ุฎูุฏ ุ ููู ุชุฑ ุงุฒ ูุฑุนุงุชุด ูุณุช .\n",
            "ุฏุฑ ุถูู ุจุฑฺฏุฑูุชู ุงุฒ ฺฉ ุงุฒ ุงุดุนุงุฑ ูุซูู ูุนูู ุฌูุงุจ ูููุงูุง ุณุช . ฺุฒ ุฌุฏุฏ ูุณุช ุ ู ุงูฺฉู ูููุงูุงุฎุฏุงููุฏฺฏุงุฑ ุชู ฺูุฏ ุจุช ุงู ุฑู ุฑูุงุช ฺฉุฑุฏู ุ ุงุดูู ุงููุฏู ฺฉุดุด ุฏุงุฏู ููุท ...\n",
            "ุงูุจุชู ฺฉู ุจุงุฏ ุจุง ุฏุฏ ุจุงุฒ ูุฐูุจ ุฎููุฏู ุจุดู ุ ฺูู ููฺฉูู ุงุนุชูุงุฏุงุช ุชุฎุฑุจ ุจุดู ุ ูู ุฏุฑ ุนู ุญุงู ฺฉุชุงุจู ฺฉู ููุถูุน ุงุตูุด ุนู ุจุงุฒฺฏุดุช ุจู ุฎูุฏ ุ ููู ุชุฑ ุงุฒ ูุฑุนุงุชุด ูุณุช .\n",
            "ุฏุฑ ุถูู ุจุฑฺฏุฑูุชู ุงุฒ ฺฉ ุงุฒ ุงุดุนุงุฑ ูุซูู ูุนูู ุฌูุงุจ ูููุงูุง ุณุช . ฺุฒ ุฌุฏุฏ ูุณุช ุ ู ุงูฺฉู ูููุงูุงุฎุฏุงููุฏฺฏุงุฑ ุชู ฺูุฏ ุจุช ุงู ุฑู ุฑูุงุช ฺฉุฑุฏู ุ ุงุดูู ุงููุฏู ฺฉุดุด ุฏุงุฏู ููุท ...\n",
            "ุนุงู ุจูุฏ ู ุงูุณุงู ุฑุง ุจู ุงุตู ุงูุณุงูุช ู ูพุฏุง ฺฉุฑุฏู ฺฏููุฑ ุฎูุฏุด ุฑุงูููุง ูฺฉูู ู ุฎู ุงุณุชุงุฏุงูู ูุฑุญูู ูุฑุญูู ุขุฏู ุฑุง ูุจุฑู ุชุง ุจู ููุตูุฏ ฺฉู ููุงูุง ฺฏูุฌ ุฏุฑูู ุงูุณุงู ุงุณุช ูุฑุณ ููุท ูุดู ฺฏูุช ุฎูุฏ ูพุงุฆููู ุฌุงุฏูฺฏุฑ ุงุณุช\n",
            "ุนุงู ุจูุฏ ู ุงูุณุงู ุฑุง ุจู ุงุตู ุงูุณุงูุช ู ูพุฏุง ฺฉุฑุฏู ฺฏููุฑ ุฎูุฏุด ุฑุงูููุง ูฺฉูู ู ุฎู ุงุณุชุงุฏุงูู ูุฑุญูู ูุฑุญูู ุขุฏู ุฑุง ูุจุฑู ุชุง ุจู ููุตูุฏ ฺฉู ููุงูุง ฺฏูุฌ ุฏุฑูู ุงูุณุงู ุงุณุช ูุฑุณ ููุท ูุดู ฺฏูุช ุฎูุฏ ูพุงุฆููู ุฌุงุฏูฺฏุฑ ุงุณุช\n",
            "ฺฉุชุงุจ ููู ุงูุนุงุฏู ุฒุจุง ุงุณุช.\n",
            "ูู ููุฏุงูู ฺฉู ูุฑู ูุงู ฺฉุชุงุจ ุฎูุจ ู ุจุฏ ฺุณุชุ\n",
            "ูุฑ ฺฉุชุงุจ ุจุง ฺฉ ูฺฉุฑ ู ุงูุฏุดู ุฎุงุต ููุดุชู ูโุดูุฏ ู ุณุงู ูุง ูุฎุชูู ุฑุง ุฏุฑุจุฑ ูโฺฏุฑุฏ ุชุง ฺฉุงูู ฺฏุฑุฏุฏ ุงูุง ูุง ููุช ุฎูุฏ ุฑุง ุตุฑู ููฺฉูู ุชุง ุจุง ููุงู ุญุณ ฺฉู ฺฉุชุงุจ ููุดุชู ฺฏุฑุฏุฏูุ ุจุฎูุงูู. ฺฉุชุงุจ ุฑุง ุจุงุฏ ุจุง ุนุดู ุฎูุงูุฏ ููุงู ุทูุฑ ฺฉู ุงุฌุงุจ ูโฺฉูุฏ ุจุงุฏ ุขู ุญุณ ุฑุง ุจุฑุง ุฎูุฏ ุงุฌุงุฏ ฺฉุฑุฏ.\n",
            "ฺฉุชุงุจ ููู ุงูุนุงุฏู ุฒุจุง ุงุณุช.\n",
            "ูู ููุฏุงูู ฺฉู ูุฑู ูุงู ฺฉุชุงุจ ุฎูุจ ู ุจุฏ ฺุณุชุ\n",
            "ูุฑ ฺฉุชุงุจ ุจุง ฺฉ ูฺฉุฑ ู ุงูุฏุดู ุฎุงุต ููุดุชู ูโุดูุฏ ู ุณุงู ูุง ูุฎุชูู ุฑุง ุฏุฑุจุฑ ูโฺฏุฑุฏ ุชุง ฺฉุงูู ฺฏุฑุฏุฏ ุงูุง ูุง ููุช ุฎูุฏ ุฑุง ุตุฑู ููฺฉูู ุชุง ุจุง ููุงู ุญุณ ฺฉู ฺฉุชุงุจ ููุดุชู ฺฏุฑุฏุฏูุ ุจุฎูุงูู. ฺฉุชุงุจ ุฑุง ุจุงุฏ ุจุง ุนุดู ุฎูุงูุฏ ููุงู ุทูุฑ ฺฉู ุงุฌุงุจ ูโฺฉูุฏ ุจุงุฏ ุขู ุญุณ ุฑุง ุจุฑุง ุฎูุฏ ุงุฌุงุฏ ฺฉุฑุฏ.\n",
            "ุฎู ุดุฑูู. ุขุฏู ูุงูุนุง ูุฐุช ูุจุฑู ุงุฒ ุฎููุฏูุด\n",
            "ุฎู ุดุฑูู. ุขุฏู ูุงูุนุง ูุฐุช ูุจุฑู ุงุฒ ุฎููุฏูุด\n",
            "ฺฉุชุงุจ ฺฉูุงฺฏุฑ ฺฉ ุงุฒ ุฌุฐุงุจ ุชุฑู ฺฉุชุงุจุง ุจูุฏ ฺฉู ุชุงุญุงูุง ุฎููุฏู ูุดู ฺฏูุช ู ุญุงูุช ุงูฺฏุฒุด ุฏุงุดุช.\n",
            "ุฏุงุณุชุงู ฺููพุงู ฺฉู ุจู ุฏูุจุงู ุญุฏุซ ุฎูุด ูุฑู ุจู ุฏูุจุงู ุฑูุง ฺฉู ุฏุฑ ุฐูู ุฏุงุฑู ู ุจุฑุฎูุงู ุฎู ุงุฒ ุงุทุฑุงูุงูุด ฺฉู ุจุฎุงุทุฑ ูุฑุงูู ฺฉุฑุฏู ูุงุฒ ูุง ุงุณุงุณ ุฒูุฏฺฏ ุดูู ูู ุฑุณุฏู ุจู ุขุฑุฒููุงุดูู ุฑู ุฏุฑุฎูุฏ ุณุฑฺฉูุจ ฺฉุฑุฏู ุญุงุถุฑ ูุณุช ุงุฒุดูู ุฏุณุช ุจฺฉุดู ฺฉูุงฺฏุฑ ุนู ฺฉุณ ฺฉู ูุชููู ูุงูุช ฺุฒ ุฑู ุชุบุฑ ุจุฏู ุง ฺุฒ ุฌุฏุฏ ุฑู ุฎูู ฺฉูู ู ุงู ฺฉุชุงุจ ุจูููู ูุดูู ูุฏู ฺฉู ูุฑฺฉุฏูู ุงุฒ ูุง ฺฉูุงฺฏุฑ ุฒูุฏฺฏ ุฎูุฏููู ูุณุชู ุงูุจุชู ูพุงุฆููู ุฏุฑ ุงู ฺฉุชุงุจ ุจู ุฎูุจ ุณุฎุช ูุง ูุณุฑ ุฑู ูุดูู ุฏุงุฏู ู ุซุงุจุช ฺฉุฑุฏู ฺฉู ุฑุณุฏู ุจู ุฑูุงูุง ุจุฏูู ูพุฑุฏุงุฎุช ูุฒูู ููฺฉู ูุณุช ฺฏุฑฺู ุฒูุฏฺฏ ูฺฉุฑุฏู ุฏุฑ ูุณุฑ ุฑูุงูุง ูู ุฎูุฏุด ูุฒูู ุง ุฑู ุฏุฑุจุฑุฏุงุฑู.\n",
            "ุงู ฺฉุชุงุจ ุจูููู ูฺฏู ูุฑฺฉุณ ุชู ุงู ุฏูุง ู ฺฏูุฌ ุฏุงุฑู ฺฏูุฌ ฺฉู ูุชููู ูุณุจุช ุจูุด ุจุชูุงูุช ุจุงุดู ุฑูุงุด ฺฉูู ู ู ุฒูุฏฺฏ ูุนููู ุฑู ุฏุงุดุชู ุจุงุดู ูุซู ุฎู ุงุฒ ุฏูุฑ ู ูุฑุงููู ุง ุงูฺฉู ูู ุจุฑู ุฏูุจุงู ฺฏูุฌุด ฺฏูุฌ ฺฉู ุจู ููู ููุณูุฏู ููุท ูุฎุตูุต ุฎูุฏุดู ฺฉุงุฑ ฺฉู ุงูู ูุฑุฏ ุจุฑุงุด ุณุงุฎุชู ุดุฏู ู ุงฺฏู ุจุง ุชููู ูุฌูุฏุด ุงูู ุฑู ุทูุจ ฺฉูู ฺฉุงุฆูุงุช ุจู ุชฺฉุงูพู ููุชู ุชุง ุงูู ุฑู ุจู ุฎูุงุณุชู ุงุด ุจุฑุณููู ุงูุจุชู ุงู ฺฉุชุงุจ ู ูฺฉุชู ุฌุงูุจ ุฏฺฏู ูู ุฏุงุฑู ู ุงูู ุงูฺฉู ูุง ูุนูุช ูุง ุฒุงุฏ ุฏุงุฑู ฺฉู ูุฏุฑุดูู ุฑู ูู ุฏููู ูุฑุตุช ูุง ฺฉู ุจุง ุจุชูุงูุช ุงุฒ ฺฉูุงุฑุดูู ูฺฏุฐุฑู ุฏุฑ ูุงูุน ูุง ูุฑ ุขูฺู ฺฉู ูุงุฒ ุฏุงุฑู ุฏุฑ ูุฌูุฏููู ุฏุงุฑู ุงูุง ุงุฏููู ูุฑู ู ุงุฒุด ุบุงููู ุงูุจุชู ุจูุธุฑู ุถุนู ฺฉูฺููู ฺฉุชุงุจ ุงู ุจูุฏ ฺฉู ููุณูุฏู ู ุณุฑ ุฌุงูุง ุงุฒ ุญูุงุฏุซ ุณุฑุน ุนุจูุฑ ฺฉุฑุฏู ุจูุฏ ู ุฎู ุจูุดูู ููพุฑุฏุงุฎุชู ุจูุฏ ูู ุจูู ุงุด ุนุงู ุจูุฏ\n",
            "ุฎูุงุตู ุงูฺฉู ุงู ฺฉุชุงุจ ูพุฑ ุงุฒ ุญุฑู ู ูฺฉุชู ุงุณุช ู ุณุฑ ุฏุงุณุชุงู ุฌุฐุงุจ ูู ุฏุงุฑู ูพุณ ุงุฒ ุฏุณุชุด ูุฏู ุฏูุณุชุงู๐\n",
            "ฺฉุชุงุจ ฺฉูุงฺฏุฑ ฺฉ ุงุฒ ุฌุฐุงุจ ุชุฑู ฺฉุชุงุจุง ุจูุฏ ฺฉู ุชุงุญุงูุง ุฎููุฏู ูุดู ฺฏูุช ู ุญุงูุช ุงูฺฏุฒุด ุฏุงุดุช.\n",
            "ุฏุงุณุชุงู ฺููพุงู ฺฉู ุจู ุฏูุจุงู ุญุฏุซ ุฎูุด ูุฑู ุจู ุฏูุจุงู ุฑูุง ฺฉู ุฏุฑ ุฐูู ุฏุงุฑู ู ุจุฑุฎูุงู ุฎู ุงุฒ ุงุทุฑุงูุงูุด ฺฉู ุจุฎุงุทุฑ ูุฑุงูู ฺฉุฑุฏู ูุงุฒ ูุง ุงุณุงุณ ุฒูุฏฺฏ ุดูู ูู ุฑุณุฏู ุจู ุขุฑุฒููุงุดูู ุฑู ุฏุฑุฎูุฏ ุณุฑฺฉูุจ ฺฉุฑุฏู ุญุงุถุฑ ูุณุช ุงุฒุดูู ุฏุณุช ุจฺฉุดู ฺฉูุงฺฏุฑ ุนู ฺฉุณ ฺฉู ูุชููู ูุงูุช ฺุฒ ุฑู ุชุบุฑ ุจุฏู ุง ฺุฒ ุฌุฏุฏ ุฑู ุฎูู ฺฉูู ู ุงู ฺฉุชุงุจ ุจูููู ูุดูู ูุฏู ฺฉู ูุฑฺฉุฏูู ุงุฒ ูุง ฺฉูุงฺฏุฑ ุฒูุฏฺฏ ุฎูุฏููู ูุณุชู ุงูุจุชู ูพุงุฆููู ุฏุฑ ุงู ฺฉุชุงุจ ุจู ุฎูุจ ุณุฎุช ูุง ูุณุฑ ุฑู ูุดูู ุฏุงุฏู ู ุซุงุจุช ฺฉุฑุฏู ฺฉู ุฑุณุฏู ุจู ุฑูุงูุง ุจุฏูู ูพุฑุฏุงุฎุช ูุฒูู ููฺฉู ูุณุช ฺฏุฑฺู ุฒูุฏฺฏ ูฺฉุฑุฏู ุฏุฑ ูุณุฑ ุฑูุงูุง ูู ุฎูุฏุด ูุฒูู ุง ุฑู ุฏุฑุจุฑุฏุงุฑู.\n",
            "ุงู ฺฉุชุงุจ ุจูููู ูฺฏู ูุฑฺฉุณ ุชู ุงู ุฏูุง ู ฺฏูุฌ ุฏุงุฑู ฺฏูุฌ ฺฉู ูุชููู ูุณุจุช ุจูุด ุจุชูุงูุช ุจุงุดู ุฑูุงุด ฺฉูู ู ู ุฒูุฏฺฏ ูุนููู ุฑู ุฏุงุดุชู ุจุงุดู ูุซู ุฎู ุงุฒ ุฏูุฑ ู ูุฑุงููู ุง ุงูฺฉู ูู ุจุฑู ุฏูุจุงู ฺฏูุฌุด ฺฏูุฌ ฺฉู ุจู ููู ููุณูุฏู ููุท ูุฎุตูุต ุฎูุฏุดู ฺฉุงุฑ ฺฉู ุงูู ูุฑุฏ ุจุฑุงุด ุณุงุฎุชู ุดุฏู ู ุงฺฏู ุจุง ุชููู ูุฌูุฏุด ุงูู ุฑู ุทูุจ ฺฉูู ฺฉุงุฆูุงุช ุจู ุชฺฉุงูพู ููุชู ุชุง ุงูู ุฑู ุจู ุฎูุงุณุชู ุงุด ุจุฑุณููู ุงูุจุชู ุงู ฺฉุชุงุจ ู ูฺฉุชู ุฌุงูุจ ุฏฺฏู ูู ุฏุงุฑู ู ุงูู ุงูฺฉู ูุง ูุนูุช ูุง ุฒุงุฏ ุฏุงุฑู ฺฉู ูุฏุฑุดูู ุฑู ูู ุฏููู ูุฑุตุช ูุง ฺฉู ุจุง ุจุชูุงูุช ุงุฒ ฺฉูุงุฑุดูู ูฺฏุฐุฑู ุฏุฑ ูุงูุน ูุง ูุฑ ุขูฺู ฺฉู ูุงุฒ ุฏุงุฑู ุฏุฑ ูุฌูุฏููู ุฏุงุฑู ุงูุง ุงุฏููู ูุฑู ู ุงุฒุด ุบุงููู ุงูุจุชู ุจูุธุฑู ุถุนู ฺฉูฺููู ฺฉุชุงุจ ุงู ุจูุฏ ฺฉู ููุณูุฏู ู ุณุฑ ุฌุงูุง ุงุฒ ุญูุงุฏุซ ุณุฑุน ุนุจูุฑ ฺฉุฑุฏู ุจูุฏ ู ุฎู ุจูุดูู ููพุฑุฏุงุฎุชู ุจูุฏ ูู ุจูู ุงุด ุนุงู ุจูุฏ\n",
            "ุฎูุงุตู ุงูฺฉู ุงู ฺฉุชุงุจ ูพุฑ ุงุฒ ุญุฑู ู ูฺฉุชู ุงุณุช ู ุณุฑ ุฏุงุณุชุงู ุฌุฐุงุจ ูู ุฏุงุฑู ูพุณ ุงุฒ ุฏุณุชุด ูุฏู ุฏูุณุชุงู\n",
            "ูุณุฎู ฺุงูพ ุฑู ุฎููุฏู ูุงูุนุง ุนุงูู. ูุธุฑ ุซุจุช ูฺฉูู ฺฉู ุฏูุณุชุงู ฺฉู ุจุฎุด ฺฉุชุงุจฺฏุฑุฏ ุฑู ูฺฏุงู ูฺฉูู ุจู ุฎููุฏู ุงู ฺฉุชุงุจ ูุดูฺฏ ุฏุนูุช ฺฉูู.\n",
            "ูุณุฎู ฺุงูพ ุฑู ุฎููุฏู ูุงูุนุง ุนุงูู. ูุธุฑ ุซุจุช ูฺฉูู ฺฉู ุฏูุณุชุงู ฺฉู ุจุฎุด ฺฉุชุงุจฺฏุฑุฏ ุฑู ูฺฏุงู ูฺฉูู ุจู ุฎููุฏู ุงู ฺฉุชุงุจ ูุดูฺฏ ุฏุนูุช ฺฉูู.\n",
            "ุนุงู ุจูุฏ ูุงูุนุง ูุฐุช ุจุฑุฏู\n",
            "ุนุงู ุจูุฏ ูุงูุนุง ูุฐุช ุจุฑุฏู\n",
            "ุงู ฺฉุชุงุจ ูุงูุนุง ุนุงู ุจูุฏ\n",
            "ฺฉูฺฉ ูฺฉูู ุดุงุฏ ูุง ูู ุจุชููู ุญุฏุซ ุฎูุด ุฑู ูพุฏุง ฺฉูู\n",
            "ู....\n",
            "ูู ูุงูุนุง ูููููู ฺุทูุฑ ฺูุฏ ููุฑ ู ุณุชุงุฑู ุฏุงุฏูุูฺฏู ุฏุงุฑูุ๐ถ\n",
            "ุงู ฺฉุชุงุจ ูุงูุนุง ุนุงู ุจูุฏ\n",
            "ฺฉูฺฉ ูฺฉูู ุดุงุฏ ูุง ูู ุจุชููู ุญุฏุซ ุฎูุด ุฑู ูพุฏุง ฺฉูู\n",
            "ู....\n",
            "ูู ูุงูุนุง ูููููู ฺุทูุฑ ฺูุฏ ููุฑ ู ุณุชุงุฑู ุฏุงุฏูุูฺฏู ุฏุงุฑูุ\n",
            "ูพุงุฆููู ุนุงูู ูุซู ููุดู ุนุงู\n",
            "ูพุงุฆููู ุนุงูู ูุซู ููุดู ุนุงู\n",
            "ูุทุนุง ุจุงุฏ ุงุฒ ุฑุงุฏู ุชุดฺฉุฑ ฺฉูู ฺฉู ุณุจุจ ุขุดูุง ุดุฏ ฺูู ูุณูุช ุงุฒ ุงู ฺฉุชุงุจ ุฑู ุงุฒ ุฑุงุฏู ู ุฏุฑ ุฑุงู ููุฒู ุดูุฏู ู ูููู ูููุน ุดูุชู ฺฉุชุงุจ ุดุฏูุุ\n",
            "ฺฉุชุงุจ ุนูููุ ุฒุจุงุณุชุ ุงู ุงุฒ ุงูุฏฺฉ ฺฉุชุงุจูุง ุจูุฏ ฺฉู ูุณุฎู ุตูุช ุด ุฑู ุชูู ฺฉุฑุฏู ู ูููุน ุฎูุงุจ ฺฏูุด ูฺฉุฑุฏู\n",
            "ูุทุนุง ุจุงุฏ ุงุฒ ุฑุงุฏู ุชุดฺฉุฑ ฺฉูู ฺฉู ุณุจุจ ุขุดูุง ุดุฏ ฺูู ูุณูุช ุงุฒ ุงู ฺฉุชุงุจ ุฑู ุงุฒ ุฑุงุฏู ู ุฏุฑ ุฑุงู ููุฒู ุดูุฏู ู ูููู ูููุน ุดูุชู ฺฉุชุงุจ ุดุฏูุุ\n",
            "ฺฉุชุงุจ ุนูููุ ุฒุจุงุณุชุ ุงู ุงุฒ ุงูุฏฺฉ ฺฉุชุงุจูุง ุจูุฏ ฺฉู ูุณุฎู ุตูุช ุด ุฑู ุชูู ฺฉุฑุฏู ู ูููุน ุฎูุงุจ ฺฏูุด ูฺฉุฑุฏู\n",
            "ุจุดุชุฑุงุฒฑฐฐุฌูุฏ ฺฉุชุงุจ ูุทุงูุนู ฺฉุฑุฏู ูฺ ฺฉุฏูู ูุงุณู ฺฉูุงฺฏุฑ ูุดุฏ.ุงู ฺฉุชุงุจ ุจุงุฏ ูุฑณูุงู ฺฉ ูุฑุชุจู ุฎููุฏ ูพุฑ ุงุฒ ุฏุฑุณ ู ุงูุฏุฑุฒ\n",
            "ุจุดุชุฑุงุฒฑฐฐุฌูุฏ ฺฉุชุงุจ ูุทุงูุนู ฺฉุฑุฏู ูฺ ฺฉุฏูู ูุงุณู ฺฉูุงฺฏุฑ ูุดุฏ.ุงู ฺฉุชุงุจ ุจุงุฏ ูุฑณูุงู ฺฉ ูุฑุชุจู ุฎููุฏ ูพุฑ ุงุฒ ุฏุฑุณ ู ุงูุฏุฑุฒ\n",
            "ูู ุฎููุฏูุด ุงูุง ูุนู ุฎู ุงุฒ ุญุฑู ูุง ฺฉู ูุฒุฏ ู ููููุฏู ุงุญุณุงุณ ู ฺฉูู ุจุงุฏ ุฏูุจุงุฑู ุจุฑฺฏุฑุฏู ุงุฒ ุงูู ุจุฎููู ู ุจุดุชุฑ ุฏุฑุจุงุฑุด ูฺฉุฑ ฺฉูู\n",
            "ูู ุฎููุฏูุด ุงูุง ูุนู ุฎู ุงุฒ ุญุฑู ูุง ฺฉู ูุฒุฏ ู ููููุฏู ุงุญุณุงุณ ู ฺฉูู ุจุงุฏ ุฏูุจุงุฑู ุจุฑฺฏุฑุฏู ุงุฒ ุงูู ุจุฎููู ู ุจุดุชุฑ ุฏุฑุจุงุฑุด ูฺฉุฑ ฺฉูู\n",
            "ุงู ฺฉุชุงุจ ุงุตูุง ฺฉ ฺฉุชุงุจ ูุนููู ูุณุช ุฎู ูุฑู ุฏุงุฑู ุจู ูุธุฑ ูู ุงู  ฺฉุชุงุจ ููู ุงูุนุงุฏู ุงุณ ุนุงุงุงุงุงุดู ุงู ฺฉุชุงุจู\n",
            "ุงู ฺฉุชุงุจ ุงุตูุง ฺฉ ฺฉุชุงุจ ูุนููู ูุณุช ุฎู ูุฑู ุฏุงุฑู ุจู ูุธุฑ ูู ุงู  ฺฉุชุงุจ ููู ุงูุนุงุฏู ุงุณ ุนุงุงุงุงุงุดู ุงู ฺฉุชุงุจู\n",
            "ุชุงุซุฑ ุฎุงุต ุชู ุฒูุฏฺฏู ูุฏุงุดุช ููุท ูุดูฺฏ ุจูุฏ ูุฑูุง ูุฏุฑุถูู ุฏุฒุฏ ุงุฒ ูููุงูุงุุจุฎูุชุฏ ุงุฏุจุงุชุชูู ุชููุช ุดู ูุณุฑฺฏุฑูู\n",
            "ุชุงุซุฑ ุฎุงุต ุชู ุฒูุฏฺฏู ูุฏุงุดุช ููุท ูุดูฺฏ ุจูุฏ ูุฑูุง ูุฏุฑุถูู ุฏุฒุฏ ุงุฒ ูููุงูุงุุจุฎูุชุฏ ุงุฏุจุงุชุชูู ุชููุช ุดู ูุณุฑฺฏุฑูู\n",
            "ฺฉุชุงุจ ุจุณุงุฑ ุฒุจุงุุชฺฉ ุชฺฉ ุฌููุงุชุด ุจุง ูุนูุง ู ูููููุุจุณุงุฑ ููุณู\n",
            "ุจ ุฎูุฏ ูุณุช ฺฉู ุฌุฒู ฺฉุชุงุจ ูุง ูุทุฑุญ ุฌูุงูู\n",
            "ฺฉุชุงุจ ุจุณุงุฑ ุฒุจุงุุชฺฉ ุชฺฉ ุฌููุงุชุด ุจุง ูุนูุง ู ูููููุุจุณุงุฑ ููุณู\n",
            "ุจ ุฎูุฏ ูุณุช ฺฉู ุฌุฒู ฺฉุชุงุจ ูุง ูุทุฑุญ ุฌูุงูู\n",
            "ุณุฑฺฉุงุฑ\n",
            "ุณุฑฺฉุงุฑ\n",
            "ููู ุงูุนุงุงุงุงุงุงุงุงุฏู\n",
            "ุชุง ุงูุงู ูฺ ฺฉุชุงุจ ุฑู ุฏุณุชุด ูุฒุฏู\n",
            "ูุฑ ฺฉุณ ูู ูุฏุฑุช ุฏุฑฺฉ ูุทุงูุจุด ูุฏุงุฑู\n",
            "ููู ุงูุนุงุงุงุงุงุงุงุงุฏู\n",
            "ุชุง ุงูุงู ูฺ ฺฉุชุงุจ ุฑู ุฏุณุชุด ูุฒุฏู\n",
            "ูุฑ ฺฉุณ ูู ูุฏุฑุช ุฏุฑฺฉ ูุทุงูุจุด ูุฏุงุฑู\n",
            "ูุฑฺ ุงุฒ ุฒุจุง ุงู ฺฉุชุงุจ ุจฺฏูุ ฺฉู ฺฏูุชู. ูุงูุนุง ฺฉู ูููโุงูุนุงุฏู ูุณุชุด๐\n",
            "ูุฑฺ ุงุฒ ุฒุจุง ุงู ฺฉุชุงุจ ุจฺฏูุ ฺฉู ฺฏูุชู. ูุงูุนุง ฺฉู ูููโุงูุนุงุฏู ูุณุชุด\n",
            "ฺฉุชุงุจ ฺฉูุง ฺฏุฑ ู ฺฉุชุงุจ ุฎูุจ ู ุฏุฑุณุช ุญุณุงุจ.ุญุชูุง ุจุฎููุฏ.\n",
            "ฺฉุชุงุจ ฺฉูุง ฺฏุฑ ู ฺฉุชุงุจ ุฎูุจ ู ุฏุฑุณุช ุญุณุงุจ.ุญุชูุง ุจุฎููุฏ.\n",
            "ุงุฒ ุฌููู ฺฉุชุงุจุง ฺฉู ุฎููุฏูุด ุฑู ุจู ููู ุชูุตู ูฺฉูู. ฺฉุชุงุจ ฺฉู ูุธุฑ ูุณุชุ ุจุณุงุฑ ุฌุฐุงุจ ู ูพูุฏุขูุฒ. ุจุฑุง ูู ฺฉู ุงุฒ ุชูุงู ฺฉุชุงุจุง ูพุงุฆููู ฺฉูุฆูู ุฌุงูุจ ุชุฑ ุจูุฏ.\n",
            "ุงุฒ ุฌููู ฺฉุชุงุจุง ฺฉู ุฎููุฏูุด ุฑู ุจู ููู ุชูุตู ูฺฉูู. ฺฉุชุงุจ ฺฉู ูุธุฑ ูุณุชุ ุจุณุงุฑ ุฌุฐุงุจ ู ูพูุฏุขูุฒ. ุจุฑุง ูู ฺฉู ุงุฒ ุชูุงู ฺฉุชุงุจุง ูพุงุฆููู ฺฉูุฆูู ุฌุงูุจ ุชุฑ ุจูุฏ.\n",
            "ฺฉุชุงุจ ุฎูุจ ุจูุฏ.ุงูุจุชู ูู ฺุงูพุดู ุฎููุฏู.ูุจ ูุทูุจ ุงูู ฺฉู ู ุฎูุงุฏ ุจฺฏู ููู ฺุฒ ุจู ุฎูุฏุช ู ุจู ุฏุฑููุช ุจุณุชฺฏ ุฏุงุฑู.ูุฑ ฺุฒ ฺฉู ุจุฑุง ุฑุณุฏู ุจู ูุฑ ูุฏู ุจุฎูุง ุชู ุฎูุฏุช ูุณุช.ููู!โบ\n",
            "ฺฉุชุงุจ ุฎูุจ ุจูุฏ.ุงูุจุชู ูู ฺุงูพุดู ุฎููุฏู.ูุจ ูุทูุจ ุงูู ฺฉู ู ุฎูุงุฏ ุจฺฏู ููู ฺุฒ ุจู ุฎูุฏุช ู ุจู ุฏุฑููุช ุจุณุชฺฏ ุฏุงุฑู.ูุฑ ฺุฒ ฺฉู ุจุฑุง ุฑุณุฏู ุจู ูุฑ ูุฏู ุจุฎูุง ุชู ุฎูุฏุช ูุณุช.ููู!\n",
            "ฺฉุชุงุจ ุณูฺฏู ู ุณุฑุดุงุฑ ุงุฒ ููุงุฏ ูุง ฺฏููุงฺฏูู\n",
            "ุจุฑุง ุฏุฑฺฉ ฺฉุงูู ุงู ฺฉุชุงุจ ุจุงุฏ ุฏุฑ ููุณูู ูุทุงูุนู ฺฏุณุชุฑุฏู ุฏุงุดุชู ุจุงุดุฏ\n",
            "ฺฉุชุงุจ ุณูฺฏู ู ุณุฑุดุงุฑ ุงุฒ ููุงุฏ ูุง ฺฏููุงฺฏูู\n",
            "ุจุฑุง ุฏุฑฺฉ ฺฉุงูู ุงู ฺฉุชุงุจ ุจุงุฏ ุฏุฑ ููุณูู ูุทุงูุนู ฺฏุณุชุฑุฏู ุฏุงุดุชู ุจุงุดุฏ\n",
            "ุฌุงูุจ ุจูุฏ. ุฏุฑุณูุง ุฒุงุฏ ุงุฒุด ฺฏุฑูุชู\n",
            "ุฌุงูุจ ุจูุฏ. ุฏุฑุณูุง ุฒุงุฏ ุงุฒุด ฺฏุฑูุชู\n",
            "ุงูุชุงุฒ: ณ.ต\n",
            "ฺุงูุฑ: ุงุฏุจ\n",
            "ูู ฺฉุชุงุจ ุฑู ุจุง ุชุฑุฌูู ูุฑุฒุงูู ูุฑุฒุงุฏ ุฎููุฏู ฺฉู ุชุฑุฌูู ูุชูุณุท ุจูุฏ. ุฏุงุณุชุงู ููุงุฏู ู ุงูฺฏุฒุด ุฏุฑููุฑุฏ ุงูฺฉู ุงูุณุงู ุจุงุฏ ุจู ูุฏุง ุฏูุด ุชูุฌู ฺฉูู. ุงุซุฑ ุงุฒ ุฏุฑุณโูุง ู ูพูุฏโูุง ูุฎุชูู ูพุฑู ฺฉู ุฏุฑ ุนู ุญุงู ุชุงููโุจุฑุงูฺฏุฒ ู ุงูฺฏุฒุด ูุณุช. ููุณูุฏู ุจุง ุชุนุฏุงุฏ ูุนุฏูุฏ ุดุฎุตุช ูุฎุงุทุจ ุฑู ุจู ุณูุฑ ูุจุฑู ฺฉู ุชุฌุฑุจุงุช ุฎูุจ ุฑู ูุชููู ุจู ุงุฑูุบุงู ุจุงุฑู. ุณุฑุนุช ุฑููุฏ ุฏุงุณุชุงู ุฎูุจู ู ูุซุฑ ฺฉุชุงุจ ูู ฺฉุงุฑุด ุฑู ุงูุฌุงู ูุฏู. ฺฉุจุงุฑ ุฎููุฏู ุงู ุงุซุฑ ุถุฑุฑ ุจู ฺฉุณ ููุฒูู.\n",
            "ุงูุชุงุฒ: ณ.ต\n",
            "ฺุงูุฑ: ุงุฏุจ\n",
            "ูู ฺฉุชุงุจ ุฑู ุจุง ุชุฑุฌูู ูุฑุฒุงูู ูุฑุฒุงุฏ ุฎููุฏู ฺฉู ุชุฑุฌูู ูุชูุณุท ุจูุฏ. ุฏุงุณุชุงู ููุงุฏู ู ุงูฺฏุฒุด ุฏุฑููุฑุฏ ุงูฺฉู ุงูุณุงู ุจุงุฏ ุจู ูุฏุง ุฏูุด ุชูุฌู ฺฉูู. ุงุซุฑ ุงุฒ ุฏุฑุณโูุง ู ูพูุฏโูุง ูุฎุชูู ูพุฑู ฺฉู ุฏุฑ ุนู ุญุงู ุชุงููโุจุฑุงูฺฏุฒ ู ุงูฺฏุฒุด ูุณุช. ููุณูุฏู ุจุง ุชุนุฏุงุฏ ูุนุฏูุฏ ุดุฎุตุช ูุฎุงุทุจ ุฑู ุจู ุณูุฑ ูุจุฑู ฺฉู ุชุฌุฑุจุงุช ุฎูุจ ุฑู ูุชููู ุจู ุงุฑูุบุงู ุจุงุฑู. ุณุฑุนุช ุฑููุฏ ุฏุงุณุชุงู ุฎูุจู ู ูุซุฑ ฺฉุชุงุจ ูู ฺฉุงุฑุด ุฑู ุงูุฌุงู ูุฏู. ฺฉุจุงุฑ ุฎููุฏู ุงู ุงุซุฑ ุถุฑุฑ ุจู ฺฉุณ ููุฒูู.\n",
            "ฺฉุชุงุจ ุฎูุจ ุจูุฏ ุงูุจุชู ูุฑ ุณููู ุง ุฑุง ุฏุฑ ุจุฑ ูู ฺฏุฑูุช ูู ุฎูุฏู ุนุงุดู ุฏุงุณุชุงู ูุง ูพุฑูุงูู ูุณุชู ฺฉู ุจู ุตูุฑุช ุญุฑูู ุง ู ุงุฏุจ ููุดุชู ุดุฏู ู ุงูุจุชู ูููู ุงุฒ ูุงุฌุฑุง ู ุงุชูุงูุงุช ุฌุฏุฏ ูุณุชูุฏ.\n",
            "ุงูุง ูู ุจู ุนููุงู ฺฉ ฺฉุชุงุจ ุฎูุงู ูฺ ููุช ููุชููู ุจู ฺฉ ฺฉุชุงุจ ุญุช ุงฺฏุฑ ุฎู ุจุฏ ุจุงุดู ุง ููุณูุฏุด ููุฑุฏ ุนูุงูู ูู ูุจุงุดู ููุฑู ุจุฏ ุจุฏู ู ูุฑ ุงุซุฑ ุงุฒ ูุธุฑ ูู ุงุญุชุฑุงู ู ูฺฺฏ ุฎุงุต ุฎูุฏุด ุฑู ุฏุงุฑู.๐๐\n",
            "ฺฉุชุงุจ ุฎูุจ ุจูุฏ ุงูุจุชู ูุฑ ุณููู ุง ุฑุง ุฏุฑ ุจุฑ ูู ฺฏุฑูุช ูู ุฎูุฏู ุนุงุดู ุฏุงุณุชุงู ูุง ูพุฑูุงูู ูุณุชู ฺฉู ุจู ุตูุฑุช ุญุฑูู ุง ู ุงุฏุจ ููุดุชู ุดุฏู ู ุงูุจุชู ูููู ุงุฒ ูุงุฌุฑุง ู ุงุชูุงูุงุช ุฌุฏุฏ ูุณุชูุฏ.\n",
            "ุงูุง ูู ุจู ุนููุงู ฺฉ ฺฉุชุงุจ ุฎูุงู ูฺ ููุช ููุชููู ุจู ฺฉ ฺฉุชุงุจ ุญุช ุงฺฏุฑ ุฎู ุจุฏ ุจุงุดู ุง ููุณูุฏุด ููุฑุฏ ุนูุงูู ูู ูุจุงุดู ููุฑู ุจุฏ ุจุฏู ู ูุฑ ุงุซุฑ ุงุฒ ูุธุฑ ูู ุงุญุชุฑุงู ู ูฺฺฏ ุฎุงุต ุฎูุฏุด ุฑู ุฏุงุฑู.\n",
            "ูุฏุช ูุง ุจูุฏ ู ุฎูุงุณุชู ุงู ฺฉุชุงุจ ุฑู ุจุฎููู ูู ุงุตูุง ูุธุฑู ุฑู ุฌูุจ ูฺฉุฑุฏ.\n",
            "ูุฏุช ูุง ุจูุฏ ู ุฎูุงุณุชู ุงู ฺฉุชุงุจ ุฑู ุจุฎููู ูู ุงุตูุง ูุธุฑู ุฑู ุฌูุจ ูฺฉุฑุฏ.\n",
            "ฺฉูุฆูู ู ุขุฏู ูุฑูู ฺฏุฑุงุณุชุุชู ุงู ุงุซุฑุด ูู ูพุฑ ุงุฒ ููุงุฏ ูุง ู ุงุนุฏุงุฏ ูุฑุงูุงุณููุฑ ูุณุชุดุูุฏู ููุง ุงู ฺฉุชุงุจ ุงู ูุณุชุด ฺฉูุุงุณูุงู ุฑุง ูุงฺุฒ ู ุถุนู ู ุงูุฑุงุท ู ุจุฏ ุฌููู ุจุฏูุูุณุญุช ุฑู ุฏู ุงุฒ ุจู ุฑูุชู ู ูุฑุงูุงุณููุฑ ู ูุฑูู ฺฏุฑุง ุฑู ุฎูุจ ู ฺฉุงูู ู ฺฉูฺฉ ฺฉููุฏู ุจุฑุง ุงุฏุงูู  ุฒูุฏฺฏ ุฌููู ุจุฏูุุญูุงุณุชูู ุจุงุดู ฺ ูุฎููุฏุูู ุฎูุฏู ุจุนุฏ ุฎููุฏู ุงู ฺฉุชุงุจุฑฒ ุตูุญู ููุฏุด ุฑู ููุดุชูุฺฉู ูุทูุจ ุฏฺฏู ูุณุชุด ฺฉู ุทูู ูฺฉุดู ฺฏูุชูุดุููุฏุด ุฑู ุญุชูุง ุจุฎููุฏ ุชุง ุฏฺุงุฑ ุดุณุชุดูู ูุบุฒ ูุดุฏุููุท ุฏุงุณุชุงูู ุณุทุญ ุฑู ูุจูุฏุุฑูุฒูุงุชูู ุจู ฺฉุงูุุดุจ ูุงุชูู ูพุฑ ุงุฒ ุขุฑุงูุด.\n",
            "ฺฉูุฆูู ู ุขุฏู ูุฑูู ฺฏุฑุงุณุชุุชู ุงู ุงุซุฑุด ูู ูพุฑ ุงุฒ ููุงุฏ ูุง ู ุงุนุฏุงุฏ ูุฑุงูุงุณููุฑ ูุณุชุดุูุฏู ููุง ุงู ฺฉุชุงุจ ุงู ูุณุชุด ฺฉูุุงุณูุงู ุฑุง ูุงฺุฒ ู ุถุนู ู ุงูุฑุงุท ู ุจุฏ ุฌููู ุจุฏูุูุณุญุช ุฑู ุฏู ุงุฒ ุจู ุฑูุชู ู ูุฑุงูุงุณููุฑ ู ูุฑูู ฺฏุฑุง ุฑู ุฎูุจ ู ฺฉุงูู ู ฺฉูฺฉ ฺฉููุฏู ุจุฑุง ุงุฏุงูู  ุฒูุฏฺฏ ุฌููู ุจุฏูุุญูุงุณุชูู ุจุงุดู ฺ ูุฎููุฏุูู ุฎูุฏู ุจุนุฏ ุฎููุฏู ุงู ฺฉุชุงุจุฑฒ ุตูุญู ููุฏุด ุฑู ููุดุชูุฺฉู ูุทูุจ ุฏฺฏู ูุณุชุด ฺฉู ุทูู ูฺฉุดู ฺฏูุชูุดุููุฏุด ุฑู ุญุชูุง ุจุฎููุฏ ุชุง ุฏฺุงุฑ ุดุณุชุดูู ูุบุฒ ูุดุฏุููุท ุฏุงุณุชุงูู ุณุทุญ ุฑู ูุจูุฏุุฑูุฒูุงุชูู ุจู ฺฉุงูุุดุจ ูุงุชูู ูพุฑ ุงุฒ ุขุฑุงูุด.\n",
            "ุจุณุงุฑ ุถุนู ุจูุฏ.ู ุฏุฑ ุนู ุญุงู ุจู ุตูุฑุช ฺฉุงููุง ูพููุงู ุจู ุชุฎุฑุจ ุฏู ุงุณูุงู ูพุฑุฏุงุฎุชู ุจูุฏ.\n",
            "ูุจูุง ุดูุฏู ุจูุฏู ููุดุชู ูุง ูพุงุฆูู ฺฉูุฆูู ูุดฺฉู ุฏุงุฑู\n",
            "ุจุณุงุฑ ุถุนู ุจูุฏ.ู ุฏุฑ ุนู ุญุงู ุจู ุตูุฑุช ฺฉุงููุง ูพููุงู ุจู ุชุฎุฑุจ ุฏู ุงุณูุงู ูพุฑุฏุงุฎุชู ุจูุฏ.\n",
            "ูุจูุง ุดูุฏู ุจูุฏู ููุดุชู ูุง ูพุงุฆูู ฺฉูุฆูู ูุดฺฉู ุฏุงุฑู\n",
            "ุญู ููุชู\n",
            "ูุงูุนุง ฺฉุชุงุจ ฺุฑูุฏ ุจูุฏ\n",
            "ุญู ููุชู\n",
            "ูุงูุนุง ฺฉุชุงุจ ฺุฑูุฏ ุจูุฏ\n",
            "ุชูุฑุจุง ูุซู ุดุงุฒุฏู ฺฉูฺููู ุจูุฏุูู ฺฉ ุฎู ูุฐุช ุจุฑุฏู!\n",
            "ุชูุฑุจุง ูุซู ุดุงุฒุฏู ฺฉูฺููู ุจูุฏุูู ฺฉ ุฎู ูุฐุช ุจุฑุฏู!\n",
            "ุชุง ูุจู ุงู ฺฉุชุงุจ ุนูุงูููุฏ ุจู ุฎูุงูุฏู ฺฉุชุงุจ ูุจูุฏู\n",
            "ุงูุง ฺฉูุงฺฏุฑโ ูุงูุนุง ุฌุฐุจู ฺฉุฑุฏ.ุฑุงุญุช ูุดุฏ ุขุฏู ุฎูุฏุดู ุฌุง ุดุฎุตุช ุงุตู ูุฑุงุฑ ุจุฏู ู ุงุฒ ุฎููุฏูุด ูุฐุช ุจุจุฑู.\n",
            "ุงฺฏุฑโ ฺฉุชุงุจูุง ูุงุจ ุฏฺฏุฑ ูุดูุงุณุฏ ุฎูุงูุดุง ุจู ูู ูพุดููุงุฏ ุจุฏุฏ\n",
            "ุชุง ูุจู ุงู ฺฉุชุงุจ ุนูุงูููุฏ ุจู ุฎูุงูุฏู ฺฉุชุงุจ ูุจูุฏู\n",
            "ุงูุง ฺฉูุงฺฏุฑโ ูุงูุนุง ุฌุฐุจู ฺฉุฑุฏ.ุฑุงุญุช ูุดุฏ ุขุฏู ุฎูุฏุดู ุฌุง ุดุฎุตุช ุงุตู ูุฑุงุฑ ุจุฏู ู ุงุฒ ุฎููุฏูุด ูุฐุช ุจุจุฑู.\n",
            "ุงฺฏุฑโ ฺฉุชุงุจูุง ูุงุจ ุฏฺฏุฑ ูุดูุงุณุฏ ุฎูุงูุดุง ุจู ูู ูพุดููุงุฏ ุจุฏุฏ\n",
            "ูุงูุนุง ุงู ฺฉุชุงุจ ุฑู ุชูุตู ูฺฉูู. ูู ฺฉู ุงุฒ ุฎููุฏูุด ูุฐุช ุจุฑุฏู.\n",
            "ูุงูุนุง ุงู ฺฉุชุงุจ ุฑู ุชูุตู ูฺฉูู. ูู ฺฉู ุงุฒ ุฎููุฏูุด ูุฐุช ุจุฑุฏู.\n",
            "ุนุงู ุจูุฏ\n",
            "ุนุงู ุจูุฏ\n",
            "ฺูุฏุฑ ุฒุจุง ุจูุฏ ูุฐุช ุจุฑุฏู ุงุฒ ุฎููุฏูุด ุญุชูุง ุจุฎููุฏุฏุฏ\n",
            "ฺูุฏุฑ ุฒุจุง ุจูุฏ ูุฐุช ุจุฑุฏู ุงุฒ ุฎููุฏูุด ุญุชูุง ุจุฎููุฏุฏุฏ\n",
            "ุญุชูุง ุจุฎููุฏ ุนุงูู\n",
            "ุญุชูุง ุจุฎููุฏ ุนุงูู\n",
            "ฺฉ ุจุงุฑ ุฎููุฏู ุงู ฺฉุชุงุจ ุงุตูุง ููุชููู ุนูู ูุทูุจ ุฑู ุจุฑุงุชูู ุนุฏุง ฺฉูู ูพุดููุงุฏ ูุดู ฺูุฏ ุจุงุฑ ฺฉู ุดุฏู ุงู ฺฉุชุงุจ ุฑู ุจุง ุญูุตูู ุจุฎููุฏ ุชุง ุฒุจุง ู ุนูู ุงู ุงุซุฑ ุฑู ุฏุฑฺฉ ฺฉูุฏ\n",
            "ฺฉ ุจุงุฑ ุฎููุฏู ุงู ฺฉุชุงุจ ุงุตูุง ููุชููู ุนูู ูุทูุจ ุฑู ุจุฑุงุชูู ุนุฏุง ฺฉูู ูพุดููุงุฏ ูุดู ฺูุฏ ุจุงุฑ ฺฉู ุดุฏู ุงู ฺฉุชุงุจ ุฑู ุจุง ุญูุตูู ุจุฎููุฏ ุชุง ุฒุจุง ู ุนูู ุงู ุงุซุฑ ุฑู ุฏุฑฺฉ ฺฉูุฏ\n",
            "ุจูุธุฑ๐๐งก๐โค๏ธ๐๐ฝ\n",
            "ุจูุธุฑ\n",
            "ุฎููุฏู ุงู ฺฉุชุงุจู ุจู ููู ูพุดููุงุฏ ูฺฉููุ ุนุงู ู ุชุงุซุฑฺฏุฐุงุฑ\n",
            "ุฎููุฏู ุงู ฺฉุชุงุจู ุจู ููู ูพุดููุงุฏ ูฺฉููุ ุนุงู ู ุชุงุซุฑฺฏุฐุงุฑ\n",
            "ุนุงู ุจูุฏ ููู\n",
            "ุนุงู ุจูุฏ ููู\n",
            "ูู ุงุตูุง ุงุฒ ุฎููุฏู ุงู ฺฉุชุงุจ ูุฐุช ูุจุฑุฏู ู ูุงูุนุง ูุชุนุฌุจู ฺุทูุฑ ุงููุฏุฑ ุงุฒ ุงู ฺฉุชุงุจ ุชุนุฑู ูฺฉูู ููุณูุฏู ุฎู ุชูุงุด ฺฉุฑุฏู ุจูุฏ ฺฉู ูุนูุงฺฏุฑุงุงูู ุจููู ูู ูุชุงุณูุงูู ูููู ูุจูุฏู ู ุงูููุฏุฑุง ูู ฺฉู ุจูู ูฺฏู ุดูุง ุฑู ุจู ูฺฉุฑ ูุง ูุฏุงุฑู ุงู ุทูุฑ ูุณุช\n",
            "ูู ุงุตูุง ุงุฒ ุฎููุฏู ุงู ฺฉุชุงุจ ูุฐุช ูุจุฑุฏู ู ูุงูุนุง ูุชุนุฌุจู ฺุทูุฑ ุงููุฏุฑ ุงุฒ ุงู ฺฉุชุงุจ ุชุนุฑู ูฺฉูู ููุณูุฏู ุฎู ุชูุงุด ฺฉุฑุฏู ุจูุฏ ฺฉู ูุนูุงฺฏุฑุงุงูู ุจููู ูู ูุชุงุณูุงูู ูููู ูุจูุฏู ู ุงูููุฏุฑุง ูู ฺฉู ุจูู ูฺฏู ุดูุง ุฑู ุจู ูฺฉุฑ ูุง ูุฏุงุฑู ุงู ุทูุฑ ูุณุช\n",
            "ูู ฺฉุชุงุจ ุตูุชุดู ุจุดุชุฑ ุฏูุณุช ุฏุงุดุชู\n",
            "ูู ฺฉุชุงุจ ุตูุชุดู ุจุดุชุฑ ุฏูุณุช ุฏุงุดุชู\n",
            "ูุฑ ฺุฒ ฺฉู ุขุฏู ุงุฒ ู ุฏุงุณุชุงู ูุชููู ุงูุชุธุงุฑ ุฏุงุดุชู ุจุงุดู ุชู ุงู ฺฉุชุงุจ ูพุฏุง ูุดู .ฺฉุชุงุจ ฺฉู ุณุฑุดุงุฑ ุงุฒ ุฌููู ูุง ฺฉู ุขุฏู ุฑู ุจู ูฺฉุฑ ูุฑู ูุจุฑู ุณุฑุดุงุฑ ุงุฒ ุนุดู ู ุฑูุญู ู ูพูุฏ...\n",
            "ูุฑ ฺุฒ ฺฉู ุขุฏู ุงุฒ ู ุฏุงุณุชุงู ูุชููู ุงูุชุธุงุฑ ุฏุงุดุชู ุจุงุดู ุชู ุงู ฺฉุชุงุจ ูพุฏุง ูุดู .ฺฉุชุงุจ ฺฉู ุณุฑุดุงุฑ ุงุฒ ุฌููู ูุง ฺฉู ุขุฏู ุฑู ุจู ูฺฉุฑ ูุฑู ูุจุฑู ุณุฑุดุงุฑ ุงุฒ ุนุดู ู ุฑูุญู ู ูพูุฏ...\n",
            "ููุจู ุฏุฑุฏ ฺฏุฑูุชู ุงุฒ ุงู ูุถุง ูุฑููฺฏ ูุณููู ูุธุฑุงุช ุฏูุณุชุงู ุฑู ุฎููุฏู ุจุฑ ฺู ุงุณุงุณ ูุธุฑ ูุฏุฏุ ุจูุฏู ุญูุฑ ุงุฒ ุฏูุง ุจ ุฎุจุฑ ุฑู ูู ุฑุงูููุง ฺฉูุฏ...\n",
            "ุชุง ุงููุฌุง ฺฉู ูู ูุฏููู ูพุงุฆููู ฺฉูุฆูู ููุณูุฏู ูุฑุงูุงุณููุฑ(ุดุทุงู ูพุฑุณุช) ุงุณุช ุฏูุณุชุงูยููุฏ ูพฺููุดฺฏุฑยุดูุฑุงุฑ ุฒุฑ ุดูุงุณ ุฑู ุฏุฑุจุงุฑ ูพุงุฆููู ฺฉูุฆููยู ุงุซุงุฑุด ุฑู ุชู ุงูพุงุฑุช ุจุจูุฏ/ ุง ฺฉู ุชู ุงูุชุฑูุช ุฏุฑุจุงุฑู ุงู ููุณูุฏูยูุจุชุฐู ุชุญูู ฺฉูุฏ.\n",
            "ููุจู ุฏุฑุฏ ฺฏุฑูุชู ุงุฒ ุงู ูุถุง ูุฑููฺฏ ูุณููู ูุธุฑุงุช ุฏูุณุชุงู ุฑู ุฎููุฏู ุจุฑ ฺู ุงุณุงุณ ูุธุฑ ูุฏุฏุ ุจูุฏู ุญูุฑ ุงุฒ ุฏูุง ุจ ุฎุจุฑ ุฑู ูู ุฑุงูููุง ฺฉูุฏ...\n",
            "ุชุง ุงููุฌุง ฺฉู ูู ูุฏููู ูพุงุฆููู ฺฉูุฆูู ููุณูุฏู ูุฑุงูุงุณููุฑ(ุดุทุงู ูพุฑุณุช) ุงุณุช ุฏูุณุชุงูยููุฏ ูพฺููุดฺฏุฑยุดูุฑุงุฑ ุฒุฑ ุดูุงุณ ุฑู ุฏุฑุจุงุฑ ูพุงุฆููู ฺฉูุฆููยู ุงุซุงุฑุด ุฑู ุชู ุงูพุงุฑุช ุจุจูุฏ/ ุง ฺฉู ุชู ุงูุชุฑูุช ุฏุฑุจุงุฑู ุงู ููุณูุฏูยูุจุชุฐู ุชุญูู ฺฉูุฏ.\n",
            "ุฎููุช ฺฉูุ ฺฉู ุฎุงูุงุช ุชู ุขูุฌุง ุจุจุฑู...\n",
            "ุฏุฏู ุจุฑ ุจูุฏู ู ุฏู ุฑุง ุจู ุชูุงุดุง ุจุจุฑู...\n",
            "ุฎููุช ฺฉูุ ฺฉู ุฎุงูุงุช ุชู ุขูุฌุง ุจุจุฑู...\n",
            "ุฏุฏู ุจุฑ ุจูุฏู ู ุฏู ุฑุง ุจู ุชูุงุดุง ุจุจุฑู...\n",
            "ุฎุฏุง ฺฉุชุงุจุด ููููู ุงูุนุงุฏุณุช\n",
            "ุฎุฏุง ฺฉุชุงุจุด ููููู ุงูุนุงุฏุณุช\n",
            "ฺฉุชุงุจ ุฌุงูุจู\n",
            "ุงูุจุชู ุจุณุชฺฏ ุจู ุฐุงุกูู ุฎูุงููุฏู ุฏุงุฑู\n",
            "ุจุงุฏ ุฎุงุต ูพุณูุฏ ู ูุชูฺฉุฑ ู ุนูู ูฺฏุฑ ุจุงุด ฺฉู ุฏุฑฺฉุด ฺฉู ู ฺฏุฑูู ุจุฑุงุช ูุฐุช ูุฏุงุฑู\n",
            "ุชูุตู ูฺฉูู ุฒูุงู ุจุฎููุฏุด ฺฉู ูุงูุนุง ุทุงูุจ ุฎููุฏู ุจุงุดู ูู ุตุฑูุง ูุงุณู ููุช ูพุฑ ฺฉุฑุฏู\n",
            "ุฏฺฏุฑ ฺฉุชุงุจูุง ููุณูุฏู ูู ุงุฑุฒุด ุฎููุฏู ุฏุงุฑู\n",
            "ฺฉุชุงุจ ุฌุงูุจู\n",
            "ุงูุจุชู ุจุณุชฺฏ ุจู ุฐุงุกูู ุฎูุงููุฏู ุฏุงุฑู\n",
            "ุจุงุฏ ุฎุงุต ูพุณูุฏ ู ูุชูฺฉุฑ ู ุนูู ูฺฏุฑ ุจุงุด ฺฉู ุฏุฑฺฉุด ฺฉู ู ฺฏุฑูู ุจุฑุงุช ูุฐุช ูุฏุงุฑู\n",
            "ุชูุตู ูฺฉูู ุฒูุงู ุจุฎููุฏุด ฺฉู ูุงูุนุง ุทุงูุจ ุฎููุฏู ุจุงุดู ูู ุตุฑูุง ูุงุณู ููุช ูพุฑ ฺฉุฑุฏู\n",
            "ุฏฺฏุฑ ฺฉุชุงุจูุง ููุณูุฏู ูู ุงุฑุฒุด ุฎููุฏู ุฏุงุฑู\n",
            "ุนู ฺฉุชุงุจ ุงุฒ ุงู ุจูุชุฑู ูุณุชุ ุนุงู ุจูุฏ.\n",
            "ุนู ฺฉุชุงุจ ุงุฒ ุงู ุจูุชุฑู ูุณุชุ ุนุงู ุจูุฏ.\n",
            "ุงู ฺฉุชุงุจ ู ุดุงูฺฉุงุฑุจู ุชูุงู ูุนูุงุณุช\n",
            "ุงู ฺฉุชุงุจ ู ุดุงูฺฉุงุฑุจู ุชูุงู ูุนูุงุณุช\n",
            "ฺฉุชุงุจ ุนุงูู.ุญุชูุง ุจุฎุฑูุด ุงุฑุฒุดุดู ุฏุงุฑู.ูุฎุตูุตุง ุจุนุถ ุฌุงูุงุด ฺฉู ู ฺุฒุง ุขููุฒุด ุฎูุจ ูฺฏู.ุฏุฑ ฺฉู ฺฉุชุงุจ ูุดูฺฏู.\n",
            "ฺฉุชุงุจ ุนุงูู.ุญุชูุง ุจุฎุฑูุด ุงุฑุฒุดุดู ุฏุงุฑู.ูุฎุตูุตุง ุจุนุถ ุฌุงูุงุด ฺฉู ู ฺุฒุง ุขููุฒุด ุฎูุจ ูฺฏู.ุฏุฑ ฺฉู ฺฉุชุงุจ ูุดูฺฏู.\n",
            "ุงู ฺฉุชุงุจ ุจุงุนุซ ูุดู ุญุช ุจุฑุง ูุญุธู ุง ูู ฺฉู ุดุฏู ุจู ุฑูุงูุง ู ุงุฑุฒููุง ููู ูฺฉุฑ ฺฉูู ู ุงูฺฉู ูฺ ููุช ุจุฑุง ูุญูู ฺฉุฑุฏูุดูู ุฏุฑ ูุณุช ู ุจุงุฏ ุจู ูุดุงูู ูุง ุงูุงู ุฏุงุดุชู ุจุงุดู ุดุงุฏ ุจุง ูุฏู ุจุฑุฏุงุดุชู ุฏุฑ ูุณุฑ ุงูุณุงูู ุดุฎุตููู ูุงุฎูุงุณุชู ุจุงุนุซ ุดู ุงูุฑุงุฏ ุฏฺฏุฑ ุฏุฑ ูุณุฑ ุงุฑุฒููุงุดูู ูุฑุงุฑ ุจฺฏุฑูุฏ ู ุงูฺฉู ูฺ ูุฑู ุฏุฑ ุฌูุงู ุงุฒ ุจู ููุฑู ู ุชููุง ุฏุฑ ฺุฑุฎุด ุงุณุช ูพุณ ุฑูุชุงุฑ ูุง ุจุฑ ุฌูุงู ูพุฑุงูููููู ูุทุนุง ุชุงุซุฑ ฺฏุฐุงุฑู . ุฌุฒ ุจูุชุฑู ฺฉุชุงุจ ูุง ุจูุฏ ฺฉู ุฎููุฏู ู ูุทุนุง ุฏูุจุงุฑู ุจู ุณุฑุงุบุด ูุฑู . ู....\n",
            "ุจุฑูู ุฒ ุชู ูุณุช ุงูฺู ุฏุฑ ุนุงูู ูุณุช ุงุฒุฎูุฏ ุจุทูุจ ูุฑ ุงูฺู ุฎูุงู ฺฉู ุชู\n",
            "ุงู ฺฉุชุงุจ ุจุงุนุซ ูุดู ุญุช ุจุฑุง ูุญุธู ุง ูู ฺฉู ุดุฏู ุจู ุฑูุงูุง ู ุงุฑุฒููุง ููู ูฺฉุฑ ฺฉูู ู ุงูฺฉู ูฺ ููุช ุจุฑุง ูุญูู ฺฉุฑุฏูุดูู ุฏุฑ ูุณุช ู ุจุงุฏ ุจู ูุดุงูู ูุง ุงูุงู ุฏุงุดุชู ุจุงุดู ุดุงุฏ ุจุง ูุฏู ุจุฑุฏุงุดุชู ุฏุฑ ูุณุฑ ุงูุณุงูู ุดุฎุตููู ูุงุฎูุงุณุชู ุจุงุนุซ ุดู ุงูุฑุงุฏ ุฏฺฏุฑ ุฏุฑ ูุณุฑ ุงุฑุฒููุงุดูู ูุฑุงุฑ ุจฺฏุฑูุฏ ู ุงูฺฉู ูฺ ูุฑู ุฏุฑ ุฌูุงู ุงุฒ ุจู ููุฑู ู ุชููุง ุฏุฑ ฺุฑุฎุด ุงุณุช ูพุณ ุฑูุชุงุฑ ูุง ุจุฑ ุฌูุงู ูพุฑุงูููููู ูุทุนุง ุชุงุซุฑ ฺฏุฐุงุฑู . ุฌุฒ ุจูุชุฑู ฺฉุชุงุจ ูุง ุจูุฏ ฺฉู ุฎููุฏู ู ูุทุนุง ุฏูุจุงุฑู ุจู ุณุฑุงุบุด ูุฑู . ู....\n",
            "ุจุฑูู ุฒ ุชู ูุณุช ุงูฺู ุฏุฑ ุนุงูู ูุณุช ุงุฒุฎูุฏ ุจุทูุจ ูุฑ ุงูฺู ุฎูุงู ฺฉู ุชู\n",
            "ุนุงุดูู ุงุฏุจุงุช ูุจุงุฏ ุงุฒ ุงู ฺฉุชุงุจ ุจฺฏุฐุฑู ๐\n",
            "ุนุงุดูู ุงุฏุจุงุช ูุจุงุฏ ุงุฒ ุงู ฺฉุชุงุจ ุจฺฏุฐุฑู \n",
            "ุณูุงู...ุจู ุงู ุฌููู ุฏูุช ฺฉูุฏ:\n",
            "ูุงุชุงูุงุฆู !ุจุงุฏ ุชู ุฏุฑ ุฎูุดุชูุุชูุงู ฺฉุชุงุจูุง ุฑุง ุจุณูุฒุงู...\n",
            "ฺฉุงุฑุจุฑุงู ฺฉู ุขูุงุฏฺฏ ุฑูุญ ู ุฑูุงู ุฏุงุฑูุฏ ฺฉู ุจู ุงู ุฌููู ุฌุงูู ุนูู ุจูพูุดุงูู ู ุฏุฑ ููุดุชู ูุงูุงูุุงุฒ ุฏู ุฎูุฏ ุจููุณูุุจุฏูู ูฺ ุงุทูุงุนุงุช ฺฉุชุงุจุุงูุฌุง ุงุนูุงู ุขูุงุฏฺฏ ฺฉููุฏ...๐โ\n",
            "ุณูุงู...ุจู ุงู ุฌููู ุฏูุช ฺฉูุฏ:\n",
            "ูุงุชุงูุงุฆู !ุจุงุฏ ุชู ุฏุฑ ุฎูุดุชูุุชูุงู ฺฉุชุงุจูุง ุฑุง ุจุณูุฒุงู...\n",
            "ฺฉุงุฑุจุฑุงู ฺฉู ุขูุงุฏฺฏ ุฑูุญ ู ุฑูุงู ุฏุงุฑูุฏ ฺฉู ุจู ุงู ุฌููู ุฌุงูู ุนูู ุจูพูุดุงูู ู ุฏุฑ ููุดุชู ูุงูุงูุุงุฒ ุฏู ุฎูุฏ ุจููุณูุุจุฏูู ูฺ ุงุทูุงุนุงุช ฺฉุชุงุจุุงูุฌุง ุงุนูุงู ุขูุงุฏฺฏ ฺฉููุฏ...\n",
            "ุดฺฏูุชุง!ูุงุชุงูุงุฆู ุชู ุฎุฏุงุฑุง ุฏุฑ ุชููฺฉ ุฏุงุฑ ู ุฎูุฏ ุงุฒ ุขู ุจ ุฎุจุฑ ุจูุฏู ุง...\n",
            "ูุงุชุงูุงุฆูุุชููุง ุฎุฏุงุณุช ฺฉู ููุชูุงู ุฏุฑ ุงูุชุธุงุฑุด ุจูุฏุุฏุฑ ุงูุชุธุงุฑ ุฎุฏุง ุจูุฏูุูุงุชุงูุงุฆูุุนู ุฏุฑ ูุงูุชู ุงูฺฉู ุงูุฑุง ูู ุงฺฉููู ุฏุฑ ูุฌูุฏ ุฎูุฏ ุฏุงุฑ....โคโค\n",
            "ุชุฑุฌูู ููุณุช ุจุญุฑู๐\n",
            "ุดฺฏูุชุง!ูุงุชุงูุงุฆู ุชู ุฎุฏุงุฑุง ุฏุฑ ุชููฺฉ ุฏุงุฑ ู ุฎูุฏ ุงุฒ ุขู ุจ ุฎุจุฑ ุจูุฏู ุง...\n",
            "ูุงุชุงูุงุฆูุุชููุง ุฎุฏุงุณุช ฺฉู ููุชูุงู ุฏุฑ ุงูุชุธุงุฑุด ุจูุฏุุฏุฑ ุงูุชุธุงุฑ ุฎุฏุง ุจูุฏูุูุงุชุงูุงุฆูุุนู ุฏุฑ ูุงูุชู ุงูฺฉู ุงูุฑุง ูู ุงฺฉููู ุฏุฑ ูุฌูุฏ ุฎูุฏ ุฏุงุฑ....\n",
            "ุชุฑุฌูู ููุณุช ุจุญุฑู\n",
            "ุงุตูุง ุชุฑุฌูุด ุฎูุจ ูุณุชโ\n",
            "ุงุตูุง ุชุฑุฌูุด ุฎูุจ ูุณุชโ\n",
            " ุฌูุฑุง ุฎูุจูุุ ุจูุชุฑ ุงุฒ ุงูู ูุณุช :/\n",
            " ุฌูุฑุง ุฎูุจูุุ ุจูุชุฑ ุงุฒ ุงูู ูุณุช :/\n",
            "ูุงุชุงูู ุง ฺฉุงุด ุนุธูุช ุฏุฑ ูฺฏุงู ุชู ุจุงุดุฏ ูู ุฏุฑ ฺุฒ ฺฉู ุจู ุงู ู ูฺฏุฑ\n",
            "ุณูุฑุงุจ;ูู ููุฏุงูู ฺฉู ฺุฑุง ูฺฏููุฏ ุงุณุจ ุญูุงู ูุญุจ ุงุณุช ฺฉุจูุชุฑ ุฒุจุงุณุช ู ฺุฑุง ุฏุฑ ููุณ ูฺ ฺฉุณ ฺฉุฑฺฉุณ ูุณุช ฺฏู ุดุจุฏุฑ ฺู ฺฉู ุงุฒ ูุงูู ูุฑูุฒ ุฏุงุฑุฏ.....ฺุดู ูุง ุฑุง ุจุงุฏ ุดุณุช ุฌูุฑ ุฏฺฏุฑ ุจุงุฏ ุฏุฏ\n",
            "ูุงุชุงูู ุง ฺฉุงุด ุนุธูุช ุฏุฑ ูฺฏุงู ุชู ุจุงุดุฏ ูู ุฏุฑ ฺุฒ ฺฉู ุจู ุงู ู ูฺฏุฑ\n",
            "ุณูุฑุงุจ;ูู ููุฏุงูู ฺฉู ฺุฑุง ูฺฏููุฏ ุงุณุจ ุญูุงู ูุญุจ ุงุณุช ฺฉุจูุชุฑ ุฒุจุงุณุช ู ฺุฑุง ุฏุฑ ููุณ ูฺ ฺฉุณ ฺฉุฑฺฉุณ ูุณุช ฺฏู ุดุจุฏุฑ ฺู ฺฉู ุงุฒ ูุงูู ูุฑูุฒ ุฏุงุฑุฏ.....ฺุดู ูุง ุฑุง ุจุงุฏ ุดุณุช ุฌูุฑ ุฏฺฏุฑ ุจุงุฏ ุฏุฏ\n",
            "ุฒุจุงุณุช...\n",
            "ุฒุจุงุณุช...\n",
            "ุฏุฑฺฉ ุนูู ู ุฎูุงูุฏ ู ููู ุนุธู ู ุฑูุญู ุง ูุทู! ุนุงูโค\n",
            "ุฏุฑฺฉ ุนูู ู ุฎูุงูุฏ ู ููู ุนุธู ู ุฑูุญู ุง ูุทู! ุนุงู\n",
            "\"ฺฉุงุด ฺฉุชุงุจู ุจู ุชู ุจุงููุฒุฏ ฺฉู ุจุด ุชุฑ ุงุฒ ุงู ฺฉุชุงุจ ุจู ุฎูุฏ ุจูพุฑุฏุงุฒ... ู ุณูพุณ ุจุด ุชุฑ ุงุฒ ุฎูุฏ ุจู ุฏฺฏุฑ ฺุฒูุง\"\n",
            "๐ูุงุฆุฏู ูุง ุฒูู/ุขูุฏุฑู ฺุฏ\n",
            "ุฎู ูุทู ุจูุฏ ูุซู ูุณู ฺฉู ุตูุฑุช ุขุฏูู ููุงุฒุด ู ฺฉูู.\n",
            "ูู ุจุง ุชุฑุฌูู  ุฎุงูู ุจุญุฑู ุฎููุฏู ูู ุจู ูุธุฑู ุชุฑุฌูู  ุขูุง ุฏุงุฑูุด ูพุฑูุฒ ุงุฏุจ ุชุฑ ู ุฒุจุงุชุฑู.\n",
            "\"ฺฉุงุด ฺฉุชุงุจู ุจู ุชู ุจุงููุฒุฏ ฺฉู ุจุด ุชุฑ ุงุฒ ุงู ฺฉุชุงุจ ุจู ุฎูุฏ ุจูพุฑุฏุงุฒ... ู ุณูพุณ ุจุด ุชุฑ ุงุฒ ุฎูุฏ ุจู ุฏฺฏุฑ ฺุฒูุง\"\n",
            "ูุงุฆุฏู ูุง ุฒูู/ุขูุฏุฑู ฺุฏ\n",
            "ุฎู ูุทู ุจูุฏ ูุซู ูุณู ฺฉู ุตูุฑุช ุขุฏูู ููุงุฒุด ู ฺฉูู.\n",
            "ูู ุจุง ุชุฑุฌูู  ุฎุงูู ุจุญุฑู ุฎููุฏู ูู ุจู ูุธุฑู ุชุฑุฌูู  ุขูุง ุฏุงุฑูุด ูพุฑูุฒ ุงุฏุจ ุชุฑ ู ุฒุจุงุชุฑู.\n",
            "ุชู ุฏุจุฑุณุชุงู ูู ุฏุงุดุชู. ุงุฏุด ุจุฎุฑ\n",
            "ุชู ุฏุจุฑุณุชุงู ูู ุฏุงุดุชู. ุงุฏุด ุจุฎุฑ\n",
            "ฺฉุชุงุจ ุจู ููุณ ุฎูุฏุด ููู ุงูุนุงุฏุณ...ุงูุง ุชุฑุฌูู ฺฉู ููฺฏ ูุฒูู...\n",
            "ฺฉุชุงุจ ุจู ููุณ ุฎูุฏุด ููู ุงูุนุงุฏุณ...ุงูุง ุชุฑุฌูู ฺฉู ููฺฏ ูุฒูู...\n",
            "ฺฉุชุงุจ ุงุณุช ฺฉู ุจุงุฏ ุฎูุงูุฏู ุดูุฏ .ูุฏุฑ ฺฉ ุดูุฏ ุจุณุงุฑ ุนุงู ุงุณุช ูุฒุจุงู ุงุฒ ุชูุตู ุงู ุงุซุฑ ูุงุชูุงู ุงุณุช.\"ุงฺฏุฑ ุฑูุญ ฺฉุณ ุงุฑุฒุด ฺุฒ ุฑุง ุฏุงุฑุฏ ุฏูู ุจุฑ ุงู ุงุณุช ฺฉู ุจุด ุงุฒ ุฏฺฏุฑุงู ุณูุฎุชู ุงุณุช\"\n",
            "ฺฉุชุงุจ ุงุณุช ฺฉู ุจุงุฏ ุฎูุงูุฏู ุดูุฏ .ูุฏุฑ ฺฉ ุดูุฏ ุจุณุงุฑ ุนุงู ุงุณุช ูุฒุจุงู ุงุฒ ุชูุตู ุงู ุงุซุฑ ูุงุชูุงู ุงุณุช.\"ุงฺฏุฑ ุฑูุญ ฺฉุณ ุงุฑุฒุด ฺุฒ ุฑุง ุฏุงุฑุฏ ุฏูู ุจุฑ ุงู ุงุณุช ฺฉู ุจุด ุงุฒ ุฏฺฏุฑุงู ุณูุฎุชู ุงุณุช\"\n",
            "\"ูุงุชุงูุงุฆูุ ุนุธูุช ุฎุฏุง ุจุงุฏ ุฏุฑ ฺุดูุงู ุชู ุจุงุดุฏุูู ุฏุฑ ุขูฺู ุจู ุขู ู ูฺฏุฑ.\"\n",
            "\"ูุงุชุงูุงุฆูุ ุนุธูุช ุฎุฏุง ุจุงุฏ ุฏุฑ ฺุดูุงู ุชู ุจุงุดุฏุูู ุฏุฑ ุขูฺู ุจู ุขู ู ูฺฏุฑ.\"\n",
            "ฺฉุชุงุจ ุจุณุงุฑ ุฎูุจ ุงุณุช. \n",
            "ุงฺฏุฑฺู ุฏุฑ ูุฑู  ฑน ููุงุฏ ููุดุชู ุดุฏู ุงุณุช  ุงูุง ุฏฺฉุชุฑ ุดุฑุนุช ุฏุฑ ุจุนุถ ุขุซุงุฑุด ุงุฒ ูุง ุฆุฏู  ูุง ุฒูู ุงุฏ ฺฉุฑุฏู ุงุณุช.\n",
            "ฺฉุชุงุจ ุจุณุงุฑ ุฎูุจ ุงุณุช. \n",
            "ุงฺฏุฑฺู ุฏุฑ ูุฑู  ฑน ููุงุฏ ููุดุชู ุดุฏู ุงุณุช  ุงูุง ุฏฺฉุชุฑ ุดุฑุนุช ุฏุฑ ุจุนุถ ุขุซุงุฑุด ุงุฒ ูุง ุฆุฏู  ูุง ุฒูู ุงุฏ ฺฉุฑุฏู ุงุณุช.\n",
            "ฺฉุชุงุจ ุฎูุจู ุจุฑุง ฺฉุณุง ฺฉู ุฏุฎุชุฑ ุฏุงุฑู...ูู ุจุดุชุฑ ุจุฑ ูุจูุง ุชุฌุฑุจุงุช ุดุฎุตู ููุณูุฏุณุช...ููุดู ุตุฏ ุฏุฑ ุตุฏ ูุธุฑุงุช ุฑู ุชุงุฏ ฺฉุฑุฏ\n",
            "ฺฉุชุงุจ ุฎูุจู ุจุฑุง ฺฉุณุง ฺฉู ุฏุฎุชุฑ ุฏุงุฑู...ูู ุจุดุชุฑ ุจุฑ ูุจูุง ุชุฌุฑุจุงุช ุดุฎุตู ููุณูุฏุณุช...ููุดู ุตุฏ ุฏุฑ ุตุฏ ูุธุฑุงุช ุฑู ุชุงุฏ ฺฉุฑุฏ\n",
            "ุงู ฺฉุชุงุจ ุฎู ุนุงู ุจูุฏุ ูุญุธูโูุง ุทูุฒ ููุฑุงู ุจุง ูุญุธูโูุง ุบูโุงูฺฏุฒ ุจุง ููุฑูุงูโูุง ฺฉูฺฺฉ ฺฉู ุฎู ุฑุงุญุช ูุดุฏ ุจุงูุงุดูู ุงุฑุชุจุงุท ุจุฑูุฑุงุฑ ฺฉุฑุฏ. ููู ฺฉู ุจุจู ฺูุฏ ุชุง ููุฌููู ฺฉู ุฎู ูุชูุงูุช ุงุฒ ูุง ูุณุชู ูุชููู ุงููุฏุฑ ุจุฒุฑฺฏ ุจุดู ู ุจู ููู ุซุงุจุช ฺฉูู ฺฉู ุจฺู ูุณุชู ุจูฺฉู ุฑุฒููุฏูโุงู...\n",
            "ุงู ฺฉุชุงุจ ุฎู ุนุงู ุจูุฏุ ูุญุธูโูุง ุทูุฒ ููุฑุงู ุจุง ูุญุธูโูุง ุบูโุงูฺฏุฒ ุจุง ููุฑูุงูโูุง ฺฉูฺฺฉ ฺฉู ุฎู ุฑุงุญุช ูุดุฏ ุจุงูุงุดูู ุงุฑุชุจุงุท ุจุฑูุฑุงุฑ ฺฉุฑุฏ. ููู ฺฉู ุจุจู ฺูุฏ ุชุง ููุฌููู ฺฉู ุฎู ูุชูุงูุช ุงุฒ ูุง ูุณุชู ูุชููู ุงููุฏุฑ ุจุฒุฑฺฏ ุจุดู ู ุจู ููู ุซุงุจุช ฺฉูู ฺฉู ุจฺู ูุณุชู ุจูฺฉู ุฑุฒููุฏูโุงู...\n",
            "ููู ุงูุนุงุฏ ุจุนุฏ\n",
            "โคโค๐๐\n",
            "ููู ุงูุนุงุฏ ุจุนุฏ\n",
            "\n",
            "ุนุงู ุจูุฏ:')\n",
            "ุนุงู ุจูุฏ:')\n",
            "ุฎูุงูุฏู ุงู ฺฏููู ฺฉุชุงุจ ูุง ุฏุฑุณู ุฒูุฏฺฏ ุจู ุขุฏู ูุฏูุ ุงุฑุฒุด ูุง ู ุงูุฏุงู ูุณู ูุง ฺฏุฐุดุชู ุฑู ุงุฏุขูุฑ ู ฺฉูู ู ูู ฺฏุฐุงุฑู ููุช ู ูุฑููฺฏ ู ฺฏุฐุดุชู ูุงู ุฑุง ูุฑุงููุด ฺฉูู... ุนุงู ุจูุฏ..\n",
            "ุฎูุงูุฏู ุงู ฺฏููู ฺฉุชุงุจ ูุง ุฏุฑุณู ุฒูุฏฺฏ ุจู ุขุฏู ูุฏูุ ุงุฑุฒุด ูุง ู ุงูุฏุงู ูุณู ูุง ฺฏุฐุดุชู ุฑู ุงุฏุขูุฑ ู ฺฉูู ู ูู ฺฏุฐุงุฑู ููุช ู ูุฑููฺฏ ู ฺฏุฐุดุชู ูุงู ุฑุง ูุฑุงููุด ฺฉูู... ุนุงู ุจูุฏ..\n",
            "ูููุด ุฏุงูุดฺฏุงู ูพุฎุด ฺฉุฑุฏ ู ูุงูุนุง ุฌุฐุงุจ ุจูุฏ...ฺฉ ุงุฒ ูููู ุงุณุฑุง ูู ุงุณุชุงุฏ ุฏุงูุดฺฏุงููููู ู ุงุฒ ุชุฌุฑุจุงุชุด ุชู ุงูู ุดุฑุงุท ุจุฑุงููู ฺฏูุช\n",
            "ูููุด ุฏุงูุดฺฏุงู ูพุฎุด ฺฉุฑุฏ ู ูุงูุนุง ุฌุฐุงุจ ุจูุฏ...ฺฉ ุงุฒ ูููู ุงุณุฑุง ูู ุงุณุชุงุฏ ุฏุงูุดฺฏุงููููู ู ุงุฒ ุชุฌุฑุจุงุชุด ุชู ุงูู ุดุฑุงุท ุจุฑุงููู ฺฏูุช\n",
            "ูุทูุง ุงู ฺฉุชุงุจ ุฑู ุฏุฑ ฺฉุชุงุจุฎุงูู ููฺฏุงู ุจุฐุงุฑุฏ\n",
            "ูุทูุง ุงู ฺฉุชุงุจ ุฑู ุฏุฑ ฺฉุชุงุจุฎุงูู ููฺฏุงู ุจุฐุงุฑุฏ\n",
            "ฺูุฏููุช ูพุด ุงู ฺฉุชุงุจ ุฑู ุฎููุฏู ูุญุงูุง ฺฉู ูฺฉุฑูฺฉููโูุจููโุ ูุตูโุขู ูููุฒ ุจู ุฎูุจ ุงุฏู ูุณุช . ุฏููุดโุจูโูุธุฑูโโุฌุฐุงุจุชโูฺฏุฑุงโูุตูโุงุณุชโฺฉูโ ุฎูุงููุฏูโุฑุงููุฑุงูโุฎูุฏูโฺฉูุฏูุงุจูโุฒุจุงูโุฏฺฏุฑโุฎูุงููุฏูโุจุงุขูโุฒูุฏฺฏโูฺฉูุฏ.ูุฏุฑุขุฎุฑ:ุฎุฏุงููุฏ ุจูโโ ุฑุฒููุฏฺฏุงู ุดุฌุงุน ฺฉุดูุฑู ุงุฒุฌููู ุงู ุจุณุช ูุณู ููุฑ ุจุณุฌโููุฑูุงูโุนุงูุจุช ุจุฎุฑ ุนุทุง ฺฉูุฏ ุงูุดุงุกุงููู.\n",
            "ฺูุฏููุช ูพุด ุงู ฺฉุชุงุจ ุฑู ุฎููุฏู ูุญุงูุง ฺฉู ูฺฉุฑูฺฉููโูุจููโุ ูุตูโุขู ูููุฒ ุจู ุฎูุจ ุงุฏู ูุณุช . ุฏููุดโุจูโูุธุฑูโโุฌุฐุงุจุชโูฺฏุฑุงโูุตูโุงุณุชโฺฉูโ ุฎูุงููุฏูโุฑุงููุฑุงูโุฎูุฏูโฺฉูุฏูุงุจูโุฒุจุงูโุฏฺฏุฑโุฎูุงููุฏูโุจุงุขูโุฒูุฏฺฏโูฺฉูุฏ.ูุฏุฑุขุฎุฑ:ุฎุฏุงููุฏ ุจูโโ ุฑุฒููุฏฺฏุงู ุดุฌุงุน ฺฉุดูุฑู ุงุฒุฌููู ุงู ุจุณุช ูุณู ููุฑ ุจุณุฌโููุฑูุงูโุนุงูุจุช ุจุฎุฑ ุนุทุง ฺฉูุฏ ุงูุดุงุกุงููู.\n",
            "ฺฉุชุงุจ ุฎูโ ูุดูฺฏ ูโ ุฌุงูุจ ุจูุฏ ฺฉู ุจุนุซ ูุง ฒณ ุชู ุงุฒ ุงุณุฑุง ุงุฑุงู ููุฌููู ุฑุง ุงุฒุดูู ุงุณุชูุงุฏู ุชุจูุบุงุช ูฺฉูู ูู ุงููุง ูุงูุน ูุดู ู ุฏุณุช ุจู ฺฉุงุฑุง ูุซู ุงุนุชุตุงุจ ู... ูุฒูู.\n",
            "ฺฉุชุงุจ ุฎูโ ูุดูฺฏ ูโ ุฌุงูุจ ุจูุฏ ฺฉู ุจุนุซ ูุง ฒณ ุชู ุงุฒ ุงุณุฑุง ุงุฑุงู ููุฌููู ุฑุง ุงุฒุดูู ุงุณุชูุงุฏู ุชุจูุบุงุช ูฺฉูู ูู ุงููุง ูุงูุน ูุดู ู ุฏุณุช ุจู ฺฉุงุฑุง ูุซู ุงุนุชุตุงุจ ู... ูุฒูู.\n",
            "ุจุณุงุฑ ุนุงู ู ุฎูุจ\n",
            "ุจูุธุฑู ุจุฎูุจ ูุถุง ุณุฎุช ุงุณุงุฑุช ุฑู ุจู ุชุตูุฑ ฺฉุดุฏู ุงู ฺฉุชุงุจ .\n",
            "ูุฎุตูุตุง ูุณูุช ุขุฎุฑ ฺฉุชุงุจ ฺฉู ุงูุฌ ุฏุงุณุชุงูู\n",
            "ุจุณุงุฑ ุนุงู ู ุฎูุจ\n",
            "ุจูุธุฑู ุจุฎูุจ ูุถุง ุณุฎุช ุงุณุงุฑุช ุฑู ุจู ุชุตูุฑ ฺฉุดุฏู ุงู ฺฉุชุงุจ .\n",
            "ูุฎุตูุตุง ูุณูุช ุขุฎุฑ ฺฉุชุงุจ ฺฉู ุงูุฌ ุฏุงุณุชุงูู\n",
            "ุฑูุงุช ฺฉูุชุงู ุงูุง ุฏุฑ ุนู ุญุงู ฺฉุงูู ู ุดุฑูุ ุจุง ุงุฏุจุงุช ู ูฺฏุงุฑุด ุนุงู. ุฎุฏุง ููุช ู ูุนูุช ุจู ุตุฏุงู ู ูพุฑูุงู ุฌุฏุฏ ุนุฑุจุณุชุงู ุงุด\n",
            "ุฑูุงุช ฺฉูุชุงู ุงูุง ุฏุฑ ุนู ุญุงู ฺฉุงูู ู ุดุฑูุ ุจุง ุงุฏุจุงุช ู ูฺฏุงุฑุด ุนุงู. ุฎุฏุง ููุช ู ูุนูุช ุจู ุตุฏุงู ู ูพุฑูุงู ุฌุฏุฏ ุนุฑุจุณุชุงู ุงุด\n",
            "ุฎู ุฎูุจ โค\n",
            "ุฎู ุฎูุจ \n",
            "ุฑูุงุช ุชูุฎ ุจุง ููู ุดุฑู\n",
            "ุฑูุงุช ุชูุฎ ุจุง ููู ุดุฑู\n",
            "ุณูุงู ูู ฺฉุชุงุจ ููุงุตุงูุญ ุงุฒ ุงุณุฑุง ุงุจุฑุงู ุฑู ูู ุฎููุฏู ุฌุงูุจู ุงู ุขูุง ูู ุงุฒ ุงู ููุฌูุงู ูุง ุงุณุฑ ูฺฏู ฺฉู ฺุทูุฑ ุตุฏุงู ุงุฒุดูู ุงุณุชูุงุฏู ุงุจุฒุงุฑ ฺฉุฑุฏ\n",
            "ุณูุงู ูู ฺฉุชุงุจ ููุงุตุงูุญ ุงุฒ ุงุณุฑุง ุงุจุฑุงู ุฑู ูู ุฎููุฏู ุฌุงูุจู ุงู ุขูุง ูู ุงุฒ ุงู ููุฌูุงู ูุง ุงุณุฑ ูฺฏู ฺฉู ฺุทูุฑ ุตุฏุงู ุงุฒุดูู ุงุณุชูุงุฏู ุงุจุฒุงุฑ ฺฉุฑุฏ\n",
            "ุจุณุช ูุณู ููุฌูุงู ุงุฑุงู ุจุนุฏ ุงุฒ ุงุณุงุฑุช ุฏุฑ ุฌูฺฏุ ููุฑุฏ ุณูุงุณุชูุงุฏู ุชุจูุบุงุช ุตุฏุงู ูุฑุงุฑ ูฺฏุฑูุฏ. ุตุฏุงู ูุตุฏ ุฏุงุดุช ุจุง ุงููุง ุงู ูุถุง ฺฉู ุงู ููุฌูุงูุงู ุจุง ุงุฎุชุงุฑ ุฎูุฏุดุงู ุจู ุฌุจูู ูุงูุฏู ุงูุฏุ ุฑุณุงูู ูุง ุฑุง ุจุฑ ุนูู ุงุฑุงู ู ุงูููุงุจ ุงุณูุงู ุจุณุฌ ฺฉูุฏ. ุงูุง ุงู ุดุฑูุฑุฏูุง ุจุฑุง ุฌููฺฏุฑ ุงุฒ ุงุฌุงุฏ ูุถุง ููู ุนูู ฺฉุดูุฑ ู ุงูููุงุจุ ฺฉุงุฑ ุจุฒุฑฺฏ ฺฉุฑุฏูุฏ ฺฉู ุดุฑุญุด ุฏุฑ ฺฉุชุงุจ ุขูุฏู ุงุณุช. .\n",
            "ุฏุฑ ุณุงู ูุดุชุงุฏ ู ูุดุชุ ุฏู ูุงูุฌุจ ุจู ุจูุงูู ุชููุจ ุฏุฑ ุงูุชุฎุงุจุงุชุ ุนูุงูู ุจุฑ ุชุถุนู ูุฏุฑุช ฺฉุดูุฑุ ูุฌูู  ุฑุณุงูู ุง ุจุฒุฑฺฏ ุนูู ฺฉุดูุฑ ุจู ูุฌูุฏ ุขูุฑุฏูุฏ. ฺูุฏุฑ ุงูู ุฏูุชุง ฺฉูฺููู ุจูุฏูุฏ ู ฺูุฏุฑ ุงู ุจุณุช ู ุณู ููุฑ ุจุฒุฑฺฏ\n",
            "ุจู ูุธุฑู ุจุง ุญุฐู ูุณุงุฆู ฺฉู ุงููุชุ ุญุฌู ฺฉุชุงุจ ุฎู ูุชููุณุช ุงุฒ ุงู ฺฉูุชุฑ ุจุงุดู.\n",
            "ุจุณุช ูุณู ููุฌูุงู ุงุฑุงู ุจุนุฏ ุงุฒ ุงุณุงุฑุช ุฏุฑ ุฌูฺฏุ ููุฑุฏ ุณูุงุณุชูุงุฏู ุชุจูุบุงุช ุตุฏุงู ูุฑุงุฑ ูฺฏุฑูุฏ. ุตุฏุงู ูุตุฏ ุฏุงุดุช ุจุง ุงููุง ุงู ูุถุง ฺฉู ุงู ููุฌูุงูุงู ุจุง ุงุฎุชุงุฑ ุฎูุฏุดุงู ุจู ุฌุจูู ูุงูุฏู ุงูุฏุ ุฑุณุงูู ูุง ุฑุง ุจุฑ ุนูู ุงุฑุงู ู ุงูููุงุจ ุงุณูุงู ุจุณุฌ ฺฉูุฏ. ุงูุง ุงู ุดุฑูุฑุฏูุง ุจุฑุง ุฌููฺฏุฑ ุงุฒ ุงุฌุงุฏ ูุถุง ููู ุนูู ฺฉุดูุฑ ู ุงูููุงุจุ ฺฉุงุฑ ุจุฒุฑฺฏ ฺฉุฑุฏูุฏ ฺฉู ุดุฑุญุด ุฏุฑ ฺฉุชุงุจ ุขูุฏู ุงุณุช. .\n",
            "ุฏุฑ ุณุงู ูุดุชุงุฏ ู ูุดุชุ ุฏู ูุงูุฌุจ ุจู ุจูุงูู ุชููุจ ุฏุฑ ุงูุชุฎุงุจุงุชุ ุนูุงูู ุจุฑ ุชุถุนู ูุฏุฑุช ฺฉุดูุฑุ ูุฌูู  ุฑุณุงูู ุง ุจุฒุฑฺฏ ุนูู ฺฉุดูุฑ ุจู ูุฌูุฏ ุขูุฑุฏูุฏ. ฺูุฏุฑ ุงูู ุฏูุชุง ฺฉูฺููู ุจูุฏูุฏ ู ฺูุฏุฑ ุงู ุจุณุช ู ุณู ููุฑ ุจุฒุฑฺฏ\n",
            "ุจู ูุธุฑู ุจุง ุญุฐู ูุณุงุฆู ฺฉู ุงููุชุ ุญุฌู ฺฉุชุงุจ ุฎู ูุชููุณุช ุงุฒ ุงู ฺฉูุชุฑ ุจุงุดู.\n",
            "ุนุงู ู ุฌุฐุงุจ\n",
            "ูุนูุช ุจู ุฌูฺฏ\n",
            "ุนุงู ู ุฌุฐุงุจ\n",
            "ูุนูุช ุจู ุฌูฺฏ\n",
            "ฺูุฏ ุณุงู ูพุด ุฎููุฏูุด ุฒุจุง ู ุบุฑูุฑ ุขูุฑู ุจูุฏ\n",
            "ุฏุงุณุชุงู ุฒูุฏฺฏ ูุชุฑุฌู ฺฉู ุชู ุฒูุฏุงู ฺฉูุงุฑ ุงู ุจุณุช ู ุณู ููุฑ ุจูุฏ ูู ุจู ุงุณู ยซููุงุตุงูุญยป ููุดุชู ุดุฏู ุจุฎููุฏ ู ูุฐุช ุจุจุฑุฏ\n",
            "ฺูุฏ ุณุงู ูพุด ุฎููุฏูุด ุฒุจุง ู ุบุฑูุฑ ุขูุฑู ุจูุฏ\n",
            "ุฏุงุณุชุงู ุฒูุฏฺฏ ูุชุฑุฌู ฺฉู ุชู ุฒูุฏุงู ฺฉูุงุฑ ุงู ุจุณุช ู ุณู ููุฑ ุจูุฏ ูู ุจู ุงุณู ยซููุงุตุงูุญยป ููุดุชู ุดุฏู ุจุฎููุฏ ู ูุฐุช ุจุจุฑุฏ\n",
            "ฺฉุชุงุจ ุนุงู ุจูุฏ\n",
            "ูุงูุนุง ููุณูุฏู ููุงุฑุช ุฒุงุฏ ุฏุฑ ุชุตูุฑ ุณุงุฒ ู ุชูุตู ุงุชูุงูุงุช ุฏุงุดุช ุฎู ูุดูฺฏ ุจูุฏ\n",
            "ฺฉุชุงุจ ุนุงู ุจูุฏ\n",
            "ูุงูุนุง ููุณูุฏู ููุงุฑุช ุฒุงุฏ ุฏุฑ ุชุตูุฑ ุณุงุฒ ู ุชูุตู ุงุชูุงูุงุช ุฏุงุดุช ุฎู ูุดูฺฏ ุจูุฏ\n",
            "ุนุงู ุจูุฏ. ูุงูุนุงู ุงุฒ ุจูุชุฑู ุขุซุงุฑ ุฏุฑ ุฒููู ุงุณุงุฑุช ุขุฒุงุฏฺฏุงู ููู ุงุณูุงู ููู ุจูุฏ.....\n",
            "ุนุงู ุจูุฏ. ูุงูุนุงู ุงุฒ ุจูุชุฑู ุขุซุงุฑ ุฏุฑ ุฒููู ุงุณุงุฑุช ุขุฒุงุฏฺฏุงู ููู ุงุณูุงู ููู ุจูุฏ.....\n",
            "ฺฉุชุงุจ ูุฎุฑุฏ ูุฑุงุฑ ูููุด ุจุงุฏ\n",
            "ฺฉุชุงุจ ูุฎุฑุฏ ูุฑุงุฑ ูููุด ุจุงุฏ\n",
            "ุนุงู ุจูุฏ ุงุฑุงุฏู ุงุณุชูุงูุช ู ุงูุงู ุงู ุงูุฑุงุฏ ูุณุจุช ุจู ุณู ฺฉู ุดุงู ููู ุงูุนุงุฏู ุจุงูุง ุจูุฏ ุงู ุงุฒ ุดุงุฎุตู ูุง ุฒูุงู ุฏูุงุน ููุฏุณ ุงุณุช ฺฉู ุฑุฒููุฏฺฏุงู ุจุฑุฎูุงู ุฌุซู ูุญู ุดุงู ุดุฌุงุนุ ุฏูุฑ ู ูุชุฑุณูุฏ ู ุจุง ุฏุณุช ุฎุงู ู ุณู ฺฉู ุชููุง ุจุง ุงูุงู ฺฉู ุจูุชุฑู ุณูุงุญ ุงุณุช ุจู ุฏู ูุฏุงู ูุฒููุฏ ฺฉุงุด ุงูุฑูุฒ ูู ุงุฒ ุงู ููุฌูุงู ูุง ุดุงูุฒุฏู ุณุงูู ุจุดุชุฑ ูพุฏุง ุจุดูุฏ.\n",
            "ุนุงู ุจูุฏ ุงุฑุงุฏู ุงุณุชูุงูุช ู ุงูุงู ุงู ุงูุฑุงุฏ ูุณุจุช ุจู ุณู ฺฉู ุดุงู ููู ุงูุนุงุฏู ุจุงูุง ุจูุฏ ุงู ุงุฒ ุดุงุฎุตู ูุง ุฒูุงู ุฏูุงุน ููุฏุณ ุงุณุช ฺฉู ุฑุฒููุฏฺฏุงู ุจุฑุฎูุงู ุฌุซู ูุญู ุดุงู ุดุฌุงุนุ ุฏูุฑ ู ูุชุฑุณูุฏ ู ุจุง ุฏุณุช ุฎุงู ู ุณู ฺฉู ุชููุง ุจุง ุงูุงู ฺฉู ุจูุชุฑู ุณูุงุญ ุงุณุช ุจู ุฏู ูุฏุงู ูุฒููุฏ ฺฉุงุด ุงูุฑูุฒ ูู ุงุฒ ุงู ููุฌูุงู ูุง ุดุงูุฒุฏู ุณุงูู ุจุดุชุฑ ูพุฏุง ุจุดูุฏ.\n",
            "ุฎุฏุงุด ุจุงุญุงู ุจูุฏ\n",
            "ุชูุตู ูฺฉูู ุญุชูุง ุจุฎููุฏ\n",
            "ุฎุฏุงุด ุจุงุญุงู ุจูุฏ\n",
            "ุชูุตู ูฺฉูู ุญุชูุง ุจุฎููุฏ\n",
            "ุงูุฑูุฒ ฺฏูุชูุฏ ูููุด ุฑู ูุฎูุงู ุจุณุงุฒู ๐\n",
            "ุงูุฏูุงุฑู ุฎูุจ ูพุด ุจุฑู ู ุนุงู ุจุณุงุฒู ...ูููู ุจุงุดูุฏ๐ุฎู ุฎูุดุญุงู ุดุฏู...๐๐๐\n",
            "ุงูุฑูุฒ ฺฏูุชูุฏ ูููุด ุฑู ูุฎูุงู ุจุณุงุฒู \n",
            "ุงูุฏูุงุฑู ุฎูุจ ูพุด ุจุฑู ู ุนุงู ุจุณุงุฒู ...ูููู ุจุงุดูุฏุฎู ุฎูุดุญุงู ุดุฏู...\n",
            "ุฎู ุฎูุจู ุญุชูุง ุจุฎููุฏุด\n",
            "๐๐๐๐\n",
            "ุฎู ุฎูุจู ุญุชูุง ุจุฎููุฏุด\n",
            "\n",
            "ุงู ฺฉุชุงุจ ฺฉ ฺฉุชุงุจ ููู ุงูุนุงุฏู ุณุช. ูุชู ฺฉุชุงุจ ุจุณุงุฑ ุฑูุงู ู ุฏููุดู ู ุฏุงุณุชุงู ุฎู ุฌุฐุงุจู. ุจู ุทูุฑ ฺฉู ูู ุงู ฺฉุชุงุจ ุฑู ุงุตูุง ูุชููุณุชู ุฒูู ุจุฐุงุฑู ู ููู ุด ุชู ุฐููู ุจู ุงู ูฺฉุฑ ูฺฉุฑุฏู ฺฉู ูุฑุงุฑู ฺู ุงุชูุงู ุจุฑุง ุงู ุจุฒุฑฺฏ ูุฑุฏูุง ุจูุชู. ู ุงูุจุชู ุจุนุถ ุฌุง ูุงุด ูู ุจุณุงุฑ ุฏุฑุฏ ูุงฺฉ ู ุบู ุงูฺฏุฒ ุจูุฏ ู ุชููฺฏุฑ ุจุฑุง ูู ู ุงูุซุงู ูู ฺฉู ุจูููู ฺู ุฒุญูุช ูุง ุจุฑุง ุญูุธ ุงุฑุงู ู ุงูููุงุจ ฺฉุดุฏู ุดุฏู ู ุจู ุฑุงุญุช ุจู ุงู ุฒุญูุงุช ูพุดุช ูฺฉูู ู ุณุฎุช ูุง ฺฉู ุจุนุถุง ูพุด ูุงุฏ ุฑู ุชุญูู ฺฉูู ุชุง ุญุฏุงูู ุจุฎุด ุงุฒ ุฏู ุฎูุฏููู ุฑู ุจู ุงู ุนุฒุฒุงู ุงุฏุง ฺฉูู ู ุจุฏุงูู ฺฉู \" ุงูููู ููุน ุงูุนูุณุฑ ูุณุฑุงู\"\n",
            "ุงู ฺฉุชุงุจ ฺฉ ฺฉุชุงุจ ููู ุงูุนุงุฏู ุณุช. ูุชู ฺฉุชุงุจ ุจุณุงุฑ ุฑูุงู ู ุฏููุดู ู ุฏุงุณุชุงู ุฎู ุฌุฐุงุจู. ุจู ุทูุฑ ฺฉู ูู ุงู ฺฉุชุงุจ ุฑู ุงุตูุง ูุชููุณุชู ุฒูู ุจุฐุงุฑู ู ููู ุด ุชู ุฐููู ุจู ุงู ูฺฉุฑ ูฺฉุฑุฏู ฺฉู ูุฑุงุฑู ฺู ุงุชูุงู ุจุฑุง ุงู ุจุฒุฑฺฏ ูุฑุฏูุง ุจูุชู. ู ุงูุจุชู ุจุนุถ ุฌุง ูุงุด ูู ุจุณุงุฑ ุฏุฑุฏ ูุงฺฉ ู ุบู ุงูฺฏุฒ ุจูุฏ ู ุชููฺฏุฑ ุจุฑุง ูู ู ุงูุซุงู ูู ฺฉู ุจูููู ฺู ุฒุญูุช ูุง ุจุฑุง ุญูุธ ุงุฑุงู ู ุงูููุงุจ ฺฉุดุฏู ุดุฏู ู ุจู ุฑุงุญุช ุจู ุงู ุฒุญูุงุช ูพุดุช ูฺฉูู ู ุณุฎุช ูุง ฺฉู ุจุนุถุง ูพุด ูุงุฏ ุฑู ุชุญูู ฺฉูู ุชุง ุญุฏุงูู ุจุฎุด ุงุฒ ุฏู ุฎูุฏููู ุฑู ุจู ุงู ุนุฒุฒุงู ุงุฏุง ฺฉูู ู ุจุฏุงูู ฺฉู \" ุงูููู ููุน ุงูุนูุณุฑ ูุณุฑุงู\"\n",
            "ุนุงููุุญุชูุง ุฏุฑ ุณุฑ ูุทุงูุนุงุช ูุฑุงุฑุด ุจุฏุฏุุชูุฎ ุงุณุงุฑุช ุจู ููุฑุงู ฺุงุดู ุทูุฒ\n",
            "ุนุงููุุญุชูุง ุฏุฑ ุณุฑ ูุทุงูุนุงุช ูุฑุงุฑุด ุจุฏุฏุุชูุฎ ุงุณุงุฑุช ุจู ููุฑุงู ฺุงุดู ุทูุฒ\n",
            "ฺฉุชุงุจ ุนุงู ูุณุช.ุญุชูุง ุจุฎููุฏ\n",
            "ฺฉุชุงุจ ุนุงู ูุณุช.ุญุชูุง ุจุฎููุฏ\n",
            "ูุชู ุฑูุงู ู ุฒุจุง ุฏุงุฑุฏ ุจุณุงุฑ ูุงุฒู ุจุฑุง ููู ุณูู\n",
            "ูุชู ุฑูุงู ู ุฒุจุง ุฏุงุฑุฏ ุจุณุงุฑ ูุงุฒู ุจุฑุง ููู ุณูู\n",
            "ฺฉุชุงุจ ููุฏ ู ุชุงุซุฑฺฏุฐุงุฑ ุจูุฏุ ุฎูุงูุฏู ุงูู ุฑู ุจู ููู ููุฌูุงูุงู ูุทูู ุชูุตู ู ฺฉูู\n",
            "ฺฉุชุงุจ ููุฏ ู ุชุงุซุฑฺฏุฐุงุฑ ุจูุฏุ ุฎูุงูุฏู ุงูู ุฑู ุจู ููู ููุฌูุงูุงู ูุทูู ุชูุตู ู ฺฉูู\n",
            "ุฎุงุทุฑุงุช ุจุณุงุฑ ุฌุงูุจ ุชูุฌู ู ููุฏ ุฏุงุฑู ุฎููุฏู ุงู ฺฉุชุงุจ ุฑุง ุจู ูุณู ุฌูุงู ุชูุตู ูฺฉูู\n",
            "ุฎุงุทุฑุงุช ุจุณุงุฑ ุฌุงูุจ ุชูุฌู ู ููุฏ ุฏุงุฑู ุฎููุฏู ุงู ฺฉุชุงุจ ุฑุง ุจู ูุณู ุฌูุงู ุชูุตู ูฺฉูู\n",
            "ฺฉุชุงุจ ููู ุงูุนุงุฏู ุฒุจุง ู ูุชู ุฑูุงู ู ฺฏุฑุง ุญุชูุง ุชูุตู ูฺฉูู ุงู ฺฉุชุงุจ ูุทุงูุนู ฺฉูุฏ ู ุงุฒ ุฎุงุทุฑุงุช ฺฉ ุงุซุฑ ุฌูฺฏ ูุฐุช ุจุจุฑุฏ\n",
            "ฺฉุชุงุจ ููู ุงูุนุงุฏู ุฒุจุง ู ูุชู ุฑูุงู ู ฺฏุฑุง ุญุชูุง ุชูุตู ูฺฉูู ุงู ฺฉุชุงุจ ูุทุงูุนู ฺฉูุฏ ู ุงุฒ ุฎุงุทุฑุงุช ฺฉ ุงุซุฑ ุฌูฺฏ ูุฐุช ุจุจุฑุฏ\n",
            "ุงู ูุฒูู ุจุฑุง ฺฉุชุงุจ ุงูฺฉุชุฑููฺฉ ฺฉู ุฒุงุฏู.ุงฺฏู ุงูฺฉุงูุด ุจุงุดู ุจุง ูุจูุบ ฺฉูุชุฑ ุจุฐุงุฑู ฺฉู ุงูุฑุงุฏ ุจุดุชุฑ ุงุณุชูุงุฏู ฺฉููุฏ.\n",
            "ุงู ูุฒูู ุจุฑุง ฺฉุชุงุจ ุงูฺฉุชุฑููฺฉ ฺฉู ุฒุงุฏู.ุงฺฏู ุงูฺฉุงูุด ุจุงุดู ุจุง ูุจูุบ ฺฉูุชุฑ ุจุฐุงุฑู ฺฉู ุงูุฑุงุฏ ุจุดุชุฑ ุงุณุชูุงุฏู ฺฉููุฏ.\n",
            "ุฎุฏุง ุฑู ุดฺฉุฑ ุฎููุฏู ู ุฎูุจ ุจูุฏ ูุฎุตูุตุง ุฑูุญู ุนุฌุจ ุงุณุฑุง ููุฌูุงู ูุคูู ุงุฑุงู...\n",
            "ุฎุฏุง ุฑู ุดฺฉุฑ ุฎููุฏู ู ุฎูุจ ุจูุฏ ูุฎุตูุตุง ุฑูุญู ุนุฌุจ ุงุณุฑุง ููุฌูุงู ูุคูู ุงุฑุงู...\n",
            "ูู ุฎูุดู ูููุฏ\n",
            "\n",
            "ูู ุฎูุดู ูููุฏ\n",
            "\n",
            "โ ๐ธูุงู ุฑูุถุงู\n",
            "\n",
            "ุงููู ุฑูุฒู ุฑุง ฺฏุฑูุชู ุ ุจุง ุณุฎุช ุจุณุงุฑ. ุชุดูฺฏ ฺฉุดูุฏู ู ุทุงูุช ุณูุฒ ุจูุฏ ุ ุงูุง ุจู ูุฑ ุญุงู ุจุง ุตุฏุง ุดูฺฉ ุชููพ ุงูุทุงุฑ ููู ฺุฒ ุชูุงู ุดุฏ ู ุฑูุฒูุงู ุฑุง ุจุงุฒ ฺฉุฑุฏู. ุฏุฑ ุนุฑุงู ุ ุงุนูุงู ููุนุฏ ุงูุทุงุฑ ูู ุจุง ุงุฐุงู ฺฉู ุจุง ุดูฺฉ ุชููพ ุงุณุชุ ุฑูุฒูุง ุงูู ุฑูุถุงู ุชุง ุงู ุชููพ ุจุฎูุงูุฏ ุดูฺฉ ุจุดูุฏ ุฌุงู ูุง ุจู ูุจ ู ุฑุณุฏ!\n",
            "ูพุฑูุฑุฏ ุนุฑุจ ุฑูุฒู ูู ฺฏุฑูุชุ ุงูุง ุจุดุชุฑ ุงุฒ ูุง ุจุฑุง ูุฑุง ุฑุณุฏู ููุนุฏ ุงูุทุงุฑ ูุญุธู ุดูุงุฑ ู ฺฉุฑุฏ. ูุฑ ุฑูุฒ ุ ุณู ุณุงุนุช ูุงูุฏู ุจู ุดูฺฉ ุชููพ ุงูุทุงุฑ ุ ุดูุงุฑุด ูุนฺฉูุณ ุฑุง ุดุฑูุน ู ฺฉุฑุฏ ู ุจู ููุตูุฑ ู ฺฏูุช: \" ููุตูุฑ ุ ุณู ุณุงุนุช ุฏฺฏู.\"\n",
            "ูู ุจ ุงุนูุงู ูพุฑูุฑุฏ ูู ู ุฏุงูุณุชู ฺฉ ููุช ุงุฐุงู ู ุดูุฏ. ุดุนุงุน ุขูุชุงุจ ฺฉู ุงุฒ ูพูุฌุฑู ุฒูุฏุงู ู ุงูุชุงุฏ ุฑู ุฏูุงุฑ ุ ุชุง ุจุฑุณุฏ ฺฉูุงุฑ ุฏุฑ ุฒูุฏุงู ุ ูุณุฑ ุฏู ุณุงุนุชู ุฑุง ุท ู ฺฉุฑุฏ. ููุช ุขูุฌุง ุ ุฏุฑ ุขุฎุฑู ุงุณุชฺฏุงู ุฎูุฏ ุ ฺฉุงููุง ุจ ุฑูฺฏ ู ุดุฏุ ุงุฒ ูพุดุช ูพูุฌุฑู ุตุฏุง ุดูฺฉ ุชููพ ุงูุทุงุฑ ุจู ฺฏูุด ู ุฑุณุฏ.\n",
            "\n",
            "๐ุขู ุจุณุช ู ุณู ููุฑ ุ ุงุญูุฏ ูุณู ุฒุงุฏู\n",
            "#ุฏูุงุน_ููุฏุณ\n",
            " ูุงู ุฑูุถุงู\n",
            "\n",
            "ุงููู ุฑูุฒู ุฑุง ฺฏุฑูุชู ุ ุจุง ุณุฎุช ุจุณุงุฑ. ุชุดูฺฏ ฺฉุดูุฏู ู ุทุงูุช ุณูุฒ ุจูุฏ ุ ุงูุง ุจู ูุฑ ุญุงู ุจุง ุตุฏุง ุดูฺฉ ุชููพ ุงูุทุงุฑ ููู ฺุฒ ุชูุงู ุดุฏ ู ุฑูุฒูุงู ุฑุง ุจุงุฒ ฺฉุฑุฏู. ุฏุฑ ุนุฑุงู ุ ุงุนูุงู ููุนุฏ ุงูุทุงุฑ ูู ุจุง ุงุฐุงู ฺฉู ุจุง ุดูฺฉ ุชููพ ุงุณุชุ ุฑูุฒูุง ุงูู ุฑูุถุงู ุชุง ุงู ุชููพ ุจุฎูุงูุฏ ุดูฺฉ ุจุดูุฏ ุฌุงู ูุง ุจู ูุจ ู ุฑุณุฏ!\n",
            "ูพุฑูุฑุฏ ุนุฑุจ ุฑูุฒู ูู ฺฏุฑูุชุ ุงูุง ุจุดุชุฑ ุงุฒ ูุง ุจุฑุง ูุฑุง ุฑุณุฏู ููุนุฏ ุงูุทุงุฑ ูุญุธู ุดูุงุฑ ู ฺฉุฑุฏ. ูุฑ ุฑูุฒ ุ ุณู ุณุงุนุช ูุงูุฏู ุจู ุดูฺฉ ุชููพ ุงูุทุงุฑ ุ ุดูุงุฑุด ูุนฺฉูุณ ุฑุง ุดุฑูุน ู ฺฉุฑุฏ ู ุจู ููุตูุฑ ู ฺฏูุช: \" ููุตูุฑ ุ ุณู ุณุงุนุช ุฏฺฏู.\"\n",
            "ูู ุจ ุงุนูุงู ูพุฑูุฑุฏ ูู ู ุฏุงูุณุชู ฺฉ ููุช ุงุฐุงู ู ุดูุฏ. ุดุนุงุน ุขูุชุงุจ ฺฉู ุงุฒ ูพูุฌุฑู ุฒูุฏุงู ู ุงูุชุงุฏ ุฑู ุฏูุงุฑ ุ ุชุง ุจุฑุณุฏ ฺฉูุงุฑ ุฏุฑ ุฒูุฏุงู ุ ูุณุฑ ุฏู ุณุงุนุชู ุฑุง ุท ู ฺฉุฑุฏ. ููุช ุขูุฌุง ุ ุฏุฑ ุขุฎุฑู ุงุณุชฺฏุงู ุฎูุฏ ุ ฺฉุงููุง ุจ ุฑูฺฏ ู ุดุฏุ ุงุฒ ูพุดุช ูพูุฌุฑู ุตุฏุง ุดูฺฉ ุชููพ ุงูุทุงุฑ ุจู ฺฏูุด ู ุฑุณุฏ.\n",
            "\n",
            "ุขู ุจุณุช ู ุณู ููุฑ ุ ุงุญูุฏ ูุณู ุฒุงุฏู\n",
            "#ุฏูุงุน_ููุฏุณ\n",
            "ุฎู ุฌุฐุงุจ ู ุนุงู... ุจู ููฺฏ ูพุดููุงุฏ ูุดู. \n",
            "ุฎู ุฌุฐุงุจ ู ุนุงู... ุจู ููฺฏ ูพุดููุงุฏ ูุดู. \n",
            "ฺฉุชุงุจ ูุดูฺฏ ุจูุฏ\n",
            "ฺฉุชุงุจ ูุดูฺฏ ุจูุฏ\n",
            "ููููู ุงุด ฺฉู ุฌุงูุจ ุจูุฏ\n",
            "ููููู ุงุด ฺฉู ุฌุงูุจ ุจูุฏ\n",
            "ููุง ฺุดุฏู ุทุนู ุชูุฎ ุงุณุงุฑุช ุฌุฒ ุจุฑุง ุขูุงูฺฉู ุงู ุฌุงู ุจูุง ุฑุง ุนุงุดูุงูู ุณุฑ ฺฉุดุฏูุฏ ูุณุฑ ูุณุช. ุฏุฑ ุงู ฺฉุชุงุจ ู ุฎูุงูู ฺฺฏููู ูุฑุฒูุฏุงู ููุฌูุงู ุฑูุญ ุงููู ฺฉุจุฑ ุจู ุฌูุงูุงู ูุดุงู ุฏุงุฏูุฏ ฺฉู ูุฑฺฏ ุฏุฑ ุฑุงู ุฑุณุฏู ุจู ุขุฑูุงู ูุงุดุงู ุจู ุทูู ูููพุง ู ูุงูุฏ ฺฉู ุชุญุช ุงุฑุงุฏู ุงุดุงู ุงุณุช.\n",
            "ููฺฉูู ฺฉุชุงุจ ุจุฑุง ฺฉุณ ฺฉู ฺูู ูุงู ุฏุฑ ุขุจ ูุฏุฑูุนูุช ุขุฒุงุฏ ู ุจูุง ุขู ุฑุง ูู ุฏุงูุฏ ููู ู ฺฉุณู ฺฉููุฏู ุจุงุดุฏ ุงูุง ฺฉุงูู ุณุฑ ุจู ฺฉุดูุฑูุง ููุณุงู ูู ุฌููู ุนุฑุงู ุฒุฏ ุชุง ุจุง ุณุทุฑ ุณุทุฑ ุงู ฺฉุชุงุจ ุจุชูุงู ููุณ ฺฉุดุฏ.\n",
            "ููุณูุฏู ูุญุชุฑู ุฌุฏุง ุงุฒ ุฏู ูุงุฌุฑุง ุฏุฏุงุฑ ุจุง ุตุฏุงู ูุนู ู ุงุนุชุตุงุจ ุบุฐุง ุจุงู ฺฉุชุงุจ ุณุงุฏู ู ุจ ูพุฑุงู ุจู ุฒูุฏฺฏ ุฑูุฒูุฑู ุงู ฺูุฏ ููุฑูุงู ููุฌูุงู ู ุฏูุง ููุฌูุงู ุชูุฃู ุจุง ุงุณุงุฑุชุดุงู ูพุฑุฏุงุฎุชู ุงุณุช ฺฉู ุฎูุงูุฏู ฺฉุชุงุจ ุจุฑุง ููุฌูุงูุงู ูุณู ุญุงุถุฑ ููฺฉู ู ฺฉูุฏ.\n",
            "ุจุงุดุฏ ุชุง ูุฑุฒูุฏุงู ุงู ูุฑุฒ ู ุจูู ูุฏุฑ ูุญุธู ูุญุธู ุขุฒุงุฏ ู ุนุฒุชุดุงู ุฑุง ุจุฏุงููุฏ.\n",
            "ููุง ฺุดุฏู ุทุนู ุชูุฎ ุงุณุงุฑุช ุฌุฒ ุจุฑุง ุขูุงูฺฉู ุงู ุฌุงู ุจูุง ุฑุง ุนุงุดูุงูู ุณุฑ ฺฉุดุฏูุฏ ูุณุฑ ูุณุช. ุฏุฑ ุงู ฺฉุชุงุจ ู ุฎูุงูู ฺฺฏููู ูุฑุฒูุฏุงู ููุฌูุงู ุฑูุญ ุงููู ฺฉุจุฑ ุจู ุฌูุงูุงู ูุดุงู ุฏุงุฏูุฏ ฺฉู ูุฑฺฏ ุฏุฑ ุฑุงู ุฑุณุฏู ุจู ุขุฑูุงู ูุงุดุงู ุจู ุทูู ูููพุง ู ูุงูุฏ ฺฉู ุชุญุช ุงุฑุงุฏู ุงุดุงู ุงุณุช.\n",
            "ููฺฉูู ฺฉุชุงุจ ุจุฑุง ฺฉุณ ฺฉู ฺูู ูุงู ุฏุฑ ุขุจ ูุฏุฑูุนูุช ุขุฒุงุฏ ู ุจูุง ุขู ุฑุง ูู ุฏุงูุฏ ููู ู ฺฉุณู ฺฉููุฏู ุจุงุดุฏ ุงูุง ฺฉุงูู ุณุฑ ุจู ฺฉุดูุฑูุง ููุณุงู ูู ุฌููู ุนุฑุงู ุฒุฏ ุชุง ุจุง ุณุทุฑ ุณุทุฑ ุงู ฺฉุชุงุจ ุจุชูุงู ููุณ ฺฉุดุฏ.\n",
            "ููุณูุฏู ูุญุชุฑู ุฌุฏุง ุงุฒ ุฏู ูุงุฌุฑุง ุฏุฏุงุฑ ุจุง ุตุฏุงู ูุนู ู ุงุนุชุตุงุจ ุบุฐุง ุจุงู ฺฉุชุงุจ ุณุงุฏู ู ุจ ูพุฑุงู ุจู ุฒูุฏฺฏ ุฑูุฒูุฑู ุงู ฺูุฏ ููุฑูุงู ููุฌูุงู ู ุฏูุง ููุฌูุงู ุชูุฃู ุจุง ุงุณุงุฑุชุดุงู ูพุฑุฏุงุฎุชู ุงุณุช ฺฉู ุฎูุงูุฏู ฺฉุชุงุจ ุจุฑุง ููุฌูุงูุงู ูุณู ุญุงุถุฑ ููฺฉู ู ฺฉูุฏ.\n",
            "ุจุงุดุฏ ุชุง ูุฑุฒูุฏุงู ุงู ูุฑุฒ ู ุจูู ูุฏุฑ ูุญุธู ูุญุธู ุขุฒุงุฏ ู ุนุฒุชุดุงู ุฑุง ุจุฏุงููุฏ.\n",
            "ุฎูุจ ุนุงู ุฎู ุฎูุจ\n",
            "ุฎูุจ ุนุงู ุฎู ุฎูุจ\n",
            "ฺฉุชุงุจ ุฑู ุจุฑุง ุจุงุฑ ุฏูู ู ุจุง ุงุทูุงุนุงุช ฺฉุงููุชุฑ ุงุฒ ุงุณุงุฑุช ุฎููุฏู ู ุงู ุจุงุฑ ุจุด ุงุฒ ูพุด ูุฐุช ุจุฑุฏู.ุจุงุฑูุง ู ุจุงุฑูุง ุฎูุฏู ุฑู ุจู ุฌุง\" ุขู ุจุณุช ู ุณู ููุฑ \"ฺฏุฐุงุดุชู ู ุจุง ุงูููุง ุณุฎุช ุฌูฺฏ ู ุงุณุงุฑุช ุฑู ฺุดุฏู.ูุทูุฆูู ูุฑุจุงุฑ ฺฉู ุงู ฺฉุชุงุจ ุฑู ุจุฎููู ูุฑฺฏุฒ ุจุฑุงู ฺฉููู ููุดู.ุนู ุงูุฎุตูุต ูุญุธุงุช ุจูุฏู ฺฉูุงุฑ \"ููุง ุตุงูุญ ูุงุฑ\"\n",
            "ฺฉุชุงุจ ุฑู ุจุฑุง ุจุงุฑ ุฏูู ู ุจุง ุงุทูุงุนุงุช ฺฉุงููุชุฑ ุงุฒ ุงุณุงุฑุช ุฎููุฏู ู ุงู ุจุงุฑ ุจุด ุงุฒ ูพุด ูุฐุช ุจุฑุฏู.ุจุงุฑูุง ู ุจุงุฑูุง ุฎูุฏู ุฑู ุจู ุฌุง\" ุขู ุจุณุช ู ุณู ููุฑ \"ฺฏุฐุงุดุชู ู ุจุง ุงูููุง ุณุฎุช ุฌูฺฏ ู ุงุณุงุฑุช ุฑู ฺุดุฏู.ูุทูุฆูู ูุฑุจุงุฑ ฺฉู ุงู ฺฉุชุงุจ ุฑู ุจุฎููู ูุฑฺฏุฒ ุจุฑุงู ฺฉููู ููุดู.ุนู ุงูุฎุตูุต ูุญุธุงุช ุจูุฏู ฺฉูุงุฑ \"ููุง ุตุงูุญ ูุงุฑ\"\n",
            "ุนุงูู ู ุงุชูุงูุงุชุด ุฎู  ูุชูุงูุชู.\n",
            "ุนุงูู ู ุงุชูุงูุงุชุด ุฎู  ูุชูุงูุชู.\n",
            "ุจฺู ูุง ุงู ฺฉุชุงุจ ู ุจุฎุฑู . ุงุฒุด ุฌููุฏู ุฏุงุฑู ุง ูู!!!\n",
            "ุจฺู ูุง ุงู ฺฉุชุงุจ ู ุจุฎุฑู . ุงุฒุด ุฌููุฏู ุฏุงุฑู ุง ูู!!!\n",
            "ูุง ุฎู ฺฉุชุงุจ ูุดูฺฏู ูู ฺฉุชุงุจ ฺุงูพุดู ุฏุงุฑู\n",
            "ูุง ุฎู ฺฉุชุงุจ ูุดูฺฏู ูู ฺฉุชุงุจ ฺุงูพุดู ุฏุงุฑู\n",
            "ฺฉุชุงุจ ูุดูฺฏู ุ ูพุดููุงุฏ ูุดู\n",
            "ฺฉุชุงุจ ูุดูฺฏู ุ ูพุดููุงุฏ ูุดู\n",
            "ุฎู ุนุงู ุจูุฏ ููุท ฺุฑุง ูุตูู ุจูุฏ.\n",
            "ุฎู ุนุงู ุจูุฏ ููุท ฺุฑุง ูุตูู ุจูุฏ.\n",
            "ูู ฺฉุชุงุจุด ุฑู ุฎููุฏู...ุฎู ุฎู ุฒุจุงุณุช...\n",
            "ููุชุธุฑ ฺฉุชุงุจ ุฏููุด ูุณุชู...ุงุฏุงูู ุฏุงุฑู ุฏฺฏูุ!ุ!\n",
            "ูู ฺฉุชุงุจุด ุฑู ุฎููุฏู...ุฎู ุฎู ุฒุจุงุณุช...\n",
            "ููุชุธุฑ ฺฉุชุงุจ ุฏููุด ูุณุชู...ุงุฏุงูู ุฏุงุฑู ุฏฺฏูุ!ุ!\n",
            "ุฎู ุฒุจุง ุจูุฏ ูู ฺฏุฑู ุฏุงุดุช ู ูู ุฎูุฏู ุนู ุงูุฎุตูุต ููุง ุตุงูุญ ูุงุฑ....\n",
            "ุฎู ุฒุจุง ุจูุฏ ูู ฺฏุฑู ุฏุงุดุช ู ูู ุฎูุฏู ุนู ุงูุฎุตูุต ููุง ุตุงูุญ ูุงุฑ....\n",
            "ูู ุฏูุณุด ุฏุงุดุชู ูุงูุนุง\n",
            "ุฎุตูุตุง ฺฉ ุชู ุจุฑูุงูู ูุงู ุนุณู ฺฉ ุชูุถุญ ุฎูุจ ุฏุฑ ููุฑุฏุด ุฏุงุฏูุฏ ู ุงุฒ ุงูู ุจุจุนุฏ ุฏูุจุงู ฺฉุชุงุจุด ุจูุฏู.\n",
            "ุดุฑุญ ุฑูุงู ู ุฒุจุง ุฏุงุดุช.\n",
            "ุจุงุฏ ุงูู ุงุฒ  ุงุณุชูุงูุช ููู ุจฺู ูุง ุฌูฺฏ ู ุจุนุฏ ุงุฒ ููุณูุฏู ฺฉุชุงุจ ุชุดฺฉุฑ ฺฉุฑุฏ \n",
            "โโโโโ\n",
            "ูู ุฏูุณุด ุฏุงุดุชู ูุงูุนุง\n",
            "ุฎุตูุตุง ฺฉ ุชู ุจุฑูุงูู ูุงู ุนุณู ฺฉ ุชูุถุญ ุฎูุจ ุฏุฑ ููุฑุฏุด ุฏุงุฏูุฏ ู ุงุฒ ุงูู ุจุจุนุฏ ุฏูุจุงู ฺฉุชุงุจุด ุจูุฏู.\n",
            "ุดุฑุญ ุฑูุงู ู ุฒุจุง ุฏุงุดุช.\n",
            "ุจุงุฏ ุงูู ุงุฒ  ุงุณุชูุงูุช ููู ุจฺู ูุง ุฌูฺฏ ู ุจุนุฏ ุงุฒ ููุณูุฏู ฺฉุชุงุจ ุชุดฺฉุฑ ฺฉุฑุฏ \n",
            "\n",
            "ูู ุจู ุชุงุฒฺฏ ูุฌููุนู ฺฉุชุงุจูุง ุขูุง ุฏฺฉุชุฑ ููุฏ ุฎุฏุงูุงู ุขุฑุงู ุฑู ุฎููุฏู .ุชูุตู ูฺฉูู ูุฑฺฉุณ  ุจู ุฒูุฏฺฏ ุงูุงูุงู ู ูพุงูุจุฑ ุฑุญูุช ุฏุฑ ูุงูุจ ุฏุงุณุชุงู ุนูุงูู ุฏุงุฑู ุงู ฺฉุชุงุจูุง ุฑู ุญุชูุง ุจุฎููู...\n",
            "ูู ุจู ุชุงุฒฺฏ ูุฌููุนู ฺฉุชุงุจูุง ุขูุง ุฏฺฉุชุฑ ููุฏ ุฎุฏุงูุงู ุขุฑุงู ุฑู ุฎููุฏู .ุชูุตู ูฺฉูู ูุฑฺฉุณ  ุจู ุฒูุฏฺฏ ุงูุงูุงู ู ูพุงูุจุฑ ุฑุญูุช ุฏุฑ ูุงูุจ ุฏุงุณุชุงู ุนูุงูู ุฏุงุฑู ุงู ฺฉุชุงุจูุง ุฑู ุญุชูุง ุจุฎููู...\n",
            "aallii\n",
            "aallii\n",
            "ูุงูุนุง ุตุงุฏูุงูู ุจูุฏ\n",
            "ูุงูุนุง ุตุงุฏูุงูู ุจูุฏ\n",
            "ุฎูุจู ูู ุญู ฺฉู ูุฏุช ฺฉูุชุงู ุฑู ุดุฑุญ ูุฏู\n",
            "ุฎูุจู ูู ุญู ฺฉู ูุฏุช ฺฉูุชุงู ุฑู ุดุฑุญ ูุฏู\n",
            "ุฎู ุฌุงูุจ ุจูุฏ. ุญู ฺฉู ุฏุงุณุชุงู ฺฉ ูุฏุช ฺฉูุชุงู ุงุฒ ุงู ุนุฒุฒุงู ุจูุฏ.\n",
            "\n",
            "ฺฉ ูฺฉุชู ุฌุงูุจ ูู ููุด ุจฺฉ ุจู ฺฏุฐุดุชู ู ุฏุงุฑุด ุจูุฏ.\n",
            "\n",
            "ุงูุชูุงุฏ ฺฉู ุฏุงุฑู.....ุงูุจุชู ฺูู ุฑุงู ูู ุฎูุงุฏ ุฑุง ุจุดู ุฒุงุฏ ุงุฒ ุฒูุฏุงู ุงุณุชุฎุจุงุฑุงุช ู ุงููุงุน ุดฺฉูุญู ูุง ูุญุดุชูุงฺฉ ุขูุฌุง ูู ฺฏู...ุฒูุฏุงู ุงุณุชุฎุจุงุฑุงุช ูุฎูู ุชุฑู ุฒูุฏุงู ุตุฏุงู ุจูุฏ ฺฉู ุฑุงู ุฒุงุฏ ุจู ูุญุดุชูุงฺฉ ุขู ููพุฑุฏุงุฎุช. ุงูุจุชู ูู ุชุญุฑุจู ูฺฉุฑุฏู :) ูู ูุทุงูุนู ฺฉุฑุฏู ุฏุฑ ุงู ุจุงุฑู :)\n",
            "ุฎู ุฌุงูุจ ุจูุฏ. ุญู ฺฉู ุฏุงุณุชุงู ฺฉ ูุฏุช ฺฉูุชุงู ุงุฒ ุงู ุนุฒุฒุงู ุจูุฏ.\n",
            "\n",
            "ฺฉ ูฺฉุชู ุฌุงูุจ ูู ููุด ุจฺฉ ุจู ฺฏุฐุดุชู ู ุฏุงุฑุด ุจูุฏ.\n",
            "\n",
            "ุงูุชูุงุฏ ฺฉู ุฏุงุฑู.....ุงูุจุชู ฺูู ุฑุงู ูู ุฎูุงุฏ ุฑุง ุจุดู ุฒุงุฏ ุงุฒ ุฒูุฏุงู ุงุณุชุฎุจุงุฑุงุช ู ุงููุงุน ุดฺฉูุญู ูุง ูุญุดุชูุงฺฉ ุขูุฌุง ูู ฺฏู...ุฒูุฏุงู ุงุณุชุฎุจุงุฑุงุช ูุฎูู ุชุฑู ุฒูุฏุงู ุตุฏุงู ุจูุฏ ฺฉู ุฑุงู ุฒุงุฏ ุจู ูุญุดุชูุงฺฉ ุขู ููพุฑุฏุงุฎุช. ุงูุจุชู ูู ุชุญุฑุจู ูฺฉุฑุฏู :) ูู ูุทุงูุนู ฺฉุฑุฏู ุฏุฑ ุงู ุจุงุฑู :)\n",
            "ุนุงุงุงุงุงู. ุงู ฺฉุชุงุจ ุฑู ุจู ูฺ ูุฌู ุงุฒ ุฏุณุช ูุฏูุฏ\n",
            "ุนุงุงุงุงุงู. ุงู ฺฉุชุงุจ ุฑู ุจู ูฺ ูุฌู ุงุฒ ุฏุณุช ูุฏูุฏ\n",
            "ุนุงู ุจูุฏ ูู ฺฉุงุด ู ฺฉู ุทููุงู ุชุฑ ุจูุฏ ู ุฌุฒุนุงุช ุจุดุชุฑ ุฏุงุดุช\n",
            "ุนุงู ุจูุฏ ูู ฺฉุงุด ู ฺฉู ุทููุงู ุชุฑ ุจูุฏ ู ุฌุฒุนุงุช ุจุดุชุฑ ุฏุงุดุช\n",
            "ูุงูุนุง ุฏุณุช ูุฑุฒุงุฏ. ููููู\n",
            "ูุงูุนุง ุฏุณุช ูุฑุฒุงุฏ. ููููู\n",
            "ุจุณุงุฑุนุงู ุจูุฏุงู ุดุงุกุงููู ุฎุฏุงุญูุธุดูู ฺฉูู ุชูุตู ูฺฉูู ุญุชูุงุฌูุงููุง ุนุฒุฒุจุฎูููุฏ.\n",
            "ูู ุฎูุฏู 14 ุณุงูู ุจูุฏุจุงฺฉู ฺฏุฑูุชุงุฑ ุฑูุชู ุจุฑุง ุฏูุงุน ุงุฒูุทู ูุฌุงูุจุงุฒุดุฏู ุจุงุชูุงู ูุฌูุฏุงู ุฑูุฏุงุฏุฑูุฏุฑุจุฎุดูุง ุงุฑุงู ุฏุฑฺฉ ูฺฉูู ูู ุชุตูุฑุณุฎุชูุง ุงู ุนุฒุฒุงู ุฏุฑุงุณุงุฑุช ุฏุฑฺฉุด ุณุฎุชู.\n",
            "ุจุณุงุฑุนุงู ุจูุฏุงู ุดุงุกุงููู ุฎุฏุงุญูุธุดูู ฺฉูู ุชูุตู ูฺฉูู ุญุชูุงุฌูุงููุง ุนุฒุฒุจุฎูููุฏ.\n",
            "ูู ุฎูุฏู 14 ุณุงูู ุจูุฏุจุงฺฉู ฺฏุฑูุชุงุฑ ุฑูุชู ุจุฑุง ุฏูุงุน ุงุฒูุทู ูุฌุงูุจุงุฒุดุฏู ุจุงุชูุงู ูุฌูุฏุงู ุฑูุฏุงุฏุฑูุฏุฑุจุฎุดูุง ุงุฑุงู ุฏุฑฺฉ ูฺฉูู ูู ุชุตูุฑุณุฎุชูุง ุงู ุนุฒุฒุงู ุฏุฑุงุณุงุฑุช ุฏุฑฺฉุด ุณุฎุชู.\n",
            "ุงูู ูุทูุง ุจุฐุงุฑุฏ ุจุฑุง ุชุฎูู ุขุฎุฑ ููุชู\n",
            "ุงูู ูุทูุง ุจุฐุงุฑุฏ ุจุฑุง ุชุฎูู ุขุฎุฑ ููุชู\n",
            "ูููู ฺฉู ุฏุฑ ุจุฑูุงูู ูุงู  ุนุณู94 ูู ุฏุนูุชุดูู ฺฉุฑุฏู ู ูุงุฌุฑุงุดูู ุชุนุฑู ฺฉุฑุฏู.\n",
            "ูููู ฺฉู ุฏุฑ ุจุฑูุงูู ูุงู  ุนุณู94 ูู ุฏุนูุชุดูู ฺฉุฑุฏู ู ูุงุฌุฑุงุดูู ุชุนุฑู ฺฉุฑุฏู.\n",
            "ูุงูุนุง ุนุงู ุจูุฏ\n",
            "ุชูุตู ูฺฉูู ุญุชูุง ุจุฎููุฏ\n",
            "ูุงูุนุง ุนุงู ุจูุฏ\n",
            "ุชูุตู ูฺฉูู ุญุชูุง ุจุฎููุฏ\n",
            "ุณูุงู \n",
            "ูุงูุนุง ฺฉุชุงุจ ููุฏ ูุขููุฒูุฏู ุง ูุณุช\n",
            "ูพุดููุงุฏ ูฺฉูู ุจุฎููุฏ\n",
            "ุณูุงู \n",
            "ูุงูุนุง ฺฉุชุงุจ ููุฏ ูุขููุฒูุฏู ุง ูุณุช\n",
            "ูพุดููุงุฏ ูฺฉูู ุจุฎููุฏ\n",
            "ุฎู ุฌุงูุจู ุฏุฑุณ ฺฏุฑูุชู ุฎู\n",
            "ุฎู ุฌุงูุจู ุฏุฑุณ ฺฏุฑูุชู ุฎู\n",
            "ุจุงุฑ ุงูู ุงุฑูุฑ ู ุฏุงุฏ ุจุฑุง ุจุงุฒ  ุดุฏู ูู ุจุนุฏ ุนุงู ุจูุฏ\n",
            "ุจุงุฑ ุงูู ุงุฑูุฑ ู ุฏุงุฏ ุจุฑุง ุจุงุฒ  ุดุฏู ูู ุจุนุฏ ุนุงู ุจูุฏ\n",
            "ุจุณุงุฑ ุฎูุจ ุจูุฏ ุนู ููุฑ\n",
            "ุจุณุงุฑ ุฎูุจ ุจูุฏ ุนู ููุฑ\n",
            "ุนุงู ุจูุฏ. ููููู ุงุฒุชุฎูู ููุงุดฺฏุงู\n",
            "ุนุงู ุจูุฏ. ููููู ุงุฒุชุฎูู ููุงุดฺฏุงู\n",
            "ููู ุงุฏ ูุงฺฉ ุชุงุณูู ููุฏุงุฒู ฺฉู ุจู ุฎุงุทุฑ ฺฉุจูุชุฑุด ููุฑูุงู ุฌูุงู ุดุฏ\n",
            "ููู ุงุฏ ูุงฺฉ ุชุงุณูู ููุฏุงุฒู ฺฉู ุจู ุฎุงุทุฑ ฺฉุจูุชุฑุด ููุฑูุงู ุฌูุงู ุดุฏ\n",
            "ุฑููู ฺฏุงุฑ ฺฉู ุฎูุฏุด ุฒูุงู ุฌุฒู ููุงูุฏฺฏุงู ูุฑุงูุณู ุฏุฑ ุณุงุฒูุงู ููู ุจูุฏูุ ุงู ฺฉุชุงุจ ุฑู ุจุงุงุณู ูุณุชุนุงุฑ ู ุจุง ฺฉูุงู ุจู ุณุงุณุชูุง ุณุงุฒูุงู ููู ู ุฌู ุญุงฺฉูู ุจุฑ ุณุงุณุช ุจู ุงูููู ุฏุฑ ุฒูุงู ุฎูุฏุด ูููุณู.ฺฉู ุฎู ุงุฒ ุงู ูุณุงุฆู ุฏุฑ ุญุงู ุญูุถุฑ ูู ูุฌูุฏ ุฏุงุฑู. ูุณุงุฆู ฺฉู ูุทุฑุญ ูฺฉูู ูุชููู ุจุง ุชุบุฑ ูุงููุง ุจู ููุถูุนุงุช ูุฎุชูู ุฏุฑ ุฒูุงููุง ูุฎุชูู ู ุญูุฒู ูุง ูุฎุชูู ูู ุชุนูู ูพุฏุง ฺฉูู. ูุซุงู ููุฑุฏ ุนูุงูู ูู ฺฉู ุฏุฑ ฺฉุชุงุจ ูุทุฑุญ ุดุฏู gentleman agreement ฺฉู ุจู ููุงุถุน ูุชุถุงุฏ ุดูุฑู ู ุขูุฑฺฉุง ูฺฏู ุนู ูุฑ ุทุฑู ููุถุนฺฏุฑ ฺฉููุ ุทุฑู ููุงุจู ูุงุฒู ูุณุช ุชุงูู ฺฉููุ ุจุงุฏ ุจูุงูุงุตูู ููุถุน ูุฎุงูู ุจฺฏุฑู! ุงู ูุณุฆูู ุฏุฑ ูุถุงูุง ุฏููุทุจ ุณุงุณ ู ุงุฏุฆูููฺฺฉ ู ุญุช ููุงุฒุนุงุช ฺฉ ุฌูุน ุฏูุณุชุงูู ูุฒ ูุงุจู ูุดุงูุฏู ุงุณุช ฺฉู ุฑููู ฺฏุงุฑ ุฎู ุฌุงูุจ ุงููู ูุทุฑุญ ฺฉุฑุฏู.\n",
            "ุฑููู ฺฏุงุฑ ฺฉู ุฎูุฏุด ุฒูุงู ุฌุฒู ููุงูุฏฺฏุงู ูุฑุงูุณู ุฏุฑ ุณุงุฒูุงู ููู ุจูุฏูุ ุงู ฺฉุชุงุจ ุฑู ุจุงุงุณู ูุณุชุนุงุฑ ู ุจุง ฺฉูุงู ุจู ุณุงุณุชูุง ุณุงุฒูุงู ููู ู ุฌู ุญุงฺฉูู ุจุฑ ุณุงุณุช ุจู ุงูููู ุฏุฑ ุฒูุงู ุฎูุฏุด ูููุณู.ฺฉู ุฎู ุงุฒ ุงู ูุณุงุฆู ุฏุฑ ุญุงู ุญูุถุฑ ูู ูุฌูุฏ ุฏุงุฑู. ูุณุงุฆู ฺฉู ูุทุฑุญ ูฺฉูู ูุชููู ุจุง ุชุบุฑ ูุงููุง ุจู ููุถูุนุงุช ูุฎุชูู ุฏุฑ ุฒูุงููุง ูุฎุชูู ู ุญูุฒู ูุง ูุฎุชูู ูู ุชุนูู ูพุฏุง ฺฉูู. ูุซุงู ููุฑุฏ ุนูุงูู ูู ฺฉู ุฏุฑ ฺฉุชุงุจ ูุทุฑุญ ุดุฏู gentleman agreement ฺฉู ุจู ููุงุถุน ูุชุถุงุฏ ุดูุฑู ู ุขูุฑฺฉุง ูฺฏู ุนู ูุฑ ุทุฑู ููุถุนฺฏุฑ ฺฉููุ ุทุฑู ููุงุจู ูุงุฒู ูุณุช ุชุงูู ฺฉููุ ุจุงุฏ ุจูุงูุงุตูู ููุถุน ูุฎุงูู ุจฺฏุฑู! ุงู ูุณุฆูู ุฏุฑ ูุถุงูุง ุฏููุทุจ ุณุงุณ ู ุงุฏุฆูููฺฺฉ ู ุญุช ููุงุฒุนุงุช ฺฉ ุฌูุน ุฏูุณุชุงูู ูุฒ ูุงุจู ูุดุงูุฏู ุงุณุช ฺฉู ุฑููู ฺฏุงุฑ ุฎู ุฌุงูุจ ุงููู ูุทุฑุญ ฺฉุฑุฏู.\n",
            "ุจุง ุชูุฌู ุจู ุญุฌู ฺฉู ุงู ฺฉุชุงุจ ุ ุฎูุงูุฏูุด ุฎุงู ุงุฒ ูุทู ูุณุช.\n",
            "ุจุง ุชูุฌู ุจู ุญุฌู ฺฉู ุงู ฺฉุชุงุจ ุ ุฎูุงูุฏูุด ุฎุงู ุงุฒ ูุทู ูุณุช.\n",
            "ุชุฑุฌูู  ุฑูุงู ูุฎูุจ ุฏุงุดุช. ุงูุง ุฎูุฏ ุฏุงุณุชุงู ุฎูุจ ุดุฑูุน ุดุฏู ุจูุฏ ูู ุงุฒ ุงูุงุณุท ุขู ุฏฺุงุฑ ุดุนุงุฑ ุฒุฏฺฏ ฺฉูุดู ุง ุดุฏู ุจูุฏ ุจูุฑ ุญุงู ููุณูุฏู ูุนุฑูู  ุจูุฏ\n",
            "ุชุฑุฌูู  ุฑูุงู ูุฎูุจ ุฏุงุดุช. ุงูุง ุฎูุฏ ุฏุงุณุชุงู ุฎูุจ ุดุฑูุน ุดุฏู ุจูุฏ ูู ุงุฒ ุงูุงุณุท ุขู ุฏฺุงุฑ ุดุนุงุฑ ุฒุฏฺฏ ฺฉูุดู ุง ุดุฏู ุจูุฏ ุจูุฑ ุญุงู ููุณูุฏู ูุนุฑูู  ุจูุฏ\n",
            "ุฎูุดูุงู ุขูุฏุ ุฎูุจ ุจูุฏ!\n",
            "ุฎูุดูุงู ุขูุฏุ ุฎูุจ ุจูุฏ!\n",
            "ูุงูุนุง ุฏูุชูู ฺฏุฑู ุนุงู\n",
            "ูุงูุนุง ุฏูุชูู ฺฏุฑู ุนุงู\n",
            "ุซุงูุซ ู ุทุงูฺูุ ููููู ุงุฒ  ูุฑ ุฏู ุดูุง\n",
            "ุซุงูุซ ู ุทุงูฺูุ ููููู ุงุฒ  ูุฑ ุฏู ุดูุง\n",
            "ุฎู ูุฒุฎุฑู ุจูุฏ\n",
            "ุฎู ูุฒุฎุฑู ุจูุฏ\n",
            "ฺฉุชุงุจ ุจุฏ ูุณุช. ูู ุชุนุฏุงุฏ ุตูุญุงุช ุขู ต ุตูุญู ุงุณุช ฺฉู ุฏุฑ ูุดุฎุตุงุช ฺฉุชุงุจ ฒด ุตูุญู ุฐฺฉุฑ ุดุฏู ุงุณุช.\n",
            "ฺฉุชุงุจ ุจุฏ ูุณุช. ูู ุชุนุฏุงุฏ ุตูุญุงุช ุขู ต ุตูุญู ุงุณุช ฺฉู ุฏุฑ ูุดุฎุตุงุช ฺฉุชุงุจ ฒด ุตูุญู ุฐฺฉุฑ ุดุฏู ุงุณุช.\n",
            "ุจุฑุง ุงู ฺฉุชุงุจ ุงููุฏุฑ ุชุฑุฌูู ุฒุงุฏู ฺฉู ุขุฏู ููโุฏููู ฺฉุฏูู ุฑู ุจุฎููู!!!\n",
            "ุจุฑุง ุงู ฺฉุชุงุจ ุงููุฏุฑ ุชุฑุฌูู ุฒุงุฏู ฺฉู ุขุฏู ููโุฏููู ฺฉุฏูู ุฑู ุจุฎููู!!!\n",
            "ฺฉุชุงุจ ุฑุงุฒ ุจุด ุงุฒ ุขู ฺฉู ุฏุฑ ูุถุง ุญุงุช ูุชุนุงู ู ุฒูุฏฺฏ ูุนูู ู ุงูู ุจุงุดุฏ ุฏุฑ ูุถุง ุฒุณุช ุญูุงู ู ุชุฑุบุจ ุฎูุงููุฏฺฏุงู ุจู ุฏูุง ฺฏุฑุง ุดุฏุฏ ุชุฑ ู ุงูุณุงู ูุญูุฑ ุนูู ุชุฑ ุงุณุช. ุดุงูุฏ ุงู ฺฏูุชู ูู ุงู ุงุณุช ฺฉู ุฑุงูุฏุง ุจุฑู ุจุนุฏ ุงุฒ ฺฉ ุฏูุฑู ุณุฎุช ู ูุฑููพุงุด ูุถุนุช ูุงู ู ุงูุชุตุงุฏุ ฺฉุชุงุจ ุฑุง ุงุฒ ุฏุฎุชุฑุด ู ฺฏุฑุฏ ฺฉู ูุทุงูุนู ฺฉูุฏ ู ุงู ฺฉุชุงุจ ู ูุญุชูุง ุงู ฺฉุชุงุจ ุจุง ูุฏู ูพูู ุฏุงุฑ ุดุฏู ุจุดุชุฑ ุจู ุฑุดุชู ุชุญุฑุฑ ุฏุฑ ุขูุฏู ุงุณุช. ุงู ฺฉุชุงุจ ฺฉู ุชูุณุท ูุงูุงุณ ูุงุชูุฒ ุจู ูุงู ยซุนูู ูพูู ุฏุงุฑ ุดุฏูยป ููุดุชู ุดุฏู ุงุณุชุ ุฎูุฑ ูุงู ุงูฺฉุงุฑ ุฑุงูุฏุง ุจุฑู ูุงูุน ุดุฏู ุงุณุช ู ู ุฏุฑ ฺฉุชุงุจ ูุงุด ฺูุฏู ุจุงุฑ ุงุฒ ุงุซุฑ ฺฏุฐุงุฑ ุงู ฺฉุชุงุจ ุจุฑ ุงูุฏุดู ุฑููุฏุง ุจุงุฑู ู ูุจุงู ูฺฉุฑ ุงุด ูุงู ู ุจุฑุฏ ฺฉู ุจูุด ุฌุฏุฏ ุจู ู ุฏุงุฏู ุงุณุช.\n",
            "ูุชุงุณูุงูู ุจุนุถ ุจู ุบูุท ุฑููุฏุง ุจุงุฑู ุฑุง ฺฉ ูุนูู ูุนููุช ู ูุฑูุฌ ุฏู ู ูุฐูุจ ู ุดูุงุฑูุฏ ู ุงูฺฉุงุฑุด ุฑุง ุงูฺฉุงุฑ ูุชุนุงู ูููุฏุงุฏ ู ฺฉููุฏุ ุฏุฑ ุญุงู ฺฉู ุงูฺฉุงุฑ ู ุงูุฏุดู ูุง ุฑุงูุฏุง ุจุฑู ุงุตููุง ูฺ ุงุฑุชุจุงุท ุจุง ุนุงูู ูุนูุง ู ุชูุฑูุงุช ุฑูุญ ูุฏุงุฑุฏ ู ุงุณุงุณุง ู ฺฉ ุงุฒ ุนูููู ุฏุงุฑุงู ุฏูุงุฒุฏฺฏ ู ุฏูุงฺฏุฑุง ุงุณุช ู ุงุฏูโูุง ู ุจุฑ ูุจูุง ุงูุณุงู ูุญูุฑ ุจูุง ุดุฏู ุงุณุช ูู ุฎุฏุง ูุญูุฑ.\n",
            "ุงู ูุทูุจ ุงุฒ ุชูุถุญุงุช ููุฏุฑุฌ ุฏุฑ ุณุงุช ฺฉุชุงุจุฑุงู ฺฏุฐุงุดุชู ุดุฏ.\n",
            "ฺฉุชุงุจ ุฑุงุฒ ุจุด ุงุฒ ุขู ฺฉู ุฏุฑ ูุถุง ุญุงุช ูุชุนุงู ู ุฒูุฏฺฏ ูุนูู ู ุงูู ุจุงุดุฏ ุฏุฑ ูุถุง ุฒุณุช ุญูุงู ู ุชุฑุบุจ ุฎูุงููุฏฺฏุงู ุจู ุฏูุง ฺฏุฑุง ุดุฏุฏ ุชุฑ ู ุงูุณุงู ูุญูุฑ ุนูู ุชุฑ ุงุณุช. ุดุงูุฏ ุงู ฺฏูุชู ูู ุงู ุงุณุช ฺฉู ุฑุงูุฏุง ุจุฑู ุจุนุฏ ุงุฒ ฺฉ ุฏูุฑู ุณุฎุช ู ูุฑููพุงุด ูุถุนุช ูุงู ู ุงูุชุตุงุฏุ ฺฉุชุงุจ ุฑุง ุงุฒ ุฏุฎุชุฑุด ู ฺฏุฑุฏ ฺฉู ูุทุงูุนู ฺฉูุฏ ู ุงู ฺฉุชุงุจ ู ูุญุชูุง ุงู ฺฉุชุงุจ ุจุง ูุฏู ูพูู ุฏุงุฑ ุดุฏู ุจุดุชุฑ ุจู ุฑุดุชู ุชุญุฑุฑ ุฏุฑ ุขูุฏู ุงุณุช. ุงู ฺฉุชุงุจ ฺฉู ุชูุณุท ูุงูุงุณ ูุงุชูุฒ ุจู ูุงู ยซุนูู ูพูู ุฏุงุฑ ุดุฏูยป ููุดุชู ุดุฏู ุงุณุชุ ุฎูุฑ ูุงู ุงูฺฉุงุฑ ุฑุงูุฏุง ุจุฑู ูุงูุน ุดุฏู ุงุณุช ู ู ุฏุฑ ฺฉุชุงุจ ูุงุด ฺูุฏู ุจุงุฑ ุงุฒ ุงุซุฑ ฺฏุฐุงุฑ ุงู ฺฉุชุงุจ ุจุฑ ุงูุฏุดู ุฑููุฏุง ุจุงุฑู ู ูุจุงู ูฺฉุฑ ุงุด ูุงู ู ุจุฑุฏ ฺฉู ุจูุด ุฌุฏุฏ ุจู ู ุฏุงุฏู ุงุณุช.\n",
            "ูุชุงุณูุงูู ุจุนุถ ุจู ุบูุท ุฑููุฏุง ุจุงุฑู ุฑุง ฺฉ ูุนูู ูุนููุช ู ูุฑูุฌ ุฏู ู ูุฐูุจ ู ุดูุงุฑูุฏ ู ุงูฺฉุงุฑุด ุฑุง ุงูฺฉุงุฑ ูุชุนุงู ูููุฏุงุฏ ู ฺฉููุฏุ ุฏุฑ ุญุงู ฺฉู ุงูฺฉุงุฑ ู ุงูุฏุดู ูุง ุฑุงูุฏุง ุจุฑู ุงุตููุง ูฺ ุงุฑุชุจุงุท ุจุง ุนุงูู ูุนูุง ู ุชูุฑูุงุช ุฑูุญ ูุฏุงุฑุฏ ู ุงุณุงุณุง ู ฺฉ ุงุฒ ุนูููู ุฏุงุฑุงู ุฏูุงุฒุฏฺฏ ู ุฏูุงฺฏุฑุง ุงุณุช ู ุงุฏูโูุง ู ุจุฑ ูุจูุง ุงูุณุงู ูุญูุฑ ุจูุง ุดุฏู ุงุณุช ูู ุฎุฏุง ูุญูุฑ.\n",
            "ุงู ูุทูุจ ุงุฒ ุชูุถุญุงุช ููุฏุฑุฌ ุฏุฑ ุณุงุช ฺฉุชุงุจุฑุงู ฺฏุฐุงุดุชู ุดุฏ.\n",
            "ุนู ุงูุงู ูู ุนฺฉุณ ูุงุฒุฑุงุช 2017 ุจุง ููุช ฺูุฏ ููุงุฑุฏ ุฑู ุจู ุฏูุงุฑ ุจุฒูู ุจุฏุณุช ูุงุฑูุด! ูู ุฏู ุณุงู ฺฉุงุฑ ฺฉูู ู ฺุฒ ูู ูุฎูุฑู ุจุงุฒู ูฺฉุฑ ูฺฉูู ุชุงุจูู ฺฉุงุฆูุงุช ฺฉุงุฑ ุจฺฉูู ฺฉู ุตุงุญุจ ุงู ูุงุดู ุจุดู. ุชู ูุฏุฑุช ู ฺฉููู ูุณุช ุจู ุงุณู ุงูฺฉุงู ูพุฐุฑ ุนู ุงฺฏุฑ ูพุด ุฒููู ูุง ฺฉ ููุถูุน ููุฌูุฏ ูุจุงุดู ุงูู ุทุฑุญ ุฏุฑ ุงุจุชุฏุง ุง ุฏุฑ ุงุฏุงูู ุจุง ุดฺฉุณุช ุฑูุจุฑู ูุดู. ุงูุจุชู ุชูุฑฺฉุฒ ุฑู ฺฉ ููุถูุน ฺฉู ุงุฒ ูุธุฑ ููุทู ููฺฉู ุจุงุดู ู ุชูุงุด ูุงุฒู ุจุฑุง ุฑุณุฏูุด ูุชููู ููุซุฑ ุจุงุดู.\n",
            "ุนู ุงูุงู ูู ุนฺฉุณ ูุงุฒุฑุงุช 2017 ุจุง ููุช ฺูุฏ ููุงุฑุฏ ุฑู ุจู ุฏูุงุฑ ุจุฒูู ุจุฏุณุช ูุงุฑูุด! ูู ุฏู ุณุงู ฺฉุงุฑ ฺฉูู ู ฺุฒ ูู ูุฎูุฑู ุจุงุฒู ูฺฉุฑ ูฺฉูู ุชุงุจูู ฺฉุงุฆูุงุช ฺฉุงุฑ ุจฺฉูู ฺฉู ุตุงุญุจ ุงู ูุงุดู ุจุดู. ุชู ูุฏุฑุช ู ฺฉููู ูุณุช ุจู ุงุณู ุงูฺฉุงู ูพุฐุฑ ุนู ุงฺฏุฑ ูพุด ุฒููู ูุง ฺฉ ููุถูุน ููุฌูุฏ ูุจุงุดู ุงูู ุทุฑุญ ุฏุฑ ุงุจุชุฏุง ุง ุฏุฑ ุงุฏุงูู ุจุง ุดฺฉุณุช ุฑูุจุฑู ูุดู. ุงูุจุชู ุชูุฑฺฉุฒ ุฑู ฺฉ ููุถูุน ฺฉู ุงุฒ ูุธุฑ ููุทู ููฺฉู ุจุงุดู ู ุชูุงุด ูุงุฒู ุจุฑุง ุฑุณุฏูุด ูุชููู ููุซุฑ ุจุงุดู.\n",
            "ูู ุงุตูุง ููุชููู ุจุงูุฑ ฺฉูู ููฺู ฺุฒ ุฑู\n",
            "ูู ุงุตูุง ููุชููู ุจุงูุฑ ฺฉูู ููฺู ฺุฒ ุฑู\n",
            "ุนุงู ฺูุฏุชุง ุงุฒ ูุณุฎู ูุง ฺุงูพู ุฑุงุฒู ุฏุงุฑู...ุฌุงูุจุด ุงูุฌุงุณ ูุงูุนู ุนูู ูฺฉูู ๐\n",
            "ุนุงู ฺูุฏุชุง ุงุฒ ูุณุฎู ูุง ฺุงูพู ุฑุงุฒู ุฏุงุฑู...ุฌุงูุจุด ุงูุฌุงุณ ูุงูุนู ุนูู ูฺฉูู \n",
            "ุฎู ุนุงู!\n",
            "ุฎู ุนุงู!\n",
            "ูุฒุฎุฑู ุชุฑู ฺฉุชุงุจ ฺฉู ุฎููุฏู\n",
            "ูุฒุฎุฑู ุชุฑู ฺฉุชุงุจ ฺฉู ุฎููุฏู\n",
            "ฺุฑุช ู ูพุฑุชู ุจุดุชุฑ ูุทุงูุจุด...ุงูฺฏุงุฑ ฺฉ ุฎุฏุง ุฑู ูุงุฏุฏู ฺฏุฑูุชู\n",
            "ฺุฑุช ู ูพุฑุชู ุจุดุชุฑ ูุทุงูุจุด...ุงูฺฏุงุฑ ฺฉ ุฎุฏุง ุฑู ูุงุฏุฏู ฺฏุฑูุชู\n",
            "ููู ุงูุนุงุฏู ุงุณุูุชุดฺฉุฑู\n",
            "ููู ุงูุนุงุฏู ุงุณุูุชุดฺฉุฑู\n",
            "ุนุงูู! \n",
            "ูุงูุนุง ูุฌูู ุฎููุฏู ุชู ุขูพุฏ ูุฐุช ุฏุงุฑู :)\n",
            "ุนุงูู! \n",
            "ูุงูุนุง ูุฌูู ุฎููุฏู ุชู ุขูพุฏ ูุฐุช ุฏุงุฑู :)\n",
            "ุดุงูฺฉุงุฑูุญุถ. ุณู ุจุงุฑ ุฎูุงูุฏู ู ูููุฒ ุณุฑ ูุดุฏู\n",
            "ุดุงูฺฉุงุฑูุญุถ. ุณู ุจุงุฑ ุฎูุงูุฏู ู ูููุฒ ุณุฑ ูุดุฏู\n",
            "ฺฉ ุงุฒ ุจูุชุฑู ฺฉุชุงุจุง ูุฏ ฺฉู ุชุง ุญุงูุง ุฎููุฏู.\n",
            "ุงฺฏู ฺฉุณ ุงุฒ ุดูุง ุฎูุดุด ูุงุฏ ูุชููู ุงุนุชุฑุงุถ ฺฉูู ุงู ูุดฺฉู ุดูุง ูุณุช. ูพุณ ุงุฒ ูุชูุงูุช ุจูุฏู ูุชุฑุณุฏ ุฎูุฏุชูู ุจุงุดุฏ ู ฺฉุงุฑ ุฑู ฺฉู ุฏูุณุช ุฏุงุฑุฏ ุงูุฌุงู ุจุฏุฏ ูู ูุงููุฏ ุงูุฑุงุฏ ุนุงูู ูุด ุนูู ฺฉูุฏ ู ุณุน ฺฉูุฏ ุจู ฺฉุณ ุขุณุจ ูุฒูุฏ. ุชู ุขุฒุงุฏ ู ุชู ุงู ุฏูุง ูุณุช ฺฉู ฺฉุงุฑุง ุฑู ฺฉู ุฏูุณุช ุฏุงุฑ ุงูุฌุงู ุจุฏ ูพุณ ุฑูุง ฺฉู ุชู ุณุฑุชู ุฑู ุฏูุจุงู ฺฉู ูุฐุงุฑ ุงุทุฑุงูุงูุช ุชู ุฑู ูพุดููู ฺฉููุ ุฏุงุณุชุงู ุงุฏูุงุฑุฏ ุฑู ูุฑุงููุด ูฺฉู ูพุณุฑ ฺฉู ุงุฒ ุฑูุชู ุจู ุฏูุจุงู ฺุฒ ฺฉู ุฎุงููุงุฏูโุงุด ุงุฒุด ุงูุชุธุงุฑ ุฏุงุดุชู ุฎูุฏุฏุงุฑ ฺฉุฑุฏ ู ุณุน ฺฉุฑุฏ ู ุฏูุจุงู ุฑูุงุด ุจุฑู ูู ุฎุงููุงุฏู ุด ุชุฑุฌุญ ุฏุงุฏู ุงูู ุชู ุชูุงุฑุณุชุงู ุจุณุชุฑ ุจุงุดู ุชุง ุงูฺฉู ฺฉุงุฑ ุฑู ุงูุฌุงู ุจุฏู ฺฉู ุฏูุณุช ุฏุงุฑู. ู ูุฑููฺฉุง ุฏุฎุชุฑ ฺฉู ุฒูุฏฺฏ ุด ุนุฏ ุงุฒ ุฏูุจุงู ูฺฉุฑุฏู ุขุฑุฒููุงุด ู ูุฏุฑ ฺฉููุงุฎุช ุจูุฏ ฺฉู ุชุตูู ฺฏุฑูุช ุจูุฑูุ ุจู ุงู ฺฉู ุฏฺฏุฑุงู ุฑุงุฌุน ุจูุช ฺู ูฺฉุฑ ุฎูุงููุฏ ฺฉุฑุฏ ุงููุช ูุฏู ุงุฒ ูุชูุงูุช ุจูุฏู ูุชุฑุณ . ุจุฑุง ุนุงูู ุจูุฏู ุงูู ุจุงุฏ ุฏูุงูู ุจุงุดุ ุฏูุจุงู ุขุฑุฒููุงุช ุจุฑู ุชู ูุงุฒ ูุฏุงุฑ ุฒูุฏฺฏุชู ุจุฑุง ฺฉุณ ุชูุถุญ ุจุฏ ุงู ุฒูุฏฺฏู ุชูุณุช. ุงุฌุงุฒู ูุฏู ุฒูุฏฺฏุช ุจู ูพูฺ ุจฺฏุฐุฑู ู ุจุฑุง ุฑุณุฏู ุจู ุฑูุงูุง ู ุขุฑุฒููุงุช ุชูุงู ุชูุงุดุชู ุจฺฉู.\n",
            "\"ุขฺฏุงู ุงุฒ ูุฑฺฏ ูุง ุฑุง ุชุดูู ูฺฉูุฏ ุดุฏุฏุชุฑ ุฒูุฏฺฏ ฺฉูู\" ูพุณ ููุงุช ุงุณุชูุงุฏู ุฑู ุงุฒ ูุฑ ุฑูุฒุช ุจุจุฑ ู ุฌูุฑ ุฒูุฏฺฏ ฺฉู ฺฉู ุงูฺฏุงุฑ ูุฑุฏุง ูุฎูุงู ุจูุฏ.\n",
            "ฺฉ ุงุฒ ุจูุชุฑู ฺฉุชุงุจุง ูุฏ ฺฉู ุชุง ุญุงูุง ุฎููุฏู.\n",
            "ุงฺฏู ฺฉุณ ุงุฒ ุดูุง ุฎูุดุด ูุงุฏ ูุชููู ุงุนุชุฑุงุถ ฺฉูู ุงู ูุดฺฉู ุดูุง ูุณุช. ูพุณ ุงุฒ ูุชูุงูุช ุจูุฏู ูุชุฑุณุฏ ุฎูุฏุชูู ุจุงุดุฏ ู ฺฉุงุฑ ุฑู ฺฉู ุฏูุณุช ุฏุงุฑุฏ ุงูุฌุงู ุจุฏุฏ ูู ูุงููุฏ ุงูุฑุงุฏ ุนุงูู ูุด ุนูู ฺฉูุฏ ู ุณุน ฺฉูุฏ ุจู ฺฉุณ ุขุณุจ ูุฒูุฏ. ุชู ุขุฒุงุฏ ู ุชู ุงู ุฏูุง ูุณุช ฺฉู ฺฉุงุฑุง ุฑู ฺฉู ุฏูุณุช ุฏุงุฑ ุงูุฌุงู ุจุฏ ูพุณ ุฑูุง ฺฉู ุชู ุณุฑุชู ุฑู ุฏูุจุงู ฺฉู ูุฐุงุฑ ุงุทุฑุงูุงูุช ุชู ุฑู ูพุดููู ฺฉููุ ุฏุงุณุชุงู ุงุฏูุงุฑุฏ ุฑู ูุฑุงููุด ูฺฉู ูพุณุฑ ฺฉู ุงุฒ ุฑูุชู ุจู ุฏูุจุงู ฺุฒ ฺฉู ุฎุงููุงุฏูโุงุด ุงุฒุด ุงูุชุธุงุฑ ุฏุงุดุชู ุฎูุฏุฏุงุฑ ฺฉุฑุฏ ู ุณุน ฺฉุฑุฏ ู ุฏูุจุงู ุฑูุงุด ุจุฑู ูู ุฎุงููุงุฏู ุด ุชุฑุฌุญ ุฏุงุฏู ุงูู ุชู ุชูุงุฑุณุชุงู ุจุณุชุฑ ุจุงุดู ุชุง ุงูฺฉู ฺฉุงุฑ ุฑู ุงูุฌุงู ุจุฏู ฺฉู ุฏูุณุช ุฏุงุฑู. ู ูุฑููฺฉุง ุฏุฎุชุฑ ฺฉู ุฒูุฏฺฏ ุด ุนุฏ ุงุฒ ุฏูุจุงู ูฺฉุฑุฏู ุขุฑุฒููุงุด ู ูุฏุฑ ฺฉููุงุฎุช ุจูุฏ ฺฉู ุชุตูู ฺฏุฑูุช ุจูุฑูุ ุจู ุงู ฺฉู ุฏฺฏุฑุงู ุฑุงุฌุน ุจูุช ฺู ูฺฉุฑ ุฎูุงููุฏ ฺฉุฑุฏ ุงููุช ูุฏู ุงุฒ ูุชูุงูุช ุจูุฏู ูุชุฑุณ . ุจุฑุง ุนุงูู ุจูุฏู ุงูู ุจุงุฏ ุฏูุงูู ุจุงุดุ ุฏูุจุงู ุขุฑุฒููุงุช ุจุฑู ุชู ูุงุฒ ูุฏุงุฑ ุฒูุฏฺฏุชู ุจุฑุง ฺฉุณ ุชูุถุญ ุจุฏ ุงู ุฒูุฏฺฏู ุชูุณุช. ุงุฌุงุฒู ูุฏู ุฒูุฏฺฏุช ุจู ูพูฺ ุจฺฏุฐุฑู ู ุจุฑุง ุฑุณุฏู ุจู ุฑูุงูุง ู ุขุฑุฒููุงุช ุชูุงู ุชูุงุดุชู ุจฺฉู.\n",
            "\"ุขฺฏุงู ุงุฒ ูุฑฺฏ ูุง ุฑุง ุชุดูู ูฺฉูุฏ ุดุฏุฏุชุฑ ุฒูุฏฺฏ ฺฉูู\" ูพุณ ููุงุช ุงุณุชูุงุฏู ุฑู ุงุฒ ูุฑ ุฑูุฒุช ุจุจุฑ ู ุฌูุฑ ุฒูุฏฺฏ ฺฉู ฺฉู ุงูฺฏุงุฑ ูุฑุฏุง ูุฎูุงู ุจูุฏ.\n",
            "ุจุณ ุฌุฐุงุงุงุงุจ\n",
            "ุจุณ ุฌุฐุงุงุงุงุจ\n",
            "ุงู ฺฉุชุงุจู ุญุชูุง ุจุฎููุฏ.ุญุชูุง ุญุชูุง ุญุชูุง .โค\n",
            "ุงููุฏุฑ ุนุงู ุจูุฏ ู ุฎูุจ ููุดุชู ุดุฏู ุจูุฏ ฺฉู ููุท ุจุงุฏ ุจุฎูู ุชุง ูุชูุฌู ุจุด\n",
            "ุงู ฺฉุชุงุจู ุญุชูุง ุจุฎููุฏ.ุญุชูุง ุญุชูุง ุญุชูุง .\n",
            "ุงููุฏุฑ ุนุงู ุจูุฏ ู ุฎูุจ ููุดุชู ุดุฏู ุจูุฏ ฺฉู ููุท ุจุงุฏ ุจุฎูู ุชุง ูุชูุฌู ุจุด\n",
            "ุงู ฺฉุชุงุจ ุฑุง ุจุงุฏ ฺฉุณุง ุจุฎููู ฺฉู ุงูุณุฑุฏฺฏ ุฏุงุฑู ุง ุงูฺฉู ุณูุงู ูุง ุจูุงุฏ ุงุฒ ุฒูุฏฺฏ ุฏุงุฑู ... ุฏุฑ ุงุตู ุจุงุฏ ุดุฑุงุท ุฑูุญุช ุจุง ุดุฑุงุท ฺฉุชุงุจ ุณุงุฒฺฏุงุฑ ุจุงุดู...\n",
            "ุงู ฺฉุชุงุจ ุฑุง ุจุงุฏ ฺฉุณุง ุจุฎููู ฺฉู ุงูุณุฑุฏฺฏ ุฏุงุฑู ุง ุงูฺฉู ุณูุงู ูุง ุจูุงุฏ ุงุฒ ุฒูุฏฺฏ ุฏุงุฑู ... ุฏุฑ ุงุตู ุจุงุฏ ุดุฑุงุท ุฑูุญุช ุจุง ุดุฑุงุท ฺฉุชุงุจ ุณุงุฒฺฏุงุฑ ุจุงุดู...\n",
            "ุงู ฺฉุชุงุจ ุงุซุฑู ฺฉ ุงูุณุงูู ุดุงูฺฉุงุฑ ู ฺฉู ูุธุฑู.\n",
            "ุจุง ุฎููุฏูุด ุงุฏ ฺฏุฑูุชู ูุฑ ุฑูุฒ ฺฉ ฺุดูุงูู ุจุงุฒ ูฺฉูู ุจุฏููู ฺฉ ุงูุฑูุฒ ู ูุฏู ุฌุฏุฏู ฺฉ ูุตุจู ุดุฏู.\n",
            "ุงุฏ ฺฏุฑูุชู ฺฉ ูู ู ุฏูููู ุงู. ูพุณ ุฎูุฏู ุฑู ุฏุฑ ูุจุงุณ ุงูุณุงู ูุงู ุนุงูู ุฌุง ูุฏู ุชุง ุฑูุฒ ูุฑุณู ฺฉ ุงู ูุฑุฏู ุฎุทุฑู ูุชูุงูุช ุจูุฏูู ููู ุจู ุฑูู ุจฺฉุดู.\n",
            "ุงู ฺฉุชุงุจ ุงุซุฑู ฺฉ ุงูุณุงูู ุดุงูฺฉุงุฑ ู ฺฉู ูุธุฑู.\n",
            "ุจุง ุฎููุฏูุด ุงุฏ ฺฏุฑูุชู ูุฑ ุฑูุฒ ฺฉ ฺุดูุงูู ุจุงุฒ ูฺฉูู ุจุฏููู ฺฉ ุงูุฑูุฒ ู ูุฏู ุฌุฏุฏู ฺฉ ูุตุจู ุดุฏู.\n",
            "ุงุฏ ฺฏุฑูุชู ฺฉ ูู ู ุฏูููู ุงู. ูพุณ ุฎูุฏู ุฑู ุฏุฑ ูุจุงุณ ุงูุณุงู ูุงู ุนุงูู ุฌุง ูุฏู ุชุง ุฑูุฒ ูุฑุณู ฺฉ ุงู ูุฑุฏู ุฎุทุฑู ูุชูุงูุช ุจูุฏูู ููู ุจู ุฑูู ุจฺฉุดู.\n",
            "ุชุฑุฌูู  ุฏฺฏู ุง ูุฎููุฏู ูู ุจู ูุธุฑ ูู ุงู ุชุฑุฌูู ุจุณุงุฑ ุฎูุจ ุจูุฏ. ูุซุฑ ุงุฏุจ ุฑู ุฎูโูุง ูููพุณูุฏู ู ุงุญุชูุงูุง ุจู ููู ุนูุช ูฺฏู ุชุฑุฌูู ุจุฏ ุจูุฏู ู ุจู ูุธุฑุดูู ุจุงุฏ ุงุญุชุฑุงู ฺฏุฐุงุดุช ุงูุง ุงฺฏุฑ ุฎูุจ ูฺฉุฑ ฺฉูู ุฏุฑฺฉ ูฺฉูู ฺฉู ุจุงุฏ ู ูุฑู ุจู ูุญู ุงู ฺฉุชุงุจ ู ูุซูุง ูุฑ ูพุงุชุฑ ุจุงุดู. ุงูุตุงู ุฏุงุดุชู ุจุงุดู. ุงูุจุชู ุงุฑุงุฏุงุช ุชุงูพ ู ูฺฏุงุฑุด ุฒุงุฏ ุจูุฏ ู ุงู ูุดฺฉู ุจู ูููุฑ ุฏุฑ ฺฉุชุงุจโูุง ุทุงูฺู ุฏุฏู ูุดู. ุจุงุฑูุง ูู ฺฏูุชู ูู ฺฉ ุดุฏู ฺฉู ุจู ูพุดููุงุฏุงุช ฺฉุงุฑุจุฑุงู ุงููุช ุฏุงุฏู ุจุดู ฺฉู ุงู ุจุงุฑ ุฏูู ุจุงุดู.\n",
            "ุชุฑุฌูู  ุฏฺฏู ุง ูุฎููุฏู ูู ุจู ูุธุฑ ูู ุงู ุชุฑุฌูู ุจุณุงุฑ ุฎูุจ ุจูุฏ. ูุซุฑ ุงุฏุจ ุฑู ุฎูโูุง ูููพุณูุฏู ู ุงุญุชูุงูุง ุจู ููู ุนูุช ูฺฏู ุชุฑุฌูู ุจุฏ ุจูุฏู ู ุจู ูุธุฑุดูู ุจุงุฏ ุงุญุชุฑุงู ฺฏุฐุงุดุช ุงูุง ุงฺฏุฑ ุฎูุจ ูฺฉุฑ ฺฉูู ุฏุฑฺฉ ูฺฉูู ฺฉู ุจุงุฏ ู ูุฑู ุจู ูุญู ุงู ฺฉุชุงุจ ู ูุซูุง ูุฑ ูพุงุชุฑ ุจุงุดู. ุงูุตุงู ุฏุงุดุชู ุจุงุดู. ุงูุจุชู ุงุฑุงุฏุงุช ุชุงูพ ู ูฺฏุงุฑุด ุฒุงุฏ ุจูุฏ ู ุงู ูุดฺฉู ุจู ูููุฑ ุฏุฑ ฺฉุชุงุจโูุง ุทุงูฺู ุฏุฏู ูุดู. ุจุงุฑูุง ูู ฺฏูุชู ูู ฺฉ ุดุฏู ฺฉู ุจู ูพุดููุงุฏุงุช ฺฉุงุฑุจุฑุงู ุงููุช ุฏุงุฏู ุจุดู ฺฉู ุงู ุจุงุฑ ุฏูู ุจุงุดู.\n",
            "ุชุฑุฌูู ููู ุงูุนุงุฏู ุงูุชุถุงุญ ุจูุฏุุจุงุนุซ ุดุฏ ฺฉุชุงุจ ุฑู ุงุฒ ูุตูู ูู ฺฉูู\n",
            "ุชุฑุฌูู ููู ุงูุนุงุฏู ุงูุชุถุงุญ ุจูุฏุุจุงุนุซ ุดุฏ ฺฉุชุงุจ ุฑู ุงุฒ ูุตูู ูู ฺฉูู\n",
            "ูุณุงุฆู ุฑู ุฌูุงุจ ูุฏู ุงู ฺฉุชุงุจ ฺฉู ุงฺฏุฑ ุชุง ู ุฌุงูุง ุจุฑุง ุฎูุฏุชูู ุชู ุฒูุฏฺฏ ูุงูุนุชูู ุชุฌุฑุจู ูฺฉุฑุฏู ุจุงุดู ุง ุญุฏุงูู ุณูุงู ูุดุฏู ุจุงุดู ูุงุณุชูู ุฏุฑฺฉุด ููฺฉูู\n",
            "ูุณุงุฆู ุฑู ุฌูุงุจ ูุฏู ุงู ฺฉุชุงุจ ฺฉู ุงฺฏุฑ ุชุง ู ุฌุงูุง ุจุฑุง ุฎูุฏุชูู ุชู ุฒูุฏฺฏ ูุงูุนุชูู ุชุฌุฑุจู ูฺฉุฑุฏู ุจุงุดู ุง ุญุฏุงูู ุณูุงู ูุดุฏู ุจุงุดู ูุงุณุชูู ุฏุฑฺฉุด ููฺฉูู\n",
            "ุงุฒ ูุฒุฎุฑู ุชุฑู ฺฉุชุงุจ ูุง ุจูุฏ ฺฉู ุฎููุฏู\n",
            "ุญู ููุช\n",
            "ุงุฒ ูุฒุฎุฑู ุชุฑู ฺฉุชุงุจ ูุง ุจูุฏ ฺฉู ุฎููุฏู\n",
            "ุญู ููุช\n",
            "ฺูุฏ ุณุงู ูุจู ุงู ฺฉุชุงุจ ุฑู ุฎููุฏู ู ุจู ุดฺฉู ุนุฌุจ ูุณูุช ูุง ุฒุงุฏุด ุฑู ูููุฒ ุงุฏูู . ุญุณ ุงู ุฑู ุฏุงุฑู ฺฉู ุดุฎุตุช ฺฉุชุงุจ ุชุจุฏู ุดุฏู ุจู ูุณูุช ุงุฒ ุดุฎุตุช ุฎูุฏู\n",
            "ุฏุงุณุชุงู ููู ุงูุนุงุฏู ูุดูฺฏู ุจุง ูพุงุงู ุฎู ุฒุจุง โฆโบ๏ธโฉ\n",
            "ฺูุฏ ุณุงู ูุจู ุงู ฺฉุชุงุจ ุฑู ุฎููุฏู ู ุจู ุดฺฉู ุนุฌุจ ูุณูุช ูุง ุฒุงุฏุด ุฑู ูููุฒ ุงุฏูู . ุญุณ ุงู ุฑู ุฏุงุฑู ฺฉู ุดุฎุตุช ฺฉุชุงุจ ุชุจุฏู ุดุฏู ุจู ูุณูุช ุงุฒ ุดุฎุตุช ุฎูุฏู\n",
            "ุฏุงุณุชุงู ููู ุงูุนุงุฏู ูุดูฺฏู ุจุง ูพุงุงู ุฎู ุฒุจุง โฆโฉ\n",
            "ฺฉุชุงุจ ูุญุชูุง ุฑูุงูุดูุงุณ ุฏุงุฑู ู ุณุน ูฺฉูุฏ ุฏุฑ ุฎูุงู ุชุงุฑฺฉ ุชุฑู ุดุฑุงุท ฺฉ ุงูฺฏุฒู ุจุฑุง ุฒูุฏฺฏ ุงุฌุงุฏ ฺฉูุฏ.ุฏุฑ ุนู ุญุงู ุงุฒ ุงูุณุงููุง ุดุฑูุฑ ู ุฎูุฏุฎูุงู ุตุญุจุช ู ฺฉูุฏ ฺฉู ููฺูุงู ุงุฒ ุฏูุงูู ูุง ุณู ุงุณุชูุงุฏู ูฺฉููุฏ ู ุจู ุนููุงู ุงุจุฒุงุฑ ุขุฒูุงุดุดูู ุจุฑุง ุฑุณุฏู ุจู ูุชุงุฌ ุฑูุงูุดูุงุณ ุงุณุชูุงุฏู ู ฺฉููุฏ .\n",
            "ููุช ุงู ฺฉุชุงุจ ู ุฎููุฏู ุชููุณุชู ุงุฑุชุจุงุท ุจู ุงู ฺฉุชุงุจ ุฏุงุฑุงููุฌุงูู ุฌูุงูุฒุงุฏู ูพุฏุง ฺฉูู .\n",
            "ุงูุฏูุงุฑู ุงุฒ ุฎููุฏูุด ูุฐุช ุจุจุฑู .\n",
            "ฺฉุชุงุจ ูุญุชูุง ุฑูุงูุดูุงุณ ุฏุงุฑู ู ุณุน ูฺฉูุฏ ุฏุฑ ุฎูุงู ุชุงุฑฺฉ ุชุฑู ุดุฑุงุท ฺฉ ุงูฺฏุฒู ุจุฑุง ุฒูุฏฺฏ ุงุฌุงุฏ ฺฉูุฏ.ุฏุฑ ุนู ุญุงู ุงุฒ ุงูุณุงููุง ุดุฑูุฑ ู ุฎูุฏุฎูุงู ุตุญุจุช ู ฺฉูุฏ ฺฉู ููฺูุงู ุงุฒ ุฏูุงูู ูุง ุณู ุงุณุชูุงุฏู ูฺฉููุฏ ู ุจู ุนููุงู ุงุจุฒุงุฑ ุขุฒูุงุดุดูู ุจุฑุง ุฑุณุฏู ุจู ูุชุงุฌ ุฑูุงูุดูุงุณ ุงุณุชูุงุฏู ู ฺฉููุฏ .\n",
            "ููุช ุงู ฺฉุชุงุจ ู ุฎููุฏู ุชููุณุชู ุงุฑุชุจุงุท ุจู ุงู ฺฉุชุงุจ ุฏุงุฑุงููุฌุงูู ุฌูุงูุฒุงุฏู ูพุฏุง ฺฉูู .\n",
            "ุงูุฏูุงุฑู ุงุฒ ุฎููุฏูุด ูุฐุช ุจุจุฑู .\n",
            "ฺฉ ุงุฒ ุจูุชุฑู ฺฉุชุงุจ ูุง ฺฉู ุฎููุฏู ุ ุงูุจุชู ุจุง ุชุฑุฌูู  ุขูุง ุญุฌุงุฒ\n",
            "ฺฉ ุงุฒ ุจูุชุฑู ฺฉุชุงุจ ูุง ฺฉู ุฎููุฏู ุ ุงูุจุชู ุจุง ุชุฑุฌูู  ุขูุง ุญุฌุงุฒ\n",
            "ุงู ฺฉุชุงุจ ฺฉ ุงุฒ ุจูุชุฑู ู ุฒุจุง ุชุฑู ฺฉุชุงุจ ูุง ุจูุฏ ฺฉู ุฎููุฏู\n",
            "ุงู ฺฉุชุงุจ ฺฉ ุงุฒ ุจูุชุฑู ู ุฒุจุง ุชุฑู ฺฉุชุงุจ ูุง ุจูุฏ ฺฉู ุฎููุฏู\n",
            "ูู ุฏููู ฺุฑุง ุงุฒ ฺฉุชุงุจ ูุง ูพุงุฆููู ฺฉูุฆูู ุฒูุฏ ุฎุณุชู ูุดู ุจุง ุงูฺฉู ุฏูุณุช ุฏุงุฑู ฺฉุชุงุจ ูุง ูุนุฑููุด ุจุฎุฑู ูู ู ุชุฑุณู ูพุดููู ุจุดู\n",
            "ูู ุฏููู ฺุฑุง ุงุฒ ฺฉุชุงุจ ูุง ูพุงุฆููู ฺฉูุฆูู ุฒูุฏ ุฎุณุชู ูุดู ุจุง ุงูฺฉู ุฏูุณุช ุฏุงุฑู ฺฉุชุงุจ ูุง ูุนุฑููุด ุจุฎุฑู ูู ู ุชุฑุณู ูพุดููู ุจุดู\n",
            "ูู ฺูุฏ ุณุงู ูพุด ุฎููุฏูุด ุฎู ฺฉุดุด ุฏุงุดุช ุงุฏูู ุชุง ุณุญุฑ ุจุฏุงุฑ ุจูุฏู ู ุชููู ฺฉุฑุฏู ุขุฎุฑุดู ู ุญุณ ุฎู ุฎูุจ ุฏุงุดุชู ุงูฺฏุงุฑ ู ุงูฺฏุฒู ู ุงูุฏ ุญุณ ุฒูุฏฺฏ ุฏุงุฑู ุขุฎุฑุด\n",
            "ุงูู ุตุจุญ ููู ุงุฒ ููุฑ ุขูุชุงุจ ูุฐุช ุจุฑุฏู ุจู ูุฑ ุญุงู ุญุณ ุฎูุจ ุงุฒ ุงู ฺฉุชุงุจ ุงุฏู ูููุฏู .\n",
            "ูู ฺูุฏ ุณุงู ูพุด ุฎููุฏูุด ุฎู ฺฉุดุด ุฏุงุดุช ุงุฏูู ุชุง ุณุญุฑ ุจุฏุงุฑ ุจูุฏู ู ุชููู ฺฉุฑุฏู ุขุฎุฑุดู ู ุญุณ ุฎู ุฎูุจ ุฏุงุดุชู ุงูฺฏุงุฑ ู ุงูฺฏุฒู ู ุงูุฏ ุญุณ ุฒูุฏฺฏ ุฏุงุฑู ุขุฎุฑุด\n",
            "ุงูู ุตุจุญ ููู ุงุฒ ููุฑ ุขูุชุงุจ ูุฐุช ุจุฑุฏู ุจู ูุฑ ุญุงู ุญุณ ุฎูุจ ุงุฒ ุงู ฺฉุชุงุจ ุงุฏู ูููุฏู .\n",
            "ูู ุงู ฺฉุชุงุจู ุจุง ุชุฑุฌูู ุขุฑุด ุญุฌุงุฒ ุฎููุฏู ู ูุฐุช ุจุฑุฏู.. ููู ุงู ููุณูุฏู ุฑู ุฏูุณุช ุฏุงุฑู ูููุชุฑ ุงุฒ ูููุด ุฏุฏฺฏุงูุดู ฺฉู ูู ููพุณูุฏู..ุฎู ุงุฒ ูุง ุขุฏูุง ููฺฉูู ุชู ุฒูุฏฺฏ ุจู ู ูพูฺ ุจุฑุณู.ูุซู ุดุฎุตุช ุฏุงุณุชุงู.. ุงูุง ุงุชูุงูุงุช ุงุทุฑุงูุด ุจุงุนุซ ุดุฏ ุฏุฏฺฏุงูุด ุจู ุฒูุฏฺฏ ุนูุถ ุดู.. ุงฺฏู ุจุฎูุงู ุจู ุฏูุง ุฎูุฏููู ูุณุจุชุด ุจุฏู ุจู ุงู ูุชุฌู ูุฑุณู ฺฉู ุจุงุฏ ุจูุชุฑ ุงุทุฑุงูู ุจุจูู ู ูุถุงูุช ฺฉูู..\n",
            "ูู ุงู ฺฉุชุงุจู ุจุง ุชุฑุฌูู ุขุฑุด ุญุฌุงุฒ ุฎููุฏู ู ูุฐุช ุจุฑุฏู.. ููู ุงู ููุณูุฏู ุฑู ุฏูุณุช ุฏุงุฑู ูููุชุฑ ุงุฒ ูููุด ุฏุฏฺฏุงูุดู ฺฉู ูู ููพุณูุฏู..ุฎู ุงุฒ ูุง ุขุฏูุง ููฺฉูู ุชู ุฒูุฏฺฏ ุจู ู ูพูฺ ุจุฑุณู.ูุซู ุดุฎุตุช ุฏุงุณุชุงู.. ุงูุง ุงุชูุงูุงุช ุงุทุฑุงูุด ุจุงุนุซ ุดุฏ ุฏุฏฺฏุงูุด ุจู ุฒูุฏฺฏ ุนูุถ ุดู.. ุงฺฏู ุจุฎูุงู ุจู ุฏูุง ุฎูุฏููู ูุณุจุชุด ุจุฏู ุจู ุงู ูุชุฌู ูุฑุณู ฺฉู ุจุงุฏ ุจูุชุฑ ุงุทุฑุงูู ุจุจูู ู ูุถุงูุช ฺฉูู..\n",
            "ุฎู ูุฒุฎุฑู ุจูุฏ .\n",
            "ุฎู ูุฒุฎุฑู ุจูุฏ .\n",
            "ุฏุงุณุชุงู ุฌุงูุจ ุฏุงุฑู ฺฉูุง ฺฉุชุงุจุง ุขูุง ฺฉูุฆูู ุฑู ุฏูุณุช ุฏุงุฑู ุงูุจุชู ุจุง ุชุฑุฌูู ุขุฑุด ุญุฌุงุฒ๐๐ท\n",
            "ุฏุงุณุชุงู ุฌุงูุจ ุฏุงุฑู ฺฉูุง ฺฉุชุงุจุง ุขูุง ฺฉูุฆูู ุฑู ุฏูุณุช ุฏุงุฑู ุงูุจุชู ุจุง ุชุฑุฌูู ุขุฑุด ุญุฌุงุฒ\n",
            "ุจุง ุชุฑุฌูู ุขุฑุด ุญุฌุงุฒ ุฎูุงูุฏู ุจูุฏู. ูุถุง ุชูุงุฑุณุชุงู ู ุฑูุฌ ูุง ุฑูุญ ู... ูุถุง ุชูุฎ ุงุณุช. ฺฉุชุงุจ ูุง ุจูุชุฑ ุงุฒ ุงู ฺฉู ูุณุชูุฏ.\n",
            "ุจุง ุชุฑุฌูู ุขุฑุด ุญุฌุงุฒ ุฎูุงูุฏู ุจูุฏู. ูุถุง ุชูุงุฑุณุชุงู ู ุฑูุฌ ูุง ุฑูุญ ู... ูุถุง ุชูุฎ ุงุณุช. ฺฉุชุงุจ ูุง ุจูุชุฑ ุงุฒ ุงู ฺฉู ูุณุชูุฏ.\n",
            "ุชุงุฒู ุดุฑูุน ฺฉุฑุฏู ุจ ุฎููุฏูุด ูู ุฏุฑฺฉู ฺฉุชุงุจ ุฌุงูุจ ูุณุชุด ู ุจุณุงุฑ ุดุฑู ฺูู ุงุฒ ุฎููุฏูุด ุฎุณุชู ููุดู\n",
            "ฺฉูุง ุงูุทูุฑ ฺฉุชุงุจุง ูพุฑูุญุชูุง ุฑู ุฏูุณุช ุฏุงุฑู.ุจุฎุตูุต ฺฉ ุงฺฉุซุฑ ฺฉุชุงุจุง ุงูุง ูพุงุฆููู ุจ ูุธุฑู ูุซู ฺฉูุงฺฏุฑ\n",
            "ุงุฑุฒุด ุฎููุฏู ุฏุงุฑู๐\n",
            "ุชุงุฒู ุดุฑูุน ฺฉุฑุฏู ุจ ุฎููุฏูุด ูู ุฏุฑฺฉู ฺฉุชุงุจ ุฌุงูุจ ูุณุชุด ู ุจุณุงุฑ ุดุฑู ฺูู ุงุฒ ุฎููุฏูุด ุฎุณุชู ููุดู\n",
            "ฺฉูุง ุงูุทูุฑ ฺฉุชุงุจุง ูพุฑูุญุชูุง ุฑู ุฏูุณุช ุฏุงุฑู.ุจุฎุตูุต ฺฉ ุงฺฉุซุฑ ฺฉุชุงุจุง ุงูุง ูพุงุฆููู ุจ ูุธุฑู ูุซู ฺฉูุงฺฏุฑ\n",
            "ุงุฑุฒุด ุฎููุฏู ุฏุงุฑู\n",
            "ููุท ุชุฑุฌูู ุขุฑุด ุญุฌุงุฒ\n",
            "ููุท ุชุฑุฌูู ุขุฑุด ุญุฌุงุฒ\n",
            "ฺฉุชุงุจ ุฎูุจ ุจูุฏ ุณูุงูุงุช ุจูุงุฏ ุฎูุจ ู ูพุฑุณุฏ ู ูุฑุฏ ุฑู ุจู ฺุงูุด ู ฺฉุดููุฏ ููุท ููุฏุงุฑ ุฏุฑ ุจุฎุด ุฏูู ฺฉุชุงุจ ุฏุงุณุชุงู ูุง ุฑู ุฒุงุฏ ฺฉุด ูุฏุงุฏ ฺฉู ุจุงุนุซ ู ุดุฏ ูุฑุฏ ุฎูุงููุฏู ุฎุณุชู ุจุดู ู ุจู ูุธุฑ ูู ูุงุฒ ุจู ุงู ููุฏุงุฑ ุฒุงุฏู ฺฏู ุฏุฑ ุฑุงุจุทู ุจุง ููุถูุน ุฌุงูุจ ุฏุฑ ุฏุงุณุชุงู ูุณุช.\n",
            "ูู ุฏุฑ ฺฉู ฺฉุชุงุจ ุฎูุจ ุจูุฏ ุงุฑุฒุด ุฎููุฏู ุฑู ุฏุงุดุช.\n",
            "ู ู ุฐุฑู ูู ุชุฑุฌูู ุฌุง ฺฉุงุฑ ุฏุงุดุช ฺูู ุฑูุงู ุฑูุงู ูุจูุฏ.\n",
            "ฺฉุชุงุจ ุฎูุจ ุจูุฏ ุณูุงูุงุช ุจูุงุฏ ุฎูุจ ู ูพุฑุณุฏ ู ูุฑุฏ ุฑู ุจู ฺุงูุด ู ฺฉุดููุฏ ููุท ููุฏุงุฑ ุฏุฑ ุจุฎุด ุฏูู ฺฉุชุงุจ ุฏุงุณุชุงู ูุง ุฑู ุฒุงุฏ ฺฉุด ูุฏุงุฏ ฺฉู ุจุงุนุซ ู ุดุฏ ูุฑุฏ ุฎูุงููุฏู ุฎุณุชู ุจุดู ู ุจู ูุธุฑ ูู ูุงุฒ ุจู ุงู ููุฏุงุฑ ุฒุงุฏู ฺฏู ุฏุฑ ุฑุงุจุทู ุจุง ููุถูุน ุฌุงูุจ ุฏุฑ ุฏุงุณุชุงู ูุณุช.\n",
            "ูู ุฏุฑ ฺฉู ฺฉุชุงุจ ุฎูุจ ุจูุฏ ุงุฑุฒุด ุฎููุฏู ุฑู ุฏุงุดุช.\n",
            "ู ู ุฐุฑู ูู ุชุฑุฌูู ุฌุง ฺฉุงุฑ ุฏุงุดุช ฺูู ุฑูุงู ุฑูุงู ูุจูุฏ.\n",
            "ุฎุท ุฏุงุณุชุงู ฺฉุชุงุจ ฺฏู ู ฺฏูฺฏ ุจูุฏู ู ูพุงู ููุง ฺฉุชุงุจ ูุจููู.\n",
            "ุฏุฑุจุงุฑู ูุญุชูุง ุจุงุฏ ฺฏูุช ููุณูุฏู ุฏุฑุจุงุฑู ุนูู ุจูุงุฑูุง ุฑูุงู ุจู ูุธุฑู ุณุฑฺฉูุจ ุงูุงู ุฏุฑูู ูุนุชูุฏู. ูุตุฏุงู ุงู ุจุงูุฑ ุฑู ูุดู ุชู ุนุดู ูุฑููฺฉุง ุจู ุงุฏูุงุฑุฏ ู ุฎูุฏุงุฑุถุง ุฏูุงูู ูุงุฑ ุฏุฑ ุญุงูุช ุจุฑููู ุฏุฑ ููุงุจู ุงุฏูุงุฑุฏ ู ุชุงุซุฑ ูุซุจุช ุงู ุงูุฏุงู ุฏุฑ ุฑูุญู ูุฑููฺฉุง ุงุดุงุฑู ฺฉุฑุฏุ ุงูุฏุงู ฺฉู ุจููุน ููุทู ุนุทู ุชุญููุงุช ุฑูุญ ูุฑููฺฉุงุณุช. ุงูุฏุงู ฺฉู ูููุฏ ุชูุงู ุฎูุงูุด ูุง ูุฑูุฎูุฑุฏู ูุฑููฺฉุงุณุช. ุฏุฑ ุฏุงุณุชุงู ูุดุฎุต ูุณุช ุนูุช ุจูุจูุฏ ูุฑููฺฉุง ุงุดูุง ุจุง ููููู ูุฑฺฏ ู ุงุบุชูุงู ูุฑุตุช ฺฉูุชุงู ุฒูุฏฺฏุณ ุง ุชุงุซุฑ ุตุญุจุช ูุง ุฒุฏฺฉุง ู ูุงุฑุง ูุจู ุจุฑ ุฑูุง ฺฉุฑุฏู ุงุณุชุงูุฏุงุฑุฏูุง ุฑูุชู ุฒูุฏฺฏ ู ุฑู ุงูุฑุฏู ุจู ุงูุงู ุฏุฑูู ุณุฑฺฉูุจ ุดุฏู. ุฏุฑ ูุฌููุน ฺฉุชุงุจ ุญุฑู ูู ู ุจุฏุน ูุฏุงุดุช.\n",
            "ุฎุท ุฏุงุณุชุงู ฺฉุชุงุจ ฺฏู ู ฺฏูฺฏ ุจูุฏู ู ูพุงู ููุง ฺฉุชุงุจ ูุจููู.\n",
            "ุฏุฑุจุงุฑู ูุญุชูุง ุจุงุฏ ฺฏูุช ููุณูุฏู ุฏุฑุจุงุฑู ุนูู ุจูุงุฑูุง ุฑูุงู ุจู ูุธุฑู ุณุฑฺฉูุจ ุงูุงู ุฏุฑูู ูุนุชูุฏู. ูุตุฏุงู ุงู ุจุงูุฑ ุฑู ูุดู ุชู ุนุดู ูุฑููฺฉุง ุจู ุงุฏูุงุฑุฏ ู ุฎูุฏุงุฑุถุง ุฏูุงูู ูุงุฑ ุฏุฑ ุญุงูุช ุจุฑููู ุฏุฑ ููุงุจู ุงุฏูุงุฑุฏ ู ุชุงุซุฑ ูุซุจุช ุงู ุงูุฏุงู ุฏุฑ ุฑูุญู ูุฑููฺฉุง ุงุดุงุฑู ฺฉุฑุฏุ ุงูุฏุงู ฺฉู ุจููุน ููุทู ุนุทู ุชุญููุงุช ุฑูุญ ูุฑููฺฉุงุณุช. ุงูุฏุงู ฺฉู ูููุฏ ุชูุงู ุฎูุงูุด ูุง ูุฑูุฎูุฑุฏู ูุฑููฺฉุงุณุช. ุฏุฑ ุฏุงุณุชุงู ูุดุฎุต ูุณุช ุนูุช ุจูุจูุฏ ูุฑููฺฉุง ุงุดูุง ุจุง ููููู ูุฑฺฏ ู ุงุบุชูุงู ูุฑุตุช ฺฉูุชุงู ุฒูุฏฺฏุณ ุง ุชุงุซุฑ ุตุญุจุช ูุง ุฒุฏฺฉุง ู ูุงุฑุง ูุจู ุจุฑ ุฑูุง ฺฉุฑุฏู ุงุณุชุงูุฏุงุฑุฏูุง ุฑูุชู ุฒูุฏฺฏ ู ุฑู ุงูุฑุฏู ุจู ุงูุงู ุฏุฑูู ุณุฑฺฉูุจ ุดุฏู. ุฏุฑ ูุฌููุน ฺฉุชุงุจ ุญุฑู ูู ู ุจุฏุน ูุฏุงุดุช.\n",
            "ุฎู ุนุงู ุจูุฏ ูุงูุนุง ุขุฎุฑ ุฏุงุณุชุงู ุฎู ุบุงููฺฏุฑู ฺฉุฑุฏ ูุซู ฺฉูุง ฺฏุฑ ุฒุจุง ุจูุฏ๐๐\n",
            "ุฎู ุนุงู ุจูุฏ ูุงูุนุง ุขุฎุฑ ุฏุงุณุชุงู ุฎู ุบุงููฺฏุฑู ฺฉุฑุฏ ูุซู ฺฉูุง ฺฏุฑ ุฒุจุง ุจูุฏ\n",
            "ุฏุงุณุชุงู ุฏุฑููุฑุฏ ุฏุฎุชุฑ ุจู ูุงู ูุฑููฺฉุงุณุช ฺฉู ุงุญุณุงุณ ูฺฉูู ุฒูุฏฺฏุด ุฏฺุงุฑ ูพูฺ ู ุฑูุฒูุฑฺฏ ุดุฏู ู ุฏูู ุจุฑุง ุงุฏุงูู  ุฒูุฏฺฏ ูุฏุงุฑู. ุจู ููู ุฏูู ูู ุจุง ุฎูุฑุฏู ูุฑุต ุฎูุฏฺฉุด ูฺฉูู ุงูุง ูู ูุฑู. ุจู ฺฉ ุจูุงุฑุณุชุงู ุฑูุงู ููุชูู ูุดู ู ฺฏูุชู ูุดู ุจู ุนูุช ุฏุงุฑููุง ฺฉู ูุตุฑู ฺฉุฑุฏูุ ููุจุด ุถุนู ุดุฏู ู ุจู ุฒูุฏ ููุฑู. ุงูุง ุชู ุฑูุฒูุง ฺฉู ุฏุฑ ูพุด ุฏุงุฑูุ ุฏุฑ ุจูุงุฑุณุชุงู ุฑูุงูุ ุงูฺฏุฒู ูุง ู ุฏูุงู ุฌุฏุฏ ุจุฑุง ุงุฏุงูู  ุฒูุฏฺฏ ูพุฏุง ูฺฉูู..\n",
            "ุฑุงุณุชุด ฺฉุชุงุจ ูุณุจุชุง ุฎูุจ ุจูุฏ ุงูุง ูู ูพุงุงูุด ุฑู ููพุณูุฏุฏู.ูุชุงุณูุงูู ุงุฒ ุงูฺฉู ูุฑ ูุฏู ุฏุงุณุชุงู ุฑู ุจู ููุน ุจุง ูุณุฆูู  ุนุดู ุฏุฑฺฏุฑ ูฺฉููุ  ุงุตูุง ุฎูุดู ููุงุฏ.\n",
            "ุฏุงุณุชุงู ุฏุฑููุฑุฏ ุฏุฎุชุฑ ุจู ูุงู ูุฑููฺฉุงุณุช ฺฉู ุงุญุณุงุณ ูฺฉูู ุฒูุฏฺฏุด ุฏฺุงุฑ ูพูฺ ู ุฑูุฒูุฑฺฏ ุดุฏู ู ุฏูู ุจุฑุง ุงุฏุงูู  ุฒูุฏฺฏ ูุฏุงุฑู. ุจู ููู ุฏูู ูู ุจุง ุฎูุฑุฏู ูุฑุต ุฎูุฏฺฉุด ูฺฉูู ุงูุง ูู ูุฑู. ุจู ฺฉ ุจูุงุฑุณุชุงู ุฑูุงู ููุชูู ูุดู ู ฺฏูุชู ูุดู ุจู ุนูุช ุฏุงุฑููุง ฺฉู ูุตุฑู ฺฉุฑุฏูุ ููุจุด ุถุนู ุดุฏู ู ุจู ุฒูุฏ ููุฑู. ุงูุง ุชู ุฑูุฒูุง ฺฉู ุฏุฑ ูพุด ุฏุงุฑูุ ุฏุฑ ุจูุงุฑุณุชุงู ุฑูุงูุ ุงูฺฏุฒู ูุง ู ุฏูุงู ุฌุฏุฏ ุจุฑุง ุงุฏุงูู  ุฒูุฏฺฏ ูพุฏุง ูฺฉูู..\n",
            "ุฑุงุณุชุด ฺฉุชุงุจ ูุณุจุชุง ุฎูุจ ุจูุฏ ุงูุง ูู ูพุงุงูุด ุฑู ููพุณูุฏุฏู.ูุชุงุณูุงูู ุงุฒ ุงูฺฉู ูุฑ ูุฏู ุฏุงุณุชุงู ุฑู ุจู ููุน ุจุง ูุณุฆูู  ุนุดู ุฏุฑฺฏุฑ ูฺฉููุ  ุงุตูุง ุฎูุดู ููุงุฏ.\n",
            "ุณุงู ฺฏุฐุดุชู ุงู ฺฉุชุงุจ ุฑู ูุทุงูุนู ฺฉุฑุฏู . ูุงูุนุง ุจ ูุธุฑ ุจูุฏ . ูพุงุงู ุฏุงุณุชุงู ุขุฏู ุบุงููฺฏุฑ ูุดู .\n",
            "ุณุงู ฺฏุฐุดุชู ุงู ฺฉุชุงุจ ุฑู ูุทุงูุนู ฺฉุฑุฏู . ูุงูุนุง ุจ ูุธุฑ ุจูุฏ . ูพุงุงู ุฏุงุณุชุงู ุขุฏู ุบุงููฺฏุฑ ูุดู .\n",
            "ุจุนุถ ููุณูุฏู ูุง ุจุนุฏ ุงุฒ ุงูฺฉู ุงุณู ุฏุฑ ฺฉุฑุฏู ุดุฑูุน ุจู ููุดุชู ุงุฑุงุฌู ูฺฉูู...\n",
            "ุจุนุถ ููุณูุฏู ูุง ุจุนุฏ ุงุฒ ุงูฺฉู ุงุณู ุฏุฑ ฺฉุฑุฏู ุดุฑูุน ุจู ููุดุชู ุงุฑุงุฌู ูฺฉูู...\n",
            "ุงู ฺฉุชุงุจ ุนุงูู ูู ููู ููุดู ุชุฑุฌุญ ูุฏู ฺฉุชุงุจูุง ูพุงุฆููู ุฑู ุจุง ุชุฑุฌูู ุขุฑุด ุญุฌุงุฒ ุจุฎููู...\n",
            "ุงู ฺฉุชุงุจ ุนุงูู ูู ููู ููุดู ุชุฑุฌุญ ูุฏู ฺฉุชุงุจูุง ูพุงุฆููู ุฑู ุจุง ุชุฑุฌูู ุขุฑุด ุญุฌุงุฒ ุจุฎููู...\n",
            "ุงู ฺฉุชุงุจ ุฎู ุนุงูู. ููู ุงูุนุงุฏู ูุญุดุฑ . ฺฉูุง ุขุซุงุฑ ูพุงุฆูู ฺฉูุฆูู ุจ ูุธุฑู. ูุงูุนุง ุดุฎุต ุฑูุดู ูฺฉุฑ ู ุขุดูุง ุจุง ุงุฏุจุงุช ูุณุชูุฏ. ุฑูุงุช ู ุฏุฎุชุฑ ุงูุณุฑุฏู ู ุณุฑ ุดุฏู ุงุฒ ุฒูุฏฺฏ ฺฉู ุชู ุชูุงุฑุณุชุงู ุท ุงุชูุงูุงุช ุจุงุนุซ ูุดู ุฏูุจุงุฑู ุจู ุฒูุฏฺฏ ุจุฑฺฏุฑุฏู. ุงูุจุชู ูู ุจุง ุชุฑุฌูู ุขูุง ุขุฑุด ุญุฌุงุฒ ุฎููุฏู.ุจูุชูู ูพุดููุงุฏ ูฺฉูู ุงุฒ ุฏุณุชุด ูุฏุฏ.\n",
            "ุงู ฺฉุชุงุจ ุฎู ุนุงูู. ููู ุงูุนุงุฏู ูุญุดุฑ . ฺฉูุง ุขุซุงุฑ ูพุงุฆูู ฺฉูุฆูู ุจ ูุธุฑู. ูุงูุนุง ุดุฎุต ุฑูุดู ูฺฉุฑ ู ุขุดูุง ุจุง ุงุฏุจุงุช ูุณุชูุฏ. ุฑูุงุช ู ุฏุฎุชุฑ ุงูุณุฑุฏู ู ุณุฑ ุดุฏู ุงุฒ ุฒูุฏฺฏ ฺฉู ุชู ุชูุงุฑุณุชุงู ุท ุงุชูุงูุงุช ุจุงุนุซ ูุดู ุฏูุจุงุฑู ุจู ุฒูุฏฺฏ ุจุฑฺฏุฑุฏู. ุงูุจุชู ูู ุจุง ุชุฑุฌูู ุขูุง ุขุฑุด ุญุฌุงุฒ ุฎููุฏู.ุจูุชูู ูพุดููุงุฏ ูฺฉูู ุงุฒ ุฏุณุชุด ูุฏุฏ.\n",
            "ฺฉ ุงุฒ ุจูุชุฑู ฺฉุชุงุจูุง ฺฉู ุฎููุฏู ู ุฎู ุชุญุช ุชุงุซุฑ ูุฑุงุฑ ฺฏุฑูุชู. ุชูุตูุงุช ุฏุงุณุชุงู ุจุณุงุฑ ุนุงู ู ฺฏุณุชุฑุฏู ูุณุช\n",
            "ฺฉ ุงุฒ ุจูุชุฑู ฺฉุชุงุจูุง ฺฉู ุฎููุฏู ู ุฎู ุชุญุช ุชุงุซุฑ ูุฑุงุฑ ฺฏุฑูุชู. ุชูุตูุงุช ุฏุงุณุชุงู ุจุณุงุฑ ุนุงู ู ฺฏุณุชุฑุฏู ูุณุช\n",
            "ุฌูุงุจ ูพุณุฑุฎุงูุฏู ุณูุงู ุนูฺฉู\n",
            "ูู ุงุตูุง ูุธุฑ ููุจูู ุงุฒ ุฎูุฏู ุฑู ุงู ฺฉุชุงุจ! ุงูุง ฺฉุชุงุจ ุฎูุจ ุงุณุช ู ุจ ุฎุงูุฏูุด ูุงุฑุฒุฏ ู ูุฒ ุจุงุฏ ุจฺฏู ฺฉ ุจุฑูุฏู ุชููุงุณุช ูู ฺฉุชุงุจ ุงุฑุฒูุฏู ุง ุงุณุช.\n",
            "ุฌูุงุจ ูพุณุฑุฎุงูุฏู ุณูุงู ุนูฺฉู\n",
            "ูู ุงุตูุง ูุธุฑ ููุจูู ุงุฒ ุฎูุฏู ุฑู ุงู ฺฉุชุงุจ! ุงูุง ฺฉุชุงุจ ุฎูุจ ุงุณุช ู ุจ ุฎุงูุฏูุด ูุงุฑุฒุฏ ู ูุฒ ุจุงุฏ ุจฺฏู ฺฉ ุจุฑูุฏู ุชููุงุณุช ูู ฺฉุชุงุจ ุงุฑุฒูุฏู ุง ุงุณุช.\n",
            "ุนุงู ูุณุช ุงู ฺฉุชุงุจ. ูพุฑ ุงุฒ ูุณุงู ุฑุฒ ฺฉู  ุฎู ุฒุจุง ุชูุตู ุดุฏู ุงูุฏ\n",
            "ุนุงู ูุณุช ุงู ฺฉุชุงุจ. ูพุฑ ุงุฒ ูุณุงู ุฑุฒ ฺฉู  ุฎู ุฒุจุง ุชูุตู ุดุฏู ุงูุฏ\n",
            "fogholadas\n",
            "fogholadas\n",
            "ุฎุฏุงูฺฉู ุตูุฑ ุณุชุงุฑู ูุญุฏ ุ ุงูุตุงูู ุ\n",
            "ุฎุฏุงูฺฉู ุตูุฑ ุณุชุงุฑู ูุญุฏ ุ ุงูุตุงูู ุ\n",
            "ููููู ูุณุชู ุงุฒ ุงูู ุฏูุ ุฎุฏุง ุฎุฑุช ุจุฏู\n",
            "ููููู ูุณุชู ุงุฒ ุงูู ุฏูุ ุฎุฏุง ุฎุฑุช ุจุฏู\n",
            "ุงุฌุงุฒู ุจุฏุฏ ูู ุฌุง ุจุฑุงุฏุฑ ูุญุฏ ุฌูุงุจ ุจุฏูุ ุจุฑูุฏู ุชููุงุณุช ุฎูุจ ูุจุงุดุฏ ุฏุฑ ุญุฏ 4ุณุชุงุฑู :-)\n",
            "ุงุฌุงุฒู ุจุฏุฏ ูู ุฌุง ุจุฑุงุฏุฑ ูุญุฏ ุฌูุงุจ ุจุฏูุ ุจุฑูุฏู ุชููุงุณุช ุฎูุจ ูุจุงุดุฏ ุฏุฑ ุญุฏ 4ุณุชุงุฑู :-)\n",
            "ุขูุง ูุญุฏ\n",
            "ุณูุงู ุนูฺฉู\n",
            "ุนู ุดูุง ููู ฺฉุชุจ ุจุงุฆููู ฺฉูุฆูู ุฎูุงูุฏู ุงุฏุุงุญุณูุช\n",
            "ูุธุฑุชุงู ุฏุฑุจุงุฑู ุจุฑูุฏู ุชููุงุณุช ฺุณุชุ\n",
            "ุขูุง ูุญุฏ\n",
            "ุณูุงู ุนูฺฉู\n",
            "ุนู ุดูุง ููู ฺฉุชุจ ุจุงุฆููู ฺฉูุฆูู ุฎูุงูุฏู ุงุฏุุงุญุณูุช\n",
            "ูุธุฑุชุงู ุฏุฑุจุงุฑู ุจุฑูุฏู ุชููุงุณุช ฺุณุชุ\n",
            "ูุงูุนุง ุนุงูู ฺฉุชุงุจุด\n",
            "ูุงูุนุง ุนุงูู ฺฉุชุงุจุด\n",
            "ุจ ูุธุฑู ฺฉูุกูู ุจุนุฏ ุงุฒ ฺฉูุงฺฏุฑ ฺฉุชุงุจ ูุงุด ูุชูุณุท ุงูุฏ ุชุง ุจุฑูุฏู ุชููุง ุณุชุ\n",
            "ุจ ูุธุฑู ฺฉูุกูู ุจุนุฏ ุงุฒ ฺฉูุงฺฏุฑ ฺฉุชุงุจ ูุงุด ูุชูุณุท ุงูุฏ ุชุง ุจุฑูุฏู ุชููุง ุณุชุ\n",
            "ุจุง ุงุญุชุฑุงู \n",
            "ฺฉุชุงุจ ุจุณุงุฑ ุฎูุจ  ุฏุฑ ุฏุฑ ูุจุงุญุซ ุฑูุงุจุท ุงุฌุชูุงุน  ู  ุฑูุด ุดูุงุณ ูุง ูุฑุฏู ูฺฏุงุฑุงูู  ุง ุงุชูู ูุชุฏููฺ ุงุณุช.\n",
            "ุจุง ุงุญุชุฑุงู \n",
            "ฺฉุชุงุจ ุจุณุงุฑ ุฎูุจ  ุฏุฑ ุฏุฑ ูุจุงุญุซ ุฑูุงุจุท ุงุฌุชูุงุน  ู  ุฑูุด ุดูุงุณ ูุง ูุฑุฏู ูฺฏุงุฑุงูู  ุง ุงุชูู ูุชุฏููฺ ุงุณุช.\n",
            "ฺู ูุฏุฑ ฺฏุฑุงูู\n",
            "ุชุงุฒู ฺฉุงุบุฐ ูู ูุตุฑู ูุดุฏู ฺฉู ูพูู ุงููู ุจุฏูุ ูุงูุนุง ุจุนุถ ููุชูุง ุฑู ูพุงู ุชุฑ ฺฉูุฏ\n",
            "ฺู ูุฏุฑ ฺฏุฑุงูู\n",
            "ุชุงุฒู ฺฉุงุบุฐ ูู ูุตุฑู ูุดุฏู ฺฉู ูพูู ุงููู ุจุฏูุ ูุงูุนุง ุจุนุถ ููุชูุง ุฑู ูพุงู ุชุฑ ฺฉูุฏ\n",
            "ุจุณุงุฑ ุนุงู. ุดุฎุตุชูุง ุฎู ุฎูุจ ุทุนูู ุจู ูุฏููุง ูุงูุนุดูู ูุฒูู. ุฏุงุณุชุงู ุจุงู ูฺฉูู ฺฉู ฺุทูุฑ ู ุงุฏู ุตุงุฏูุงูู ูุชููู ุฏฺุงุฑ ฺุงูุดุง ุฌุฏ ู ุณู ุงุณุชูุงุฏู ูุง ุจุฏ ุจุดู\n",
            "ุจุณุงุฑ ุนุงู. ุดุฎุตุชูุง ุฎู ุฎูุจ ุทุนูู ุจู ูุฏููุง ูุงูุนุดูู ูุฒูู. ุฏุงุณุชุงู ุจุงู ูฺฉูู ฺฉู ฺุทูุฑ ู ุงุฏู ุตุงุฏูุงูู ูุชููู ุฏฺุงุฑ ฺุงูุดุง ุฌุฏ ู ุณู ุงุณุชูุงุฏู ูุง ุจุฏ ุจุดู\n",
            "ุจุณุงุฑ ุฎูุดุญุงู ฺฉููุฏู ุงุณุช ฺฉู ุญู ูุงุดุฑ ูุญููุธ ุงุณุช. ุงูุง ฺฉุงุด ฺฉู ููุช ูุง ุจู ุฏูู ฺุงูพ ูุฌุงุฒ ุดุงู ุชุนุฏู ุดูุฏ. ุฏุฑ ุงูฺฏูุณ ูุซูุง ฺฉุชุงุจ 120 ูพููุฏ ุฏุฑ ฺุงูพ ุฏุฌุชุงู ููุงุชุง 20 ุฏูุงุฑ ููุช ูุฎูุฑุฏ ุนู ฺฉ ุดุดู. ุจู ูุธุฑู ุจุง ุงู ุฑูู ูุง ุตุฑูู ุจุง ุฎุฑุฏ ุฎูุฏ ฺฉุชุงุจูุงุณุช ฺูู ุฎูุงูุด ุฑุง ุฑุงุญุช ุชุฑ ูฺฉูุฏ.\n",
            "ุงูุจุชู ุงู ุทุฑุญ ุชุฎูู ููุชู ฺุฒ ุฎูุจ ุงุณุช\n",
            "ุจุณุงุฑ ุฎูุดุญุงู ฺฉููุฏู ุงุณุช ฺฉู ุญู ูุงุดุฑ ูุญููุธ ุงุณุช. ุงูุง ฺฉุงุด ฺฉู ููุช ูุง ุจู ุฏูู ฺุงูพ ูุฌุงุฒ ุดุงู ุชุนุฏู ุดูุฏ. ุฏุฑ ุงูฺฏูุณ ูุซูุง ฺฉุชุงุจ 120 ูพููุฏ ุฏุฑ ฺุงูพ ุฏุฌุชุงู ููุงุชุง 20 ุฏูุงุฑ ููุช ูุฎูุฑุฏ ุนู ฺฉ ุดุดู. ุจู ูุธุฑู ุจุง ุงู ุฑูู ูุง ุตุฑูู ุจุง ุฎุฑุฏ ุฎูุฏ ฺฉุชุงุจูุงุณุช ฺูู ุฎูุงูุด ุฑุง ุฑุงุญุช ุชุฑ ูฺฉูุฏ.\n",
            "ุงูุจุชู ุงู ุทุฑุญ ุชุฎูู ููุชู ฺุฒ ุฎูุจ ุงุณุช\n",
            "ุฑููู ฺฏุงุฑ ุชููุง ููุณูุฏู  ูุฑุงูุณู ุงู ฺฉู ุฏูุจุงุฑ ุฌุงุฒู ฺฏูฺฉูุฑ ุฑู ุจุฑุฏู\n",
            "ูุซู ููุดู ุนุงู\n",
            "ุฑููู ฺฏุงุฑ ุชููุง ููุณูุฏู  ูุฑุงูุณู ุงู ฺฉู ุฏูุจุงุฑ ุฌุงุฒู ฺฏูฺฉูุฑ ุฑู ุจุฑุฏู\n",
            "ูุซู ููุดู ุนุงู\n",
            "ูุงูุนุง ุฎู ุฎูุจู ููููู ุทุงูฺู ุขุฏู ูููุน ุฎููุฏู ุบุฑู ุฏุงุณุชุงู ฺฉุชุงุจ ูุดู ูุงูุนุง ูุดูฺฏู\n",
            "ูุงูุนุง ุฎู ุฎูุจู ููููู ุทุงูฺู ุขุฏู ูููุน ุฎููุฏู ุบุฑู ุฏุงุณุชุงู ฺฉุชุงุจ ูุดู ูุงูุนุง ูุดูฺฏู\n",
            "ูุงูุนุง ุฎูุจู ฺฉุชุงุจ ุฎู ุนุงูู ููููู ุทุงูฺู.\n",
            "ูุงูุนุง ุฎูุจู ฺฉุชุงุจ ุฎู ุนุงูู ููููู ุทุงูฺู.\n",
            "ุฌุงุฒู ฺฉูฺฏูุฑ ุจู ุจูุชุฑู ฺฉุชุงุจ ุฏุงุณุชุงู ููุชุดุฑ ุดุฏู ุฏุฑ ุณุงู ุฏุงุฏู ูุดูุ ูุงูุนุงู ุฎูุดุญุงู ฺฉููุฏู ุงุณุช ฺฉู ุงู ฺฉุชุงุจ ุจู ูุงุฑุณ ุชุฑุฌูู ุดุฏู  ู ูุดุฑ ุซุงูุซ ุงูู ุฑู ููุชุดุฑ ฺฉุฑุฏู.\n",
            "ุจุง ุฎููุฏูุด ูุงูุนุงู ูพ ุจุฑุฏู ูุดู ฺฉู ุงู ฺฉุชุงุจ ุจู ุทูุฑ ุดุงุณุชู ุง ุงูุชุฎุงุจ ุดุฏูุ ูู ูููุน ุฎููุฏู ฺฉุชุงุจ ุฏููุงู ุบุฑู ุฏุฑ ูุถุง ุณุงุฎุชู ุดุฏู ุฏุฑ ฺฉุชุงุจ ู ุดุฏู\n",
            "ุฌุงุฒู ฺฉูฺฏูุฑ ุจู ุจูุชุฑู ฺฉุชุงุจ ุฏุงุณุชุงู ููุชุดุฑ ุดุฏู ุฏุฑ ุณุงู ุฏุงุฏู ูุดูุ ูุงูุนุงู ุฎูุดุญุงู ฺฉููุฏู ุงุณุช ฺฉู ุงู ฺฉุชุงุจ ุจู ูุงุฑุณ ุชุฑุฌูู ุดุฏู  ู ูุดุฑ ุซุงูุซ ุงูู ุฑู ููุชุดุฑ ฺฉุฑุฏู.\n",
            "ุจุง ุฎููุฏูุด ูุงูุนุงู ูพ ุจุฑุฏู ูุดู ฺฉู ุงู ฺฉุชุงุจ ุจู ุทูุฑ ุดุงุณุชู ุง ุงูุชุฎุงุจ ุดุฏูุ ูู ูููุน ุฎููุฏู ฺฉุชุงุจ ุฏููุงู ุบุฑู ุฏุฑ ูุถุง ุณุงุฎุชู ุดุฏู ุฏุฑ ฺฉุชุงุจ ู ุดุฏู\n",
            "ุงู ุทุฑุญ ุชุฎูู ฺฉุชุงุจ ููุชู ุนุงูู\n",
            "ูุทูุง ุงุฏุงูู ุจุฏุฏุด\n",
            "ุงู ุทุฑุญ ุชุฎูู ฺฉุชุงุจ ููุชู ุนุงูู\n",
            "ูุทูุง ุงุฏุงูู ุจุฏุฏุด\n",
            "ุทุงูฺู ุฌุงู, ฺฉุชุงุจ ูุง ุฌุฏุฏุช ุนุงูู, ฺฉุชุงุจ ุจุดุชุฑ ุจฺฏุฐุงุฑ, ุฏุฑ ุถูู ุฑููู ฺฏุงุฑ ุฑู ุนุดู ุงุณุช ูุจุณ!\n",
            "ุทุงูฺู ุฌุงู, ฺฉุชุงุจ ูุง ุฌุฏุฏุช ุนุงูู, ฺฉุชุงุจ ุจุดุชุฑ ุจฺฏุฐุงุฑ, ุฏุฑ ุถูู ุฑููู ฺฏุงุฑ ุฑู ุนุดู ุงุณุช ูุจุณ!\n",
            "ูุงูุนุง ฺฉุชุงุจ ุฌุงูุจู. ููุฏูู ุงุด ุฑู ฺฉู ุฎููุฏู ุชุดูู ุดุฏู  ุดุนุฑูุงุด ุฑู ุจุฎููู. ู ุดุนุฑ ุงููุด ยซุฑุจ ุงุนููยป ูุงูุนุง ุฌุงูุจ ุจูุฏ. ู ุจูู ุดุนุฑูุงุด ูู ุฎู ุณูุณ ฺฏูุชู ุดุฏูุฏ. ูพุดููุงุฏ ู ฺฉูู ุญุชูุง ุจุฎููุฏ\n",
            "ูุงูุนุง ฺฉุชุงุจ ุฌุงูุจู. ููุฏูู ุงุด ุฑู ฺฉู ุฎููุฏู ุชุดูู ุดุฏู  ุดุนุฑูุงุด ุฑู ุจุฎููู. ู ุดุนุฑ ุงููุด ยซุฑุจ ุงุนููยป ูุงูุนุง ุฌุงูุจ ุจูุฏ. ู ุจูู ุดุนุฑูุงุด ูู ุฎู ุณูุณ ฺฏูุชู ุดุฏูุฏ. ูพุดููุงุฏ ู ฺฉูู ุญุชูุง ุจุฎููุฏ\n",
            "ุชูุตู ูฺฉูู ุจุฎููุฏุด\n",
            "ุชูุตู ูฺฉูู ุจุฎููุฏุด\n",
            "ฺฉุชุงุจ ุฎู ุฎูุจู.ุชูุตู ูฺฉูู ุจุฎููุฏ.ุงูุจุชู  ุจุง ุชุฑุฌูู ุขุฑุด ุญุฌุงุฒ ุจุง ุนููุงู ุฒุฑู ุขูุฑ ููุฑ ุฎู ุจูุชุฑู...๐\n",
            "ฺฉุชุงุจ ุฎู ุฎูุจู.ุชูุตู ูฺฉูู ุจุฎููุฏ.ุงูุจุชู  ุจุง ุชุฑุฌูู ุขุฑุด ุญุฌุงุฒ ุจุง ุนููุงู ุฒุฑู ุขูุฑ ููุฑ ุฎู ุจูุชุฑู...\n",
            "ุดุฑููุฑ\n",
            "ุดุฑููุฑ\n",
            "ูุฑูุฑ ฺฏุฐุฑุง ู ฺฏุงู ูุงุฏุฑุณุช ุจุฑ ุงูุฏุดูโูุง ููุณู ฺฉู ุจุงุนุซ ุงุฌุงุฏ ุณูุก ุจุฑุฏุงุดุช ุฏุฑ ุฎูุงููุฏู ูุงุขฺฏุงู ูโุดูุฏ.\n",
            "ูุฑูุฑ ฺฏุฐุฑุง ู ฺฏุงู ูุงุฏุฑุณุช ุจุฑ ุงูุฏุดูโูุง ููุณู ฺฉู ุจุงุนุซ ุงุฌุงุฏ ุณูุก ุจุฑุฏุงุดุช ุฏุฑ ุฎูุงููุฏู ูุงุขฺฏุงู ูโุดูุฏ.\n",
            "ุงุทูุงุนุงุช ุฎู ฺฉู ู ุจุนุถุง ูุงุฏุฑุณุช\n",
            "ุงุทูุงุนุงุช ุฎู ฺฉู ู ุจุนุถุง ูุงุฏุฑุณุช\n",
            "ฺฉ ุงุฒ ุจูุชุฑู ุถููู ูุง  ุฑูุฒูุงูู ูุง  ฺฉุดูุฑ ฺฉู ูุฑ ฺฉุดูุจู ููุชุดุฑ ูโุดูุฏ.\n",
            "ฺฉ ุงุฒ ุจูุชุฑู ุถููู ูุง  ุฑูุฒูุงูู ูุง  ฺฉุดูุฑ ฺฉู ูุฑ ฺฉุดูุจู ููุชุดุฑ ูโุดูุฏ.\n",
            "ูฺฉุฑ ูฺฉุฑุฏู ฺฉุชุงุจ ุฑุงูููุง ฺฏุงู ุจู ฺฏุงู ุจุฑุง ุฑุณุฏู ุจู ฺฉ ุฒู ูููู ุจุงุดู ูู ุตุฑูุง ฺุฒ ูุจูุฏ ุฌุฒ ุฌููุงุช ุงููุงู ุจุฎุด ู ุงูุฑฺ ุฏููุฏูุ ุงูุจุชู ุชูุตุฑ ุฎูุฏูู ฺฉู ุจุฏูู ุฎููุฏู ููููู ฺฉุชุงุจ ุฏุงูููุฏุด ฺฉุฑุฏู\n",
            "ูู ุจุงุฒ ุจู ูุฑุญุงู ุฎู ุงู ุจุฏ ูุจูุฏ\n",
            "ูฺฉุฑ ูฺฉุฑุฏู ฺฉุชุงุจ ุฑุงูููุง ฺฏุงู ุจู ฺฏุงู ุจุฑุง ุฑุณุฏู ุจู ฺฉ ุฒู ูููู ุจุงุดู ูู ุตุฑูุง ฺุฒ ูุจูุฏ ุฌุฒ ุฌููุงุช ุงููุงู ุจุฎุด ู ุงูุฑฺ ุฏููุฏูุ ุงูุจุชู ุชูุตุฑ ุฎูุฏูู ฺฉู ุจุฏูู ุฎููุฏู ููููู ฺฉุชุงุจ ุฏุงูููุฏุด ฺฉุฑุฏู\n",
            "ูู ุจุงุฒ ุจู ูุฑุญุงู ุฎู ุงู ุจุฏ ูุจูุฏ\n",
            "โฅุฒูุงู ุจุฑุฌุณุชู ฺู ฺฉุณ ุขู ูุง ุฑุง ุชูุงุดุง ฺฉูุฏ ู ฺู ูฺฉูุฏุ ุฎูุฏุดุงู ุฑุง ูุทูุฆู ู ุจุฑุฌุณุชู ุฏุฑ ูุธุฑ ูฺฏุฑูุฏ.\n",
            "โฅุชุนูุฏ ุจุฏูุฏ ฺฉู ุนุงู ู ุจ ูุธุฑ ุจุงุดุฏ.\n",
            "โฅุจุง ุฎูุฏุชุงู ุจู ุนููุงู ูุฑุฏ ฺฉู ูููุงุฑู ุฏุฑ ุงูููุช ูุฑุงุฑ ุฏุงุฑุฏ ุฑูุชุงุฑ ฺฉูุฏ.\n",
            "โฅุจู ฺฏููู ุง ุญุฑูู ุง ูุจุงุณ ุจูพูุดุฏุ ุชุตูุฑ ุงุฒ ูุฏุฑุช ู ุดุงุณุชฺฏ ุงุฌุงุฏ ฺฉูุฏ.\n",
            "โฅุฎูุฏุชุงู ุฑุง ุชุง ุณุทุญ ุฎูุจ ุจูุฏู ูุญุฏูุฏ ูฺฉูุฏ. ูุนุงุฑ ูุงุชุงู ุฑุง ุชุง ุญุฏ ุนุงู ุจูุฏู ุจุงูุง ุจุจุฑุฏ ู ุฏุฑ ุงู ูุณุฑ ูฺ ูุตุงูุญู ุง ูฺฉูุฏ.\n",
            "โฅุขูุฏู ูุชุนูู ุจู ุงูุฑุงุฏ ุดุงุณุชู ุงุณุช.\n",
            "โฅูุฑููู ููููุช: ฺฉู ุฒูุฏุชุฑ ฺฉุงุฑ ุฑุง ุดุฑูุน ฺฉูุฏุ ฺฉู ุณุฎุช ุชุฑ ฺฉุงุฑ ฺฉูุฏุ ฺฉู ุจุดุชุฑ ุฏุฑ ูุญู ฺฉุงุฑ ุจูุงูุฏ.\n",
            "---> ุจุงุฏ ุงูุง ุฑู ุจุง ุทูุง ุจููุณู ุจุฐุงุฑู ุฌูู ฺุดู ุฎูุฏู.\n",
            "ุฒูุงู ุจุฑุฌุณุชู ฺู ฺฉุณ ุขู ูุง ุฑุง ุชูุงุดุง ฺฉูุฏ ู ฺู ูฺฉูุฏุ ุฎูุฏุดุงู ุฑุง ูุทูุฆู ู ุจุฑุฌุณุชู ุฏุฑ ูุธุฑ ูฺฏุฑูุฏ.\n",
            "ุชุนูุฏ ุจุฏูุฏ ฺฉู ุนุงู ู ุจ ูุธุฑ ุจุงุดุฏ.\n",
            "ุจุง ุฎูุฏุชุงู ุจู ุนููุงู ูุฑุฏ ฺฉู ูููุงุฑู ุฏุฑ ุงูููุช ูุฑุงุฑ ุฏุงุฑุฏ ุฑูุชุงุฑ ฺฉูุฏ.\n",
            "ุจู ฺฏููู ุง ุญุฑูู ุง ูุจุงุณ ุจูพูุดุฏุ ุชุตูุฑ ุงุฒ ูุฏุฑุช ู ุดุงุณุชฺฏ ุงุฌุงุฏ ฺฉูุฏ.\n",
            "ุฎูุฏุชุงู ุฑุง ุชุง ุณุทุญ ุฎูุจ ุจูุฏู ูุญุฏูุฏ ูฺฉูุฏ. ูุนุงุฑ ูุงุชุงู ุฑุง ุชุง ุญุฏ ุนุงู ุจูุฏู ุจุงูุง ุจุจุฑุฏ ู ุฏุฑ ุงู ูุณุฑ ูฺ ูุตุงูุญู ุง ูฺฉูุฏ.\n",
            "ุขูุฏู ูุชุนูู ุจู ุงูุฑุงุฏ ุดุงุณุชู ุงุณุช.\n",
            "ูุฑููู ููููุช: ฺฉู ุฒูุฏุชุฑ ฺฉุงุฑ ุฑุง ุดุฑูุน ฺฉูุฏุ ฺฉู ุณุฎุช ุชุฑ ฺฉุงุฑ ฺฉูุฏุ ฺฉู ุจุดุชุฑ ุฏุฑ ูุญู ฺฉุงุฑ ุจูุงูุฏ.\n",
            "---> ุจุงุฏ ุงูุง ุฑู ุจุง ุทูุง ุจููุณู ุจุฐุงุฑู ุฌูู ฺุดู ุฎูุฏู.\n",
            "ุฏุฑ ุชุนุฏุงุฏ ุงูฺฏุดุช ุดูุงุฑ ุงุฒ ุฌููุงุช ุงู ฺฉุชุงุจ  ุจู ุฒู ุงุดุงุฑู ุดุฏู ุจูุฏ ฺฉู ุงูู ูู ุงููุฏุฑ ฺฉู ุจูุฏ ฺฉู ูู ุดู ฺฏูุช ุชููุง ุฏุฑ ููุฑุฏ ุฒู ูุง ุตุฏู ู ฺฉูู. ุงฺฏุฑ ุจู ูู ุจฺฏู ุจุฑุงุงู ุชุฑุณ ฺฉุชุงุจ ุจู ูุงู \"ุฒู ูููู\" ูุฏุงุฑู ู ุงู ุฌููุงุช ูุฌููุนู ุง ุงุฒ ุฌููู ูุง ฺฏูุชู ุดุฏู ุฏุฑ ฺฉุชุงุจ ูุง ุฏฺฏุฑ ุงุดููู ฺฉู ุชูุณุท ุงู ุฏู ููุฑ (ุงุณุงู ูุชุฑุฌู ูุง) ุฌูุน ุขูุฑ ุดุฏูุ ุญุชูุง ุจุงูุฑ ู ฺฉูู. ุจู ูุธุฑ ูู ฺฉุชุงุจ ุฎูุจ ูุจูุฏ.\n",
            "ุฏุฑ ุชุนุฏุงุฏ ุงูฺฏุดุช ุดูุงุฑ ุงุฒ ุฌููุงุช ุงู ฺฉุชุงุจ  ุจู ุฒู ุงุดุงุฑู ุดุฏู ุจูุฏ ฺฉู ุงูู ูู ุงููุฏุฑ ฺฉู ุจูุฏ ฺฉู ูู ุดู ฺฏูุช ุชููุง ุฏุฑ ููุฑุฏ ุฒู ูุง ุตุฏู ู ฺฉูู. ุงฺฏุฑ ุจู ูู ุจฺฏู ุจุฑุงุงู ุชุฑุณ ฺฉุชุงุจ ุจู ูุงู \"ุฒู ูููู\" ูุฏุงุฑู ู ุงู ุฌููุงุช ูุฌููุนู ุง ุงุฒ ุฌููู ูุง ฺฏูุชู ุดุฏู ุฏุฑ ฺฉุชุงุจ ูุง ุฏฺฏุฑ ุงุดููู ฺฉู ุชูุณุท ุงู ุฏู ููุฑ (ุงุณุงู ูุชุฑุฌู ูุง) ุฌูุน ุขูุฑ ุดุฏูุ ุญุชูุง ุจุงูุฑ ู ฺฉูู. ุจู ูุธุฑ ูู ฺฉุชุงุจ ุฎูุจ ูุจูุฏ.\n",
            "ุฎูุจ ุจูุฏ\n",
            "ูู ุฏูุจุงู ฺฉุชุงุจ \"ุฒู ฺฉุงูู\" ูุณุชู ุงุฒ \"ูุงุฑุงุจู ููุฑฺฏุงู\"\n",
            "ููููู ูุดู ุงฺฏ ุจุฑุงู ุฏุฑ ูุธุฑ ุฏุงุดุชู ุจุงุดุฏุด.\n",
            "ฺฉุชุงุจ ุฎู ุฎูุจู ฺฏูุง\n",
            "ุฎูุจ ุจูุฏ\n",
            "ูู ุฏูุจุงู ฺฉุชุงุจ \"ุฒู ฺฉุงูู\" ูุณุชู ุงุฒ \"ูุงุฑุงุจู ููุฑฺฏุงู\"\n",
            "ููููู ูุดู ุงฺฏ ุจุฑุงู ุฏุฑ ูุธุฑ ุฏุงุดุชู ุจุงุดุฏุด.\n",
            "ฺฉุชุงุจ ุฎู ุฎูุจู ฺฏูุง\n",
            "@ูุณุง\n",
            "ูุณุฎูโ ฺฉุงุบุฐ ฺฉุชุงุจ ธฒ ุตูุญู ุงุณุช. ูุณุฎูโ ePUB ฺฉุชุงุจ ุชู ฺฏูุด ุดูุง ุดุฏู ดด ุตูุญู. ุงูุงู ุงฺฏู ููู ฺฉุชุงุจ ุฑู ุจุฒุฑฺฏโุชุฑ ฺฉูุฏ ุชุนุฏุงุฏ ุตูุญุงุช ุจุดุชุฑ ูโุดู. ฺฉูฺฺฉุด ูู ุจฺฉูุฏ ุชุนุฏุงุฏ ุตูุญุงุช ฺฉูุชุฑ ูโุดู.\n",
            "@ูุณุง\n",
            "ูุณุฎูโ ฺฉุงุบุฐ ฺฉุชุงุจ ธฒ ุตูุญู ุงุณุช. ูุณุฎูโ ePUB ฺฉุชุงุจ ุชู ฺฏูุด ุดูุง ุดุฏู ดด ุตูุญู. ุงูุงู ุงฺฏู ููู ฺฉุชุงุจ ุฑู ุจุฒุฑฺฏโุชุฑ ฺฉูุฏ ุชุนุฏุงุฏ ุตูุญุงุช ุจุดุชุฑ ูโุดู. ฺฉูฺฺฉุด ูู ุจฺฉูุฏ ุชุนุฏุงุฏ ุตูุญุงุช ฺฉูุชุฑ ูโุดู.\n",
            "ููุดุชู  ธฒ ุตูุญู ุฏุฑ ุตูุฑุช ฺฉู ดดุตูุญู ุจุดุชุฑ ูุณุช!!!!ุ!!\n",
            "ููุดุชู  ธฒ ุตูุญู ุฏุฑ ุตูุฑุช ฺฉู ดดุตูุญู ุจุดุชุฑ ูุณุช!!!!ุ!!\n",
            "ูุชู ุฎู ุฌุงูุจ ุฏุงุฑู. ูุฐุช ุจุฑุฏู\n",
            "ูุชู ุฎู ุฌุงูุจ ุฏุงุฑู. ูุฐุช ุจุฑุฏู\n",
            "ุนุงู ุจูุฏ ูู ูุงูุนุง ุฏูุณุช ุฏุงุดุชู ุงู ฺฉุชุงุจู\n",
            "ุนุงู ุจูุฏ ูู ูุงูุนุง ุฏูุณุช ุฏุงุดุชู ุงู ฺฉุชุงุจู\n",
            "ุชุฑุฌูู ุจู ุดุฏุช ุถุนูู ฺฉุชุงุจ ุฎูุจู . ูุฑฺฏูู ูุฏุงุฑู ฺฉุชุงุจ ุงุฐุช ูฺฉูู\n",
            "ุชุฑุฌูู ุจู ุดุฏุช ุถุนูู ฺฉุชุงุจ ุฎูุจู . ูุฑฺฏูู ูุฏุงุฑู ฺฉุชุงุจ ุงุฐุช ูฺฉูู\n",
            "ฺฉุชุงุจ ุจุณุงุฑ ุฑุงูฺฏุดุง ุจุฑุง ุฏุฑฺฉ ุฑูุงูฺฉุงู ุงุณุช ุจุง ฺฉูุชุฑู ุงุทูุงุนุงุช ุฏุฑ ููุฑุฏ ุฑูุงูฺฉุงู ุจุงุฒ ูู ฺุฒ ูุง ุจุณุงุฑ ููุฏ ุฏุณุชฺฏุฑุชูู ูุดูุ ฺูู ุณุฎูุฑุงู ูุง ูุฑูุฏ ุจูุฏู ู ูุญู ูุฑูุฏ ุฏุฑ ุงูู ูุง ุณุงุฏู ู ุฌุฐุงุจูุ ุจุฎุด ุฏููุด ูู ฺฉู ฺฉูุง ฺฉ ูฺฉุงููู  ุฎุงู ุจู ูุฑูุฏ ู ฺฉ ูุงุถ ูุณุช ฺฉู ูุฑูุฏ ุฏุฑ ุงูู ุงุฒ ุฑูุงูฺฉุงู ุชูุณุท ุบุฑ ูพุฒุดฺฉุงู ุฏูุงุน ูฺฉูู ฺฉู ุงูู ูู ุจู ุงูุฏุงุฒู  ุจุฎุด ุงูู ููุฏู\n",
            "ฺฉุชุงุจ ุจุณุงุฑ ุฑุงูฺฏุดุง ุจุฑุง ุฏุฑฺฉ ุฑูุงูฺฉุงู ุงุณุช ุจุง ฺฉูุชุฑู ุงุทูุงุนุงุช ุฏุฑ ููุฑุฏ ุฑูุงูฺฉุงู ุจุงุฒ ูู ฺุฒ ูุง ุจุณุงุฑ ููุฏ ุฏุณุชฺฏุฑุชูู ูุดูุ ฺูู ุณุฎูุฑุงู ูุง ูุฑูุฏ ุจูุฏู ู ูุญู ูุฑูุฏ ุฏุฑ ุงูู ูุง ุณุงุฏู ู ุฌุฐุงุจูุ ุจุฎุด ุฏููุด ูู ฺฉู ฺฉูุง ฺฉ ูฺฉุงููู  ุฎุงู ุจู ูุฑูุฏ ู ฺฉ ูุงุถ ูุณุช ฺฉู ูุฑูุฏ ุฏุฑ ุงูู ุงุฒ ุฑูุงูฺฉุงู ุชูุณุท ุบุฑ ูพุฒุดฺฉุงู ุฏูุงุน ูฺฉูู ฺฉู ุงูู ูู ุจู ุงูุฏุงุฒู  ุจุฎุด ุงูู ููุฏู\n",
            "ุขุง ุงู ฺฉุชุงุจ ุขููุฒุด ุฑูุงูฺฉุงู ูุฏู ูุฎูุงุณุชู ฺฉ ุงุฒ ฺฉุชุงุจ ูุง ูุฑูุฏ ุฑู ูุนุฑู ฺฉูู ฺฉู ุงููุฒุด ุฑูุงูฺฉุงูุด ุชู ุงูู ฺฉุชุงุจ ุจุงุดู\n",
            "ุขุง ุงู ฺฉุชุงุจ ุขููุฒุด ุฑูุงูฺฉุงู ูุฏู ูุฎูุงุณุชู ฺฉ ุงุฒ ฺฉุชุงุจ ูุง ูุฑูุฏ ุฑู ูุนุฑู ฺฉูู ฺฉู ุงููุฒุด ุฑูุงูฺฉุงูุด ุชู ุงูู ฺฉุชุงุจ ุจุงุดู\n",
            "ุจุฑุง ูุทุงูุนู ฺฉุงุฑูุง ููุณูุฏฺฏุงู ฺฉู ูพฺุฏู ุตุญุจุช ู ฺฉููุฏ ุจูุชุฑู ุฑูุด ุงูู ฺฉู ุงูู ููุฏูุง ู ุชูุณุฑูุง ููุณูุฏฺฏุงู ุฏฺฏู ุฑู ุฏุฑ ููุฑุฏ ุงูู ููุณูุฏู ุจุฎููู ุจุนุฏ ุณุฑุงุบ ูุชู ุงุตู ุจุฑูุ ูุซูุง ุจุฑุง ูููุฏู ูุฑูุฏ ฺฉ ูุชูฺฉุฑ ุจู ุงุณู ุงุฑฺฉ ุจุฑู ูุณุช ฺฉู ุชูุณู ุจูุฏ ูุฑูุฏ ุงุฒ ููุงุฏุ ูู ู ูู ุจุฑุชุฑ ุฑู ุจุง ูุซุงู ู ุจุง ุฒุจุงู ุณุงุฏู ุขูุฑุฏู ฺฉู ุจุง ุฎููุฏู ุงูู ูุดู ูพ ุจู ุชูฺฉุฑุงุช ูุฑูุฏ ูพ ุจุฑุฏ.\n",
            "ุจุฑุง ูุทุงูุนู ฺฉุงุฑูุง ููุณูุฏฺฏุงู ฺฉู ูพฺุฏู ุตุญุจุช ู ฺฉููุฏ ุจูุชุฑู ุฑูุด ุงูู ฺฉู ุงูู ููุฏูุง ู ุชูุณุฑูุง ููุณูุฏฺฏุงู ุฏฺฏู ุฑู ุฏุฑ ููุฑุฏ ุงูู ููุณูุฏู ุจุฎููู ุจุนุฏ ุณุฑุงุบ ูุชู ุงุตู ุจุฑูุ ูุซูุง ุจุฑุง ูููุฏู ูุฑูุฏ ฺฉ ูุชูฺฉุฑ ุจู ุงุณู ุงุฑฺฉ ุจุฑู ูุณุช ฺฉู ุชูุณู ุจูุฏ ูุฑูุฏ ุงุฒ ููุงุฏุ ูู ู ูู ุจุฑุชุฑ ุฑู ุจุง ูุซุงู ู ุจุง ุฒุจุงู ุณุงุฏู ุขูุฑุฏู ฺฉู ุจุง ุฎููุฏู ุงูู ูุดู ูพ ุจู ุชูฺฉุฑุงุช ูุฑูุฏ ูพ ุจุฑุฏ.\n",
            "ฺฉุชุงุจ ูุง ูุฑูุฏ ฺฉุชุงุจ ูุง ุณูฺฏู ูุณุชูุฏ ฺฉู ูู ุจู ุดุฎุตู ฺูู ุฏุฑ ุญูุถู ุฑูุงูฺฉุงู ูุณูุช ุงุฒ ูุฑูุฏ ู ูุณูุช ุงุฒ ููฺฏ ูุทุงูุนู ฺฉุฑุฏู ุจู ููู ูพุดููุงุฏ ููฺฉููุฺฉุชุงุจ ูุณุช ฺฉู ฺฉุณ ุจุจูู ุฎูุดุด ุจุงุฏ ู ุจุฎููู ู ุจุนุฏ ุชูุงูุฺูู  ุงูู ุจู ุงุดุชุจุงู ูฺฉุฑ ูฺฉูู ุฑูุงูฺฉุงู ุดุฏู:) ู ูข.ุงุญุชูุงู ุฏุงุฑู ฺุฒ ูุชูุฌู ูุดูุูพุณ ุจู ฺฉุณุงู ฺฉู ุจู ุงู ุดุงุฎู ุนูุงูู ุฏุงุฑูุฏ ุฎููุฏู ฺฉุชุงุจูุง ูุฑูุฏ ุฑู ูพุดููุงุฏ ูฺฉูู\n",
            "ฺฉุชุงุจ ูุง ูุฑูุฏ ฺฉุชุงุจ ูุง ุณูฺฏู ูุณุชูุฏ ฺฉู ูู ุจู ุดุฎุตู ฺูู ุฏุฑ ุญูุถู ุฑูุงูฺฉุงู ูุณูุช ุงุฒ ูุฑูุฏ ู ูุณูุช ุงุฒ ููฺฏ ูุทุงูุนู ฺฉุฑุฏู ุจู ููู ูพุดููุงุฏ ููฺฉููุฺฉุชุงุจ ูุณุช ฺฉู ฺฉุณ ุจุจูู ุฎูุดุด ุจุงุฏ ู ุจุฎููู ู ุจุนุฏ ุชูุงูุฺูู  ุงูู ุจู ุงุดุชุจุงู ูฺฉุฑ ูฺฉูู ุฑูุงูฺฉุงู ุดุฏู:) ู ูข.ุงุญุชูุงู ุฏุงุฑู ฺุฒ ูุชูุฌู ูุดูุูพุณ ุจู ฺฉุณุงู ฺฉู ุจู ุงู ุดุงุฎู ุนูุงูู ุฏุงุฑูุฏ ุฎููุฏู ฺฉุชุงุจูุง ูุฑูุฏ ุฑู ูพุดููุงุฏ ูฺฉูู\n",
            "ฺฉุชุงุจ ุนุงู ุงุฒ ุฌูุช ุดุฑูุน ูฺฏุฑุด ุฏุฑ ุจุงุฑู ุนูู ุฑูุงูฺฉุงู \n",
            "ฺฉุชุงุจ ุนุงู ุงุฒ ุฌูุช ุดุฑูุน ูฺฏุฑุด ุฏุฑ ุจุงุฑู ุนูู ุฑูุงูฺฉุงู \n",
            "ฺฉุงุฑุขูุฏ ู ูุชุญูู ฺฉููุฏู ุดุฏุฏุง ุชูุตู ูฺฉูู\n",
            "ฺฉุงุฑุขูุฏ ู ูุชุญูู ฺฉููุฏู ุดุฏุฏุง ุชูุตู ูฺฉูู\n",
            "โคโคโค\n",
            "ฺฉุฏ ุชุฎูู ตฐ ุฏุฑุตุฏ\n",
            "Y98MACRCUNYJ2\n",
            "\n",
            "ฺฉุฏ ุชุฎูู ตฐ ุฏุฑุตุฏ\n",
            "Y98MACRCUNYJ2\n",
            "ูุทูุง ุงุซุงุฑู ุงุดูู ุฑู ฺฉุงูู ฺฉูุฏ\n",
            "ูุทูุง ุงุซุงุฑู ุงุดูู ุฑู ฺฉุงูู ฺฉูุฏ\n",
            "ุชุฑุฌูู ุงุญูุฏูพูุฑ ุจู ุจูฺฉููุณฺฉ ุฑูุญ ูุฏู.ุงุฒ ุจูุชูุง ุจุงุฒ ูู ุดุนุฑ ุจุฒุงุฑุฏ ูุฎุตูุตุง ฺฉุชุงุจ ุชุงุฒู ุญุงูุธ ููุณู\n",
            "ุชุฑุฌูู ุงุญูุฏูพูุฑ ุจู ุจูฺฉููุณฺฉ ุฑูุญ ูุฏู.ุงุฒ ุจูุชูุง ุจุงุฒ ูู ุดุนุฑ ุจุฒุงุฑุฏ ูุฎุตูุตุง ฺฉุชุงุจ ุชุงุฒู ุญุงูุธ ููุณู\n",
            "ุจูฺฉูุณฺฉ ููุณ ูู\n",
            "ุจูฺฉูุณฺฉ ููุณ ูู\n",
            "ุนูุถ ฺฉุฑุฏูู ูุฏุงูู ฺฉุงูุงูุง ุชููุฒูู !\n",
            "ูุงูู ูุง ุฑู ู ุจู ฺฉู ูฺ ฺฉุฏูู ูุงูุน ูุณุชู !\n",
            "ุจุง ู ูุญุดุชู ูุงูุน ุดุงุฎ ุจู ุดุงุฎ !\n",
            "ุจุฌูุจ !\n",
            "ุจุฌูุจ !\n",
            "ุจุดุชุฑ !\n",
            "ฺฉูุชุฑ !\n",
            "ุตูุฑุชุง ุจูุช ูุฑููู ู ุฏู !\n",
            "ุงููุง ุฑู ุจุง ฺ ูพุฑ ฺฉุฑุฏู ุ\n",
            "ฺู ุฌูุฑ ุฌุง ุดุฏู ุชู ุงูู ุดุดู ุ\n",
            "ฺฉ ฺูพููุฏูุชุดูู ุงูู ุชู ุ\n",
            "ฺุฒ ูุณุช ุ\n",
            "ุชู ุงู ุฏูุง\n",
            "ุงู ุฏูุง...\n",
            "ุงูุง ูุฑุฏูู ูู ูุณุชู\n",
            "ูุฑุฏูุง ูู ฺฉุฌุง ุฑูุชู ุ\n",
            "\n",
            "\n",
            "ุนูุถ ฺฉุฑุฏูู ูุฏุงูู ฺฉุงูุงูุง ุชููุฒูู !\n",
            "ูุงูู ูุง ุฑู ู ุจู ฺฉู ูฺ ฺฉุฏูู ูุงูุน ูุณุชู !\n",
            "ุจุง ู ูุญุดุชู ูุงูุน ุดุงุฎ ุจู ุดุงุฎ !\n",
            "ุจุฌูุจ !\n",
            "ุจุฌูุจ !\n",
            "ุจุดุชุฑ !\n",
            "ฺฉูุชุฑ !\n",
            "ุตูุฑุชุง ุจูุช ูุฑููู ู ุฏู !\n",
            "ุงููุง ุฑู ุจุง ฺ ูพุฑ ฺฉุฑุฏู ุ\n",
            "ฺู ุฌูุฑ ุฌุง ุดุฏู ุชู ุงูู ุดุดู ุ\n",
            "ฺฉ ฺูพููุฏูุชุดูู ุงูู ุชู ุ\n",
            "ฺุฒ ูุณุช ุ\n",
            "ุชู ุงู ุฏูุง\n",
            "ุงู ุฏูุง...\n",
            "ุงูุง ูุฑุฏูู ูู ูุณุชู\n",
            "ูุฑุฏูุง ูู ฺฉุฌุง ุฑูุชู ุ\n",
            "\n",
            "\n",
            "ุณูุงู .ุดูุฏ ูุญูุฏุงุจุฑุงูู ููุช ุดุฎุตุช ููุฑุจูู ู ุงุญุณุงุณุงุช ู ุฎุตูุตุง ุฎุงูุต ุฏุงุฑู ...ู ุงุฒ ุฎุตูุตุงุช ุจุงุฑุฒุดูู ุฎููุต ุฏุฑ ูุช ุุนูู ู ฺฏูุชุงุฑู .\n",
            "ุจ ููู ุฎูุฏุดูู ููู ฺุ ููู ฺุ ููู ฺ ุฎูุงุณุช ุฎุฏุง ุจุงุดู ฺฉ ุงฺฏู ุงู ุฌูุฑ ุดุฏ ูพุฑูุฒู ู ุดฺฉุณุช ูุนูุง ูุฏุงุฑู ุจุฑุง ูุง .\n",
            "ฺฉู ฺฉุชุงุจุ ุฎุงุทุฑุงุช ฺฉูุชุงู ฺฉูุชุงู ุงุฒ ุงุดูู ุฏุงุฑู .ู ุฏุฑุจุงุฑู ุชููุฏุดูู ูู ุญุงุฌ ุญุณู ฺฉุชุง ุุงุณููุฏ ุงูุณุงู ุชู ุดููฺู ุตุญุจุช ุนุฌุจ ฺฉุฑุฏู .\n",
            "ุณูุงู .ุดูุฏ ูุญูุฏุงุจุฑุงูู ููุช ุดุฎุตุช ููุฑุจูู ู ุงุญุณุงุณุงุช ู ุฎุตูุตุง ุฎุงูุต ุฏุงุฑู ...ู ุงุฒ ุฎุตูุตุงุช ุจุงุฑุฒุดูู ุฎููุต ุฏุฑ ูุช ุุนูู ู ฺฏูุชุงุฑู .\n",
            "ุจ ููู ุฎูุฏุดูู ููู ฺุ ููู ฺุ ููู ฺ ุฎูุงุณุช ุฎุฏุง ุจุงุดู ฺฉ ุงฺฏู ุงู ุฌูุฑ ุดุฏ ูพุฑูุฒู ู ุดฺฉุณุช ูุนูุง ูุฏุงุฑู ุจุฑุง ูุง .\n",
            "ฺฉู ฺฉุชุงุจุ ุฎุงุทุฑุงุช ฺฉูุชุงู ฺฉูุชุงู ุงุฒ ุงุดูู ุฏุงุฑู .ู ุฏุฑุจุงุฑู ุชููุฏุดูู ูู ุญุงุฌ ุญุณู ฺฉุชุง ุุงุณููุฏ ุงูุณุงู ุชู ุดููฺู ุตุญุจุช ุนุฌุจ ฺฉุฑุฏู .\n",
            "ุดูุฏ ููุช ฺฉ ุงุณุทูุฑู  ูุงูุน ูุณุชู...\n",
            "ุดูุฏ ููุช ฺฉ ุงุณุทูุฑู  ูุงูุน ูุณุชู...\n",
            "ุณุฑุฒูู ฺฏูุฌู ูุง ุณุจุฒ ู ููุฌูุฏ ฺฉูุฏ\n",
            "ูุทูู\n",
            "ุณุฑุฒูู ฺฏูุฌู ูุง ุณุจุฒ ู ููุฌูุฏ ฺฉูุฏ\n",
            "ูุทูู\n",
            "ูุฑุชุง ูููุฑ ุฑุง ุจุง ุตุจูุฑ ู ุขุฑุงูุด ุจุฎูุงูุฏ. ูุฐุช ู ุจุฑุฏ.\n",
            "ูุฑุชุง ูููุฑ ุฑุง ุจุง ุตุจูุฑ ู ุขุฑุงูุด ุจุฎูุงูุฏ. ูุฐุช ู ุจุฑุฏ.\n",
            "ุฎูุจ ูุณุช\n",
            "ุฎูุจ ูุณุช\n",
            "ุฎู ุฎูุดู ูููุฏุ\n",
            "ุฎู ุฎูุดู ูููุฏุ\n",
            "ุชุฑุฌูู  ุงู ฺฉุชุงุจ ุฎู ุฎูุจู.ุจุง ุงู ฺฉู ูุฑุงุชุฑ ุงุฒ ุฎุท ุณุฑ ฺฉ ุฑูุงูู ู ุจุดุชุฑ ูุฎูุงุฏ ุญุฑู ูุงุดู ุจุงู ฺฉูู  ุฎูุงูุฏูุด ูุซู ุจูู ุฑูุงู ูุง ูููุฑ ูุฐุช ุจุฎุดู\n",
            "ุชุฑุฌูู  ุงู ฺฉุชุงุจ ุฎู ุฎูุจู.ุจุง ุงู ฺฉู ูุฑุงุชุฑ ุงุฒ ุฎุท ุณุฑ ฺฉ ุฑูุงูู ู ุจุดุชุฑ ูุฎูุงุฏ ุญุฑู ูุงุดู ุจุงู ฺฉูู  ุฎูุงูุฏูุด ูุซู ุจูู ุฑูุงู ูุง ูููุฑ ูุฐุช ุจุฎุดู\n",
            "ุทุงูฺู ุฏุงุฑู ุฑูุฒ ุจู ุฑูุฒ ุจูุชุฑ ูุดู, ุทุงูฺู ูุฑุงุชุฑ ุงุฒ ฺฉ ุงูพ ุฎูุงูุฏ ุดุฏ, ุทุงูฺู ุจู ููู ุณููู ูุง ุงุญุชุฑุงู ูฺฏุฐุงุฑู ู ุงู ุฎู ูููู\n",
            "ุทุงูฺู ุฏุงุฑู ุฑูุฒ ุจู ุฑูุฒ ุจูุชุฑ ูุดู, ุทุงูฺู ูุฑุงุชุฑ ุงุฒ ฺฉ ุงูพ ุฎูุงูุฏ ุดุฏ, ุทุงูฺู ุจู ููู ุณููู ูุง ุงุญุชุฑุงู ูฺฏุฐุงุฑู ู ุงู ุฎู ูููู\n",
            "ูุฑุณ ุจู ุทุงูฺู ู ูุดุฑ ุจูุชูุงุฑ ุจุง ุงูุชุดุงุฑ ุงู ฺฉุชุงุจ ุฎูุจ\n",
            "ูุฑุณ ุจู ุทุงูฺู ู ูุดุฑ ุจูุชูุงุฑ ุจุง ุงูุชุดุงุฑ ุงู ฺฉุชุงุจ ุฎูุจ\n",
            "ูุงูุนุง ููููู\n",
            "ูุงูุนุง ููููู\n",
            "Y986STYXCWS2Rฺฉุฏ 30 ุฏุฑุตุฏ\n",
            "Y986STYXCWS2Rฺฉุฏ 30 ุฏุฑุตุฏ\n",
            "ูู ุงู ฺฉุชุงุจู ุชู ุฏูุฑู  ุฑุงฺฏุงู ฺฏุฑูุชู ูู ุงูุงู ฺฉู ุทุงูฺู ุฑู ูพุงฺฉ ู ูุตุจ ฺฉุฑุฏู ูฺฏู ุจุงุฏ ูพุฑุฏุงุฎุช ฺฉู!!ฺุฑุงุงุงุุุุ\n",
            "ูู ุงู ฺฉุชุงุจู ุชู ุฏูุฑู  ุฑุงฺฏุงู ฺฏุฑูุชู ูู ุงูุงู ฺฉู ุทุงูฺู ุฑู ูพุงฺฉ ู ูุตุจ ฺฉุฑุฏู ูฺฏู ุจุงุฏ ูพุฑุฏุงุฎุช ฺฉู!!ฺุฑุงุงุงุุุุ\n",
            "ฺุฑุง ููุงุฑุจุงุฒู ุฏูุณ ุฏุงุฑูุ!\n",
            "ฺุฑุง ููุงุฑุจุงุฒู ุฏูุณ ุฏุงุฑูุ!\n",
            "ฺฉุชุงุจ ฺฉู ููุช ุดุฑูุน ฺฉุฑุฏู ุฑูุง ูฺฉุฑุฏู ุจุง ุฏุงุณุชุงู ฺฏู ุนุงู\n",
            "ฺฉุชุงุจ ฺฉู ููุช ุดุฑูุน ฺฉุฑุฏู ุฑูุง ูฺฉุฑุฏู ุจุง ุฏุงุณุชุงู ฺฏู ุนุงู\n",
            "ูุฌุฐูุจ ุงู ฺฉุชุงุจ ุดุฏู\n",
            "ูุฌุฐูุจ ุงู ฺฉุชุงุจ ุดุฏู\n",
            "ุชุฑุฌูู ฺฉุชุงุจ ูุงูุนุง ุถุนูู ุงูุง ุงููุฏุฑ ุฏุงุณุชุงู ฺฉุชุงุจ ุฌุฐุงุจู ฺฉู ูู ุชู ุณู ุฑูุฒุ ฺฉุชุงุจ ุฑู ุชููู ฺฉุฑุฏู . ุงูุงู ฺฉุชุงุจ ุจุง ุชุฑุฌูุด ุฎู ูุดฺฉู ุฏุงุดุชู ุงูุง ฺฉู ฺฉู ุนุงุฏุช ฺฉุฑุฏู ู ุชููุณุชู ุฌููู ู ฺฉููู ุตุญุญ ุฑู ุญุฏุณ ุจุฒูู โบ๏ธ\n",
            "ุชุฑุฌูู ฺฉุชุงุจ ูุงูุนุง ุถุนูู ุงูุง ุงููุฏุฑ ุฏุงุณุชุงู ฺฉุชุงุจ ุฌุฐุงุจู ฺฉู ูู ุชู ุณู ุฑูุฒุ ฺฉุชุงุจ ุฑู ุชููู ฺฉุฑุฏู . ุงูุงู ฺฉุชุงุจ ุจุง ุชุฑุฌูุด ุฎู ูุดฺฉู ุฏุงุดุชู ุงูุง ฺฉู ฺฉู ุนุงุฏุช ฺฉุฑุฏู ู ุชููุณุชู ุฌููู ู ฺฉููู ุตุญุญ ุฑู ุญุฏุณ ุจุฒูู \n",
            "\"ุฎูฺฉ ุขู ููุงุฑุจุงุฒ ฺฉู ุจุจุงุฎุช ุขูฺู ุจูุฏุด\n",
            "ุจููุงูุฏ ูฺุด ุงูุง ููุณ ููุงุฑ ุฏฺฏุฑ\"\n",
            "ุฑูุงู ูู ุจุง ุชุฑุฌูู ุง ุถุนู ู ฺฏูฺฏ ูุงููุฏ ุณฺฏุงุฑ ุจุฏูู ูฺฉูุชูู . ุงุซุฑ ุจุฎุด ฺฉ ุงุซุฑ ุฏุฑ ุชุฑุฌูู ุ ุฏูุช ุฏุฑ ุงูุชูุงู ููุงูู ู ุณูููุช ุฏุฑ ุฏุฑฺฉ ู ููู ุฎูุงููุฏุณุช ูู ูพฺุฏฺฏ ูุง ุงุฏุจ ู ฺฏุฑุฏูู ูุง ุงุจูุงู ู ุงูุงู .\n",
            "\"ุฎูฺฉ ุขู ููุงุฑุจุงุฒ ฺฉู ุจุจุงุฎุช ุขูฺู ุจูุฏุด\n",
            "ุจููุงูุฏ ูฺุด ุงูุง ููุณ ููุงุฑ ุฏฺฏุฑ\"\n",
            "ุฑูุงู ูู ุจุง ุชุฑุฌูู ุง ุถุนู ู ฺฏูฺฏ ูุงููุฏ ุณฺฏุงุฑ ุจุฏูู ูฺฉูุชูู . ุงุซุฑ ุจุฎุด ฺฉ ุงุซุฑ ุฏุฑ ุชุฑุฌูู ุ ุฏูุช ุฏุฑ ุงูุชูุงู ููุงูู ู ุณูููุช ุฏุฑ ุฏุฑฺฉ ู ููู ุฎูุงููุฏุณุช ูู ูพฺุฏฺฏ ูุง ุงุฏุจ ู ฺฏุฑุฏูู ูุง ุงุจูุงู ู ุงูุงู .\n",
            "ุณุฎุช ูู ุฎูุจ\n",
            "ุณุฎุช ูู ุฎูุจ\n",
            "ู ุงู ุจูุฏ ุขุฑูุงู ูุง ุงูููุงุจ ูุงุณู ูุทุงูุนู๐ ุงู ฺู ุชุฑุฌูู ุงู ูุงุณู ฺฉุชุงุจุง ุฑุงฺฏุงู ุขุฎู๐\n",
            "ู ุงู ุจูุฏ ุขุฑูุงู ูุง ุงูููุงุจ ูุงุณู ูุทุงูุนู ุงู ฺู ุชุฑุฌูู ุงู ูุงุณู ฺฉุชุงุจุง ุฑุงฺฏุงู ุขุฎู\n",
            "ุชุฑุฌูู ูพฺุฏู.....ุจุงุฏ ุชูุฑฺฉุฒ ุจุงูุง ุฏุงุดุชู ุจุงุด ุชุง ุจุชูู ุฏุงุณุชุงู ุฑู ุฏุฑฺฉ ฺฉู\n",
            "ุชุฑุฌูู ูพฺุฏู.....ุจุงุฏ ุชูุฑฺฉุฒ ุจุงูุง ุฏุงุดุชู ุจุงุด ุชุง ุจุชูู ุฏุงุณุชุงู ุฑู ุฏุฑฺฉ ฺฉู\n",
            "ุฎูุจ ุจูุฏ. ุจุง ุงูฺฉู ูุชู ุฑูุงู ูุฏุงุดุช ูู ูุงูุนุง ุจู ูุธุฑู ุชูุตูุงุช ุฏุงุณุชุงูุณฺฉ ุฎู ุฎูุจ ุจูุฏ.\n",
            "ุฎูุจ ุจูุฏ. ุจุง ุงูฺฉู ูุชู ุฑูุงู ูุฏุงุดุช ูู ูุงูุนุง ุจู ูุธุฑู ุชูุตูุงุช ุฏุงุณุชุงูุณฺฉ ุฎู ุฎูุจ ุจูุฏ.\n",
            "ูุงูุง ุจุนููุงู ฺฉุณ ฺฉู ุฒุงุฏ ุญุฑูู ุง ูุทุงูุนู ููฺฉูู ู ูุฏุงุฑู ุงุตูุง ูุชููุณุชู ุจุงูุงุด ุงุฑุชุจุงุท ุจุฑูุฑุงุฑ ฺฉูู ู ุชุง ฺฉู ุตูุญู ูู ูพุด ุฑูุชู ูู ฺุฒ ูุชูุฌู ูุดุฏู...ู ุจ ุฎุงู ุดุฏู.๐๐\n",
            "ูุงูุง ุจุนููุงู ฺฉุณ ฺฉู ุฒุงุฏ ุญุฑูู ุง ูุทุงูุนู ููฺฉูู ู ูุฏุงุฑู ุงุตูุง ูุชููุณุชู ุจุงูุงุด ุงุฑุชุจุงุท ุจุฑูุฑุงุฑ ฺฉูู ู ุชุง ฺฉู ุตูุญู ูู ูพุด ุฑูุชู ูู ฺุฒ ูุชูุฌู ูุดุฏู...ู ุจ ุฎุงู ุดุฏู.\n",
            "ุชุฑุฌูู ฺฏุฌ ู ฺฏูฺฏ ุงุณุช ูุณุทุง ฺฉุชุงุจ ุงุฒ ูุทุงูุนู ููุตุฑู ุดุฏู\n",
            "ุชุฑุฌูู ฺฏุฌ ู ฺฏูฺฏ ุงุณุช ูุณุทุง ฺฉุชุงุจ ุงุฒ ูุทุงูุนู ููุตุฑู ุดุฏู\n",
            "ุจู ุฎูุฏ ฺฉุชุงุจ 5 ุณุชุงุฑู ูุฏูุ ุชุฑุฌูู ุขู ุงุญูุฏ ุฑู ฺฏูฺฏ ู ูพฺุฏู ุจูุฏ ู ุงุฒ ฺฉุชุงุจุฎุงูู ุชุฑุฌูู ุตุงูุญ ุญุณู ฺฏุฑูุชู ุฎููุฏู ฺฉูุง ฺฉุชุงุจ ุนุงู ุจูุฏุด\n",
            "ุจู ุฎูุฏ ฺฉุชุงุจ 5 ุณุชุงุฑู ูุฏูุ ุชุฑุฌูู ุขู ุงุญูุฏ ุฑู ฺฏูฺฏ ู ูพฺุฏู ุจูุฏ ู ุงุฒ ฺฉุชุงุจุฎุงูู ุชุฑุฌูู ุตุงูุญ ุญุณู ฺฏุฑูุชู ุฎููุฏู ฺฉูุง ฺฉุชุงุจ ุนุงู ุจูุฏุด\n",
            "ุจุง ุงูฺฉู ุธุงูุฑุง ูฺฏุงุฑุด ฺฉุชุงุจ ุจุง ุนุฌูู ุตูุฑุช ฺฏุฑูุชูุ ุงูุง ุฏุงุณุชุงููุณฺฉ ุดุฎุตุช ูพุฑุฏุงุฒ ูุง ู ุชูุตู ุญุงูุงุช ุฑูุงู ู ุงุญุณุงุณ ุฑู ุฎู ุนุงู ุงูุฌุงู ุฏุงุฏู ู ูุดู ุฎู ุฎูุจ ูููุนุช ูุง ุฑู ุชุฎู ฺฉุฑุฏ. ุจุฑุฎ ุฏูุณุชุงู ูุณุจุช ุจู ุงู ุชุฑุฌูู ุงุจุฑุงุฒ ูุงุฑุงุถุงุช ฺฉุฑุฏู. ุงุฒ ูุธุฑ ูู ุชุฑุฌูู ูู ูุดฺฉู ูุฏุงุดุช ู ูฺฉุฑ ูฺฉูู ุจุฎุงุทุฑ ุณุจฺฉ ููู ููุณูุฏู ฺฉู ุจูุธุฑ ุฏุดูุงุฑ ุง ุบุฑุฑูุงู ูุงุฏ. ู ุฒุงุฏ ุฑุจุท ุจู ูุชุฑุฌู ูุฏุงุฑู. ุงูุง ุจูุฑุญุงู ุณููู ุง ูุณ..\n",
            "ุจุง ุงูฺฉู ุธุงูุฑุง ูฺฏุงุฑุด ฺฉุชุงุจ ุจุง ุนุฌูู ุตูุฑุช ฺฏุฑูุชูุ ุงูุง ุฏุงุณุชุงููุณฺฉ ุดุฎุตุช ูพุฑุฏุงุฒ ูุง ู ุชูุตู ุญุงูุงุช ุฑูุงู ู ุงุญุณุงุณ ุฑู ุฎู ุนุงู ุงูุฌุงู ุฏุงุฏู ู ูุดู ุฎู ุฎูุจ ูููุนุช ูุง ุฑู ุชุฎู ฺฉุฑุฏ. ุจุฑุฎ ุฏูุณุชุงู ูุณุจุช ุจู ุงู ุชุฑุฌูู ุงุจุฑุงุฒ ูุงุฑุงุถุงุช ฺฉุฑุฏู. ุงุฒ ูุธุฑ ูู ุชุฑุฌูู ูู ูุดฺฉู ูุฏุงุดุช ู ูฺฉุฑ ูฺฉูู ุจุฎุงุทุฑ ุณุจฺฉ ููู ููุณูุฏู ฺฉู ุจูุธุฑ ุฏุดูุงุฑ ุง ุบุฑุฑูุงู ูุงุฏ. ู ุฒุงุฏ ุฑุจุท ุจู ูุชุฑุฌู ูุฏุงุฑู. ุงูุง ุจูุฑุญุงู ุณููู ุง ูุณ..\n",
            "ุนู ุงูุฑุบู ุขูฺฉู ุดูุฏู ุจูุฏู ฺฉู ูุฆูุฏูุฑ ุฏุงุณุชุงููุณฺฉ ุฏุงุณุชุงู ููุณ ุจุง ุณุจฺฉ ูพูุฌ ฺฏุฑุงุงูู ุงุณุช\n",
            "ุฏุฑ ุงูุชูุง ุงู ุงุซุฑ ุนุฌุจ ู ุจู ุงุฏ ูุงูุฏู ุฏุฑ ุงูุชู ฺฉู ุฏุงุณุชุงููุณฺฉ ูฺฏุงู ูุซุจุช ุจู ุฒูุฏฺฏ ุฏุงุดุช\n",
            "ุจู ุงู ุฌููู ุชูุฌู ฺฉูุฏ\n",
            "ุจุงุฏ ุงุฒ ูุงู ูุฑุฏฺฏุงู ุจุฑุฎุฒู\n",
            "ุง ุฌุงุฆ ฺฉู ููุท ฺฉ ูููุฑู ุฏุฑ ุฌุจ ุขูฺฉุณ ุงูุงูููฺ ูุงูุฏู ุจูุฏ ู ุงู ุจุง ุฌุฑุงุช ุจู ุฎุฑุฌ ุฏุงุฏูยู ููุงุฑ ฺฉุฑุฏูยุตุฏ ู ููุชุงุฏ ูููุฑู ุจู ุฏุณุช ุขูุฑุฏ ู ุชุตูู ฺฏุฑูุช ฺฉู ุงุฒ ูุฑุฏุง ุงุฒ ูุงู ูุฑุฏฺฏุงู ุจุฑุฎุฒุฏ\n",
            "ุนู ุงูุฑุบู ุขูฺฉู ุดูุฏู ุจูุฏู ฺฉู ูุฆูุฏูุฑ ุฏุงุณุชุงููุณฺฉ ุฏุงุณุชุงู ููุณ ุจุง ุณุจฺฉ ูพูุฌ ฺฏุฑุงุงูู ุงุณุช\n",
            "ุฏุฑ ุงูุชูุง ุงู ุงุซุฑ ุนุฌุจ ู ุจู ุงุฏ ูุงูุฏู ุฏุฑ ุงูุชู ฺฉู ุฏุงุณุชุงููุณฺฉ ูฺฏุงู ูุซุจุช ุจู ุฒูุฏฺฏ ุฏุงุดุช\n",
            "ุจู ุงู ุฌููู ุชูุฌู ฺฉูุฏ\n",
            "ุจุงุฏ ุงุฒ ูุงู ูุฑุฏฺฏุงู ุจุฑุฎุฒู\n",
            "ุง ุฌุงุฆ ฺฉู ููุท ฺฉ ูููุฑู ุฏุฑ ุฌุจ ุขูฺฉุณ ุงูุงูููฺ ูุงูุฏู ุจูุฏ ู ุงู ุจุง ุฌุฑุงุช ุจู ุฎุฑุฌ ุฏุงุฏูยู ููุงุฑ ฺฉุฑุฏูยุตุฏ ู ููุชุงุฏ ูููุฑู ุจู ุฏุณุช ุขูุฑุฏ ู ุชุตูู ฺฏุฑูุช ฺฉู ุงุฒ ูุฑุฏุง ุงุฒ ูุงู ูุฑุฏฺฏุงู ุจุฑุฎุฒุฏ\n",
            "ูู ุชุฑุฌูู ุณุฑูุด ุญุจุจ ู ุฎุฑุฏู ููุฏููู ุงู ุชุฑุฌูู ุฎูุจู ุง ูุงู ูู\n",
            "ูู ุชุฑุฌูู ุณุฑูุด ุญุจุจ ู ุฎุฑุฏู ููุฏููู ุงู ุชุฑุฌูู ุฎูุจู ุง ูุงู ูู\n",
            "ุชุฑุฌูู ุด ูุฒุฎุฑูู\n",
            "ุชุฑุฌูู ุด ูุฒุฎุฑูู\n",
            "ุนุงูู ุง ฺฉุงุด ุตูุชุด ูู ุฑุงฺฏุงู ุจูุฏ\n",
            "ุนุงูู ุง ฺฉุงุด ุตูุชุด ูู ุฑุงฺฏุงู ุจูุฏ\n",
            "ุฌุงูุจ ู ูุงุจู ุชุงูู ๐\n",
            "ููุณูุฏู ุญุฑุต ู ุทูุน ุ ุบุฑูุฑ ู ุฎูุฏุฎูุงู ุ ุฑุฐุงูุช ู ูพุณุช ู ุนุดู ุฑู ุฏุฑ ุณุงู ู ุจ ุญุณ ุจุง ุทุนู ฺฏุณ ุจู ุชุตูุฑ ฺฉุดุฏู...ูฺฺฏ ูุง ุงูุณุงู ุฎุงุต ุฑู ุจู ููุช ูุง ฺฏููุงฺฏูู ูุณุจุช ุฏุงุฏู ฺฉู ุจู ูุธุฑู ูุดู ุงููุง ุฑู ุชู ูุฑ ุขุฏู ุฏุฏ...ุดุฎุตุช ุชุงุฑฺฉู ุดุฎุตุช ุงุตู ุฏุงุณุชุงู ุฑู ุจ ููุงุจ ุจู ุชุตูุฑ ฺฉุดุฏู ู ุฎูุงููุฏู ุฑู ุจุง ุนูู ุงุนุชุงุฏ ุงูฺฉุณ ุจู ููุงุฑ ุ ุดููุชุด ุจุฑุง ุจุฏุณุช ุขูุฑุฏู ูพูู ู ุฏุฑ ุนู ุญุงู ุนุฏู ุชูุงูุด ูุณุจุช ุจู ูพูู ุฑู ู ุงูฺฉู ฺุฌูุฑ ุชูู ุฏูุฑ ุจุงุทู ุงุฒ ููุงุฑ ุฒูุฏฺฏุด ุฑู ูฺฏุฐุฑููู ูุดูู ูุฏู...\n",
            "ุฌุงูุจ ู ูุงุจู ุชุงูู \n",
            "ููุณูุฏู ุญุฑุต ู ุทูุน ุ ุบุฑูุฑ ู ุฎูุฏุฎูุงู ุ ุฑุฐุงูุช ู ูพุณุช ู ุนุดู ุฑู ุฏุฑ ุณุงู ู ุจ ุญุณ ุจุง ุทุนู ฺฏุณ ุจู ุชุตูุฑ ฺฉุดุฏู...ูฺฺฏ ูุง ุงูุณุงู ุฎุงุต ุฑู ุจู ููุช ูุง ฺฏููุงฺฏูู ูุณุจุช ุฏุงุฏู ฺฉู ุจู ูุธุฑู ูุดู ุงููุง ุฑู ุชู ูุฑ ุขุฏู ุฏุฏ...ุดุฎุตุช ุชุงุฑฺฉู ุดุฎุตุช ุงุตู ุฏุงุณุชุงู ุฑู ุจ ููุงุจ ุจู ุชุตูุฑ ฺฉุดุฏู ู ุฎูุงููุฏู ุฑู ุจุง ุนูู ุงุนุชุงุฏ ุงูฺฉุณ ุจู ููุงุฑ ุ ุดููุชุด ุจุฑุง ุจุฏุณุช ุขูุฑุฏู ูพูู ู ุฏุฑ ุนู ุญุงู ุนุฏู ุชูุงูุด ูุณุจุช ุจู ูพูู ุฑู ู ุงูฺฉู ฺุฌูุฑ ุชูู ุฏูุฑ ุจุงุทู ุงุฒ ููุงุฑ ุฒูุฏฺฏุด ุฑู ูฺฏุฐุฑููู ูุดูู ูุฏู...\n",
            "ุฏูุณุชุงู ูุดู ุจฺฏู ฺฉู ุทุงูฺู ููู ฺฉุชุงุจ ูุงุฑู ุฎูุงุตู ูฺฉูู ูุฐุงุฑู ุง ฺฉุงูู ูู ูุณุชุ\n",
            "ุฏูุณุชุงู ูุดู ุจฺฏู ฺฉู ุทุงูฺู ููู ฺฉุชุงุจ ูุงุฑู ุฎูุงุตู ูฺฉูู ูุฐุงุฑู ุง ฺฉุงูู ูู ูุณุชุ\n",
            "ุงฺฏู ูููุฒ ฺฉุชุงุจู ูุฎููุฏู ูุธุฑ ููู ูฺฏุงู ูฺฉูู..\n",
            "ููุฏููู ฺู ุนูุช ุฏุงุฑู ฺฉู ุฌูุฑ ฺฉู ููุงุฑ ุฑู ุชูุตู ฺฉุฑุฏู ุจูุฏ ุจุงุนุซ ูุดุฏ ููู ูุซู ุดุฎุตุช ุงุตู ูฺฉุฑ ฺฉูู.. ุฌูุฑ ฺฉู ุขุฎุฑ ุฏุงุณุชุงู ฺฉู ูฺฏู ูู ุฏฺฏู ููุงุฑ ููฺฉูู ูุทูุฆูู ฺฉู ุงู ฺฉุงุฑ ุฑู ุงูุฌุงู ูุฏู ฺฉู ูุงูุนุง ุงูุฌุงู ูุฏู ู ุฌุงูุจ ุงู ุฌุงุณุช ฺฉู ููุช ุฎูุฏู ุฑู ุฌุงุด ูุฐุงุฑู ูู ูฺฉุฑ ูฺฉูู ููู ููู ฺฉุงุฑ ุฑู ุงูุฌุงู ูุฏู.. ุญุงูุง ุงู ููฺฉูู ุงุฒ ุถุนู ุดุฎุตุช ุฎูุฏู ุจุงุดู ุง ุงููุฏุฑ ููุณูุฏู ุฎูุจ ุขุฏู ุฑู ุจุง ุงูฺฉุณ ููุฑุงู ฺฉุฑุฏู ฺฉู ูุฏู ุจู ูุฏู ุจุงูุงุด ุจู ููุง ุฑูุชู..\n",
            "ุฏุฑ ุถูู ุงูฺฉุณ ุฎู ูุณุจุช ุจู ุงุทุฑุงูุงูุด ุจุง ุญุฑุต ุตุญุจุช ูฺฉุฑุฏ ู ูฺฉุฑ ูฺฉุฑุฏ ฺฉู ุงุฒ ููู ุจูุชุฑู ู ฺฉุงุฑ ุฎูุฏุด ุขุฎุฑ ุจู ุฌุงูุง ุจุฏุชุฑ ุฑุณุฏ..\n",
            "ูุชุงุณูุงูู ุนุดูุด ุจู ูพูููุง ูู ูู ุชููุง ูุชููุณุช ูุฌุงุชุด ุจุฏู ฺฉู ุจุฏุชุฑ ุงูู ุฑู ูุฑู ุจุฑุฏ.. ุญุช ุขุฎุฑุด ูู ุณุฑ ุนูู ููุฏ ุจูุฏู ุฎุฏุง\n",
            "( ุจุงุฏ ุจฺฏู ูพูููุงู ููุตุฑ ุจูุฏ ฺุฑุง ุงููุฏ ุจุงูุงุด ุจุฏ ุฑูุชุงุฑ ูฺฉุฑุฏุ )\n",
            "ุญุณ ูฺฉูู ูุงุฏุฑุจุฒุฑฺฏ ูู ููุด ุจุฒุฑฺฏ ุชู ุชุบุฑุงุช ุงูฺฉุณ ุฏุงุดุช ุงูฺฏุงุฑ ุงูู ููุน ุฑู ุจูุด ุงูุชูุงู ุฏุงุฏ..\n",
            "ูฺฉุฑ ุฏฺฏู ุง ฺฉู ุฏุงุฑู ุงูู ฺฉู ุงู ูุดฺฉูฺฉ ุจูุฏู ุจู ููู ู ุฏุฏ ุจุฏ ฺฉู ุจู ููู ุฏุงุดุช ูู ุจุงุนุซ ุดุฏ ุฏูุณุช ูุง ูุซู ุขุณุชู ูู ุงุฒุด ุฏูุฑ ุจุดู..\n",
            "ุฏุฑ ฺฉู ุงูฺฏุงุฑ ุชูุงู ุฑุงู ูุง ุฑู ุงุฒ ุฎูุฏุด ฺฏุฑูุช\n",
            "ฺุฒ ฺฉู ุฏุฑฺฉ ูฺฉุฑุฏู ูพุงุฑุณ ุฑูุชู ุจุง ุจูุงูุด ุจูุฏ ฺฉู ุญููุชุง ููููุฏู ูุงุณู ููุณ ุจูุฏ ุง ุนูุฏู ฺุฒ ุฑู ุฏุงุดุช ุง ููุชููุณุช ูพูู ุฏุงุดุชู ุฑู ุชุญูู ฺฉูู ุง ูุฒุงุฑ ุชุง ฺุฒ ุฏฺฏู ฺฉู ูุงูุนุง ูุงูุนุง ููููุฏูุด.. ุงูฺฏุงุฑ ุงู ุชฺฉู ุงุฒ ุดุฎุตุชุด ุฌุฏุง ุจูุฏ.. ุฎูุดุญุงู ูุดู ุงฺฏู ฺฉุณ ุชูุถุญ ุฏุงุฑู ุจฺฏู\n",
            "ุงฺฏู ูููุฒ ฺฉุชุงุจู ูุฎููุฏู ูุธุฑ ููู ูฺฏุงู ูฺฉูู..\n",
            "ููุฏููู ฺู ุนูุช ุฏุงุฑู ฺฉู ุฌูุฑ ฺฉู ููุงุฑ ุฑู ุชูุตู ฺฉุฑุฏู ุจูุฏ ุจุงุนุซ ูุดุฏ ููู ูุซู ุดุฎุตุช ุงุตู ูฺฉุฑ ฺฉูู.. ุฌูุฑ ฺฉู ุขุฎุฑ ุฏุงุณุชุงู ฺฉู ูฺฏู ูู ุฏฺฏู ููุงุฑ ููฺฉูู ูุทูุฆูู ฺฉู ุงู ฺฉุงุฑ ุฑู ุงูุฌุงู ูุฏู ฺฉู ูุงูุนุง ุงูุฌุงู ูุฏู ู ุฌุงูุจ ุงู ุฌุงุณุช ฺฉู ููุช ุฎูุฏู ุฑู ุฌุงุด ูุฐุงุฑู ูู ูฺฉุฑ ูฺฉูู ููู ููู ฺฉุงุฑ ุฑู ุงูุฌุงู ูุฏู.. ุญุงูุง ุงู ููฺฉูู ุงุฒ ุถุนู ุดุฎุตุช ุฎูุฏู ุจุงุดู ุง ุงููุฏุฑ ููุณูุฏู ุฎูุจ ุขุฏู ุฑู ุจุง ุงูฺฉุณ ููุฑุงู ฺฉุฑุฏู ฺฉู ูุฏู ุจู ูุฏู ุจุงูุงุด ุจู ููุง ุฑูุชู..\n",
            "ุฏุฑ ุถูู ุงูฺฉุณ ุฎู ูุณุจุช ุจู ุงุทุฑุงูุงูุด ุจุง ุญุฑุต ุตุญุจุช ูฺฉุฑุฏ ู ูฺฉุฑ ูฺฉุฑุฏ ฺฉู ุงุฒ ููู ุจูุชุฑู ู ฺฉุงุฑ ุฎูุฏุด ุขุฎุฑ ุจู ุฌุงูุง ุจุฏุชุฑ ุฑุณุฏ..\n",
            "ูุชุงุณูุงูู ุนุดูุด ุจู ูพูููุง ูู ูู ุชููุง ูุชููุณุช ูุฌุงุชุด ุจุฏู ฺฉู ุจุฏุชุฑ ุงูู ุฑู ูุฑู ุจุฑุฏ.. ุญุช ุขุฎุฑุด ูู ุณุฑ ุนูู ููุฏ ุจูุฏู ุฎุฏุง\n",
            "( ุจุงุฏ ุจฺฏู ูพูููุงู ููุตุฑ ุจูุฏ ฺุฑุง ุงููุฏ ุจุงูุงุด ุจุฏ ุฑูุชุงุฑ ูฺฉุฑุฏุ )\n",
            "ุญุณ ูฺฉูู ูุงุฏุฑุจุฒุฑฺฏ ูู ููุด ุจุฒุฑฺฏ ุชู ุชุบุฑุงุช ุงูฺฉุณ ุฏุงุดุช ุงูฺฏุงุฑ ุงูู ููุน ุฑู ุจูุด ุงูุชูุงู ุฏุงุฏ..\n",
            "ูฺฉุฑ ุฏฺฏู ุง ฺฉู ุฏุงุฑู ุงูู ฺฉู ุงู ูุดฺฉูฺฉ ุจูุฏู ุจู ููู ู ุฏุฏ ุจุฏ ฺฉู ุจู ููู ุฏุงุดุช ูู ุจุงุนุซ ุดุฏ ุฏูุณุช ูุง ูุซู ุขุณุชู ูู ุงุฒุด ุฏูุฑ ุจุดู..\n",
            "ุฏุฑ ฺฉู ุงูฺฏุงุฑ ุชูุงู ุฑุงู ูุง ุฑู ุงุฒ ุฎูุฏุด ฺฏุฑูุช\n",
            "ฺุฒ ฺฉู ุฏุฑฺฉ ูฺฉุฑุฏู ูพุงุฑุณ ุฑูุชู ุจุง ุจูุงูุด ุจูุฏ ฺฉู ุญููุชุง ููููุฏู ูุงุณู ููุณ ุจูุฏ ุง ุนูุฏู ฺุฒ ุฑู ุฏุงุดุช ุง ููุชููุณุช ูพูู ุฏุงุดุชู ุฑู ุชุญูู ฺฉูู ุง ูุฒุงุฑ ุชุง ฺุฒ ุฏฺฏู ฺฉู ูุงูุนุง ูุงูุนุง ููููุฏูุด.. ุงูฺฏุงุฑ ุงู ุชฺฉู ุงุฒ ุดุฎุตุชุด ุฌุฏุง ุจูุฏ.. ุฎูุดุญุงู ูุดู ุงฺฏู ฺฉุณ ุชูุถุญ ุฏุงุฑู ุจฺฏู\n",
            "ุจุง ุงูฺฉู ููุณูุฏู ุฒูุงู ฺฉู ุจุฑุง ููุดุชู ุงู ฺฉุชุงุจ ฺฏุฐุงุดุชู ุงุณุช ุงูุง ุฑูุงู ุฎูุจ ุงุฒ ฺฉุงุฑ ุฏุฑุขูุฏู ู ุดุฎุตุชโูุง ุจุง ููุชโูุง ูุฎุชูู ุฑุง ุจู ุฎูุจ ุฏุฑ ฺฉูุงุฑ ูู ฺฏูุฌุงูุฏู ุงุณุช.\n",
            "ููุณูุฏู ุงุฒ ูุนูู ุฑูุณ ุง ูโููุณุฏ ฺฉู ุงุนุชุงุฏ ุจู ููุงุฑ ุงู ู ุฒูุฏฺฏโุงุด ุฑุง ุจู ุณูุช ูพูฺ ูุฏุงุช ูโฺฉูุฏ.\n",
            "ุจุง ุงูฺฉู ููุณูุฏู ุฒูุงู ฺฉู ุจุฑุง ููุดุชู ุงู ฺฉุชุงุจ ฺฏุฐุงุดุชู ุงุณุช ุงูุง ุฑูุงู ุฎูุจ ุงุฒ ฺฉุงุฑ ุฏุฑุขูุฏู ู ุดุฎุตุชโูุง ุจุง ููุชโูุง ูุฎุชูู ุฑุง ุจู ุฎูุจ ุฏุฑ ฺฉูุงุฑ ูู ฺฏูุฌุงูุฏู ุงุณุช.\n",
            "ููุณูุฏู ุงุฒ ูุนูู ุฑูุณ ุง ูโููุณุฏ ฺฉู ุงุนุชุงุฏ ุจู ููุงุฑ ุงู ู ุฒูุฏฺฏโุงุด ุฑุง ุจู ุณูุช ูพูฺ ูุฏุงุช ูโฺฉูุฏ.\n",
            "ุงูุงู ฺฉุชุงุจ ฺฉูุฏ ูพุด ูุฑู ุชุง ุฒูุงู ฺฉู ูุงุฏุฑุจุฒุฑฺฏ ูุงุฏ ู ูุฌุงู ุฎุงุต ุฎูุฏุด ุฑู ุจู ุฏุงุณุชุงู ูุฏู. ู ููุฑุฏ ฺฉู ฺฉู ุฏุฏู ุฏูุณุชุงู ุฑุงุฌุจ ฺฉุชุงุจ ุจฺฏู ุงู ุจูุฏ ฺฉู ููุณูุฏู ุฎู ุฎูุจ ุงุฒ ุญุณ ู ุญุงู ููุงุฑ ฺฉุฑุฏู ุจู ูุฎุงุทุจ ุชูุถุญ ูุฏู ุฌูุฑ ฺฉู ุขุฏู ุฎูุฏุดู ุชู ุงูู ุดุฑุงุท ุญุณ ูฺฉูู ู ุงฺฏุฑ ุชุง ุงูุงู ุงู ฺฉุงุฑ ุฑู ูฺฉุฑุฏู ูุชููู ุงุฒ ุณุฑููุดุช ุดุฎุตุช ูุง ุจูููู ฺฉู ฺู ุณุฑุงูุฌุงู ุฑู ุฏูุจุงู ุฏุงุฑู.\n",
            "ุงูุงู ฺฉุชุงุจ ฺฉูุฏ ูพุด ูุฑู ุชุง ุฒูุงู ฺฉู ูุงุฏุฑุจุฒุฑฺฏ ูุงุฏ ู ูุฌุงู ุฎุงุต ุฎูุฏุด ุฑู ุจู ุฏุงุณุชุงู ูุฏู. ู ููุฑุฏ ฺฉู ฺฉู ุฏุฏู ุฏูุณุชุงู ุฑุงุฌุจ ฺฉุชุงุจ ุจฺฏู ุงู ุจูุฏ ฺฉู ููุณูุฏู ุฎู ุฎูุจ ุงุฒ ุญุณ ู ุญุงู ููุงุฑ ฺฉุฑุฏู ุจู ูุฎุงุทุจ ุชูุถุญ ูุฏู ุฌูุฑ ฺฉู ุขุฏู ุฎูุฏุดู ุชู ุงูู ุดุฑุงุท ุญุณ ูฺฉูู ู ุงฺฏุฑ ุชุง ุงูุงู ุงู ฺฉุงุฑ ุฑู ูฺฉุฑุฏู ูุชููู ุงุฒ ุณุฑููุดุช ุดุฎุตุช ูุง ุจูููู ฺฉู ฺู ุณุฑุงูุฌุงู ุฑู ุฏูุจุงู ุฏุงุฑู.\n",
            "ุณูุงู ุฏูุณุชุงู ฺฉ ุณูุงู ุฏุงุดุชู ูู ุชุงุฒู ุนุถู ุทุงูฺู ุดุฏู ูุฎูุงุณุชู ุจุจูู ฺุฌูุฑ ูุดู ุจู ููุงู ุตูุญู  ููุฑุฏ ูุธุฑ ุฑูุชุุุุ\n",
            "ุณูุงู ุฏูุณุชุงู ฺฉ ุณูุงู ุฏุงุดุชู ูู ุชุงุฒู ุนุถู ุทุงูฺู ุดุฏู ูุฎูุงุณุชู ุจุจูู ฺุฌูุฑ ูุดู ุจู ููุงู ุตูุญู  ููุฑุฏ ูุธุฑ ุฑูุชุุุุ\n",
            "ุฌุงูุจ ุจูุฏ! ุงุจุชุฏุงุด ุจู ฺฉูุฏ ูพุด ูุฑูุช ุงูุง ุฏุฑ ุงุฏุงูู ุฌุฐุงุจุช ุจุดุชุฑ ูพุฏุง ฺฉุฑุฏ!\n",
            "ุนุดู ุจ ฺูู ู ฺุฑุง ุงูฺฉุณ ุงูุงูููฺ ุจู ูพูููุง ุนุฌุจ ุจูุฏ! ุญุงูุช ุจู ุนุดู ู ุชููุฑ ฺฉู ูู ูุชููุณุช ุฌููุดู ูุงุณุด ุจุฏู ู ูู ุฌููุดู ุงุฒุด ุจฺฏุฑู! ุงุฎุฑ ฺฉุชุงุจ ู ูฺฏุงู ุงูฺฉุณ ุจู ูพูููุง ู ุฏฺฏุฑู ูู ูุงุจู ุชุงูู ุจูุฏ !\n",
            "ุฌุงูุจ ุจูุฏ! ุงุจุชุฏุงุด ุจู ฺฉูุฏ ูพุด ูุฑูุช ุงูุง ุฏุฑ ุงุฏุงูู ุฌุฐุงุจุช ุจุดุชุฑ ูพุฏุง ฺฉุฑุฏ!\n",
            "ุนุดู ุจ ฺูู ู ฺุฑุง ุงูฺฉุณ ุงูุงูููฺ ุจู ูพูููุง ุนุฌุจ ุจูุฏ! ุญุงูุช ุจู ุนุดู ู ุชููุฑ ฺฉู ูู ูุชููุณุช ุฌููุดู ูุงุณุด ุจุฏู ู ูู ุฌููุดู ุงุฒุด ุจฺฏุฑู! ุงุฎุฑ ฺฉุชุงุจ ู ูฺฏุงู ุงูฺฉุณ ุจู ูพูููุง ู ุฏฺฏุฑู ูู ูุงุจู ุชุงูู ุจูุฏ !\n",
            "ุฏุฑูุฏ ู ุณูพุงุณ ุจฺฉุฑุงู ุนุงู ุจูุฏ ุนุงู\n",
            "ุฏุฑูุฏ ู ุณูพุงุณ ุจฺฉุฑุงู ุนุงู ุจูุฏ ุนุงู\n",
            "ุจุฑุง ุดุฑูุน ุฎูุจ ุจูุฏ ...\n",
            "ุจุฑุง ุดุฑูุน ุฎูุจ ุจูุฏ ...\n",
            "ุฎู ุฒุจุง ุจูุฏ ๐ ฺฉุงููุง ูุงุจู ุฏุฑฺฉ ุจูุฏ ฺฉู ุนุดู ุจู ูพูููุง ุจุงุนุซ ุดุฏ ุฑุงู ููุงุฑ ุจุงุฒ ุจุดู ฺุฒ ุจู ุฌุฒ ูพูููุง ุจุฑุงุด ุงููุช ูุฏุงุดุช\n",
            "ุฎู ุฒุจุง ุจูุฏ  ฺฉุงููุง ูุงุจู ุฏุฑฺฉ ุจูุฏ ฺฉู ุนุดู ุจู ูพูููุง ุจุงุนุซ ุดุฏ ุฑุงู ููุงุฑ ุจุงุฒ ุจุดู ฺุฒ ุจู ุฌุฒ ูพูููุง ุจุฑุงุด ุงููุช ูุฏุงุดุช\n",
            "ุฏุงุณุชุงู ุจู ฺฉูุฏ ูพุด ูุฑู ู ุชูุฑุจุง ุชุง ูุจู ุงุฒ ูุฑูุฏ ูุงุฏุฑุจุฒุฑฺฏุ ุจู ุนูุช ฺฉูุฏ ุงุญุชูุงู ุฑูุง ฺฉุฑุฏู ฺฉุชุงุจ ูุฌูุฏ ุฏุงุฑู.\n",
            "ูู ุจุนุฏ ุงุฒ ูุฑูุฏ ูุงุฏุฑุจุฒุฑฺฏ ุจุณุงุฑ ุฌุฐุงุจ ูุดู.\n",
            "ุฏุงุณุชุงู ุจู ฺฉูุฏ ูพุด ูุฑู ู ุชูุฑุจุง ุชุง ูุจู ุงุฒ ูุฑูุฏ ูุงุฏุฑุจุฒุฑฺฏุ ุจู ุนูุช ฺฉูุฏ ุงุญุชูุงู ุฑูุง ฺฉุฑุฏู ฺฉุชุงุจ ูุฌูุฏ ุฏุงุฑู.\n",
            "ูู ุจุนุฏ ุงุฒ ูุฑูุฏ ูุงุฏุฑุจุฒุฑฺฏ ุจุณุงุฑ ุฌุฐุงุจ ูุดู.\n",
            "ุงู ฺฉุชุงุจ ูุง ฺฉู ุฑูุฒุง ุนุงุฏ ูู ุฑุงฺฏุงู ูุณุชูุฏ. ูุทูุง ุขุฎุฑ ููุชู ูุง ฺูุฏ ุชุง ุงุฒ ฺฉุชุงุจ ูุง ฺฉู ุฑุงฺฏุงู ูุณุชูุฏ ุฑู ุฑุงฺฏุงู ฺฉูุฏ!\n",
            "ุงู ฺฉุชุงุจ ูุง ฺฉู ุฑูุฒุง ุนุงุฏ ูู ุฑุงฺฏุงู ูุณุชูุฏ. ูุทูุง ุขุฎุฑ ููุชู ูุง ฺูุฏ ุชุง ุงุฒ ฺฉุชุงุจ ูุง ฺฉู ุฑุงฺฏุงู ูุณุชูุฏ ุฑู ุฑุงฺฏุงู ฺฉูุฏ!\n",
            "ฺฉุชุงุจ ุฎู ุฎูุจ ุจูุฏ ู ุญุฑุต ู ููุน ุขุฏู ุฒุงุฏ ุฑู ุจู ุฎูุจ ุชูุตู ู ฺฉุฑุฏ ูู ฺฉ ุณุชุงุฑู ูู ุฏู ฺูู ุชุนุตุจ ููุช ุฏุงุดุช\n",
            "ฺฉุชุงุจ ุฎู ุฎูุจ ุจูุฏ ู ุญุฑุต ู ููุน ุขุฏู ุฒุงุฏ ุฑู ุจู ุฎูุจ ุชูุตู ู ฺฉุฑุฏ ูู ฺฉ ุณุชุงุฑู ูู ุฏู ฺูู ุชุนุตุจ ููุช ุฏุงุดุช\n",
            "ุงูุงูุ ุฏุงุณุชุงู ุจุณุงุฑ ฺฉูุฏ ูพุด ูุฑูุช ู ุชุฑุฌูู ูู ฺฉุงุฑ ุฑู ุณุฎุช ุชุฑ ูฺฉุฑุฏ. ุฏุงุณุชุงู ุงุฒ ูุตู 14 ุจู ุจุนุฏ ุจุฑุง ูู ุฌุฐุงุจ ุชุฑ ุดุฏ. ูพุดููุงุฏ ูฺฉูู ุงฺฏุฑ ุชููุณุชุฏ ุชุฑุฌูู ูุง ุฏฺฏุฑ ุฑู ุจุฎููุฏ. ุฏุฑ ฺฉู ฺฉุชุงุจ ุฎูุจู ูู ูุทุนุง ุฌุฒู ุดุงูฺฉุงุฑูุง ุฏุงุณุชุงููุณฺฉ ูุณุช. ุงฺฏุฑ ูุฎูุงุฏ ุฏุงุณุชุงููุณฺฉ ุฑู ุจูุชุฑ ุจุดูุงุณุฏุ ุฌูุงุช ู ูฺฉุงูุงุช ุง ุจุฑุงุฏุฑุงู ฺฉุงุฑุงูุงุฒูู ุฑูุจุฎููุฏ...\n",
            "ุงูุงูุ ุฏุงุณุชุงู ุจุณุงุฑ ฺฉูุฏ ูพุด ูุฑูุช ู ุชุฑุฌูู ูู ฺฉุงุฑ ุฑู ุณุฎุช ุชุฑ ูฺฉุฑุฏ. ุฏุงุณุชุงู ุงุฒ ูุตู 14 ุจู ุจุนุฏ ุจุฑุง ูู ุฌุฐุงุจ ุชุฑ ุดุฏ. ูพุดููุงุฏ ูฺฉูู ุงฺฏุฑ ุชููุณุชุฏ ุชุฑุฌูู ูุง ุฏฺฏุฑ ุฑู ุจุฎููุฏ. ุฏุฑ ฺฉู ฺฉุชุงุจ ุฎูุจู ูู ูุทุนุง ุฌุฒู ุดุงูฺฉุงุฑูุง ุฏุงุณุชุงููุณฺฉ ูุณุช. ุงฺฏุฑ ูุฎูุงุฏ ุฏุงุณุชุงููุณฺฉ ุฑู ุจูุชุฑ ุจุดูุงุณุฏุ ุฌูุงุช ู ูฺฉุงูุงุช ุง ุจุฑุงุฏุฑุงู ฺฉุงุฑุงูุงุฒูู ุฑูุจุฎููุฏ...\n",
            "ูุณุจุช ุจู ุดูุฑุช ฺฉุชุงุจ ู ูุงู ููุณูุฏู ุงูููุฏุฑ ุฏุงุณุชุงู ุจุฑุงู ุฌุฐุงุจ ูุจูุฏ ุชุฑุฌูู ูู ฺฉุงุฑู ุณุฎุช ุชุฑ ฺฉุฑุฏู ุจูุฏ\n",
            "ูุณุจุช ุจู ุดูุฑุช ฺฉุชุงุจ ู ูุงู ููุณูุฏู ุงูููุฏุฑ ุฏุงุณุชุงู ุจุฑุงู ุฌุฐุงุจ ูุจูุฏ ุชุฑุฌูู ูู ฺฉุงุฑู ุณุฎุช ุชุฑ ฺฉุฑุฏู ุจูุฏ\n",
            "ุจู ูุธุฑู ุชุง ูุญุธู ูุฑูุฏ ูุงุฏุฑุจุฒุฑฺฏุ ุฏุงุณุชุงู ููุฏุงุฑ ูุงุณู ฺฉุณู ฺฉููุฏู ุจูุฏ ุญุช ููุงูุน ฺฉู ููุฑูุงู ุฏุงุณุชุงู ุจุง ุดูุฑ ู ุดุนู ุฒุงุฏุงููุตู ุจุง ฺูุฑุงู ู ุงุทุฑุงูุงูุด ุจุญุซ ู ฺฉุฑุฏ ุจู ูุธุฑู ุชูุงุด ูุฐุจูุญุงู ููุณูุฏู ุจุฑุง ูุฌุงู ุงูฺฏุฒ ฺฉุฑุฏู ุฌู ุฏุงุณุชุงู ุจูุฏู ุ ุจุนุฏ ุงุฒ ูุฑูุฏ ูุงุฏุฑุจุฒุฑฺฏ ุฏุงุณุชุงู ุงูุฌ ฺฏุฑูุช.ุฏูู ูุงุณู ููุฑูุงู ุฏุงุณุชุงู ู ุณูุฎุช ุจู ุฏูู ุงุนุชุงุฏ ุจู ููุงุฑ ุงุฒ ุงูู ุจุฏุชุฑ ุชู ฺุทูุฑ ุฏูุช ุงููุฏ ุจุง ุงูู ููู ูพูู ุจุง ุฎุงูู ุจูุงูุด ุจุฑ ูพุงุฑุณุ! ูพููุช ุฑู ุงูฺฉ ุญู ู ูู ฺฉู !! ุชุฑุฌูู ุฑูุงู ูุจูุฏ ุงูุจุชู ููุดู ุฎุฑุฏู ฺฏุฑูุช ฺูู ุฏุฑ ุงูู ุฏูุฑู ุงู ุฌูุฑ ูุซุฑ ูุนููู ุจูุฏู\n",
            "ุจู ูุธุฑู ุชุง ูุญุธู ูุฑูุฏ ูุงุฏุฑุจุฒุฑฺฏุ ุฏุงุณุชุงู ููุฏุงุฑ ูุงุณู ฺฉุณู ฺฉููุฏู ุจูุฏ ุญุช ููุงูุน ฺฉู ููุฑูุงู ุฏุงุณุชุงู ุจุง ุดูุฑ ู ุดุนู ุฒุงุฏุงููุตู ุจุง ฺูุฑุงู ู ุงุทุฑุงูุงูุด ุจุญุซ ู ฺฉุฑุฏ ุจู ูุธุฑู ุชูุงุด ูุฐุจูุญุงู ููุณูุฏู ุจุฑุง ูุฌุงู ุงูฺฏุฒ ฺฉุฑุฏู ุฌู ุฏุงุณุชุงู ุจูุฏู ุ ุจุนุฏ ุงุฒ ูุฑูุฏ ูุงุฏุฑุจุฒุฑฺฏ ุฏุงุณุชุงู ุงูุฌ ฺฏุฑูุช.ุฏูู ูุงุณู ููุฑูุงู ุฏุงุณุชุงู ู ุณูุฎุช ุจู ุฏูู ุงุนุชุงุฏ ุจู ููุงุฑ ุงุฒ ุงูู ุจุฏุชุฑ ุชู ฺุทูุฑ ุฏูุช ุงููุฏ ุจุง ุงูู ููู ูพูู ุจุง ุฎุงูู ุจูุงูุด ุจุฑ ูพุงุฑุณุ! ูพููุช ุฑู ุงูฺฉ ุญู ู ูู ฺฉู !! ุชุฑุฌูู ุฑูุงู ูุจูุฏ ุงูุจุชู ููุดู ุฎุฑุฏู ฺฏุฑูุช ฺูู ุฏุฑ ุงูู ุฏูุฑู ุงู ุฌูุฑ ูุซุฑ ูุนููู ุจูุฏู\n",
            "ุฑูุงู ุฒุจุง ุจูุฏ ูุญุงูุงุช ู ุฑูุญุงุช ฺฉุงุฑุงฺฉุชุฑ ุงุตู ุฏุงุณุชุงู ุฑู ุจู ุฒุจุง ุจุงู ฺฉุฑุฏู ุจูุฏ\n",
            "ุฑูุงู ุฒุจุง ุจูุฏ ูุญุงูุงุช ู ุฑูุญุงุช ฺฉุงุฑุงฺฉุชุฑ ุงุตู ุฏุงุณุชุงู ุฑู ุจู ุฒุจุง ุจุงู ฺฉุฑุฏู ุจูุฏ\n",
            "ูุซุฑุด ุจู ูุธุฑู ุณุฎุช ู ฺฉู ูพฺุฏู ุจูุฏ. ฺฉุณ ุชุฑุฌูู ุฑูุงู ุชุฑ ุณุฑุงุบ ุฏุงุฑู ุ\n",
            "ูุซุฑุด ุจู ูุธุฑู ุณุฎุช ู ฺฉู ูพฺุฏู ุจูุฏ. ฺฉุณ ุชุฑุฌูู ุฑูุงู ุชุฑ ุณุฑุงุบ ุฏุงุฑู ุ\n",
            "ุฎู ุนุงู ุจูุฏ...ุฐูู ุฑู ุฏุฑฺฏุฑ ูฺฉูู ู ูุงุฏุงุฑ ูฺฉูู ฺฉู ุจุง ุฑูุง ฺฉ ูููู ุขูฺฉุณ ุงูุงูฺฉููฺ ูุณุช ุฌุฏุงู ฺฉูุฏ ฺฏุงูุง ููุฑุงูุด ุจุงุดุฏ ู ุขุฎุฑ ุณุฑ ูู ู ุฏูุฑ ุฏฺฏู ุงุฒ ุงูู ุฏุงุณุชุงู ุฑู ุดุฑูุน ฺฉูุฏ...ุฌูุฑุง ูุณูุณู ุงูฺฏุฒ ุจุฑุง ููุงุฑ ฺฉุฑุฏู ูู ุฏุฑ ูููู ุญุงู ุฎูุงููุฏู ุฑู ุจุงุฒูุฏุงุฑู ุงุฒ ูุฑ ููุน ุญุฑฺฉุช...ุนุดู ูพูููุง ู ุขูฺฉุณ ุงูุงูฺฉููฺ ุฑู ูู ุจููุน ุฎุงุต ุชุฑุณู ูฺฉูู ฺฉ ุฏุงุณุชุงู ุฑู ุงุฒ ุจุนุฏ ุนุงุดูุงูู ุจุดุชุฑ ูพฺุฏู ูฺฉูู...\n",
            "ุฎู ุนุงู ุจูุฏ...ุฐูู ุฑู ุฏุฑฺฏุฑ ูฺฉูู ู ูุงุฏุงุฑ ูฺฉูู ฺฉู ุจุง ุฑูุง ฺฉ ูููู ุขูฺฉุณ ุงูุงูฺฉููฺ ูุณุช ุฌุฏุงู ฺฉูุฏ ฺฏุงูุง ููุฑุงูุด ุจุงุดุฏ ู ุขุฎุฑ ุณุฑ ูู ู ุฏูุฑ ุฏฺฏู ุงุฒ ุงูู ุฏุงุณุชุงู ุฑู ุดุฑูุน ฺฉูุฏ...ุฌูุฑุง ูุณูุณู ุงูฺฏุฒ ุจุฑุง ููุงุฑ ฺฉุฑุฏู ูู ุฏุฑ ูููู ุญุงู ุฎูุงููุฏู ุฑู ุจุงุฒูุฏุงุฑู ุงุฒ ูุฑ ููุน ุญุฑฺฉุช...ุนุดู ูพูููุง ู ุขูฺฉุณ ุงูุงูฺฉููฺ ุฑู ูู ุจููุน ุฎุงุต ุชุฑุณู ูฺฉูู ฺฉ ุฏุงุณุชุงู ุฑู ุงุฒ ุจุนุฏ ุนุงุดูุงูู ุจุดุชุฑ ูพฺุฏู ูฺฉูู...\n",
            "ุชุฑุฌูู ุณุฑูุด ุญุจุจ ุฑูุงู ุชุฑ ูุณุช\n",
            "ุชุฑุฌูู ุณุฑูุด ุญุจุจ ุฑูุงู ุชุฑ ูุณุช\n",
            "ุจุจุฎุดุฏ ุดุฎุตุช ุนูู ุฎุงูู ุจูุฏ ุง ูุงุฏุฑ ุจุฒุฑฺฏุ\n",
            "ู ูพูููุง ุฎูุงูุฑ ุฒู ฺูุฑุงู ุจูุฏ ุง ุฏุฎุชุฑ ุฎูุงูุฏุด\n",
            "ุงูุจุชู ูู ุตูุญู  ท ูุณุชู\n",
            "ุจุจุฎุดุฏ ุดุฎุตุช ุนูู ุฎุงูู ุจูุฏ ุง ูุงุฏุฑ ุจุฒุฑฺฏุ\n",
            "ู ูพูููุง ุฎูุงูุฑ ุฒู ฺูุฑุงู ุจูุฏ ุง ุฏุฎุชุฑ ุฎูุงูุฏุด\n",
            "ุงูุจุชู ูู ุตูุญู  ท ูุณุชู\n",
            "ุฑููุงู ุฎู ูู ูุณุช ุขุฏูู ุญุฒุจ ูฺฉูู\n",
            "ุฑููุงู ุฎู ูู ูุณุช ุขุฏูู ุญุฒุจ ูฺฉูู\n",
            "ฺฉุชุงุจ ุฎูุจ ุจูุฏ ู ฺฉูุง ูุฎูุงุฏ ุจฺฏู ููุงุฑ ุจุฏู ู ูุงุจูุฏฺฏุฑ ุฒูุฏฺฏู ูู ุจู ูุธุฑู ุชู ุจุงู ุฎูุฑุฏู ฺุฒ ูุง ุฒุงุฏู ุฑู ุดุฏู ุจูุฏ .... ฺฉุงุด ูุชู ฺฉู ุฑูุงู ุชุฑ ุจูุฏ ู ูพุดููุงุฏ ูู ุงูู ฺฉู ุงูู ุจุฑู ุชู ูฺฉูพุฏุง ุจุง ุงุณุงู ุฏุงุณุชุงู ุงุดูุง ุจุดู ู ุจุนุฏ ฺฉุงุฑุชูู ุฎู ุฑุงุญุช ูุดู ๐\n",
            "ฺฉุชุงุจ ุฎูุจ ุจูุฏ ู ฺฉูุง ูุฎูุงุฏ ุจฺฏู ููุงุฑ ุจุฏู ู ูุงุจูุฏฺฏุฑ ุฒูุฏฺฏู ูู ุจู ูุธุฑู ุชู ุจุงู ุฎูุฑุฏู ฺุฒ ูุง ุฒุงุฏู ุฑู ุดุฏู ุจูุฏ .... ฺฉุงุด ูุชู ฺฉู ุฑูุงู ุชุฑ ุจูุฏ ู ูพุดููุงุฏ ูู ุงูู ฺฉู ุงูู ุจุฑู ุชู ูฺฉูพุฏุง ุจุง ุงุณุงู ุฏุงุณุชุงู ุงุดูุง ุจุดู ู ุจุนุฏ ฺฉุงุฑุชูู ุฎู ุฑุงุญุช ูุดู \n",
            "ุฏุฑฺฏุฑ ุดุฏู ุจุง ุงุณุงู ุฏุงุณุชุงู ุจุงุนุซ ูุดู ุงุฒ ููููู ู ุจุงู ฺฉู ุฏูุฑ ุจุดู. ูุจู ุงุฒ ุดุฑูุน ุจู ุฎูุงูุฏู ฺฉุชุงุจ ุญุชูุง ุฎูุงุตู ุง ุงุฒ ุขู ุจุฎููุฏ๐\n",
            "ุฏุฑฺฏุฑ ุดุฏู ุจุง ุงุณุงู ุฏุงุณุชุงู ุจุงุนุซ ูุดู ุงุฒ ููููู ู ุจุงู ฺฉู ุฏูุฑ ุจุดู. ูุจู ุงุฒ ุดุฑูุน ุจู ุฎูุงูุฏู ฺฉุชุงุจ ุญุชูุง ุฎูุงุตู ุง ุงุฒ ุขู ุจุฎููุฏ\n",
            "ุนู ุจุง ุงู ุชุฑุฌูู... ุณฺฉูุช ฺฉูู ุจูุชุฑู๐ถ\n",
            "ุนู ุจุง ุงู ุชุฑุฌูู... ุณฺฉูุช ฺฉูู ุจูุชุฑู\n",
            "ูุงูุนุง ุจูุชุฑ ูุณุช  ุชุฑูุฌู  ุฑูุงู ุชุฑ ูู ุฒุฏู ุจุดู ุ\n",
            "ูุงูุนุง ุจูุชุฑ ูุณุช  ุชุฑูุฌู  ุฑูุงู ุชุฑ ูู ุฒุฏู ุจุดู ุ\n",
            "ุนุงูู.\n",
            "ุจุงุฏ ุจฺฏู ฺฉู ุฑุฐูุช ูุง ุงุฎูุงู ุฑู ุฎู ุฎูุจ ุจู ุชุตูุฑ ู ฺฉุดู.ุญุณุด ู ฺฉู.ูู ูุณูุณู ุฑู ู ูู ุฒุดุช ุงุด ุฑู. ฺฉู ฺฉ ุงุด ูู ููุงุฑู\n",
            "ฺฉ ุงุฒ ุฏูุณุชุงู ุฑูุงู ุฎููุฏู ฺฏูุช ุฏูุณุช ุฏุงุดุชู ุชุฑู ฺฉุชุงุจ ุฏุงุณุชุงููุณฺฉู\n",
            "ูู ุจู ูุธุฑู ููุฒูุงู ู ฺฉุชุงุจ ุฏฺฏู ฺฉู ูุดูู ุฏููุฏู ูุถูุช ูุง ุงุฎูุงู ูุณุช ุฑู ุจุฎููุฏ ฺฉู ุฒูุฏฺฏ ุจุง ุงู ุดุฎุตุช ูุง ููู ุชุงุซุฑ ุจุฏ ุฒุงุฏ ุชู ุฑูุญู ุชูู ูุฐุงุฑู\n",
            "ูู ููุฒูุงู ฺฉุชุงุจ ยซฺูุฑุงูุ ูุฑุฏ ุจุฑุง ุชูุงู ูุตููยป ุฑู ู ุฎููุฏู\n",
            "ุนุงูู.\n",
            "ุจุงุฏ ุจฺฏู ฺฉู ุฑุฐูุช ูุง ุงุฎูุงู ุฑู ุฎู ุฎูุจ ุจู ุชุตูุฑ ู ฺฉุดู.ุญุณุด ู ฺฉู.ูู ูุณูุณู ุฑู ู ูู ุฒุดุช ุงุด ุฑู. ฺฉู ฺฉ ุงุด ูู ููุงุฑู\n",
            "ฺฉ ุงุฒ ุฏูุณุชุงู ุฑูุงู ุฎููุฏู ฺฏูุช ุฏูุณุช ุฏุงุดุชู ุชุฑู ฺฉุชุงุจ ุฏุงุณุชุงููุณฺฉู\n",
            "ูู ุจู ูุธุฑู ููุฒูุงู ู ฺฉุชุงุจ ุฏฺฏู ฺฉู ูุดูู ุฏููุฏู ูุถูุช ูุง ุงุฎูุงู ูุณุช ุฑู ุจุฎููุฏ ฺฉู ุฒูุฏฺฏ ุจุง ุงู ุดุฎุตุช ูุง ููู ุชุงุซุฑ ุจุฏ ุฒุงุฏ ุชู ุฑูุญู ุชูู ูุฐุงุฑู\n",
            "ูู ููุฒูุงู ฺฉุชุงุจ ยซฺูุฑุงูุ ูุฑุฏ ุจุฑุง ุชูุงู ูุตููยป ุฑู ู ุฎููุฏู\n",
            "ฺฉุชุงุจ ูุง ุงู ููุณูุฏู ููู ุฏุงุฑู ุฎููุฏูุด\n",
            "ฑ: ุฒุงุฏ ุฏุฑ ฺฏุฑ ุงุณููุง ูุดุฏ\n",
            "( ุฑูุณุง ุงุณูุง ูพฺุฏู ุง ุฏุงุฑู)\n",
            "ฒ:ุดุฎุตุช ูุง ุฏุงุณุชุงู ุนูููุง ุฑูุญ ุชุงุฑฺฉ ุฏุงุฑู\n",
            "(ุนู ุดุฎุตุช ูพุฑุฏุงุฒุงุด ูุณูุงุณ ุฏุงุดุชู ุชู ูพุฑุฏุงุฎุชู ุจู ุงููุง)\n",
            "ณ:ูุฑ ูุฏุช ู ููุณ ุนูู ุจฺฉุดุฏ ู ูุญุท ู ุนูุถ ฺฉูุฏ ฺูู ูุงูุนุง ุฏูุงูู ูุดุฏ ุงูุณุฑุฏุชููู ูฺฉูู ุญุชูุง ูฺฉุฑุชููู ูุดุบูู ูฺฉูู\n",
            "ด:ุงุฒ ุญุฌู ุฒุงุฏ ุฏุงุณุชุงู ูุชุฑุณุฏ ุฎู ุชู ูพุฑุฏุงุฎุช ุฏุงุณุชุงู ุฒุงุฏู ุฑู ฺฉุฑุฏู\n",
            "(ฺูุงุฑ ุตูุญู ูุฎูู ุชุงุฒู ุฏุงุดุชู ุญุงูุช ุฏุฑููู ุทุฑูู ุชู ุถุญ ูุฏุงุฏู\n",
            "ุฎูุงุตู ุณุฎุช ูฺฏุฑุฏ ู ุญุงู ฺฉูุฏ ุจุงุด.๐\n",
            "ฺฉุชุงุจ ูุง ุงู ููุณูุฏู ููู ุฏุงุฑู ุฎููุฏูุด\n",
            "ฑ: ุฒุงุฏ ุฏุฑ ฺฏุฑ ุงุณููุง ูุดุฏ\n",
            "( ุฑูุณุง ุงุณูุง ูพฺุฏู ุง ุฏุงุฑู)\n",
            "ฒ:ุดุฎุตุช ูุง ุฏุงุณุชุงู ุนูููุง ุฑูุญ ุชุงุฑฺฉ ุฏุงุฑู\n",
            "(ุนู ุดุฎุตุช ูพุฑุฏุงุฒุงุด ูุณูุงุณ ุฏุงุดุชู ุชู ูพุฑุฏุงุฎุชู ุจู ุงููุง)\n",
            "ณ:ูุฑ ูุฏุช ู ููุณ ุนูู ุจฺฉุดุฏ ู ูุญุท ู ุนูุถ ฺฉูุฏ ฺูู ูุงูุนุง ุฏูุงูู ูุดุฏ ุงูุณุฑุฏุชููู ูฺฉูู ุญุชูุง ูฺฉุฑุชููู ูุดุบูู ูฺฉูู\n",
            "ด:ุงุฒ ุญุฌู ุฒุงุฏ ุฏุงุณุชุงู ูุชุฑุณุฏ ุฎู ุชู ูพุฑุฏุงุฎุช ุฏุงุณุชุงู ุฒุงุฏู ุฑู ฺฉุฑุฏู\n",
            "(ฺูุงุฑ ุตูุญู ูุฎูู ุชุงุฒู ุฏุงุดุชู ุญุงูุช ุฏุฑููู ุทุฑูู ุชู ุถุญ ูุฏุงุฏู\n",
            "ุฎูุงุตู ุณุฎุช ูฺฏุฑุฏ ู ุญุงู ฺฉูุฏ ุจุงุด.\n",
            "ุงู ฺฉุชุงุจ ฺุทูุฑูุูุทูุง ูุธุฑุชูููุจฺฏุฏ.ุงุฑุฒุด ุฎููุฏู ุฏุงุฑูุ\n",
            "ุงู ฺฉุชุงุจ ฺุทูุฑูุูุทูุง ูุธุฑุชูููุจฺฏุฏ.ุงุฑุฒุด ุฎููุฏู ุฏุงุฑูุ\n",
            "ูุง ุฎู ุณุฎุชูู ุงู ฺฉุชุงุจู ุงุฏุงูู ุจุฏู ู ุจุฑ ูฺฏุฑุฏู ุนูุจ.\n",
            "ูุง ุฎู ุณุฎุชูู ุงู ฺฉุชุงุจู ุงุฏุงูู ุจุฏู ู ุจุฑ ูฺฏุฑุฏู ุนูุจ.\n",
            "ูุทูุง ู ฺฉุชุงุจ ุฎูุจ ูุนุฑู ฺฉูุฏ ุชุงุฒู ุณูููู ูุฑุฏฺฏุงู ุฑู ุชููู ฺฉุฑุฏู ุงุฒ ุชู ุจุญุฑุด ุฏุฑ ุจุงู\n",
            "ูุทูุง ู ฺฉุชุงุจ ุฎูุจ ูุนุฑู ฺฉูุฏ ุชุงุฒู ุณูููู ูุฑุฏฺฏุงู ุฑู ุชููู ฺฉุฑุฏู ุงุฒ ุชู ุจุญุฑุด ุฏุฑ ุจุงู\n",
            "ุชุฑุฌูู ูุง ุงุณุชุงุฏ ุขู ุงุญูุฏ ฺฉู ุดูุงุณุช\n",
            "ููุชูุง ุงูู ุฏุงุณุชุงู ฺูู ุจุง ุชุนุฏุงุฏ ุฒุงุฏ ุงุณุงู ูุงุดูุงุณ ุฑูุจุฑู ูุด ุชุฑุบุจ ุจู ุงุฏุงูู ูุทุงูุนู ุตูุฑุช ูู ฺฏุฑู\n",
            "ุชุฑุฌูู ูุง ุงุณุชุงุฏ ุขู ุงุญูุฏ ฺฉู ุดูุงุณุช\n",
            "ููุชูุง ุงูู ุฏุงุณุชุงู ฺูู ุจุง ุชุนุฏุงุฏ ุฒุงุฏ ุงุณุงู ูุงุดูุงุณ ุฑูุจุฑู ูุด ุชุฑุบุจ ุจู ุงุฏุงูู ูุทุงูุนู ุตูุฑุช ูู ฺฏุฑู\n",
            "๐ฅ\n",
            "ู ูพุดููุงุฏ ุจู ุนุฒุฒุงู ฺฉู ูุฎูุงููุฏ ุงู ฺฉุชุงุจ ุฑุง ุจุฎูุงููุฏ ุ ุงู ฺฉุชุงุจ ุชุง ุงูุชูุง ูุตู ด ฺฉู ุญุฏูุฏ ธด ุตูุญู ูุดูุฏ ุ ฺฏูฺฏ ู ฺฉุณู ฺฉููุฏู ุงุณุช ุ ุงู ด ูุตู ุฑุง ุจุฏูู ุชุงูู ู ุจุง ุณุฑุนุช ุจุฎูุงูุฏ ู ุงุฒ ูุตู ต ุจู ุจุนุฏ ุฏุงุณุชุงู ุฑูุงู ูุดูุฏ ู ุฏูฺุณุจ ุฌูุฑ ฺฉู ุฏูุชุงู ููุฎูุงูุฏ ุฑูุงุด ฺฉูุฏ ุุุ ู ุฏุฑ ุงูุชูุง ูุชูุงูุฏ ุงู ด ูุตู ุงูู ุฑุง ุฏูุจุงุฑู ุจุฎูุงูุฏ ุชุง ฺฏูฺฏ ุจูุฏู ุขู ุงุฒ ุจู ุจุฑูุฏ ุ ุฏุฑ ุงู ฺูุงุฑ ูุตู ุงุตูุง ูุนููู ูุณุช ฺฉู ุฑุงู ุฏููุง ฺฉุณุช ุ ูุฑุฏ ุงุณุช ุง ุฒู ุ ู ุงูุฑุงุฏ ุฏฺฏุฑ ูู ฺฏูฺฏ ูุณุชูุฏ ูู ุงุฒ ูุตู ต ุจู ุจุนุฏ ููู ฺ ุฑูุดู ูุดูุฏ ุุุ\n",
            "ุดุฎุตุช ูุง ุฏุงุณุชุงู\n",
            "ฑ- ุงูฺฉุณ ุงูุงูููฺ : ุดุฎุตุช ุงุตู ู ุฑุงู ุฏุงุณุชุงู( ุขููุฒฺฏุงุฑ ุฏู ุจฺู ฺูุฑุงู ฺฉู ฺฉู ุงุฒ ฺฉ ุฎุฏูุชฺฉุงุฑ ูุฏุงุฑุฏ๐ฅ ุงุฑุฒุด ูุนูู ุฏุฑ ูฺฏุงู ุฑูุณ ูุง ุธุงูุฑุง ุฎู ูพุงู ุงุณุช)\n",
            "ฒ- ูพูููุง : ุฏุฎุชุฑ ุฎูุงูุฏู ฺูุฑุงู ฺฉู ูุนุดููู ุงูฺฉุณ ูุณุชุด\n",
            "ณ- ฺูุฑุงู : ูุฑุฏ ุฑูุณ ุชุจุงุฑ ฺฉู ุฎูุฏุจุงุฎุชู ู ูุงู ุจุงุฎุชู ุงุณุช\n",
            "ด- ูุงุฏูุงุฒู ุจูุงูุด : ๐ ุฒู ูุฑุตุช ุทูุจ ู ุฎูุด ฺฏุฐุฑุงู ฺฉู .....\n",
            "ต- ุฏฺฏุฑู ุง ููุงู ูุฑุฏฺฉ ูุฑุงูุณู: ฺฉุณ ฺฉู ฺูุฑุงู ุจู ุงู ููุฑูุถ ุงุณุช ู ุงุณุฑ ุงู ถ- ุจุงุจูุดฺฉุง : ุฎุงูู ฺูุฑุงู ฺฉู ุฎู ุซุฑูุชููุฏ ุงุณุช ู ููู ุจ ุตุจุฑุงูู ููุชุธุฑ ูุฑฺฏุด ูุณุชูุฏ ุชุง ุงุฑุซ ......\n",
            "ท- ูุณุชุฑ ุขุณุชู : ูุฑุฏ ุงูฺฏูุณ .\n",
            ".\n",
            ".\n",
            "ฺฉุชุงุจุณุช ุนุงู ุฏุฑ ูุตู ููุงุฑ ุ ฺฉู ฺู ุจูุงุณุช ุฎุงููุงู ุณูุฒ ฺฉู ุจู ุฑุงุญุช ูุชูุงูุฏ ูู ุชููุง ุฎุงููุงุฏู ุง ุฑุง ุจูฺฉู ุฌุงูุนู ุง ุฑุง ูุชูุงุด ฺฉูุฏ\n",
            "\n",
            "ู ูพุดููุงุฏ ุจู ุนุฒุฒุงู ฺฉู ูุฎูุงููุฏ ุงู ฺฉุชุงุจ ุฑุง ุจุฎูุงููุฏ ุ ุงู ฺฉุชุงุจ ุชุง ุงูุชูุง ูุตู ด ฺฉู ุญุฏูุฏ ธด ุตูุญู ูุดูุฏ ุ ฺฏูฺฏ ู ฺฉุณู ฺฉููุฏู ุงุณุช ุ ุงู ด ูุตู ุฑุง ุจุฏูู ุชุงูู ู ุจุง ุณุฑุนุช ุจุฎูุงูุฏ ู ุงุฒ ูุตู ต ุจู ุจุนุฏ ุฏุงุณุชุงู ุฑูุงู ูุดูุฏ ู ุฏูฺุณุจ ุฌูุฑ ฺฉู ุฏูุชุงู ููุฎูุงูุฏ ุฑูุงุด ฺฉูุฏ ุุุ ู ุฏุฑ ุงูุชูุง ูุชูุงูุฏ ุงู ด ูุตู ุงูู ุฑุง ุฏูุจุงุฑู ุจุฎูุงูุฏ ุชุง ฺฏูฺฏ ุจูุฏู ุขู ุงุฒ ุจู ุจุฑูุฏ ุ ุฏุฑ ุงู ฺูุงุฑ ูุตู ุงุตูุง ูุนููู ูุณุช ฺฉู ุฑุงู ุฏููุง ฺฉุณุช ุ ูุฑุฏ ุงุณุช ุง ุฒู ุ ู ุงูุฑุงุฏ ุฏฺฏุฑ ูู ฺฏูฺฏ ูุณุชูุฏ ูู ุงุฒ ูุตู ต ุจู ุจุนุฏ ููู ฺ ุฑูุดู ูุดูุฏ ุุุ\n",
            "ุดุฎุตุช ูุง ุฏุงุณุชุงู\n",
            "ฑ- ุงูฺฉุณ ุงูุงูููฺ : ุดุฎุตุช ุงุตู ู ุฑุงู ุฏุงุณุชุงู( ุขููุฒฺฏุงุฑ ุฏู ุจฺู ฺูุฑุงู ฺฉู ฺฉู ุงุฒ ฺฉ ุฎุฏูุชฺฉุงุฑ ูุฏุงุฑุฏ ุงุฑุฒุด ูุนูู ุฏุฑ ูฺฏุงู ุฑูุณ ูุง ุธุงูุฑุง ุฎู ูพุงู ุงุณุช)\n",
            "ฒ- ูพูููุง : ุฏุฎุชุฑ ุฎูุงูุฏู ฺูุฑุงู ฺฉู ูุนุดููู ุงูฺฉุณ ูุณุชุด\n",
            "ณ- ฺูุฑุงู : ูุฑุฏ ุฑูุณ ุชุจุงุฑ ฺฉู ุฎูุฏุจุงุฎุชู ู ูุงู ุจุงุฎุชู ุงุณุช\n",
            "ด- ูุงุฏูุงุฒู ุจูุงูุด :  ุฒู ูุฑุตุช ุทูุจ ู ุฎูุด ฺฏุฐุฑุงู ฺฉู .....\n",
            "ต- ุฏฺฏุฑู ุง ููุงู ูุฑุฏฺฉ ูุฑุงูุณู: ฺฉุณ ฺฉู ฺูุฑุงู ุจู ุงู ููุฑูุถ ุงุณุช ู ุงุณุฑ ุงู ถ- ุจุงุจูุดฺฉุง : ุฎุงูู ฺูุฑุงู ฺฉู ุฎู ุซุฑูุชููุฏ ุงุณุช ู ููู ุจ ุตุจุฑุงูู ููุชุธุฑ ูุฑฺฏุด ูุณุชูุฏ ุชุง ุงุฑุซ ......\n",
            "ท- ูุณุชุฑ ุขุณุชู : ูุฑุฏ ุงูฺฏูุณ .\n",
            ".\n",
            ".\n",
            "ฺฉุชุงุจุณุช ุนุงู ุฏุฑ ูุตู ููุงุฑ ุ ฺฉู ฺู ุจูุงุณุช ุฎุงููุงู ุณูุฒ ฺฉู ุจู ุฑุงุญุช ูุชูุงูุฏ ูู ุชููุง ุฎุงููุงุฏู ุง ุฑุง ุจูฺฉู ุฌุงูุนู ุง ุฑุง ูุชูุงุด ฺฉูุฏ\n",
            "ุงุญุชุฑุงู ุฒุงุฏ ุจุฑุง ุขูุง ุฏุงุณุชุงููุณฺฉ ูุงุฆูู ุงูุง ูุชููุณุชู ุฒุงุฏ ุจุง ุงู ฺฉุชุงุจุดูู ุงุฑุชุจุงุท ุจุฑูุฑุงุฑ ฺฉูู ุณุน ู ฺฉูู ฺฉ ุจุงุฑู ุฏฺฏู ุงู ฺฉุชุงุจ ุฑู ูุทุงูุนู ฺฉูู\n",
            "ุงุญุชุฑุงู ุฒุงุฏ ุจุฑุง ุขูุง ุฏุงุณุชุงููุณฺฉ ูุงุฆูู ุงูุง ูุชููุณุชู ุฒุงุฏ ุจุง ุงู ฺฉุชุงุจุดูู ุงุฑุชุจุงุท ุจุฑูุฑุงุฑ ฺฉูู ุณุน ู ฺฉูู ฺฉ ุจุงุฑู ุฏฺฏู ุงู ฺฉุชุงุจ ุฑู ูุทุงูุนู ฺฉูู\n",
            "ุงุฏูู ุชู ุฏุจุฑุณุชุงู ุฎููุฏู ู ุจู ูุนูู ุงุฏุจุงุชููู ุฏุงุฏู ุจุฎูููุฏ ฺฉู ูุฏู ููุณูุฏู ุฑู ุจูููู! ูุฑุตุช ูฺฉุฑุฏูุฏ ุจุฎูููุฏ ู ูููุฒ ูู ููุงุฑุจุงุฒ ุงุฒ ฺฉุชุงุจ ูุงู ฺฉู ุฎู ููููุฏูุด.\n",
            "ุงุฏูู ุชู ุฏุจุฑุณุชุงู ุฎููุฏู ู ุจู ูุนูู ุงุฏุจุงุชููู ุฏุงุฏู ุจุฎูููุฏ ฺฉู ูุฏู ููุณูุฏู ุฑู ุจูููู! ูุฑุตุช ูฺฉุฑุฏูุฏ ุจุฎูููุฏ ู ูููุฒ ูู ููุงุฑุจุงุฒ ุงุฒ ฺฉุชุงุจ ูุงู ฺฉู ุฎู ููููุฏูุด.\n",
            "ููุฏููู ฺุฑุง ุญุณ ูฺฉูู ฺฉู ุงูฺฏุงุฑ ุฏุงุฑู ุชู ุดุฎุตุช ุฏฺฏุฑู ฺฉู ู ูุฑุงูุณูู(ุงุฒ ุงูู ุจู ุนููุงู ู ูุฑุงูุณู ุญูู ฺฏุฑ ู ูฺฉุงุฑ ุงุฏ ูฺฉูู) ุงุบุฑุงู ูฺฉูู ุ\n",
            "ููุฏููู ฺุฑุง ุญุณ ูฺฉูู ฺฉู ุงูฺฏุงุฑ ุฏุงุฑู ุชู ุดุฎุตุช ุฏฺฏุฑู ฺฉู ู ูุฑุงูุณูู(ุงุฒ ุงูู ุจู ุนููุงู ู ูุฑุงูุณู ุญูู ฺฏุฑ ู ูฺฉุงุฑ ุงุฏ ูฺฉูู) ุงุบุฑุงู ูฺฉูู ุ\n",
            "ุณูุงู ูู ุงู ุฑูุงู ุฑู ุฎููุฏู ูู ุจู ูุธุฑู ุฒุงุฏ ุฌุฐุงุจ ูุจูุฏ ููุท ุงุทูุงุนุงุช ุฎูุจ ุฏุฑุจุงุฑู ููุชูุง ูุฎุชูู ฺฉุณุจ ฺฉุฑุฏู ูุซู ููุช ุฑูุณู ุง ูุฑุงูุณู ุงุงูฺฏูุณ\n",
            "ุณูุงู ูู ุงู ุฑูุงู ุฑู ุฎููุฏู ูู ุจู ูุธุฑู ุฒุงุฏ ุฌุฐุงุจ ูุจูุฏ ููุท ุงุทูุงุนุงุช ุฎูุจ ุฏุฑุจุงุฑู ููุชูุง ูุฎุชูู ฺฉุณุจ ฺฉุฑุฏู ูุซู ููุช ุฑูุณู ุง ูุฑุงูุณู ุงุงูฺฏูุณ\n",
            "ุจูุธุฑู ฺฉุชุงุจูุง ุฑูุณ ุฎู ฺฉุณู ฺฉููุฏู ูุณุชูุฏ ู ุชุญููุด ุจุฑุง ูู ุณุฎุชู ูุงูุนุง\n",
            "ุจูุธุฑู ฺฉุชุงุจูุง ุฑูุณ ุฎู ฺฉุณู ฺฉููุฏู ูุณุชูุฏ ู ุชุญููุด ุจุฑุง ูู ุณุฎุชู ูุงูุนุง\n",
            "ุจู ูุธุฑ ูู ุนุงูู\n",
            "ุจู ูุธุฑ ูู ุนุงูู\n",
            "ุณูุงู. ุขุง ฺฉุณ ูุฏููู ฺฉุชุงุจูุง ฺฉ ูุดูู ูฺฉูู ฺฉุฌุง ูุฑู ุฏููุง.?\n",
            "ุณูุงู. ุขุง ฺฉุณ ูุฏููู ฺฉุชุงุจูุง ฺฉ ูุดูู ูฺฉูู ฺฉุฌุง ูุฑู ุฏููุง.?\n",
            "ุขูุง ุชู ุฑู ุฎุฏุง ฺฉ ุจฺฏู ฺุทูุฑ ูุดู ูุฏู ุฏุงุฏ ุชู ุฑู ุฎุฏุงุงุงุง\n",
            "ุฏูู ุงู ฺฉู ุขุง ูุดู ุจุฏูู ุณู ฺฉุงุฑุช ุงุฒ ุทุงูฺู ุงุณุชูุงุฏู ฺฉุฑุฏุุฎ\n",
            "ุขูุง ุชู ุฑู ุฎุฏุง ฺฉ ุจฺฏู ฺุทูุฑ ูุดู ูุฏู ุฏุงุฏ ุชู ุฑู ุฎุฏุงุงุงุง\n",
            "ุฏูู ุงู ฺฉู ุขุง ูุดู ุจุฏูู ุณู ฺฉุงุฑุช ุงุฒ ุทุงูฺู ุงุณุชูุงุฏู ฺฉุฑุฏุุฎ\n",
            "Mehdi Tamadon Rastegar\n",
            "ุฏุฑุจุงุฑู ุงูุณุงููุง ุญุฑุต ุงุณุช ฺฉู ุฎุงฺฉ ฺฏูุฑ ุทูุน ุขููุง ุฑุง ฺฉู ฺฉูุฏ.ุฎูุจ ุดุฎุตุช ูพุฑุฏุงุฒ ฺฉุฑุฏู ุงุณุช.\n",
            "Mehdi Tamadon Rastegar\n",
            "ุฏุฑุจุงุฑู ุงูุณุงููุง ุญุฑุต ุงุณุช ฺฉู ุฎุงฺฉ ฺฏูุฑ ุทูุน ุขููุง ุฑุง ฺฉู ฺฉูุฏ.ุฎูุจ ุดุฎุตุช ูพุฑุฏุงุฒ ฺฉุฑุฏู ุงุณุช.\n",
            "ุฎู ุฎูุจ ุดุฎุตุช ูพุฑุฏุงุฒ ูฺฉูู\n",
            "ุฎู ุฎูุจ ุดุฎุตุช ูพุฑุฏุงุฒ ูฺฉูู\n",
            "ุนุงู๐\n",
            "ุดุฎุตุช ูพุฑุฏุงุฒ ฺฉู ุญุฑู ูุฏุงุดุช\n",
            "ุนุงู\n",
            "ุดุฎุตุช ูพุฑุฏุงุฒ ฺฉู ุญุฑู ูุฏุงุดุช\n",
            "ููููู ุงุฒ ูุงุดุฑ ฺฉู ุงู ููุณุฎู ุฑู ุฑุงฺฏุงู ฺฏุฐุงุดุช\n",
            "ููููู ุงุฒ ูุงุดุฑ ฺฉู ุงู ููุณุฎู ุฑู ุฑุงฺฏุงู ฺฏุฐุงุดุช\n",
            "ุฒุงุฏุฌุฐุงุจ ูุจูุฏ\n",
            "ุฒุงุฏุฌุฐุงุจ ูุจูุฏ\n",
            "ุจุจุฎุดุฏ ู ฺฉุชุงุจ ุฎูุจ ุจู ูู ูุนุฑู ู ฺฉูุฏ ุุุ\n",
            "ุจุจุฎุดุฏ ู ฺฉุชุงุจ ุฎูุจ ุจู ูู ูุนุฑู ู ฺฉูุฏ ุุุ\n",
            "ุจู ูุธุฑ ูู ุฌุฐุงุจ ุจูุฏ\n",
            "ุจู ูุธุฑ ูู ุฌุฐุงุจ ุจูุฏ\n",
            "ุชูุฑุจุง ุชุง ููู  ฺฉุชุงุจ ุฌุฐุงุจ ูุจูุฏุ ุจุนุฏ ุงุฒ ุงูู ูู ฺฉุดุด ุฒุงุฏ ูุฏุงุดุช.\n",
            "ุชูุฑุจุง ุชุง ููู  ฺฉุชุงุจ ุฌุฐุงุจ ูุจูุฏุ ุจุนุฏ ุงุฒ ุงูู ูู ฺฉุดุด ุฒุงุฏ ูุฏุงุดุช.\n",
            "ฺฉุฌุง ุญุงูุธู ฺฏูุด ูุชููู ุจู ฺฉุชุงุจ ุฏุณุชุฑุณ ุฏุงุดุชู ุจุงุดู ุ ูโุฎูุงู ุชุจุฏู ฺฉูู ุจูุฑุณุชู ุฑู ฺฉุชุงุจุฎูุงู ฺฉูุฏู ุงู\n",
            "ฺฉุฌุง ุญุงูุธู ฺฏูุด ูุชููู ุจู ฺฉุชุงุจ ุฏุณุชุฑุณ ุฏุงุดุชู ุจุงุดู ุ ูโุฎูุงู ุชุจุฏู ฺฉูู ุจูุฑุณุชู ุฑู ฺฉุชุงุจุฎูุงู ฺฉูุฏู ุงู\n",
            "ฺฉุชุงุจ ุฌุฐุงุจ ุจูุฏ ฺูู ุชุง ุงูุงุณุท ฺฉุชุงุจ ุดุฎุต ุงูู ูุดุฎุต ูุจูุฏ ฺฉู ฺฏุฌ ฺฉููุฏู ุจูุฏ ูู ุฏุฑ ฺฉู ุฎูุจ ุจูุฏ\n",
            "ฺฉุชุงุจ ุฌุฐุงุจ ุจูุฏ ฺูู ุชุง ุงูุงุณุท ฺฉุชุงุจ ุดุฎุต ุงูู ูุดุฎุต ูุจูุฏ ฺฉู ฺฏุฌ ฺฉููุฏู ุจูุฏ ูู ุฏุฑ ฺฉู ุฎูุจ ุจูุฏ\n",
            "ุฎูุฏ ฺฉุชุงุจ ุฏุงุณุชุงู ุฌุฐุงุจ ูุฏุงุดุช ู ุชุฑุฌูู ุฌูุงู ฺฉุงุฑ ุฑู ุจุฏุชุฑ ฺฉุฑุฏู ุจูุฏ\n",
            "ุฎูุฏ ฺฉุชุงุจ ุฏุงุณุชุงู ุฌุฐุงุจ ูุฏุงุดุช ู ุชุฑุฌูู ุฌูุงู ฺฉุงุฑ ุฑู ุจุฏุชุฑ ฺฉุฑุฏู ุจูุฏ\n",
            "ู ุฌุงูุงุด ุฎูุจ ุจูุฏ ุ ูู ุฎุณุชู ฺฉููุฏู ุจูุฏ ุ ุฌุฐุงุจุชุด ุฎู ฺฉู ุจูุฏ .\n",
            "ู ุฌุงูุงุด ุฎูุจ ุจูุฏ ุ ูู ุฎุณุชู ฺฉููุฏู ุจูุฏ ุ ุฌุฐุงุจุชุด ุฎู ฺฉู ุจูุฏ .\n",
            "ูพุงุงู ุนุฌุจ ุ ุญุณ ุนุฌุจ ู ุนุดู ุนุฌุจ ฺฉุชุงุจ ฺฉู ุจู ูุฑ ฺฉุณ ูุชูุงูุฏ ูููุนุช ุฒูุงู ุฑุง ฺฉู ุฏุงุณุชุงูุณฺฉ ุฎูุงุณุชุงุฑ ุชูููุด ุจู ูุฎุงุทุจ ุจูุฏู ุฑุง ููุชูู ฺฉูุฏ.\n",
            "ูู ุงูุงู ุงุฒ ุชุฑุฌูู  ุฌูุงู ุขู ุงุญูุฏ :|\n",
            "ูพุงุงู ุนุฌุจ ุ ุญุณ ุนุฌุจ ู ุนุดู ุนุฌุจ ฺฉุชุงุจ ฺฉู ุจู ูุฑ ฺฉุณ ูุชูุงูุฏ ูููุนุช ุฒูุงู ุฑุง ฺฉู ุฏุงุณุชุงูุณฺฉ ุฎูุงุณุชุงุฑ ุชูููุด ุจู ูุฎุงุทุจ ุจูุฏู ุฑุง ููุชูู ฺฉูุฏ.\n",
            "ูู ุงูุงู ุงุฒ ุชุฑุฌูู  ุฌูุงู ุขู ุงุญูุฏ :|\n",
            "ุขุซุงุฑ ููุณูุฏู ูุง ุฑูุณ ููู ุงูุนุงุฏู ุงุณ\n",
            "ุขุซุงุฑ ููุณูุฏู ูุง ุฑูุณ ููู ุงูุนุงุฏู ุงุณ\n",
            "ุงฺฏู ูุดู ุฏุฑ ุฑูพูุง ุงู ูพุงู ุฏุฑ ููุฑุฏ ูพุงุงูุด ูุธุฑ ุจุฏู. ููููู๐\n",
            "ุงฺฏู ูุดู ุฏุฑ ุฑูพูุง ุงู ูพุงู ุฏุฑ ููุฑุฏ ูพุงุงูุด ูุธุฑ ุจุฏู. ููููู\n",
            "๐ฃ๐ฃ๐ฃ ุฎุทุฑ ูู ุฑูุชู ๐ฃ๐ฃ๐ฃ\n",
            "ุขูฺฉุณ ุงูุงููฺ ูุนูู ุณุฑุฎุงูู  ุจฺู ูุง ฺูุฑุงู ุงุณุชุ ู ุจู ุตูุฑุช ุจุณุงุฑ ูุงฺฏูุงู ุนุงุดู ูพูููุง ุฏุฎุชุฑุฎูุงูุฏู  ฺูุฑุงู ู ุดูุฏ.\n",
            "ุขูฺฉุณ ุงูุงููฺ ุจุง ุญุฑู ูพูููุง ุดุฑูุน ุจู ููุงุฑ ู ฺฉูุฏ ู ุฏุฑ ูุฌู ูุฑู ู ุฑูุฏ ู ูุฑุจุงุฑ ุญุฑุต ุชุฑ ุงุฒ ุจุงุฑ ูุจู ู ุดูุฏ.\n",
            "ุขูฺฉุณ ุฏุฑ ุขุฎุฑ ุชุตูู ู ฺฏุฑุฏ ุจู ุฎุงุทุฑ ูพูููุง ููุงุฑ ุฑุง ฺฉูุงุฑ ุจฺฏุฐุงุฑุฏ ุงูุงุฏุฑ ุณุทูุฑ ูพุงุงู ููุณูุฏู ุดูฺฉ ุจุณุงุฑ ุจุฒุฑฺฏ ุจุฑ ูุฎุงุทุจ ูุงุฑุฏ ู ฺฉูุฏ.\n",
            "๐ฃ๐ฃ๐ฃ๐ฃ๐ฃ\n",
            "ุจุฑุฎูุงู ุดุฑูุน ุจุณุงุฑ ฺฉุณู ฺฉููุฏู  ุฏุงุณุชุงู ุจู ูุธุฑู ุฌูุน ุจูุฏ ู ูพุงุงู ุจุณุงุฑ ุฎูุจ ุฏุงุดุช ุจู ุทูุฑ ฺฉู ุฎูุงููุฏู ุจุณุงุฑ ุบุงูู ฺฏุฑ ู ุดุฏ.\n",
            "ุนุดู ุขูฺฉุณ ุจู ูพูููุง ุจุณุงุฑ ุนุฌุจ ู ุบุฑ ูุงุจู ุจุงูุฑ ุจู ูุธุฑ ู ุขูุฏ.\n",
            "ูุซุฑ ฺฉุชุงุจ ุฑูุงู ูุจูุฏ ฺฉู ูุทุนุง ุชุฑุฌูู ุฏุฑ ุขู ุฏุฎู ุงุณุช ู ุดุงุฏ ฺฉ ุงุฒ ุนูู ฺฉุณู ฺฉููุฏู ุจูุฏู ุงูุงู ุฑูุงู ููู ุจุงุดุฏ.\n",
            "ุฏุฑ ฺฉู ุฎูุจ ุจูุฏ ุฎูุดุญุงูู ฺฉ ฺฉุชุงุจ ุฑูุณ ุจุงุนุซ ุดุฏ ูู ุงุฏ ุขู  ูุฑุขู ุจูุชู.\n",
            "\"ุงุฒ ุชู ุฏุฑุจุงุฑู  ุดุฑุงุจ ู ููุงุฑ ู ูพุฑุณูุฏ ุจฺฏู ุฏุฑ ุขููุง ฺฏูุงู ูุถุฑุฑ ุจุฒุฑฺฏ ูุฌูุฏ ุฏุงุฑุฏ ู ููุงูุน ูุฒ ุจุฑุง ูุฑุฏู ุฏุฑ ุจุฑุฏุงุฑูุฏ ูู ุถุฑุฑ ุขููุง ุจุดุชุฑ ุงุฒ ููุนุดุงู ุงุณุช\" ุจูุฑู ฒฑน\n",
            " ุฎุทุฑ ูู ุฑูุชู \n",
            "ุขูฺฉุณ ุงูุงููฺ ูุนูู ุณุฑุฎุงูู  ุจฺู ูุง ฺูุฑุงู ุงุณุชุ ู ุจู ุตูุฑุช ุจุณุงุฑ ูุงฺฏูุงู ุนุงุดู ูพูููุง ุฏุฎุชุฑุฎูุงูุฏู  ฺูุฑุงู ู ุดูุฏ.\n",
            "ุขูฺฉุณ ุงูุงููฺ ุจุง ุญุฑู ูพูููุง ุดุฑูุน ุจู ููุงุฑ ู ฺฉูุฏ ู ุฏุฑ ูุฌู ูุฑู ู ุฑูุฏ ู ูุฑุจุงุฑ ุญุฑุต ุชุฑ ุงุฒ ุจุงุฑ ูุจู ู ุดูุฏ.\n",
            "ุขูฺฉุณ ุฏุฑ ุขุฎุฑ ุชุตูู ู ฺฏุฑุฏ ุจู ุฎุงุทุฑ ูพูููุง ููุงุฑ ุฑุง ฺฉูุงุฑ ุจฺฏุฐุงุฑุฏ ุงูุงุฏุฑ ุณุทูุฑ ูพุงุงู ููุณูุฏู ุดูฺฉ ุจุณุงุฑ ุจุฒุฑฺฏ ุจุฑ ูุฎุงุทุจ ูุงุฑุฏ ู ฺฉูุฏ.\n",
            "\n",
            "ุจุฑุฎูุงู ุดุฑูุน ุจุณุงุฑ ฺฉุณู ฺฉููุฏู  ุฏุงุณุชุงู ุจู ูุธุฑู ุฌูุน ุจูุฏ ู ูพุงุงู ุจุณุงุฑ ุฎูุจ ุฏุงุดุช ุจู ุทูุฑ ฺฉู ุฎูุงููุฏู ุจุณุงุฑ ุบุงูู ฺฏุฑ ู ุดุฏ.\n",
            "ุนุดู ุขูฺฉุณ ุจู ูพูููุง ุจุณุงุฑ ุนุฌุจ ู ุบุฑ ูุงุจู ุจุงูุฑ ุจู ูุธุฑ ู ุขูุฏ.\n",
            "ูุซุฑ ฺฉุชุงุจ ุฑูุงู ูุจูุฏ ฺฉู ูุทุนุง ุชุฑุฌูู ุฏุฑ ุขู ุฏุฎู ุงุณุช ู ุดุงุฏ ฺฉ ุงุฒ ุนูู ฺฉุณู ฺฉููุฏู ุจูุฏู ุงูุงู ุฑูุงู ููู ุจุงุดุฏ.\n",
            "ุฏุฑ ฺฉู ุฎูุจ ุจูุฏ ุฎูุดุญุงูู ฺฉ ฺฉุชุงุจ ุฑูุณ ุจุงุนุซ ุดุฏ ูู ุงุฏ ุขู  ูุฑุขู ุจูุชู.\n",
            "\"ุงุฒ ุชู ุฏุฑุจุงุฑู  ุดุฑุงุจ ู ููุงุฑ ู ูพุฑุณูุฏ ุจฺฏู ุฏุฑ ุขููุง ฺฏูุงู ูุถุฑุฑ ุจุฒุฑฺฏ ูุฌูุฏ ุฏุงุฑุฏ ู ููุงูุน ูุฒ ุจุฑุง ูุฑุฏู ุฏุฑ ุจุฑุฏุงุฑูุฏ ูู ุถุฑุฑ ุขููุง ุจุดุชุฑ ุงุฒ ููุนุดุงู ุงุณุช\" ุจูุฑู ฒฑน\n",
            "ูุดูฺฏู ุฑุชูุด ุณุฑุนู ูุฑฺู ุจฺฏุฐุฑู ุฌุฐุงุจ ุชุฑ ูุดู ูพุดููุงุฏ ูุดูุฏ !\n",
            "ูุดูฺฏู ุฑุชูุด ุณุฑุนู ูุฑฺู ุจฺฏุฐุฑู ุฌุฐุงุจ ุชุฑ ูุดู ูพุดููุงุฏ ูุดูุฏ !\n",
            "ุฎูุจ ุจูุฏ ุงูุงู ุฏุงุณุชุงู ุฌุฐุงุจ ูุจูุฏ ฺฉู ฺฉู ุฌุฐุงุจุช ุฏุงุณุชุงู ุฒุงุฏ ุดุฏ ู ูุณูุช ุงุฎุฑ ุฏุงุณุชุงู ุฑู ููุณูุฏู ุฒูุฏ ุฌูุน ฺฉุฑุฏ\n",
            "ุฎูุจ ุจูุฏ ุงูุงู ุฏุงุณุชุงู ุฌุฐุงุจ ูุจูุฏ ฺฉู ฺฉู ุฌุฐุงุจุช ุฏุงุณุชุงู ุฒุงุฏ ุดุฏ ู ูุณูุช ุงุฎุฑ ุฏุงุณุชุงู ุฑู ููุณูุฏู ุฒูุฏ ุฌูุน ฺฉุฑุฏ\n",
            "ุฌุฐุงุจ ุจูุฏ ูุฑุณ\n",
            "ุฌุฐุงุจ ุจูุฏ ูุฑุณ\n",
            "ุฎูุจ ุจูุฏ ูู ฺูู ุฏุงุณุชุงููุณฺฉ ุงู ฺฉุชุงุจู ุจุง ุนุฌูู ููุดุชู (ุงฺฏู ุฏูุช ฺฉูู ุงุดุงุฑู ุดุฏู) ูฺฏุงุฑุด ูุนููู ุฏุงุดุช ูู ุฏุฑ ฺฉู ุจุฏ ูุจูุฏ\n",
            "ุฎูุจ ุจูุฏ ูู ฺูู ุฏุงุณุชุงููุณฺฉ ุงู ฺฉุชุงุจู ุจุง ุนุฌูู ููุดุชู (ุงฺฏู ุฏูุช ฺฉูู ุงุดุงุฑู ุดุฏู) ูฺฏุงุฑุด ูุนููู ุฏุงุดุช ูู ุฏุฑ ฺฉู ุจุฏ ูุจูุฏ\n",
            "ุฑุณฺฉ ูพุฐุฑูู ุจุงูุง ุจุฑุฏ๐\n",
            "ุฑุณฺฉ ูพุฐุฑูู ุจุงูุง ุจุฑุฏ\n",
            "ุฒุจุง ุจูุฏ ู ุงูุจุชู ุงููุฒูุฏู\n",
            "ุฒุจุง ุจูุฏ ู ุงูุจุชู ุงููุฒูุฏู\n",
            "ุฎููุฏู ู ุจุณุงุฑ ุฌุฐุงุจ ู ุดุฑู ุจูุฏ ุนู ุงูุฎุตูุต ฺฉู ุฏุงุณุชุงู ูุงูุนู ุฎูุฏ ููุณูุฏุณุช\n",
            "ุฎููุฏู ู ุจุณุงุฑ ุฌุฐุงุจ ู ุดุฑู ุจูุฏ ุนู ุงูุฎุตูุต ฺฉู ุฏุงุณุชุงู ูุงูุนู ุฎูุฏ ููุณูุฏุณุช\n",
            "ุชุงุฒู ุดุฑูุน ฺฉุฑุฏู ุจุฎูููุด ฑฐ ุตูุญู ุงูู ุฑู ุฎููุฏู ูุนูุง ฺุฒ ุงุฒุด ููููุฏู ุฎุฎุฎุฎ ูุซู ุงุจุชุฏุง ุณุฑุงููุง ุงุฑุงู ูุณุช ุชุง ูุฎูุงุฏ ุฑุงู ุจูุชู ฺฉู ุทูู ูฺฉุดู ุฏุฑูุงูุน ุฏุงุฑู ุชุงุช ุชุงุช ูฺฉูู ุฎุฎุฎุฎ\n",
            "ุชุงุฒู ุดุฑูุน ฺฉุฑุฏู ุจุฎูููุด ฑฐ ุตูุญู ุงูู ุฑู ุฎููุฏู ูุนูุง ฺุฒ ุงุฒุด ููููุฏู ุฎุฎุฎุฎ ูุซู ุงุจุชุฏุง ุณุฑุงููุง ุงุฑุงู ูุณุช ุชุง ูุฎูุงุฏ ุฑุงู ุจูุชู ฺฉู ุทูู ูฺฉุดู ุฏุฑูุงูุน ุฏุงุฑู ุชุงุช ุชุงุช ูฺฉูู ุฎุฎุฎุฎ\n",
            "ฺู ุฏุงุณุชุงูุ ุชูุตู ูฺฉูู ุญุชูุง ุจุฎููุฏ . ุงููุด ุฑู ุทุงูุช ุจุงุฑู ุ ุฏฺฏู ุฏูุณุช ูุฎูุงูุฏ ุฏุงุดุช ุชููู ุจุดู . ุชุฑุฌูู ุนุงู . ููู ฺ ุนุงู ุฎู ุฎูุจู ุงู ฺฉุชุงุจ\n",
            "ฺู ุฏุงุณุชุงูุ ุชูุตู ูฺฉูู ุญุชูุง ุจุฎููุฏ . ุงููุด ุฑู ุทุงูุช ุจุงุฑู ุ ุฏฺฏู ุฏูุณุช ูุฎูุงูุฏ ุฏุงุดุช ุชููู ุจุดู . ุชุฑุฌูู ุนุงู . ููู ฺ ุนุงู ุฎู ุฎูุจู ุงู ฺฉุชุงุจ\n",
            "ุงูุงู ุฏุงุณุชุงู ฺฉู ฺฉูุฏ ูพุด ูุฑู ูู ุจุนุฏุด ุฎูุจ ูุดู ููุฒุฏฺฉ ุจู ูพุงุงู ุฏุงุณุชุงู ฺฉู ููุด ุฏูุณุช ุฏุงุดุชู ุจุจูู ฺ ูุดู ุ ูพูุฌุงู ุตูุญู ุงุฎุฑ ู ฺฉ ุฌุง ุฎููุฏู ู ฺฉู ูุฐุช ุจุฑุฏู.. ุชุฑุฌูู ูู ุฎูุจ ุจูุฏ ูู ูุฐุช ุจุฑุฏู ุฏุฑฺฉู...ููููู ุงุฒ ุทุงูฺู\n",
            "ุงูุงู ุฏุงุณุชุงู ฺฉู ฺฉูุฏ ูพุด ูุฑู ูู ุจุนุฏุด ุฎูุจ ูุดู ููุฒุฏฺฉ ุจู ูพุงุงู ุฏุงุณุชุงู ฺฉู ููุด ุฏูุณุช ุฏุงุดุชู ุจุจูู ฺ ูุดู ุ ูพูุฌุงู ุตูุญู ุงุฎุฑ ู ฺฉ ุฌุง ุฎููุฏู ู ฺฉู ูุฐุช ุจุฑุฏู.. ุชุฑุฌูู ูู ุฎูุจ ุจูุฏ ูู ูุฐุช ุจุฑุฏู ุฏุฑฺฉู...ููููู ุงุฒ ุทุงูฺู\n",
            "ุจุฑุง ูู ุฌุฐุงุจ ูุจูุฏ๐\n",
            "ุจุฑุง ูู ุฌุฐุงุจ ูุจูุฏ\n",
            "ุงู ฺฉุชุงุจ ุฑู ุณุงู ฺฏุฐุดุชู ุฎููุฏู ู ูุฐุช ุจุฑุฏู ุ ุจุณุงุฑ ุฒุจุง ู ุฎูุงูุฏู\n",
            "ุงู ฺฉุชุงุจ ุฑู ุณุงู ฺฏุฐุดุชู ุฎููุฏู ู ูุฐุช ุจุฑุฏู ุ ุจุณุงุฑ ุฒุจุง ู ุฎูุงูุฏู\n",
            "ุจุณุงุฑ ุนุงู ู ุฒุจุงุณุช...\n",
            "ุจุณุงุฑ ุนุงู ู ุฒุจุงุณุช...\n",
            "ฺฉุณู ฺฉููุฏู ุจูุฏ\n",
            "ฺฉุณู ฺฉููุฏู ุจูุฏ\n",
            "ุชุฑุฌูู ุงู ุงุซุฑ ุงุตูุง ุฌุงูุจ ูุณุช\n",
            "ุชุฑุฌูู ุงู ุงุซุฑ ุงุตูุง ุฌุงูุจ ูุณุช\n",
            "ุชุง ุญุงูุง ุงุฒุด ฺฉุชุงุจ ูุฎููุฏูุ ุงุฒ ุงุดุชุงู ุจฺฉ ู ููฺฏู ู ูููฺฏู ฺฉุชุงุจ ูุง ุฎูุงูุฏู ุงู ุงูุง ุงุฒ ุฑูุณู ูฺ ูุฎูุงูุฏู ุงู.\n",
            "ุชุง ุญุงูุง ุงุฒุด ฺฉุชุงุจ ูุฎููุฏูุ ุงุฒ ุงุดุชุงู ุจฺฉ ู ููฺฏู ู ูููฺฏู ฺฉุชุงุจ ูุง ุฎูุงูุฏู ุงู ุงูุง ุงุฒ ุฑูุณู ูฺ ูุฎูุงูุฏู ุงู.\n",
            "ุฏุงุณุชุงููุณฺฉ ุฏุฑุญุฏู ฺฉู ูุดู ูพุฑุณุชุฏุด!ูุนูุชโค\n",
            "ุฏุงุณุชุงููุณฺฉ ุฏุฑุญุฏู ฺฉู ูุดู ูพุฑุณุชุฏุด!ูุนูุช\n",
            "ุดุงูฺฉุงุฑู ุงู ฺฉุชุงุจ ุฏุฑ ููุงุช ุณุงุฏฺฏ ฺูุงู ูุดฺฉู ูุฌุน ุฑู ุฏุฑ ุฒูุฏฺฏ ุขุฏู ูุทุฑุญ ูฺฉูู. ูุงูุนุง ฺฉุชุงุจ ุณุงุฏู ู ุนููู๐\n",
            "ุดุงูฺฉุงุฑู ุงู ฺฉุชุงุจ ุฏุฑ ููุงุช ุณุงุฏฺฏ ฺูุงู ูุดฺฉู ูุฌุน ุฑู ุฏุฑ ุฒูุฏฺฏ ุขุฏู ูุทุฑุญ ูฺฉูู. ูุงูุนุง ฺฉุชุงุจ ุณุงุฏู ู ุนููู\n",
            "ูุฑ ฺฉุชุงุจ ุงุฒ ููู ุชุฑู ุจุฎุด ูุงุด ุงูู ุฏุงุณุชุงูู ุงูุง ูุงูุนุง ุงูู ุฏุงุณุชุงู ุจุณุงุฑ ฺฉุณู ฺฉููุฏู ู ฺฏูฺฏู . ุงุฒ ุฎููุฏู ุจูู ุฏุงุณุชุงู ุงุฏู ุฑู ููุตุฑู ูฺฉูู\n",
            "ูุฑ ฺฉุชุงุจ ุงุฒ ููู ุชุฑู ุจุฎุด ูุงุด ุงูู ุฏุงุณุชุงูู ุงูุง ูุงูุนุง ุงูู ุฏุงุณุชุงู ุจุณุงุฑ ฺฉุณู ฺฉููุฏู ู ฺฏูฺฏู . ุงุฒ ุฎููุฏู ุจูู ุฏุงุณุชุงู ุงุฏู ุฑู ููุตุฑู ูฺฉูู\n",
            "ุทุงูฺู ุฏูุช ฺฏุฑู ุจุง ุงู ุชุฎูู ููุงุดฺฏุงู \n",
            "ุนุงู\n",
            "ุทุงูฺู ุฏูุช ฺฏุฑู ุจุง ุงู ุชุฎูู ููุงุดฺฏุงู \n",
            "ุนุงู\n",
            "ุนุงู ุ ุงูุง ููุท ุจุฑุง ฺฉุจุงุฑ ุฎููุฏู\n",
            "ุนุงู ุ ุงูุง ููุท ุจุฑุง ฺฉุจุงุฑ ุฎููุฏู\n",
            "ฺฉุชุงุจุงุดู ุฎูุฏูุณุช ุฏุงุฑู. ุจุฎุตูุต ูุญุงฺฉูู ุงู ููุณูุฏู ุฑู\n",
            "ฺฉุชุงุจุงุดู ุฎูุฏูุณุช ุฏุงุฑู. ุจุฎุตูุต ูุญุงฺฉูู ุงู ููุณูุฏู ุฑู\n",
            "ููุฏููู ฺุฑุง ุญุณ ูฺฉูู ู ฺุฒ ุชู ฺฉุชุงุจุง ุฏุงุณุชุงููุณฺฉ ฺฉูู  ุดุงุฏ ูุชุฌู ฺฏุฑ ููุง ุงุฎุฑุดูู ููุฏููู ุจู ฺ ูุฑุณู\n",
            "ููุฏููู ฺุฑุง ุญุณ ูฺฉูู ู ฺุฒ ุชู ฺฉุชุงุจุง ุฏุงุณุชุงููุณฺฉ ฺฉูู  ุดุงุฏ ูุชุฌู ฺฏุฑ ููุง ุงุฎุฑุดูู ููุฏููู ุจู ฺ ูุฑุณู\n",
            "ุฏุงุณุชุง ูุจุณฺฉ ุญุฑู ูุฏุงุฑู . ูู ฺฉู ุฎูุดู ุงููุฏ .\n",
            "ุฏุงุณุชุง ูุจุณฺฉ ุญุฑู ูุฏุงุฑู . ูู ฺฉู ุฎูุดู ุงููุฏ .\n",
            "ฺฉุชุงุจ ุฎู ุฎูุจ ุจูุฏ\n",
            "ุฏููุง ูููุทูุฑู\n",
            "ุจุงุฏ ุชู ฺฏุฑูููุง ู ุญุฒุจูุง ุณุงุณ ุจูุฏ ุชุง ฺฏูุฏ ู ฺฉุซุงูุชุดูู ุฑู ุจุจู\n",
            "ุจุงุฏ ุจูุดุงู ุจูุฏ ุชุง ุจุจู ุงุนูุงู ู ุฑูุชุงุฑ ุฑูุจุฑุงู ฺูุฏุฑ ุจุง ฺฏูุชุงุฑุดูู ูุฑู ูฺฉูู\n",
            "ุจุฑุง ฺฉุณุจ ูุฏุฑุช ุชู ุจู ูุฑ ุฑุฐุงูุช ูุฏููุฏ\n",
            "ฺฉุชุงุจ ุฎู ุฎูุจ ุจูุฏ\n",
            "ุฏููุง ูููุทูุฑู\n",
            "ุจุงุฏ ุชู ฺฏุฑูููุง ู ุญุฒุจูุง ุณุงุณ ุจูุฏ ุชุง ฺฏูุฏ ู ฺฉุซุงูุชุดูู ุฑู ุจุจู\n",
            "ุจุงุฏ ุจูุดุงู ุจูุฏ ุชุง ุจุจู ุงุนูุงู ู ุฑูุชุงุฑ ุฑูุจุฑุงู ฺูุฏุฑ ุจุง ฺฏูุชุงุฑุดูู ูุฑู ูฺฉูู\n",
            "ุจุฑุง ฺฉุณุจ ูุฏุฑุช ุชู ุจู ูุฑ ุฑุฐุงูุช ูุฏููุฏ\n",
            "ุงู ฺฉุชุงุจ ู ููุงุดูุงูู  ุณุงุณ ูุณุช .\n",
            "ุงูุงูุด ููฺฏู ุฎู ุญุฑู ูุฒุฏ ุญูุตูู ุงู ุฑู ุณุฑ ูุจุฑุฏ ูููู ุจุนุถ ุฌููู ูุง ุฑู ูุฎููุฏู ุฑุฏูฺฉุฑุฏู.\n",
            "ุงฺฏู ุณุงุณุช ุฑู ุฏูุณุช ุฏุงุฑู. ุจุฎููุฏุด\n",
            "ุงู ฺฉุชุงุจ ู ููุงุดูุงูู  ุณุงุณ ูุณุช .\n",
            "ุงูุงูุด ููฺฏู ุฎู ุญุฑู ูุฒุฏ ุญูุตูู ุงู ุฑู ุณุฑ ูุจุฑุฏ ูููู ุจุนุถ ุฌููู ูุง ุฑู ูุฎููุฏู ุฑุฏูฺฉุฑุฏู.\n",
            "ุงฺฏู ุณุงุณุช ุฑู ุฏูุณุช ุฏุงุฑู. ุจุฎููุฏุด\n",
            "ููุณฺฏุฑ ู ุฒุจุง. ุดุฎุตุช ูพุฑุฏุงุฒ ููู ุงูุนุงุฏู. ูุฑฺฉุฏูู ุงุฒ ุดุฎุตุช ูุง ุงุตู ุงู ููุงุดูุงูู ูุชููู ููุงูุฏู  ุชุงู ุชูพ ูุง ูุฎุชูู ุณุงุณ ุชู ุฒูุงู ูุง ูุฎุชูู ุจุงุดู. ุณุงุฑุชุฑ ุจู ุฎูุจ ุชููุณุชู ุจู ูุฎุงุทุจ ูุดูู ุจุฏู ฺฉู ููุฏู ุฑุฑ ู ููฺฏู ุฏู ูุฌู ฺฉ ุงูุณุงู ุณุฑุฏุฑฺฏู ุจู ุงูุฑุงุท ู ุชูุฑุท ูุณุชู ฺฉู ุฏุฑ ููุงุช ูุฑ ุฏู ุจู ูุญู ุดฺฉุณุช ุฎูุฑุฏู ุงูุฏุ ฺฉ ุจุง ฺฉุดุชู ุดุฏู ุชูุณุท ุงููฺฉุ ุงููฺฉ ุจุง ฺฉุดุชู ุงูฺฉ! ูฺฉุฑ ฺฉูู ุณุงุฑุชุฑ ูุฎูุงุณุช ุจฺฏู ฺฉู ุจุงุฏ ููุฑุฑ ู ููฺฏู ุจุง ูู ุชุฑฺฉุจ ูุดุฏู ุชุง ฺุฒ ุฏุฑุณุช ุงุฒ ุขุจ ุฏุฑู ุงููุฏ! ุตูุญุงุช ุขุฎุฑ ฺฉุชุงุจุ ุจุญุซูุง ููุง ููฺฏู ู ุงููฺฏุง ููู ุงูุนุงุฏู ุณุช! ุฎูุฏุฏุฑฺฏุฑ ุงูุณุงู ุฑู ุจู ุฎูุจ ... ุจู ุฎูุจ ููุ ููู ุงูุนุงุฏู ูุดูู ูุฏู! ูู ุดูุชู ุด ุดุฏู. ููุท ุงุดุชุจุงูุงุช ุชุงูพ ุฒุงุฏู.\n",
            "ููุณฺฏุฑ ู ุฒุจุง. ุดุฎุตุช ูพุฑุฏุงุฒ ููู ุงูุนุงุฏู. ูุฑฺฉุฏูู ุงุฒ ุดุฎุตุช ูุง ุงุตู ุงู ููุงุดูุงูู ูุชููู ููุงูุฏู  ุชุงู ุชูพ ูุง ูุฎุชูู ุณุงุณ ุชู ุฒูุงู ูุง ูุฎุชูู ุจุงุดู. ุณุงุฑุชุฑ ุจู ุฎูุจ ุชููุณุชู ุจู ูุฎุงุทุจ ูุดูู ุจุฏู ฺฉู ููุฏู ุฑุฑ ู ููฺฏู ุฏู ูุฌู ฺฉ ุงูุณุงู ุณุฑุฏุฑฺฏู ุจู ุงูุฑุงุท ู ุชูุฑุท ูุณุชู ฺฉู ุฏุฑ ููุงุช ูุฑ ุฏู ุจู ูุญู ุดฺฉุณุช ุฎูุฑุฏู ุงูุฏุ ฺฉ ุจุง ฺฉุดุชู ุดุฏู ุชูุณุท ุงููฺฉุ ุงููฺฉ ุจุง ฺฉุดุชู ุงูฺฉ! ูฺฉุฑ ฺฉูู ุณุงุฑุชุฑ ูุฎูุงุณุช ุจฺฏู ฺฉู ุจุงุฏ ููุฑุฑ ู ููฺฏู ุจุง ูู ุชุฑฺฉุจ ูุดุฏู ุชุง ฺุฒ ุฏุฑุณุช ุงุฒ ุขุจ ุฏุฑู ุงููุฏ! ุตูุญุงุช ุขุฎุฑ ฺฉุชุงุจุ ุจุญุซูุง ููุง ููฺฏู ู ุงููฺฏุง ููู ุงูุนุงุฏู ุณุช! ุฎูุฏุฏุฑฺฏุฑ ุงูุณุงู ุฑู ุจู ุฎูุจ ... ุจู ุฎูุจ ููุ ููู ุงูุนุงุฏู ูุดูู ูุฏู! ูู ุดูุชู ุด ุดุฏู. ููุท ุงุดุชุจุงูุงุช ุชุงูพ ุฒุงุฏู.\n",
            "ููุงุดูุงูู ุฎู ุฎูุจูุ ุดุฎุตุช ุงุตู ฺฉ ุงุฏูโุขู ฺฏุฑุง ูุณุช ู ูุดฺฉูุงุช ุงููู ุฏุฑ ุฏูุง ูุงูุน ูุดูู ูุฏู!\n",
            "ุชุฑุฌูู ฺฉ ุฎุฑุฏู ูุดฺฉู ุฏุงุดุช ู ฺฉู ุจุนุถ ุฌุงูุง ฺฏูฺฏ ุจูุฏ ูู ุฏุฑ ฺฉู ุฎูุจ ุจูุฏุด.\n",
            "ููุงุดูุงูู ุฎู ุฎูุจูุ ุดุฎุตุช ุงุตู ฺฉ ุงุฏูโุขู ฺฏุฑุง ูุณุช ู ูุดฺฉูุงุช ุงููู ุฏุฑ ุฏูุง ูุงูุน ูุดูู ูุฏู!\n",
            "ุชุฑุฌูู ฺฉ ุฎุฑุฏู ูุดฺฉู ุฏุงุดุช ู ฺฉู ุจุนุถ ุฌุงูุง ฺฏูฺฏ ุจูุฏ ูู ุฏุฑ ฺฉู ุฎูุจ ุจูุฏุด.\n",
            "ููู ุงูุนุงุฏู ุจูุฏ๐\n",
            "ููู ุงูุนุงุฏู ุจูุฏ\n",
            "ฺูู ฺฉู ุณุงุณ ุจูุฏ ูู ุฒุงุฏ ุฏูุณ ูุฏุงุดุชู๐ููฺฉู ฺุณฺฉุง ุฑู ุจุดุชุฑ ุงุฒ ุงููฺฏุง ุฏูุณุช ุฏุงุดุชู๐\n",
            "ฺูู ฺฉู ุณุงุณ ุจูุฏ ูู ุฒุงุฏ ุฏูุณ ูุฏุงุดุชูููฺฉู ฺุณฺฉุง ุฑู ุจุดุชุฑ ุงุฒ ุงููฺฏุง ุฏูุณุช ุฏุงุดุชู\n",
            "ยซููฺฏู ุฏุฑ ุงู ฺฏุฑ ู ุฏุงุฑ ุฏูุจุณุชูโ ููุณุฑ ููุฏูโุฑุฑ ูโุดูุฏยป ุฎูุงุตูโ ุบูุท!\n",
            "ุฎูุฏ ููุงุดูุงูู ูู ุฒุงุฏ ุจุงุจ ุทุจุน ูู ูุจูุฏ. ุงูุจุชู ุงุฏู ุฌุงูุจ ุจูุฏุ ุงูุง ุจุฎุด ุงุฒ ุฏุงููฺฏโูุง ุฑู ุฏูุณุช ูุฏุงุดุชูุ ู ูููุทูุฑ ุชุฑุฌูู ฺฉุฏุณุช ู ุฑูุงู ูุจูุฏุ ุจุง ุฏูฺฏุงูฺฏ ุฒุจุงู.\n",
            "ยซููฺฏู ุฏุฑ ุงู ฺฏุฑ ู ุฏุงุฑ ุฏูุจุณุชูโ ููุณุฑ ููุฏูโุฑุฑ ูโุดูุฏยป ุฎูุงุตูโ ุบูุท!\n",
            "ุฎูุฏ ููุงุดูุงูู ูู ุฒุงุฏ ุจุงุจ ุทุจุน ูู ูุจูุฏ. ุงูุจุชู ุงุฏู ุฌุงูุจ ุจูุฏุ ุงูุง ุจุฎุด ุงุฒ ุฏุงููฺฏโูุง ุฑู ุฏูุณุช ูุฏุงุดุชูุ ู ูููุทูุฑ ุชุฑุฌูู ฺฉุฏุณุช ู ุฑูุงู ูุจูุฏุ ุจุง ุฏูฺฏุงูฺฏ ุฒุจุงู.\n",
            "ููุงุด ูุงูู ุจุณุงุฑ ุฌุงูุจ ุงุณุช ฺฉู ุฏุฑ ููุฑุฏ ุณุงุณุช ู ุงุญุฒุงุจ ุณุงุณุชุ ฺฉุชุงุจ ุฑุงุฌุน ุจู ูุฑุฏ ุณุช ฺฉู ุจู ฺฉ ุญุฒุจ ุณุงุณ ุจุณุงุฑ ูุนุชูุฏ ุงุณุช ู ุจุฑุง ุขู ุจุณุงุฑ ุชูุงุด ูฺฉูุฏ ู ุจู ุฒูุฏุงู ูุฑูุฏ ู.... ูู ุจุนุฏุง ูุชูุฌู ูุดูุฏ ุขุฑูุงู ูุง ุญุฒุจ ฺฉุงููุง ุชุบุฑ ฺฉุฑุฏู ู...ุ ฺฉุชุงุจ ฺฉุงููุง ุจู ูพฺุฏฺฏ ู ุบุฑูุงุจู ูพุด ุจู ุจูุฏู ุณุงุณุช ุงุดุงุฑู ุฏุงุฑุฏุ ุจูุธุฑ ูู ุฎู ุฎูุจ ู ุฌุงูุจ ู ุขููุฒูุฏู ุจูุฏ\n",
            "ููุงุด ูุงูู ุจุณุงุฑ ุฌุงูุจ ุงุณุช ฺฉู ุฏุฑ ููุฑุฏ ุณุงุณุช ู ุงุญุฒุงุจ ุณุงุณุชุ ฺฉุชุงุจ ุฑุงุฌุน ุจู ูุฑุฏ ุณุช ฺฉู ุจู ฺฉ ุญุฒุจ ุณุงุณ ุจุณุงุฑ ูุนุชูุฏ ุงุณุช ู ุจุฑุง ุขู ุจุณุงุฑ ุชูุงุด ูฺฉูุฏ ู ุจู ุฒูุฏุงู ูุฑูุฏ ู.... ูู ุจุนุฏุง ูุชูุฌู ูุดูุฏ ุขุฑูุงู ูุง ุญุฒุจ ฺฉุงููุง ุชุบุฑ ฺฉุฑุฏู ู...ุ ฺฉุชุงุจ ฺฉุงููุง ุจู ูพฺุฏฺฏ ู ุบุฑูุงุจู ูพุด ุจู ุจูุฏู ุณุงุณุช ุงุดุงุฑู ุฏุงุฑุฏุ ุจูุธุฑ ูู ุฎู ุฎูุจ ู ุฌุงูุจ ู ุขููุฒูุฏู ุจูุฏ\n",
            "ฺุฌูุฑ ูุดู ุฐุฎุฑู ุงุด ฺฉุฑุฏ ู ุชูู ฺฉุงููพูุชุฑ ุฎููุฏุด ุุุุ\n",
            "ฺุฌูุฑ ูุดู ุฐุฎุฑู ุงุด ฺฉุฑุฏ ู ุชูู ฺฉุงููพูุชุฑ ุฎููุฏุด ุุุุ\n",
            "ูุงูุนุง ุนุงููุ ุงุดุงูุง ุชุง ุงูุชูุง ูููุทูุฑ ุจุงุดู.\n",
            "ูุงูุนุง ุนุงููุ ุงุดุงูุง ุชุง ุงูุชูุง ูููุทูุฑ ุจุงุดู.\n",
            "ููุฏููู ฺุฑุง ูู ฺุณฺฉุง ุฑู ุจุดุชุฑ ุงุฒ ุงููฺฏุง ุฏูุณ ุฏุงุฑู ๐\n",
            "ููุฏููู ฺุฑุง ูู ฺุณฺฉุง ุฑู ุจุดุชุฑ ุงุฒ ุงููฺฏุง ุฏูุณ ุฏุงุฑู \n",
            "ุชุง ูุณุท ุฏุงุณุชุงู ุฎุณุชู ฺฉููุฏู ุจูุฏ ุงูุง ุจุนุฏ ุนุงู ุจูุฏ ุงุฑุฒุด ุฎููุฏู ุฏุงุฑู ูุงูุนุง\n",
            "ุชุง ูุณุท ุฏุงุณุชุงู ุฎุณุชู ฺฉููุฏู ุจูุฏ ุงูุง ุจุนุฏ ุนุงู ุจูุฏ ุงุฑุฒุด ุฎููุฏู ุฏุงุฑู ูุงูุนุง\n",
            "ุจูุธุฑ ูู ฺูุชุง ูฺฉุชู ุฑู ูุดู ุงุฒ ุงู ฺฉุชุงุจ ุจุฑุฏุงุดุช ฺฉุฑุฏ ูููุณูุฏู ุจูุด ุงุดุงุฑู ฺฉุฑุฏู:\n",
            "ฑ.ููุณูุฏู ุฏุฑ ุชูุงุดู ุชุง ุงูุฏุงู ุงุญุฒุงุจ ุฑู ูุดูู ุจุฏู ฺฉู ูุฏุงู ุฏุฑ ุญุงู ุชุบุฑู ู ุฎู ุงุฒูููุง ุจู ูุฏู ุงููุดูู ูพุงุจูุฏ ูุณุชู.\n",
            "ฒ.ฺฉุดุชู ุจุฑุง ูุฏุฑุช ุฎู ุชู ุณุงุณุช ูุฑุณููู\n",
            "ณ.ูุฏุฑุช ุงูุณุงู ูุง ุฑู ุนูุถ ูฺฉูู....ุงูููุง ุญุงุถุฑู ุจุฑุง ูุฏุฑุช ุฏุฑูุบ ุจฺฏู ุขุฏู ุจฺฉุดู ....ุงุนูุงู ฺฉู ุชู ูุฑ ุฏู ู ูุฐูุจ ูฺฉููุด ุดุฏู\n",
            "ุฏุฑฺฉู ุฎู ูฺฉุงุช ูุดู ุงุฒ ฺฉุชุงุจ ุฏุฑุขูุฑุฏ.\n",
            "ุฑุงุฌุน ุจู ุฎูุฏ ููุงุด ูุงูู ุงุฒ ูุญุงุธ ุบุฑูุงุจู ูพุด ุจู ุจูุฏู ุฎู ุนุงูู ู ููู ุจุงุนุซ ุจุงูุง ุงููุฏูุด ุดุฏู ุชุง ุญุฏูุฏ....\n",
            "ุงูุง ุฏุฑ ฺฉู ุฒุงุฏ ุงุฒ ุฏุงุณุชุงูุด ุฎูุดู ูููุฏ\n",
            "ุจูุธุฑ ูู ฺูุชุง ูฺฉุชู ุฑู ูุดู ุงุฒ ุงู ฺฉุชุงุจ ุจุฑุฏุงุดุช ฺฉุฑุฏ ูููุณูุฏู ุจูุด ุงุดุงุฑู ฺฉุฑุฏู:\n",
            "ฑ.ููุณูุฏู ุฏุฑ ุชูุงุดู ุชุง ุงูุฏุงู ุงุญุฒุงุจ ุฑู ูุดูู ุจุฏู ฺฉู ูุฏุงู ุฏุฑ ุญุงู ุชุบุฑู ู ุฎู ุงุฒูููุง ุจู ูุฏู ุงููุดูู ูพุงุจูุฏ ูุณุชู.\n",
            "ฒ.ฺฉุดุชู ุจุฑุง ูุฏุฑุช ุฎู ุชู ุณุงุณุช ูุฑุณููู\n",
            "ณ.ูุฏุฑุช ุงูุณุงู ูุง ุฑู ุนูุถ ูฺฉูู....ุงูููุง ุญุงุถุฑู ุจุฑุง ูุฏุฑุช ุฏุฑูุบ ุจฺฏู ุขุฏู ุจฺฉุดู ....ุงุนูุงู ฺฉู ุชู ูุฑ ุฏู ู ูุฐูุจ ูฺฉููุด ุดุฏู\n",
            "ุฏุฑฺฉู ุฎู ูฺฉุงุช ูุดู ุงุฒ ฺฉุชุงุจ ุฏุฑุขูุฑุฏ.\n",
            "ุฑุงุฌุน ุจู ุฎูุฏ ููุงุด ูุงูู ุงุฒ ูุญุงุธ ุบุฑูุงุจู ูพุด ุจู ุจูุฏู ุฎู ุนุงูู ู ููู ุจุงุนุซ ุจุงูุง ุงููุฏูุด ุดุฏู ุชุง ุญุฏูุฏ....\n",
            "ุงูุง ุฏุฑ ฺฉู ุฒุงุฏ ุงุฒ ุฏุงุณุชุงูุด ุฎูุดู ูููุฏ\n",
            "ฺฉ ุงุฒ ุจูุชุฑู ููุงุดูุงูู ูุง ุฏูุงุณุช .ุงุชูุฏ ูุฑุฏุง ุชูุฑู ุชุงุฆุงุชุฑ ููู ูุณุช๐\n",
            "ฺฉ ุงุฒ ุจูุชุฑู ููุงุดูุงูู ูุง ุฏูุงุณุช .ุงุชูุฏ ูุฑุฏุง ุชูุฑู ุชุงุฆุงุชุฑ ููู ูุณุช\n",
            "ูุง ุจูุชุฑู ฺฉุชุงุจ ูุณุช ฺฉ ุฎููุฏู ู ุฏูุณ ุฏุงุฑู ุจุงุฑูุง ุจุฎูููุด ู ุณุจฺฉ ุฌุฏุฏ ุฏุงุดุช ู ุฎู ุฏุฑุณ ุจุฒุฑฺฏ ูุฏู ุจุง ุฎููุฏู ุงู ฺฉุชุงุจ ุจูุฏ ฺฉ ูููุฏู ูุงูุนุง ฺฉุชุงุจ ุฎููุฏู ุจุงุนุซ ูุดู ุชุฌุฑุจู ูุงุช ุฒุงุฏ ุจุดู . ูุฑ ฺ ุจฺฏู ฺฉู ฺฏูุชู .ุญุชูุง ุจุฎููุฏ ุงูุง ูู ุจู ุนููุงู ุงููู ฺฉุชุงุจ ฺฉ ูุชูุฌู ุจุดุฏ ฺูุฏุฑ ุจุง ุจูู ฺฉุชุงุจุง ูุฑู ุฏุงุฑู ูฺูุฏ ูุชูุงูุช\n",
            "ูุง ุจูุชุฑู ฺฉุชุงุจ ูุณุช ฺฉ ุฎููุฏู ู ุฏูุณ ุฏุงุฑู ุจุงุฑูุง ุจุฎูููุด ู ุณุจฺฉ ุฌุฏุฏ ุฏุงุดุช ู ุฎู ุฏุฑุณ ุจุฒุฑฺฏ ูุฏู ุจุง ุฎููุฏู ุงู ฺฉุชุงุจ ุจูุฏ ฺฉ ูููุฏู ูุงูุนุง ฺฉุชุงุจ ุฎููุฏู ุจุงุนุซ ูุดู ุชุฌุฑุจู ูุงุช ุฒุงุฏ ุจุดู . ูุฑ ฺ ุจฺฏู ฺฉู ฺฏูุชู .ุญุชูุง ุจุฎููุฏ ุงูุง ูู ุจู ุนููุงู ุงููู ฺฉุชุงุจ ฺฉ ูุชูุฌู ุจุดุฏ ฺูุฏุฑ ุจุง ุจูู ฺฉุชุงุจุง ูุฑู ุฏุงุฑู ูฺูุฏ ูุชูุงูุช\n",
            "ุจุณุงุฑ ุฒุจุง ููู ููุดุชู ุดุฏู ุญุชูุง ุจุฎููุฏุด\n",
            "ุจุณุงุฑ ุฒุจุง ููู ููุดุชู ุดุฏู ุญุชูุง ุจุฎููุฏุด\n",
            "ุงู ููุงุดูุงูู ูุซู ฺฉ ฺุงูู ุฏู ูุจู ุจุฑุง ุงูุฑุงุฏ ุงุณุช ฺฉู ู ุฎูุงููุฏ ูุจุงุฑุฒู ุจุง ุญฺฉููุช ุง ุณุณุชู ูุงฺฉุงุฑุขูุฏ ุฑุง ุขุบุงุฒ ฺฉููุฏ ุงุฒ ฺฉ ุทุฑู ( ููู) ุงูุฑุงุฏ ุญููุช ุฌู ุจุง ุชุทุจู ุฑูุฏุงุฏูุง ููุงุดูุงูู ุจุง ูุถุนุช ุณุงุณ ุงุฌุชูุงุน ุฑูุฒฺฏุงุฑ ุฎูุฏ ููฺฉู ุงุณุช ุงุฒ ุนุถูุช ู ูุนุงูุช ุฏุฑ ุชุดฺฉูุงุช ู ุง ุญุช ฺฉ ุชุฌูุน ูุณุงููุช ุขูุฒ ุฎูุฏุฏุงุฑ ฺฉููุฏ ู ูุงูุณุงูู ููู ูุจุงุฑุฒุงุช ุฑุง ุงุฒ ุงุจุชุฏุง ุดฺฉุณุช ุฎูุฑุฏู ุชูู ฺฉููุฏ ( ุงูุจุชู ุฏุฑ ุฏูุง ูุงูุน ุงูุณุงู ูุง ูุนูููุง ููู ูุจุงุฑุฒุงุช ุฎูุฏ ุฑุง ู ฺููุฏ ฺฉู ุงฺฏุฑ ุงูฺฏููู ูุจูุฏ ูููุฒ ุจุฑุฏู ุฏุงุฑ ุฏุฑ ุฏูุง ุฑูุงุฌ ุฏุงุดุช ู ุญฺฉููุช ุขูพุงุฑุชุงุฏ ุฏุฑ ุขูุฑูุง ุฌููุจ ุฌููุงู ูุฏุงุฏ ู ุฒูุงู ุงุฑููพุง ู ุขูุฑฺฉุง ุญู ุฑุง ูุฏุงุดุชูุฏ ู....)\n",
            "ุงุฒ ุทุฑู ุฏฺฏุฑ ( ูุซุจุช) ุจู ุขุฒุงุฏุฎูุงูุงู ู ุขููุฒุฏ ฺฉู ูุฑฺฏุฒ ุฏุฑ ุชูุงุด ูุง ุตุงุฏูุงูู ุฎูุฏุ ูุฌุฏุงู ู ุงุฎูุงูุงุช ุฎูุฏ ุฑุง ูุฏุง ุงุณุงู ู ุดูุฑุช ุณุงุฒูุงู ุง ุญุฒุจ ุง ุชุดฺฉูุงุช ฺฉู ุนุถูุช ุขู ุฑุง ุฏุงูุทูุจุงูู ูพุฐุฑูุชู ุงูุฏุ ูฺฉููุฏ. ูุจุงุฑุฒุงู ุฑุงู ุขุฒุงุฏ ูููุงุฑู ุจุงุฏ ูุฑุงูุจ ุจุงุดูุฏ ุฏุฑ ุชูุงุด ุจุฑุง ุฏุฑูุงู ุจูุงุฑ ูุง ุณุงุณ ู ุงุฌุชูุงุน ุญุงฺฉู ุจุฑ ุฌุงูุนู ุ ุฎูุฏ ุจูุงุฑ ูฺฏุฑุฏูุฏ!\n",
            "ุงู ููุงุดูุงูู ูุซู ฺฉ ฺุงูู ุฏู ูุจู ุจุฑุง ุงูุฑุงุฏ ุงุณุช ฺฉู ู ุฎูุงููุฏ ูุจุงุฑุฒู ุจุง ุญฺฉููุช ุง ุณุณุชู ูุงฺฉุงุฑุขูุฏ ุฑุง ุขุบุงุฒ ฺฉููุฏ ุงุฒ ฺฉ ุทุฑู ( ููู) ุงูุฑุงุฏ ุญููุช ุฌู ุจุง ุชุทุจู ุฑูุฏุงุฏูุง ููุงุดูุงูู ุจุง ูุถุนุช ุณุงุณ ุงุฌุชูุงุน ุฑูุฒฺฏุงุฑ ุฎูุฏ ููฺฉู ุงุณุช ุงุฒ ุนุถูุช ู ูุนุงูุช ุฏุฑ ุชุดฺฉูุงุช ู ุง ุญุช ฺฉ ุชุฌูุน ูุณุงููุช ุขูุฒ ุฎูุฏุฏุงุฑ ฺฉููุฏ ู ูุงูุณุงูู ููู ูุจุงุฑุฒุงุช ุฑุง ุงุฒ ุงุจุชุฏุง ุดฺฉุณุช ุฎูุฑุฏู ุชูู ฺฉููุฏ ( ุงูุจุชู ุฏุฑ ุฏูุง ูุงูุน ุงูุณุงู ูุง ูุนูููุง ููู ูุจุงุฑุฒุงุช ุฎูุฏ ุฑุง ู ฺููุฏ ฺฉู ุงฺฏุฑ ุงูฺฏููู ูุจูุฏ ูููุฒ ุจุฑุฏู ุฏุงุฑ ุฏุฑ ุฏูุง ุฑูุงุฌ ุฏุงุดุช ู ุญฺฉููุช ุขูพุงุฑุชุงุฏ ุฏุฑ ุขูุฑูุง ุฌููุจ ุฌููุงู ูุฏุงุฏ ู ุฒูุงู ุงุฑููพุง ู ุขูุฑฺฉุง ุญู ุฑุง ูุฏุงุดุชูุฏ ู....)\n",
            "ุงุฒ ุทุฑู ุฏฺฏุฑ ( ูุซุจุช) ุจู ุขุฒุงุฏุฎูุงูุงู ู ุขููุฒุฏ ฺฉู ูุฑฺฏุฒ ุฏุฑ ุชูุงุด ูุง ุตุงุฏูุงูู ุฎูุฏุ ูุฌุฏุงู ู ุงุฎูุงูุงุช ุฎูุฏ ุฑุง ูุฏุง ุงุณุงู ู ุดูุฑุช ุณุงุฒูุงู ุง ุญุฒุจ ุง ุชุดฺฉูุงุช ฺฉู ุนุถูุช ุขู ุฑุง ุฏุงูุทูุจุงูู ูพุฐุฑูุชู ุงูุฏุ ูฺฉููุฏ. ูุจุงุฑุฒุงู ุฑุงู ุขุฒุงุฏ ูููุงุฑู ุจุงุฏ ูุฑุงูุจ ุจุงุดูุฏ ุฏุฑ ุชูุงุด ุจุฑุง ุฏุฑูุงู ุจูุงุฑ ูุง ุณุงุณ ู ุงุฌุชูุงุน ุญุงฺฉู ุจุฑ ุฌุงูุนู ุ ุฎูุฏ ุจูุงุฑ ูฺฏุฑุฏูุฏ!\n",
            "ูุงูุนุง ูุฐุช ุจุฎุด ุจูุฏ\n",
            "ุจุฑุง ูู ฺฉู ุนูุงุฏ ุณุงุณ ู ุนูุงูู ุจู ุณุงุณุช ุฏุงุฑู\n",
            "ูุงูุนุง ูุฐุช ุจุฎุด ุจูุฏ\n",
            "ุจุฑุง ูู ฺฉู ุนูุงุฏ ุณุงุณ ู ุนูุงูู ุจู ุณุงุณุช ุฏุงุฑู\n",
            "ฺฉุชุงุจุด ุฎู ุฎูุจ ุจูุฏ ููู ุทูุฑ ุชุฑุฌูู ุด\n",
            "ฺฉุชุงุจุด ุฎู ุฎูุจ ุจูุฏ ููู ุทูุฑ ุชุฑุฌูู ุด\n",
            "ุจุณุงุฑ ููุงุดูุงูู  ฺฏุฑุง ู ุฌุฐุงุจ ุจูุฏ ุ ูู ูู ูุงููุฏ ููฺฏู ุงุฒ ุฑูุชุงุฑ ู ููุด ู ุงูุจุชู ุนูุงุฆุฏ ูู ฺูุฏุงู ุฌุงูุจ ููุฏู ุฑุฑ ุฎูุดู ุขูุฏู ู ุงุฒ ุงูุฑุงุฏ ูุงููุฏ ูู ฺฉู ููุงุฏ ุงูุณุงููุง ุฎุดฺฉู ููุฏุณ ฺฉู ููุท ูุธุฑ ุฎูุฏ ุฑุง ูุจูู ุฏุงุฑูุฏ ู ูุตูุญุช ุงูุฏุด ุฑุง ูุฎุชุต ุฎูุฏ ูุฏุงููุฏ ูุชููุฑ ู ุจุฒุงุฑู .\n",
            "ููฺฏู ูุฑุจุงู ุฒูุฏ ุจุงูุฑ ู ุงุนุชูุงุฏ ูุง ุจุฌุง ุฎูุฏ ุดุฏ .\n",
            "ู ฺู ุฌุงูุจ ุงุณุช ฺฉู ุจุณุงุฑ ุงุฒ ุขุฑูุงู ูุง ู ุนูุงุฆุฏ ู ุงูฺฉุงุฑ ุญุฒุจุดุงู ูุฑุงุจุช ุฎุงุต ุจุง ุญุฒุจ ุชูุฏู ู ุณุงุฒูุงู ูุฌุงูุฏู ุฏุงุฑุฏ ุ ุฏููุง ููฺู ุชุดฺฉูุงุช ุฑุง ุจุง ููุงู ุงูุฏุงู ุฏุฑ ุชุงุฑุฎ ฺฉุดูุฑ ุฎูุฏูุงู ุฏุงุดุชู ุงู ู ุดฺฉ ูุฏุงุฑู ฺฉู ุฏุฑ ูุฑ ุงูููุงุจ ุฏุฑ ุฏูุง ููฺู ุชุดฺฉูุงุช ุจุง ููุงู ุฑูฺฉุฑุฏูุง ูุฌูุฏ ุฏุงุดุชู ุงุณุช ู ุฎูุงูุฏ ุฏุงุดุช ฺูู ุณูุงุฑู ููุณ ููุงุฑ ูพุดุช ุงู ุฌุฑุงู ูุง ูุฌูุฏ ุฏุงุฑุฏ ู ุงู ฺฉุณ ูุณุช ุฌุฒ ุงุจูุณ ุ ฺฉู ุชูุงู ุชูุงุด ุฎูุฏ ุฑุง ูฺฉูุฏ ุชุง ุงูุณุงู ุฑุง ุงุฒ ุงูุณุงูุชุด ุฏูุฑ ฺฉูุฏ ุจู ูุฑ ูุญู ฺฉู ุดุฏู ุ\n",
            "ุจุณุงุฑ ููุงุดูุงูู  ฺฏุฑุง ู ุฌุฐุงุจ ุจูุฏ ุ ูู ูู ูุงููุฏ ููฺฏู ุงุฒ ุฑูุชุงุฑ ู ููุด ู ุงูุจุชู ุนูุงุฆุฏ ูู ฺูุฏุงู ุฌุงูุจ ููุฏู ุฑุฑ ุฎูุดู ุขูุฏู ู ุงุฒ ุงูุฑุงุฏ ูุงููุฏ ูู ฺฉู ููุงุฏ ุงูุณุงููุง ุฎุดฺฉู ููุฏุณ ฺฉู ููุท ูุธุฑ ุฎูุฏ ุฑุง ูุจูู ุฏุงุฑูุฏ ู ูุตูุญุช ุงูุฏุด ุฑุง ูุฎุชุต ุฎูุฏ ูุฏุงููุฏ ูุชููุฑ ู ุจุฒุงุฑู .\n",
            "ููฺฏู ูุฑุจุงู ุฒูุฏ ุจุงูุฑ ู ุงุนุชูุงุฏ ูุง ุจุฌุง ุฎูุฏ ุดุฏ .\n",
            "ู ฺู ุฌุงูุจ ุงุณุช ฺฉู ุจุณุงุฑ ุงุฒ ุขุฑูุงู ูุง ู ุนูุงุฆุฏ ู ุงูฺฉุงุฑ ุญุฒุจุดุงู ูุฑุงุจุช ุฎุงุต ุจุง ุญุฒุจ ุชูุฏู ู ุณุงุฒูุงู ูุฌุงูุฏู ุฏุงุฑุฏ ุ ุฏููุง ููฺู ุชุดฺฉูุงุช ุฑุง ุจุง ููุงู ุงูุฏุงู ุฏุฑ ุชุงุฑุฎ ฺฉุดูุฑ ุฎูุฏูุงู ุฏุงุดุชู ุงู ู ุดฺฉ ูุฏุงุฑู ฺฉู ุฏุฑ ูุฑ ุงูููุงุจ ุฏุฑ ุฏูุง ููฺู ุชุดฺฉูุงุช ุจุง ููุงู ุฑูฺฉุฑุฏูุง ูุฌูุฏ ุฏุงุดุชู ุงุณุช ู ุฎูุงูุฏ ุฏุงุดุช ฺูู ุณูุงุฑู ููุณ ููุงุฑ ูพุดุช ุงู ุฌุฑุงู ูุง ูุฌูุฏ ุฏุงุฑุฏ ู ุงู ฺฉุณ ูุณุช ุฌุฒ ุงุจูุณ ุ ฺฉู ุชูุงู ุชูุงุด ุฎูุฏ ุฑุง ูฺฉูุฏ ุชุง ุงูุณุงู ุฑุง ุงุฒ ุงูุณุงูุชุด ุฏูุฑ ฺฉูุฏ ุจู ูุฑ ูุญู ฺฉู ุดุฏู ุ\n",
            "ุณุงุณุช ุจุง ูุฌูุฏ ฺฉุซู ุจูุฏูุด ุงุฒ ุฎูุฏ ฺฏุฐุดุชฺฏ ู ุฎูุงุฏ ุูุฑูุงู ูุชู ุงุฒ ุทุฑู ฺฉ ุณุงุณุช ูุฏุงุฑ ุดุงุฏ ุฌูู ฺฉ ูุชู ุนุงู ุฑู ุจฺฏุฑู ุ ูู ูุง ููุท ุงูู ูุชู ุฑู ู ุจูู ...ุจู ูุธุฑ ูู ุณุงุณุช ุงุจุฒุงุฑ ุููู ูุฏู ฺฉู ุงฺฏู ุฏุฑุณุช ุจุงุดู ุงูู ุงุจุฒุงุฑ ูู ููุฌู ุฌููู ู ฺฉูู ู ุงูุจุชู ุจุงูุนฺฉุณ ...\n",
            "ุณุงุณุช ุจุง ูุฌูุฏ ฺฉุซู ุจูุฏูุด ุงุฒ ุฎูุฏ ฺฏุฐุดุชฺฏ ู ุฎูุงุฏ ุูุฑูุงู ูุชู ุงุฒ ุทุฑู ฺฉ ุณุงุณุช ูุฏุงุฑ ุดุงุฏ ุฌูู ฺฉ ูุชู ุนุงู ุฑู ุจฺฏุฑู ุ ูู ูุง ููุท ุงูู ูุชู ุฑู ู ุจูู ...ุจู ูุธุฑ ูู ุณุงุณุช ุงุจุฒุงุฑ ุููู ูุฏู ฺฉู ุงฺฏู ุฏุฑุณุช ุจุงุดู ุงูู ุงุจุฒุงุฑ ูู ููุฌู ุฌููู ู ฺฉูู ู ุงูุจุชู ุจุงูุนฺฉุณ ...\n",
            "20 ุจู ฺฉุชุงุจ ุ20 ุจู ููุณูุฏู ู 20 ูู ุจู ุทุฑุญ ุฑู ุฌูุฏ ุุฌูุงู ูู ฺฉู ุฌุง ุฎูุฏ ุฏุงุฑู ุูุฎูุต ฺฉูุงู ุดุฑ ูุงุฏุฑุช ุญูุงูุช ุจุง ฺฉุชุงุจ ฺฉ ููุดุช\n",
            "20 ุจู ฺฉุชุงุจ ุ20 ุจู ููุณูุฏู ู 20 ูู ุจู ุทุฑุญ ุฑู ุฌูุฏ ุุฌูุงู ูู ฺฉู ุฌุง ุฎูุฏ ุฏุงุฑู ุูุฎูุต ฺฉูุงู ุดุฑ ูุงุฏุฑุช ุญูุงูุช ุจุง ฺฉุชุงุจ ฺฉ ููุดุช\n",
            "ุงุฒ ุงู ฺฉุชุงุจูุงุณุช ฺฉู ููุดู ุฒููุด ฺฏุฐุงุดุช. ุฌุงูุจ ุจูุฏ.\n",
            "ุงุฒ ุงู ฺฉุชุงุจูุงุณุช ฺฉู ููุดู ุฒููุด ฺฏุฐุงุดุช. ุฌุงูุจ ุจูุฏ.\n",
            "ุดุงูฺฉุงุฑ.ูุฑุณ ุขูุง ุณุงุชุฑ\n",
            "ุดุงูฺฉุงุฑ.ูุฑุณ ุขูุง ุณุงุชุฑ\n",
            "ููู ุฏุนูุงูุง ุงูฺฉ ุงุณุช ู ุจู ุฎุงุทุฑ ูุฏุฑุช ุงุณุช ู ูุฑ ููุช ุจุฑุง ุฑุณุฏู ุจู ูุฏุฑุช ูุงุฒ ุจู ูุตุงูุญู ุจุงุดุฏ ููู ุชูฺฉุฑุงุช ุณุงุณ ุจุง ูู ูููู ู ุฎูุฑูุฏ ู ุจู ุฑุงุญุช ุญุฑู ู ุฒููุฏ .ฺุงู ูพู ุณุงุฑุชุฑ\n",
            "ููู ุฏุนูุงูุง ุงูฺฉ ุงุณุช ู ุจู ุฎุงุทุฑ ูุฏุฑุช ุงุณุช ู ูุฑ ููุช ุจุฑุง ุฑุณุฏู ุจู ูุฏุฑุช ูุงุฒ ุจู ูุตุงูุญู ุจุงุดุฏ ููู ุชูฺฉุฑุงุช ุณุงุณ ุจุง ูู ูููู ู ุฎูุฑูุฏ ู ุจู ุฑุงุญุช ุญุฑู ู ุฒููุฏ .ฺุงู ูพู ุณุงุฑุชุฑ\n",
            "ุณูุงู ูู ูุฎุงู ฺฉุชุงุจ ุจู ุตูุฑุช ฺุงูพ ุจุฎุฑู ุจุงุฏ ฺฺฉุงุฑ ฺฉููุ\n",
            "ุณูุงู ูู ูุฎุงู ฺฉุชุงุจ ุจู ุตูุฑุช ฺุงูพ ุจุฎุฑู ุจุงุฏ ฺฺฉุงุฑ ฺฉููุ\n",
            "khob bvdsh\n",
            "khob bvdsh\n",
            "ุจุณุงุฑ ุฒุจุง ุจูุฏ\n",
            "ุจุณุงุฑ ุฒุจุง ุจูุฏ\n",
            "ฺุฑุง ูุธุฑุงุช ฺฉุชุงุจ ุจู ุฎุงุทุฑ ู ูุง ุจุงุฒ ููุดู ูุงู ููู ุงูุฌูุฑู ุง ููุท ูุงู ูู ุจุงุฒ ููุดู\n",
            "ฺุฑุง ูุธุฑุงุช ฺฉุชุงุจ ุจู ุฎุงุทุฑ ู ูุง ุจุงุฒ ููุดู ูุงู ููู ุงูุฌูุฑู ุง ููุท ูุงู ูู ุจุงุฒ ููุดู\n",
            "ูุชู ู ููููู ุนุงูู. ุชุฑุฌูู ูุชููุณุช ุฑูุงู ุชุฑ ุจุงุดู. ุฏุฑ ฺฉู ุฎู ุฎูุจู\n",
            "ูุชู ู ููููู ุนุงูู. ุชุฑุฌูู ูุชููุณุช ุฑูุงู ุชุฑ ุจุงุดู. ุฏุฑ ฺฉู ุฎู ุฎูุจู\n",
            "ุนุงู ุจูุฏ ุ ุชุฑุฌูู ุด ูู ุฎู ุฎูุจ ู ุจุฏูู ูุดฺฉู . ูพุดููุงุฏ ูุฏู ุจุฎููุฏ.\n",
            "ุนุงู ุจูุฏ ุ ุชุฑุฌูู ุด ูู ุฎู ุฎูุจ ู ุจุฏูู ูุดฺฉู . ูพุดููุงุฏ ูุฏู ุจุฎููุฏ.\n",
            "ุฎู ฺูุฑู ููู ุงุฒ ุณุงุณุช ุฑู ุจู ุชุตูุฑ ฺฉุดุฏู. ุจูุธุฑู ุจุฒุฑฺฏุชุฑู ููุทู ูุดุชุฑฺฉ ููู  ุณุงุณุช ูุงุฑู ุจู ุนุงู ุชุฑู ุดฺฉู ููฺฉู ุจุงู ฺฉุฑุฏู. ูุฐุช ุจุฑุฏู.\n",
            "ุฎู ฺูุฑู ููู ุงุฒ ุณุงุณุช ุฑู ุจู ุชุตูุฑ ฺฉุดุฏู. ุจูุธุฑู ุจุฒุฑฺฏุชุฑู ููุทู ูุดุชุฑฺฉ ููู  ุณุงุณุช ูุงุฑู ุจู ุนุงู ุชุฑู ุดฺฉู ููฺฉู ุจุงู ฺฉุฑุฏู. ูุฐุช ุจุฑุฏู.\n",
            "ุนุงูุ ุณุงุณ ู ููุณู ู ุฏุฑุงูุงุชฺฉ\n",
            "ุนุงูุ ุณุงุณ ู ููุณู ู ุฏุฑุงูุงุชฺฉ\n",
            "ุฏุงุณุชุงู ุฌุงูุจู. ุฎูุดู ุงููุฏ. ุดุฑูุนุด ุฎูุจู. ุขุฏูู ฺฉูุฌฺฉุงู ุจู ุงุฏุงูู ุฏุงุณุชุงู ูฺฉูู. ุจู ุฎุงุทุฑ ุจุฑฺฏุดุช ุจู ุนูุจุด.\n",
            "ฺฏุงู ูุง ุงูุทูุฑ ุฑูุชุงุฑ ูโฺฉูู. ุจุนุฏ ุงุฒ ุฒูุงูุ ุขุฑูุงูโูุง ูุง ุชุบุฑ ูโฺฉููุฏ.\n",
            "ุฒูุงู ููู ฺุฒ ุฑุง ุชุบุฑ ูโุฏูุฏ.\n",
            "ุฏุงุณุชุงู ุฌุงูุจู. ุฎูุดู ุงููุฏ. ุดุฑูุนุด ุฎูุจู. ุขุฏูู ฺฉูุฌฺฉุงู ุจู ุงุฏุงูู ุฏุงุณุชุงู ูฺฉูู. ุจู ุฎุงุทุฑ ุจุฑฺฏุดุช ุจู ุนูุจุด.\n",
            "ฺฏุงู ูุง ุงูุทูุฑ ุฑูุชุงุฑ ูโฺฉูู. ุจุนุฏ ุงุฒ ุฒูุงูุ ุขุฑูุงูโูุง ูุง ุชุบุฑ ูโฺฉููุฏ.\n",
            "ุฒูุงู ููู ฺุฒ ุฑุง ุชุบุฑ ูโุฏูุฏ.\n",
            "ูุงูุนุง ุฑูุงู ุฒุจุง ูุณุช.ุจู ููู ุฏูุณุชุงู ุชูุตู ูฺฉูู ุจุฎููู\n",
            "ูุงูุนุง ุฑูุงู ุฒุจุง ูุณุช.ุจู ููู ุฏูุณุชุงู ุชูุตู ูฺฉูู ุจุฎููู\n",
            "ู ุชุฆุงุชุฑ ฺฉู ุงุฒ ุงู ุฏุงุณุชุงู ุงูุชุจุงุณ ุดุฏู ุจูุฏ ุฏุฏู ุจูุฏู ูุจูุงุ ุฏุงุณุชุงู ุจู ูุฑุงุชุจ ฺฏุฑุงุชุฑ ุจูุฏ ุบุฑ ุงุฒ ูพุงุงู ฺฏูฺฏุด\n",
            "ู ุชุฆุงุชุฑ ฺฉู ุงุฒ ุงู ุฏุงุณุชุงู ุงูุชุจุงุณ ุดุฏู ุจูุฏ ุฏุฏู ุจูุฏู ูุจูุงุ ุฏุงุณุชุงู ุจู ูุฑุงุชุจ ฺฏุฑุงุชุฑ ุจูุฏ ุบุฑ ุงุฒ ูพุงุงู ฺฏูฺฏุด\n",
            "ุฎูุจ ุฎูุจ ุจูุฏ ูุฎุตูุตุง ุงฺฏู ูููุดู ุจุณุงุฒู ุงูุจุชู ฺฉู ุฎู ุณุงูุณูุฑ ุฎูุงูุฏ ุฏุงุดุช๐ูู ุฏุงุณุชุงูุด ุฌุงูุจ ุจูุฏ ุจุฎููุฏ ุฏูุณุชุงู\n",
            "ุฎูุจ ุฎูุจ ุจูุฏ ูุฎุตูุตุง ุงฺฏู ูููุดู ุจุณุงุฒู ุงูุจุชู ฺฉู ุฎู ุณุงูุณูุฑ ุฎูุงูุฏ ุฏุงุดุชูู ุฏุงุณุชุงูุด ุฌุงูุจ ุจูุฏ ุจุฎููุฏ ุฏูุณุชุงู\n",
            "โญ๐โญ๐โญ\n",
            "\n",
            "ุนุงุงุงุงู ุจูุฏ .\n",
            "ููู ุงูุนุงุฏู ุชูุฎ ุนูู ุฏุงุดุช. ููฺฏู ุชููุง ุนูู ุฑุง ุชุฌุฑุจู ฺฉุฑุฏ\n",
            "ุนุงุงุงุงู ุจูุฏ .\n",
            "ููู ุงูุนุงุฏู ุชูุฎ ุนูู ุฏุงุดุช. ููฺฏู ุชููุง ุนูู ุฑุง ุชุฌุฑุจู ฺฉุฑุฏ\n",
            "ฺฉุชุงุจ ุจุณุงุฑ ุฎูุจ ุงุณุช . ู ูฺฉุฑ ู ฺฉูู ฺฉู ุงุฒ ฺูุฏ ูุธุฑ ุญุงุฆุฒ ุงููุช ุงุณุช โ. ุงูู ุงุฒ ูุธุฑ ุงุฏุจ ู ุจุฎุตูุต ุงุฏุจุงุช ููุงุด ุงุซุฑ ููู ุงุณุช ฺฉู ุฏุฑ ุจุณุงุฑ ุงุฒ ฺฉุดูุฑ ูุง ุงู ุงุซุฑ ุจู ุฑู ุตุญูู ุฑูุชู . ู ุงุฒ ูุธุฑ ุงุฏุฆูููฺ ู ููุณูู ุงฺฏุฒุณุชุงูุณุงูุช ฺฉู ุงุตูู ููู ุจุงู ุดุฏู ุฏุฑ ุงู ููุณูู ุฏุฑ ุงู ฺฉุชุงุจ ุจู ุฏูุนุงุช ุฐฺฉุฑ ุดุฏู ุงุฒ ูุจู : ูุถุนุช ุงููู ( ุชููุฏ - ุฎุงููุงุฏู ) ุ ุขุฒุงุฏุ ุงูุชุฎุงุจ ุ ูุณุฆููุช ุงูุณุงู ุ ุฏููุฑู ูุงุด ุงุฒ ุขุฒุงุฏ . ููฺูู ุงู ุงุซุฑ ุงุฒ ุฌูุงุช ู ูฺฉุงูุงุช ุฏุงุณุชุงููุณฺฉ ู ุดุฎุตุช ุงูู ุขู ูู ุจุณุงุฑ ุจูุฑู ุจุฑุฏู . ู ุงู ุฏุฑ ุญุงู ุงุณุช ฺฉู ุฏุงุณุชุงููุณฺฉ ุฑู ูู ุงุฒ ุงููู ุงฺฏุฒุณุชุงูุณุงูุช ูุง ู ุฏูููุฏ.\n",
            "ู ุฏฺฏุฑ ุงุฒ ูุธุฑ ุชุงุฑุฎ ู ุจุงู ูพฺุฏฺฏ ุฌุงูุนู ุณุงุณ ุขู ุฒูุงู ูุฑุงูุณู ุ ุงุชุญุงุฏ ุญุฒุจ ฺฉูููุณุช ูุฑุงูุณู ุจุง ุงุญุฒุงุจ ูุจุฑุงู ู ุณูุทูุช ุทูุจ ู ุบุฑู . ุณุงุฑุชุฑ ุฏุฑ ุงู ฺฉุชุงุจ ุณุงุณุช ูุง ูุญุงูุธู ฺฉุงุฑุงูู ุญุฒุจ ฺฉูููุณุช ูุฑุงูุณู ุฑุง ููุฏ ู ฺฉูุฏ ู ฺฉูููุณุช ุงุฏู ุงูุด ุฑุง ุฏุฑ ุดุฎุตุช ููฺฏู ูุนุฑู ู ฺฉูุฏ.\n",
            "ฺฉุชุงุจ ุจุณุงุฑ ุฎูุจ ุงุณุช . ู ูฺฉุฑ ู ฺฉูู ฺฉู ุงุฒ ฺูุฏ ูุธุฑ ุญุงุฆุฒ ุงููุช ุงุณุช โ. ุงูู ุงุฒ ูุธุฑ ุงุฏุจ ู ุจุฎุตูุต ุงุฏุจุงุช ููุงุด ุงุซุฑ ููู ุงุณุช ฺฉู ุฏุฑ ุจุณุงุฑ ุงุฒ ฺฉุดูุฑ ูุง ุงู ุงุซุฑ ุจู ุฑู ุตุญูู ุฑูุชู . ู ุงุฒ ูุธุฑ ุงุฏุฆูููฺ ู ููุณูู ุงฺฏุฒุณุชุงูุณุงูุช ฺฉู ุงุตูู ููู ุจุงู ุดุฏู ุฏุฑ ุงู ููุณูู ุฏุฑ ุงู ฺฉุชุงุจ ุจู ุฏูุนุงุช ุฐฺฉุฑ ุดุฏู ุงุฒ ูุจู : ูุถุนุช ุงููู ( ุชููุฏ - ุฎุงููุงุฏู ) ุ ุขุฒุงุฏุ ุงูุชุฎุงุจ ุ ูุณุฆููุช ุงูุณุงู ุ ุฏููุฑู ูุงุด ุงุฒ ุขุฒุงุฏ . ููฺูู ุงู ุงุซุฑ ุงุฒ ุฌูุงุช ู ูฺฉุงูุงุช ุฏุงุณุชุงููุณฺฉ ู ุดุฎุตุช ุงูู ุขู ูู ุจุณุงุฑ ุจูุฑู ุจุฑุฏู . ู ุงู ุฏุฑ ุญุงู ุงุณุช ฺฉู ุฏุงุณุชุงููุณฺฉ ุฑู ูู ุงุฒ ุงููู ุงฺฏุฒุณุชุงูุณุงูุช ูุง ู ุฏูููุฏ.\n",
            "ู ุฏฺฏุฑ ุงุฒ ูุธุฑ ุชุงุฑุฎ ู ุจุงู ูพฺุฏฺฏ ุฌุงูุนู ุณุงุณ ุขู ุฒูุงู ูุฑุงูุณู ุ ุงุชุญุงุฏ ุญุฒุจ ฺฉูููุณุช ูุฑุงูุณู ุจุง ุงุญุฒุงุจ ูุจุฑุงู ู ุณูุทูุช ุทูุจ ู ุบุฑู . ุณุงุฑุชุฑ ุฏุฑ ุงู ฺฉุชุงุจ ุณุงุณุช ูุง ูุญุงูุธู ฺฉุงุฑุงูู ุญุฒุจ ฺฉูููุณุช ูุฑุงูุณู ุฑุง ููุฏ ู ฺฉูุฏ ู ฺฉูููุณุช ุงุฏู ุงูุด ุฑุง ุฏุฑ ุดุฎุตุช ููฺฏู ูุนุฑู ู ฺฉูุฏ.\n",
            "ูุงูุนุง ุนุงู ุจูุฏ ุงุฒ ุจูุชุฑู ูุง ฺฉู ุฎููุฏู ุจูุฏู๐๐๐๐\n",
            "ูุงูุนุง ุนุงู ุจูุฏ ุงุฒ ุจูุชุฑู ูุง ฺฉู ุฎููุฏู ุจูุฏู\n",
            "ุนุงู........ููุท ูุทูุง ฺฉุณุงู ุจุฎููู ฺฉู ุจู ูพุฎุชฺฏ ูุงุฒู ุฑุณุฏู๐๐๐น\n",
            "ุนุงู........ููุท ูุทูุง ฺฉุณุงู ุจุฎููู ฺฉู ุจู ูพุฎุชฺฏ ูุงุฒู ุฑุณุฏู\n",
            "ูู ุงู ฺฉุชุงุจ ู ูุฎููุฏู ุงุฒ ูุณุช ฺฉุชุงุจุงู ูพุงฺฉ ูฺฉูู.ุจุง ูุฌูุฏ ููฺู ฺฉุงููุช ูุง ุงุฒุงูุงู ูุชููู ุจูููู ฺฉู ุฏุฑุงุฎุฑ ุงู ฺฉุชุงุจ ุจุงุนุซ ุฏุฑฺฏุฑ ุฐูู ุฏุฑููู ูุดู ูพุณ ููุฎูููุด.ูู ูุฎูุงู ู ฺฉุชุงุจ ุจุฎููู ฺฉู ุจูู ุงุฑุงูุด ุจุฏู ูู ุจู ูุธุฑ ูุงุฏ ุงู ฺฉุชุงุจ ุงุฒุงูู ฺฉุชุงุจุง ูุณุช.ูู ุงุฒ ุณุงุณุช ูุชููุฑู\n",
            "ูู ุงู ฺฉุชุงุจ ู ูุฎููุฏู ุงุฒ ูุณุช ฺฉุชุงุจุงู ูพุงฺฉ ูฺฉูู.ุจุง ูุฌูุฏ ููฺู ฺฉุงููุช ูุง ุงุฒุงูุงู ูุชููู ุจูููู ฺฉู ุฏุฑุงุฎุฑ ุงู ฺฉุชุงุจ ุจุงุนุซ ุฏุฑฺฏุฑ ุฐูู ุฏุฑููู ูุดู ูพุณ ููุฎูููุด.ูู ูุฎูุงู ู ฺฉุชุงุจ ุจุฎููู ฺฉู ุจูู ุงุฑุงูุด ุจุฏู ูู ุจู ูุธุฑ ูุงุฏ ุงู ฺฉุชุงุจ ุงุฒุงูู ฺฉุชุงุจุง ูุณุช.ูู ุงุฒ ุณุงุณุช ูุชููุฑู\n",
            "ุฎูุจ ุจูุฏ ูู ุตูุญู ูกูฃ ุณูุฏ ุจูุฏ!\n",
            "ุฎูุจ ุจูุฏ ูู ุตูุญู ูกูฃ ุณูุฏ ุจูุฏ!\n",
            "ุฎูุงูุดุง ููู ฺุฒู ุจู ุฏู ูุตู ูฺฉูู / ูุธุฑุงุช ูุฑ ฺฉุชุงุจ ุฑู ูฺฏุงู ูฺฉุชู ุจุงุฏ ูุงฺู ุฏู ุฑู ุจุจูู ุญุชูุง ุ!\n",
            "ุฎูุงูุดุง ููู ฺุฒู ุจู ุฏู ูุตู ูฺฉูู / ูุธุฑุงุช ูุฑ ฺฉุชุงุจ ุฑู ูฺฏุงู ูฺฉุชู ุจุงุฏ ูุงฺู ุฏู ุฑู ุจุจูู ุญุชูุง ุ!\n",
            "ุงุดูู ฺฉ ุจ ุฏู ุจูุฏู ุุุ\n",
            "ุงุดูู ฺฉ ุจ ุฏู ุจูุฏู ุุุ\n",
            "ุฎูุจ ุจูุฏ ุฏูุณุช ุฏุงุดุชู.\n",
            "ุฎูุจ ุจูุฏ ุฏูุณุช ุฏุงุดุชู.\n",
            "ฺ ุจฺฏู ูุงูุง\n",
            "ฺ ุจฺฏู ูุงูุง\n",
            "ุจู ุฏุฑฺฉ ุนูู ุงุฒ ุณุงุณุช ุฑุณุฏู ุจูุฏู\n",
            "ุจู ุฏุฑฺฉ ุนูู ุงุฒ ุณุงุณุช ุฑุณุฏู ุจูุฏู\n",
            "ูุซ ูุงูุนุช ุจูุฏ ุณุงุณุช ฺฉุซู ูุฎุงุฆูู.ูุฑฺฉ ูุงุฑุฏุด ุดุฏ ุฏุณุชุงุด ุงููุฏู ูุดู\n",
            "ูุซ ูุงูุนุช ุจูุฏ ุณุงุณุช ฺฉุซู ูุฎุงุฆูู.ูุฑฺฉ ูุงุฑุฏุด ุดุฏ ุฏุณุชุงุด ุงููุฏู ูุดู\n",
            "ููู ุงูุนุงุฏู ุจูุฏ ู ูุงูุนุง ุงุฒุด ูุฐุช ุจุฑุฏูุ ุชุฑุฌูู ูู ุฑูุงู ู ุนุงู\n",
            "ุณูพุงุณฺฏุฒุงุฑู ุทุงูฺู\n",
            "ููู ุงูุนุงุฏู ุจูุฏ ู ูุงูุนุง ุงุฒุด ูุฐุช ุจุฑุฏูุ ุชุฑุฌูู ูู ุฑูุงู ู ุนุงู\n",
            "ุณูพุงุณฺฏุฒุงุฑู ุทุงูฺู\n",
            "ููู ุงูุนุงุฏู ุจูุฏุ ุฏุงุณุชุงู ฺฉุดุด ุจุณุงุฑ ุจุงูุง ุฏุงุดุช. ุดุฏุฏุง ูพุดููุงุฏ ูุดู. ุงูุฏูุงุฑู ฺฉ ุฑูุฒ ุจุชููู ุชุฆุงุชุฑ ุงู ููุงุดูุงูู ุฑู ุจุจูู\n",
            "ููู ุงูุนุงุฏู ุจูุฏุ ุฏุงุณุชุงู ฺฉุดุด ุจุณุงุฑ ุจุงูุง ุฏุงุดุช. ุดุฏุฏุง ูพุดููุงุฏ ูุดู. ุงูุฏูุงุฑู ฺฉ ุฑูุฒ ุจุชููู ุชุฆุงุชุฑ ุงู ููุงุดูุงูู ุฑู ุจุจูู\n",
            "ุชุง ุงูุฌุง ฺฉู ูุฎููู ุฌุงูุจ ู ุฌุฐุงุจ ุจูุฏ ุจุฑุงู(ุจุดุชุฑ ุงุฒ ูุตูุดู ุฎููุฏู)\n",
            "ุชุง ุงูุฌุง ฺฉู ูุฎููู ุฌุงูุจ ู ุฌุฐุงุจ ุจูุฏ ุจุฑุงู(ุจุดุชุฑ ุงุฒ ูุตูุดู ุฎููุฏู)\n",
            "ููฺฏู ููู ุงูุนุงุฏู ุจูุฏ ุงูุง ุงุฑุฒุด ุฎููุฏู ุฑู ุฏุงุดุช.. ูุฌุงู ุงูฺฏุฒ ู ุชุง ุญุฏูุฏ ุบุฑูุงุจู ูพุด ุจู ุจูุฏ ู ุฏุงุณุชุงู ฺฉุงููุง ูุชูุงูุช ุฑูุงุช ุดุฏู ุจูุฏ\n",
            "ููฺฏู ููู ุงูุนุงุฏู ุจูุฏ ุงูุง ุงุฑุฒุด ุฎููุฏู ุฑู ุฏุงุดุช.. ูุฌุงู ุงูฺฏุฒ ู ุชุง ุญุฏูุฏ ุบุฑูุงุจู ูพุด ุจู ุจูุฏ ู ุฏุงุณุชุงู ฺฉุงููุง ูุชูุงูุช ุฑูุงุช ุดุฏู ุจูุฏ\n",
            "ูุฑ ฺ ุงุฒ ุฏุงุณุชุงู ูฺฏุฐุฑู ุฒุจุงุชุฑ ูุดู. ุนุงู ุจูุฏ\n",
            "ูุฑ ฺ ุงุฒ ุฏุงุณุชุงู ูฺฏุฐุฑู ุฒุจุงุชุฑ ูุดู. ุนุงู ุจูุฏ\n",
            "ู ุฑูุงู ููู ุงูุนุงุฏู ูุฑุจูุท ุจู ุญูุงุฏุซ ุฏุงุฎู ุญุฒุจ ฺูพ ุฏุฑ ุฒูุงู ุฌูฺฏ ุฌูุงู ุฏูู.\n",
            "ุชุฑุฌูู ุฌูุงู ูู ูุฐุช ุจุฎุดู.\n",
            "ูพุดููุงุฏ ูฺฉูู ุญุชูุง ุจุฎููุฏ. ูุฎุตูุตุง ุงู ฺฉู ฺุงู ูพู ุณุงุฑุชุฑ ููุณูู ุจุฒุฑฺฏ ุงฺฏุฒุณุชุงูุณุงูุณุช ูุฑุงูุณู ุงูู ููุดุชู ฺฉู ุฏุฑ ฺฉูุฏฺฉ ุฌูฺฏ ุฌูุงู ุงูู ุฑู ุฏุฏู ู ุฏุฑ ุจุฒุฑฺฏุณุงู ุฌูฺฏ ุฏูู ุฑู!\n",
            "ู ุฑูุงู ููู ุงูุนุงุฏู ูุฑุจูุท ุจู ุญูุงุฏุซ ุฏุงุฎู ุญุฒุจ ฺูพ ุฏุฑ ุฒูุงู ุฌูฺฏ ุฌูุงู ุฏูู.\n",
            "ุชุฑุฌูู ุฌูุงู ูู ูุฐุช ุจุฎุดู.\n",
            "ูพุดููุงุฏ ูฺฉูู ุญุชูุง ุจุฎููุฏ. ูุฎุตูุตุง ุงู ฺฉู ฺุงู ูพู ุณุงุฑุชุฑ ููุณูู ุจุฒุฑฺฏ ุงฺฏุฒุณุชุงูุณุงูุณุช ูุฑุงูุณู ุงูู ููุดุชู ฺฉู ุฏุฑ ฺฉูุฏฺฉ ุฌูฺฏ ุฌูุงู ุงูู ุฑู ุฏุฏู ู ุฏุฑ ุจุฒุฑฺฏุณุงู ุฌูฺฏ ุฏูู ุฑู!\n",
            "ุจุณุงุฑ ุฌุงูุจ ู ุชุงูู ุจุฑุงูฺฏุฒ\n",
            "ุจุณุงุฑ ุฌุงูุจ ู ุชุงูู ุจุฑุงูฺฏุฒ\n",
            "ูู ุฎูุดู ูููุฏ ุงุฒ ุงู ฺฉุชุงุจ\n",
            "ูู ุฎูุดู ูููุฏ ุงุฒ ุงู ฺฉุชุงุจ\n",
            "ุงุฒ ุฎููุฏูุด ุฎู ูุฐุช ุจุฑุฏู. ุนููุ ู ุฏุฑ ุนู ุญุงู ุฌุฐุงุจ ู ูพุฑฺฉุดุด ุจูุฏ.\n",
            "ุงุฒ ุฎููุฏูุด ุฎู ูุฐุช ุจุฑุฏู. ุนููุ ู ุฏุฑ ุนู ุญุงู ุฌุฐุงุจ ู ูพุฑฺฉุดุด ุจูุฏ.\n",
            "ุฎุดุจุฎุช ฺุณุชุ ุฌุงูุงูู ุฒุณุชู ุจุง ุชูุงู ุจุฏุจุฎุช ูุง.ุจูุธุฑู ฺุงุฑู ฺุงูพูู\n",
            "ุฎุดุจุฎุช ฺุณุชุ ุฌุงูุงูู ุฒุณุชู ุจุง ุชูุงู ุจุฏุจุฎุช ูุง.ุจูุธุฑู ฺุงุฑู ฺุงูพูู\n",
            "ููุฏ ุจูุฏ\n",
            "ููุฏ ุจูุฏ\n",
            "ยซุงฺฏู ููุฌ ูุงุฏุฑุฒุงุฏุจู ุฏูุง ุจุง ูููุฑูุงู ุฏู ุงูููพฺฉ ูุด ุตุฏุฏุฑุตุฏ ุฎูุฏุช ููุตุฑยป\n",
            "ฺุงู ูพู ุณุงุฑุชุฑ\n",
            "ยซุงฺฏู ููุฌ ูุงุฏุฑุฒุงุฏุจู ุฏูุง ุจุง ูููุฑูุงู ุฏู ุงูููพฺฉ ูุด ุตุฏุฏุฑุตุฏ ุฎูุฏุช ููุตุฑยป\n",
            "ฺุงู ูพู ุณุงุฑุชุฑ\n",
            "ุจู ุบุฑ ุงุฒ ูุณูุช ูุง ฺฉู ฺฉููู ูุง  ูููุจู ุณููุจู ุณุงุณ ุฏุงุดุช ุจูุด ุฎูุจ ุจูุฏุ ูู ูฺฉ ฺฉุฑุฏู ฺุณฺฉุง ู ููฺฏู ุจุง ูู ุชุตูู ฺฏุฑูุชู ู ููุดู ฺฉุดุฏู ฺฉู ุงู ุฌูุฑ ููุฏู ุฑุฑ ุฑู ุจฺฉุดูุ  ุจุนุฏ ุฏุฏู ุงุดุชุจุงู ฺฉุฑุฏู\n",
            "ุจู ุบุฑ ุงุฒ ูุณูุช ูุง ฺฉู ฺฉููู ูุง  ูููุจู ุณููุจู ุณุงุณ ุฏุงุดุช ุจูุด ุฎูุจ ุจูุฏุ ูู ูฺฉ ฺฉุฑุฏู ฺุณฺฉุง ู ููฺฏู ุจุง ูู ุชุตูู ฺฏุฑูุชู ู ููุดู ฺฉุดุฏู ฺฉู ุงู ุฌูุฑ ููุฏู ุฑุฑ ุฑู ุจฺฉุดูุ  ุจุนุฏ ุฏุฏู ุงุดุชุจุงู ฺฉุฑุฏู\n",
            "ุฎู ุจุงุญุงูู! ูุฑ ฺฉุณ ูุณูุช ุฌุฒุงุช ุฑุง ุฑุงุฌุน ุจู ฺฉุชุงุจ ููุดุชูุุจุงุฏ ุจูุด ุฌุงุฒู ุฎูฺฏ ุชุฑู ุฎูุงููุฏู ุชุนูู ุจฺฏุฑู.ุงุฎู ูุงูุตุจ ฺฉุฌุง ฺุณฺฉุง ุฒู ุฑูุจุฑ ุญุฒุจ ุจูุฏ ฺฉู ุจุนุฏ ููฺฏู ุนุงุดูุด ุดุฏู ุจุงุดู!!! ุจุงููุดุูุงุจุบูุ ุฏุงูุดููุฏ ุุงุณุชุงุฏุูุฑุฒุงููุุณุฑูุงู ุนูู ู ุฏุงูุดฺฏุงู ุ ฺุณฺฉุง ููุณุฑ ุฎูุฏ ููฺฏู ุจูุฏ ุงุฒ ูููู ุงูู ููุงุดูุงูู!!!!!!!!!!\n",
            "ุฎู ุจุงุญุงูู! ูุฑ ฺฉุณ ูุณูุช ุฌุฒุงุช ุฑุง ุฑุงุฌุน ุจู ฺฉุชุงุจ ููุดุชูุุจุงุฏ ุจูุด ุฌุงุฒู ุฎูฺฏ ุชุฑู ุฎูุงููุฏู ุชุนูู ุจฺฏุฑู.ุงุฎู ูุงูุตุจ ฺฉุฌุง ฺุณฺฉุง ุฒู ุฑูุจุฑ ุญุฒุจ ุจูุฏ ฺฉู ุจุนุฏ ููฺฏู ุนุงุดูุด ุดุฏู ุจุงุดู!!! ุจุงููุดุูุงุจุบูุ ุฏุงูุดููุฏ ุุงุณุชุงุฏุูุฑุฒุงููุุณุฑูุงู ุนูู ู ุฏุงูุดฺฏุงู ุ ฺุณฺฉุง ููุณุฑ ุฎูุฏ ููฺฏู ุจูุฏ ุงุฒ ูููู ุงูู ููุงุดูุงูู!!!!!!!!!!\n",
            "ุจูุชุฑ ุงุฒ ุนุงู ุจูุฏ :)\n",
            "ุจูุชุฑ ุงุฒ ุนุงู ุจูุฏ :)\n",
            "ูุทูุข ููุงุดูุงูู  ุฑูุณูพ ุจุฒุฑฺฏูุงุฑ ุงุซุฑ ฺุงู ูพู ุณุงุฑุชุฑ ุฑู ูู ุฏุฑ ุจุฎุด ุฑุงฺฏุงู ุจุฐุงุฑุฏ.ุฎู ฺฉูุชุงู ู ฺฉูุงุจ ู ูุดูฺฏู\n",
            "ูุทูุข ููุงุดูุงูู  ุฑูุณูพ ุจุฒุฑฺฏูุงุฑ ุงุซุฑ ฺุงู ูพู ุณุงุฑุชุฑ ุฑู ูู ุฏุฑ ุจุฎุด ุฑุงฺฏุงู ุจุฐุงุฑุฏ.ุฎู ฺฉูุชุงู ู ฺฉูุงุจ ู ูุดูฺฏู\n",
            "ุนุงู ุจูุฏ ูุฐุช ุจุฑุฏู\n",
            "ุนุงู ุจูุฏ ูุฐุช ุจุฑุฏู\n",
            "ููุงุด ูุงูู  ุนุงู ุจูุฏ ุฎู ุฎูุจ ููููู ูุฏุฑุช ุฏุฑ ุณุงุณุช ุ ุฎุงูุช ุุตุฏุงูุช ู ุงุนุชูุงุฏ ุฑู ูุฑุณููู \n",
            "ููุงุด ูุงูู  ุนุงู ุจูุฏ ุฎู ุฎูุจ ููููู ูุฏุฑุช ุฏุฑ ุณุงุณุช ุ ุฎุงูุช ุุตุฏุงูุช ู ุงุนุชูุงุฏ ุฑู ูุฑุณููู \n",
            "ูุดูฺฏ ุจูุฏ ุฎู ุฏูุณุช ุฏุงุดุชู ุจูุฏ\n",
            "ูุดูฺฏ ุจูุฏ ุฎู ุฏูุณุช ุฏุงุดุชู ุจูุฏ\n",
            "ุฎู ุฎูุจ ุจูุฏ ููุงุด ูุงูู ููู ุงูุนุงุฏู ุงู ุ\n",
            "ุณุงุณ ุจูุฏูุด ุชู ุณู ฺฉู ุงุฒุฏูุงุฌ ฺฉุฑุฏู ุญุณ ุฏูุณ ูุฏุงุดุชู ุฎุงูุช ุจูุด  ู ุฏุฑ ุงุฎุฑ ูุชู ุฏุงุณุชุงู ุบู ุงูฺฏุฒู ุง ูุณุช.\n",
            "ูู ุฏุฑ ฺฉู ุจุงุฏ ุฏุฎุชุฑู ูู ูฺฉุดุช ุจูุชุฑ ุจูุฏ ุจูุธุฑู ูู\n",
            "ุฎู ุฎูุจ ุจูุฏ ููุงุด ูุงูู ููู ุงูุนุงุฏู ุงู ุ\n",
            "ุณุงุณ ุจูุฏูุด ุชู ุณู ฺฉู ุงุฒุฏูุงุฌ ฺฉุฑุฏู ุญุณ ุฏูุณ ูุฏุงุดุชู ุฎุงูุช ุจูุด  ู ุฏุฑ ุงุฎุฑ ูุชู ุฏุงุณุชุงู ุบู ุงูฺฏุฒู ุง ูุณุช.\n",
            "ูู ุฏุฑ ฺฉู ุจุงุฏ ุฏุฎุชุฑู ูู ูฺฉุดุช ุจูุชุฑ ุจูุฏ ุจูุธุฑู ูู\n",
            "ุฎูุจ ุจูุฏ . ุฑูุฌ ู ุฏุฑุฏ ู ูุฑุจ ู ูฺฉุฑ ุฑู ุฏุฑ ุฌุงูุนู  ุฑู ูุดุงู ูุฏูุฏ . ุงฺฉุซุฑุง ููุช ุจู ูุฏุฑุช ฺฉู ู ุฑุณูุฏ ูุฑุงููุด ู ฺฉููุฏ ูุฏู ูุง ูพุงฺฉ ุฑู . ู ุฌุงูุนู ุฑู ุจู ุชุฎุฏุฑ ู ฺฉุดุงููุฏ.\n",
            "ุฎูุจ ุจูุฏ . ุฑูุฌ ู ุฏุฑุฏ ู ูุฑุจ ู ูฺฉุฑ ุฑู ุฏุฑ ุฌุงูุนู  ุฑู ูุดุงู ูุฏูุฏ . ุงฺฉุซุฑุง ููุช ุจู ูุฏุฑุช ฺฉู ู ุฑุณูุฏ ูุฑุงููุด ู ฺฉููุฏ ูุฏู ูุง ูพุงฺฉ ุฑู . ู ุฌุงูุนู ุฑู ุจู ุชุฎุฏุฑ ู ฺฉุดุงููุฏ.\n",
            "ุดูุง ุฎู ุฎูุจุฏ ููููู ุญุฑู ูุฏุงุฑู๐\n",
            "ุดูุง ุฎู ุฎูุจุฏ ููููู ุญุฑู ูุฏุงุฑู\n",
            "ุจ ูุธุฑ ุจูุฏ.ุชุง ุฏุฑ ููุช ุจุฏุงุฑ ูููุฏู ู ุชูููุด ฺฉุฑุฏู.\n",
            "ุจ ูุธุฑ ุจูุฏ.ุชุง ุฏุฑ ููุช ุจุฏุงุฑ ูููุฏู ู ุชูููุด ฺฉุฑุฏู.\n",
            "ุฎูุจ....\n",
            "ุฎูุจ....\n",
            "๏บ๏บ ๏ปญ๏ป๏บ๏ปฒ ๏บ๏ปช ๏ฎ๏บฌ๏บท๏บ๏ปช ๏บญ๏บ๏ปฎ๏ป ๏ปง๏ปค๏ปด๏ป๏ปจ๏ปช ๏บง๏ปด๏ป๏ปฒ ๏ป๏บด๏ป ๏ป๏ปจ๏ปจ๏บช๏บณ๏บ ( ุง๏ป๏บ๏บ๏ปช ๏บท๏บ๏ปณ๏บช ๏ป๏ป๏ป ๏บ๏บฎุง ๏ปฃ๏ปฆ ๏ป๏ปช ุง๏บฏ ๏ป๏ป๏ปค๏บ๏บ ๏ป๏ป๏ปค๏บ๏ปช ๏บณ๏ปด๏บ๏บณ๏ปฒ ๏ญผ๏ปด๏บฐ๏ปฑ ๏ปง๏ปค๏ปด๏บช๏ปญ๏ปง๏ปข)  ๏ปญ๏ป๏ปฒ ๏บ๏ป๏บช๏บต ๏บง๏ปด๏ป๏ปฒ ๏บง๏ปฎ๏บ ๏ปฃ๏ปด๏บธ๏ปช.  ๏บฉ๏ปญ๏บณ๏บ ๏บฉุง๏บท๏บ๏ปข.\n",
            "๏ป๏บ๏ป๏ญฝ๏ปช ุง๏บฏ๏บ ๏ปฃ๏ปค๏ปจ๏ปฎ๏ปง๏ปข ๏บง๏ปด๏ป๏ปฒ ๏ปญ๏ปุช  ๏บ๏ปฎ๏บฉ ๏ป๏บ๏บ๏บ ๏ปง๏บจ๏ปฎ๏ปง๏บช๏ปฉ ๏บ๏ปฎ๏บฉ๏ปก !\n",
            "         ( ุง   ุง   ุง     )      .   ุง.\n",
            " ุง   ุช      !\n",
            "ฺฉุชุงุจ ููููู ุงูุนุงุฏู!  ุทุฑุฒ ูฺฉุฑุด ฺฉุงููุง ุฐูู ุฑู ุฏุฑฺฏุฑ ูฺฉูู ู ุขุฏู ุฑู ุฏูุจุงู ุฎูุฏุด ูฺฉุดููู. ูู ฺฉุงุด ุชู ุฎูุงุตู ฺฉุชุงุจ ุฏุงุณุชุงู ุฑู ูู ูุฏุฏ! ุฎูุดุจุฎุชุงูู ูู ุฎูุฏู ุฎูุงุตู ุฑู ุจุนุฏ ุฎููุฏู ฺฉุชุงุจ ุฏุฏู.\n",
            "ฺฉุชุงุจ ููููู ุงูุนุงุฏู!  ุทุฑุฒ ูฺฉุฑุด ฺฉุงููุง ุฐูู ุฑู ุฏุฑฺฏุฑ ูฺฉูู ู ุขุฏู ุฑู ุฏูุจุงู ุฎูุฏุด ูฺฉุดููู. ูู ฺฉุงุด ุชู ุฎูุงุตู ฺฉุชุงุจ ุฏุงุณุชุงู ุฑู ูู ูุฏุฏ! ุฎูุดุจุฎุชุงูู ูู ุฎูุฏู ุฎูุงุตู ุฑู ุจุนุฏ ุฎููุฏู ฺฉุชุงุจ ุฏุฏู.\n",
            "ุนุงุงุงู.ูุฑุณ.\n",
            "ุนุงุงุงู.ูุฑุณ.\n",
            "ูุงูุนุง ูุดูฺฏ ุจูุฏ .ูุฑุณ ุทุงูฺู\n",
            "ูุงูุนุง ูุดูฺฏ ุจูุฏ .ูุฑุณ ุทุงูฺู\n",
            "ฺุฑุง  ุชู ุชูุถุญุงุช ูฺฏู ฺฉู \" ููฺฏู ุฏูุจุณุชู ููุณุฑ ููุฏุฑุฑ ูุดูุฏ\" ุุุุ!!! ๐\n",
            "ฺุฑุง  ุชู ุชูุถุญุงุช ูฺฏู ฺฉู \" ููฺฏู ุฏูุจุณุชู ููุณุฑ ููุฏุฑุฑ ูุดูุฏ\" ุุุุ!!! \n",
            "ููููู ฺฉู ุฑุงฺฏุงู ฺฉุฑุฏุฏ\n",
            "\n",
            "ููููู ฺฉู ุฑุงฺฏุงู ฺฉุฑุฏุฏ\n",
            "\n",
            "ูพูุฌ ุณุชุงุฑู ุงูู ุจุฑุง ฺฉุชุงุจ\n",
            "ูพูุฌ ุณุชุงุฑู ุฏูู ูุงุณู ุงูุชุดุงุฑุงุช ุฌุงู ฺฉู ฺฉุชุงุจ ุฑู ุฑุงฺฏุงู ูุฑุงุฑ ุฏุงุฏู\n",
            "ูพูุฌ ุณุชุงุฑู ุงูู ุจุฑุง ฺฉุชุงุจ\n",
            "ูพูุฌ ุณุชุงุฑู ุฏูู ูุงุณู ุงูุชุดุงุฑุงุช ุฌุงู ฺฉู ฺฉุชุงุจ ุฑู ุฑุงฺฏุงู ูุฑุงุฑ ุฏุงุฏู\n",
            "ููููู ฺฉู ุฑุงฺฏุงู ุจูุฏ  ู ุชุง ุตุจุญ ุจุฏุงุฑ ูููุฏู ุจุฑุง ุฎููุฏูุด ู ูุฐุช ุจุฑุฏู\n",
            "ููููู ฺฉู ุฑุงฺฏุงู ุจูุฏ  ู ุชุง ุตุจุญ ุจุฏุงุฑ ูููุฏู ุจุฑุง ุฎููุฏูุด ู ูุฐุช ุจุฑุฏู\n",
            "ุฎู ฺฉูุชุงู ุจูุฏ\n",
            "ุณุงุณ ู ุฑูุญู ุฌูฺฏุฌู \n",
            "ุฏุฑฺฉู ูู ุฎูุดู ูููุฏ\n",
            "ุฎู ฺฉูุชุงู ุจูุฏ\n",
            "ุณุงุณ ู ุฑูุญู ุฌูฺฏุฌู \n",
            "ุฏุฑฺฉู ูู ุฎูุดู ูููุฏ\n",
            "ุฎูุงูุฏู ุด ุจุณุงุฑ ุจุฑุงู ูุฐุช ุจุฎุด ุจูุฏ!\n",
            "ุฎูุงูุฏู ุด ุจุณุงุฑ ุจุฑุงู ูุฐุช ุจุฎุด ุจูุฏ!\n",
            "ุฎู ุฒุจุง ุจูุฏ\n",
            "ุฎู ุฒุจุง ุจูุฏ\n",
            "ุจุณุงุฑ ุจุณุงุฑ ุนุงู ุจูุฏ ุ ููููู\n",
            "ุจุณุงุฑ ุจุณุงุฑ ุนุงู ุจูุฏ ุ ููููู\n",
            "ุงุฑุฒุด ุฎููุฏูู ุฏุงุดุช ุชุง ุงูุงู ฺฉ ูพูุฌ ุตุจุญู ู ุณุฑู ุฎููุฏูุด ูุชููุณุชู ููุด ฺฉูู ูููููู ุงุฒุชูู \n",
            "ุงุฑุฒุด ุฎููุฏูู ุฏุงุดุช ุชุง ุงูุงู ฺฉ ูพูุฌ ุตุจุญู ู ุณุฑู ุฎููุฏูุด ูุชููุณุชู ููุด ฺฉูู ูููููู ุงุฒุชูู \n",
            "ุจุง ุณูุงูุ ูููููู ุงุฒ ููุน ูุฑุงุด ู ุงุฌุงุฏ ุณูููุช ุฏุฑ ุฎูุงูุฏู\n",
            "ุจุง ุณูุงูุ ูููููู ุงุฒ ููุน ูุฑุงุด ู ุงุฌุงุฏ ุณูููุช ุฏุฑ ุฎูุงูุฏู\n",
            "jaleb va gooyaye jameaye emroozi\n",
            "jaleb va gooyaye jameaye emroozi\n",
            "ุจุณุงุฑ ูุฐุช ุจุฑุฏู ุงุฒ ุฎูุงูุฏู ฺฉุชุงุจ \n",
            "ููููู ุงุฒ ุฒุญูุงุชุชูู\n",
            "ุจุณุงุฑ ูุฐุช ุจุฑุฏู ุงุฒ ุฎูุงูุฏู ฺฉุชุงุจ \n",
            "ููููู ุงุฒ ุฒุญูุงุชุชูู\n",
            "ุฎูุงูุฏู ู ูุฐุช ุจุฑุฏู..ุนุงู ุจูุฏ. \n",
            "ุฎูุงูุฏู ู ูุฐุช ุจุฑุฏู..ุนุงู ุจูุฏ. \n",
            "ูุดุฑู ุจุณุงุฑ ูุฒู ู ุฏูุณุช ุฏุงุดุชูโุงู.\n",
            "ูุดุฑู ุจุณุงุฑ ูุฒู ู ุฏูุณุช ุฏุงุดุชูโุงู.\n",
            "ุฏู ฺฏุฑูู ุนูุฏู ุฏุฑ ุจุฑุฎูุฑุฏ ุจุง  ููฺู ูุธุฑู ูุง ู ฺฉุชุงุจุง ูุณุช.\n",
            "ุงูู ุฑูุดููฺฉุฑ ููุงูุง ฺฉู ููู ุฒูุฑุดููู ูุฒูู ุจู ฺุฒุง ุงูุงู ุจุงุฑู ฺฉู ุชูุด ุฎุจุฑ ุงุฒ ุฏู ู ุงู ุญุฑูุง ู ุงุณูุงู ูุจุงุดูุ ูู ุจู ูุฑ ุญุงู  ุฑูุด ูุนูู ุจุฑุง ุฒูุฏฺฏ ุจู ุฏุณุช ุจุฏู. ุจุฑุง ููู ฺฉูุง ุชุงุฏุด ูฺฉูู\n",
            "ุฏูู ููููุง ู ุฏู ุฏุงุฑุง ฺฉู ฺูู ูฺ ฺฉุฌุง ุงู ฺฉุชุงุจุง ุงุณู ุฎุฏุง ูุณุช ุงุณุชูุจุงุท ูฺฉููุ ฺฉุชุงุจ ุฏุงุฑู ูฺฏู ฺฉุงุฑุง ฺฉู ุฎุฏุง ูฺฉููุ ูุซูุง ุญุงุฌุช ูุฏูุ ุชุญุช ุชุณูุท ฺฉุงูู ุฎูุฏู ุงูุณุงูู ฺฉู ุนู ุฎุฏุงู ูุฌูุฏ ูุฏุงุฑู. ุจุฑุง ููู ฺฉูุง ุฑุฏุด ูฺฉูู.\n",
            "ุญุงูุง ุจุงุฏ ุจุดูู ฺฉู ูฺฏุง ฺฉููุ ุงููุง ุงฺฏู ุจู ุฎุฏุง ุจู ุงูู ุจุฒุฑฺฏุช ุงูุงู ุฏุงุฑ ู ูฺฉ ูฺฉู ุณุงุฒู ฺฉุงุฑ ุฌูุงู ุงูููุฏุฑ ุณุงุฏุณุช ฺฉู ุชู ุฏุฑฺฉุด ฺฉู ู ฺุฒู ุฑุฏ ุง ุงุซุจุงุช ฺฉูุ ูู ูุนุทูุ ูฺู ุงุฒ ุงูู ุงุนุชูุงุฏุงุชุช ููููุฏ.\n",
            "ุงฺฏู ูู ุฌุฒู ุฏุณุชู ุงูู ฺฉูุ ุจุฑุง ูู ุจฺฏู ุฏููุง ุชูุฌู ู ุชูุฑฺฉุฒ ฺฉุฒุฏู ุฑู  ฺุฒุ ู ู ูฺฉุฑุดู ฺฉุฑุฏูุ ุจุง ุฏุนุง ฺฉุฑุฏู ู ุฎูุงุณุชูุด ฺู ูุฑู ุฏุงุฑูุ \n",
            "ุงุฒ ูุญุงุธ ุนุฑูุงู ุฌูุชุชูู ุฏุงุฑุฏ  ฺุฒู ูฺฏุฏุ :)))) ุฌูุชุชููู ุจุงูู ุฏุนูุงุชููู\n",
            "ุฏู ฺฏุฑูู ุนูุฏู ุฏุฑ ุจุฑุฎูุฑุฏ ุจุง  ููฺู ูุธุฑู ูุง ู ฺฉุชุงุจุง ูุณุช.\n",
            "ุงูู ุฑูุดููฺฉุฑ ููุงูุง ฺฉู ููู ุฒูุฑุดููู ูุฒูู ุจู ฺุฒุง ุงูุงู ุจุงุฑู ฺฉู ุชูุด ุฎุจุฑ ุงุฒ ุฏู ู ุงู ุญุฑูุง ู ุงุณูุงู ูุจุงุดูุ ูู ุจู ูุฑ ุญุงู  ุฑูุด ูุนูู ุจุฑุง ุฒูุฏฺฏ ุจู ุฏุณุช ุจุฏู. ุจุฑุง ููู ฺฉูุง ุชุงุฏุด ูฺฉูู\n",
            "ุฏูู ููููุง ู ุฏู ุฏุงุฑุง ฺฉู ฺูู ูฺ ฺฉุฌุง ุงู ฺฉุชุงุจุง ุงุณู ุฎุฏุง ูุณุช ุงุณุชูุจุงุท ูฺฉููุ ฺฉุชุงุจ ุฏุงุฑู ูฺฏู ฺฉุงุฑุง ฺฉู ุฎุฏุง ูฺฉููุ ูุซูุง ุญุงุฌุช ูุฏูุ ุชุญุช ุชุณูุท ฺฉุงูู ุฎูุฏู ุงูุณุงูู ฺฉู ุนู ุฎุฏุงู ูุฌูุฏ ูุฏุงุฑู. ุจุฑุง ููู ฺฉูุง ุฑุฏุด ูฺฉูู.\n",
            "ุญุงูุง ุจุงุฏ ุจุดูู ฺฉู ูฺฏุง ฺฉููุ ุงููุง ุงฺฏู ุจู ุฎุฏุง ุจู ุงูู ุจุฒุฑฺฏุช ุงูุงู ุฏุงุฑ ู ูฺฉ ูฺฉู ุณุงุฒู ฺฉุงุฑ ุฌูุงู ุงูููุฏุฑ ุณุงุฏุณุช ฺฉู ุชู ุฏุฑฺฉุด ฺฉู ู ฺุฒู ุฑุฏ ุง ุงุซุจุงุช ฺฉูุ ูู ูุนุทูุ ูฺู ุงุฒ ุงูู ุงุนุชูุงุฏุงุชุช ููููุฏ.\n",
            "ุงฺฏู ูู ุฌุฒู ุฏุณุชู ุงูู ฺฉูุ ุจุฑุง ูู ุจฺฏู ุฏููุง ุชูุฌู ู ุชูุฑฺฉุฒ ฺฉุฒุฏู ุฑู  ฺุฒุ ู ู ูฺฉุฑุดู ฺฉุฑุฏูุ ุจุง ุฏุนุง ฺฉุฑุฏู ู ุฎูุงุณุชูุด ฺู ูุฑู ุฏุงุฑูุ \n",
            "ุงุฒ ูุญุงุธ ุนุฑูุงู ุฌูุชุชูู ุฏุงุฑุฏ  ฺุฒู ูฺฏุฏุ :)))) ุฌูุชุชููู ุจุงูู ุฏุนูุงุชููู\n",
            "ููุณูุฏุด ูุงฺฉู ุฌฺฉุณููู๐จ๐จ๐จ๐จ๐จ๐จ๐จ\n",
            "ููุณูุฏุด ูุงฺฉู ุฌฺฉุณููู\n",
            "ูุงููู ุฌุฐุจ ุฏุฑูุบู ูุญุถู....\n",
            "ูุงููู ุฌุฐุจ ุฏุฑูุบู ูุญุถู....\n",
            "ุณูุงูุ ููููู ุงุฒ ุงุฑุงู ฺฉุชุงุจูุง ููุฏุชููุ ุงู ฺฉุชุงุจ ููู ุงูุนุงุฏู ุจูุฏ ู ุฎู ุงุฒ ูฺฉุงุช ุฑุฒ ุฑู ุฏุฑ ููุฑุฏ ูุงููู ุฌุฐุจ ฺฉู ุฏุฑ ฺฉุชุงุจูุง ุฏฺฏู ุงุดุงุฑู ูุดุฏูุ ุจุงู ูฺฉูู\n",
            "ุณูุงูุ ููููู ุงุฒ ุงุฑุงู ฺฉุชุงุจูุง ููุฏุชููุ ุงู ฺฉุชุงุจ ููู ุงูุนุงุฏู ุจูุฏ ู ุฎู ุงุฒ ูฺฉุงุช ุฑุฒ ุฑู ุฏุฑ ููุฑุฏ ูุงููู ุฌุฐุจ ฺฉู ุฏุฑ ฺฉุชุงุจูุง ุฏฺฏู ุงุดุงุฑู ูุดุฏูุ ุจุงู ูฺฉูู\n",
            "ูุทุงูุจ ููุฏ ุฏุงุดุช ููููู\n",
            "ูุทุงูุจ ููุฏ ุฏุงุดุช ููููู\n",
            "ุงููู ฺฉุชุงุจ ุจูุฏ ฺฉู ุงุฒ \"ูุงุฑุชู ุณูฺฏูู\" ูุทุงูุนู ฺฉุฑุฏู.\n",
            "ุฌูุงุจ ุณูฺฏูู ุงููู ฺฉุณ ุงุณุช ฺฉู ุจู ุทูุฑ ุฑุณู ุงุฒ\" ุฑูุงูุดูุงุณ ูุซุจุช\" ู ฺฏูุฏ ู ุดุงุฎู  ุฌุฏุฏ ุจู ุนููุงู \"ุฑูุงูุดูุงุณ ูุซุจุช \" ุฑุง ุจู ุนูู ุฑูุงูุดูุงุณ ุงุถุงูู ฺฉุฑุฏู ุงุณุช.\n",
            "ูุทุงูุจ ฺฉุชุงุจ ฺฉุงุฑุจุฑุฏ ุงุณุช.\n",
            "ฺูุฏ ุชุณุช ุชุดุฎุต ุงูุณุฑุฏฺฏ ู ุฑูุดูุง ููุงุจูู ุจุง ุงูุณุฑุฏฺฏ ุฑุง ูุทุฑุญ ฺฉุฑุฏู ุงุณุช ฺฉู ุจู ูุธุฑู ฺฉุงุฑฺฏุดุง ุจูุฏ.\n",
            "ุฏุฑ ฺฉูุงุฑ ุชูุงู ุงููุง ูุจุงุฏ ุงุฒ ุชุฑุฌูู ุบุงูู ุดุฏุ ุชุฑุฌูู  ุฎูุจ ุฏุงุดุช.\n",
            "ุฌุฏุง ุงุฒ ูุทุงูุจ ฺฉุชุงุจ ุจุฑุง ุฏุฑูุงู ุงูุณุฑุฏฺฏุูุจุงุฏ ุงุฒ ุฑฺู ุบุฐุง ููุงุณุจ ู ุฏูููุดูุง ููุซุฑ ุจุฑุง ุงุฌุงุฏ ุขุฑุงูุด ู ุดุงุฏ ู ูุดุงุท ุบููุช ฺฉุฑุฏ.\n",
            "ุงููู ฺฉุชุงุจ ุจูุฏ ฺฉู ุงุฒ \"ูุงุฑุชู ุณูฺฏูู\" ูุทุงูุนู ฺฉุฑุฏู.\n",
            "ุฌูุงุจ ุณูฺฏูู ุงููู ฺฉุณ ุงุณุช ฺฉู ุจู ุทูุฑ ุฑุณู ุงุฒ\" ุฑูุงูุดูุงุณ ูุซุจุช\" ู ฺฏูุฏ ู ุดุงุฎู  ุฌุฏุฏ ุจู ุนููุงู \"ุฑูุงูุดูุงุณ ูุซุจุช \" ุฑุง ุจู ุนูู ุฑูุงูุดูุงุณ ุงุถุงูู ฺฉุฑุฏู ุงุณุช.\n",
            "ูุทุงูุจ ฺฉุชุงุจ ฺฉุงุฑุจุฑุฏ ุงุณุช.\n",
            "ฺูุฏ ุชุณุช ุชุดุฎุต ุงูุณุฑุฏฺฏ ู ุฑูุดูุง ููุงุจูู ุจุง ุงูุณุฑุฏฺฏ ุฑุง ูุทุฑุญ ฺฉุฑุฏู ุงุณุช ฺฉู ุจู ูุธุฑู ฺฉุงุฑฺฏุดุง ุจูุฏ.\n",
            "ุฏุฑ ฺฉูุงุฑ ุชูุงู ุงููุง ูุจุงุฏ ุงุฒ ุชุฑุฌูู ุบุงูู ุดุฏุ ุชุฑุฌูู  ุฎูุจ ุฏุงุดุช.\n",
            "ุฌุฏุง ุงุฒ ูุทุงูุจ ฺฉุชุงุจ ุจุฑุง ุฏุฑูุงู ุงูุณุฑุฏฺฏุูุจุงุฏ ุงุฒ ุฑฺู ุบุฐุง ููุงุณุจ ู ุฏูููุดูุง ููุซุฑ ุจุฑุง ุงุฌุงุฏ ุขุฑุงูุด ู ุดุงุฏ ู ูุดุงุท ุบููุช ฺฉุฑุฏ.\n",
            "ุณูุงู\n",
            "ููุช ฺฉุชุงุจ ุฑุง ูฃููู ุชููุงู ุฒุฏู ุงุณุช ูู ููุช ูุฎูุงูุฏ ฺฉุชุงุจ ุฑุง ุจุฎุฑุฏ ููุช ูกูขตูู ุฑุง ูุดุงู ูุฏูุฏ!\n",
            "ุณูุงู\n",
            "ููุช ฺฉุชุงุจ ุฑุง ูฃููู ุชููุงู ุฒุฏู ุงุณุช ูู ููุช ูุฎูุงูุฏ ฺฉุชุงุจ ุฑุง ุจุฎุฑุฏ ููุช ูกูขตูู ุฑุง ูุดุงู ูุฏูุฏ!\n",
            "ุจุฑุง ูู ุฎู ฺฉุงุฑุจุฑุฏ ุจูุฏ ุดุงุฏ ฺูู ุฏุฑ ุดุฑุงุท ุฎููุฏู ฺฉู ุจูุด ูุงุฒ ุฏุงุดุชู . ูุซุงู ูุง ุฒุงุฏ ฺฉุชุงุจ ุจุงุนุซ ูุดู ุงุตู ุญุฑู ฺฉุชุงุจ ุจุฑุง ุขุฏู ุฌุง ุจูุชู ู ูู ุงุฒ ุจุนุฏ ุฎููุฏู ุงู ฺฉุชุงุจ ูุงูุนุง ุชููุณุชู ุจู ุฎู ุงุฒ ุจุฏุจู ูุงู ุบูุจู ฺฉูู ู ฺฉูุชุฑ ุจู ุจุงูุฑูุง ุงุดุชุจุงูู ุงุฌุงุฒู  ุนุฑุถ ุงูุฏุงู ุจุฏูโบ ฺฏูุง ฺฉุชุงุจ ุฎูุงุตู ุดุฏู ุณุช ูู ุจู ูุธุฑู ุจุงุฒู ุฎู ุชฺฉุฑุงุฑ ุฏุงุฑู ูพุดููุงุฏ ูฺฉูู ุญู ูุทุงูุนู ูฺฉุชู ุจุฑุฏุงุฑ ฺฉูุฏ\n",
            "ุจุฑุง ูู ุฎู ฺฉุงุฑุจุฑุฏ ุจูุฏ ุดุงุฏ ฺูู ุฏุฑ ุดุฑุงุท ุฎููุฏู ฺฉู ุจูุด ูุงุฒ ุฏุงุดุชู . ูุซุงู ูุง ุฒุงุฏ ฺฉุชุงุจ ุจุงุนุซ ูุดู ุงุตู ุญุฑู ฺฉุชุงุจ ุจุฑุง ุขุฏู ุฌุง ุจูุชู ู ูู ุงุฒ ุจุนุฏ ุฎููุฏู ุงู ฺฉุชุงุจ ูุงูุนุง ุชููุณุชู ุจู ุฎู ุงุฒ ุจุฏุจู ูุงู ุบูุจู ฺฉูู ู ฺฉูุชุฑ ุจู ุจุงูุฑูุง ุงุดุชุจุงูู ุงุฌุงุฒู  ุนุฑุถ ุงูุฏุงู ุจุฏู ฺฏูุง ฺฉุชุงุจ ุฎูุงุตู ุดุฏู ุณุช ูู ุจู ูุธุฑู ุจุงุฒู ุฎู ุชฺฉุฑุงุฑ ุฏุงุฑู ูพุดููุงุฏ ูฺฉูู ุญู ูุทุงูุนู ูฺฉุชู ุจุฑุฏุงุฑ ฺฉูุฏ\n",
            "ูุชุงุณูุงูู ุญุช ููุดู ฺฏูุช ุงู ฺฉุชุงุจ ุชุฑุฌูู ุจุฏ ุฏุงุฑู. ฺุฑุง ฺฉู ุจู ูฺ ุนููุงู ุจู ูุชู ูุณุฎู ุงุตู ููุง ุฏุงุฑ ูุจูุฏู ู ุจุดุชุฑ ุดุจู ุจู ูุช ุจุฑุฏุงุฑ ู ุฌุฒูู ููุณ ุงุฒ ฺฉุชุงุจ ุงุตู ุณุช. ุจู ุฑุงุญุช ูุดู ูุณุฎู ุงูฺฏูุณ ุณููพู ฺฉุชุงุจ ุฑู ุงุฒ ฺฏูฺฏู playbook ุจฺฏุฑุฏ - ฺฉู ูุฌุงู ูู ูุณุช - ู ููุงุณู ฺฉูุฏ. ูู ูุตู ุงูู ุงู ฺฉุชุงุจ ุฑู ุฎููุฏู ู ฺฏุฐุงุดุชู ุฒูู ู ูุธุฑ ุฏุฑ ููุฑุฏ ุจูู ูุตูโูุง ูุฏุงุฑู.\n",
            "ูุชุงุณูุงูู ุญุช ููุดู ฺฏูุช ุงู ฺฉุชุงุจ ุชุฑุฌูู ุจุฏ ุฏุงุฑู. ฺุฑุง ฺฉู ุจู ูฺ ุนููุงู ุจู ูุชู ูุณุฎู ุงุตู ููุง ุฏุงุฑ ูุจูุฏู ู ุจุดุชุฑ ุดุจู ุจู ูุช ุจุฑุฏุงุฑ ู ุฌุฒูู ููุณ ุงุฒ ฺฉุชุงุจ ุงุตู ุณุช. ุจู ุฑุงุญุช ูุดู ูุณุฎู ุงูฺฏูุณ ุณููพู ฺฉุชุงุจ ุฑู ุงุฒ ฺฏูฺฏู playbook ุจฺฏุฑุฏ - ฺฉู ูุฌุงู ูู ูุณุช - ู ููุงุณู ฺฉูุฏ. ูู ูุตู ุงูู ุงู ฺฉุชุงุจ ุฑู ุฎููุฏู ู ฺฏุฐุงุดุชู ุฒูู ู ูุธุฑ ุฏุฑ ููุฑุฏ ุจูู ูุตูโูุง ูุฏุงุฑู.\n",
            "ฺฉุชุงุจ ุฑูุงู ูุจูุฏ ูู ุฏุฑ ุนู ุญุงู ูฺฉุงุช ุฌุงูุจ ูู ุฏุฑููุด ุจูุฏ ุชุง ุตูุญู ุตุฏ\n",
            "ุงุฒ ุตูุญู ุตุฏ ุจู ุจุนุฏ ุงูุฏูุงุฑ ฺฉููุฏู ู ุฑุงู ุญู ุจุฑุง ูุจุงุฑุฒู ุจุง ุฎูุฏุชูู ูุฏู ฺฉู ุนุงูู\n",
            "๐๐โ๏ธ\n",
            "ฺฉุชุงุจ ุฑูุงู ูุจูุฏ ูู ุฏุฑ ุนู ุญุงู ูฺฉุงุช ุฌุงูุจ ูู ุฏุฑููุด ุจูุฏ ุชุง ุตูุญู ุตุฏ\n",
            "ุงุฒ ุตูุญู ุตุฏ ุจู ุจุนุฏ ุงูุฏูุงุฑ ฺฉููุฏู ู ุฑุงู ุญู ุจุฑุง ูุจุงุฑุฒู ุจุง ุฎูุฏุชูู ูุฏู ฺฉู ุนุงูู\n",
            "\n",
            "ุฏุฑ ูุฌููุน ฺฉุชุงุจ ฺฉุงุฑุจุฑุฏ ุจุง ุฑุงูฺฉุงุฑูุง ุนููู. ุงูุง ูู ุฎูุงุตู ุดุฏู ู ูู ุงุดฺฉุงูุงุช ูฺฏุงุฑุด ู ุญุช ุงููุง ุฏุงุฑู.\n",
            "ุฏุฑ ูุฌููุน ฺฉุชุงุจ ฺฉุงุฑุจุฑุฏ ุจุง ุฑุงูฺฉุงุฑูุง ุนููู. ุงูุง ูู ุฎูุงุตู ุดุฏู ู ูู ุงุดฺฉุงูุงุช ูฺฏุงุฑุด ู ุญุช ุงููุง ุฏุงุฑู.\n",
            "ฺฉุชุงุจ ุฎูุจ ุจูุฏ ูุฎุตูุตุง ุจุฎุด ุณูู ฺฉู ุฑุงูฺฉุงุฑูุง ุนูู ุงุฑุงุฆู ุฏุงุฏู ุจูุฏ. ฺูู ุฎูุงุตู ุงุณุช ูุทุงูุจ ฺฉู ฺฏูฺฏ ูุณุชู ู ุฎูุจ ุจุฑุง ุฎูุงููุฏู ุฌุง ูููุชู\n",
            "ุฑุงูฺฉุงุฑูุง ูุงุฒ ุจู ุชูุฑู ุฏุงุฑู ุชุง ุชุจุฏู ุจู ุนุงุฏุช ุจุดู\n",
            "ฺฉุชุงุจ ุฎูุจ ุจูุฏ ูุฎุตูุตุง ุจุฎุด ุณูู ฺฉู ุฑุงูฺฉุงุฑูุง ุนูู ุงุฑุงุฆู ุฏุงุฏู ุจูุฏ. ฺูู ุฎูุงุตู ุงุณุช ูุทุงูุจ ฺฉู ฺฏูฺฏ ูุณุชู ู ุฎูุจ ุจุฑุง ุฎูุงููุฏู ุฌุง ูููุชู\n",
            "ุฑุงูฺฉุงุฑูุง ูุงุฒ ุจู ุชูุฑู ุฏุงุฑู ุชุง ุชุจุฏู ุจู ุนุงุฏุช ุจุดู\n",
            "ฺุฑุง ฺฉุชุงุจ ุดุงุฏูุงู ุฏุฑูู ุงุฒ ุงู ููุณูุฏู ุฑู ููุฒุงุฑุฏ ุ\n",
            "ฺุฑุง ฺฉุชุงุจ ุดุงุฏูุงู ุฏุฑูู ุงุฒ ุงู ููุณูุฏู ุฑู ููุฒุงุฑุฏ ุ\n",
            "ุจุฑุง ุฒูุฏฺฏู ุฎููุฏู ููุท!\n",
            "ฺฉุงุด ต ุ ถ ุณุงู ุฒูุฏุชุฑ ุฎููุฏู ุจูุฏู\n",
            "ุง ฺฉุงุด ฺฉุชุงุจูุง ุฏฺฏุด ุฑู ูู ุจุฒุงุฑู\n",
            "ุจุฑุง ุฒูุฏฺฏู ุฎููุฏู ููุท!\n",
            "ฺฉุงุด ต ุ ถ ุณุงู ุฒูุฏุชุฑ ุฎููุฏู ุจูุฏู\n",
            "ุง ฺฉุงุด ฺฉุชุงุจูุง ุฏฺฏุด ุฑู ูู ุจุฒุงุฑู\n",
            "ูุณุฎู ฺุงูพ ุดู ุฏุงุฑูุ ุนุงูู\n",
            "ูุณุฎู ฺุงูพ ุดู ุฏุงุฑูุ ุนุงูู\n",
            "ูฺฉุฑ ูฺฉูู ฺฉุชุงุจ ุจุง ูุถุง ุฌุฏุฏ ู ุญุฑููุง ุฌุฏุฏ ุจู ุฎูุงููุฏฺฏุงู .ุชูุฏู ฺฉุฑุฏูุ ู ุฎูุงูุฏู ุขู ุฎุงู ุงุฒ ูุทู ูุณุช\n",
            "ูฺฉุฑ ูฺฉูู ฺฉุชุงุจ ุจุง ูุถุง ุฌุฏุฏ ู ุญุฑููุง ุฌุฏุฏ ุจู ุฎูุงููุฏฺฏุงู .ุชูุฏู ฺฉุฑุฏูุ ู ุฎูุงูุฏู ุขู ุฎุงู ุงุฒ ูุทู ูุณุช\n",
            "ุฎู ุฎูุดู ูููุฏุ ุจ ูุธุฑู ุจุดุชุฑ ุจ ุฏุฑุฏ ฺฉุณุง ูุฎูุฑู ฺฉ ุจุฎูุงู  ูุฑูุฑ ุจุฑ ุชุงุฑุฎ ุงุฏุจุงุช ูุนุงุตุฑ ุฏุงุดุชู ุจุงุดูุฏ.\n",
            "ุฎู ุฎูุดู ูููุฏุ ุจ ูุธุฑู ุจุดุชุฑ ุจ ุฏุฑุฏ ฺฉุณุง ูุฎูุฑู ฺฉ ุจุฎูุงู  ูุฑูุฑ ุจุฑ ุชุงุฑุฎ ุงุฏุจุงุช ูุนุงุตุฑ ุฏุงุดุชู ุจุงุดูุฏ.\n",
            "ฺฉุงุด ฺฉุชุงุจุงุฑู ูุฑูุด ูู ุฏุงุดุชู\n",
            "ฺฉุงุด ฺฉุชุงุจุงุฑู ูุฑูุด ูู ุฏุงุดุชู\n",
            "ุจุฑุฎูุงู ุนููุงู ุจู ุดุฏุช ูุฌุฐูุจ ฺฉููุฏู ุงู ฺฉุชุงุจ ุงุฒ ูุธุฑ ูู ฺุฒ ุฒุงุฏ ุจุฑุง ฺฏูุชู ูุฏุงุฑุฏ\n",
            "ุจุฑุฎูุงู ุนููุงู ุจู ุดุฏุช ูุฌุฐูุจ ฺฉููุฏู ุงู ฺฉุชุงุจ ุงุฒ ูุธุฑ ูู ฺุฒ ุฒุงุฏ ุจุฑุง ฺฏูุชู ูุฏุงุฑุฏ\n",
            "ุชุฑุฌูู ุฑููู ูุจูุฏ..ูู ูุณุฎู ฺุงูพ ููู ุชุฑุฌูู ู ุงูุชุดุงุฑุงุช ุฑู ุฎููุฏู..ููุดุชู ูุง ูพุงุฆููู ูุทูุฆูุง ุฒุจุงุณุช ูู ฺฉุงุด ูุฑ ูุชุฑุฌู ูู ูุฎูุงุฏ ูุฑ ููู ุฑู ุชุฑุฌูู ฺฉูู.\n",
            "ุชุฑุฌูู ุฑููู ูุจูุฏ..ูู ูุณุฎู ฺุงูพ ููู ุชุฑุฌูู ู ุงูุชุดุงุฑุงุช ุฑู ุฎููุฏู..ููุดุชู ูุง ูพุงุฆููู ูุทูุฆูุง ุฒุจุงุณุช ูู ฺฉุงุด ูุฑ ูุชุฑุฌู ูู ูุฎูุงุฏ ูุฑ ููู ุฑู ุชุฑุฌูู ฺฉูู.\n",
            "ููุดู ุณุน ูฺฉูู ุงุฒ ุฎููุฏู ฺฉุชุงุจุง ุชุฑุจุช ุจุง ููุณูุฏู ูุงุฑุณ ุฏูุฑ ฺฉูู.ู ุญู ฺฉู ุงูุจุงุฑ ููุงุฏุงุฑ ูุจูุฏู ู ุญุฏูุฏ ุฏูุณุงุนุช ุงุฒ ููุชูู ูุฏุฑ ุฏุงุฏู.\n",
            "ุจู ุงูุฏ ฺฉู ูุทูุจ ุจุฏุฑุฏ ุจุฎูุฑ ฺฉู ุชู ฺฉุชุงุจุง ุงูููุฑ ูุฏุฏู ุจุงุดู ุุจุจูู.\n",
            "ูฺ.\n",
            "ุจู ููุณูุฏู ูุง ุชูู ูฺฉูู ุงููุฏุฑ ุจู ุฏูุจุงู ุชุนุงุฑู ฺฉููู ูุง ู ุชูุตูุงุช ุงุถุงู ูุฑู.ู ุฑุงูฺฉุงุฑ ุจุฏู.\n",
            "ุงูุชุถุงุญ\n",
            "ููุดู ุณุน ูฺฉูู ุงุฒ ุฎููุฏู ฺฉุชุงุจุง ุชุฑุจุช ุจุง ููุณูุฏู ูุงุฑุณ ุฏูุฑ ฺฉูู.ู ุญู ฺฉู ุงูุจุงุฑ ููุงุฏุงุฑ ูุจูุฏู ู ุญุฏูุฏ ุฏูุณุงุนุช ุงุฒ ููุชูู ูุฏุฑ ุฏุงุฏู.\n",
            "ุจู ุงูุฏ ฺฉู ูุทูุจ ุจุฏุฑุฏ ุจุฎูุฑ ฺฉู ุชู ฺฉุชุงุจุง ุงูููุฑ ูุฏุฏู ุจุงุดู ุุจุจูู.\n",
            "ูฺ.\n",
            "ุจู ููุณูุฏู ูุง ุชูู ูฺฉูู ุงููุฏุฑ ุจู ุฏูุจุงู ุชุนุงุฑู ฺฉููู ูุง ู ุชูุตูุงุช ุงุถุงู ูุฑู.ู ุฑุงูฺฉุงุฑ ุจุฏู.\n",
            "ุงูุชุถุงุญ\n",
            "ุฎู ุฎูุจูููู\n",
            "ุฎู ุฎูุจูููู\n",
            "ููุดุชูโูุงู ฺฏุฑุงู ุงู ุดูุงุฑู :\n",
            "ฑ.ูุดฺฉุฑฺฉุด ุงุฑุงู ุจุฑุง ุฑูุง ูู (ุชุงุฑุฎฺู ุญุถูุฑ ูุธุงู ุงุฑุงู ุฏุฑ ูู)\n",
            "ฒ.ุจู ุฎุงุทุฑ ุฏุงุฑู ู ุญู ูโุทูุจู ( ุตุฏุณุงูฺฏ ูุณูโฺฉุด ุงุฑููโูุง ุชูุณุท ุนุซูุงู )\n",
            "ููุดุชูโูุงู ฺฏุฑุงู ุงู ุดูุงุฑู :\n",
            "ฑ.ูุดฺฉุฑฺฉุด ุงุฑุงู ุจุฑุง ุฑูุง ูู (ุชุงุฑุฎฺู ุญุถูุฑ ูุธุงู ุงุฑุงู ุฏุฑ ูู)\n",
            "ฒ.ุจู ุฎุงุทุฑ ุฏุงุฑู ู ุญู ูโุทูุจู ( ุตุฏุณุงูฺฏ ูุณูโฺฉุด ุงุฑููโูุง ุชูุณุท ุนุซูุงู )\n",
            "ฺฉุชุงุจ ฺฉู ุญุฌู ุงูุง ุงุฑุฒุดููุฏ ฺฉู ุจุฑุง ุดุฑูุน ูุฑุขูุฏ ุฎูุฏุงุฑ ุจู ุชูุงู ุณูู ุชูุตู ูุดู\n",
            "ฺฉุชุงุจ ฺฉู ุญุฌู ุงูุง ุงุฑุฒุดููุฏ ฺฉู ุจุฑุง ุดุฑูุน ูุฑุขูุฏ ุฎูุฏุงุฑ ุจู ุชูุงู ุณูู ุชูุตู ูุดู\n",
            "ูุงุณู ูู ููุท ฒฑ ุตูุญู ุงุด ุงููุฏู ุนู ุณู ูุตูุด ฺุฑุง ุงุง ููู ููุฏุงุฑ ูุณุช ุง ุงฺฏุฑ ูุณุช ฺฺฉุงุฑ ฺฉููุ\n",
            "ูุงุณู ูู ููุท ฒฑ ุตูุญู ุงุด ุงููุฏู ุนู ุณู ูุตูุด ฺุฑุง ุงุง ููู ููุฏุงุฑ ูุณุช ุง ุงฺฏุฑ ูุณุช ฺฺฉุงุฑ ฺฉููุ\n",
            "ุงู ฺฉู ดธ ุตูุญู ุณ! \n",
            "ูพุณ ุจูู ุด  ฺ ูุดูุ\n",
            "ุงู ฺฉู ดธ ุตูุญู ุณ! \n",
            "ูพุณ ุจูู ุด  ฺ ูุดูุ\n",
            "ูุฎุชุตุฑ ู ููุฏ \n",
            "ุนุงู๐\n",
            "ูุฎุชุตุฑ ู ููุฏ \n",
            "ุนุงู\n",
            "ูุงูุนุง ุจุฑุง ููุฌูุงูุงู ฺฉุชุงุจ ุฎูุจูุ\n",
            "ูฺฏุงู ูู ุฑู ุจู ุฎุงููุงุฏู ู ุฒูุฏฺฏู ุนูุถ ฺฉุฑุฏ..\n",
            "ุงูุงู ูุงูุนุง ุดุงุฏู ู ุงุฒ ุฒูุฏฺฏ ุฑุงุถ\n",
            "ูุงูุนุง ุจุฑุง ููุฌูุงูุงู ฺฉุชุงุจ ุฎูุจูุ\n",
            "ูฺฏุงู ูู ุฑู ุจู ุฎุงููุงุฏู ู ุฒูุฏฺฏู ุนูุถ ฺฉุฑุฏ..\n",
            "ุงูุงู ูุงูุนุง ุดุงุฏู ู ุงุฒ ุฒูุฏฺฏ ุฑุงุถ\n",
            "ุจุณุงุฑ ุจุณุงุฑ ุฒุจุง ู ุฏููุดู ุงุณุช .ูุงุฏู ฺฏูุฑุฏูุฑ ุนุงู ุงุณุช.ุงููุงูุนุง ุชูุงูุณุช ุงุญุณุงุณ ูุฑุง ูุณุจุช ุจู ุงู ฺฉุชุงุจ ุจุฑูู ุจฺฉุดุฏ ูุจุงุนุซ ุดูุฏ ุชุง ฺฉุชุงุจ ุฑุง ุจุด ุงุฒ ุฏูุจุงุฑ ุจุฎูุงูู.ูุจุฑุฎ ุงุฒ ูุณูุช ูุงุด ููฺฉู  ุฐููู ุดูุฏ๐ูุฑุญุจุง\n",
            "ุจุณุงุฑ ุจุณุงุฑ ุฒุจุง ู ุฏููุดู ุงุณุช .ูุงุฏู ฺฏูุฑุฏูุฑ ุนุงู ุงุณุช.ุงููุงูุนุง ุชูุงูุณุช ุงุญุณุงุณ ูุฑุง ูุณุจุช ุจู ุงู ฺฉุชุงุจ ุจุฑูู ุจฺฉุดุฏ ูุจุงุนุซ ุดูุฏ ุชุง ฺฉุชุงุจ ุฑุง ุจุด ุงุฒ ุฏูุจุงุฑ ุจุฎูุงูู.ูุจุฑุฎ ุงุฒ ูุณูุช ูุงุด ููฺฉู  ุฐููู ุดูุฏูุฑุญุจุง\n",
            "๏ปฃ๏ปค๏ปจ๏ปฎ๏ปฅ ๏ป๏บ๏บ๏บ ๏บง๏ปฎ๏บ๏ปด๏ปช ๏บ๏บ ๏ป๏ปด๏ปค๏บ ๏ปฃ๏ปจ๏บ๏บณ๏บ.๏ปซ๏ปจ๏ปฎ๏บฏ ๏ป๏ป ๏ป๏บ๏บ๏บ ๏บญ๏ปญ ๏ปง๏บจ๏ปฎ๏ปง๏บช๏ปก ๏ปญ๏ป๏ปฒ ๏บ๏บ ๏ปง๏ปด๏ปข ๏ปง๏ฎ๏บ๏ปซ๏ปฒ ๏บ๏ปช ๏ปฃ๏ป๏บช๏ปฃ๏บ๏บ ๏ปฃ๏บ๏ปฎ๏บ๏ปช ๏บท๏บช๏ปก ๏บฉ๏ป๏ปด๏ป๏บ ๏บ๏ปช ๏ปฃ๏บด๏บ๏ป๏ปช  ๏ญ๏ปด๏บธ๏บฎ๏ป๏บ ๏บ๏บค๏บผ๏ปด๏ป๏ปฒ ๏ปง๏ฎ๏บ๏ปฉ ๏ป๏ป๏ปค๏ปฒ ู ๏ป๏ปค๏ป๏ปฒ ๏บท๏บช๏ปฉ.๏บ๏บ ๏บ๏บธ๏ป๏บฎ.(๏บญุง๏บฉ)\n",
            "     .                     ู  . .(ุง)\n",
            "ุจู ูุธุฑู ุชุฑุฌูู ุจูุชุฑ ูุชูุงูุณุช ุฏุงุดุชู ุจุงุดุฏ ู ุงูุจุชู ูุฌููุนุง ุจุฑุง ุดุฑูุน ฺฉุชุงุจ ุฎูุจ ุงุณุช.\n",
            "ุจู ูุธุฑู ุชุฑุฌูู ุจูุชุฑ ูุชูุงูุณุช ุฏุงุดุชู ุจุงุดุฏ ู ุงูุจุชู ูุฌููุนุง ุจุฑุง ุดุฑูุน ฺฉุชุงุจ ุฎูุจ ุงุณุช.\n",
            "ุฏุฑูุฏ ุจุฑ ฺฉูุฑูุด ุจุฒุฑฺฏ\n",
            "ุฏุฑูุฏ ุจุฑ ฺฉูุฑูุด ุจุฒุฑฺฏ\n",
            "ุงุตููุง ุฏูู ุงู ููู ุตุญุจุช ุฑุงุฌุน ุจู ฺฉูุฑูุด ุจุฒุฑฺฏ ุงูู ฺฉู ฺุดู ุงูุซุงู ุดูุง ูุง ุฏุฑ ุจุงุฏ ุฌูุงุจ\n",
            "ุงุตููุง ุฏูู ุงู ููู ุตุญุจุช ุฑุงุฌุน ุจู ฺฉูุฑูุด ุจุฒุฑฺฏ ุงูู ฺฉู ฺุดู ุงูุซุงู ุดูุง ูุง ุฏุฑ ุจุงุฏ ุฌูุงุจ\n",
            "ุชุงุฑุฎ ู ฺฉูุฑุด ุฌููุงูฺฏุงู ููู ุดุฏู ุ ูุฑ ฺฉุณ ุงุฒ ุฑุงู ู ุฑุณุฏ ุจุฑุง ุฎุงู ูุจูุฏู ุนุฑุถู ฺฉุชุงุจ ู ุณุงุฒุฏ ุ ฺฉ ูุนูุงุฑ ุ ฺฉ ูุงููุฏ ูููู ุงู ฺฉุชุงุจ ุญุดุฑู ุดูุงุณ\n",
            "ุชุงุฑุฎ ู ฺฉูุฑุด ุฌููุงูฺฏุงู ููู ุดุฏู ุ ูุฑ ฺฉุณ ุงุฒ ุฑุงู ู ุฑุณุฏ ุจุฑุง ุฎุงู ูุจูุฏู ุนุฑุถู ฺฉุชุงุจ ู ุณุงุฒุฏ ุ ฺฉ ูุนูุงุฑ ุ ฺฉ ูุงููุฏ ูููู ุงู ฺฉุชุงุจ ุญุดุฑู ุดูุงุณ\n",
            "ุนู ุงุฑุงู ูุจู ฺฉูุฑูุด ุชุงุฑุฎ ูุฏุงุดุชู. ุชุง ุฌุง ฺฉู ูุฏููู ุชูุฏููุง ุฎู ูุฏู ุชุฑ ุฏุฑ ุงุฑุงู ูุฌูุฏ ุฏุงุดุชูุฏ ู ุฏุฑุณุช ูุณุช ฺฉู ุชุงุฑุฎ ุงุฑุงู ุฑู 2500 ุณุงูู ุจุงู ฺฉูู. ุงฺฏู ุงุดุชุจุงู ูฺฉูู ูฺฉูพุฏุง ูู ฺฉู ูุฏู ุชุฑู ฺฉุดูุฑ ุฌูุงู ุฑู ุงุฑุงู ูุงูุจุฑุฏู ุชุงุฑุฎ ุชุงุณุณ ฺฉุดูุฑ ุฏุฑุงุฑุงู ุฑู ูพูุฌ ูุฒุงุฑ ุณุงู ุจุงู ฺฉุฑุฏู.\n",
            "ุนู ุงุฑุงู ูุจู ฺฉูุฑูุด ุชุงุฑุฎ ูุฏุงุดุชู. ุชุง ุฌุง ฺฉู ูุฏููู ุชูุฏููุง ุฎู ูุฏู ุชุฑ ุฏุฑ ุงุฑุงู ูุฌูุฏ ุฏุงุดุชูุฏ ู ุฏุฑุณุช ูุณุช ฺฉู ุชุงุฑุฎ ุงุฑุงู ุฑู 2500 ุณุงูู ุจุงู ฺฉูู. ุงฺฏู ุงุดุชุจุงู ูฺฉูู ูฺฉูพุฏุง ูู ฺฉู ูุฏู ุชุฑู ฺฉุดูุฑ ุฌูุงู ุฑู ุงุฑุงู ูุงูุจุฑุฏู ุชุงุฑุฎ ุชุงุณุณ ฺฉุดูุฑ ุฏุฑุงุฑุงู ุฑู ูพูุฌ ูุฒุงุฑ ุณุงู ุจุงู ฺฉุฑุฏู.\n",
            "ุจุฑุงู ุฌุงูุจู ุจุฏููู ุฏูู ุจุฑุฎ ุงุฒ ุงูุฑุงุฏ ุงุฒ ุญูุงุชูุง ูุงุจู ุฌุง ุงุฒ ฺฉูุฑูุด ฺูุุ!!!!\n",
            "ุจุฑุงู ุฌุงูุจู ุจุฏููู ุฏูู ุจุฑุฎ ุงุฒ ุงูุฑุงุฏ ุงุฒ ุญูุงุชูุง ูุงุจู ุฌุง ุงุฒ ฺฉูุฑูุด ฺูุุ!!!!\n",
            "ฺฉูุฑูุด ฺฉุจุฑ \n",
            "\n",
            "ฺฉูุฑูุด ุงุฒ ุจุฒุฑฺฏุชุฑู  ูพุงุฏุดุงูุงู ุงุณุช ฺฉู ูู  ุชููุง  ุชุงุฑุฎ \n",
            "ุจูฺฉู  ุฌูุงู  ุจู ูุงู ุงู ุงูุชุฎุงุฑ ู ฺฉูุฏ. \n",
            "ุงู ุชููุง  ุจูุงุฏ  ู  ุจูุงูฺฏุฐุงุฑ  ฺฉ ุงููพุฑุงุทูุฑ  ูุนุธู ุฏุฑ ุฌูุงู \n",
            "ูุณุช  ฺฉู ูุงู ุงู  ุฑุง ูพุฑ  ุขูุงุฒู ฺฉุฑุฏู  ุงุณุช ุ ุจูฺฉู ุงู \n",
            "ุจูุงุฏ ฺฏุฐุงุฑ  ููุดูุฑ ุงุณุช  ฺฉู  ุชุงุฑุฎ  ู ุฌูุงูุงู ุจู  ุขู \n",
            "ุงูุชุฎุงุฑ ู ฺฉููุฏ.!! \n",
            "\n",
            "ุฏุฑ ุชุงุฑุฎ  ูุงู  ูพุงุฏุดุงูุงู  ููุฑุงู ุจุง  ุธูู  ู ุณุชู  ู ุบุงุฑุช  ู ฺูพุงูู ุงุณุช.  ุงูุง  ูุงู ฺฉูุฑูุด  ููุฑุงู ุจุง  ุนุฏุงูุช  ู  ูุงููู   ู  ูุฏุงุฑุง ุงุณุช. \n",
            "ุขูฺู ุงูุฑูุฒ  ุจุง  ูุงู   ( ูุฏุงุฑุง )   ู    tolerance  ุฏุฑ ููุณููโ ุณุงุณ ุฌูุงู  ููุฑุฏ  ุชูุฌู  ู ุชุญูู  ูุชูฺฉุฑุงู  ูุฑุงุฑ ฺฏุฑูุชู  ุงุณุช  ุ \n",
            "ูพุฏุฏู ุง ุงุณุช  ฺฉู  ุฏุฑ  ตฐฐ  ุณุงู  ูุจู ุงุฒ  ููุงุฏ  ฺฉูุฑูุด  ุฏุฑ \n",
            "ุจู ุงูููุฑู  ู ูุณุจุช  ุจู  ุจุงุจูุงู  ู  ูุนุชูุฏุงุช  ุขููุง  ุงูุฌุงู. \n",
            "\n",
            "ฺฉูุฑูุด  ฺฉุจุฑ ุชููุง  ูพุงุฏุดุงู ุงุณุช  ฺฉู ุฏุฑ ฺฉุชุจ ููุฏุณ \n",
            "ููุจ ููุฌ  ู  ุฑูุง ุจุฎุด ูพุฏุง ฺฉุฑุฏู ุงุณุช.!! \n",
            "ุงู  ฺฉุณ ุงุณุช  ฺฉู  ูุฏุฑุช  ุฎูุด ุฑุง  ุฏุฑ ุขุฒุงุฏ  ููู  ููุฏ \n",
            "ุฏุฑ ุจู ุงูููุฑู ู  ุจุงุจู  ุจฺฉุงุฑ ฺฏุฑูุช  ู  ุงู  ููู  ุฑุง  ุงุฒ ูุบ \n",
            "ุจุฑุฏฺฏ  ุจุงุจูุงู ูุฌุงุช  ุฏุงุฏ  ู ุจู  ุขููุง ฺฉุฑุงูุช ุจุฎุดุฏ.  ุจู ููู \n",
            "ุฎุงุทุฑ ุจุฎุด ุงุฒ  ฺฉุชุงุจ  ููุฏุณ  ุนูุฏ  ุนุชู ุจู ุงู ุงุฎุชุตุงุต \n",
            "ุงูุชู  ู ุงุฒ ุงู ุจุนููุงู  ุฑูุง ุจุฎุด ุงุฏ ฺฉุฑุฏู ุงุณุช. \n",
            "ุงู  ูู ุชููุง  ููุฏ ุงู ุฑุง ุฏุฑ  ุฑูุชู  ุจู ุณุฑุฒูู  ุฎูุด ุขุฒุงุฏ\n",
            " ฺฏุฐุงุดุช  ุจูฺฉู ุจู ุขููุง ุฏุฑ ุณุงุฎุชู ูุนุงุจุฏุดุงู ฺฉูฺฉ ูููุฏ. \n",
            "ู ุงูุงูุช  ุจุฒุฑฺฏุงู  ู ูพุงูุจุฑุงู  ุจู ุงุณุฑุงู  ุงุฒ ุฌููู  ุญุถุฑุช \n",
            "ุฏุงูุงู  ูพุงูุจุฑ ู  ฒฐ ููุฑ ุฏฺฏุฑ ุงุฒ ูพุงูุจุฑ ุงู  ุขูุงู ุฏุฑ ุงุฑุงู  \n",
            "ุจุฏูู  ุงุฑุชุจุงุท  ุจุง  ุฑูุชุงุฑ ู ุงุฎูุงู  ุนุงู ุงูุณุงู ุงู ูุณุช!! \n",
            "\n",
            "ุจ ุฌูุช ูุณุช  ฺฉู  ุงุณุชุงุฏ  ุงุจูุงูฺฉูุงู  ุขุฒุงุฏ  ูุฒุฑ ูุนุงุฑู ุฒูุงู \n",
            "ฺฏุงูุฏ  ู  ููุณุฑ ูุฑุขู  ูุฌุฏ  ุฏุฑ ุชูุณุฑ  ุฎูุฏ  ุ ุชุญููุงุชุด ุฑุง ุชุง ุจุฏุงูุฌุง ุงุฏุงูู ูุฏูุฏ  ฺฉู  ุจุง  ุตุฑุงุญุช   ุจููุณุฏ  ฺฉู  ุจู  ุงุญุชูุงู \n",
            "ุฒุงุฏ  ( ุฐูุงููุฑูู )  ููุงู  ฺฉูุฑูุด  ุฏูู   ุงููพุฑุงุทูุฑ  \n",
            "ูุฎุงููุดุงู ุงุณุช  .!! \n",
            "ู ูุฌููุนู  ุฏุฏฺฏุงู ุงุณุชุงุฏ ุงุจูุงูฺฉูุงู ุขุฒุงุฏ  ุฏุฑ ฺฉุชุงุจ ุจู ูุงู \n",
            "ุฐูุงููุฑูู ุชูุณุท ุงุณุชุงุฏ ุจุงุณุชุงู ูพุงุฑุฒ ุชุฑุฌูู  ู ฺุงูพ\n",
            "ุดุฏู ุงุณุช. \n",
            "ุจู ูุฑุญุงู! \n",
            "ุฐูุงููุฑูู ฺู ฺฉูุฑูุด ุจุงุดุฏ ฺู  ูุจุงุดุฏ ุ  ฺฉูุฑูุด ูพุงุฏุดุงู ุจุฒุฑฺฏ ู ุจูุงููุฏ ุงุณุช  ฺฉู  ุชุงุฑุฎ  ุฌูุงู  ู ุฌูุงูุงู  ุจู ุงู ู  \n",
            "ุฎุฏูุงุช ุงู ุงูุชุฎุงุฑ ู ฺฉููุฏ. \n",
            "ุงูุง  ุงู  ุงูุชุฎุงุฑ ูุจุงุฏ  ูุง  ุฏฺุงุฑ ุงูุฑุงุท ฺฏุฑุง ฺฉุงุฐุจ  ู ุจุงุณุชุงู \n",
            "ฺฏุฑุง ุจุฏูู  ุขฺฏุงู ููุงุฏ.!! \n",
            "ูุงูุณูุงู\n",
            "ฺฉูุฑูุด ฺฉุจุฑ \n",
            "\n",
            "ฺฉูุฑูุด ุงุฒ ุจุฒุฑฺฏุชุฑู  ูพุงุฏุดุงูุงู ุงุณุช ฺฉู ูู  ุชููุง  ุชุงุฑุฎ \n",
            "ุจูฺฉู  ุฌูุงู  ุจู ูุงู ุงู ุงูุชุฎุงุฑ ู ฺฉูุฏ. \n",
            "ุงู ุชููุง  ุจูุงุฏ  ู  ุจูุงูฺฏุฐุงุฑ  ฺฉ ุงููพุฑุงุทูุฑ  ูุนุธู ุฏุฑ ุฌูุงู \n",
            "ูุณุช  ฺฉู ูุงู ุงู  ุฑุง ูพุฑ  ุขูุงุฒู ฺฉุฑุฏู  ุงุณุช ุ ุจูฺฉู ุงู \n",
            "ุจูุงุฏ ฺฏุฐุงุฑ  ููุดูุฑ ุงุณุช  ฺฉู  ุชุงุฑุฎ  ู ุฌูุงูุงู ุจู  ุขู \n",
            "ุงูุชุฎุงุฑ ู ฺฉููุฏ.!! \n",
            "\n",
            "ุฏุฑ ุชุงุฑุฎ  ูุงู  ูพุงุฏุดุงูุงู  ููุฑุงู ุจุง  ุธูู  ู ุณุชู  ู ุบุงุฑุช  ู ฺูพุงูู ุงุณุช.  ุงูุง  ูุงู ฺฉูุฑูุด  ููุฑุงู ุจุง  ุนุฏุงูุช  ู  ูุงููู   ู  ูุฏุงุฑุง ุงุณุช. \n",
            "ุขูฺู ุงูุฑูุฒ  ุจุง  ูุงู   ( ูุฏุงุฑุง )   ู    tolerance  ุฏุฑ ููุณููโ ุณุงุณ ุฌูุงู  ููุฑุฏ  ุชูุฌู  ู ุชุญูู  ูุชูฺฉุฑุงู  ูุฑุงุฑ ฺฏุฑูุชู  ุงุณุช  ุ \n",
            "ูพุฏุฏู ุง ุงุณุช  ฺฉู  ุฏุฑ  ตฐฐ  ุณุงู  ูุจู ุงุฒ  ููุงุฏ  ฺฉูุฑูุด  ุฏุฑ \n",
            "ุจู ุงูููุฑู  ู ูุณุจุช  ุจู  ุจุงุจูุงู  ู  ูุนุชูุฏุงุช  ุขููุง  ุงูุฌุงู. \n",
            "\n",
            "ฺฉูุฑูุด  ฺฉุจุฑ ุชููุง  ูพุงุฏุดุงู ุงุณุช  ฺฉู ุฏุฑ ฺฉุชุจ ููุฏุณ \n",
            "ููุจ ููุฌ  ู  ุฑูุง ุจุฎุด ูพุฏุง ฺฉุฑุฏู ุงุณุช.!! \n",
            "ุงู  ฺฉุณ ุงุณุช  ฺฉู  ูุฏุฑุช  ุฎูุด ุฑุง  ุฏุฑ ุขุฒุงุฏ  ููู  ููุฏ \n",
            "ุฏุฑ ุจู ุงูููุฑู ู  ุจุงุจู  ุจฺฉุงุฑ ฺฏุฑูุช  ู  ุงู  ููู  ุฑุง  ุงุฒ ูุบ \n",
            "ุจุฑุฏฺฏ  ุจุงุจูุงู ูุฌุงุช  ุฏุงุฏ  ู ุจู  ุขููุง ฺฉุฑุงูุช ุจุฎุดุฏ.  ุจู ููู \n",
            "ุฎุงุทุฑ ุจุฎุด ุงุฒ  ฺฉุชุงุจ  ููุฏุณ  ุนูุฏ  ุนุชู ุจู ุงู ุงุฎุชุตุงุต \n",
            "ุงูุชู  ู ุงุฒ ุงู ุจุนููุงู  ุฑูุง ุจุฎุด ุงุฏ ฺฉุฑุฏู ุงุณุช. \n",
            "ุงู  ูู ุชููุง  ููุฏ ุงู ุฑุง ุฏุฑ  ุฑูุชู  ุจู ุณุฑุฒูู  ุฎูุด ุขุฒุงุฏ\n",
            " ฺฏุฐุงุดุช  ุจูฺฉู ุจู ุขููุง ุฏุฑ ุณุงุฎุชู ูุนุงุจุฏุดุงู ฺฉูฺฉ ูููุฏ. \n",
            "ู ุงูุงูุช  ุจุฒุฑฺฏุงู  ู ูพุงูุจุฑุงู  ุจู ุงุณุฑุงู  ุงุฒ ุฌููู  ุญุถุฑุช \n",
            "ุฏุงูุงู  ูพุงูุจุฑ ู  ฒฐ ููุฑ ุฏฺฏุฑ ุงุฒ ูพุงูุจุฑ ุงู  ุขูุงู ุฏุฑ ุงุฑุงู  \n",
            "ุจุฏูู  ุงุฑุชุจุงุท  ุจุง  ุฑูุชุงุฑ ู ุงุฎูุงู  ุนุงู ุงูุณุงู ุงู ูุณุช!! \n",
            "\n",
            "ุจ ุฌูุช ูุณุช  ฺฉู  ุงุณุชุงุฏ  ุงุจูุงูฺฉูุงู  ุขุฒุงุฏ  ูุฒุฑ ูุนุงุฑู ุฒูุงู \n",
            "ฺฏุงูุฏ  ู  ููุณุฑ ูุฑุขู  ูุฌุฏ  ุฏุฑ ุชูุณุฑ  ุฎูุฏ  ุ ุชุญููุงุชุด ุฑุง ุชุง ุจุฏุงูุฌุง ุงุฏุงูู ูุฏูุฏ  ฺฉู  ุจุง  ุตุฑุงุญุช   ุจููุณุฏ  ฺฉู  ุจู  ุงุญุชูุงู \n",
            "ุฒุงุฏ  ( ุฐูุงููุฑูู )  ููุงู  ฺฉูุฑูุด  ุฏูู   ุงููพุฑุงุทูุฑ  \n",
            "ูุฎุงููุดุงู ุงุณุช  .!! \n",
            "ู ูุฌููุนู  ุฏุฏฺฏุงู ุงุณุชุงุฏ ุงุจูุงูฺฉูุงู ุขุฒุงุฏ  ุฏุฑ ฺฉุชุงุจ ุจู ูุงู \n",
            "ุฐูุงููุฑูู ุชูุณุท ุงุณุชุงุฏ ุจุงุณุชุงู ูพุงุฑุฒ ุชุฑุฌูู  ู ฺุงูพ\n",
            "ุดุฏู ุงุณุช. \n",
            "ุจู ูุฑุญุงู! \n",
            "ุฐูุงููุฑูู ฺู ฺฉูุฑูุด ุจุงุดุฏ ฺู  ูุจุงุดุฏ ุ  ฺฉูุฑูุด ูพุงุฏุดุงู ุจุฒุฑฺฏ ู ุจูุงููุฏ ุงุณุช  ฺฉู  ุชุงุฑุฎ  ุฌูุงู  ู ุฌูุงูุงู  ุจู ุงู ู  \n",
            "ุฎุฏูุงุช ุงู ุงูุชุฎุงุฑ ู ฺฉููุฏ. \n",
            "ุงูุง  ุงู  ุงูุชุฎุงุฑ ูุจุงุฏ  ูุง  ุฏฺุงุฑ ุงูุฑุงุท ฺฏุฑุง ฺฉุงุฐุจ  ู ุจุงุณุชุงู \n",
            "ฺฏุฑุง ุจุฏูู  ุขฺฏุงู ููุงุฏ.!! \n",
            "ูุงูุณูุงู\n",
            "ุงูุชุถุงุญ ุจูุฏ\n",
            "ุงูุชุถุงุญ ุจูุฏ\n",
            "ฺฉุชุงุจ ุนุงู ุจูุฏ. ูุชู ููู ุงูุนุงุฏู ู ุฑูุงู ู ูุงุจู ุฏุฑฺฉ ุจุฑุง ููู\n",
            "\n",
            "ฺฉุชุงุจ ุนุงู ุจูุฏ. ูุชู ููู ุงูุนุงุฏู ู ุฑูุงู ู ูุงุจู ุฏุฑฺฉ ุจุฑุง ููู\n",
            "\n",
            "ฺฉุชุงุจ ุฎูุจ ุจุงุฏ ุจุงุดุฏ\n",
            "ฺฉุชุงุจ ุฎูุจ ุจุงุฏ ุจุงุดุฏ\n",
            "ุจุง ุณูพุงุณ ุงุฒ ููุณูุฏู ูุญุชุฑู ุฌูุงุจ ุฏฺฉุชุฑ ูฺฉู  ู   ูพุงฺฏุงูโ ูุฑููฺฏ ุทุงูฺู\n",
            "ุจุง ุณูพุงุณ ุงุฒ ููุณูุฏู ูุญุชุฑู ุฌูุงุจ ุฏฺฉุชุฑ ูฺฉู  ู   ูพุงฺฏุงูโ ูุฑููฺฏ ุทุงูฺู\n",
            "ุนุฑุถ ุงุฏุจ ู ุงุญุชุฑุงู \n",
            "ุฎู ุจู  ุฏูุจุงู  ฺฉุชุงุจ  ู ููุดุชู ุง ุจูุฏู ฺฉู ุจู ุจุฑุฑุณ ุชุงุฑุฎ  ( ุชุฑุงูู )  ู ุชุฑุงูู ุณุฑุง ุฏุฑ ุงุฑุงู ูพุฑุฏุงุฎุชู ุจุงุดุฏ. \n",
            "ุงฺฏุฑฺู ุฏุฑ ุจุงุฑู  ุชุงุฑุฎ ููุณู ู ููุณู ุฏุงูุงู ุจุฒุฑฺฏ ุขุซุงุฑ ุจุณุงุฑ ฺฏุฑุงูุจูุง ุฏุฑ ุงุฏุจุงุช ูุงุฑุณ ูุฌูุฏ ุฏุงุฑุฏ ู ุง ุฏุฑ ุถูู ฺฉุชุงุจ ูุง ุงุฏุจ  ุง  ุงููุงุน ุงุฏุจ  ุงุดุงุฑู ุง ุจู\n",
            "  ( ุชุฑุงูู ) ูุฒ  ุดุฏู  ุจุงุดุฏ. \n",
            "ุงูุง  ุฏุฑ ุงู ฺฉุชุงุจ ุงุฑุฌููุฏ ุ  ููุถูุน ( ุชุฑุงูู )  ุจู ุตูุฑุช ูุงุญุฏ  ููุฑุฏ ุจุฑุฑุณ  ู ฺฉูฺฉุงุด ูุฑุงุฑ ฺฏุฑูุชู  ู ุชุฑุงูู ุณุฑุง ุฑุง ุชุง ุฏูุฑุงู ูุจู ุงุฒ ุงุณูุงู ู  ุจุฒุฑฺฏุงู ููฺูู ( ุจุงุฑุจุฏ ู ูฺฉุณุง )  ุงุฏุงูู ุฏุงุฏู ุงุณุช. ุงฺฏุฑฺู ููุณู ุชุงุฑุฎ ุจู  ูุฏูุช ุงูุณุงู ู ุชุงุฑุฎ ุฏุงุฑุฏ.\n",
            "ุนุฑุถ ุงุฏุจ ู ุงุญุชุฑุงู \n",
            "ุฎู ุจู  ุฏูุจุงู  ฺฉุชุงุจ  ู ููุดุชู ุง ุจูุฏู ฺฉู ุจู ุจุฑุฑุณ ุชุงุฑุฎ  ( ุชุฑุงูู )  ู ุชุฑุงูู ุณุฑุง ุฏุฑ ุงุฑุงู ูพุฑุฏุงุฎุชู ุจุงุดุฏ. \n",
            "ุงฺฏุฑฺู ุฏุฑ ุจุงุฑู  ุชุงุฑุฎ ููุณู ู ููุณู ุฏุงูุงู ุจุฒุฑฺฏ ุขุซุงุฑ ุจุณุงุฑ ฺฏุฑุงูุจูุง ุฏุฑ ุงุฏุจุงุช ูุงุฑุณ ูุฌูุฏ ุฏุงุฑุฏ ู ุง ุฏุฑ ุถูู ฺฉุชุงุจ ูุง ุงุฏุจ  ุง  ุงููุงุน ุงุฏุจ  ุงุดุงุฑู ุง ุจู\n",
            "  ( ุชุฑุงูู ) ูุฒ  ุดุฏู  ุจุงุดุฏ. \n",
            "ุงูุง  ุฏุฑ ุงู ฺฉุชุงุจ ุงุฑุฌููุฏ ุ  ููุถูุน ( ุชุฑุงูู )  ุจู ุตูุฑุช ูุงุญุฏ  ููุฑุฏ ุจุฑุฑุณ  ู ฺฉูฺฉุงุด ูุฑุงุฑ ฺฏุฑูุชู  ู ุชุฑุงูู ุณุฑุง ุฑุง ุชุง ุฏูุฑุงู ูุจู ุงุฒ ุงุณูุงู ู  ุจุฒุฑฺฏุงู ููฺูู ( ุจุงุฑุจุฏ ู ูฺฉุณุง )  ุงุฏุงูู ุฏุงุฏู ุงุณุช. ุงฺฏุฑฺู ููุณู ุชุงุฑุฎ ุจู  ูุฏูุช ุงูุณุงู ู ุชุงุฑุฎ ุฏุงุฑุฏ.\n",
            "ูพุงุงู ุฏุฑุฏูุงฺฉ ุฏุงุฑู ฺฉู ูุฌ ููุช ูุฑุงููุดุด ูฺฉุฑุฏูโค\n",
            "ูพุงุงู ุฏุฑุฏูุงฺฉ ุฏุงุฑู ฺฉู ูุฌ ููุช ูุฑุงููุดุด ูฺฉุฑุฏู\n",
            "ฺฉุชุงุจ ููููููู ุงูุนุงุฏู ุง ุจูุฏ ุจู ูุธุฑ ูู ุชุฑุฌูุด ูู ุจุณุงุฑ ุฎูุจ ููุฏูู ููุท ุงุฎุฑุด ุฎู ุบู ุงูฺฏุฒ ุจูุฏ ฺฉู ูู ูููุดู ุฏูุณุช ุฏุงุดุชู\n",
            "ฺฉุชุงุจ ููููููู ุงูุนุงุฏู ุง ุจูุฏ ุจู ูุธุฑ ูู ุชุฑุฌูุด ูู ุจุณุงุฑ ุฎูุจ ููุฏูู ููุท ุงุฎุฑุด ุฎู ุบู ุงูฺฏุฒ ุจูุฏ ฺฉู ูู ูููุดู ุฏูุณุช ุฏุงุดุชู\n",
            "ฺุฑุงููุดู ุฎุฑุฏุดุุุ\n",
            "ฺุฑุงููุดู ุฎุฑุฏุดุุุ\n",
            "5:30ุตุจุญ ุงูุงู ุชูููุด ฺฉุฑุฏู ุฏุฑููุฑุฏ ฺฉุชุงุจ ูุฑฺุฒ ฺฉู ุจฺฏู ุญู ูุทูุจ ุงุฏุง ูุดุฏู. ุนุงุดูุงูู ุจ ูุนู ูุงูุนู ฺฉููู .ุจ ูุธุฑู ฺฉุชุงุจู ฺฉ ุจุงุฏ ูุฑฺฉุณ ุจุฎููุฏุด ู ุงุตูุง ูุงุฒูู ฺฉ ุฎููุฏู ุจุดู ูุฑฺูุฏ ุงู ฺฉุชุงุจ ูุงูุนุง ุจ ุฌุงฺฏุงูุด ูุฑุณุฏ.\n",
            "ุจุฎููุฏ ู ูุฐุช ุจุจุฑุฏ\n",
            "5:30ุตุจุญ ุงูุงู ุชูููุด ฺฉุฑุฏู ุฏุฑููุฑุฏ ฺฉุชุงุจ ูุฑฺุฒ ฺฉู ุจฺฏู ุญู ูุทูุจ ุงุฏุง ูุดุฏู. ุนุงุดูุงูู ุจ ูุนู ูุงูุนู ฺฉููู .ุจ ูุธุฑู ฺฉุชุงุจู ฺฉ ุจุงุฏ ูุฑฺฉุณ ุจุฎููุฏุด ู ุงุตูุง ูุงุฒูู ฺฉ ุฎููุฏู ุจุดู ูุฑฺูุฏ ุงู ฺฉุชุงุจ ูุงูุนุง ุจ ุฌุงฺฏุงูุด ูุฑุณุฏ.\n",
            "ุจุฎููุฏ ู ูุฐุช ุจุจุฑุฏ\n",
            "ุฎู ุฏุงุณุชุงู ุฒุจุง ุจูุฏ ูุงูุนุง ูุฐุช ุจุฑุฏู.\n",
            "ุฎู ุฏุงุณุชุงู ุฒุจุง ุจูุฏ ูุงูุนุง ูุฐุช ุจุฑุฏู.\n",
            "ุฒุจุงุณุช ู ุงูุจุชู ฺฉู ฺฉุณู ฺฉููุฏู\n",
            "ุฒุจุงุณุช ู ุงูุจุชู ฺฉู ฺฉุณู ฺฉููุฏู\n",
            "ุนุงุงุงูู ูู ฺฉ ุฎู ุฏูุณุด ุฏุงุฑู..\n",
            "ุนุงุงุงูู ูู ฺฉ ุฎู ุฏูุณุด ุฏุงุฑู..\n",
            "ุนุงููุููู ุงูุนุงุฏู\n",
            "ุนุงููุููู ุงูุนุงุฏู\n",
            "ุฎูุจ ุจูุฏุ ููููู ุงุฒ ูพุดููุงุฏุชูู...\n",
            "ุฎูุจ ุจูุฏุ ููููู ุงุฒ ูพุดููุงุฏุชูู...\n",
            "ุณูุงู ุฏูุณุชุงู ุจุฑุง ุฎุฑุฏ ูุณุฎู ฺุงูพ ฺฉุฏูู ุงูุชุดุงุฑุงุช ุชูุฑุงู ุฏุงุฑูุ\n",
            "ุณูุงู ุฏูุณุชุงู ุจุฑุง ุฎุฑุฏ ูุณุฎู ฺุงูพ ฺฉุฏูู ุงูุชุดุงุฑุงุช ุชูุฑุงู ุฏุงุฑูุ\n",
            "ูุงูุนุง ุนุงู ุจูุฏ ุขุฏู ูุฌุฐูุจุด ูุดู\n",
            "ูู ุงุฒ ฺฉุชุงุจ ูุง ุฑูุงู ูุงูุชุฒ ุฎู ุฎูุดู ูุงุฏ ุงฺฏู ฺฉุณ ฺฉุชุงุจ ุงูุฌูุฑ ุฎููุฏู ูุทูุง ุจฺฏู ููู ุจุฎููู\n",
            "โค๐ค\n",
            "ูุงูุนุง ุนุงู ุจูุฏ ุขุฏู ูุฌุฐูุจุด ูุดู\n",
            "ูู ุงุฒ ฺฉุชุงุจ ูุง ุฑูุงู ูุงูุชุฒ ุฎู ุฎูุดู ูุงุฏ ุงฺฏู ฺฉุณ ฺฉุชุงุจ ุงูุฌูุฑ ุฎููุฏู ูุทูุง ุจฺฏู ููู ุจุฎููู\n",
            "\n",
            "ุงู ฺฉุชุงุจ ููู ุงูุนุงุฏู ุงุณุช. ููุณูุฏู ุงู ฺฉุชุงุจ ฺฉููุงุช ู ุฌููุงุช ู ุฏุงุณุชุงู ุฑุง ุฌูุฑ ุจุง ุธุฑุงูุช ุทุฑุงุญ ฺฉุฑุฏู ุงุณุช ฺฉู ูุฑ ุฎูุงููุฏู ุง ุฑุง ูุฎ ฺฉูุจ ฺฉุชุงุจุด ู ฺฉูุฏ\n",
            "ุงู ฺฉุชุงุจ ููู ุงูุนุงุฏู ุงุณุช. ููุณูุฏู ุงู ฺฉุชุงุจ ฺฉููุงุช ู ุฌููุงุช ู ุฏุงุณุชุงู ุฑุง ุฌูุฑ ุจุง ุธุฑุงูุช ุทุฑุงุญ ฺฉุฑุฏู ุงุณุช ฺฉู ูุฑ ุฎูุงููุฏู ุง ุฑุง ูุฎ ฺฉูุจ ฺฉุชุงุจุด ู ฺฉูุฏ\n",
            "ูู ูุงูุนุง ฺฉุชุงุจุดู ุฎู ุจุดุชุฑ ุชูุตู ูฺฉูู ุชุง ูููุด ฺูู ุชู ฺฉุชุงุจ ุนูุงูู ุจุฑ ุฌุฑุงู ุฌุฐุงุจ ฺฉู ุจู ุฎูุจ ุจู ุชุตูุฑ ฺฉุดุฏู ุดุฏู ุฏุงููฺฏุง ูุงุจ ู ุจ ูุธุฑ ุฏุงุฑู ฺฉู ุงุฏูู ุณุงุนุช ูุง ุจู ูฺฉุฑ ูุฑู ูุจุฑู\n",
            "ูู ูุงูุนุง ฺฉุชุงุจุดู ุฎู ุจุดุชุฑ ุชูุตู ูฺฉูู ุชุง ูููุด ฺูู ุชู ฺฉุชุงุจ ุนูุงูู ุจุฑ ุฌุฑุงู ุฌุฐุงุจ ฺฉู ุจู ุฎูุจ ุจู ุชุตูุฑ ฺฉุดุฏู ุดุฏู ุฏุงููฺฏุง ูุงุจ ู ุจ ูุธุฑ ุฏุงุฑู ฺฉู ุงุฏูู ุณุงุนุช ูุง ุจู ูฺฉุฑ ูุฑู ูุจุฑู\n",
            "ูููุด ุนุงูู\n",
            "ูุงูุนู ุฏูุง ุจู ุฏุงูุฑุฌูุช ูุง ูุงุฒ ุฏุงุฑู\n",
            "ูููุด ุนุงูู\n",
            "ูุงูุนู ุฏูุง ุจู ุฏุงูุฑุฌูุช ูุง ูุงุฒ ุฏุงุฑู\n",
            "ูู ูพูุฌ ุณุงูู ฺฉู ุฑูุฒุงูู ุฏู ฺฉุชุงุจ ูุฎูุงูู\n",
            "ุงู ุงููู ฺฉุชุงุจ ุจูุฏ ฺฉู ฺฏุฑู ุงู ุฑุง ุฏุฑ ุงูุฑุฏ ู ููุจู ุฑุง ูฺุงูู ฺฉุฑุฏ.\n",
            "ุงูุฑุงุฏ ฺฉู ุทุงูุชุด ุฑุง ูุฏุงุฑูุฏุ ุฌูุฏ ุงุฎุฑ ุฑุง ูุฎููู\n",
            "ูู ูพูุฌ ุณุงูู ฺฉู ุฑูุฒุงูู ุฏู ฺฉุชุงุจ ูุฎูุงูู\n",
            "ุงู ุงููู ฺฉุชุงุจ ุจูุฏ ฺฉู ฺฏุฑู ุงู ุฑุง ุฏุฑ ุงูุฑุฏ ู ููุจู ุฑุง ูฺุงูู ฺฉุฑุฏ.\n",
            "ุงูุฑุงุฏ ฺฉู ุทุงูุชุด ุฑุง ูุฏุงุฑูุฏุ ุฌูุฏ ุงุฎุฑ ุฑุง ูุฎููู\n",
            "ูููุดู ูุดูฺฏู\n",
            "ูููุดู ูุดูฺฏู\n",
            "ฺฉุชุงุจุดู ูุฎููุฏู ุงูุง ูููุดู ุฏุฏู ู ูุดูฺฏ ุจูุฏ\n",
            "ฺฉุชุงุจุดู ูุฎููุฏู ุงูุง ูููุดู ุฏุฏู ู ูุดูฺฏ ุจูุฏ\n",
            "ุนุงู ุจูุฏ\n",
            "ุงุตูุง ุงุฒ ุฎููุฏูุด ูพุดููู ูุจุณุชู ุจุง ุงูฺฉู ุงูุชุญุงู ุฏุงุฑู ู ูฺ ูุฎููุฏู ูู ุจุงุฒ ุฑุงุถู ฺฉู ููุชูู ุจุฑุง ูู ฺู ฺฉุชุงุจ ฺฏุฐุงุดุชู\n",
            "ุชุฑุฌูู ุด ุฑูุงู ู ุฎูุจ ุจูุฏ\n",
            "ุฏุฑ ฺฉู ูุถุง ุฏุงุณุชุงู ู ุฑููุฏุด ู ุชุฑุฌูู ุงุด ููู ุจุฑุงู ุฎูุจ ู ูุงุจู ูุจูู ุจูุฏ ู ุงุฒ ุฎููุฏู ฺฉุชุงุจ ููุงุงุงุงุงุช ูุฐุช ุฑู ุจุฑุฏู\n",
            "ูพุดููุงุฏ ูุดู๐๐๐\n",
            "ุนุงู ุจูุฏ\n",
            "ุงุตูุง ุงุฒ ุฎููุฏูุด ูพุดููู ูุจุณุชู ุจุง ุงูฺฉู ุงูุชุญุงู ุฏุงุฑู ู ูฺ ูุฎููุฏู ูู ุจุงุฒ ุฑุงุถู ฺฉู ููุชูู ุจุฑุง ูู ฺู ฺฉุชุงุจ ฺฏุฐุงุดุชู\n",
            "ุชุฑุฌูู ุด ุฑูุงู ู ุฎูุจ ุจูุฏ\n",
            "ุฏุฑ ฺฉู ูุถุง ุฏุงุณุชุงู ู ุฑููุฏุด ู ุชุฑุฌูู ุงุด ููู ุจุฑุงู ุฎูุจ ู ูุงุจู ูุจูู ุจูุฏ ู ุงุฒ ุฎููุฏู ฺฉุชุงุจ ููุงุงุงุงุงุช ูุฐุช ุฑู ุจุฑุฏู\n",
            "ูพุดููุงุฏ ูุดู\n",
            "ุจุง ุงูฺฉู ููุช ูููุด ุฑู ุฏุฏู ู ูุชูุฌู ุดุฏู ุจุฑุงุณุงุณ ฺฉุชุงุจู ูุฏุงู ูฺฉุฑ ูฺฉุฑุฏู ฺฉุชุงุจุด ุจุงุฏ ฺูุฏุฑ ูููโุงูุนุงุฏู ุชุฑ ุจุงุดูุ ุชู ุฐููู ุฎูุฑุฏ ู ููู ุฑู ุจุดุชุฑ ุฏูุณุช ุฏุงุดุชู\n",
            "ฺฉุชุงุจ ุฎูุจ ุจูุฏ ู ฺฉูุง ุงุฏู ุงุตู ุฏุงุณุชุงู ูุงูุนุงุงุงุงุงุง ุฌุงูุจู ุงูุง ููุฏููู ฺูู ููู ุฑู ุฎู ุฏูุณุช ุฏุงุดุชู ฺฉุชุงุจ ุจู ูุธุฑู ุงูู ุงูุฏุงุฒู ูู ูุจูุฏ ุง ุงฺฏุฑ ููู ุฑู ููุฏุฏู ูู ููู ูุธุฑ ุฑู ุฏุงุดุชู\n",
            "ูุถุง ฺฉุชุงุจ ุฎู ุชูุฌุฑ ุชุฑ ู ุงุญุณุงุณุงุช ุชุฑ ู ุดุฎุตุช ุชุฑุณ ุฎู ุถุนู ุชุฑ ุจูุฏ\n",
            "ุจูุฑุญุงู ุจูุด ูพูุฌ ูุฏู ฺูู ุงุฏู ฺฉุชุงุจ ุฑู ุจู ุดุฏุช ุฏูุณุช ุฏุงุดุชู ู ุจุง ุชูุงู ุงู ุชูุงุณุฑ ุงุฑุฒุด ุฎููุฏู ุฑู ุฏุงุดุช ู ุงฺฏุฑ ฺฉุชุงุจุด ูุจูุฏ ุงุฒ ุฏุฏู ููู ุจู ุงู ูุดูฺฏ ูุญุฑูู ุจูุฏู\n",
            "ุจุง ุงูฺฉู ููุช ูููุด ุฑู ุฏุฏู ู ูุชูุฌู ุดุฏู ุจุฑุงุณุงุณ ฺฉุชุงุจู ูุฏุงู ูฺฉุฑ ูฺฉุฑุฏู ฺฉุชุงุจุด ุจุงุฏ ฺูุฏุฑ ูููโุงูุนุงุฏู ุชุฑ ุจุงุดูุ ุชู ุฐููู ุฎูุฑุฏ ู ููู ุฑู ุจุดุชุฑ ุฏูุณุช ุฏุงุดุชู\n",
            "ฺฉุชุงุจ ุฎูุจ ุจูุฏ ู ฺฉูุง ุงุฏู ุงุตู ุฏุงุณุชุงู ูุงูุนุงุงุงุงุงุง ุฌุงูุจู ุงูุง ููุฏููู ฺูู ููู ุฑู ุฎู ุฏูุณุช ุฏุงุดุชู ฺฉุชุงุจ ุจู ูุธุฑู ุงูู ุงูุฏุงุฒู ูู ูุจูุฏ ุง ุงฺฏุฑ ููู ุฑู ููุฏุฏู ูู ููู ูุธุฑ ุฑู ุฏุงุดุชู\n",
            "ูุถุง ฺฉุชุงุจ ุฎู ุชูุฌุฑ ุชุฑ ู ุงุญุณุงุณุงุช ุชุฑ ู ุดุฎุตุช ุชุฑุณ ุฎู ุถุนู ุชุฑ ุจูุฏ\n",
            "ุจูุฑุญุงู ุจูุด ูพูุฌ ูุฏู ฺูู ุงุฏู ฺฉุชุงุจ ุฑู ุจู ุดุฏุช ุฏูุณุช ุฏุงุดุชู ู ุจุง ุชูุงู ุงู ุชูุงุณุฑ ุงุฑุฒุด ุฎููุฏู ุฑู ุฏุงุดุช ู ุงฺฏุฑ ฺฉุชุงุจุด ูุจูุฏ ุงุฒ ุฏุฏู ููู ุจู ุงู ูุดูฺฏ ูุญุฑูู ุจูุฏู\n",
            "ุฎู ฺฉุชุงุจ ุฎูุจ ุจูุฏ ุจุง ุงูฺฉู ูุงูุชุฒ ุจูุฏ ุงูุง ุฎู ฺุฒุง ูุดุฏ ุงุฒุด ุงุฏ ฺฏุฑูุช\n",
            "ุฎู ฺฉุชุงุจ ุฎูุจ ุจูุฏ ุจุง ุงูฺฉู ูุงูุชุฒ ุจูุฏ ุงูุง ุฎู ฺุฒุง ูุดุฏ ุงุฒุด ุงุฏ ฺฏุฑูุช\n",
            "ฺฉุชุงุจ ุชุฎู ุฎู ูุดูฺฏ ุจูุฏุ ููุณูุฏู ููู ุฎูุจ ุฏุงุดุชู ู ูุชุฑุฌู ูู ุนุงู ุชุฑุฌูู ฺฉุฑุฏู.. ุฏูุณุชุด ุฏุงุดุชู ู ุญุชูุง ุฏู ุฌูุฏ ุจุนุฏ ุฑู ูู ูุฎููู ุงู ุดุงุงููู\n",
            "ฺฉุชุงุจ ุชุฎู ุฎู ูุดูฺฏ ุจูุฏุ ููุณูุฏู ููู ุฎูุจ ุฏุงุดุชู ู ูุชุฑุฌู ูู ุนุงู ุชุฑุฌูู ฺฉุฑุฏู.. ุฏูุณุชุด ุฏุงุดุชู ู ุญุชูุง ุฏู ุฌูุฏ ุจุนุฏ ุฑู ูู ูุฎููู ุงู ุดุงุงููู\n",
            "ุฎูุจ ุจูุฏ ุ ุดุงุฏ ูุฑ ฺฉุฏุงู ุงุฒ ุจุฎุด ูุง ุดูุฑ ููุงุฏ ุงุฒ ุจุฎุด ูุง ูุฌูุฏ ุงูุณุงู ุจุงุดูุฏ ุ ุง ุฌุงูุนู ุ ุจุงุฏ ุจุดุชุฑ ุฏุฑ ููุฑุฏุด ูฺฉุฑ ฺฉูู ุ ุงฺฏุฑ ุจู ุฑูุงููุง ุชุฎู ุนูุงูู ุฏุงุฑุฏ ุฎูุจู ุ\n",
            "ุฎูุจ ุจูุฏ ุ ุดุงุฏ ูุฑ ฺฉุฏุงู ุงุฒ ุจุฎุด ูุง ุดูุฑ ููุงุฏ ุงุฒ ุจุฎุด ูุง ูุฌูุฏ ุงูุณุงู ุจุงุดูุฏ ุ ุง ุฌุงูุนู ุ ุจุงุฏ ุจุดุชุฑ ุฏุฑ ููุฑุฏุด ูฺฉุฑ ฺฉูู ุ ุงฺฏุฑ ุจู ุฑูุงููุง ุชุฎู ุนูุงูู ุฏุงุฑุฏ ุฎูุจู ุ\n",
            "ุฎู ุฎูุจ ุญุณ ุชุฌุณู ุฑู ุฏุฑ ุฎูุงููุฏู ุงุฌุงุฏ ูฺฉูู ุชูุตู ูุง ุฏูู ู ุฏุงุณุชุงู ุฌุฐุงุจ ุฏุงุฑู ุงูุจุชู ุงฺฏู ูููุดู ูุจูุง ุฏุฏู ูฺฉุฑ ูฺฉูู ุฒุงุฏ ุจุฑุงุชูู ุฌุฐุงุจ ุจุงุดู...๐๐\n",
            "ุฎู ุฎูุจ ุญุณ ุชุฌุณู ุฑู ุฏุฑ ุฎูุงููุฏู ุงุฌุงุฏ ูฺฉูู ุชูุตู ูุง ุฏูู ู ุฏุงุณุชุงู ุฌุฐุงุจ ุฏุงุฑู ุงูุจุชู ุงฺฏู ูููุดู ูุจูุง ุฏุฏู ูฺฉุฑ ูฺฉูู ุฒุงุฏ ุจุฑุงุชูู ุฌุฐุงุจ ุจุงุดู...\n",
            "ุงฺฏู ูุซู ูููุด ุจุงุดู ุจุงุฏ ูุดูฺฏ ุจุงุดุน\n",
            "ุงฺฏู ูุซู ูููุด ุจุงุดู ุจุงุฏ ูุดูฺฏ ุจุงุดุน\n",
            "ฺฉุชุงุจ ุจูุฏ ุชุฎู ุงูุจุชู ูู ูฺฉุฑูฺฉูู ุงฺฏู ูููุทูุฑ ูพุด ุจุฑู ุฏูุง ุจู ูููู ุณูุช ูุฑู.. ูฺฉุฑูฺฉูู ููุฌูุงููุง ุฎูุดุดูู ุจุงุฏ ู ุฏูุณุด ุฏุงุดุชู ุจุงุดู.. ููู ููุท ููู ฺฉุชุงุจ ุฑู ุฎููุฏู ุดูุฏู ุฏู ุจุฎุด ุฏฺฏู ูู ุฏุงุฑู.. ฺฉุชุงุจ ุฌูุฑ ุจูุฏ ฺฉู ุจูุงูุงุตูู ู ุจ ูููู ููุฑู ุณุฑุงุบ ุจุฎุด ูุง ุจุนุฏ ูู ุงฺฏู ฺฉุชุงุจ ุฎูุจ ุฏฺฏู ุง ูพุฏุง ูฺฉุฑุฏู ู ุฑูุฒ ูุฑู ูุฎูููุด๐๐\n",
            "ฺฉุชุงุจ ุจูุฏ ุชุฎู ุงูุจุชู ูู ูฺฉุฑูฺฉูู ุงฺฏู ูููุทูุฑ ูพุด ุจุฑู ุฏูุง ุจู ูููู ุณูุช ูุฑู.. ูฺฉุฑูฺฉูู ููุฌูุงููุง ุฎูุดุดูู ุจุงุฏ ู ุฏูุณุด ุฏุงุดุชู ุจุงุดู.. ููู ููุท ููู ฺฉุชุงุจ ุฑู ุฎููุฏู ุดูุฏู ุฏู ุจุฎุด ุฏฺฏู ูู ุฏุงุฑู.. ฺฉุชุงุจ ุฌูุฑ ุจูุฏ ฺฉู ุจูุงูุงุตูู ู ุจ ูููู ููุฑู ุณุฑุงุบ ุจุฎุด ูุง ุจุนุฏ ูู ุงฺฏู ฺฉุชุงุจ ุฎูุจ ุฏฺฏู ุง ูพุฏุง ูฺฉุฑุฏู ู ุฑูุฒ ูุฑู ูุฎูููุด\n",
            "ุจู ูุธุฑู ูุญุดุฑ ุจูุฏ ูู ุชุง ฺูุฏ ุฑูุฒ ุจู ุฎุงุทุฑ ุขุฎุฑ ฺฉุชุงุจ ุฌูุฏ ุณูู ุงูุณุฑุฏู ุจูุฏู.๐ข๐ญ\n",
            "ุจู ูุธุฑู ูุญุดุฑ ุจูุฏ ูู ุชุง ฺูุฏ ุฑูุฒ ุจู ุฎุงุทุฑ ุขุฎุฑ ฺฉุชุงุจ ุฌูุฏ ุณูู ุงูุณุฑุฏู ุจูุฏู.\n",
            "ุฎู ูุนููู\n",
            "ุฎู ูุนููู\n",
            "ุนุงู ู ูพุฑ ุงุฒ ูุฌุงู\n",
            "ุนุงู ู ูพุฑ ุงุฒ ูุฌุงู\n",
            "ุฌุฐุงุจ ู ูพุฑ ูุฌุงู ๐\n",
            "ุฌุฐุงุจ ู ูพุฑ ูุฌุงู \n",
            "ุฎู ุฏูุณุฏุงุดุชู ุจูุฏ ู ูพุฑ ุงุฒ ูุฌุงู.. ุฏุฑ ุทูู ุฑูุงู ุถุฑุจุงู ููุจู ุจุงูุง ุจูุฏ ู ฺฉู ูุฌุงู ุฏุงุดุชู.. ุงูุงู ูุฎูุงู ุจุฑู ูููุด ุฑู ุจุจูู๐\n",
            "ุฎู ุฏูุณุฏุงุดุชู ุจูุฏ ู ูพุฑ ุงุฒ ูุฌุงู.. ุฏุฑ ุทูู ุฑูุงู ุถุฑุจุงู ููุจู ุจุงูุง ุจูุฏ ู ฺฉู ูุฌุงู ุฏุงุดุชู.. ุงูุงู ูุฎูุงู ุจุฑู ูููุด ุฑู ุจุจูู\n",
            "ุฎู ุฌุฐุงุจ ุจูุฏุ ฺฉ ุณุฑู ูุดุณุชู ุณุฑุด ู ุงุฒ ุงูููุง ุจูุฏ ฺฉู ุขุฏู ูุดุชุงู ุจูุฏ ุจูุด ุฑู ุจุฎูููุ ุจุง ูููุด ูู ู ุฌุงูุง ูุชูุงูุช ุจูุฏุ ูุฑ ุฏูุด ุฎูุจู ุงูุจุชู ุงูุง ุชูุตู ูู ุงูู ฺฉู ุงูู ฺฉุชุงุจุดู ุจุฎููู ุจุนุฏ ุงฺฏู ุฏูุณ ุฏุงุดุชุฏ ูููู ุจุจูู\n",
            "ุฎู ุฌุฐุงุจ ุจูุฏุ ฺฉ ุณุฑู ูุดุณุชู ุณุฑุด ู ุงุฒ ุงูููุง ุจูุฏ ฺฉู ุขุฏู ูุดุชุงู ุจูุฏ ุจูุด ุฑู ุจุฎูููุ ุจุง ูููุด ูู ู ุฌุงูุง ูุชูุงูุช ุจูุฏุ ูุฑ ุฏูุด ุฎูุจู ุงูุจุชู ุงูุง ุชูุตู ูู ุงูู ฺฉู ุงูู ฺฉุชุงุจุดู ุจุฎููู ุจุนุฏ ุงฺฏู ุฏูุณ ุฏุงุดุชุฏ ูููู ุจุจูู\n",
            "ุงู ฺฉุชุงุจ ุจุดุชุฑ ฺฉ ฺฉุชุงุจ ุนูู ุชุฎู ูุฎุตูุต ููุฌูุงู ูุง ู ุฌูุงู ูุง ุดูุงุฎุชู ุดุฏู ุงูุง ุงฺฏู ุนูู ุจูุด ูฺฏุงู ุจุดู ุ ฺฉุชุงุจ ุฌุงูุจู. ูุฌูุฏ ูุฑูู ูุง ูุฎุชูู ุ ู ุงูฺฉู ูุฑฺฉุณ ูพุณ ุงุฒ ุงูุชุฎุงุจ ูุฑูู  ุฎูุฏ ... ุจุฏูู ูฺ ูฺฉุฑ ... ฺฉุงุฑูุง ู ุฑูุด ูุง ูุฑูู  ุงูุชุฎุงุจ ุฑู ุงูุฌุงู ูุฏู ู ... ุญุงูุง ฺฉ ููุฑ ฺฉู ูุงุฏ ุชุบุฑ ุงุฌุงุฏ ฺฉูู ูุดู ุณูุช ุดฺฉู ... ุฏุงุณุชุงู ุฌุงูุจู ... ุงูุจุชู ูู ููุท ุฌูุฏ ฺฉ ุฑู ุฎููุฏู ฺูู ูููุดู ฺฉู ุฏุฏู ูุณูุช ูุง ุฏฺฏู ุฎู ูุงูุชุฒ ุดุฏู ุจูุฏ ู ูู ุฎูุดู ูููุฏ ู ุจุฑุง ููู ุจู ูุทุงูุนู ูููุฌูุฏ ููุงุนุช ฺฉุฑุฏู.\n",
            "ุงู ฺฉุชุงุจ ุจุดุชุฑ ฺฉ ฺฉุชุงุจ ุนูู ุชุฎู ูุฎุตูุต ููุฌูุงู ูุง ู ุฌูุงู ูุง ุดูุงุฎุชู ุดุฏู ุงูุง ุงฺฏู ุนูู ุจูุด ูฺฏุงู ุจุดู ุ ฺฉุชุงุจ ุฌุงูุจู. ูุฌูุฏ ูุฑูู ูุง ูุฎุชูู ุ ู ุงูฺฉู ูุฑฺฉุณ ูพุณ ุงุฒ ุงูุชุฎุงุจ ูุฑูู  ุฎูุฏ ... ุจุฏูู ูฺ ูฺฉุฑ ... ฺฉุงุฑูุง ู ุฑูุด ูุง ูุฑูู  ุงูุชุฎุงุจ ุฑู ุงูุฌุงู ูุฏู ู ... ุญุงูุง ฺฉ ููุฑ ฺฉู ูุงุฏ ุชุบุฑ ุงุฌุงุฏ ฺฉูู ูุดู ุณูุช ุดฺฉู ... ุฏุงุณุชุงู ุฌุงูุจู ... ุงูุจุชู ูู ููุท ุฌูุฏ ฺฉ ุฑู ุฎููุฏู ฺูู ูููุดู ฺฉู ุฏุฏู ูุณูุช ูุง ุฏฺฏู ุฎู ูุงูุชุฒ ุดุฏู ุจูุฏ ู ูู ุฎูุดู ูููุฏ ู ุจุฑุง ููู ุจู ูุทุงูุนู ูููุฌูุฏ ููุงุนุช ฺฉุฑุฏู.\n",
            "ุชู ูุงุฒ ุฎููุฏู  ฺฉุชุงุจู ูุงูุชุฒู  ฺฉุชุงุจ ูุงูุชุฒ ุฎูุจ ูพุดููุงุฏ ุจุฏู (ูู ุฌุงู ูุงุฏุฑุชูู ูุฑ ูพุงุชุฑ ูพุดููุงุฏ ูุฏู๐)\n",
            "ุชู ูุงุฒ ุฎููุฏู  ฺฉุชุงุจู ูุงูุชุฒู  ฺฉุชุงุจ ูุงูุชุฒ ุฎูุจ ูพุดููุงุฏ ุจุฏู (ูู ุฌุงู ูุงุฏุฑุชูู ูุฑ ูพุงุชุฑ ูพุดููุงุฏ ูุฏู)\n",
            "ุฎูุจ ุจูุฏ ูู ูฺฉุฑ ฺฉูู ููู ุงู ฺฉุชุงุจ ุฑู ูู ูุจูุง ุฏุฏู ุฏุฑุณุชู ุ\n",
            "ุฎูุจ ุจูุฏ ูู ูฺฉุฑ ฺฉูู ููู ุงู ฺฉุชุงุจ ุฑู ูู ูุจูุง ุฏุฏู ุฏุฑุณุชู ุ\n",
            "ุฎู ุฒุจุงุณุช ูููุด ูู ููุฌูุฏู\n",
            "ุฎู ุฒุจุงุณุช ูููุด ูู ููุฌูุฏู\n",
            "ูุงุฑุบ ุงุฒ ุดุจุงูุช ูุง ุงู ุฏุงุณุชุงู ุจู ูุฌููุนู ูุง ุนูู ุชุฎู ูุดุงุจูุ ูฺฉุฑู ฺฉูู ุจุฑุง ุฏูุณุชุฏุงุฑุงู ูุฌููุนู ูุง ูุงูุชุฒุ ุจุง ูุฑุณู ู ุณุงูุ ุฌุฐุงุจ ู ุฎูุงูุฏู ุจุงุดู.\n",
            "ูุงุฑุบ ุงุฒ ุดุจุงูุช ูุง ุงู ุฏุงุณุชุงู ุจู ูุฌููุนู ูุง ุนูู ุชุฎู ูุดุงุจูุ ูฺฉุฑู ฺฉูู ุจุฑุง ุฏูุณุชุฏุงุฑุงู ูุฌููุนู ูุง ูุงูุชุฒุ ุจุง ูุฑุณู ู ุณุงูุ ุฌุฐุงุจ ู ุฎูุงูุฏู ุจุงุดู.\n",
            "ุงู ฺฉุชุงุจ ููู ุงุฏ ุฏูุฑุงู ููุฌูุงูู ููุฏุงุฒู ูพุฑ ุงุฒ ูุฌุงูุงุช ูุฎุชุต ุจู ุงูู ุณู\n",
            "ุจุฑุง ฺฉุณุง ฺฉู ฺฉุชุงุจุง ุชู ุณุจฺฉ ูุฌุงู ุชุฎู ุฏูุณุช ุฏุงุฑูุฏ ฺฉุชุงุจ ุฎูุจู\n",
            "ูู ุงู ฺฉุชุงุจู ุฏูุณุชุฏุงุดุชู ูุงุฑุบ ุงุฒ ุณู ู ุณุงูู\n",
            "ูฺฉุชู ุงูฺฉู ุดุงุฏ ุงูุงู ฺฉุชุงุจ ุฒุงุฏ ุฌุฐุงุจ ูุจุงุดู ุงูุง ุจุนุฏุด ุฑููุฏ ูุชูุงูุช ุฑู ูพุด ูฺฏุฑู\n",
            "ุงู ฺฉุชุงุจ ููู ุงุฏ ุฏูุฑุงู ููุฌูุงูู ููุฏุงุฒู ูพุฑ ุงุฒ ูุฌุงูุงุช ูุฎุชุต ุจู ุงูู ุณู\n",
            "ุจุฑุง ฺฉุณุง ฺฉู ฺฉุชุงุจุง ุชู ุณุจฺฉ ูุฌุงู ุชุฎู ุฏูุณุช ุฏุงุฑูุฏ ฺฉุชุงุจ ุฎูุจู\n",
            "ูู ุงู ฺฉุชุงุจู ุฏูุณุชุฏุงุดุชู ูุงุฑุบ ุงุฒ ุณู ู ุณุงูู\n",
            "ูฺฉุชู ุงูฺฉู ุดุงุฏ ุงูุงู ฺฉุชุงุจ ุฒุงุฏ ุฌุฐุงุจ ูุจุงุดู ุงูุง ุจุนุฏุด ุฑููุฏ ูุชูุงูุช ุฑู ูพุด ูฺฏุฑู\n",
            "ููู ุงูุนุงุฏู ุฎูุจ ู ุฌุฐุงุจ! ููู :) ุญุชูุง ุงฺฏู ููุช ฺฉุฑุฏุฏ ุญุช ุดุฏู ููููู ุงุด ุฑู ูู ุจุฎููุฏ ฺูู ูุงูุนุง ุงุฒ ุงูู ุฏุงุณุชุงู ูุง ฺฉู ุดุฏุฏุง ุดูุงุฑู ุฏุฑฺฏุฑ ุฎูุฏุด ูฺฉูู ู ุฎู ุญุฑู ูุง ูพุดุช ุงุชูุงูุงุชุด ูุณุช.\n",
            "ููู ุงูุนุงุฏู ุฎูุจ ู ุฌุฐุงุจ! ููู :) ุญุชูุง ุงฺฏู ููุช ฺฉุฑุฏุฏ ุญุช ุดุฏู ููููู ุงุด ุฑู ูู ุจุฎููุฏ ฺูู ูุงูุนุง ุงุฒ ุงูู ุฏุงุณุชุงู ูุง ฺฉู ุดุฏุฏุง ุดูุงุฑู ุฏุฑฺฏุฑ ุฎูุฏุด ูฺฉูู ู ุฎู ุญุฑู ูุง ูพุดุช ุงุชูุงูุงุชุด ูุณุช.\n",
            "ุฎู ุฎูุดู ุงููุฏ ู ุฏุงุณุชุงูุด ูู ุฎู ุฌุงูุจู ุ ูุถุงุณุงุฒุด ู ุฌุงูุง ุฎู ูู ูุดู ู ุงุฏู ุฑู ุจุง ุฎูุฏุด ููุฑุงู ูฺฉูู . ุชู ุงู ุณุจฺฉ ฺฉุชุงุจ ุ ุงู ุงุฒ ฺฉุชุงุจ ูุง ููุฑุฏ ุนูุงูู ุงู ุจูุฏ ุงฺฏุฑ ฺฉุณ ฺฉุชุงุจ ุฌุงูุจ ู ุฎููุฏู ุฏฺฏู ุง ุชู ุงู ุณุจฺฉ ูุดูุงุณู ูุทูุง ุจฺฏู ูุง ูู ุงุณุชูุงุฏู ฺฉูู . ุฎู ููููู ๐โบ\n",
            "ุฎู ุฎูุดู ุงููุฏ ู ุฏุงุณุชุงูุด ูู ุฎู ุฌุงูุจู ุ ูุถุงุณุงุฒุด ู ุฌุงูุง ุฎู ูู ูุดู ู ุงุฏู ุฑู ุจุง ุฎูุฏุด ููุฑุงู ูฺฉูู . ุชู ุงู ุณุจฺฉ ฺฉุชุงุจ ุ ุงู ุงุฒ ฺฉุชุงุจ ูุง ููุฑุฏ ุนูุงูู ุงู ุจูุฏ ุงฺฏุฑ ฺฉุณ ฺฉุชุงุจ ุฌุงูุจ ู ุฎููุฏู ุฏฺฏู ุง ุชู ุงู ุณุจฺฉ ูุดูุงุณู ูุทูุง ุจฺฏู ูุง ูู ุงุณุชูุงุฏู ฺฉูู . ุฎู ููููู \n",
            "ูู ูููุด ูู ฺฉุชุงุจุด ุฎู ุฎูููุจู ุญุชูุง ุจุฎููุฏ ุง ูููุดู ูฺฏุงู ฺฉูุฏ๐๐\n",
            "ูู ูููุด ูู ฺฉุชุงุจุด ุฎู ุฎูููุจู ุญุชูุง ุจุฎููุฏ ุง ูููุดู ูฺฏุงู ฺฉูุฏ\n",
            "ฺู ุฎูุจ ฺฉู ุงู ููู ฺฉุชุงุจ ุฑุงฺฏุงู ฺฉุฑุฏุฏ\n",
            "ฺู ุฎูุจ ฺฉู ุงู ููู ฺฉุชุงุจ ุฑุงฺฏุงู ฺฉุฑุฏุฏ\n",
            "ูููุด ุนุงูู ฺฉุชุงุจุด ูู ูุทุนุง ุนุงู ุจุงุฏ ุจุงุดู. ููููู ุจุงุจุช ุนุฏ\n",
            "ูููุด ุนุงูู ฺฉุชุงุจุด ูู ูุทุนุง ุนุงู ุจุงุฏ ุจุงุดู. ููููู ุจุงุจุช ุนุฏ\n",
            "ูุฑุณ ุทุงูฺู ุนุฒุฒ ุจุฑุง ฺฉุชุงุจ ูุง ุจุง ุงุฑุฒุด ฺฉู ุนุฏ ุฏุงุฏุฏ๐ธ๐ธ๐ธ๐๐ป๐๐ป\n",
            "ูุฑุณ ุทุงูฺู ุนุฒุฒ ุจุฑุง ฺฉุชุงุจ ูุง ุจุง ุงุฑุฒุด ฺฉู ุนุฏ ุฏุงุฏุฏ\n",
            "ุฏุณุช ูุฑุฒุงุฏ ุทุงูฺู .ุฏูุชูู ฺฏุฑู... 12 ฺฉุชุงุจ ุฑุงฺฏุงู ุงุญุณูุช\n",
            "ุฏุณุช ูุฑุฒุงุฏ ุทุงูฺู .ุฏูุชูู ฺฏุฑู... 12 ฺฉุชุงุจ ุฑุงฺฏุงู ุงุญุณูุช\n",
            "ุณูุงู ุทุงูฺู ุจู ูุธุฑู ุฑุงฺฏุงู ฺฉุฑุฏู ฺฉ ุฌูุฏ ุงุฒ ฺฉ ฺฉุชุงุจ ุณู ุฌูุฏ ุจุดุชุฑ ุจุฑุง ุงูู ฺฉู ูุงุฑู ุจู ุฎุฑุฏ ุฏู ฺฉุชุงุจ ุฏฺฏู ุชุดูู ฺฉู ู ุงู ุนุฏ ุจู ุญุณุงุจ ููุงุฏ ุงฺฏุฑ ูุงูุนุง ูุตุฏ ุนุฏ ุฏุงุฏู ุฏุงุฑุฏ ูุฑ ุณู ฺฉุชุงุจ ุฑู ุฑุงฺฏุงู ฺฉูุฏ.\n",
            "ุณูุงู ุทุงูฺู ุจู ูุธุฑู ุฑุงฺฏุงู ฺฉุฑุฏู ฺฉ ุฌูุฏ ุงุฒ ฺฉ ฺฉุชุงุจ ุณู ุฌูุฏ ุจุดุชุฑ ุจุฑุง ุงูู ฺฉู ูุงุฑู ุจู ุฎุฑุฏ ุฏู ฺฉุชุงุจ ุฏฺฏู ุชุดูู ฺฉู ู ุงู ุนุฏ ุจู ุญุณุงุจ ููุงุฏ ุงฺฏุฑ ูุงูุนุง ูุตุฏ ุนุฏ ุฏุงุฏู ุฏุงุฑุฏ ูุฑ ุณู ฺฉุชุงุจ ุฑู ุฑุงฺฏุงู ฺฉูุฏ.\n",
            "ูููุด ุนุงูู ฺฉุชุงุจุด ูู ุฎู ุนุงูู ุงุฒ ฺฉูุช ูุฑู ูุฎูู ุฏุงุณุชุงูุด ูุฌุงูู\n",
            "ูููุด ุนุงูู ฺฉุชุงุจุด ูู ุฎู ุนุงูู ุงุฒ ฺฉูุช ูุฑู ูุฎูู ุฏุงุณุชุงูุด ูุฌุงูู\n",
            "ฺฉุชุงุจ ู ููุฏููู ูู ุนุงุดู ูููุด ูุณุชู\n",
            "ฺฉุชุงุจ ู ููุฏููู ูู ุนุงุดู ูููุด ูุณุชู\n",
            "ุฌุงูุจ ููุฏ\n",
            "ุฌุงูุจ ููุฏ\n",
            "ูู ุงู ฺฉุชุงุจ ุฑู ุฏุฑ ูุงูุจ ุงุณู divergent ุฎููุฏู ูู ุชุฑุฌูู ุง ฺฉู ุฏุฑ ููููุด ุฏุฏู ุชุฑุฌูู  ุฎูุจ ุจูุฏ\n",
            "ูู ุงู ฺฉุชุงุจ ุฑู ุฏุฑ ูุงูุจ ุงุณู divergent ุฎููุฏู ูู ุชุฑุฌูู ุง ฺฉู ุฏุฑ ููููุด ุฏุฏู ุชุฑุฌูู  ุฎูุจ ุจูุฏ\n",
            "ูููุด ุฑู ูู ุณุงุฎุชู ูููู divergent ูุนุฑูู\n",
            "ูููุด ุฑู ูู ุณุงุฎุชู ูููู divergent ูุนุฑูู\n",
            "ุจู ูุธุฑู ฺฉุชุงุจ ุฎูุจ ู ุฌุงูุจ ุจูุฏ ูู ฺฉู ุฏูุฑ ุงุฒ ูุงูุนุช ุจูุฏ. ููุณูุฏู ฺฉู ุฏุฑ ููุฑุฏ ูุฏุฑุช ู ุดุฌุงุนุช ู ุฎุงุต ุจูุฏู ุจุฆุงุชุฑุณ ุงุบุฑุงู ฺฉุฑุฏู ุจูุฏ.\n",
            "ุจู ูุธุฑู ฺฉุชุงุจ ุฎูุจ ู ุฌุงูุจ ุจูุฏ ูู ฺฉู ุฏูุฑ ุงุฒ ูุงูุนุช ุจูุฏ. ููุณูุฏู ฺฉู ุฏุฑ ููุฑุฏ ูุฏุฑุช ู ุดุฌุงุนุช ู ุฎุงุต ุจูุฏู ุจุฆุงุชุฑุณ ุงุบุฑุงู ฺฉุฑุฏู ุจูุฏ.\n",
            "ุจุณุงุฑ ูุดุชุงูู ฺฉู ุงู ฺฉุชุงุจ ุฑู ูุทุงูุนู ฺฉูู ุงูุง ุฏุฑ ุญุงู ุญุงุถุฑ ูู ููุชุด ุฑู ูุฏุงุฑู ูู ุงูฺฉู ฺฉู ฺฉุชุงุจ ูุทุงูุนู ูฺฉุฑุฏู ุฑู ุฏุณุชู ุจุงู ูููุฏู.\n",
            "ุจุณุงุฑ ูุดุชุงูู ฺฉู ุงู ฺฉุชุงุจ ุฑู ูุทุงูุนู ฺฉูู ุงูุง ุฏุฑ ุญุงู ุญุงุถุฑ ูู ููุชุด ุฑู ูุฏุงุฑู ูู ุงูฺฉู ฺฉู ฺฉุชุงุจ ูุทุงูุนู ูฺฉุฑุฏู ุฑู ุฏุณุชู ุจุงู ูููุฏู.\n",
            "ุงูู ูฺฉุฑ ฺฉุฑุฏู ุดุจู ฑนธดูุณุชุดุ ูู ุฎู ุถุนู ุชุฑ ุงุฒ ุงูู ุจูุฏ..๐\n",
            "ุงูู ูฺฉุฑ ฺฉุฑุฏู ุดุจู ฑนธดูุณุชุดุ ูู ุฎู ุถุนู ุชุฑ ุงุฒ ุงูู ุจูุฏ..\n",
            "ุชุฑุฌูู  ฺฉุชุงุจ ุนุงู ุจูุฏ ๐\n",
            "ุชุฑุฌูู  ฺฉุชุงุจ ุนุงู ุจูุฏ \n",
            "ูุงูุนุง ุนุงู ุจูุฏ.. \n",
            "ููุชููุณุชู ุฏุณุช ุงุฒ ุฎููุฏูุด ุจุฑุฏุงุฑู ุงุตูุง..\n",
            "ูุงูุนุง ุนุงู ุจูุฏ.. \n",
            "ููุชููุณุชู ุฏุณุช ุงุฒ ุฎููุฏูุด ุจุฑุฏุงุฑู ุงุตูุง..\n",
            "ุขูุง ุงุญุณุงู ุตูุง ุงฺฏู ฺฉุชุงุจ ุงุตู ุฑู ุฎููุฏู ุจุงุดุฏ ููุณูุฏู (ูุฑููฺฉุง ุฑุงู) ุชู ุตูุญู ุชูุถุญุงุชุ ุนููุงู ฺฉุชุงุจ ุฑู ฺฉุงููุง ุชุดุฑุญ ฺฉุฑุฏู.  ุชู ุชูุถุญุงุชุด ุงููุฏู:  ุชู ุงู ฺฉุชุงุจdivergent ุจู ฺฉุณ ูฺฏู ฺฉู ููุน ุฏฺฏู ุง ุงุฒ ุฒูุฏฺฏ ุฑู ุฏุฑ ูพุด ูฺฏุฑู ู ุงุฒ ูุณุฑ ุนุงุฏ ููุญุฑู ูุดู ุจูุงุจุฑุงู \"ุณูุช ุดฺฉู\" ุชุฑุฌูู ุจู ุฌุง ู ุนุงู ุจูุฏ. \n",
            "ุขูุง ุงุญุณุงู ุตูุง ุงฺฏู ฺฉุชุงุจ ุงุตู ุฑู ุฎููุฏู ุจุงุดุฏ ููุณูุฏู (ูุฑููฺฉุง ุฑุงู) ุชู ุตูุญู ุชูุถุญุงุชุ ุนููุงู ฺฉุชุงุจ ุฑู ฺฉุงููุง ุชุดุฑุญ ฺฉุฑุฏู.  ุชู ุชูุถุญุงุชุด ุงููุฏู:  ุชู ุงู ฺฉุชุงุจdivergent ุจู ฺฉุณ ูฺฏู ฺฉู ููุน ุฏฺฏู ุง ุงุฒ ุฒูุฏฺฏ ุฑู ุฏุฑ ูพุด ูฺฏุฑู ู ุงุฒ ูุณุฑ ุนุงุฏ ููุญุฑู ูุดู ุจูุงุจุฑุงู \"ุณูุช ุดฺฉู\" ุชุฑุฌูู ุจู ุฌุง ู ุนุงู ุจูุฏ. \n",
            "ุงุณู ุงุตู ฺฉุชุงุจ divergent ูุณุช\n",
            "ุนู ุจ ูุธุฑ \n",
            "ุจู ูุธุฑู ุณูุช ุดฺฉู ุงุดุชุจุงูู.\n",
            "ูู ฺฉุชุงุจ ุฎู ุฎูุจู.\n",
            "ุณุจฺฉ ููุดุชู ูุฑู ุฏุงุฑู ุจุฎุตูุต ุฌูุฏ ุขุฎุฑ.\n",
            "ุญุชูุง ุจุฎููุฏ.\n",
            "ุงุณู ุงุตู ฺฉุชุงุจ divergent ูุณุช\n",
            "ุนู ุจ ูุธุฑ \n",
            "ุจู ูุธุฑู ุณูุช ุดฺฉู ุงุดุชุจุงูู.\n",
            "ูู ฺฉุชุงุจ ุฎู ุฎูุจู.\n",
            "ุณุจฺฉ ููุดุชู ูุฑู ุฏุงุฑู ุจุฎุตูุต ุฌูุฏ ุขุฎุฑ.\n",
            "ุญุชูุง ุจุฎููุฏ.\n",
            "ููู  ุฌูุฏ ูุงุด ููู ุงูุนุงุฏู ุจูุฏ ูู ูพุงุฑุณุงู ุฎููุฏู. ููุถูุนุด ูููู ูุฏุฑ ฺฉ  ฺฉุชุงุจ ูุง ูุฑ ูพุงุชุฑ ุฌุฏุฏ ุจูุฏ ุงูู ุฌุฏุฏู\n",
            "ููู  ุฌูุฏ ูุงุด ููู ุงูุนุงุฏู ุจูุฏ ูู ูพุงุฑุณุงู ุฎููุฏู. ููุถูุนุด ูููู ูุฏุฑ ฺฉ  ฺฉุชุงุจ ูุง ูุฑ ูพุงุชุฑ ุฌุฏุฏ ุจูุฏ ุงูู ุฌุฏุฏู\n",
            "ุนุงุดู ุงู ฺฉุชุงุจ ูุง ู ูููุด ูุณุชู...ุงูฺฏูุณุด ูู ุนุงุงุงุงูู...ุนุงุดู ุจุงุฒฺฏุฑุงูุด ูู ูุณุชู...\n",
            "ุนุงุดู ุงู ฺฉุชุงุจ ูุง ู ูููุด ูุณุชู...ุงูฺฏูุณุด ูู ุนุงุงุงุงูู...ุนุงุดู ุจุงุฒฺฏุฑุงูุด ูู ูุณุชู...\n",
            "ุญุฑู ูุฏุงุฑู\n",
            "ุญุฑู ูุฏุงุฑู\n",
            "ุชู  ุงู ุณุจฺฉ ฺฉุชุงุจุง ุฏฺฏู ูู ูุณุชุุ\n",
            "ฺฉุชุงุจ ุนุงู ุจูุฏ\n",
            "ุชู  ุงู ุณุจฺฉ ฺฉุชุงุจุง ุฏฺฏู ูู ูุณุชุุ\n",
            "ฺฉุชุงุจ ุนุงู ุจูุฏ\n",
            "ุนุงู ุจูุฏ!ุชุฑุฌูู ูู ุญุฑู ูุฏุงุดุช!ูฅ ุณุชุงุฑู  ูฅุณุชุงุฑู!!\n",
            "ุนุงู ุจูุฏ!ุชุฑุฌูู ูู ุญุฑู ูุฏุงุดุช!ูฅ ุณุชุงุฑู  ูฅุณุชุงุฑู!!\n",
            "ุฎู ุนุงู ุจูุฏ. ุชุฑุฌูู  ุฎู ุฎูุจ ูู ุฏุงุดุช ู ุณุฑุน ุฌูู ูุฑูุช.\n",
            "ุฎู ุนุงู ุจูุฏ. ุชุฑุฌูู  ุฎู ุฎูุจ ูู ุฏุงุดุช ู ุณุฑุน ุฌูู ูุฑูุช.\n",
            "ุจุณุงุฑ ุฎูุจ ุจูุฏ ู ุชุฑุฌูู ุจุณุงุฑ ุนุงู ุฏุงุดุช. ุฎู ุณุฑุน ุฌูู ูุฑูุช.\n",
            "ุจุณุงุฑ ุฎูุจ ุจูุฏ ู ุชุฑุฌูู ุจุณุงุฑ ุนุงู ุฏุงุดุช. ุฎู ุณุฑุน ุฌูู ูุฑูุช.\n",
            "ูฅ  ูุตู ุงูู ุฎู ุฎูุจ ู ูุฌุงู ุงูฺฏุฒ ุจูุฏ ูู ุจุนุฏุด ฺฉู ฺฉูุฏ ุดุฏ ุงูุง  ูฉ ูุตู ุขุฎุฑุด ุนุงู ุจูุฏ.\n",
            "ฺฉูุง  ูฃูฉ ูุตูู.\n",
            "ุชุฑุฌูู ุฎูุจ ู ุฑูุงู ุฏุงุดุช.\n",
            "ุฏุฑ ฺฉู ฺฉุชุงุจ ุฎูุจ ุจูุฏ.\n",
            "ูฅ  ูุตู ุงูู ุฎู ุฎูุจ ู ูุฌุงู ุงูฺฏุฒ ุจูุฏ ูู ุจุนุฏุด ฺฉู ฺฉูุฏ ุดุฏ ุงูุง  ูฉ ูุตู ุขุฎุฑุด ุนุงู ุจูุฏ.\n",
            "ฺฉูุง  ูฃูฉ ูุตูู.\n",
            "ุชุฑุฌูู ุฎูุจ ู ุฑูุงู ุฏุงุดุช.\n",
            "ุฏุฑ ฺฉู ฺฉุชุงุจ ุฎูุจ ุจูุฏ.\n",
            "ุชุฑุฌูู ุงุด ุนุงู ุจูุฏ. ฺฉุชุงุจ ุฑู ุชู ฺฉ ุฑูุฒ ุชููู ฺฉุฑุฏู๐๐๐\n",
            "ุชุฑุฌูู ุงุด ุนุงู ุจูุฏ. ฺฉุชุงุจ ุฑู ุชู ฺฉ ุฑูุฒ ุชููู ฺฉุฑุฏู\n",
            "ุจู ูุธุฑ ูู ฺฉุชุงุจ ููู ุงูุนุงุฏู ุง ุจูุฏ.\n",
            "ุจู ูุธุฑ ูู ฺฉุชุงุจ ููู ุงูุนุงุฏู ุง ุจูุฏ.\n",
            "ฺฉุชุงุจ ุฎูุจุณุช. ุชุตูุฑ ุณุงุฒ ุจุณุงุฑ ูู ู ุฑูุงู. ูุถุง ูุงูุชุฒ ุฌุฐุงุจ ู ูพุฑุดูุฑ ุฏุงุฑู. ูุงูุนุง ูุฐุช ุจุฑุฏู. ุณูพุงุณฺฏุฒุงุฑู.\n",
            "ฺฉุชุงุจ ุฎูุจุณุช. ุชุตูุฑ ุณุงุฒ ุจุณุงุฑ ูู ู ุฑูุงู. ูุถุง ูุงูุชุฒ ุฌุฐุงุจ ู ูพุฑุดูุฑ ุฏุงุฑู. ูุงูุนุง ูุฐุช ุจุฑุฏู. ุณูพุงุณฺฏุฒุงุฑู.\n",
            "ฺฉุชุงุจ ุฌุฐุงุจู ู ุฎูุงููุฏู ุฑู ุจู ุฏูุจุงู ฺฉุฑุฏู ฺฉุชุงุจ ุชุฑุบุจ ู ฺฉูู.\n",
            "ฺฉุชุงุจ ุฌุฐุงุจู ู ุฎูุงููุฏู ุฑู ุจู ุฏูุจุงู ฺฉุฑุฏู ฺฉุชุงุจ ุชุฑุบุจ ู ฺฉูู.\n",
            "ฺฉุชุงุจ ุจุณุงุฑ ูุดูฺฏู ูุงูุนุง ุจุฑุง ฺฉุณุง ฺฉู ุงุฒ ฺฉุชุงุจ ู ุณุจฺฉ ุนุทุด ูุจุงุฑุฒู ุฎูุดุดูู ูุงุฏ ูพุดููุงุฏ ูุดููู ... \n",
            "ุทุงูฺู ุงฺฏู ฺฉุชุงุจูุง ูุนุฑูู ุฌูุงู ุชู ุณุจฺฉ ูุงูุชุฒ ูุซู ุงุฑุจุงุจ ุญููู ูุง . ูุฑ ูพุงุชุฑ . ูุงุฑูุง ูู ุจุฐุงุฑ ุฎู ุฎูุจู\n",
            "ฺฉุชุงุจ ุจุณุงุฑ ูุดูฺฏู ูุงูุนุง ุจุฑุง ฺฉุณุง ฺฉู ุงุฒ ฺฉุชุงุจ ู ุณุจฺฉ ุนุทุด ูุจุงุฑุฒู ุฎูุดุดูู ูุงุฏ ูพุดููุงุฏ ูุดููู ... \n",
            "ุทุงูฺู ุงฺฏู ฺฉุชุงุจูุง ูุนุฑูู ุฌูุงู ุชู ุณุจฺฉ ูุงูุชุฒ ูุซู ุงุฑุจุงุจ ุญููู ูุง . ูุฑ ูพุงุชุฑ . ูุงุฑูุง ูู ุจุฐุงุฑ ุฎู ุฎูุจู\n",
            "ุงู ฺฉุชุงุจ ฺฉ ุณู ฺฏุงูุณุช ุนู ุฏูุจุงูู ุฏุงุฑู ู ูุงู ุงู ุณู ฺฏุงูู:1_ุณูุช ุดฺฉู2_ุดูุฑุด3_ูู ูพูุงู\n",
            "ฺฉู ุงุฒ ุฑู ุฏู ฺฉุชุงุจ ุงูู ููู ูู ุณุงุฎุชู ุดุฏู ู ุงุฎุฑ ูู ุณุงุฎุชู ุฎูุงูุฏ ุดุฏ ฺฉู ููู ฺฉู ฺฉุชุงุจ ุฏูู ุณุงุฎุชู ุฏุฑ ุญุงู ุญุงุธุฑ ุชู ุณููุง ูุง ุฏุฑ ุญุงู ุงฺฉุฑุงู\n",
            "ุงู ฺฉุชุงุจ ฺฉ ุณู ฺฏุงูุณุช ุนู ุฏูุจุงูู ุฏุงุฑู ู ูุงู ุงู ุณู ฺฏุงูู:1_ุณูุช ุดฺฉู2_ุดูุฑุด3_ูู ูพูุงู\n",
            "ฺฉู ุงุฒ ุฑู ุฏู ฺฉุชุงุจ ุงูู ููู ูู ุณุงุฎุชู ุดุฏู ู ุงุฎุฑ ูู ุณุงุฎุชู ุฎูุงูุฏ ุดุฏ ฺฉู ููู ฺฉู ฺฉุชุงุจ ุฏูู ุณุงุฎุชู ุฏุฑ ุญุงู ุญุงุธุฑ ุชู ุณููุง ูุง ุฏุฑ ุญุงู ุงฺฉุฑุงู\n",
            "ุจ ูุธุฑู ุดุฑูุน ุฎู ุฎูุจ ุฏุงุดุช ุงูุง ุฏุฑ ุงุฏุงูู ุงูุช ฺฉุฑุฏุดุ ุจ ูุฑ ุญุงู ุงุฒ ุฎุงูุฏูุด ูพุดูุงู ูุณุชู.\n",
            "ุจ ูุธุฑู ุดุฑูุน ุฎู ุฎูุจ ุฏุงุดุช ุงูุง ุฏุฑ ุงุฏุงูู ุงูุช ฺฉุฑุฏุดุ ุจ ูุฑ ุญุงู ุงุฒ ุฎุงูุฏูุด ูพุดูุงู ูุณุชู.\n",
            "ุนู ุฑุบู ุจุนุถ ุบูุท ูุง ุงููุงุ ููู ุงูุนุงุฏู ุจูุฏ. ูู ุฏุงุณุชุงู ู ูู ุชุฑุฌูู\n",
            "ุนู ุฑุบู ุจุนุถ ุบูุท ูุง ุงููุงุ ููู ุงูุนุงุฏู ุจูุฏ. ูู ุฏุงุณุชุงู ู ูู ุชุฑุฌูู\n",
            "ุฎู ุฌุงูุจู  ู ฺฉุณุฑู ูุดู ุงุฒ ุงูู ุชุง ุขุฎุฑุด ุฑู ุฎููุฏ ุ ููุชูุง ู ฺฉู ุฒุงุฏ ูุงูุชุฒ ู ุบุฑ ูุงูุนู !\n",
            "ุฎู ุฌุงูุจู  ู ฺฉุณุฑู ูุดู ุงุฒ ุงูู ุชุง ุขุฎุฑุด ุฑู ุฎููุฏ ุ ููุชูุง ู ฺฉู ุฒุงุฏ ูุงูุชุฒ ู ุบุฑ ูุงูุนู !\n",
            "ุฎู ุฎูุจ ุจูุฏ ููุท ฺฉุงุด ุจุฑุง ุฌูุฏ ุฏู ู ุณู ูู ุชุฎูู ูุฐุงุดุชุฏ...\n",
            "ุฎู ุฎูุจ ุจูุฏ ููุท ฺฉุงุด ุจุฑุง ุฌูุฏ ุฏู ู ุณู ูู ุชุฎูู ูุฐุงุดุชุฏ...\n",
            "ุฎูุจ ุขูุง ุฎููููููุจ ....\n",
            "ุฎูุจ ุขูุง ุฎููููููุจ ....\n",
            "ุนุงูู ููููู ููุท ุงฺฏู ู ุชููุฏ ฺฉุชุงุจ ูุง ุฏููุฏู ูุฒุงุฑ ุชู ู ูุบูู ุฎ ู ุงุชุด (game of thranth) ุฑู ูู ุจุฒุงุฑุฏ ููููู ูุดู\n",
            "ุนุงูู ููููู ููุท ุงฺฏู ู ุชููุฏ ฺฉุชุงุจ ูุง ุฏููุฏู ูุฒุงุฑ ุชู ู ูุบูู ุฎ ู ุงุชุด (game of thranth) ุฑู ูู ุจุฒุงุฑุฏ ููููู ูุดู\n",
            "ููููู ุทุงูฺู. ุนุงูู\n",
            "ููููู ุทุงูฺู. ุนุงูู\n",
            "ูุงูุนุง ุนุงูููููู......\n",
            "ูุงูุนุง ุนุงูููููู......\n",
            "ุงูุชุชุงุญู ฺฉุชุงุจ ุขููุฏุฑ ุฎูุจ ุจูุฏ ฺฉ ูุชูุงูุณุชู ูุงู ู ูพูุฌ ุณุชุงุฑู ุฑุง ูุฏูู!\n",
            "ุงูุชุชุงุญู ฺฉุชุงุจ ุขููุฏุฑ ุฎูุจ ุจูุฏ ฺฉ ูุชูุงูุณุชู ูุงู ู ูพูุฌ ุณุชุงุฑู ุฑุง ูุฏูู!\n",
            "ูู ููููุง ูุฑ ุณู ฺฏุงูู ุฑู ุฏุฏู ู ุนุงู ุจูุฏ.\n",
            "ูู ููููุง ูุฑ ุณู ฺฏุงูู ุฑู ุฏุฏู ู ุนุงู ุจูุฏ.\n",
            "ุงู ูู ูุดูฺฏ ุจูุฏ.\n",
            "ฺฉุชุงุจ ุงูู ุฑู ุฏูุณุชุงู ูฺฏู ูุดูฺฏ ุชุฑ ุจูุฏ ู ูู ูฺฉุฑ ูฺฉูู ุนูุชุด ุงูู ฺฉู ุชูุฑุจุง ูููู ูฺฺฏ ูุง ุนุฌุจ ฺฉู ุชู ฺฉุชุงุจ ุงูู ูุทุฑุญ ุดุฏู ุจูุฏ ุงู ุฌุง ุชฺฉุฑุงุฑ ู ุดุฏุ ูู ฺฉู ููุณูุฏู ุญุฑู ุฌุฏุฏ ุจุฑุง ฺฏูุชู ูุฏุงุดุชู ุจุงุดู ูู ุจุง ูููู ูฺฺฏ ูุง ู ุงุฎูุงู ูุง ุฏุงุณุชุงู ุฑู ุฌูู ุจุฑุฏู. ฺุฒ ุจูุดูู ุงุถุงูู ูฺฉุฑุฏู. ู ุงูฺฉู ุงุฒ ูุญุงุธ ุชุงูพ ฺฉู ุงุฑุงุฏ ุฏุงุดุช ฺฉู ุฎุจ ูุณููุง ุฎูุงููุฏู ุชุฑุฌุญ ูุฏู ููุช ุชู ุงูุฌ ุฏุงุณุชุงู ูุณุช ฺุดูุด ฺฏุฑ ูฺฉูู ุจู ฺฉููุงุช ุชุง ุงููุง ุฑู ุญุฏุณ ุจุฒูู ุง ูุฑุชุจ ฺฉูู\n",
            "ุงู ูู ูุดูฺฏ ุจูุฏ.\n",
            "ฺฉุชุงุจ ุงูู ุฑู ุฏูุณุชุงู ูฺฏู ูุดูฺฏ ุชุฑ ุจูุฏ ู ูู ูฺฉุฑ ูฺฉูู ุนูุชุด ุงูู ฺฉู ุชูุฑุจุง ูููู ูฺฺฏ ูุง ุนุฌุจ ฺฉู ุชู ฺฉุชุงุจ ุงูู ูุทุฑุญ ุดุฏู ุจูุฏ ุงู ุฌุง ุชฺฉุฑุงุฑ ู ุดุฏุ ูู ฺฉู ููุณูุฏู ุญุฑู ุฌุฏุฏ ุจุฑุง ฺฏูุชู ูุฏุงุดุชู ุจุงุดู ูู ุจุง ูููู ูฺฺฏ ูุง ู ุงุฎูุงู ูุง ุฏุงุณุชุงู ุฑู ุฌูู ุจุฑุฏู. ฺุฒ ุจูุดูู ุงุถุงูู ูฺฉุฑุฏู. ู ุงูฺฉู ุงุฒ ูุญุงุธ ุชุงูพ ฺฉู ุงุฑุงุฏ ุฏุงุดุช ฺฉู ุฎุจ ูุณููุง ุฎูุงููุฏู ุชุฑุฌุญ ูุฏู ููุช ุชู ุงูุฌ ุฏุงุณุชุงู ูุณุช ฺุดูุด ฺฏุฑ ูฺฉูู ุจู ฺฉููุงุช ุชุง ุงููุง ุฑู ุญุฏุณ ุจุฒูู ุง ูุฑุชุจ ฺฉูู\n",
            "ุฌูุฏ ุฏูู ุนูุงูู ุจุฑ ุฏุงุดุชู ุณุฑ ุงุดุชุจุงูุงุช ุชุงูพ ุ ุงุฒ ูุธุฑ ููุถูุน ู ุงุชูุงูุงุช ุฏุงุณุชุงู ุณุทุญ ูพุงู ุชุฑ ุงุฒ ุฌูุฏ ุงูู ุฏุงุฑู .\n",
            "ูู ุฏุฑ ูุฌููุน ุงู ู ุณู ฺฏุงูู ููุถูุน ุฌุงูุจ ุฏุงุฑู ู ุฌุฐุงุจู ๐\n",
            "ุฌูุฏ ุฏูู ุนูุงูู ุจุฑ ุฏุงุดุชู ุณุฑ ุงุดุชุจุงูุงุช ุชุงูพ ุ ุงุฒ ูุธุฑ ููุถูุน ู ุงุชูุงูุงุช ุฏุงุณุชุงู ุณุทุญ ูพุงู ุชุฑ ุงุฒ ุฌูุฏ ุงูู ุฏุงุฑู .\n",
            "ูู ุฏุฑ ูุฌููุน ุงู ู ุณู ฺฏุงูู ููุถูุน ุฌุงูุจ ุฏุงุฑู ู ุฌุฐุงุจู \n",
            "ุฌูุฏ ุงูู ุงุฒ ูุฑ ูุธุฑ ุฎูุจ ุจูุฏ ุงูุง ุฌูุฏ ุฏูู ูพุฑ ุงุฒ ุงุดุชุจุงูุงุช ุชุงูพู .\n",
            "ุฌูุฏ ุงูู ุงุฒ ูุฑ ูุธุฑ ุฎูุจ ุจูุฏ ุงูุง ุฌูุฏ ุฏูู ูพุฑ ุงุฒ ุงุดุชุจุงูุงุช ุชุงูพู .\n",
            "ูุฒุฎุฑูุ\n",
            "ูุฒุฎุฑูุ\n",
            "ูู ููููู ุฑุง ุฎูุงูุฏู ูู ููุช ฺฉุชุงุจ ุฑุง ุฎุฑุฏู ูุชู ุญุฐู ุดุฏู ุนูุชุด ฺูุ\n",
            "ูู ููููู ุฑุง ุฎูุงูุฏู ูู ููุช ฺฉุชุงุจ ุฑุง ุฎุฑุฏู ูุชู ุญุฐู ุดุฏู ุนูุชุด ฺูุ\n",
            "ุชุฑุฌูู ูุฑ  ฺฉุชุงุจ ุงุฒ ฺฉุชุงุจ ูุง ุณู ฺฏุงูู ุจุณุงุฑ ุฑูุงู ูุจุงุดุฏ. ุจุณุงุฑ ูุฐุช ุจุฑุฏู... ุฎุณุชู ูุจุงุดุฏ ุฎุงูู ูุชุฑุฌู... ๐๐\n",
            "ุชุฑุฌูู ูุฑ  ฺฉุชุงุจ ุงุฒ ฺฉุชุงุจ ูุง ุณู ฺฏุงูู ุจุณุงุฑ ุฑูุงู ูุจุงุดุฏ. ุจุณุงุฑ ูุฐุช ุจุฑุฏู... ุฎุณุชู ูุจุงุดุฏ ุฎุงูู ูุชุฑุฌู... \n",
            "ุนุงู ุจูุฏ!ุงุฒ ุงูู ฺฉุชุงุจ ูุง ฺฉู ุขุฏู ุงุฒ ุฎููุฏูุด ูุฐุช ูุจุฑู ู ุจุง ุดุฎุตุช ูุง ุจู ุฑุงุญุช ุฏุงุณุชุงู ุงุฑุชุจุงุท ุจุฑูุฑุงุฑ ูฺฉูู!๐\n",
            "ุนุงู ุจูุฏ!ุงุฒ ุงูู ฺฉุชุงุจ ูุง ฺฉู ุขุฏู ุงุฒ ุฎููุฏูุด ูุฐุช ูุจุฑู ู ุจุง ุดุฎุตุช ูุง ุจู ุฑุงุญุช ุฏุงุณุชุงู ุงุฑุชุจุงุท ุจุฑูุฑุงุฑ ูฺฉูู!\n",
            "ูุฐุชุจุฎุด ุจูุฏ.\n",
            "ูุฐุชุจุฎุด ุจูุฏ.\n",
            "ูู ฺฉุชุงุจ ุงุตู ุดู ูู ุฎููุฏู. ุจุงุฏ ุจฺฏู ุชุฑุฌูู ุงุด ูุญุดุฑู. ุฑููุฏ ุฏุงุณุชุงู ูู ุฎู ุฌุฐุงุจู.๐๐ปฺฉูุง ููุช ุดุฑูุน ุจู ุฎููุฏู ุงู ุณู ฺฏุงูู ูฺฉู ุฏฺฏู ููุชูู ฺฉุชุงุจ ุฑู ุฒูู ุจุฐุงุฑ.\n",
            "ูู ฺฉุชุงุจ ุงุตู ุดู ูู ุฎููุฏู. ุจุงุฏ ุจฺฏู ุชุฑุฌูู ุงุด ูุญุดุฑู. ุฑููุฏ ุฏุงุณุชุงู ูู ุฎู ุฌุฐุงุจู.ฺฉูุง ููุช ุดุฑูุน ุจู ุฎููุฏู ุงู ุณู ฺฏุงูู ูฺฉู ุฏฺฏู ููุชูู ฺฉุชุงุจ ุฑู ุฒูู ุจุฐุงุฑ.\n",
            "ฺฉุงุฑุจุฑ ูุงุฏ ุ ููููู ฺฉู ฺฏูุช ...ุฑุงุณุชุด ูู ูู ูพูุงู ุฑู ุณุฑฺ ฺฉุฑุฏู ุงููุฏ ฺฉู ูุณุช !ุญุงูุง ุชู ุจุฎุด ุฑูุงููุง ุฎุงุฑุฌ ูพุฏุงุด ฺฉุฑุฏู ...ูููุฒ ูุฎููุฏู ...ุงูุฏูุงุฑู ุฎูุจ ุจุงุดู !\n",
            "ฺฉุงุฑุจุฑ ูุงุฏ ุ ููููู ฺฉู ฺฏูุช ...ุฑุงุณุชุด ูู ูู ูพูุงู ุฑู ุณุฑฺ ฺฉุฑุฏู ุงููุฏ ฺฉู ูุณุช !ุญุงูุง ุชู ุจุฎุด ุฑูุงููุง ุฎุงุฑุฌ ูพุฏุงุด ฺฉุฑุฏู ...ูููุฒ ูุฎููุฏู ...ุงูุฏูุงุฑู ุฎูุจ ุจุงุดู !\n",
            "ฺฉุงุฑุจุฑ 4552 !! ุทุงูฺู ูู ูพูุงู ุฑู ูู ุฏุงุฑู...ููู ุงูุชุดุงุฑุงุช ููุฑูุฒ ููุฑ ููุชุดุฑุด ฺฉุฑุฏู\n",
            "ฺฉุงุฑุจุฑ 4552 !! ุทุงูฺู ูู ูพูุงู ุฑู ูู ุฏุงุฑู...ููู ุงูุชุดุงุฑุงุช ููุฑูุฒ ููุฑ ููุชุดุฑุด ฺฉุฑุฏู\n",
            "ููุดู ฺฏูุช ฺฉู ุฎูุงูุฏูุด ููุช ุชูู ฺฉุฑุฏูู ...ฺฉุงููุง ุณุฑฺฏุฑู ฺฉููุฏู ุงุณ...ูุณุจุช ุจู ุฌูุฏ ุงูู ูู ฺูุฏุงู ุงูุช ฺฉูุช ูุฏุงุดุช ูู ูุดู ฺฏูุช ุชุง ุญุฏูุฏ ฺฏุฌ ฺฉููุฏู ุจูุฏ ู ูุดุฏ ฺฉู ุงูุทูุฑ ูุจุงุดู ...ุฌูุฏ ุณูู ุฑู ุงุฒ ฺฉุฌุง ุชูู ฺฉูู ุ ุทุงูฺู ฺฉู ูุฏุงุฑู ...ุงุตูุง ูู ูพูุงู ุชุฑุฌูู ุดุฏู ุ!\n",
            "ููุดู ฺฏูุช ฺฉู ุฎูุงูุฏูุด ููุช ุชูู ฺฉุฑุฏูู ...ฺฉุงููุง ุณุฑฺฏุฑู ฺฉููุฏู ุงุณ...ูุณุจุช ุจู ุฌูุฏ ุงูู ูู ฺูุฏุงู ุงูุช ฺฉูุช ูุฏุงุดุช ูู ูุดู ฺฏูุช ุชุง ุญุฏูุฏ ฺฏุฌ ฺฉููุฏู ุจูุฏ ู ูุดุฏ ฺฉู ุงูุทูุฑ ูุจุงุดู ...ุฌูุฏ ุณูู ุฑู ุงุฒ ฺฉุฌุง ุชูู ฺฉูู ุ ุทุงูฺู ฺฉู ูุฏุงุฑู ...ุงุตูุง ูู ูพูุงู ุชุฑุฌูู ุดุฏู ุ!\n",
            "ุจุง ูุญุฏ ููุงููู.....ุฌูุฏ ฺฉุด ูู ุชุฑ ุจูุฏ....ุงูุง ุจุง ุงู ุญุงู ุงุฑุฒุด ุฎููุฏู ุฑู. ุฏุงุฑู...๐\n",
            "ุจุง ูุญุฏ ููุงููู.....ุฌูุฏ ฺฉุด ูู ุชุฑ ุจูุฏ....ุงูุง ุจุง ุงู ุญุงู ุงุฑุฒุด ุฎููุฏู ุฑู. ุฏุงุฑู...\n",
            "ุฑุงุณุชุด ุจ ูุธุฑู ูุณุจุช ุจ ุฌูุฏ ูุจู ุจ ุทูุฑ ุขุดฺฉุงุฑ ูุงูููุฏ ุชุฑ ุดุฏูุ ู ุจุนุถ ุฌุงูุงุด ุฎู ุขุจฺฉ ูุ ุงูุง ุฏุฑ ูุฌููุน ูููุฒ ุงุฑุฒุด ุฎููุฏู ุฑู ุฏุงุฑูุ ุฌุงูุจู ฺฉ ุงุตููุง ุฏุฑ ุงฺฉุซุฑ ุชุฑูููฺ ูุง ูุณูุช ุฏูู ุงุฒ ุงูู ุถุนู ุชุฑ ูุดู ุญุงูุง ุจุงุฏ ุจุจูู ุฌูุฏ ุณูู ุด ุฏุฑ ฺ ุญุฏู :-D\n",
            "ุฑุงุณุชุด ุจ ูุธุฑู ูุณุจุช ุจ ุฌูุฏ ูุจู ุจ ุทูุฑ ุขุดฺฉุงุฑ ูุงูููุฏ ุชุฑ ุดุฏูุ ู ุจุนุถ ุฌุงูุงุด ุฎู ุขุจฺฉ ูุ ุงูุง ุฏุฑ ูุฌููุน ูููุฒ ุงุฑุฒุด ุฎููุฏู ุฑู ุฏุงุฑูุ ุฌุงูุจู ฺฉ ุงุตููุง ุฏุฑ ุงฺฉุซุฑ ุชุฑูููฺ ูุง ูุณูุช ุฏูู ุงุฒ ุงูู ุถุนู ุชุฑ ูุดู ุญุงูุง ุจุงุฏ ุจุจูู ุฌูุฏ ุณูู ุด ุฏุฑ ฺ ุญุฏู :-D\n",
            "ุงู ฺฉุชุงุจ ููู ุงูุนุงุฏู ุจูุฏ.\n",
            "ุงู ฺฉุชุงุจ ููู ุงูุนุงุฏู ุจูุฏ.\n",
            "ุนุงูู ุงฺฏู ู ุดู ฺฉุชุงุจ ูุง ุจุฑุชุฑ ู ุฌุฏุฏ ุฏูุง ุฑู ุจุฒุงุฑ ูุซู ูุบูู ุฎ ู ุขุชุด ุง ฺฉุชุงุจ ูุง ุฏฺฏู ุง ฺฉู ุจุฑูุฏู ุฌุงุฒู ุดุฏู ููููู\n",
            "ุนุงูู ุงฺฏู ู ุดู ฺฉุชุงุจ ูุง ุจุฑุชุฑ ู ุฌุฏุฏ ุฏูุง ุฑู ุจุฒุงุฑ ูุซู ูุบูู ุฎ ู ุขุชุด ุง ฺฉุชุงุจ ูุง ุฏฺฏู ุง ฺฉู ุจุฑูุฏู ุฌุงุฒู ุดุฏู ููููู\n",
            "ุฎู ูพุงุงู ุจุฏ ุฏุงุดุช ุจูุธุฑู ููุณูุฏู ูุชููุณุช ู ูพุงุงู ุฎู ูุดูฺฏุชุฑ ุจุฑุงุด ุจููุณู ุจุนุฏ ุงุฒ ุฎููุฏู ณุฌูุฏ ฺฉุชุงุจ ูู ฺฉูุง ูพูฺฉุฑ ูุด๐๐\n",
            "ุฎู ูพุงุงู ุจุฏ ุฏุงุดุช ุจูุธุฑู ููุณูุฏู ูุชููุณุช ู ูพุงุงู ุฎู ูุดูฺฏุชุฑ ุจุฑุงุด ุจููุณู ุจุนุฏ ุงุฒ ุฎููุฏู ณุฌูุฏ ฺฉุชุงุจ ูู ฺฉูุง ูพูฺฉุฑ ูุด\n",
            "ูุดูฺฏ ุจูุฏุ ุนู ุจู ฺฉุจุงุฑ ุฎููุฏูุด ู ุงุฑุฒุฏ ุ ูุฑ ฺูุฏ ูุณุทุงุด ุฎู ุฎุณุชู ฺฉููุฏู ูุดุฏ ู ูพุงุงูุด ูู ุฎู ุชูุฎ ุจูุฏุ ุญุณ ูฺฉูู ูููุด ุจุงุฏ ูุดูฺฏ ุชุฑ ุจุงุดู\n",
            "ูุดูฺฏ ุจูุฏุ ุนู ุจู ฺฉุจุงุฑ ุฎููุฏูุด ู ุงุฑุฒุฏ ุ ูุฑ ฺูุฏ ูุณุทุงุด ุฎู ุฎุณุชู ฺฉููุฏู ูุดุฏ ู ูพุงุงูุด ูู ุฎู ุชูุฎ ุจูุฏุ ุญุณ ูฺฉูู ูููุด ุจุงุฏ ูุดูฺฏ ุชุฑ ุจุงุดู\n",
            "ุงุฎููู ฺุฑุง ุงููุฏ ูพุงุงูุด ุจุฏ ุจูุฏ\n",
            "ุงุฎููู ฺุฑุง ุงููุฏ ูพุงุงูุด ุจุฏ ุจูุฏ\n",
            "ุงู ฺฉุชุงุจ ูุง ุณู ฺฏุงูู ุฑู ูุฎููุฏู ูููุด ุฏุฏู ฺฉู ุฎู ุฎู ูุดูฺฏ ุจูุฏ ูุฎุตูุตุง ูุณูุช ุณููุด ฺฉู ุงุฒ ฺฉ ู ุฏู ูุดูฺฏ ุชุฑ ุจูุฏ ุฏุฑ ฺฉู ูุจูุบ ููุณูุฏู ูุฑุงุชุฑ ุงุฒ ููู ุงูุนุงุฏู ุจูุฏ.\n",
            "ุงู ฺฉุชุงุจ ูุง ุณู ฺฏุงูู ุฑู ูุฎููุฏู ูููุด ุฏุฏู ฺฉู ุฎู ุฎู ูุดูฺฏ ุจูุฏ ูุฎุตูุตุง ูุณูุช ุณููุด ฺฉู ุงุฒ ฺฉ ู ุฏู ูุดูฺฏ ุชุฑ ุจูุฏ ุฏุฑ ฺฉู ูุจูุบ ููุณูุฏู ูุฑุงุชุฑ ุงุฒ ููู ุงูุนุงุฏู ุจูุฏ.\n",
            "ู ุจูุงุฎุฑู ูพุงุงู ุงู ุณู ฺฏุงูู๐\n",
            "ุฌูุฏ ุณูู ูุฑุงุฒ ู ูุดุจ ู ูุฌุงู ุฏุงุฑู ุุงูุง ฺฉุดุด ฺฉู ุฏุงุฑู ูุญุช ฺูุฏุชุง ูุตูู ูุฎููุฏู ุชุง ุฒูุฏุชุฑ ุจู ูพุงุงูุด ุจุฑุณู !\n",
            "ูพุงุงู ุชูุฎ ุฏุงุฑู ุุงูุง ุฏุฑ ูุฌููุน ุงู ุณู ฺฉุชุงุจ ูุชููู ุงููุฒูุฏู ูู ุจุงุดูโ\n",
            "ู ุจูุงุฎุฑู ูพุงุงู ุงู ุณู ฺฏุงูู\n",
            "ุฌูุฏ ุณูู ูุฑุงุฒ ู ูุดุจ ู ูุฌุงู ุฏุงุฑู ุุงูุง ฺฉุดุด ฺฉู ุฏุงุฑู ูุญุช ฺูุฏุชุง ูุตูู ูุฎููุฏู ุชุง ุฒูุฏุชุฑ ุจู ูพุงุงูุด ุจุฑุณู !\n",
            "ูพุงุงู ุชูุฎ ุฏุงุฑู ุุงูุง ุฏุฑ ูุฌููุน ุงู ุณู ฺฉุชุงุจ ูุชููู ุงููุฒูุฏู ูู ุจุงุดู\n",
            "ุชู ุณู ุฑูุฒ ุงู ุณู ฺฏุงูู ุฑู ุฎููุฏู.ุงูุฑูุฒ ุฑูุฒ ุณููู ู ูู ุงูููุฏุฑ ุดูฺฉู ุดุฏู ฺฉู ููุฏููู ูุจูุบ ููุณูุฏู ุฑู ุชุญุณู ฺฉูู ุง ูุญุดุด ุจุฏู.ุฌุฒู ูุงูุชุฒ ูุงู ฺฉู ุจู ุขุฏู ุฏุฑุณ ุฒูุฏฺฏ ูุฏู\n",
            "ุชู ุณู ุฑูุฒ ุงู ุณู ฺฏุงูู ุฑู ุฎููุฏู.ุงูุฑูุฒ ุฑูุฒ ุณููู ู ูู ุงูููุฏุฑ ุดูฺฉู ุดุฏู ฺฉู ููุฏููู ูุจูุบ ููุณูุฏู ุฑู ุชุญุณู ฺฉูู ุง ูุญุดุด ุจุฏู.ุฌุฒู ูุงูุชุฒ ูุงู ฺฉู ุจู ุขุฏู ุฏุฑุณ ุฒูุฏฺฏ ูุฏู\n",
            "ุงุฎุฑ ุงู ฺฉุชุงุจ ฺ ุดุฏ ูฺฏูุ\n",
            "ุงุฎู ูู ูููุด ุฑู ุฏุฏู ูพุงุงู ุฎุงุต ูุฏุงุดุช\n",
            "ุงุฎุฑ ุงู ฺฉุชุงุจ ฺ ุดุฏ ูฺฏูุ\n",
            "ุงุฎู ูู ูููุด ุฑู ุฏุฏู ูพุงุงู ุฎุงุต ูุฏุงุดุช\n",
            "ูุฑ ุณู ฺฉุชุงุจ ุนุงู ุจูุฏู ูู ูพุงุงูุด ุฎู ุดูฺฉู ฺฉููุฏู ฺฉููุฏู ุจูุฏ ฺูุฏ ุฑูุฒ ูุงุฒูู ฺฉู ูพุงุงู ุฏุงุณุชุงู ุฑู ูุถู ฺฉูู\n",
            "ูุฑ ุณู ฺฉุชุงุจ ุนุงู ุจูุฏู ูู ูพุงุงูุด ุฎู ุดูฺฉู ฺฉููุฏู ฺฉููุฏู ุจูุฏ ฺูุฏ ุฑูุฒ ูุงุฒูู ฺฉู ูพุงุงู ุฏุงุณุชุงู ุฑู ูุถู ฺฉูู\n",
            "ุนุงู ุจูุฏ ูุงุณู ููู ุชูุตู ูฺฉูู\n",
            "ุนุงู ุจูุฏ ูุงุณู ููู ุชูุตู ูฺฉูู\n",
            "ฺฉ ุงุฒ ุจูุชุฑู ฺฉุชุงุจุง ุนูุฑู ุจูุฏ\n",
            "ุจู ูุธุฑู ููุณูุฏู ุงุฒ ุฏุฏ ูุงูุนุง ุฌุงูุจ ุจู ุฒูุฏฺฏ ู ุงูุณุงู ูุง ูฺฏุงู ฺฉุฑุฏู ุจูุฏ\n",
            "ูุฑ ฺฉุฏูู ุงุฒ ุดุฎุตุช ูุง ููุงุฏ ุงุฒ ุงูุณุงู ูุง ุงุทุฑุงูููู ุจูุฏู\n",
            "ูู ุฎูุฏู ูุงูุนุง ุฏุฏ ููุณู ูุณุจุช ุจู ููู ฺุฒ ุจุฑุง ููู ุงู ฺฉุชุงุจ ุจุฑุง ูู ูพูุฌุฑู ุง ุจู ฺฉ ุฏูุง ุฌุฏุฏ ุจูุฏ ฺฉู ูฺ ููุช ุชุง ุงู ุญุฏ ุจูุด ุฏูุช ูฺฉุฑุฏู ุจูุฏู\n",
            "ูพุงุงู ฺฉุชุงุจ... ุฎู ุฒุจุง ุงูุง ุดูฺฉู ุงูุฑ ุจูุฏ\n",
            "ูู ุฎูุฏู ฺฉ ููุชู ุทูู ฺฉุดุฏ ุชุง ุจู ุญุงูุช ูุฑูุงู ุจุฑฺฏุฑุฏู ุงูุง ุจุงุฒู ุงุฑุฒุด ุฎููุฏู ุฑู ุฏุงุดุช ุทูุฑ ฺฉู ูุฎูุงู ุจุงุฒู ุงู ฺฉุชุงุจู ุจุงุฑ ูุง ู ุจุงุฑ ุจุฎููู\n",
            "ู ุฑุงุณุช ูุดู ูุทูุง ุฌูุฏ ฺูุงุฑูุด ุฑู ูู ุจุฐุงุฑุฏ ูุณุจุช ุจูุด ุงุญุณุงุณ ูุงุฒ ุฏุงุฑู\n",
            "ููููู\n",
            "ฺฉ ุงุฒ ุจูุชุฑู ฺฉุชุงุจุง ุนูุฑู ุจูุฏ\n",
            "ุจู ูุธุฑู ููุณูุฏู ุงุฒ ุฏุฏ ูุงูุนุง ุฌุงูุจ ุจู ุฒูุฏฺฏ ู ุงูุณุงู ูุง ูฺฏุงู ฺฉุฑุฏู ุจูุฏ\n",
            "ูุฑ ฺฉุฏูู ุงุฒ ุดุฎุตุช ูุง ููุงุฏ ุงุฒ ุงูุณุงู ูุง ุงุทุฑุงูููู ุจูุฏู\n",
            "ูู ุฎูุฏู ูุงูุนุง ุฏุฏ ููุณู ูุณุจุช ุจู ููู ฺุฒ ุจุฑุง ููู ุงู ฺฉุชุงุจ ุจุฑุง ูู ูพูุฌุฑู ุง ุจู ฺฉ ุฏูุง ุฌุฏุฏ ุจูุฏ ฺฉู ูฺ ููุช ุชุง ุงู ุญุฏ ุจูุด ุฏูุช ูฺฉุฑุฏู ุจูุฏู\n",
            "ูพุงุงู ฺฉุชุงุจ... ุฎู ุฒุจุง ุงูุง ุดูฺฉู ุงูุฑ ุจูุฏ\n",
            "ูู ุฎูุฏู ฺฉ ููุชู ุทูู ฺฉุดุฏ ุชุง ุจู ุญุงูุช ูุฑูุงู ุจุฑฺฏุฑุฏู ุงูุง ุจุงุฒู ุงุฑุฒุด ุฎููุฏู ุฑู ุฏุงุดุช ุทูุฑ ฺฉู ูุฎูุงู ุจุงุฒู ุงู ฺฉุชุงุจู ุจุงุฑ ูุง ู ุจุงุฑ ุจุฎููู\n",
            "ู ุฑุงุณุช ูุดู ูุทูุง ุฌูุฏ ฺูุงุฑูุด ุฑู ูู ุจุฐุงุฑุฏ ูุณุจุช ุจูุด ุงุญุณุงุณ ูุงุฒ ุฏุงุฑู\n",
            "ููููู\n",
            "ู ฺฉุชุงุจ ุฏฺฏู ุงู ูุณุช ฺฉู ูุดู ฺูุงุฑูู ฺฉุชุงุจ ุงุณูุด four ุงุฒ ุฒุจุงู ุชูุจุงุณ ฺฏูุชู ูุดู ูุฏุฑ ุจุงุฑู ุงููู ูู ุฏููู ฺุฑุง ุจุนุฏ ุงุฒ ุญุฏูุฏ ูค ุณุงู ูููุฒ ฺฉุณฺฉ ุชุฑุฌูู ุงุด ูฺฉุฑุฏู\n",
            "ุฎูุงููู ุชูุจุงุณู ุฏูุณุช ุฏุงุฑู ู ู ุฎูุงู ุฏุฑุจุงุฑู ุงุด ุจุดุชุฑ ุจุฏููู\n",
            "ู ฺฉุชุงุจ ุฏฺฏู ุงู ูุณุช ฺฉู ูุดู ฺูุงุฑูู ฺฉุชุงุจ ุงุณูุด four ุงุฒ ุฒุจุงู ุชูุจุงุณ ฺฏูุชู ูุดู ูุฏุฑ ุจุงุฑู ุงููู ูู ุฏููู ฺุฑุง ุจุนุฏ ุงุฒ ุญุฏูุฏ ูค ุณุงู ูููุฒ ฺฉุณฺฉ ุชุฑุฌูู ุงุด ูฺฉุฑุฏู\n",
            "ุฎูุงููู ุชูุจุงุณู ุฏูุณุช ุฏุงุฑู ู ู ุฎูุงู ุฏุฑุจุงุฑู ุงุด ุจุดุชุฑ ุจุฏููู\n",
            "ุนุงูู ุงู ฺฉุชุงุจ\n",
            "ุนุงูู ุงู ฺฉุชุงุจ\n",
            "ุนุงู ุจูุฏ ... ูพุงุงู ููุณ ูุฏุงุดุช ... ูุงูุชุฒ ุฌุฏุฏ ู ุฌุฐุงุจ ุจูุฏ\n",
            "ุนุงู ุจูุฏ ... ูพุงุงู ููุณ ูุฏุงุดุช ... ูุงูุชุฒ ุฌุฏุฏ ู ุฌุฐุงุจ ุจูุฏ\n",
            "ฺุทูุฑ ูุชููู ุฌุง ุบุฑ ุงุฒ ุทุงูฺู ุจุงุฒ ฺฉูู ฺฉุชุงุจูุ ุนู ฺุทูุฑ ุงูุชูุงู ุจุฏู ุฎุงุฑุฌ ุงุฒ ุทุงูฺู\n",
            "ฺุทูุฑ ูุชููู ุฌุง ุบุฑ ุงุฒ ุทุงูฺู ุจุงุฒ ฺฉูู ฺฉุชุงุจูุ ุนู ฺุทูุฑ ุงูุชูุงู ุจุฏู ุฎุงุฑุฌ ุงุฒ ุทุงูฺู\n",
            "ุฌูุฏ ฺูุงุฑู ุงู ฺฉุชุงุจ ุชุฑุฌูู ุดุฏูุ \n",
            "ุงฺฏุฑ ุฌูุฏ ฺูุงุฑูู ุฏุงุฑู ุ ูุทูุง ุจุฒุงุฑู\n",
            "ุฌูุฏ ฺูุงุฑู ุงู ฺฉุชุงุจ ุชุฑุฌูู ุดุฏูุ \n",
            "ุงฺฏุฑ ุฌูุฏ ฺูุงุฑูู ุฏุงุฑู ุ ูุทูุง ุจุฒุงุฑู\n",
            "ููู ุงูุนุงุฏุณ ุงู ฺฉุชุงุจ ูู ูพุงุงูุด ุฎู ุจุฑุง ูู ุฏูฺุณุจ ูุจูุฏ ุูุงูุนุง ุดูฺฉู ุดุฏู...\n",
            "ููู ุงูุนุงุฏุณ ุงู ฺฉุชุงุจ ูู ูพุงุงูุด ุฎู ุจุฑุง ูู ุฏูฺุณุจ ูุจูุฏ ุูุงูุนุง ุดูฺฉู ุดุฏู...\n",
            "ฺฉุชุงุจ ุจุณุงุฑ ุฌุฐุงุจ ุจูุฏ ุจุง ุชุฑุฌูู ุจุณุงุฑ ุฑูุงู...\n",
            "ฺฉุชุงุจ ุจุณุงุฑ ุฌุฐุงุจ ุจูุฏ ุจุง ุชุฑุฌูู ุจุณุงุฑ ุฑูุงู...\n",
            "ุนุงู ุนุงู ุนุงู ๐๐๐ุงุฒ ุงูฺฉู ูพุงุงู ููุณ ูุฏุงุดุช ูุฐุช ุจุฑุฏู.\n",
            "ุนุงู ุนุงู ุนุงู ุงุฒ ุงูฺฉู ูพุงุงู ููุณ ูุฏุงุดุช ูุฐุช ุจุฑุฏู.\n",
            "ุจุณุงุฑ ูุฐุช ุจุฑุฏู. ุฎููุฏูุด ุฑู ุญุชูุง ุญุชูุง ุชูุตู ูฺฉูู.\n",
            "ุจุณุงุฑ ูุฐุช ุจุฑุฏู. ุฎููุฏูุด ุฑู ุญุชูุง ุญุชูุง ุชูุตู ูฺฉูู.\n",
            "ุฎู ุนุงู ุจูุฏ ุ ุงูุจุชู ูุณูุช ุงูู ุงุฒ ููู ุจูุชุฑ ุจูุฏ...\n",
            "ูพุงุงูุด ูู ุดูฺฉ ุดุฏู...\n",
            "ุฎู ุนุงู ุจูุฏ ุ ุงูุจุชู ูุณูุช ุงูู ุงุฒ ููู ุจูุชุฑ ุจูุฏ...\n",
            "ูพุงุงูุด ูู ุดูฺฉ ุดุฏู...\n",
            "ุจ ูุธุฑู ููุณูุฏู ุฏุฑ ุณู ุชุง ฺฉุชุงุจ ุณุฑ ูุฒูู ุฑุง ุท ฺฉุฑุฏูุ ูุตู ุงู ฺฉุชุงุจ ุฒุงุฏ ุจูุฏ ู ูุชููุณุช ุญุฐู ุดูุ ฺฉู ุณู ฺฉุชุงุจ ุฑุง ุจุงุฏ ุฏุฑ ููุงู ุงูู ุฎูุงุตู ูฺฉุฑุฏ.\n",
            "ุจ ูุธุฑู ููุณูุฏู ุฏุฑ ุณู ุชุง ฺฉุชุงุจ ุณุฑ ูุฒูู ุฑุง ุท ฺฉุฑุฏูุ ูุตู ุงู ฺฉุชุงุจ ุฒุงุฏ ุจูุฏ ู ูุชููุณุช ุญุฐู ุดูุ ฺฉู ุณู ฺฉุชุงุจ ุฑุง ุจุงุฏ ุฏุฑ ููุงู ุงูู ุฎูุงุตู ูฺฉุฑุฏ.\n",
            "ฺ ุจฺฏู ุ ... ุชุตูุฑุงุช ูุจู ุงู ุฑู ุจูู ุฑุฎุช ... ุจูุชุฑ ุจูุฏ ุงู ุฌูุฏ ุฑู ูู ุฎููุฏู ...ุงูุงู ุฏููุง ุญุณ ฺฉุณ ุฑู ุฏุงุฑู ฺฉู ูุฑุจ ุฏุงุฏู ุดุฏู !..\n",
            "ฺ ุจฺฏู ุ ... ุชุตูุฑุงุช ูุจู ุงู ุฑู ุจูู ุฑุฎุช ... ุจูุชุฑ ุจูุฏ ุงู ุฌูุฏ ุฑู ูู ุฎููุฏู ...ุงูุงู ุฏููุง ุญุณ ฺฉุณ ุฑู ุฏุงุฑู ฺฉู ูุฑุจ ุฏุงุฏู ุดุฏู !..\n",
            "ุนุงู ุจูุฏ ๐๐๐๐๐\n",
            "ุนุงู ุจูุฏ \n",
            "ุนุงูู ูุทูุง ฺฉุชุงุจ ูุง ุฏฺฏุฑ ฺฉู ุชุฑุฌูู ุง ูุณุช ู ุจุฑุง ุฑูุฌ ุฌูุงู ู ููุฌูุงู ุงุณุช ุฑู ุจุดุชุฑ ุจุฒุงุฑุฏ\n",
            "ุนุงูู ูุทูุง ฺฉุชุงุจ ูุง ุฏฺฏุฑ ฺฉู ุชุฑุฌูู ุง ูุณุช ู ุจุฑุง ุฑูุฌ ุฌูุงู ู ููุฌูุงู ุงุณุช ุฑู ุจุดุชุฑ ุจุฒุงุฑุฏ\n",
            "ุจูุธุฑ\n",
            "ุจูุธุฑ\n",
            "ฺฉุชุงุจ ฺฉู ุนููู ูุจุงุฏ ุงููุฏ ุงุฑุงู ุงุฏุจ ู ุชูุตู ู ุงูุง ุฏุงุดุชู ุจุงุดู๐๐๐๐\n",
            "ุงุตู ุฏูู ูููุฏ ุงุฏุงูุด ุจุฏู\n",
            "ูุทุงูุจ ุชฺฉุฑุงุฑ ู ุจูุธุฑู ูพุด ูพุง ุงูุชุงุฏู!\n",
            "ุจุนููุงู  ฺฉุชุงุจ ุงูฺฏุฒุด ุจุฏฺฉ ูุณ! ูู ุงูููุฏุฑุง ูู ุฎูุจ ูุณ!\n",
            "ุงูุจุชู ุงุฒ ุญู ูฺฏุฐุฑู ุณุฑูุตูุง ุฌุงูุจ ุฏุงุดุช ู ฺุฒุง ุฎูุจ ุฑู ุจุฑุง ุจุฑุฑุณ ฺฉุฑุฏู ุฏุฑ ูุธุฑ ฺฏุฑูุชู ุจูุฏ ุงูุง ุฎู ุจูุดูู ููพุฑุฏุงุฎุช ู ุฒูุฏ ุงุฒ ุฑูุดูู ุฑุฏ ุดุฏ ู ฺฉุงุฑุจุฑุฏ ูุจูุฏ ู ุงูฺฏุงุฑ ุงูุดุง ููุดุชู ุจุง ููุถูุน ููุงู!!!\n",
            "ู ุชู ุงูุดุง ุจุฑุง ุฎูุดฺฏู ุดุฏู ุจุงุฏ  ฺฉู ุงุทูุงุนุงุช ุฑู ุชู  ุณุฑ ุฌููุงุช ูุดูฺฏ ูุดูฺฏ ฺฉูุงุฑ ูู ุจฺู ุชุง ููุฑู ุจฺฏุฑ ๐\n",
            "ฺฉุชุงุจ ฺฉู ุนููู ูุจุงุฏ ุงููุฏ ุงุฑุงู ุงุฏุจ ู ุชูุตู ู ุงูุง ุฏุงุดุชู ุจุงุดู\n",
            "ุงุตู ุฏูู ูููุฏ ุงุฏุงูุด ุจุฏู\n",
            "ูุทุงูุจ ุชฺฉุฑุงุฑ ู ุจูุธุฑู ูพุด ูพุง ุงูุชุงุฏู!\n",
            "ุจุนููุงู  ฺฉุชุงุจ ุงูฺฏุฒุด ุจุฏฺฉ ูุณ! ูู ุงูููุฏุฑุง ูู ุฎูุจ ูุณ!\n",
            "ุงูุจุชู ุงุฒ ุญู ูฺฏุฐุฑู ุณุฑูุตูุง ุฌุงูุจ ุฏุงุดุช ู ฺุฒุง ุฎูุจ ุฑู ุจุฑุง ุจุฑุฑุณ ฺฉุฑุฏู ุฏุฑ ูุธุฑ ฺฏุฑูุชู ุจูุฏ ุงูุง ุฎู ุจูุดูู ููพุฑุฏุงุฎุช ู ุฒูุฏ ุงุฒ ุฑูุดูู ุฑุฏ ุดุฏ ู ฺฉุงุฑุจุฑุฏ ูุจูุฏ ู ุงูฺฏุงุฑ ุงูุดุง ููุดุชู ุจุง ููุถูุน ููุงู!!!\n",
            "ู ุชู ุงูุดุง ุจุฑุง ุฎูุดฺฏู ุดุฏู ุจุงุฏ  ฺฉู ุงุทูุงุนุงุช ุฑู ุชู  ุณุฑ ุฌููุงุช ูุดูฺฏ ูุดูฺฏ ฺฉูุงุฑ ูู ุจฺู ุชุง ููุฑู ุจฺฏุฑ \n",
            "ฺฉ ุงุฒ ูุงูุนุง ุถุนู ุชุฑู ฺฉุชุงุจ ูุง ฺฉู ุฎููุฏูุุงุตูุง ฺฉุชุงุจ ููุดุฏ ฺฏูุชุูุตุญุช ุจูุฏุููุท ุฌููุงุช ูุนููู ู ูุซุจุช ููุดุชู ุดุฏูุ ู ุฑุงุฌุจ ฺฉ ุฌููู ฺฉู ุชูุถุญ ุฏุงุฏูุฺฉ ุณุชุงุฑู ุจู ุงุฌุจุงุฑ ูุฏูุุจู ูุธุฑู ุงุฑุฒุด ฺฉ ุจุงุฑ ุฎููุฏู ุฑู ุจุง ุชุฑุฏุฏ ูุดู ุจูุด ุฏุงุฏุ\n",
            "ฺฉ ุงุฒ ูุงูุนุง ุถุนู ุชุฑู ฺฉุชุงุจ ูุง ฺฉู ุฎููุฏูุุงุตูุง ฺฉุชุงุจ ููุดุฏ ฺฏูุชุูุตุญุช ุจูุฏุููุท ุฌููุงุช ูุนููู ู ูุซุจุช ููุดุชู ุดุฏูุ ู ุฑุงุฌุจ ฺฉ ุฌููู ฺฉู ุชูุถุญ ุฏุงุฏูุฺฉ ุณุชุงุฑู ุจู ุงุฌุจุงุฑ ูุฏูุุจู ูุธุฑู ุงุฑุฒุด ฺฉ ุจุงุฑ ุฎููุฏู ุฑู ุจุง ุชุฑุฏุฏ ูุดู ุจูุด ุฏุงุฏุ\n",
            "ุจุณุงุฑ ุนุงู๐๐\n",
            "ุจุณุงุฑ ุนุงู\n",
            "ุฎู ุฎูุจู ุงฺฏู ฺฉุณ ูุฎูุงุฏ ุชุบุฑ ฺฉูู ุจูุด ุงฺฏุงู ูุฏู ู ู ุฌูุฑุง ูุญุฑฺฉุดู...ูููู ุจุงุดุฏ ุนุฒุฒุงู\n",
            "ุฎู ุฎูุจู ุงฺฏู ฺฉุณ ูุฎูุงุฏ ุชุบุฑ ฺฉูู ุจูุด ุงฺฏุงู ูุฏู ู ู ุฌูุฑุง ูุญุฑฺฉุดู...ูููู ุจุงุดุฏ ุนุฒุฒุงู\n",
            "\"ฺฉุฌุงูู\"ุฑูุงุช ุงุฒ ุณุฎุช ูุง ู ุฑูุฌ ูุง ู ูุงูุนุช ุฒูุฏฺฏ ุชุฑฺฉูู ูุงุณุช.ุงุฒ ฺูุงุฑ ุฏุงุณุชุงู ุชุดฺฉู ุดุฏู ุงุณุช; ุจุง ููุงู ูุซุฑ ุฑูุงู ู ูุทู ู ุจุง ููุงู ูฺฉุชู ุณูุฌ ูุง  ูุฎุตูุตู\"ูุณู ููุฌู\".\n",
            "ุงูุง...ุฑุชู ฺฉูุฏ ู ฺฉููุงุฎุช ุฏุงุณุชุงููุง ุญูุตูู ุฑุง ุณุฑ ูุจุฑุฏ.ูุจู ุชุฑ ฺฉุชุงุจู ุฏฺฏุฑ ุงุฒ ุงู ููุณูุฏู ุฎูุงูุฏู ุจูุฏู ุจู ูุงู \"ูุงูู\";ู ูููุน ุฎูุงูุฏู ฺฉุฌุงูู ุงูฺฏุงุฑ ุฏุงุดุชู ุฏูุจุงุฑู ูุงูู ูุฎูุงูุฏู,ุงุฒ ูุธุฑ ูู ุบุฑ ุงุฒ ุฏุงุณุชุงู ูพุงุงู ุจูู ฺฉุชุงุจ ูฺ ุญุฑู ุฌุฏุฏ ุจุฑุง ฺฏูุชู ูุฏุงุดุช;ูุญุชูุง ุชฺฉุฑุงุฑ!\n",
            "ยคยคยค\n",
            "ุฏู ุณุชุงุฑู;ููุท ุจู ุฎุงุทุฑ ูพุงุงู ุจูุฏู ุฏุงุณุชุงูู ุขุฎุฑ,ฺฉู ุจุฑุง ูู ุจุณุงุฑ ุฏู ูุดู ุจูุฏ.\n",
            "\"ฺฉุฌุงูู\"ุฑูุงุช ุงุฒ ุณุฎุช ูุง ู ุฑูุฌ ูุง ู ูุงูุนุช ุฒูุฏฺฏ ุชุฑฺฉูู ูุงุณุช.ุงุฒ ฺูุงุฑ ุฏุงุณุชุงู ุชุดฺฉู ุดุฏู ุงุณุช; ุจุง ููุงู ูุซุฑ ุฑูุงู ู ูุทู ู ุจุง ููุงู ูฺฉุชู ุณูุฌ ูุง  ูุฎุตูุตู\"ูุณู ููุฌู\".\n",
            "ุงูุง...ุฑุชู ฺฉูุฏ ู ฺฉููุงุฎุช ุฏุงุณุชุงููุง ุญูุตูู ุฑุง ุณุฑ ูุจุฑุฏ.ูุจู ุชุฑ ฺฉุชุงุจู ุฏฺฏุฑ ุงุฒ ุงู ููุณูุฏู ุฎูุงูุฏู ุจูุฏู ุจู ูุงู \"ูุงูู\";ู ูููุน ุฎูุงูุฏู ฺฉุฌุงูู ุงูฺฏุงุฑ ุฏุงุดุชู ุฏูุจุงุฑู ูุงูู ูุฎูุงูุฏู,ุงุฒ ูุธุฑ ูู ุบุฑ ุงุฒ ุฏุงุณุชุงู ูพุงุงู ุจูู ฺฉุชุงุจ ูฺ ุญุฑู ุฌุฏุฏ ุจุฑุง ฺฏูุชู ูุฏุงุดุช;ูุญุชูุง ุชฺฉุฑุงุฑ!\n",
            "ยคยคยค\n",
            "ุฏู ุณุชุงุฑู;ููุท ุจู ุฎุงุทุฑ ูพุงุงู ุจูุฏู ุฏุงุณุชุงูู ุขุฎุฑ,ฺฉู ุจุฑุง ูู ุจุณุงุฑ ุฏู ูุดู ุจูุฏ.\n",
            "ุชู ฺฉุชุงุจูุฑูุด ูุง ุงูุชุฑูุช ููุชุด 1900 ุจุฑู ฺฺฉ ฺฉูู.ุงุฒ ุชุงูฺู ุงูุชุธุงุฑ ูุฏุงุดุชู\n",
            "ุชู ฺฉุชุงุจูุฑูุด ูุง ุงูุชุฑูุช ููุชุด 1900 ุจุฑู ฺฺฉ ฺฉูู.ุงุฒ ุชุงูฺู ุงูุชุธุงุฑ ูุฏุงุดุชู\n",
            "ุชูุฑุจุง 5ุ6ุณุงู ูพุด ุฎููุฏูุด ุนุงูู\n",
            "ุงูุจุชู ฺฉุชุงุจ ูู ุชุฑุฌูู ููุฑุฏุงุฏ ูุฑูุฒุจุฎุช ุ ุงูุชุดุงุฑุงุช ุฑุดุฏู...ุชุฑุฌูู ุฑููู ู ุฎูุจ ุฏุงุฑู\n",
            "ุชูุฑุจุง 5ุ6ุณุงู ูพุด ุฎููุฏูุด ุนุงูู\n",
            "ุงูุจุชู ฺฉุชุงุจ ูู ุชุฑุฌูู ููุฑุฏุงุฏ ูุฑูุฒุจุฎุช ุ ุงูุชุดุงุฑุงุช ุฑุดุฏู...ุชุฑุฌูู ุฑููู ู ุฎูุจ ุฏุงุฑู\n",
            "ุฏุฑ ุชูุถุญุงุช ฺฉุชุงุจ ููุดุชู ุดุฏู ฑณถุตูุญู ู ููุช ุฎุฑุฏู ธทุตูุญู ุงูุจุชู ุงู ุจุงุฑ ุฏููู ุนู ฺฉุชุงุจ ูุจู ูู ฺฉู ุฎุฑุฏู ููู ูุถุนุช ุฑู ุฏุงุดุชุุุุ!!!!!\n",
            "ุงู ูุณูู ุฑุง ุฏุฑ ฺฉุชุงุจ ุฑุงู ุ ูุฏุจู ุง ูุฑุง ฺฉุชุงุจ ุง.... ูุฏุงุดุชู\n",
            "ุจู ุฌุง ูฺฏุฑุงู ุฎุฑุฏ ูู ฺฉูู\n",
            "ุฏุฑ ุชูุถุญุงุช ฺฉุชุงุจ ููุดุชู ุดุฏู ฑณถุตูุญู ู ููุช ุฎุฑุฏู ธทุตูุญู ุงูุจุชู ุงู ุจุงุฑ ุฏููู ุนู ฺฉุชุงุจ ูุจู ูู ฺฉู ุฎุฑุฏู ููู ูุถุนุช ุฑู ุฏุงุดุชุุุุ!!!!!\n",
            "ุงู ูุณูู ุฑุง ุฏุฑ ฺฉุชุงุจ ุฑุงู ุ ูุฏุจู ุง ูุฑุง ฺฉุชุงุจ ุง.... ูุฏุงุดุชู\n",
            "ุจู ุฌุง ูฺฏุฑุงู ุฎุฑุฏ ูู ฺฉูู\n",
            "ูุงูุนุง ฺฉุชุงุจ ุฎูุจู. ูู ุชูุตู ุงุด ูฺฉูู. ูฺฉุชู ูุซุจุชุด ุงูู ฺฉู ูุจุงุญุซ ฺฉู ฺฉ ููุณูุฏู ุขูุฑฺฉุง ููุดุชู ุฑู \"ุงุฑุงูุฒู\" ฺฉุฑุฏู. ุนู ุทูุฑ ฺฉู ุจุง ูุฑููฺฏ ุงุฑุงู ูุฎููู ู ุงู ุจู ููู ุจุด ุชุฑ ูุทูุจ ุฎู ฺฉูฺฉ ูฺฉูู. ฺฉุงุด ุงูุฑุงุฏ ุฏฺฏุฑ ูู ุจูุฏู ุชุง ฺฉุชุงุจ ูุง ุฏฺฏู  ุฑูุงูุดูุงุณ ููููุช ุฑู \"ุงุฑุงูุฒู\" ฺฉูู. ฺูู ูุฑููฺฏ ูุง ุฌุงูุนู ูุง ู ุดุฑุงุท ุฒูุฏฺฏ ูุง ุจุง ุงูู ูุง ุฎู ูุชูุงูุชู .\n",
            "ูุงูุนุง ฺฉุชุงุจ ุฎูุจู. ูู ุชูุตู ุงุด ูฺฉูู. ูฺฉุชู ูุซุจุชุด ุงูู ฺฉู ูุจุงุญุซ ฺฉู ฺฉ ููุณูุฏู ุขูุฑฺฉุง ููุดุชู ุฑู \"ุงุฑุงูุฒู\" ฺฉุฑุฏู. ุนู ุทูุฑ ฺฉู ุจุง ูุฑููฺฏ ุงุฑุงู ูุฎููู ู ุงู ุจู ููู ุจุด ุชุฑ ูุทูุจ ุฎู ฺฉูฺฉ ูฺฉูู. ฺฉุงุด ุงูุฑุงุฏ ุฏฺฏุฑ ูู ุจูุฏู ุชุง ฺฉุชุงุจ ูุง ุฏฺฏู  ุฑูุงูุดูุงุณ ููููุช ุฑู \"ุงุฑุงูุฒู\" ฺฉูู. ฺูู ูุฑููฺฏ ูุง ุฌุงูุนู ูุง ู ุดุฑุงุท ุฒูุฏฺฏ ูุง ุจุง ุงูู ูุง ุฎู ูุชูุงูุชู .\n",
            "ุงููุฏุฑ ฺฉุชุงุจุด ุบูุท ุชุงูพ ู ูุฑุงุณุช ุฏุงุฑู ฺฉู ูุณุท ฺฉุงุฑ ุจุฎุงูุด ุดุฏู. ูุฑู ุชู ุงูพ ูุง ุฏฺฏู ูพุฏุงุด ฺฉูู!\n",
            "ุงููุฏุฑ ฺฉุชุงุจุด ุบูุท ุชุงูพ ู ูุฑุงุณุช ุฏุงุฑู ฺฉู ูุณุท ฺฉุงุฑ ุจุฎุงูุด ุดุฏู. ูุฑู ุชู ุงูพ ูุง ุฏฺฏู ูพุฏุงุด ฺฉูู!\n",
            "ุชูุฑุจุง ูููู ฺฉุชุงุจ ููฺฏุฐุงุฑู ฺฉุณ ุงุนุตุงุจู ุฑุง ุจูู ุจุฑุฒุฏ ุจู ูฺฏุงุฑุด ูุงุฑุณ ู ููุงุณุจ ุจุง ูุฑููฺฏ ุงุฑุงู ฺฉู ุงูุจุชู ุฎู ูฺฉุงุช ฺฉุงุฑุจุฑุฏ ุฒุงุฏ ูุฏุงุดุช\n",
            "ุชูุฑุจุง ูููู ฺฉุชุงุจ ููฺฏุฐุงุฑู ฺฉุณ ุงุนุตุงุจู ุฑุง ุจูู ุจุฑุฒุฏ ุจู ูฺฏุงุฑุด ูุงุฑุณ ู ููุงุณุจ ุจุง ูุฑููฺฏ ุงุฑุงู ฺฉู ุงูุจุชู ุฎู ูฺฉุงุช ฺฉุงุฑุจุฑุฏ ุฒุงุฏ ูุฏุงุดุช\n",
            "ู ฺฉุชุงุจ ููุฏ\n",
            "ู ฺฉุชุงุจ ููุฏ\n",
            "ฺฉุชุงุจ ุฎู ุฎูุจู ุ ุงฺฉุซุฑ ูุงุฑุงุญุช ูุง ูุง ุจู ุฎุงุทุฑ ุจุงูุฑูุง ุบุฑููุทููููู ุ ูุซูุง ุงูุชุธุงุฑ ุฏุงุฑู ููู ูุงุฑู ุฏูุณุช ุฏุงุดุชู ุจุงุดูุฏ ู ุชุงุฏ ฺฉููุฏ ูู ุนูู ูฺฏู ฺฉู ฺูู ฺุฒ ููฺฉู ูุณุช.\n",
            "ุนูู ูุนูุช ุฎู ุจุฒุฑฺฏู ูู ุงฺฉุซุฑ ุขุฏููุง ุนุงููุงูู ุฒูุฏฺฏ ูู ฺฉูู ู ุงุณุฑ ุชูุงูุงุชุดูููุ ูุซูุง ุดูุชู ู ููุงู ู ููุตุจ ูุดู ู ุจู ุฎุงุทุฑ ุฑุณุฏู ุจูุด ุญุช ููฺฉูู ุฎูุดุจุฎุช ู ุขุฑุงูุดุดูู ุฑู ูู ูุฏุง ฺฉูู.\n",
            "ฺฉุชุงุจ ุฎู ุฎูุจู ุ ุงฺฉุซุฑ ูุงุฑุงุญุช ูุง ูุง ุจู ุฎุงุทุฑ ุจุงูุฑูุง ุบุฑููุทููููู ุ ูุซูุง ุงูุชุธุงุฑ ุฏุงุฑู ููู ูุงุฑู ุฏูุณุช ุฏุงุดุชู ุจุงุดูุฏ ู ุชุงุฏ ฺฉููุฏ ูู ุนูู ูฺฏู ฺฉู ฺูู ฺุฒ ููฺฉู ูุณุช.\n",
            "ุนูู ูุนูุช ุฎู ุจุฒุฑฺฏู ูู ุงฺฉุซุฑ ุขุฏููุง ุนุงููุงูู ุฒูุฏฺฏ ูู ฺฉูู ู ุงุณุฑ ุชูุงูุงุชุดูููุ ูุซูุง ุดูุชู ู ููุงู ู ููุตุจ ูุดู ู ุจู ุฎุงุทุฑ ุฑุณุฏู ุจูุด ุญุช ููฺฉูู ุฎูุดุจุฎุช ู ุขุฑุงูุดุดูู ุฑู ูู ูุฏุง ฺฉูู.\n",
            "ููู ุงูุนุงุฏูุุจุงุฒููุณ ุดุฏู ุจุฑุง ุฌุงูุนู  ุงุฑุงู.\n",
            "ุงฺฏู ุจุชููุฏ ุจุฎููุฏุดุุญุช ููููู ุฑูุุฎู ุฒุงุฏ ููุฏู ุจุฑุงุชูู.\n",
            "ููู ุงูุนุงุฏูุุจุงุฒููุณ ุดุฏู ุจุฑุง ุฌุงูุนู  ุงุฑุงู.\n",
            "ุงฺฏู ุจุชููุฏ ุจุฎููุฏุดุุญุช ููููู ุฑูุุฎู ุฒุงุฏ ููุฏู ุจุฑุงุชูู.\n",
            "ุงู ฺฉุชุงุจ ุฑุง ุฎูุงูุฑู ฺฉู ุฑูุงูุดูุงุณ ูุณุช ุจูู ูุนุฑู ฺฉุฑุฏู ฺฉุชุงุจ ุฎูุจ ูุณุช ุ ูุทูุฆู ุจุงุดุฏ ุงุฑุฒุด ุฎููุฏู ุฑุง ุฏุงุฑู\n",
            "ุงู ฺฉุชุงุจ ุฑุง ุฎูุงูุฑู ฺฉู ุฑูุงูุดูุงุณ ูุณุช ุจูู ูุนุฑู ฺฉุฑุฏู ฺฉุชุงุจ ุฎูุจ ูุณุช ุ ูุทูุฆู ุจุงุดุฏ ุงุฑุฒุด ุฎููุฏู ุฑุง ุฏุงุฑู\n",
            "ุงู ฺฉุชุงุจ ุฑู ุดุฏุฏุง ุชูุตู ูฺฉูู ุฎุตูุตุง ุงฺฏุฑ ุทุงูุจ ุขุฑุงูุด ุฏุฑ ุฒูุฏฺฏุชูู ูุณุชู ู ุงุทุฑุงูุงูุชูู ุดูุง ุฑู ุฏูฺฏุฑ ูฺฉููุฏ. ููุช ุชููู ูุดู ุขุฏู ูฺฏู ฺฉุงุด ุณุงููุง ูพุด ุฎููุฏู ุจูุฏูุด.\n",
            "ุงู ฺฉุชุงุจ ุฑู ุดุฏุฏุง ุชูุตู ูฺฉูู ุฎุตูุตุง ุงฺฏุฑ ุทุงูุจ ุขุฑุงูุด ุฏุฑ ุฒูุฏฺฏุชูู ูุณุชู ู ุงุทุฑุงูุงูุชูู ุดูุง ุฑู ุฏูฺฏุฑ ูฺฉููุฏ. ููุช ุชููู ูุดู ุขุฏู ูฺฏู ฺฉุงุด ุณุงููุง ูพุด ุฎููุฏู ุจูุฏูุด.\n",
            "ฺฉุชุงุจ ุจุณุงุฑ ฺฉุงุฑุจุฑุฏ ูุจุงุดุฏ.\n",
            "ฺฉุชุงุจ ุจุณุงุฑ ฺฉุงุฑุจุฑุฏ ูุจุงุดุฏ.\n",
            "ุฎููุฏู ุงู ฺฉุชุงุจ ุจุฑุง ููู ุงูุฑุงุฏ ุถุฑูุฑู. ูฺฏุงูุชูู ุฑู ุจู ูุดฺฉูุงุช ุฎุตูุตุง ูุดฺฉูุงุช ุฑุงุจุทู ุง ุนูุถ ู ฺฉูู. ุจุงุฏ ูุง ู ูุจุงุฏูุง ุฑู ุฒุฑ ุณูุงู ู ุจุฑู. ุฎูุงุตู ุจฺฏู ุงฺฏุฑ  ูุงูุนุง ุฏูุจุงู ุขุฑุงูุด ูุณุชู ุงุจู ฺฉ ุงุฒ ฺฉุชุงุจ ูุงู ฺฉู ุญุชูุง ุจุงุฏ ุจุฎููุจู\n",
            "ุฎููุฏู ุงู ฺฉุชุงุจ ุจุฑุง ููู ุงูุฑุงุฏ ุถุฑูุฑู. ูฺฏุงูุชูู ุฑู ุจู ูุดฺฉูุงุช ุฎุตูุตุง ูุดฺฉูุงุช ุฑุงุจุทู ุง ุนูุถ ู ฺฉูู. ุจุงุฏ ูุง ู ูุจุงุฏูุง ุฑู ุฒุฑ ุณูุงู ู ุจุฑู. ุฎูุงุตู ุจฺฏู ุงฺฏุฑ  ูุงูุนุง ุฏูุจุงู ุขุฑุงูุด ูุณุชู ุงุจู ฺฉ ุงุฒ ฺฉุชุงุจ ูุงู ฺฉู ุญุชูุง ุจุงุฏ ุจุฎููุจู\n",
            "ฺฉุชุงุจ ุจุง ุฌุฒุงุช ุฏูู ุจุฑุง ุงุตูุงุญ ุทุฑุฒ ูฺฉุฑ ุจูฺู ุจุง ุจุฑฺฏุฑุฏุงู ุฑุงูู ฺฉุฑู ฺฉู ุงู ุฑูุฒุง ุจู ฺูุฑู ูุนุฑูู ุฑูุงูุดูุงุณ ฺฉุดูุฑ ุชุจุฏู ุดุฏู\n",
            "ฺฉุชุงุจ ุจุง ุฌุฒุงุช ุฏูู ุจุฑุง ุงุตูุงุญ ุทุฑุฒ ูฺฉุฑ ุจูฺู ุจุง ุจุฑฺฏุฑุฏุงู ุฑุงูู ฺฉุฑู ฺฉู ุงู ุฑูุฒุง ุจู ฺูุฑู ูุนุฑูู ุฑูุงูุดูุงุณ ฺฉุดูุฑ ุชุจุฏู ุดุฏู\n",
            "ูุฑ ุทุงูฺู\n",
            "ูุฑ ุทุงูฺู\n",
            "ุงูุฑุนุจุงุณ ููุฏุง ูุฑุฏ ุฏุงูุดููุฏ ุจุง ุชุญุตูุงุช ุนุงูู ู ุงูุณุงู ุฑุงุณุชู ุจูุฏ ฺฉู ุชูุงู ุนูุฑ ุจุฑุง ูพุดุฑูุช ู ุงุฑุชูุง ูููุด ุชูุงุด ฺฉุฑุฏ ู ุฏุฑ ูพุงุงู ูุฒ ูพุณ ุงุฒ ุขูฺฉู ุญุงุถุฑ ูุดุฏ ุงุฒ ฺฉุดูุฑ ุจฺฏุฑุฒุฏ ุจู ุฏุณุช ูุฒุฏูุฑ ุนุงุฑ ุงุฒ ุงูุณุงูุช ุฏุฑ ุฏุงุฏฺฏุงู ูุฑูุงุด ุจู ูุชู ุฑุณุฏ.\n",
            "ุงูุฑุนุจุงุณ ููุฏุง ูุฑุฏ ุฏุงูุดููุฏ ุจุง ุชุญุตูุงุช ุนุงูู ู ุงูุณุงู ุฑุงุณุชู ุจูุฏ ฺฉู ุชูุงู ุนูุฑ ุจุฑุง ูพุดุฑูุช ู ุงุฑุชูุง ูููุด ุชูุงุด ฺฉุฑุฏ ู ุฏุฑ ูพุงุงู ูุฒ ูพุณ ุงุฒ ุขูฺฉู ุญุงุถุฑ ูุดุฏ ุงุฒ ฺฉุดูุฑ ุจฺฏุฑุฒุฏ ุจู ุฏุณุช ูุฒุฏูุฑ ุนุงุฑ ุงุฒ ุงูุณุงูุช ุฏุฑ ุฏุงุฏฺฏุงู ูุฑูุงุด ุจู ูุชู ุฑุณุฏ.\n",
            "ูู ุงูุงู ููุฑ ู ฺูพุงูู ูุณุช ู ูููฺฉุช ฺฏู ู ุจูุจู ุงุณุช\n",
            "ูู ุงูุงู ููุฑ ู ฺูพุงูู ูุณุช ู ูููฺฉุช ฺฏู ู ุจูุจู ุงุณุช\n",
            "ููุฏุง ฺฉ ูุฑุงูุงุณูู ุจูุฏ ู ุฏุฑ ุฏูุฑู ุตุฏุงุฑุช ุงู ุงุฑุงู ุจู ุนุฑุตู ุชุงุฎุช ู ุชุงุฒ ูฺูุง ุฑูฺฏุงุฑูฺฏ ูุฑุงูุงุณููุฑ ุจุฏู ุดุฏ. ูุงู ููุฏุง ุจู ุฏูุฑุงู\" ุซุจุงุช\"ุณูุทูุช ูุญูุฏุฑุถุง ูพููู ฺฏุฑู ุฎูุฑุฏู ุงุณุช ู ุณุงููุง ุตุฏุงุฑุช ุงู ุงูุฌ ูุณุงุฏ ู ุชุจุงู ู ฺฉู ุชุงุฒ ุดุงู ูุญุณูุจ ูุดูุฏ. ุฏุฑ ุฏูุฑุงู ููุฏุงุณุช ฺฉู ูพููุฏูุง ููุงู ู ุนุงู ุฏุฑุจุงุฑ ูพููู ุจุง ูุญุงูู ูุฏุฑุชููุฏ ู ฺูพุงููฺฏุฑ ุบุฑุจ ู ุตูููุณู ุฌูุงู ุจู ูุณุชุญฺฉู ุชุฑู ุดฺฉู ุฎูุฏ ุฑุณุฏ ู ุดุงู ูุบุฑูุฑ ุฏุฑ ุนุฑุตู ุจู ุงูููู ุจูุซุงุจู ฺฉ ุฏฺฉุชุงุชูุฑ ุจููุฏ ูพุฑูุงุฒ ู ุฏุฑ ููุทูู ุจู ุนููุงู ุงุณุชูุงุฑุชุฑู ุฏูุณุช ุบุฑุจ ุธุงูุฑ ุดุฏ.ู ุฏุฑ ฺฉุดูุฑ ฺฉู ููุฑ ู ุชุจุงู ุขู ุฑุง ุจู ฺฉุงู ุงูุญุทุงุท ฺฉุดุฏู ุจูุฏ ูุชูุฑุนูุงูู ูุฑุง ุฑุณุฏู ุฏุฑูุงุฒู ูุง ุชูุฏู ุจุฒุฑฺฏ ุฑุง ุตูุง ูุฏุงุฏ. ุฏุฑ ุงู ุฏูุฑุงู ููุฏุง ุฏุฑ ุงูฺฉุงุฑ ุนููู ูุฑุฏู ุงุฑุงู ุจู ุนููุงู ฺูุฑู ุง ูุณููุจ ุงูุงุฎุชุงุฑ ู ููููู ุง ฺฉุงูู ุงุฒ ูุฎุณุช ูุฒุฑ ฺุงฺฉุฑููุด ู ูุงูุฏ ุดุฎุตุช ุซุจุช ุดุฏุูุฎุณุช ูุฒุฑ ฺฉู ุจุง ุญุถูุฑ ุงู ุดุงู ู ุชูุงูุณุช ุฌููู ูุฑูุด ฺฉูุฏ ุฎูุฏ ุฑุง ุจู ูุซุงุจู ูุฏุฑุช ูุทููู ุุจุฑ ูุฑุงุฒ ูุงููู ุงุณุงุณ ูุดุฑูุทู ุููุงุด ุฏูุฏ. \n",
            "ุงูุฑุนุจุงุณ ููุฏุง ุงุฒ ูุธุฑ ุจุฑุงุฏุฑุด ูุฑุฏูู ููุฏุง ุณูพุฑ ุจูุง ุดุงู ุดุฏ ฺฉู ุดุงู ููฺฏุงู ูุฑุงุฑ ุจุง ุขู ฺฉู ุงูฺฉุงู ุจุฑุฏู ุงู ู ูุนูุช ุงููู ูุตุฑ ู ุฏฺฏุฑ ุณุฑุงู ุญฺฉููุช ุฑุง ุฏุงุดุช (ฺฉู 18 ุขุจุงู 57ุจู ุฏุณุชูุฑ ุดุงู ุฏุณุชฺฏุฑ ุดุฏู ุจูุฏูุฏ)ุงูุง ุขูุงู ุฑุง ุจุฑุง ูุฌุงุช ุฎูุฏ ุฑูุง ฺฉุฑุฏ ู ุงู ฺูู ุดุฏ ฺฉู ฺูุฏ ูุงู ุจุนุฏ ู ุฏุฑ ุชุงุฑุฎ 18 ูุฑูุฑุฏู57 ุญฺฉู ุงุนุฏุงู ุงู ุงุฌุฑุง ู ุงูุฑุนุจุงุณ ููุฏุง ุชุฑุจุงุฑุงู ุดุฏ.\n",
            "ููุฏุง ฺฉ ูุฑุงูุงุณูู ุจูุฏ ู ุฏุฑ ุฏูุฑู ุตุฏุงุฑุช ุงู ุงุฑุงู ุจู ุนุฑุตู ุชุงุฎุช ู ุชุงุฒ ูฺูุง ุฑูฺฏุงุฑูฺฏ ูุฑุงูุงุณููุฑ ุจุฏู ุดุฏ. ูุงู ููุฏุง ุจู ุฏูุฑุงู\" ุซุจุงุช\"ุณูุทูุช ูุญูุฏุฑุถุง ูพููู ฺฏุฑู ุฎูุฑุฏู ุงุณุช ู ุณุงููุง ุตุฏุงุฑุช ุงู ุงูุฌ ูุณุงุฏ ู ุชุจุงู ู ฺฉู ุชุงุฒ ุดุงู ูุญุณูุจ ูุดูุฏ. ุฏุฑ ุฏูุฑุงู ููุฏุงุณุช ฺฉู ูพููุฏูุง ููุงู ู ุนุงู ุฏุฑุจุงุฑ ูพููู ุจุง ูุญุงูู ูุฏุฑุชููุฏ ู ฺูพุงููฺฏุฑ ุบุฑุจ ู ุตูููุณู ุฌูุงู ุจู ูุณุชุญฺฉู ุชุฑู ุดฺฉู ุฎูุฏ ุฑุณุฏ ู ุดุงู ูุบุฑูุฑ ุฏุฑ ุนุฑุตู ุจู ุงูููู ุจูุซุงุจู ฺฉ ุฏฺฉุชุงุชูุฑ ุจููุฏ ูพุฑูุงุฒ ู ุฏุฑ ููุทูู ุจู ุนููุงู ุงุณุชูุงุฑุชุฑู ุฏูุณุช ุบุฑุจ ุธุงูุฑ ุดุฏ.ู ุฏุฑ ฺฉุดูุฑ ฺฉู ููุฑ ู ุชุจุงู ุขู ุฑุง ุจู ฺฉุงู ุงูุญุทุงุท ฺฉุดุฏู ุจูุฏ ูุชูุฑุนูุงูู ูุฑุง ุฑุณุฏู ุฏุฑูุงุฒู ูุง ุชูุฏู ุจุฒุฑฺฏ ุฑุง ุตูุง ูุฏุงุฏ. ุฏุฑ ุงู ุฏูุฑุงู ููุฏุง ุฏุฑ ุงูฺฉุงุฑ ุนููู ูุฑุฏู ุงุฑุงู ุจู ุนููุงู ฺูุฑู ุง ูุณููุจ ุงูุงุฎุชุงุฑ ู ููููู ุง ฺฉุงูู ุงุฒ ูุฎุณุช ูุฒุฑ ฺุงฺฉุฑููุด ู ูุงูุฏ ุดุฎุตุช ุซุจุช ุดุฏุูุฎุณุช ูุฒุฑ ฺฉู ุจุง ุญุถูุฑ ุงู ุดุงู ู ุชูุงูุณุช ุฌููู ูุฑูุด ฺฉูุฏ ุฎูุฏ ุฑุง ุจู ูุซุงุจู ูุฏุฑุช ูุทููู ุุจุฑ ูุฑุงุฒ ูุงููู ุงุณุงุณ ูุดุฑูุทู ุููุงุด ุฏูุฏ. \n",
            "ุงูุฑุนุจุงุณ ููุฏุง ุงุฒ ูุธุฑ ุจุฑุงุฏุฑุด ูุฑุฏูู ููุฏุง ุณูพุฑ ุจูุง ุดุงู ุดุฏ ฺฉู ุดุงู ููฺฏุงู ูุฑุงุฑ ุจุง ุขู ฺฉู ุงูฺฉุงู ุจุฑุฏู ุงู ู ูุนูุช ุงููู ูุตุฑ ู ุฏฺฏุฑ ุณุฑุงู ุญฺฉููุช ุฑุง ุฏุงุดุช (ฺฉู 18 ุขุจุงู 57ุจู ุฏุณุชูุฑ ุดุงู ุฏุณุชฺฏุฑ ุดุฏู ุจูุฏูุฏ)ุงูุง ุขูุงู ุฑุง ุจุฑุง ูุฌุงุช ุฎูุฏ ุฑูุง ฺฉุฑุฏ ู ุงู ฺูู ุดุฏ ฺฉู ฺูุฏ ูุงู ุจุนุฏ ู ุฏุฑ ุชุงุฑุฎ 18 ูุฑูุฑุฏู57 ุญฺฉู ุงุนุฏุงู ุงู ุงุฌุฑุง ู ุงูุฑุนุจุงุณ ููุฏุง ุชุฑุจุงุฑุงู ุดุฏ.\n",
            "ุฏุฑูุบ ุฎุฏูุช ููุฏุง ุจ ุณุงุจูู ุจู\n",
            "ุฏุฑูุบ ุฎุฏูุช ููุฏุง ุจ ุณุงุจูู ุจู\n",
            "ุจู ูุธุฑ ุฎูุจ ูุงุฏ\n",
            "ุจู ูุธุฑ ุฎูุจ ูุงุฏ\n",
            "ูู ฺุงูพุดู ุชุง ุงูุงู ู ุงู ุดูุงุฑู  ุฎุฑุฏู.ฺฉ ูุฌูู ููู ุงูุนุงุงุงุงุงุฏู\n",
            "ูู ฺุงูพุดู ุชุง ุงูุงู ู ุงู ุดูุงุฑู  ุฎุฑุฏู.ฺฉ ูุฌูู ููู ุงูุนุงุงุงุงุงุฏู\n",
            "ฺฉุชุงุจ ุฌุงูุน ุจุง ููุงุจุน ูุนุชุจุฑ ุงุณุช.\n",
            "ฺฉุชุงุจ ุฌุงูุน ุจุง ููุงุจุน ูุนุชุจุฑ ุงุณุช.\n",
            "ฺฉุชุงุจ ุฎู ุฎู ุฎูุจูููู\n",
            "ฺฉุชุงุจ ุฎู ุฎู ุฎูุจูููู\n",
            "ฺฉุชุงุจ ุฌุงูุจ ู ุณุฑุดุงุฑ ุงุฒ ูุทุงูุจ ููุฏ ู ุจุง ุณูุฏุช ูู ููุดุชู ุดุฏู ุงุณุช.\n",
            "ฺฉุชุงุจ ุฌุงูุจ ู ุณุฑุดุงุฑ ุงุฒ ูุทุงูุจ ููุฏ ู ุจุง ุณูุฏุช ูู ููุดุชู ุดุฏู ุงุณุช.\n",
            "ุดุงููุงูู ฺฉ ฺฉุชุงุจ ุชุงุฑุฎ ุจู ูุนูุง ุนูู ุชุงุฑุฎ ฺฉู ุงฺฉููู ู ุดูุงุณู ูุณุช. ุดุงููุงูู ูุฌููุนู ุง ููุธูู ุงุฒ ุฑูุงุช ูุง ุชุงุฑุฎุ ุฏุงุณุชุงู ู ุงุณุทูุฑู ุง ุงุณุช. ุงุฒ ููู ุฑู ูุงูุฏู ูุงู ฺฉูุฑุด ุฏุฑ ุดุงููุงูู ุจู ูุนูุง ูุจูุฏ ุงู ฺูุฑู ุชุงุฑุฎ ูุณุช. ุฏูู ุงูฺฉู ุงุณูุงุฏ ุชุงุฑุฎ ู ุจุงุณุชุงู ุดูุงุณ ุฑูุดู ู ุฏููุ ูุฑูุงูุฑูุง ูุฎุงููุดุงู ู ฺฉูุฑุด ุจุฒุฑฺฏ ุฑุง ุชุงุฏ ู ฺฉูุฏ. ูุงููุฏ ุณูฺฏ ูฺฏุงุฑู ุจุณุชูู ู ููุญ ุญููู ุจุดุฑ ููุดูุฑ ฺฉูุฑุด ุจุฒุฑฺฏ. ุฏุฑ ฺฉ ุณุฏู ุงุฎุฑุ ฺฉุงูุด ูุง ุจุงุณุชุงู ุดูุงุณ ุฌุฏุฏุ ุฑุดุฏ ุฏุงูุด ุจุงุณุชุงู ุดูุงุณ ู ูพฺููุด ูุง ุฏุงูุดฺฏุงู ฺฏุณุชุฑุฏูุ ุฒููู ุฑุง ุจุฑุง ุดูุงุฎุช ุจูุชุฑ ู ุจุดุชุฑ ุงุฑุงู ุจุงุณุชุงู ูุฑุงูู ฺฉุฑุฏู ุงุณุช. ุจู ููู ุณุจุจุ ูุง ุฏุฑ ุงู ุฏูุฑู ุฒูุงูุ ุดุงูุฏ ุดฺฉููุง ุงูุชุดุงุฑ ูุญุชูุง ุฏุฑ ุงู ุญูุฒู ูุณุชู.\n",
            "ุดุงููุงูู ฺฉ ฺฉุชุงุจ ุชุงุฑุฎ ุจู ูุนูุง ุนูู ุชุงุฑุฎ ฺฉู ุงฺฉููู ู ุดูุงุณู ูุณุช. ุดุงููุงูู ูุฌููุนู ุง ููุธูู ุงุฒ ุฑูุงุช ูุง ุชุงุฑุฎุ ุฏุงุณุชุงู ู ุงุณุทูุฑู ุง ุงุณุช. ุงุฒ ููู ุฑู ูุงูุฏู ูุงู ฺฉูุฑุด ุฏุฑ ุดุงููุงูู ุจู ูุนูุง ูุจูุฏ ุงู ฺูุฑู ุชุงุฑุฎ ูุณุช. ุฏูู ุงูฺฉู ุงุณูุงุฏ ุชุงุฑุฎ ู ุจุงุณุชุงู ุดูุงุณ ุฑูุดู ู ุฏููุ ูุฑูุงูุฑูุง ูุฎุงููุดุงู ู ฺฉูุฑุด ุจุฒุฑฺฏ ุฑุง ุชุงุฏ ู ฺฉูุฏ. ูุงููุฏ ุณูฺฏ ูฺฏุงุฑู ุจุณุชูู ู ููุญ ุญููู ุจุดุฑ ููุดูุฑ ฺฉูุฑุด ุจุฒุฑฺฏ. ุฏุฑ ฺฉ ุณุฏู ุงุฎุฑุ ฺฉุงูุด ูุง ุจุงุณุชุงู ุดูุงุณ ุฌุฏุฏุ ุฑุดุฏ ุฏุงูุด ุจุงุณุชุงู ุดูุงุณ ู ูพฺููุด ูุง ุฏุงูุดฺฏุงู ฺฏุณุชุฑุฏูุ ุฒููู ุฑุง ุจุฑุง ุดูุงุฎุช ุจูุชุฑ ู ุจุดุชุฑ ุงุฑุงู ุจุงุณุชุงู ูุฑุงูู ฺฉุฑุฏู ุงุณุช. ุจู ููู ุณุจุจุ ูุง ุฏุฑ ุงู ุฏูุฑู ุฒูุงูุ ุดุงูุฏ ุดฺฉููุง ุงูุชุดุงุฑ ูุญุชูุง ุฏุฑ ุงู ุญูุฒู ูุณุชู.\n",
            "ฺุฑุง ูุจู ุงุฒ ูุฑูุฏ ุงุณุชุนูุงุฑฺฏุฑุงู ุงูฺฏูุณ ูุงู ุงุฒ ฺฉูุฑูุด ูุจูุฏู. ุญุช ุฏุฑ ฺฉุชุงุจ ุดุงููุงูู ูุฒ ุงุณู ุงุฒ ุงู ุงูุฑุฏู ูุดุฏู.\n",
            "ฺุฑุง ุชูุงู ููุงุจุน ุงุฒ ุฒุจุงู ููุงู ุงุณุชุ\n",
            "ฺุฑุง ูุจู ุงุฒ ูุฑูุฏ ุงุณุชุนูุงุฑฺฏุฑุงู ุงูฺฏูุณ ูุงู ุงุฒ ฺฉูุฑูุด ูุจูุฏู. ุญุช ุฏุฑ ฺฉุชุงุจ ุดุงููุงูู ูุฒ ุงุณู ุงุฒ ุงู ุงูุฑุฏู ูุดุฏู.\n",
            "ฺุฑุง ุชูุงู ููุงุจุน ุงุฒ ุฒุจุงู ููุงู ุงุณุชุ\n",
            "ฺฉุชุงุจ ูุณุจุชุง ููุฏ ูุณุช\n",
            "ฺฉุชุงุจ ูุณุจุชุง ููุฏ ูุณุช\n",
            "ฺฉุชุงุจ ุฎูุจู ูุนูุง ุฏุงุฑู ุงุฒ ุฎููุฏูุด ูุฐุช ูุจุฑู ู ุงุทูุงุนุงุช ุฎูุจ ูฺฏุฑู ุงุฒุด\n",
            "ฺฉุชุงุจ ุฎูุจู ูุนูุง ุฏุงุฑู ุงุฒ ุฎููุฏูุด ูุฐุช ูุจุฑู ู ุงุทูุงุนุงุช ุฎูุจ ูฺฏุฑู ุงุฒุด\n",
            "ุณุงู ุง ุงุฒ ุจูุฑุงู ุจุถุง\n",
            "ุณุงู ุง ุงุฒ ุจูุฑุงู ุจุถุง\n",
            "ุชุดฺฉุฑุงุช ูุฑุงูุงู\n",
            "ุชุดฺฉุฑุงุช ูุฑุงูุงู\n",
            "ฺฉุชุงุจ ุนุงู ูุณุช ูู ุญู ุนูุฑุบู ุฒุญูุช ุฒุงุฏ ุขูุง ุณู ุชุฑุฌูู ุณุฎุช ููู ูุณุช .\n",
            "ฺฉุชุงุจ ุนุงู ูุณุช ูู ุญู ุนูุฑุบู ุฒุญูุช ุฒุงุฏ ุขูุง ุณู ุชุฑุฌูู ุณุฎุช ููู ูุณุช .\n",
            "ฺฉุชุงุจ ุนุงู ุญุฑู ูุฏุงุฑู ุจฺฉุช ูู ุญู ฺฉู ุชุฑุฌูู ุณู ุงูุชุถุงุญู.\n",
            "ฺฉุชุงุจ ุนุงู ุญุฑู ูุฏุงุฑู ุจฺฉุช ูู ุญู ฺฉู ุชุฑุฌูู ุณู ุงูุชุถุงุญู.\n",
            "ฺฉุชุงุจ ููู ุงูุนุงุฏู ุฌุงูุจู . ูู ฺฉู ุฎูุดู ุงููุฏ .\n",
            "ฺฉุชุงุจ ููู ุงูุนุงุฏู ุฌุงูุจู . ูู ฺฉู ุฎูุดู ุงููุฏ .\n",
            "ุนุงู. ููููู ุงุฒ ูุดุฑ ุซุงูุซ ู ุทุงูฺู\n",
            "ุนุงู. ููููู ุงุฒ ูุดุฑ ุซุงูุซ ู ุทุงูฺู\n",
            "ุจุง ุงู ุดูุงุฑู ุนุงุดู ุฑูุดู ุดุฏู\n",
            "ุจุง ุงู ุดูุงุฑู ุนุงุดู ุฑูุดู ุดุฏู\n",
            "ุฌูุน ุขูุฑ ุงุณูุงุฏ ููู ุณุงูุงฺฉ ุฏุฑ ููุฑุฏ ูุฑ ุดุฎุต ู ุงู ฺฉุชุงุจ ูู ุจูุฑุงู ุขุฑุงูุง ู ฺู ฺฉุณ ุจูุชุฑ ุงุฒ ุงู ูุงูุนุง\n",
            "ุนุงุงู ุจูุฏ\n",
            "ุฌูุน ุขูุฑ ุงุณูุงุฏ ููู ุณุงูุงฺฉ ุฏุฑ ููุฑุฏ ูุฑ ุดุฎุต ู ุงู ฺฉุชุงุจ ูู ุจูุฑุงู ุขุฑุงูุง ู ฺู ฺฉุณ ุจูุชุฑ ุงุฒ ุงู ูุงูุนุง\n",
            "ุนุงุงู ุจูุฏ\n",
            "ฺฏุงู ุงููุงุช ุงุฒ ฺฉูุฌฺฉุงู ุงุณูุงุฏ ุณุงูุงฺฉ ุฑู ุจุง ฺุดูุงู ู ุจูุนุฏู! ฺฏุงู ูู ุจู ุชููู ูุง ููุฌูุฏ ุฏุฑ ูุชู ู ุฎูุฏุฏู.... ุฎูุงุตู ุงูฺฉู ูพูุฏ ุงุฎูุงู: ฺฉ ุทุฑูู ูุจุงุฏ ุจู ูุงุถ ุฑูุช\n",
            "\n",
            "ุงฺฏุฑ ฺฉุณ ฺฏูุช \"ุดูุจู\" ุง ฺฉู ุณุงูุงฺฉ ุจุฑุง ุขุฑุงูุง ุชุนู ฺฉุฑุฏู ุจูุฏู ฺฉ ุจูุฏุ ูกู ุชุง ูุบุช ูุงุจ ุนุฑุงู ุงุฏุด ูุฏู\n",
            "ฺฏุงู ุงููุงุช ุงุฒ ฺฉูุฌฺฉุงู ุงุณูุงุฏ ุณุงูุงฺฉ ุฑู ุจุง ฺุดูุงู ู ุจูุนุฏู! ฺฏุงู ูู ุจู ุชููู ูุง ููุฌูุฏ ุฏุฑ ูุชู ู ุฎูุฏุฏู.... ุฎูุงุตู ุงูฺฉู ูพูุฏ ุงุฎูุงู: ฺฉ ุทุฑูู ูุจุงุฏ ุจู ูุงุถ ุฑูุช\n",
            "\n",
            "ุงฺฏุฑ ฺฉุณ ฺฏูุช \"ุดูุจู\" ุง ฺฉู ุณุงูุงฺฉ ุจุฑุง ุขุฑุงูุง ุชุนู ฺฉุฑุฏู ุจูุฏู ฺฉ ุจูุฏุ ูกู ุชุง ูุบุช ูุงุจ ุนุฑุงู ุงุฏุด ูุฏู\n",
            "ูุฏููุฏ ฺฉุฏูู ุชุฑุฌูู ุงู ฺฉุชุงุจ ุงุฒ ููู ุจูุชุฑูุ\n",
            "ูุฏููุฏ ฺฉุฏูู ุชุฑุฌูู ุงู ฺฉุชุงุจ ุงุฒ ููู ุจูุชุฑูุ\n",
            "ฺฉ ุงุซุฑ ูุงูุนุง ุชุงุซุฑ ฺฏุฐุงุฑ.\n",
            "ฺฉ ุงุซุฑ ูุงูุนุง ุชุงุซุฑ ฺฏุฐุงุฑ.\n",
            "ฒฐ ุฏุฑุตุฏ\n",
            "SB98KDP96ZD42A\n",
            "ฒฐ ุฏุฑุตุฏ\n",
            "SB98KDP96ZD42A\n",
            "SB98J7WNHN8RGX\n",
            "ฺฉุฏ ุชุฎูู ณฐ ุฏุฑุตุฏุ\n",
            "SB98J7WNHN8RGX\n",
            "ฺฉุฏ ุชุฎูู ณฐ ุฏุฑุตุฏุ\n",
            "ูู ูุณุฎู ูุฒฺฉ ุงู ฺฉุชุงุจ ุฑู ุจุง ุชุฑุฌูู ููุฏ ุนูู ุฏุฑ ุฏูุฑุงู ุณุฑุจุงุฒ ุฎููุฏู .\n",
            "ุจุงุฑ ฺฉุณุงู ฺฉู ุจู ุฑูุงู ูุง ุชุงุฑุฎ ุนูุงูู ุฏุงุฑู ุงู ฺฉุชุงุจ ฺฉ ูุนูุช ุจุฒุฑฺฏู . ุงุชูุงูุงุช ุงุฒ ุชูุฑุจุง ุงูุงู ุฌูููุฑ ูุฑุงูุณู ุดุฑูุน ูุดู ุดุฑุงุท ุงุฌุชูุงุน ู ุณุงุณ ุฏูุฑุงู ุฎูุฏุด ุฑู ุจู ุฎูุจ ุชูุตู ูฺฉูู . ุจู ุฒุจุง ูุงูพูุฆูู ุฑู ุจู ูุฎุงุทุจ ูุนุฑู ูฺฉูู ู ฺฉุชุงุจ ุชุง ุณููุท ูุงูพูุฆูู ุงุฏุงูู ุฏุงุฑู\n",
            "ูู ูุณุฎู ูุฒฺฉ ุงู ฺฉุชุงุจ ุฑู ุจุง ุชุฑุฌูู ููุฏ ุนูู ุฏุฑ ุฏูุฑุงู ุณุฑุจุงุฒ ุฎููุฏู .\n",
            "ุจุงุฑ ฺฉุณุงู ฺฉู ุจู ุฑูุงู ูุง ุชุงุฑุฎ ุนูุงูู ุฏุงุฑู ุงู ฺฉุชุงุจ ฺฉ ูุนูุช ุจุฒุฑฺฏู . ุงุชูุงูุงุช ุงุฒ ุชูุฑุจุง ุงูุงู ุฌูููุฑ ูุฑุงูุณู ุดุฑูุน ูุดู ุดุฑุงุท ุงุฌุชูุงุน ู ุณุงุณ ุฏูุฑุงู ุฎูุฏุด ุฑู ุจู ุฎูุจ ุชูุตู ูฺฉูู . ุจู ุฒุจุง ูุงูพูุฆูู ุฑู ุจู ูุฎุงุทุจ ูุนุฑู ูฺฉูู ู ฺฉุชุงุจ ุชุง ุณููุท ูุงูพูุฆูู ุงุฏุงูู ุฏุงุฑู\n",
            "ุงุฎู ูููุฒ ูุชููุณุชู ฺฉุชุงุจู ุจุฎููู๐๐๐SB98MPXVP3CBTZ\n",
            "ุงุฎู ูููุฒ ูุชููุณุชู ฺฉุชุงุจู ุจุฎูููSB98MPXVP3CBTZ\n",
            "ูู ุงู ฺฉุชุงุจ ุฑู ุงุฒ ูุดุฑ ุงูู ฺฏุฑูุชู ูู ูุชุงุณูุงูู ูููุฒ ูุฑุตุช ูฺฉุฑุฏู ุจุฎููู. ุชุงุฑุฎ ูุฑุงูุณู ุฑู ุฏูุณุช ุฏุงุฑู ฺฉุชุงุจ ูุงุฑ ุขูุชูุงูุช ุฑู ุฎููุฏู ุจุงุฏ ุจฺฏู ฺฉุชุงุจ ูุดูฺฏ ุจูุฏ ูู ฺฉู ุงุญุณุงุณ ุจูุฏ ู ูู ุงุทูุงุนุงุช ุชุงุฑุฎ ุขุฏู ุฑู ุจุงูุง ู ุจุฑู.\n",
            "ูู ุงู ฺฉุชุงุจ ุฑู ุงุฒ ูุดุฑ ุงูู ฺฏุฑูุชู ูู ูุชุงุณูุงูู ูููุฒ ูุฑุตุช ูฺฉุฑุฏู ุจุฎููู. ุชุงุฑุฎ ูุฑุงูุณู ุฑู ุฏูุณุช ุฏุงุฑู ฺฉุชุงุจ ูุงุฑ ุขูุชูุงูุช ุฑู ุฎููุฏู ุจุงุฏ ุจฺฏู ฺฉุชุงุจ ูุดูฺฏ ุจูุฏ ูู ฺฉู ุงุญุณุงุณ ุจูุฏ ู ูู ุงุทูุงุนุงุช ุชุงุฑุฎ ุขุฏู ุฑู ุจุงูุง ู ุจุฑู.\n",
            "ูู ูุณุฎู ฺุงูพ ุฑู ุฎููุฏู . ุฑุงุณุชุด ุฏุงุณุชุงู ุฑู ุฏูุณุช ูุฏุงุดุชู ู ุขุฎุฑุง ูุงูุนุง ุฏุงุดุช ุงุฒ ุฏุฒุฑู ุจุฏู ูููุฏ\n",
            "ูู ูุณุฎู ฺุงูพ ุฑู ุฎููุฏู . ุฑุงุณุชุด ุฏุงุณุชุงู ุฑู ุฏูุณุช ูุฏุงุดุชู ู ุขุฎุฑุง ูุงูุนุง ุฏุงุดุช ุงุฒ ุฏุฒุฑู ุจุฏู ูููุฏ\n",
            "ูฺฉุฑ ููโฺฉูู ูฺ ููุช ูโุฑูุชู ุณุฑุงุบ ุชุงุฑุฎ ูุฑุงูุณูุฑูู ุงู ฺฉุชุงุจ ุจุง ุฏุงุณุชุงู ุฌุฏุงุจุด ุจุฎุด ุงุฒ ุชุงุฑุฎ ูุฑุงูุณู ุฑู ูู ุจู ุฎูุงููุฏู ุงุฏ ูโุฏู. ูุงูุนุง ุงุฑุฒุด ุฎููุฏู ฺูุฏู ุจุงุฑู ุฑู ุฏุงุฑู\n",
            "ูฺฉุฑ ููโฺฉูู ูฺ ููุช ูโุฑูุชู ุณุฑุงุบ ุชุงุฑุฎ ูุฑุงูุณูุฑูู ุงู ฺฉุชุงุจ ุจุง ุฏุงุณุชุงู ุฌุฏุงุจุด ุจุฎุด ุงุฒ ุชุงุฑุฎ ูุฑุงูุณู ุฑู ูู ุจู ุฎูุงููุฏู ุงุฏ ูโุฏู. ูุงูุนุง ุงุฑุฒุด ุฎููุฏู ฺูุฏู ุจุงุฑู ุฑู ุฏุงุฑู\n",
            "ุฏุฑ ุนู ุฏุงุณุชุงู ู ุณุฑฺฏุฑู ฺฉููุฏฺฏุุงุทูุงุนุงุช ุชุงุฑุฎ ุฌุงูุจ ูู ุฏุฑ ุงุฎุชุงุฑ ูุฐุงุฑู\n",
            "ุฏุฑ ุนู ุฏุงุณุชุงู ู ุณุฑฺฏุฑู ฺฉููุฏฺฏุุงุทูุงุนุงุช ุชุงุฑุฎ ุฌุงูุจ ูู ุฏุฑ ุงุฎุชุงุฑ ูุฐุงุฑู\n",
            "ฺฉุชุงุจ ุฒุจุง ุงูุจุชู ุจุนุถ ุฌุงูุง ุงุฒ ุฏุณุช ุฏุฒุฑู ุฎู ุญุฑุต ูุฎูุฑ ู ุงูฺฉู ุฒุงุฏ ุงุฒ ุฌูฺฏ ุชุนุฑู ูฺฉูู\n",
            "ฺฉุชุงุจ ุฒุจุง ุงูุจุชู ุจุนุถ ุฌุงูุง ุงุฒ ุฏุณุช ุฏุฒุฑู ุฎู ุญุฑุต ูุฎูุฑ ู ุงูฺฉู ุฒุงุฏ ุงุฒ ุฌูฺฏ ุชุนุฑู ูฺฉูู\n",
            "ูุงูุนุง ฺฉุชุงุจ ุฎูุจ ุจูุฏ ูุฐุช ุจุฑุฏู\n",
            "ูุงูุนุง ฺฉุชุงุจ ุฎูุจ ุจูุฏ ูุฐุช ุจุฑุฏู\n",
            "ุชูุตู ุฌูฺฏ ุฒุงุฏ ุฏุงุฑู.\n",
            "ุจู ูุธุฑู ูููุด ูุชููุณุชู ุงุจูุช ูุงูพูุฆูู ุฑู ุฎูุจ ุจู ฺุดู ุจุงุฑู.\n",
            "ุชูุตู ุฌูฺฏ ุฒุงุฏ ุฏุงุฑู.\n",
            "ุจู ูุธุฑู ูููุด ูุชููุณุชู ุงุจูุช ูุงูพูุฆูู ุฑู ุฎูุจ ุจู ฺุดู ุจุงุฑู.\n",
            "ุนุงู ุจูุฏ๐๐๐ฆ๐ฆ๐ฆ๐น๐น๐ป๐\n",
            "ุนุงู ุจูุฏ\n",
            "ุนุงุงุงุงู ุจูุฏ\n",
            "ุนุงุงุงุงู ุจูุฏ\n",
            "ฺฉุชุงุจ ุจุณุงุฑ ุฎูุจ ุจูุฏ ู ุจู ูุธุฑู ุฏุฒุฑู ุชุง ุงููุฌุง ฺฉู ูุชููุณุช ุณุน ฺฉุฑุฏ ฺฉู ุนุงุฏูุงูู ู ุจ ุทุฑู ุชุงุฑุฎ ุฑู ุฑูุงุช ฺฉููุ ุชููุง ฺุฒ ฺฉู ูููุน ุฎููุฏู ฺฉุชุงุจ ููู ุงุฒุงุฑ ูุฏุงุฏุ ูุทู ูุฑูุด ฺุงู ุจุงุชุณุช ุจูุฏ ฺฉู ุจุฎุงุทุฑ ูพุงุฏุดุงู ุดุฏู ู ูพุด ฺฏุฑูุชู ุงุฒ ูุงูพูุฆูู ุจู ฺฉุดูุฑ ุฎูุฏุด ุฎุงูุช ฺฉุฑุฏุ ุจู ูุธุฑู ูุงูพูุฆูู ุจุง ุงูฺฉู ุฏฺฉุชุงุชูุฑ ุจูุฏ ู ุจุด ุงุฒ ุญุฏ ุทูุน ูุฏุฑุช ุฏุงุดุช ูู ุจู ูุฑุงุชุจ ุจูุชุฑ ุงุฒ ฺุงู ุจุงุชุณุช ุจูุฏ\n",
            "ฺฉุชุงุจ ุจุณุงุฑ ุฎูุจ ุจูุฏ ู ุจู ูุธุฑู ุฏุฒุฑู ุชุง ุงููุฌุง ฺฉู ูุชููุณุช ุณุน ฺฉุฑุฏ ฺฉู ุนุงุฏูุงูู ู ุจ ุทุฑู ุชุงุฑุฎ ุฑู ุฑูุงุช ฺฉููุ ุชููุง ฺุฒ ฺฉู ูููุน ุฎููุฏู ฺฉุชุงุจ ููู ุงุฒุงุฑ ูุฏุงุฏุ ูุทู ูุฑูุด ฺุงู ุจุงุชุณุช ุจูุฏ ฺฉู ุจุฎุงุทุฑ ูพุงุฏุดุงู ุดุฏู ู ูพุด ฺฏุฑูุชู ุงุฒ ูุงูพูุฆูู ุจู ฺฉุดูุฑ ุฎูุฏุด ุฎุงูุช ฺฉุฑุฏุ ุจู ูุธุฑู ูุงูพูุฆูู ุจุง ุงูฺฉู ุฏฺฉุชุงุชูุฑ ุจูุฏ ู ุจุด ุงุฒ ุญุฏ ุทูุน ูุฏุฑุช ุฏุงุดุช ูู ุจู ูุฑุงุชุจ ุจูุชุฑ ุงุฒ ฺุงู ุจุงุชุณุช ุจูุฏ\n",
            "ูู ูุณุฎู ฺุงูพุด ุฑู ุฎููุฏู ุจุง ุงู ฺฉู ุฎู ุณุงูุณูุฑ ุฏุงุดุช ุงูุง ุนุงู ุจูุฏ\n",
            "ูู ูุณุฎู ฺุงูพุด ุฑู ุฎููุฏู ุจุง ุงู ฺฉู ุฎู ุณุงูุณูุฑ ุฏุงุดุช ุงูุง ุนุงู ุจูุฏ\n",
            "ฺฉุชุงุจ ฺฉู ุฏูุช ููุฎูุงุฏ ุจุฐุงุฑุด ุฒูู...ูุนุฑฺฉู ุงุณุช๐\n",
            "ฺฉุชุงุจ ฺฉู ุฏูุช ููุฎูุงุฏ ุจุฐุงุฑุด ุฒูู...ูุนุฑฺฉู ุงุณุช\n",
            "ุตุฏ ุจุงุฑ ูู ุงู ฺฉุชุงุจู ุจุฎูู ุจุงุฒู ฺฉูู ุฎู ุฒุจุงุณุช๐๐๐๐๐๐\n",
            "ุตุฏ ุจุงุฑ ูู ุงู ฺฉุชุงุจู ุจุฎูู ุจุงุฒู ฺฉูู ุฎู ุฒุจุงุณุช\n",
            "ฺุฑุง ุงููุฏุฑ ฺฏุฑูููุุ\n",
            "ฺุฑุง ุงููุฏุฑ ฺฏุฑูููุุ\n",
            "๐ญ๐ญ๐ญููุช ุงู ฺฉุชุงุจู ุชููู ฺฉุฑุฏู ุจู ุดุฏุช ุบูฺฏู ุดุฏููู ุฌูุฑ ฺฉ ุฏูู ูุฎูุงุณุช ุฒุงุฑ ุฒุงุฑ ฺฏุฑู ฺฉูู.....ุฏูุณุชุงู ุงฺฏุฑ ุญุณุจ ุญุงู ุจู ุงู ุตูุฑุช ูุฌูุฏ ุฏุงุฑู ุง ฺฉุชุงุจ ุชุงุฑุฎ ฺฉู ุงุฏุบุงู ุดุฏู ุจุง ุนุดู.ูุณุช ูุนุฑู ฺฉูุฏ ุจู ุดุฏุชุช ูุดุชุงูู ฺฉ ุจุฑู ุณุฑุงุบุด\n",
            "ููุช ุงู ฺฉุชุงุจู ุชููู ฺฉุฑุฏู ุจู ุดุฏุช ุบูฺฏู ุดุฏููู ุฌูุฑ ฺฉ ุฏูู ูุฎูุงุณุช ุฒุงุฑ ุฒุงุฑ ฺฏุฑู ฺฉูู.....ุฏูุณุชุงู ุงฺฏุฑ ุญุณุจ ุญุงู ุจู ุงู ุตูุฑุช ูุฌูุฏ ุฏุงุฑู ุง ฺฉุชุงุจ ุชุงุฑุฎ ฺฉู ุงุฏุบุงู ุดุฏู ุจุง ุนุดู.ูุณุช ูุนุฑู ฺฉูุฏ ุจู ุดุฏุชุช ูุดุชุงูู ฺฉ ุจุฑู ุณุฑุงุบุด\n",
            "ุจู ูุธุฑ ูู ฺฉุชุงุจ ุจุณุงุฑ ฺฉู ูุธุฑ ุงุณุช .ุจุง ุงูฺฉู ฺูุฏ ุณุงู ูุจู ุงู ฺฉุชุงุจ ุฑุง ุฎูุงูุฏู ุจูุฏูุ ูู ููุช ุฏุฑ ุทุงูฺู ุฏุฏู ุฎู ุฎูุดุญุงู ุดุฏู ู ุงุฒ ุฎูุงูุฏูุด ูุฐุช ูุฑุงูุงู ุจุฑุฏู .\n",
            "ุจู ูุธุฑ ูู ฺฉุชุงุจ ุจุณุงุฑ ฺฉู ูุธุฑ ุงุณุช .ุจุง ุงูฺฉู ฺูุฏ ุณุงู ูุจู ุงู ฺฉุชุงุจ ุฑุง ุฎูุงูุฏู ุจูุฏูุ ูู ููุช ุฏุฑ ุทุงูฺู ุฏุฏู ุฎู ุฎูุดุญุงู ุดุฏู ู ุงุฒ ุฎูุงูุฏูุด ูุฐุช ูุฑุงูุงู ุจุฑุฏู .\n",
            "ฺ ุจฺฏู ุงุฒ ุงู ฺฉุชุงุจ ุขุฎู๐\n",
            "ุงฺฏู ุจู ุงุฏุจุงุช ฺฉูุงุณฺฉ ูุฒูุฏฺฏ ูุงูู ูุง ุนูุงูู ุฏุงุฑ ุจุงุฏ ูุณุฎู ฺุงูพุด ุฑูุจุฎุฑ ฺฉ ููุดู ุชูฺฉุชุงุจุฎููุช ุจุงุดู ุุงูุจุชู ุจ ูุชุฑุฌูุด ูู ุฏูุช ฺฉู ูุฑฺูุฏุฑ ูุฏู ุชุฑุจุงุดู ุจูุชุฑ ฺฉูุชุฑุญุฐูุงุช ุฏุงุฑู !\n",
            "ุณู ุณุงู ูพุด ุฎููุฏูุด ู ุจุงูุงุด ุฒูุฏฺฏ ฺฉุฑุฏู ุงู ฺฉุชุงุจ ุงุฒุฑู ุฏูุชุฑุฎุงุทุฑุงุช ุนุดู ุงูู ูุงูพูุฆูู ููุดุชู ุดุฏู ุงุฒ 14ุณุงูฺฏ ุชุงุฒูุงู ฺฉ ููฺฉู ุณูุฆุฏ ูุดู ู ููู ููุณูุฏู ูู ุจุง ฺฏุฐุดุช ุฒูุงู ุชุบุฑ ูฺฉูู ุงูฺฏุงุฑ ฺฉ ุดูุงูู ุจุงุงู ฺฉุชุงุจ ุจุฒุฑฺฏ ูุดุฏ\n",
            "ูู ูุณุฎู ฺุงูพุด ุฑู ุฎููุฏู ฺฉ 700 ุตูุญู ุจูุฏ ูู ุงููุฏุฑ ุฌุฐุงุจ ุจูุฏฺฉ ูู ุชููุณุชู ุจุฒุงุฑู ุฒูู ูฺูุฏุฑูุฒู ุชูููุด ฺฉุฑุฏู\n",
            "ููุท ฺูุฏุชุง ุชูุตู ุงฺฏู ฺุฒ ุฏุฑููุฑุฏ ุชุงุฑุฎ ูุฑุงูุณู ูู ุฏููุฏ ู ุณุฑฺ ฺฉูฺฺฉ ุฏุฑููุฑุฏุด ฺฉูุฏฺูู ุฏุฑ ุบุฑุงู ุตูุฑุช ุจุฑุงุชูู ููุท ู ุนุงุดูุงูู ฺฉูุงุณฺฉ ูุณุชุด ุฏุฑุญุงู ฺฉ ุงูุถุงุน ุงูุชุตุงุฏ ู ุณุงุณ ุงูู ุฏูุฑุงู ุฑููู ุจู ุชุตูุฑ ฺฉุดุฏู\n",
            "ูููุด ุฑู ูู ูุจูุฏ ฺฉ ุงุตูุง ุจุง ฺฉุชุงุจุด ูุงุจู ููุงุณู ูุณุช\n",
            "ฺฉ ุฐุฑู ูู ูุชููุณุชู ุจู ุฎูุจ ุฏุฒุฑู ุนุงุดู ุฑู ุจู ุชุตูุฑุจฺฉุดู ฺูู ุฎู ูู ุจุงุฒฺฏุฑุงุด ุจุฏุงูุชุฎุงุจ ุดุฏู ู ูู ุงูฺฉู ุฎู ุงุฒ ูุณูุช ูุง ฺฉ ุชู ฺฉุชุงุจ ูุณุช ุชูููู ููุฑุฏู .\n",
            "ุฎูุงุตู ุงูฺฉู ุจุฎูุงูุฏ ู ูุฐุช ุจุจุฑุฏ๐๐๐ธ\n",
            "ู ุฏุฑ ุขุฎุฑ ฺฉ ุณูุงู ุฏุงุฑู ุงุฒฺฉุณุง ฺฉ ุงู ฺฉุชุงุจ ุฑู ุฎููุฏูุฏ ุฏุฑ ุงูุชูุงููุดุชู ุดุฏู ฺฉ ูุงูพูุฆูู ุฎุงุทุฑุงุชุด ุฑูุฏุฑุชุจุนุฏู ููุดุชู ู ุฏุฑูุช ูู ุฌุง ุฎููุฏู ฺฉ ุงู ฺฉุชุงุจ ุธุงูุฑุง ฺุงูพ ุดุฏู ฺฉุณ ุงุณูุด ุฑู ูุฏูููุ\n",
            "ฺ ุจฺฏู ุงุฒ ุงู ฺฉุชุงุจ ุขุฎู\n",
            "ุงฺฏู ุจู ุงุฏุจุงุช ฺฉูุงุณฺฉ ูุฒูุฏฺฏ ูุงูู ูุง ุนูุงูู ุฏุงุฑ ุจุงุฏ ูุณุฎู ฺุงูพุด ุฑูุจุฎุฑ ฺฉ ููุดู ุชูฺฉุชุงุจุฎููุช ุจุงุดู ุุงูุจุชู ุจ ูุชุฑุฌูุด ูู ุฏูุช ฺฉู ูุฑฺูุฏุฑ ูุฏู ุชุฑุจุงุดู ุจูุชุฑ ฺฉูุชุฑุญุฐูุงุช ุฏุงุฑู !\n",
            "ุณู ุณุงู ูพุด ุฎููุฏูุด ู ุจุงูุงุด ุฒูุฏฺฏ ฺฉุฑุฏู ุงู ฺฉุชุงุจ ุงุฒุฑู ุฏูุชุฑุฎุงุทุฑุงุช ุนุดู ุงูู ูุงูพูุฆูู ููุดุชู ุดุฏู ุงุฒ 14ุณุงูฺฏ ุชุงุฒูุงู ฺฉ ููฺฉู ุณูุฆุฏ ูุดู ู ููู ููุณูุฏู ูู ุจุง ฺฏุฐุดุช ุฒูุงู ุชุบุฑ ูฺฉูู ุงูฺฏุงุฑ ฺฉ ุดูุงูู ุจุงุงู ฺฉุชุงุจ ุจุฒุฑฺฏ ูุดุฏ\n",
            "ูู ูุณุฎู ฺุงูพุด ุฑู ุฎููุฏู ฺฉ 700 ุตูุญู ุจูุฏ ูู ุงููุฏุฑ ุฌุฐุงุจ ุจูุฏฺฉ ูู ุชููุณุชู ุจุฒุงุฑู ุฒูู ูฺูุฏุฑูุฒู ุชูููุด ฺฉุฑุฏู\n",
            "ููุท ฺูุฏุชุง ุชูุตู ุงฺฏู ฺุฒ ุฏุฑููุฑุฏ ุชุงุฑุฎ ูุฑุงูุณู ูู ุฏููุฏ ู ุณุฑฺ ฺฉูฺฺฉ ุฏุฑููุฑุฏุด ฺฉูุฏฺูู ุฏุฑ ุบุฑุงู ุตูุฑุช ุจุฑุงุชูู ููุท ู ุนุงุดูุงูู ฺฉูุงุณฺฉ ูุณุชุด ุฏุฑุญุงู ฺฉ ุงูุถุงุน ุงูุชุตุงุฏ ู ุณุงุณ ุงูู ุฏูุฑุงู ุฑููู ุจู ุชุตูุฑ ฺฉุดุฏู\n",
            "ูููุด ุฑู ูู ูุจูุฏ ฺฉ ุงุตูุง ุจุง ฺฉุชุงุจุด ูุงุจู ููุงุณู ูุณุช\n",
            "ฺฉ ุฐุฑู ูู ูุชููุณุชู ุจู ุฎูุจ ุฏุฒุฑู ุนุงุดู ุฑู ุจู ุชุตูุฑุจฺฉุดู ฺูู ุฎู ูู ุจุงุฒฺฏุฑุงุด ุจุฏุงูุชุฎุงุจ ุดุฏู ู ูู ุงูฺฉู ุฎู ุงุฒ ูุณูุช ูุง ฺฉ ุชู ฺฉุชุงุจ ูุณุช ุชูููู ููุฑุฏู .\n",
            "ุฎูุงุตู ุงูฺฉู ุจุฎูุงูุฏ ู ูุฐุช ุจุจุฑุฏ\n",
            "ู ุฏุฑ ุขุฎุฑ ฺฉ ุณูุงู ุฏุงุฑู ุงุฒฺฉุณุง ฺฉ ุงู ฺฉุชุงุจ ุฑู ุฎููุฏูุฏ ุฏุฑ ุงูุชูุงููุดุชู ุดุฏู ฺฉ ูุงูพูุฆูู ุฎุงุทุฑุงุชุด ุฑูุฏุฑุชุจุนุฏู ููุดุชู ู ุฏุฑูุช ูู ุฌุง ุฎููุฏู ฺฉ ุงู ฺฉุชุงุจ ุธุงูุฑุง ฺุงูพ ุดุฏู ฺฉุณ ุงุณูุด ุฑู ูุฏูููุ\n",
            "ฺฉุชุงุจ ุจุณุงุฑ ุฎูุจ ู ุฌุฐุงุจ ุงุณุชุ ฺฉุชุงุจ ุฏุฑ ููุฑุฏ ุฒูุฏฺฏ ุฏุฒุฑู ูุงูุฒุฏ ูุงูพูุฆูู ุจูุงูพุงุฑุช ุงุณุช ฺฉู ูุฑฺฏุฒ ุจุง ุงู ุงุฒุฏูุงุฌ ููฺฉูุฏ ู ุฏุฑ ุขูุฏู ููฺฉู ุณูุฆุฏ ูุดูุฏุ ูู ุงุทูุงุนุงุช ุฎูุจ ุฑุงุฌุน ุจู ูุงูพูุฆูู ู ฺฺฏููฺฏ ุจู ูุฏุฑุช ุฑุณุฏูุด ู ุดฺฉุณุช ู ุชุจุนุฏุด ูุฏูุฏ. ู ูฺฉุชู ูุซุจุช ุฏฺฏุฑุด ุงู ุงุณุช ฺฉู ุจุณุงุฑ ุฎูุจ ู ุฑูุงู ููุดุชู ู ุชุฑุฌูู ุดุฏู.\n",
            "ฺฉุชุงุจ ุจุณุงุฑ ุฎูุจ ู ุฌุฐุงุจ ุงุณุชุ ฺฉุชุงุจ ุฏุฑ ููุฑุฏ ุฒูุฏฺฏ ุฏุฒุฑู ูุงูุฒุฏ ูุงูพูุฆูู ุจูุงูพุงุฑุช ุงุณุช ฺฉู ูุฑฺฏุฒ ุจุง ุงู ุงุฒุฏูุงุฌ ููฺฉูุฏ ู ุฏุฑ ุขูุฏู ููฺฉู ุณูุฆุฏ ูุดูุฏุ ูู ุงุทูุงุนุงุช ุฎูุจ ุฑุงุฌุน ุจู ูุงูพูุฆูู ู ฺฺฏููฺฏ ุจู ูุฏุฑุช ุฑุณุฏูุด ู ุดฺฉุณุช ู ุชุจุนุฏุด ูุฏูุฏ. ู ูฺฉุชู ูุซุจุช ุฏฺฏุฑุด ุงู ุงุณุช ฺฉู ุจุณุงุฑ ุฎูุจ ู ุฑูุงู ููุดุชู ู ุชุฑุฌูู ุดุฏู.\n",
            "ูุงูุนุง ฺฉุชุงุจ ูุญุดุฑ ุจูุฏ ุุฎู ุฎู ูุดูฺฏ\n",
            "ูุงูุนุง ฺฉุชุงุจ ูุญุดุฑ ุจูุฏ ุุฎู ุฎู ูุดูฺฏ\n",
            "ูููุงูุนุงุฏู ุงุฑุฒุด ุฎุฑุฏ ุฏุงุฑู ุงฺฏู ุงูฺฉุงูุดู ุฏุงุฑุฏ ู ุฏูุจุงู ฺฉุชุงุจ ุฎูุจุฏ ุจุฑุง ุฎุฑุฏ ุจุฎุฑุฏ ุงูู ูฺฏุฑุงู ูุจุงุดุฏ\n",
            "ูููุงูุนุงุฏู ุงุฑุฒุด ุฎุฑุฏ ุฏุงุฑู ุงฺฏู ุงูฺฉุงูุดู ุฏุงุฑุฏ ู ุฏูุจุงู ฺฉุชุงุจ ุฎูุจุฏ ุจุฑุง ุฎุฑุฏ ุจุฎุฑุฏ ุงูู ูฺฏุฑุงู ูุจุงุดุฏ\n",
            "ุงู ฺฉุชุงุจ ฺุงูพ ฺูุฏู ูุณุช ุ ุ ฺฉุณ ูุฏููู ฺุงูพ ุงูู ุงุตูุง ฺฏุฑ ูุงุฏ ุง ูู ุ ฺฉุฏูู ุชุฑุฌูู ุณุงูุณูุฑ ฺฉูุชุฑ ุฏุงุฑู\n",
            "ุงู ฺฉุชุงุจ ฺุงูพ ฺูุฏู ูุณุช ุ ุ ฺฉุณ ูุฏููู ฺุงูพ ุงูู ุงุตูุง ฺฏุฑ ูุงุฏ ุง ูู ุ ฺฉุฏูู ุชุฑุฌูู ุณุงูุณูุฑ ฺฉูุชุฑ ุฏุงุฑู\n",
            "ฺฉ ุงุฒ ุฒุจุงุชุฑู ฺฉุชุงุจูุง ฺฉู ุชุง ุงูุงู ุฎููุฏู. ูุงูุนุง ุนุงู ุจูุฏ. ุนุฌุจ ุฒูุฏฺฏ ูพุฑ ูุฑุงุฒ ู ูุดุจ ุฏุงุดุช ุฏุฒุฑู ฺฉูุงุฑ....\n",
            "ฺฉ ุงุฒ ุฒุจุงุชุฑู ฺฉุชุงุจูุง ฺฉู ุชุง ุงูุงู ุฎููุฏู. ูุงูุนุง ุนุงู ุจูุฏ. ุนุฌุจ ุฒูุฏฺฏ ูพุฑ ูุฑุงุฒ ู ูุดุจ ุฏุงุดุช ุฏุฒุฑู ฺฉูุงุฑ....\n",
            "ุฎูุด ุจู ุญุงูุด ฺู ุฒูุฏฺฏ ูพุฑ ูุงุฌุฑุง ุฏุงุดุชู\n",
            "ุฎูุด ุจู ุญุงูุด ฺู ุฒูุฏฺฏ ูพุฑ ูุงุฌุฑุง ุฏุงุดุชู\n",
            "ุจุณุงุฑ ุนุงู...ููู ุงูุนุงุฏุณุช\n",
            "ุจุณุงุฑ ุนุงู...ููู ุงูุนุงุฏุณุช\n",
            "ฺฉุชุงุจ ูุดูฺฏู.ุดุงุฏ ููุช ุชู ุชูุถุญุงุชุด ุฎููุฏู ูุดู ฺฉู ููุถูุนุด ุชู ุญุงู ู ููุง ุฌูฺฏู ู ุฐุฑู ุฏูุณุฑุฏ ฺฉููุฏู ุจุงุดู ุงูุง ุงูููุฏุฑ ุฎูุจ ุจุง ฺฉููุงุช ุจุงุฒ ุดุฏู ฺฉู ุฌุง ูฺ ุงุฑุงุฏ ูุณุช.ูู ูุณุฎู ฺุงูพุดู ุฎููุฏู ุจ ูุธุฑู ุงฺฏู ุงุฒ ูุดฺฉู ุชุฑุฌูู ุชู ุงูุชุดุงุฑุงุช ูุง ูุฎุชูู ุจฺฏุฐุฑูุฺฉุงุฑ ููุณูุฏุด ุนุงูููููู.\n",
            "ฺฉุชุงุจ ูุดูฺฏู.ุดุงุฏ ููุช ุชู ุชูุถุญุงุชุด ุฎููุฏู ูุดู ฺฉู ููุถูุนุด ุชู ุญุงู ู ููุง ุฌูฺฏู ู ุฐุฑู ุฏูุณุฑุฏ ฺฉููุฏู ุจุงุดู ุงูุง ุงูููุฏุฑ ุฎูุจ ุจุง ฺฉููุงุช ุจุงุฒ ุดุฏู ฺฉู ุฌุง ูฺ ุงุฑุงุฏ ูุณุช.ูู ูุณุฎู ฺุงูพุดู ุฎููุฏู ุจ ูุธุฑู ุงฺฏู ุงุฒ ูุดฺฉู ุชุฑุฌูู ุชู ุงูุชุดุงุฑุงุช ูุง ูุฎุชูู ุจฺฏุฐุฑูุฺฉุงุฑ ููุณูุฏุด ุนุงูููููู.\n",
            "ุชุตูุฑ ูพุฑุฏุงุฒ ุฎู ุฎูุจ ุฏุงุดุช. ุจุง ุงูฺฉู ต_ถ ุณุงู ูพุด ุฎููุฏู ูู ูููุฒ ุจุนุถ ูุณูุช ูุงุดู ุงุฏูู. ฺฉุชุงุจู ฺฉู ุญุชูุง ุจุงุฏ ุฎููุฏ.\n",
            "ุชุตูุฑ ูพุฑุฏุงุฒ ุฎู ุฎูุจ ุฏุงุดุช. ุจุง ุงูฺฉู ต_ถ ุณุงู ูพุด ุฎููุฏู ูู ูููุฒ ุจุนุถ ูุณูุช ูุงุดู ุงุฏูู. ฺฉุชุงุจู ฺฉู ุญุชูุง ุจุงุฏ ุฎููุฏ.\n",
            "ุจูุชุฑู ุชุฑุฌูู  ุงู ฺฉุชุงุจ ฺฉุฏูููุุุ\n",
            "ุจูุชุฑู ุชุฑุฌูู  ุงู ฺฉุชุงุจ ฺฉุฏูููุุุ\n",
            "ูุญุดุฑู ุงู ุฑูุงู...ุชูุตู ูฺฉูู ุญุชูุง ุจุฎููุฏ\n",
            "ูุญุดุฑู ุงู ุฑูุงู...ุชูุตู ูฺฉูู ุญุชูุง ุจุฎููุฏ\n",
            "ูู ูุณุฎู ฺุงูพ ุฑู ุจุงตฐุฏุฑุตุฏ ุชุฎูู ฺฏุฑูุชูฒตุชููู ู ุจูุธุฑู ุงุฑุฒุดุด ุฎุฑุฏู ุฏุงุดุช ุจุณุงุฑ ุฌุงูุจ ูุณุช ุชูุตู ูฺฉูู ฺุงูพุดู ุจฺฏุฑุฏ ูู ุญุณ ุจูุชุฑ ุฏุงุฑู ุจุฑุง ุฎููุฏู ู ูู ูุชููุฏ ุจู ุนุฒุฒุงูุชูู ุจุฏุฏ ุงููุงู ุงุฒู ูุฐุช ุจ ูุตุจ ููููู\n",
            "ูู ูุณุฎู ฺุงูพ ุฑู ุจุงตฐุฏุฑุตุฏ ุชุฎูู ฺฏุฑูุชูฒตุชููู ู ุจูุธุฑู ุงุฑุฒุดุด ุฎุฑุฏู ุฏุงุดุช ุจุณุงุฑ ุฌุงูุจ ูุณุช ุชูุตู ูฺฉูู ฺุงูพุดู ุจฺฏุฑุฏ ูู ุญุณ ุจูุชุฑ ุฏุงุฑู ุจุฑุง ุฎููุฏู ู ูู ูุชููุฏ ุจู ุนุฒุฒุงูุชูู ุจุฏุฏ ุงููุงู ุงุฒู ูุฐุช ุจ ูุตุจ ููููู\n",
            "ุนุงู ุงุณุช\n",
            "ุนุงู ุงุณุช\n",
            "ูู ูุณุฎู ฺุงูพ ุฑู ุจุง ฺฉ ุชุฑุฌูู ุฏฺฏู ุฎููุฏู. ุงู ูฅ ุณุชุงุฑู ุฑู ูู ุจู ููุณูุฏู ู ุฏู. ุฌุฒู ุจูุชุฑู ุฑูุงููุง ฺฉู ุฏุฑ ุนูุฑู ุฎููุฏู. ุนุงุดู ฺุงู ุจุงุชุณุช ุจุฑูุงุฏูุชู.\n",
            "ูู ูุณุฎู ฺุงูพ ุฑู ุจุง ฺฉ ุชุฑุฌูู ุฏฺฏู ุฎููุฏู. ุงู ูฅ ุณุชุงุฑู ุฑู ูู ุจู ููุณูุฏู ู ุฏู. ุฌุฒู ุจูุชุฑู ุฑูุงููุง ฺฉู ุฏุฑ ุนูุฑู ุฎููุฏู. ุนุงุดู ฺุงู ุจุงุชุณุช ุจุฑูุงุฏูุชู.\n",
            "ุณูุงู ูุณุฎู ฺุงูพ ฺูุฏ ุฌูุฏ ุฏุงุฑูุ\n",
            "ุณูุงู ูุณุฎู ฺุงูพ ฺูุฏ ุฌูุฏ ุฏุงุฑูุ\n",
            "ูุณุฎู  ฺุงูพุดู ุชุงุฒู ุดุฑูู ฺฉุฑุฏู ฺฉุชุงุจ ูุดูฺฏู\n",
            "ูุณุฎู  ฺุงูพุดู ุชุงุฒู ุดุฑูู ฺฉุฑุฏู ฺฉุชุงุจ ูุดูฺฏู\n",
            "ูู ุจุง ุชุฑุฌูู ุฐุจุญ ุงููู ููุตูุฑ ูููุฏู ุจู ูุธุฑู ุจูุชุฑู ุฑูุงู ุชุงุฑุฎ ุงู ฺฉุชุงุจ ูุณุชุด ุจุฏูู ุดฺฉ\n",
            "ูู ุจุง ุชุฑุฌูู ุฐุจุญ ุงููู ููุตูุฑ ูููุฏู ุจู ูุธุฑู ุจูุชุฑู ุฑูุงู ุชุงุฑุฎ ุงู ฺฉุชุงุจ ูุณุชุด ุจุฏูู ุดฺฉ\n",
            "ุฏุฑ ุฎูุจ ุจูุฏู ฺฉุชุงุจ ุดฺฉ ูุณุช.ุงูุจุชู ุชูุฌู ูู ุฏุงุดุชู ุจุงุดุฏ ฺฉู ''ุฑูุงู'' ูุฒููุง ุจุฑุงุณุงุณ ูุงูุนุช ููุดุชู ูุดุฏู.ุงู ฺฉุชุงุจ ุจุฑฺฏุฑูุชู ุงุฒ ุฑูุฏุงุฏูุง ูุฑุงูุณู ู ุงูููุงุจ ูุฑุงูุณู ุณุช.ุงูุง ุฏุฑููุน ุฎูุฏุด ฺฉ ุฏุงุณุชุงูู ู ูุฑุฏุงุณุชุงู ูุชููู ูุจุงูุบู ุขูุฒุุชุญุฑู ุดุฏู ุง ุจู ุฏูุฑ ุงุฒ ูุงูุนุช ุจุงุดู.\n",
            "ุญุช ฺฉุชุงุจ ูุง ูุนุชุจุฑ ุชุงุฑุฎ ูู ุจุณุงุฑ ููุช ูุง ฺุฒูุง ุงุฒ ุชุงุฑุฎ ุฑู ุฏุฑ ุชุงุฑฺฉ ูุฑุงุฑ ุฏุงุฏู.ุชฺฉูู ุงู ฺฉุชุงุจ ูู ุฑูุดูู.ุงฺฏุฑ ฺฉู ูุจู ุงุฑ ุฎููุฏูุด ุณุฑฺ ุฏุฑ ุฒููู ุงูููุงุจ ูุฑุงูุณู ู ุงุณุงู ุงูุฑุงุฏ ฺฉุชุงุจ ุฏุงุดุชู ุจุงุดุฏ ุณุฑุฏุฑฺฏู ูู ุดุฏ.\n",
            "ุจุนุฏุงุฒุฎููุฏู ูู ูฺฉุฑ ูฺฉูุฏ ุชุงุฑุฎ ุฏุงู ุดุฏุฏ.ููุดุชู ูุง ุงู ฺฉุชุงุจ ููุชููู ููุจุน ูพฺููุด ูุนุชุจุฑ ุจุงุดู๏ผ)))\n",
            "ุฏุฑ ุฎูุจ ุจูุฏู ฺฉุชุงุจ ุดฺฉ ูุณุช.ุงูุจุชู ุชูุฌู ูู ุฏุงุดุชู ุจุงุดุฏ ฺฉู ''ุฑูุงู'' ูุฒููุง ุจุฑุงุณุงุณ ูุงูุนุช ููุดุชู ูุดุฏู.ุงู ฺฉุชุงุจ ุจุฑฺฏุฑูุชู ุงุฒ ุฑูุฏุงุฏูุง ูุฑุงูุณู ู ุงูููุงุจ ูุฑุงูุณู ุณุช.ุงูุง ุฏุฑููุน ุฎูุฏุด ฺฉ ุฏุงุณุชุงูู ู ูุฑุฏุงุณุชุงู ูุชููู ูุจุงูุบู ุขูุฒุุชุญุฑู ุดุฏู ุง ุจู ุฏูุฑ ุงุฒ ูุงูุนุช ุจุงุดู.\n",
            "ุญุช ฺฉุชุงุจ ูุง ูุนุชุจุฑ ุชุงุฑุฎ ูู ุจุณุงุฑ ููุช ูุง ฺุฒูุง ุงุฒ ุชุงุฑุฎ ุฑู ุฏุฑ ุชุงุฑฺฉ ูุฑุงุฑ ุฏุงุฏู.ุชฺฉูู ุงู ฺฉุชุงุจ ูู ุฑูุดูู.ุงฺฏุฑ ฺฉู ูุจู ุงุฑ ุฎููุฏูุด ุณุฑฺ ุฏุฑ ุฒููู ุงูููุงุจ ูุฑุงูุณู ู ุงุณุงู ุงูุฑุงุฏ ฺฉุชุงุจ ุฏุงุดุชู ุจุงุดุฏ ุณุฑุฏุฑฺฏู ูู ุดุฏ.\n",
            "ุจุนุฏุงุฒุฎููุฏู ูู ูฺฉุฑ ูฺฉูุฏ ุชุงุฑุฎ ุฏุงู ุดุฏุฏ.ููุดุชู ูุง ุงู ฺฉุชุงุจ ููุชููู ููุจุน ูพฺููุด ูุนุชุจุฑ ุจุงุดู)))\n",
            "ููู ุงูุนุงุฏู ุจูุฏ.\n",
            "ููู ุงูุนุงุฏู ุจูุฏ.\n",
            "ุตุฏุชุงุณุชุงุฑู ูู ุจุฑุงุด ฺฉูู ูู ุนุงุงุงุงุงุงุดู ุงู ฺฉุชุงุจ ุดุฏู๐\n",
            "ุตุฏุชุงุณุชุงุฑู ูู ุจุฑุงุด ฺฉูู ูู ุนุงุงุงุงุงุงุดู ุงู ฺฉุชุงุจ ุดุฏู\n",
            "ุงุฑุฒุด ุฎููุฏู ุฏุงุฑู\n",
            "ุงุฑุฒุด ุฎููุฏู ุฏุงุฑู\n",
            "ฺฉ ุงุฒ ุจูุชุฑู ฺฉุชุงุจูุง ุจูุฏ ฺฉู ุฎููุฏู . ุฏุฒุฑู ุฏุฑ ุฎูุงู ุชูุตู ุนุดู ูุงูพูุฆูู ุจู ุงู ฺฉู ุงูุจุชู ูฺููุช ููุฌุฑ ุจู ุงุฒุฏูุงุฌ ุขููุง ูุดุฏ ุ ุดุฑุงุท ุงูููุงุจ ูุฑุงูุณู ู ฺฺฏููฺฏ ุจู ูุฏุฑุช ุฑุณุฏู ูุงูพูุฆูู ู ุจุฑฺฉูุงุฑ ุงู ู ุจุณุงุฑ ูุณุงุฆู ุฏฺฏุฑ ุฑู ฺฉู ุจุฑุง ุฏุงูุณุชูุดูู ุจุงุฏ ุจู ฺฉุชุงุจูุง ุชุงุฑุฎ ุฑุฌูุน ฺฉุฑุฏ ุดุฑุญ ุฏุงุฏู ู ุงูุจุชู ุดุงุฏ ุชุง ุงู ุงูุฏุงุฒู ุจู ุฏุฑูู ุฒูุฏฺฏ ูุงูพูุฆูู ุฏุฑ ฺฉุชุจ ุชุงุฑุฎ ุงุดุงุฑู ูุดุฏู ุจุงุดู . ุฎูุงูุฏู ุงู ฺฉุชุงุจ ุฌุฐุงุจ ุชูุตู ูุดู ุงูุจุชู ุงูุงุณุท ฺฉุชุงุจ ููฺฉูู ฺฉู ุงุฒ ุฌุฐุงุจุช ุขู ฺฉู ุจุดู ุงูุง ููุง ุขููุฏุฑ ฺฉุดุด ุฏุงุฑู ฺฉู ุชุง ุขุฎุฑุด ูพุด ุจุฑุฏ .\n",
            "ฺฉ ุงุฒ ุจูุชุฑู ฺฉุชุงุจูุง ุจูุฏ ฺฉู ุฎููุฏู . ุฏุฒุฑู ุฏุฑ ุฎูุงู ุชูุตู ุนุดู ูุงูพูุฆูู ุจู ุงู ฺฉู ุงูุจุชู ูฺููุช ููุฌุฑ ุจู ุงุฒุฏูุงุฌ ุขููุง ูุดุฏ ุ ุดุฑุงุท ุงูููุงุจ ูุฑุงูุณู ู ฺฺฏููฺฏ ุจู ูุฏุฑุช ุฑุณุฏู ูุงูพูุฆูู ู ุจุฑฺฉูุงุฑ ุงู ู ุจุณุงุฑ ูุณุงุฆู ุฏฺฏุฑ ุฑู ฺฉู ุจุฑุง ุฏุงูุณุชูุดูู ุจุงุฏ ุจู ฺฉุชุงุจูุง ุชุงุฑุฎ ุฑุฌูุน ฺฉุฑุฏ ุดุฑุญ ุฏุงุฏู ู ุงูุจุชู ุดุงุฏ ุชุง ุงู ุงูุฏุงุฒู ุจู ุฏุฑูู ุฒูุฏฺฏ ูุงูพูุฆูู ุฏุฑ ฺฉุชุจ ุชุงุฑุฎ ุงุดุงุฑู ูุดุฏู ุจุงุดู . ุฎูุงูุฏู ุงู ฺฉุชุงุจ ุฌุฐุงุจ ุชูุตู ูุดู ุงูุจุชู ุงูุงุณุท ฺฉุชุงุจ ููฺฉูู ฺฉู ุงุฒ ุฌุฐุงุจุช ุขู ฺฉู ุจุดู ุงูุง ููุง ุขููุฏุฑ ฺฉุดุด ุฏุงุฑู ฺฉู ุชุง ุขุฎุฑุด ูพุด ุจุฑุฏ .\n",
            "ุฎู ฺฉุชุงุจ ุฎูุจู ุญุชูุง ุจุฎููุฏุด\n",
            "ุฎู ฺฉุชุงุจ ุฎูุจู ุญุชูุง ุจุฎููุฏุด\n",
            "ูุฎุงุณุชู ุจฺฏุฑูุด ููุชุด ทต ุชููู ุจูุฏ ูู ูุงู ู ุงูุชุดุงุฑุงุช ุฏฺฏู ุง ุจูุฏ\n",
            "ูุฎุงุณุชู ุจฺฏุฑูุด ููุชุด ทต ุชููู ุจูุฏ ูู ูุงู ู ุงูุชุดุงุฑุงุช ุฏฺฏู ุง ุจูุฏ\n",
            "ูุงูุนุง ูุดูฺฏ ู ุฒุจุง ุจูุฏ ูู ฺฉู ููุช ฺฉุชุงุจ ุชูุงู ุดุฏ ุชุง ฺูุฏ ุฑูุฒ ุญุงูู ฺฏุฑูุชู ุจูุฏ \n",
            "ุงูุจุชู ููู ุชุฑุฌูู ูุง ุฎูุจ ูุณุชู ู ุงุฑุฒุด ุงุซุฑ ุฑู ูพุงู ูุงุฑู ูุซู ูุดุฑ ุงูู\n",
            "ูุงูุนุง ูุดูฺฏ ู ุฒุจุง ุจูุฏ ูู ฺฉู ููุช ฺฉุชุงุจ ุชูุงู ุดุฏ ุชุง ฺูุฏ ุฑูุฒ ุญุงูู ฺฏุฑูุชู ุจูุฏ \n",
            "ุงูุจุชู ููู ุชุฑุฌูู ูุง ุฎูุจ ูุณุชู ู ุงุฑุฒุด ุงุซุฑ ุฑู ูพุงู ูุงุฑู ูุซู ูุดุฑ ุงูู\n",
            "ุญุงู ู ููุง ูุฑุงูุณู ูุฑู ูุฌุฏูู ุฑู ุฎู ุฎูุจ ููุชูู ูฺฉูู .ุดุฎุตุช ุฏุฒุฑู ูุงูุนุง ุจูุธุฑู!ุฏุฎุชุฑ ูุญฺฉู ู ูู ฺฉู ูฺ ููุช ุงุตุงูุช ุฎูุฏุดู ูุฑุงููุด ูฺฉุฑุฏ.. ูู ููุท ฺฉู ุงุฒ ุงู ูุณุฎู ู ุชุฑุฌูู ุฑู ุฎููุฏู ูู ุจู ูุธุฑู ุชุฑุฌูู ุขูุง ุงุฑุฌ ูพุฒุดฺฉุฒุงุฏ ุฌุฐุงุจ ุชุฑู..\n",
            "ุญุงู ู ููุง ูุฑุงูุณู ูุฑู ูุฌุฏูู ุฑู ุฎู ุฎูุจ ููุชูู ูฺฉูู .ุดุฎุตุช ุฏุฒุฑู ูุงูุนุง ุจูุธุฑู!ุฏุฎุชุฑ ูุญฺฉู ู ูู ฺฉู ูฺ ููุช ุงุตุงูุช ุฎูุฏุดู ูุฑุงููุด ูฺฉุฑุฏ.. ูู ููุท ฺฉู ุงุฒ ุงู ูุณุฎู ู ุชุฑุฌูู ุฑู ุฎููุฏู ูู ุจู ูุธุฑู ุชุฑุฌูู ุขูุง ุงุฑุฌ ูพุฒุดฺฉุฒุงุฏ ุฌุฐุงุจ ุชุฑู..\n",
            "ุจุฏ ูุจูุฏ .\n",
            "ุจุฏ ูุจูุฏ .\n",
            "ุชุฑุฌูุด ฺุฒ ุจุดุชุฑ ุงุฒ ุงูุชุถุงุญ ุจูุฏ ๐\n",
            "ุชุฑุฌูุด ฺุฒ ุจุดุชุฑ ุงุฒ ุงูุชุถุงุญ ุจูุฏ \n",
            "ูุงูุนุง ฺฉุชุงุจู ุนุงู ุจูุฏ....ุฏููุดู ู ฺฏูุง ู ุฑูุงู\n",
            "ูุงูุนุง ฺฉุชุงุจู ุนุงู ุจูุฏ....ุฏููุดู ู ฺฏูุง ู ุฑูุงู\n",
            "ุงู ฺฉุชุงุจ ฺูุฏุฑ ุฒุจุงุณุช .....\n",
            "ุงู ฺฉุชุงุจ ฺูุฏุฑ ุฒุจุงุณุช .....\n",
            "ูู ุนุงุดู ุงู ฺฉุชุงุจู ุงูุจุชู ุจุฑุงู ูููุฒ ุฏุฑฺฉุด ุณุฎุชู ูุฎุตูุตุง ุฌุงูุง ุชุงุฑุฎุด ุงูุง ุฎู ููู ุงูุนุงุฏู ุงุณุช ุญุชูุง ุจุฎููู\n",
            "ูู ุนุงุดู ุงู ฺฉุชุงุจู ุงูุจุชู ุจุฑุงู ูููุฒ ุฏุฑฺฉุด ุณุฎุชู ูุฎุตูุตุง ุฌุงูุง ุชุงุฑุฎุด ุงูุง ุฎู ููู ุงูุนุงุฏู ุงุณุช ุญุชูุง ุจุฎููู\n",
            "ุฏุฒุฑู ูุงูุนุง ุนุงูู...\n",
            "ูู ูุณุฎู ฺุงูพุดู ุฎููุฏู...\n",
            "ูุงูุนุง ุฏูุณุด ุฏุงุฑู...\n",
            "....\n",
            "ุฏุฒุฑู ูุงูุนุง ุนุงูู...\n",
            "ูู ูุณุฎู ฺุงูพุดู ุฎููุฏู...\n",
            "ูุงูุนุง ุฏูุณุด ุฏุงุฑู...\n",
            "....\n",
            "ูุญุดุฑู...\n",
            "ูู ุงูุฑูุฒ ุจู ุนููุงู ฺฉ ุงุฒ ฺฉุงุฑุจุฑุงู \"ุทุงูฺู\" ุนุฒุฒุุฎูุงุณุชู ุงุฒ ุฏูุณุชุงู ู ฺฉุงุฑุจุฑุงู ฺฉู ููุฏ ูุง ุญุฑูู ุง ุุจู ุงุดุชุฑุงฺฉ ูฺฏุฐุงุฑู ุุตููุงูู ุชุดฺฉุฑ ฺฉูู.ุจุชุฑุชุจ ุงุฒ :ุขูุง ุณุงูุงุฑ-ุขูุง  ุฑูุญ ุงููู-ุขูุง  ุญุฌุช-ุขูุง ุงุจูุฐุฑ-ูุงุทูู ุฎุงููู-ูุณุช ุฎุงููู ู ฺฉุงุฑุจุฑุงู ุฏฺฏู ุง ุจุง ูุงู ุงุนุฏุงุฏ ูุณุชู ู ุฎูุฏุชูู ู ุชููุฏ ููุฏูุงุดููู ุจุฎููุฏ ู ูุฐุช ุจุจุฑุฏ.ุฎู ุงุฒ ุนุฒุฒุงู ุงุญุชูุงูุง ุงุฒ ููู ุงูุชุงุฏู ฺูู ุฏุฑ ุญุงู ุญุงุถุฑ ุญุถูุฑ ุฐูู ูุฏุงุฑู.ุจุง ุชุดฺฉุฑ ู ุณูพุงุณ ุงุฒ ูุฏุฑุช ู ูพุฑุณูู ูุญุชุฑู \"ุทุงูฺู\"\n",
            "ูุญุดุฑู...\n",
            "ูู ุงูุฑูุฒ ุจู ุนููุงู ฺฉ ุงุฒ ฺฉุงุฑุจุฑุงู \"ุทุงูฺู\" ุนุฒุฒุุฎูุงุณุชู ุงุฒ ุฏูุณุชุงู ู ฺฉุงุฑุจุฑุงู ฺฉู ููุฏ ูุง ุญุฑูู ุง ุุจู ุงุดุชุฑุงฺฉ ูฺฏุฐุงุฑู ุุตููุงูู ุชุดฺฉุฑ ฺฉูู.ุจุชุฑุชุจ ุงุฒ :ุขูุง ุณุงูุงุฑ-ุขูุง  ุฑูุญ ุงููู-ุขูุง  ุญุฌุช-ุขูุง ุงุจูุฐุฑ-ูุงุทูู ุฎุงููู-ูุณุช ุฎุงููู ู ฺฉุงุฑุจุฑุงู ุฏฺฏู ุง ุจุง ูุงู ุงุนุฏุงุฏ ูุณุชู ู ุฎูุฏุชูู ู ุชููุฏ ููุฏูุงุดููู ุจุฎููุฏ ู ูุฐุช ุจุจุฑุฏ.ุฎู ุงุฒ ุนุฒุฒุงู ุงุญุชูุงูุง ุงุฒ ููู ุงูุชุงุฏู ฺูู ุฏุฑ ุญุงู ุญุงุถุฑ ุญุถูุฑ ุฐูู ูุฏุงุฑู.ุจุง ุชุดฺฉุฑ ู ุณูพุงุณ ุงุฒ ูุฏุฑุช ู ูพุฑุณูู ูุญุชุฑู \"ุทุงูฺู\"\n",
            "ฺฉ ุงุฒ ุจูุชุฑู ุฑูุงู ูุง ฺฉู ุฎููุฏู\n",
            " ุงุฒ ุงููุฌุง ฺฉู ุจุฑ ุงุณุงุณ ูุงูุนุชู ู ุชุงุฑุฎ ูู ูุณุช ุนุงุดูุด ุดุฏู \n",
            "ุฑูุงู ู ฺฏุฑุง ุชุฑุฌูู ุงุซุฑ ูู ุงุฒ ูุฑ ุญุซ ุฎู ุฎูุจ ุจูุฏ\n",
            "ฺฉ ุงุฒ ุจูุชุฑู ุฑูุงู ูุง ฺฉู ุฎููุฏู\n",
            " ุงุฒ ุงููุฌุง ฺฉู ุจุฑ ุงุณุงุณ ูุงูุนุชู ู ุชุงุฑุฎ ูู ูุณุช ุนุงุดูุด ุดุฏู \n",
            "ุฑูุงู ู ฺฏุฑุง ุชุฑุฌูู ุงุซุฑ ูู ุงุฒ ูุฑ ุญุซ ุฎู ุฎูุจ ุจูุฏ\n",
            "ฺฉุชุงุจ ุฌุฐุงุจู. ุจุนุฏ ุชุงุฑุฎุดู ุฎูุจู ุขุฏู ุชุงุฑุฎุด ุฎูุจ ูุดู๐\n",
            "ฺฉุชุงุจ ุฌุฐุงุจู. ุจุนุฏ ุชุงุฑุฎุดู ุฎูุจู ุขุฏู ุชุงุฑุฎุด ุฎูุจ ูุดู\n",
            "ุจูุชุฑู ุฑูุงู ฺฉู ุชูุฒูุฏฺฏู ุฎููุฏู ููู ุงูุนุงุฏู ๐๐๐๐ุฑูุงู ุฎููุงุงุฒุฏุณุชุด ูุฏู\n",
            "ุจูุชุฑู ุฑูุงู ฺฉู ุชูุฒูุฏฺฏู ุฎููุฏู ููู ุงูุนุงุฏู ุฑูุงู ุฎููุงุงุฒุฏุณุชุด ูุฏู\n",
            "ูู  ุงู ฺฉุชุงุจ ุฑู ฺูุฏ ุฑูุฒ ูพุด ุดุฑูุน ฺฉุฑุฏู  ุจู ูุธุฑู ฺฉ ุงุฒ ุจูุชุฑู ฺฉุชุงุจุง ุชุงุฑุฎู ฺฉู ุชููู ุงุฒ ุฑูุงู  ู ุชุงุฑุฎ ูุณุชุด\n",
            "ูู  ุงู ฺฉุชุงุจ ุฑู ฺูุฏ ุฑูุฒ ูพุด ุดุฑูุน ฺฉุฑุฏู  ุจู ูุธุฑู ฺฉ ุงุฒ ุจูุชุฑู ฺฉุชุงุจุง ุชุงุฑุฎู ฺฉู ุชููู ุงุฒ ุฑูุงู  ู ุชุงุฑุฎ ูุณุชุด\n",
            "ุจุนุถ ุงุฒ ฺฉุชุงุจุง  ุฑู ุจุฏูู ุงูฺฉู ุฏูุจุงุฑู ุจุฎูู ููุช ุงุณูุดูู ุฑู ูุดูู ุชูุงู ูุชู ฺฉุชุงุจ ูุซู ููู ุชู ุฐููุช ูุฑูุฑ ูุดู.  ุฏุฒุฑู ุจุฑุง ูู ุงุฒ ููู ููุนู\n",
            "ุจุนุถ ุงุฒ ฺฉุชุงุจุง  ุฑู ุจุฏูู ุงูฺฉู ุฏูุจุงุฑู ุจุฎูู ููุช ุงุณูุดูู ุฑู ูุดูู ุชูุงู ูุชู ฺฉุชุงุจ ูุซู ููู ุชู ุฐููุช ูุฑูุฑ ูุดู.  ุฏุฒุฑู ุจุฑุง ูู ุงุฒ ููู ููุนู\n",
            "ุงููู  ู ฺฉ ุงุฒ ุฒุจุงุชุฑู ุฑูุงู ูุง ฺฉู ุฎููุฏู\n",
            "ุงููู  ู ฺฉ ุงุฒ ุฒุจุงุชุฑู ุฑูุงู ูุง ฺฉู ุฎููุฏู\n",
            "ุงู ฺฉุชุงุจ ฺฉ ุงุฒ ุจูุชุฑู ฺฉุชุงุจูุงุณุช ฺฉู ุชุงุฑุฎ ู ุฏุงุณุชุงู ุฑู ุฏุฑ ฺฉ ูุงูุจ ุจู ุฎูุงููุฏู ูุฏูุฏ. ูุงุฌุฑุง ุนุดู ู ูุฑุงุฒ ู ูุดุจ ูุง ุฒูุฏฺฏ ุฏุฒุฑู ูู ุฑู ุฏุฑฺฏุฑ ุฎูุฏุด ฺฉุฑุฏ ู ุจุณุงุฑ ุงุฒ ูุชู ฺฉุชุงุจ ูุฐุช ุจุฑุฏู. \n",
            "ุงู ฺฉุชุงุจ ฺฉ ุงุฒ ุจูุชุฑู ฺฉุชุงุจูุงุณุช ฺฉู ุชุงุฑุฎ ู ุฏุงุณุชุงู ุฑู ุฏุฑ ฺฉ ูุงูุจ ุจู ุฎูุงููุฏู ูุฏูุฏ. ูุงุฌุฑุง ุนุดู ู ูุฑุงุฒ ู ูุดุจ ูุง ุฒูุฏฺฏ ุฏุฒุฑู ูู ุฑู ุฏุฑฺฏุฑ ุฎูุฏุด ฺฉุฑุฏ ู ุจุณุงุฑ ุงุฒ ูุชู ฺฉุชุงุจ ูุฐุช ุจุฑุฏู. \n",
            "ูุงู ูุดุฑ ุงูู ุจูุชุฑู .ุงูู ุชุฑุฌูู ุฑู ุจุฎููู\n",
            "ูุงู ูุดุฑ ุงูู ุจูุชุฑู .ุงูู ุชุฑุฌูู ุฑู ุจุฎููู\n",
            "ุนุงู ู ุจ ูุธุฑ ุจูุฏ ูู ฺฉุชุงุจ ุจูฺฉู ุฎูุฏ ุฏุฒุฑู ุชุตูุฑ ฺฉูุฏ ู ุฒู ุฏู ูุฑุฏ ุชู ุฒูุฏฺฏุด ูุฑุงุฑ ฺฏุฑูุชู ฺฉู ูุฑ ุฏู ุจู ุณูุทูุช ุฑุณุฏู!!\n",
            "ุงู ููุท ุชู ูุตู ูุง ููฺฉูู ุงูุง ุฏุฒุฑู ูุงูุน ุจูุฏ.\n",
            "ุจุฎููุฏ ู ุงุฒ ุงูู ุฑู ุณฺฉู ูุงูพูุฆูู ุจูุงูพุงุฑุช ุขฺฏุงู ุจุดุฏ.\n",
            "ููู ุงูุนุงุฏู ุจูุฏ ูู ุฎู ูุฐุช ุจุฑุฏู.\n",
            "ุนุงู ู ุจ ูุธุฑ ุจูุฏ ูู ฺฉุชุงุจ ุจูฺฉู ุฎูุฏ ุฏุฒุฑู ุชุตูุฑ ฺฉูุฏ ู ุฒู ุฏู ูุฑุฏ ุชู ุฒูุฏฺฏุด ูุฑุงุฑ ฺฏุฑูุชู ฺฉู ูุฑ ุฏู ุจู ุณูุทูุช ุฑุณุฏู!!\n",
            "ุงู ููุท ุชู ูุตู ูุง ููฺฉูู ุงูุง ุฏุฒุฑู ูุงูุน ุจูุฏ.\n",
            "ุจุฎููุฏ ู ุงุฒ ุงูู ุฑู ุณฺฉู ูุงูพูุฆูู ุจูุงูพุงุฑุช ุขฺฏุงู ุจุดุฏ.\n",
            "ููู ุงูุนุงุฏู ุจูุฏ ูู ุฎู ูุฐุช ุจุฑุฏู.\n",
            "ูู ูุณุฎู ฺุงูพ ุฑู ุฏุงุฑู. ูุงูุนุง ุนุงู ู ูุฌุงู ุงูฺฏุฒู. ุจุฎุตูุต ุงูฺฉู ุฏุงุฑ ุงุฒ ูุณูุช ุงุฒ ุชุงุฑุฎ ูุทูุน ูุด. ุจุฏุชุฑู ูุณูุชุด ุฑูุง ฺฉุฑุฏู ููุณุฑุด ุจุฑุง ฺูุฏู ุณุงูู ุจุฎุงุทุฑ ุฎุงููุงุฏุด ุจู ุณูุฆุฏ ููุฑู ู ููุณุฑ ู ูุฑุฒูุฏุด ุฑู ุฑูุง ูฺฉูู!!! ุฏูู ูุฎุงุณุช ุฌุง ุงูู ฺฏุฑู ูฺฉุฑุฏู\n",
            "ูู ูุณุฎู ฺุงูพ ุฑู ุฏุงุฑู. ูุงูุนุง ุนุงู ู ูุฌุงู ุงูฺฏุฒู. ุจุฎุตูุต ุงูฺฉู ุฏุงุฑ ุงุฒ ูุณูุช ุงุฒ ุชุงุฑุฎ ูุทูุน ูุด. ุจุฏุชุฑู ูุณูุชุด ุฑูุง ฺฉุฑุฏู ููุณุฑุด ุจุฑุง ฺูุฏู ุณุงูู ุจุฎุงุทุฑ ุฎุงููุงุฏุด ุจู ุณูุฆุฏ ููุฑู ู ููุณุฑ ู ูุฑุฒูุฏุด ุฑู ุฑูุง ูฺฉูู!!! ุฏูู ูุฎุงุณุช ุฌุง ุงูู ฺฏุฑู ูฺฉุฑุฏู\n",
            "ุณูุงู. ุงู ฺฉุชุงุจ ฺฉ ุดุงูฺฉุงุฑ ุจ ูุธุฑ ุงุฏุจ ู ุชุงุฑุฎ ุณุช . ุจุฎููุฏ ุญุชูุง\n",
            "ุณูุงู. ุงู ฺฉุชุงุจ ฺฉ ุดุงูฺฉุงุฑ ุจ ูุธุฑ ุงุฏุจ ู ุชุงุฑุฎ ุณุช . ุจุฎููุฏ ุญุชูุง\n",
            "ุจุณุงุฑ ุฒุจุง ุจูุฏ.ูพุดููุงุฏ ูฺฉูู ุจุฎููุฏ\n",
            "ุจุณุงุฑ ุฒุจุง ุจูุฏ.ูพุดููุงุฏ ูฺฉูู ุจุฎููุฏ\n",
            "ุจ ููุงุช ุฒุจุงฺฉ ุดุงูฺฉุงุฑุจ ูุธุฑุงุฏุจ ุชุฑุฌูู ุงุด ูู ุฎู ุฎูุจู ุงุฒุฏุณุชุด ูุฏู ุฏูุณุชุงู๐\n",
            "ุจ ููุงุช ุฒุจุงฺฉ ุดุงูฺฉุงุฑุจ ูุธุฑุงุฏุจ ุชุฑุฌูู ุงุด ูู ุฎู ุฎูุจู ุงุฒุฏุณุชุด ูุฏู ุฏูุณุชุงู\n",
            "ฺฉุชุงุจ ุฎูุจ ุจูุฏ .ุฌุฐุงุจุช ุฎุงุต ุฏุงุดุช ูู ู ุงุดฺฉุงู ฺฉู ุฏุงุดุช ุงู ุจูุฏ ฺฉ ุจุนุถ ูุณูุชุงุด ุจุด ุงุฒ ุงูุฏุงุฒู ุจู ูุณุงู ุณุงุณ ู ูุธุงู ูพุฑ ู ุจุงู ุฏุงุฏู ุจูุฏ ู ุงุฒ ุงุตู ุฏุงุณุชุงู ุฏูุฑ ูุดุฏ.ุงู ูุณูุชุง ู ุฎูุฑุฏู ฺฉุณู ฺฉููุฏู ุจูุฏ.ูู ุฏุฑ ฺฉู ุฎููุฏูุด ุงุฑุฒุด ุฏุงุฑู :)\n",
            "ฺฉุชุงุจ ุฎูุจ ุจูุฏ .ุฌุฐุงุจุช ุฎุงุต ุฏุงุดุช ูู ู ุงุดฺฉุงู ฺฉู ุฏุงุดุช ุงู ุจูุฏ ฺฉ ุจุนุถ ูุณูุชุงุด ุจุด ุงุฒ ุงูุฏุงุฒู ุจู ูุณุงู ุณุงุณ ู ูุธุงู ูพุฑ ู ุจุงู ุฏุงุฏู ุจูุฏ ู ุงุฒ ุงุตู ุฏุงุณุชุงู ุฏูุฑ ูุดุฏ.ุงู ูุณูุชุง ู ุฎูุฑุฏู ฺฉุณู ฺฉููุฏู ุจูุฏ.ูู ุฏุฑ ฺฉู ุฎููุฏูุด ุงุฑุฒุด ุฏุงุฑู :)\n",
            "ุงู ฺฉุชุงุจ ูุญุดุฑู ููู ุงูุนุงุฏู ุงุณุช ุญุชูุงุจุฎููุฏ ุงุฑุฒุด ุฎุฑุฏู ูุฏุงุฑู๐๐๐๐๐\n",
            "ุงู ฺฉุชุงุจ ูุญุดุฑู ููู ุงูุนุงุฏู ุงุณุช ุญุชูุงุจุฎููุฏ ุงุฑุฒุด ุฎุฑุฏู ูุฏุงุฑู\n",
            "ฺฉุชุงุจ ุฏุฒุฑู ุชู ฺฉุชุงุจุฑุงู ุฑุงฺฏุงูู\n",
            "ฺฉุชุงุจ ุฏุฒุฑู ุชู ฺฉุชุงุจุฑุงู ุฑุงฺฏุงูู\n",
            "ูู ฺฉุชุงุจ ู ูู ูููุด ุนุงูู...๐๐ผ๐ููููู ุทุงูฺู\n",
            "ูู ฺฉุชุงุจ ู ูู ูููุด ุนุงูู...ููููู ุทุงูฺู\n",
            "ฺฉุชุงุจ ููู ุงูุนุงุฏู ุงู ฺฉุณ ุชู ุงู ุณุจฺฉ ู ุชููู ฺฉุชุงุจ ูุนุฑู ฺฉููุุุ\n",
            "ฺฉุชุงุจ ููู ุงูุนุงุฏู ุงู ฺฉุณ ุชู ุงู ุณุจฺฉ ู ุชููู ฺฉุชุงุจ ูุนุฑู ฺฉููุุุ\n",
            "ุงู ฺฉุชุงุจ ุนุงูู . ูุฎุตูุตุง ุงู ฺฉู ูุงูุนู . ูุณุฎู  ฺุงูพ ุงุด 2 ุฌูุฏ ูุณุชุด ฺฉู ุญุฏูุฏ 900 ุชุง 1000 ุตูุญู ุงุณุช ูู ุงุฑุฒุด ุฎููุฏู ุฑู ุฏุงุฑู ู ุง ุญุช ุจุด ุชุฑ. ุงูฺฉู ูุงูพูุฆูู ุจุง ุฎุฑู ุณุฑ ุงู ุจูุง ูุง ุฑู ุณุฑู ุฎูุฏุด ูุงุฑู ุงููุฒูุฏู ุงุณุช ู ุงู ฺฉู ุฏุฒุฑู ูพุง ุนุดูุด ุนู ุจุฑูุงุฏูุช ููููู ุญุช ุจุง ุงูฺฉู ุฏุฑ ฺฉุดูุฑ ูุง ุฌุฏุง  ุฒูุฏฺฏ ูฺฉุฑุฏู ูู ุชุญุณู ุจุฑ ุงูฺฏุฒู .\n",
            "ุงู ฺฉุชุงุจ ุนุงูู . ูุฎุตูุตุง ุงู ฺฉู ูุงูุนู . ูุณุฎู  ฺุงูพ ุงุด 2 ุฌูุฏ ูุณุชุด ฺฉู ุญุฏูุฏ 900 ุชุง 1000 ุตูุญู ุงุณุช ูู ุงุฑุฒุด ุฎููุฏู ุฑู ุฏุงุฑู ู ุง ุญุช ุจุด ุชุฑ. ุงูฺฉู ูุงูพูุฆูู ุจุง ุฎุฑู ุณุฑ ุงู ุจูุง ูุง ุฑู ุณุฑู ุฎูุฏุด ูุงุฑู ุงููุฒูุฏู ุงุณุช ู ุงู ฺฉู ุฏุฒุฑู ูพุง ุนุดูุด ุนู ุจุฑูุงุฏูุช ููููู ุญุช ุจุง ุงูฺฉู ุฏุฑ ฺฉุดูุฑ ูุง ุฌุฏุง  ุฒูุฏฺฏ ูฺฉุฑุฏู ูู ุชุญุณู ุจุฑ ุงูฺฏุฒู .\n",
            "ฺฉุชุงุจ ุนุงูู. ุงูฺฉู ููุงุน ุชุงุฑุฎ ุฑู ุงุฒ ู ุฒุงูู  ุฏฺฏู ู ุงุฒ ุจุนุฏ ุนุงุทู ุงูููุง ุจุจู ูุงูุนุง ุฌุฐุงุจู. ู ุงูฺฉู ูุงูพูุฆูู ุจูุงูพุงุฑุช ุจุง ุงูู ุฏุฑุฌู ุงุฒ ูุฏุฑุช ู ุซุฑูุช ุฏุฑ ุฌูุงู ุชู ฺู ููุฑ ูุญุดุชูุงฺฉ ุฏุณุช ู ูพุง ูุฒุฏู ู ุจุง ุชูุงุด ุฎู ุฒุงุฏ ุจู ููฺูู ุฌุงฺฏุงู ุฑุณุฏู ุญุฑุช ุงูฺฏุฒู. ุงุฒ ุทุฑู ุฏฺฏู ุงูฺฉู ุฒู ูุง ุจุง ุงูฺฉู ูุฑฺฏุฒ ุชู ุฌูฺฏ ูุง ู ูุดฺฉุฑฺฉุด ูุง ุญุถูุฑ ูุฏุงุดุชู ูู ุฏุฑ ูพุดุช ุตุญูู ุจู ูุฏุฑ ููุด ูุง ูพุฑุฑูฺฏ ุงูุง ฺฉุฑุฏู ฺฉู ฺู ุจุณุง ุณุฑููุดุช ฺฉุดูุฑูุงุฑู ุจุด ุงุฒ ุฌูฺฏ ุชููุณุชู ุชุบุฑ ุจุฏู.\n",
            "ฺฉุชุงุจ ุนุงูู. ุงูฺฉู ููุงุน ุชุงุฑุฎ ุฑู ุงุฒ ู ุฒุงูู  ุฏฺฏู ู ุงุฒ ุจุนุฏ ุนุงุทู ุงูููุง ุจุจู ูุงูุนุง ุฌุฐุงุจู. ู ุงูฺฉู ูุงูพูุฆูู ุจูุงูพุงุฑุช ุจุง ุงูู ุฏุฑุฌู ุงุฒ ูุฏุฑุช ู ุซุฑูุช ุฏุฑ ุฌูุงู ุชู ฺู ููุฑ ูุญุดุชูุงฺฉ ุฏุณุช ู ูพุง ูุฒุฏู ู ุจุง ุชูุงุด ุฎู ุฒุงุฏ ุจู ููฺูู ุฌุงฺฏุงู ุฑุณุฏู ุญุฑุช ุงูฺฏุฒู. ุงุฒ ุทุฑู ุฏฺฏู ุงูฺฉู ุฒู ูุง ุจุง ุงูฺฉู ูุฑฺฏุฒ ุชู ุฌูฺฏ ูุง ู ูุดฺฉุฑฺฉุด ูุง ุญุถูุฑ ูุฏุงุดุชู ูู ุฏุฑ ูพุดุช ุตุญูู ุจู ูุฏุฑ ููุด ูุง ูพุฑุฑูฺฏ ุงูุง ฺฉุฑุฏู ฺฉู ฺู ุจุณุง ุณุฑููุดุช ฺฉุดูุฑูุงุฑู ุจุด ุงุฒ ุฌูฺฏ ุชููุณุชู ุชุบุฑ ุจุฏู.\n",
            "ฺฉุชุงุจ ุฎูุจ ู ุชุงุซุฑ ฺฏุฐุงุฑ ุจูุฏ.\n",
            "ููููู.\n",
            "ฺฉุชุงุจ ุฎูุจ ู ุชุงุซุฑ ฺฏุฐุงุฑ ุจูุฏ.\n",
            "ููููู.\n",
            "ุฏูุณุชุงู ุฏุฑ ููุฑุฏ ููุช ฺฉุชุงุจุง ุจ ุงูุตุงู ูฺฉูุฏ ุฏฺฏู.. \n",
            "ููุช ูุง ูุงูุนุง ูุนููู ู ููุงุณุจ ู.. \n",
            "ูุชููู ุจุฑุง ุงุทููุงู ฺฉ ุณุฑ ุจู ุจุฑูุงูู ูุง ูุดุงุจู ุจุฒูู ุง ุงูฺฉู ุงูู  ุงุฒ ุญุฌู ฺฉุชุงุจ ูุง ู ููุช ูุณุฎู ูุง ฺุงูพุดูู ูุทูุน ุจุดุฏ.. ุจุง ุชุดฺฉุฑ :)\n",
            "ุฏูุณุชุงู ุฏุฑ ููุฑุฏ ููุช ฺฉุชุงุจุง ุจ ุงูุตุงู ูฺฉูุฏ ุฏฺฏู.. \n",
            "ููุช ูุง ูุงูุนุง ูุนููู ู ููุงุณุจ ู.. \n",
            "ูุชููู ุจุฑุง ุงุทููุงู ฺฉ ุณุฑ ุจู ุจุฑูุงูู ูุง ูุดุงุจู ุจุฒูู ุง ุงูฺฉู ุงูู  ุงุฒ ุญุฌู ฺฉุชุงุจ ูุง ู ููุช ูุณุฎู ูุง ฺุงูพุดูู ูุทูุน ุจุดุฏ.. ุจุง ุชุดฺฉุฑ :)\n",
            "ูุงุจู ุชูุฌู ุจุฑุฎ ุฏูุณุชุงู ฺฉู ูฺฏู ููุช ฺฉุชุงุจ ฺฏุฑูููุ ุงู ฺฉุชุงุจ ุจุดุชุฑ ุงุฒ ูงูู ุตูุญู ุงุณุช ู ุฏุฑ ุงุตู ุฏู ุฌูุฏู ู ููุช ูุณุฎู ฺุงูพุด ูฃู-ูคู ูุฒุงุฑ ุชููููุ ุชู ููู ุฌุง ฺฉุชุงุจุง ูขูู-ูฃูู ุตูุญู ุง ูุณุช ฺฉู ูคููู-ูฅููู ุชููู ููุชุดููู ู ุจุง ุชูุฌู ุจู ุงู ููุถูุน ุจู ูุธุฑู ููุช ฺฉุชุงุจ ูุนููู ู ููุตูุงูู ุงุณุชุ ุฏุฑ ุถูู ฺฉุชุงุจุด ููู ุงูุนุงุฏุณุชุ ุชุฑุฌูู ุฎู ุฎูุจ ูู ุฏุงุฑูุ ูู ฺฉู ฺฉูุด ุฑู ูฃ-ูค ุฑูุฒู ุชููู ฺฉุฑุฏูุ ูุฎููุฏู ุงุฒ ุฏุณุชุด ูุฏู\n",
            "ูุงุจู ุชูุฌู ุจุฑุฎ ุฏูุณุชุงู ฺฉู ูฺฏู ููุช ฺฉุชุงุจ ฺฏุฑูููุ ุงู ฺฉุชุงุจ ุจุดุชุฑ ุงุฒ ูงูู ุตูุญู ุงุณุช ู ุฏุฑ ุงุตู ุฏู ุฌูุฏู ู ููุช ูุณุฎู ฺุงูพุด ูฃู-ูคู ูุฒุงุฑ ุชููููุ ุชู ููู ุฌุง ฺฉุชุงุจุง ูขูู-ูฃูู ุตูุญู ุง ูุณุช ฺฉู ูคููู-ูฅููู ุชููู ููุชุดููู ู ุจุง ุชูุฌู ุจู ุงู ููุถูุน ุจู ูุธุฑู ููุช ฺฉุชุงุจ ูุนููู ู ููุตูุงูู ุงุณุชุ ุฏุฑ ุถูู ฺฉุชุงุจุด ููู ุงูุนุงุฏุณุชุ ุชุฑุฌูู ุฎู ุฎูุจ ูู ุฏุงุฑูุ ูู ฺฉู ฺฉูุด ุฑู ูฃ-ูค ุฑูุฒู ุชููู ฺฉุฑุฏูุ ูุฎููุฏู ุงุฒ ุฏุณุชุด ูุฏู\n",
            "ูู ุงู ฺฉุชุงุจ ุฑู ุฎููุฏู ูููุด ุฑู ูู ุฏุฏู ุนุงูู.ูุฎูุงุณุชู  ุจุงุฑ ุฏฺฏู ูู ุจุฎููู ูู ุฎู ฺฏุฑููู ุชุฑุฌุญ ูุฏู ุจู ูููู ฺฉุจุงุฑ ฺฉู ุฎููุฏู ุงฺฉุชูุง ฺฉูู\n",
            "ูู ุงู ฺฉุชุงุจ ุฑู ุฎููุฏู ูููุด ุฑู ูู ุฏุฏู ุนุงูู.ูุฎูุงุณุชู  ุจุงุฑ ุฏฺฏู ูู ุจุฎููู ูู ุฎู ฺฏุฑููู ุชุฑุฌุญ ูุฏู ุจู ูููู ฺฉุจุงุฑ ฺฉู ุฎููุฏู ุงฺฉุชูุง ฺฉูู\n",
            "ุฎู ฺฏุฑููู ุชุฑุฌุญ ูุฏู ูุณุฎู ุงุตู ุจุฎุฑู\n",
            "ุฎู ฺฏุฑููู ุชุฑุฌุญ ูุฏู ูุณุฎู ุงุตู ุจุฎุฑู\n",
            "ฺฉู ฺฏุฑูู ูุณุชุ\n",
            "ฺฉู ฺฏุฑูู ูุณุชุ\n",
            "ูู ุงู ฺฉุชุงุจ ุฑู ุฎููุฏู ุงูุจุชู ุจุง ุชุฑุฌูู ูพุฒุดฺฉุฒุงุฏ ฺฉู ููู ุงูุนุงุฏู ุจูุฏ\n",
            "ูู ุงู ฺฉุชุงุจ ุฑู ุฎููุฏู ุงูุจุชู ุจุง ุชุฑุฌูู ูพุฒุดฺฉุฒุงุฏ ฺฉู ููู ุงูุนุงุฏู ุจูุฏ\n",
            "ุนฺฉุณ ุฑู ุฌูุฏ ุจุงุฏ ุฎุงูู ุฌู ุณูููุฒ ุจุงุดู.\n",
            "ุนฺฉุณ ุฑู ุฌูุฏ ุจุงุฏ ุฎุงูู ุฌู ุณูููุฒ ุจุงุดู.\n",
            "ุฏูุณุชุงู ฺฉุณ ุงุทูุงุน ุฏุงุฑู ฺฉู ุงุณู ุฎุงููู ฺฉู ุชุตูุฑ ุฌูุฏ ุงู ุฑูุงู ูุณุชุด ฺูุ\n",
            "ุฏูุณุชุงู ฺฉุณ ุงุทูุงุน ุฏุงุฑู ฺฉู ุงุณู ุฎุงููู ฺฉู ุชุตูุฑ ุฌูุฏ ุงู ุฑูุงู ูุณุชุด ฺูุ\n",
            "ูู ฺฉุชุงุจ ุฏุฒุฑู ุฑูุฏุงุฑู ุชุง ุงูุงู ุณู ุจุงุฑ ุฎููุฏูุด.ุจ ูุธุฑู ูุงูฺฉู ุฏุงุณุชุงูุด ูุงูุนู ุจุดุชุฑ ุงุฏูู ูุฌุฐูุจ ูฺฉูู.ุญุชูุง ุจุฎููุฏ.\n",
            "ูู ฺฉุชุงุจ ุฏุฒุฑู ุฑูุฏุงุฑู ุชุง ุงูุงู ุณู ุจุงุฑ ุฎููุฏูุด.ุจ ูุธุฑู ูุงูฺฉู ุฏุงุณุชุงูุด ูุงูุนู ุจุดุชุฑ ุงุฏูู ูุฌุฐูุจ ูฺฉูู.ุญุชูุง ุจุฎููุฏ.\n",
            "ุจูุชุฑู ฺฉุชุงุจ ฺฉู ุฎููุฏู\n",
            "ุจูุชุฑู ฺฉุชุงุจ ฺฉู ุฎููุฏู\n",
            "ุนุงู ู ููู ุงูุนุงุฏู ๐๐๐\n",
            "ุนุงู ู ููู ุงูุนุงุฏู \n",
            "ฺฉ ุงุฒ ุจูุชุฑุฑุฑู ฺฉุชุงุจุง ฺฉ ุฎููุฏู\n",
            "ูุฑุณ ุงุฒ ูุชุฑุฌู ฺฉุงุฑุด ุนุงู ุจูุฏ\n",
            "\"ูฺ ฺุฒ ูุงูุน ุชุฑ ุงุฒ ูฺ ูุณุช\"\n",
            "ฺฉ ุงุฒ ุจูุชุฑุฑุฑู ฺฉุชุงุจุง ฺฉ ุฎููุฏู\n",
            "ูุฑุณ ุงุฒ ูุชุฑุฌู ฺฉุงุฑุด ุนุงู ุจูุฏ\n",
            "\"ูฺ ฺุฒ ูุงูุน ุชุฑ ุงุฒ ูฺ ูุณุช\"\n",
            "ูุงููู ู ูุฑุฏ ุนุจุงุฑุช ุงุณุช ุงุฒ ฺฉ ฺฏูุชฺฏู ุฏุฑููู ุฌุณุชุฌูฺฏุฑุงูู ุฏุฑ ุงุนูุงู ุฑูุญ ู ุฑูุชุงุฑ ุ ุฏุฑ ูุงูพุณู ูุญุธุงุช ุฒูุฏฺฏ ุจุง ฺฉ ููฺู ุขฺฏุงู ุงุฒ ุฒูุงู ูุฑฺฏ ... ุฑุงู ุชุง ุญุฏูุฏ ุบุฑูุงุจู ุงุนุชูุงุฏ ุงุณุช ุ ุดุงุฏ ุจู ุฏูู ุถุนู ุฏุฑ ูพุฐุฑุด ู ูุถู ูููุนุช ุงุด ุฏุฑ ุฒูุฏฺฏ. ูพูฺ ฺฏุฑุงู ุงู ุงุซุฑ ฺฉู ุชุง ุญุฏูุฏ ุจู ุงูุจุฒูุฑุฏ ู ุฒูุฏ ุฌุฒ ููุงู ู ุจููุฏฺฏ ฺุฒ ุจู ุฎูุงููุฏู ุณุงุทุน ูู ฺฉูุฏ. ููุงู ููุงู ฺฉู ุฎูุฏู ุฑุงู ูู ุจุงุฒฺฏู ู ฺฉูุฏ ู ุงุฒ ุขู ุฏู ู ุฒูุฏ ู ุชุงุญุฏูุฏ ุชุณููุด ูุดูุฏ. ุฌูุงู ุฑุงู ุ ุฌูุงู ุณุช ุจ ุฑูฺฏ ู ุจ ูุฏู ฺฉู ูู ุฏฺฏุฑ ุดุงุฏ ุจุฑุงุด ุงููุช ุฏุงุฑุฏ ู ูู ุฎุดู. ุชููุง ุจู ุตุฑู ฺฏุฐุฑุงู ูุญุธุงุชุด ุชุตูู ุจู ุงูุฌุงู ฺฉุงุฑูุง ู ฺฏุฑุฏ ุชุง ุจุง ุฎูุฏู ูุดูุงุฎุชู ุงุด ฺฉููุฌุงุฑ ุจุฑูุฏ.\n",
            "ูุงููู ู ูุฑุฏ ุนุจุงุฑุช ุงุณุช ุงุฒ ฺฉ ฺฏูุชฺฏู ุฏุฑููู ุฌุณุชุฌูฺฏุฑุงูู ุฏุฑ ุงุนูุงู ุฑูุญ ู ุฑูุชุงุฑ ุ ุฏุฑ ูุงูพุณู ูุญุธุงุช ุฒูุฏฺฏ ุจุง ฺฉ ููฺู ุขฺฏุงู ุงุฒ ุฒูุงู ูุฑฺฏ ... ุฑุงู ุชุง ุญุฏูุฏ ุบุฑูุงุจู ุงุนุชูุงุฏ ุงุณุช ุ ุดุงุฏ ุจู ุฏูู ุถุนู ุฏุฑ ูพุฐุฑุด ู ูุถู ูููุนุช ุงุด ุฏุฑ ุฒูุฏฺฏ. ูพูฺ ฺฏุฑุงู ุงู ุงุซุฑ ฺฉู ุชุง ุญุฏูุฏ ุจู ุงูุจุฒูุฑุฏ ู ุฒูุฏ ุฌุฒ ููุงู ู ุจููุฏฺฏ ฺุฒ ุจู ุฎูุงููุฏู ุณุงุทุน ูู ฺฉูุฏ. ููุงู ููุงู ฺฉู ุฎูุฏู ุฑุงู ูู ุจุงุฒฺฏู ู ฺฉูุฏ ู ุงุฒ ุขู ุฏู ู ุฒูุฏ ู ุชุงุญุฏูุฏ ุชุณููุด ูุดูุฏ. ุฌูุงู ุฑุงู ุ ุฌูุงู ุณุช ุจ ุฑูฺฏ ู ุจ ูุฏู ฺฉู ูู ุฏฺฏุฑ ุดุงุฏ ุจุฑุงุด ุงููุช ุฏุงุฑุฏ ู ูู ุฎุดู. ุชููุง ุจู ุตุฑู ฺฏุฐุฑุงู ูุญุธุงุชุด ุชุตูู ุจู ุงูุฌุงู ฺฉุงุฑูุง ู ฺฏุฑุฏ ุชุง ุจุง ุฎูุฏู ูุดูุงุฎุชู ุงุด ฺฉููุฌุงุฑ ุจุฑูุฏ.\n",
            "ูฺ ุทูุฑ ูุงุจู ุฏุฑฺฉ ูุจูุฏ.\n",
            "ูฺ ุทูุฑ ูุงุจู ุฏุฑฺฉ ูุจูุฏ.\n",
            "ุจูุชุฑู ฺฉุชุงุจ ุฏุฑ ุณุจฺฉ ูููุณู\n",
            "ุจูุชุฑู ฺฉุชุงุจ ุฏุฑ ุณุจฺฉ ูููุณู\n",
            "ุฒุจุง.ุฌุฐุงุจ.ูพุฑฺฉุดุด ู ุชุฑุฌูู ุฎูุจ.\n",
            "ุฒุจุง.ุฌุฐุงุจ.ูพุฑฺฉุดุด ู ุชุฑุฌูู ุฎูุจ.\n",
            "ุจฺฉุช ุดฺฏูุช ุขูุฑู\n",
            "ุจฺฉุช ุดฺฏูุช ุขูุฑู\n",
            "ุนุงูุ ุฎู ุนุงูุ ุจุงุฒ ูู ููููู ุงุฒ ููู ุดูุง\n",
            "ุนุงูุ ุฎู ุนุงูุ ุจุงุฒ ูู ููููู ุงุฒ ููู ุดูุง\n",
            "ฺฉุชุงุจ ุฎู ุฎูุจ ูุณุช\n",
            "ฺฉุชุงุจ ุฎู ุฎูุจ ูุณุช\n",
            "ุงู ุชุฑุฌูู ุฎูุจ ูุณุชุ ูู ฺฉูุช ฺฉุชุงุจ ุนุงููุ ฺฉ ุงุฒ ูุชูุงูุช ุชุฑู ูุง ู ุจูุชุฑู ูุง ุฏูุง ุจฺฉุชูุ ููู ูุญุชูุงุฑู ุงุฒ ูุดุฑ ฺุดูู ุจุง ุนููุงู ููุงูุฏู ุจุง ุชุฑุฌูู  ููุฏ ููุฏ ุชูู ฺฉูุฏุ ฺฉู ููุฏ ู ุชุนููุงุช ูู ุถููุด ูุณุช.\n",
            "ุงู ุชุฑุฌูู ุฎูุจ ูุณุชุ ูู ฺฉูุช ฺฉุชุงุจ ุนุงููุ ฺฉ ุงุฒ ูุชูุงูุช ุชุฑู ูุง ู ุจูุชุฑู ูุง ุฏูุง ุจฺฉุชูุ ููู ูุญุชูุงุฑู ุงุฒ ูุดุฑ ฺุดูู ุจุง ุนููุงู ููุงูุฏู ุจุง ุชุฑุฌูู  ููุฏ ููุฏ ุชูู ฺฉูุฏุ ฺฉู ููุฏ ู ุชุนููุงุช ูู ุถููุด ูุณุช.\n",
            "ุงฺฏุฑ ูุจู ุงุฒ ุงู ฺฉูุงฺฏุฑ ุฑู ุฎููุฏู ุจุงุดุฏ ุงู ฺฉุชุงุจ ฺุฒ ุงุถุงูู ุชุฑ ุงุฒ ุงูู ูุฏุงุฑู.โโ..ฺฉูุงฺฏุฑ ุชฺฉูู ุชุฑ ู ููู ุงูุนุงุฏุณ\n",
            "ุงฺฏุฑ ูุจู ุงุฒ ุงู ฺฉูุงฺฏุฑ ุฑู ุฎููุฏู ุจุงุดุฏ ุงู ฺฉุชุงุจ ฺุฒ ุงุถุงูู ุชุฑ ุงุฒ ุงูู ูุฏุงุฑู.โโ..ฺฉูุงฺฏุฑ ุชฺฉูู ุชุฑ ู ููู ุงูุนุงุฏุณ\n",
            "ุจู ุณูุงู ูุง ุฎูุจ ุฌูุงุจ ูุฏุงุฏ ุณูุงูุงุช ฺฉ ุชู ุฒูุฏฺฏ ูุฑฺฏ ุจุงุฑ ูพุด ุงููุฏู ุดุงุฏ ูู ุฑููุฏ ุฏุงุณุชุงู ุฌุฐุจ ูฺฉุฑุฏ ููู!\n",
            "ฺฉุชุงุจ ฺฉูุงฺฏุฑุด ุฎู ุฌุฐุงุจ ุชุฑู\n",
            "ุจู ุณูุงู ูุง ุฎูุจ ุฌูุงุจ ูุฏุงุฏ ุณูุงูุงุช ฺฉ ุชู ุฒูุฏฺฏ ูุฑฺฏ ุจุงุฑ ูพุด ุงููุฏู ุดุงุฏ ูู ุฑููุฏ ุฏุงุณุชุงู ุฌุฐุจ ูฺฉุฑุฏ ููู!\n",
            "ฺฉุชุงุจ ฺฉูุงฺฏุฑุด ุฎู ุฌุฐุงุจ ุชุฑู\n",
            "ฺฉุชุงุจ ููู ุงูุนุงุฏู ุง ุจูุฏ\n",
            "ฺฉุชุงุจ ููู ุงูุนุงุฏู ุง ุจูุฏ\n",
            "ุจุง ุงู ฺฉู ููุถูุน ฺฉู ุฏุงุณุชุงู ุชูุงูุช ุนูู ุจุง ุนูุงุฏ ูุง ุฏุงุฑู ู ุงูุงู ฺฉุชุงุจ ฺฉู ฺฏุฌ ฺฉููุฏู ุจู ูุธุฑ ูุฑุณู ุงูุง ุฏุฑ ุขุฎุฑ ุจู ูู ุฏุฑุณ ุจุฒุฑฺฏ ุฏุงุฏ ฺูู ุจูุธุฑู ููู  ูุง ุฏุฑ ุฑุงุจุทู ุจุง ุฎุฏุง ฺฉ ุฌุง ูุซู ุงูุง ูโุดู ู ุงูุฏูุงุฑู ฺฉู ูุซู ุงููู ุฑุงู ุฎูุฏููู ุฑู ูพุฏุง ฺฉูู.\n",
            "ุจุง ุงู ฺฉู ููุถูุน ฺฉู ุฏุงุณุชุงู ุชูุงูุช ุนูู ุจุง ุนูุงุฏ ูุง ุฏุงุฑู ู ุงูุงู ฺฉุชุงุจ ฺฉู ฺฏุฌ ฺฉููุฏู ุจู ูุธุฑ ูุฑุณู ุงูุง ุฏุฑ ุขุฎุฑ ุจู ูู ุฏุฑุณ ุจุฒุฑฺฏ ุฏุงุฏ ฺูู ุจูุธุฑู ููู  ูุง ุฏุฑ ุฑุงุจุทู ุจุง ุฎุฏุง ฺฉ ุฌุง ูุซู ุงูุง ูโุดู ู ุงูุฏูุงุฑู ฺฉู ูุซู ุงููู ุฑุงู ุฎูุฏููู ุฑู ูพุฏุง ฺฉูู.\n",
            "ูุซุฑ ุฎูุจ ู ุฏุงุณุชุงู ุฌุฐุงุจ ู ....ูุงูุนุง ุจู ูฺฉุฑ ูุฑู ูุจุฑู ุงุฏูู! ุฏุฑุณุง ุจุฒุฑฺฏ ูุฏู...ุฎู ุฎู ุญู ุฎูุจู!\n",
            "ูุซุฑ ุฎูุจ ู ุฏุงุณุชุงู ุฌุฐุงุจ ู ....ูุงูุนุง ุจู ูฺฉุฑ ูุฑู ูุจุฑู ุงุฏูู! ุฏุฑุณุง ุจุฒุฑฺฏ ูุฏู...ุฎู ุฎู ุญู ุฎูุจู!\n",
            "ฺฉ ุงุฒ ุจูุชุฑู ู ูพุฑูุญุชูุง ุชุฑู ฺฉุชุงุจ ูุง ฺฉู ุชุง ุจู ุญุงู ุฎูุงูุฏู.\n",
            "ฺฉ ุงุฒ ุจูุชุฑู ู ูพุฑูุญุชูุง ุชุฑู ฺฉุชุงุจ ูุง ฺฉู ุชุง ุจู ุญุงู ุฎูุงูุฏู.\n",
            "ุฏุงุณุชุงู ุนุฑูุงู ู ุจุณุงุฑ ุฒุจุง . ูุฑ ฺู ุงุฒ ููุดุชู ูุง ุงู ูุฑุฏ ุชุนุฑู ุดูุฏ ุ ุจุงุฒ ูู ฺฉู ุงุณุช . ูุฑุฏ ฺฉู ุจุฑ ุชูุงู ุจุนุฏ ูุง ุฑูุญุงู ู ููุณู ุงูุณุงู ูุง ูุงููุฑ ู ุฏูุฏ .\n",
            "ุฏุงุณุชุงู ุนุฑูุงู ู ุจุณุงุฑ ุฒุจุง . ูุฑ ฺู ุงุฒ ููุดุชู ูุง ุงู ูุฑุฏ ุชุนุฑู ุดูุฏ ุ ุจุงุฒ ูู ฺฉู ุงุณุช . ูุฑุฏ ฺฉู ุจุฑ ุชูุงู ุจุนุฏ ูุง ุฑูุญุงู ู ููุณู ุงูุณุงู ูุง ูุงููุฑ ู ุฏูุฏ .\n",
            "ุงฺฏู ุฏุฑุณุช ุชุฑุฌูู ูุดุฏ ุดุงุฏ ูุดูฺฏ ุชุฑ ุจูุฏ ุฏุฑ ฺฉู ุจุฏฺฉ ูุจูุฏ\n",
            "ุงฺฏู ุฏุฑุณุช ุชุฑุฌูู ูุดุฏ ุดุงุฏ ูุดูฺฏ ุชุฑ ุจูุฏ ุฏุฑ ฺฉู ุจุฏฺฉ ูุจูุฏ\n",
            "ฺฉุชุงุจ ุงู ฺฏููู ุดุฑูุน ู ุดูุฏ:\n",
            "ฺูุฏ ฺฉููู ุชูุถุญ:\n",
            "ูุชุฑุฌู ุฏุงุณุชุงู ุฑุง ุฏุฑ ุฏู ุฎุท ูู ู ุฏูุฏ:|\n",
            "ุขุฏู ุจู ุนูู ูุชุฑุฌู ู ูุงุดุฑ ุดฺฉ ู ฺฉูู!!!!\n",
            "ฺฉุชุงุจ ุงู ฺฏููู ุดุฑูุน ู ุดูุฏ:\n",
            "ฺูุฏ ฺฉููู ุชูุถุญ:\n",
            "ูุชุฑุฌู ุฏุงุณุชุงู ุฑุง ุฏุฑ ุฏู ุฎุท ูู ู ุฏูุฏ:|\n",
            "ุขุฏู ุจู ุนูู ูุชุฑุฌู ู ูุงุดุฑ ุดฺฉ ู ฺฉูู!!!!\n",
            "ุฏุฑ ุญุงู ุฎููุฏูุดู ๐\n",
            "ุจุงุฒู ูุงู ุทุงูฺู ู ฺฉุชุงุจุงูู ูุฎููู ูู ูุฑู ุงุญูุฏ ุฏูู ุจุฑุงุช ุชูฺฏ ูุดู๐\n",
            "ุฏุฑ ุญุงู ุฎููุฏูุดู \n",
            "ุจุงุฒู ูุงู ุทุงูฺู ู ฺฉุชุงุจุงูู ูุฎููู ูู ูุฑู ุงุญูุฏ ุฏูู ุจุฑุงุช ุชูฺฏ ูุดู\n",
            "ุขูุจุฑ ฺฉุงูู ุงุฒ ููโุชุฑู ููุณูุฏูโูุง ุงฺฏุฒุณุชุงูุณุงูุณู ูุณุชุ ฺฉุณ ฺฉู ุณุงุฑุชุฑ ุฏุฑุจุงุฑู ุจฺฏุงููโุด ูโููุณู ุงูู ุจูุฏู ฺุฌูุฑ ุงุฒ ุตูุช ฺฉุงุฑ ุจฺฉุดู ุชุง ฺุฒ ฺฉู ุฏุฑ ุฐููุด ูุณุช ุฑู ุจู ูุฎุงุทุจโุด ูุดูู ุจุฏูุ ุณูุกุชูุงูู ูู ูุซู ุจฺฏุงูู ู ุทุงุนูู ููุงู ูุฏูโูุง ุงฺฏุฒุณุชุงูุณุงูุณุช ุฑู ุฏูุจุงู ูโฺฉููุ ูุทุนุง ุฏุฑุจุงุฑู ฺฉุงูู ููุดู ูุธุฑ ุฎูุจ ู ุจุฏ ุฏุงุฏ ฺูู ุงุฒ ููโุชุฑู ูุง ุฏุฑ ุงู ุณุจฺฉ ุจูุฏู ู ูุฑ ุจุงุฑ ฺฉู ฺฉุชุงุจโูุงุด ุฑู ุจุฎููุฏ ฺุฒ ุฌุฏุฏ ุฏุฑ ุฑุงุจุทูโ ุจุง ุฏูุง ูุงู ุงุฏ ูโฺฏุฑุฏ.\n",
            "ฺฉุชุงุจโูุง ฺฉุงูู ุฑู ุจุงุฏ ุขูุณุชู ู ุจุง ุชุฃูู ุฎููุฏุ ุงููุฏ ุขุฑูู ฺฉู ุจุชููู ุชฺฉโุชฺฉ ุตุญููโูุง ฺฉู ุชูุตู ูโฺฉูู ุฑู ุชู ุฐููุชูู ุจุณุงุฒุฏ ู ุจุง ุฏุงุณุชุงู ุฌูู ุจุจุฑุฏ.\n",
            "ุขูุจุฑ ฺฉุงูู ุงุฒ ููโุชุฑู ููุณูุฏูโูุง ุงฺฏุฒุณุชุงูุณุงูุณู ูุณุชุ ฺฉุณ ฺฉู ุณุงุฑุชุฑ ุฏุฑุจุงุฑู ุจฺฏุงููโุด ูโููุณู ุงูู ุจูุฏู ฺุฌูุฑ ุงุฒ ุตูุช ฺฉุงุฑ ุจฺฉุดู ุชุง ฺุฒ ฺฉู ุฏุฑ ุฐููุด ูุณุช ุฑู ุจู ูุฎุงุทุจโุด ูุดูู ุจุฏูุ ุณูุกุชูุงูู ูู ูุซู ุจฺฏุงูู ู ุทุงุนูู ููุงู ูุฏูโูุง ุงฺฏุฒุณุชุงูุณุงูุณุช ุฑู ุฏูุจุงู ูโฺฉููุ ูุทุนุง ุฏุฑุจุงุฑู ฺฉุงูู ููุดู ูุธุฑ ุฎูุจ ู ุจุฏ ุฏุงุฏ ฺูู ุงุฒ ููโุชุฑู ูุง ุฏุฑ ุงู ุณุจฺฉ ุจูุฏู ู ูุฑ ุจุงุฑ ฺฉู ฺฉุชุงุจโูุงุด ุฑู ุจุฎููุฏ ฺุฒ ุฌุฏุฏ ุฏุฑ ุฑุงุจุทูโ ุจุง ุฏูุง ูุงู ุงุฏ ูโฺฏุฑุฏ.\n",
            "ฺฉุชุงุจโูุง ฺฉุงูู ุฑู ุจุงุฏ ุขูุณุชู ู ุจุง ุชุฃูู ุฎููุฏุ ุงููุฏ ุขุฑูู ฺฉู ุจุชููู ุชฺฉโุชฺฉ ุตุญููโูุง ฺฉู ุชูุตู ูโฺฉูู ุฑู ุชู ุฐููุชูู ุจุณุงุฒุฏ ู ุจุง ุฏุงุณุชุงู ุฌูู ุจุจุฑุฏ.\n",
            "ฺุฑุง ุจุงุฏ ุชู ูููู ฺูุฏ ุฎุท ุงูู ููุฏูู ุฏุงุณุชุงู ฺฉุงูู ุงุณูพูู ุดูุุ ุฏู ุตูุญู  ุงูู ุฑู ุฎููุฏู ุจุฏูู ุงูฺฉู ูุชูุฌู ุจุงุดู ููุฏูู ุงุณุช. ูฺฉุฑ ฺฉุฑุฏู ุฏุงุณุชุงู ุดุฑูุน ุดุฏู ฺฉู ูู ุฏุฏู ููุดุชู ุงู ุฎูุงุตู  ฺฉู ฺฉุชุงุจ ุจูุฏ!! ุจุนุฏ ูู ฺฉุฑุฏู ุงุฏุงูู  ููุฏูู ุฑู ุฑูุชู ุฏุงุณุชุงู ุฑู ุดุฑูุน ฺฉุฑุฏู ูู ุฏฺฏู ูฺ ุฌุฐุงุจุช ูุงุณู ูุฏุงุฑู ฺูู ูุฏููู ฺ ูุดู ุชูุด..\n",
            "ฺุฑุง ุจุงุฏ ุชู ูููู ฺูุฏ ุฎุท ุงูู ููุฏูู ุฏุงุณุชุงู ฺฉุงูู ุงุณูพูู ุดูุุ ุฏู ุตูุญู  ุงูู ุฑู ุฎููุฏู ุจุฏูู ุงูฺฉู ูุชูุฌู ุจุงุดู ููุฏูู ุงุณุช. ูฺฉุฑ ฺฉุฑุฏู ุฏุงุณุชุงู ุดุฑูุน ุดุฏู ฺฉู ูู ุฏุฏู ููุดุชู ุงู ุฎูุงุตู  ฺฉู ฺฉุชุงุจ ุจูุฏ!! ุจุนุฏ ูู ฺฉุฑุฏู ุงุฏุงูู  ููุฏูู ุฑู ุฑูุชู ุฏุงุณุชุงู ุฑู ุดุฑูุน ฺฉุฑุฏู ูู ุฏฺฏู ูฺ ุฌุฐุงุจุช ูุงุณู ูุฏุงุฑู ฺูู ูุฏููู ฺ ูุดู ุชูุด..\n",
            "ุชุฑุฌูู ุงุตูุง ุฎูุจ ูุจูุฏ. ฺฉุชุงุจ ฺฉุงููุง ุฎุณุชู ฺฉููุฏู ู ูุฒุฎุฑู ุจูุฏ.\n",
            "ุชุฑุฌูู ุงุตูุง ุฎูุจ ูุจูุฏ. ฺฉุชุงุจ ฺฉุงููุง ุฎุณุชู ฺฉููุฏู ู ูุฒุฎุฑู ุจูุฏ.\n",
            "ุงุตูุฃ ุฏูุณุชุด ูุฏุงุดุชู๐ุงููู ููุงุดูุงูู ุง ุจูุฏ ฺฉู ุฎููุฏู ู ุงุฒ ูุฑ ฺ ููุงุดูุงูู ุงุณุช ูุชููุฑ ุดุฏู๐\n",
            "ุงุตูุฃ ุชุฑุฌูู ุฎูุจ ูุจูุฏ ุฎูููููู ุจุฏ ุจูููุฏ๐๐\n",
            "ุจู ุณุฎุช ุชูููุด ฺฉุฑุฏู\n",
            "ุงุตูุฃ ุฏูุณุชุด ูุฏุงุดุชูุงููู ููุงุดูุงูู ุง ุจูุฏ ฺฉู ุฎููุฏู ู ุงุฒ ูุฑ ฺ ููุงุดูุงูู ุงุณุช ูุชููุฑ ุดุฏู\n",
            "ุงุตูุฃ ุชุฑุฌูู ุฎูุจ ูุจูุฏ ุฎูููููู ุจุฏ ุจูููุฏ\n",
            "ุจู ุณุฎุช ุชูููุด ฺฉุฑุฏู\n",
            "ุชุฑุฌูู ุถุนู\n",
            "ุชุฑุฌูู ุถุนู\n",
            "ู ููุงุดูุงููู ฺฉูุชุงู ฺฉู ุจู ูุธุฑ ูู ุจุฑุง ุดุฑูุน ุขุซุงุฑ ฺฉุงูู ู ุขุดูุง ุดุฏู ุจุง ูููุดููุ ุชุง ุญุฏูุฏ ููุงุณุจู.\n",
            "ุชุฑุฌูู ุงูุชุถุงุญู ุฌูุฑ ฺฉู ู ุณุฑ ุฏุงููฺฏ ูุงุฑู ุจุนุฏ ุงุฒ ฺูุฏุจุงุฑ ุฎููุฏู ุจุงุฒูู ููุชูู ุจููู ู ูุฌุจูุฑ ุงุฒุดูู ุฑุฏ ุจุด.ุงุฒ ุฌูุงู ุขู ุงุญูุฏ ุงูุชุธุงุฑ ู ุชุฑุฌูู ุฎูุจ ุฑู ุฏุงุดุชู.(ุงูุจุชู ุงููู ุชุฑุฌูู ุงู ฺฉู ุงุฒ ุงุดูู ูุฎููู ู ููุฏููู ุจูู ุงุดูู ูู ุงูุทูุฑู ุง ูู.)\n",
            "ู ุณุชุงุฑู ฺฉู ูุงุณู ุชุฑุฌูู ฺฉู ฺฉุฑุฏู ฺฉ ุฏฺฏู ุจุฑุง ููุฏูู:|\n",
            "ุชู ููุฏูู ุฏุฑ ฺฉ ุฏู ุจูุฏ ฺฉู ุฏุงุณุชุงู ุฑู ูู ูุฏู ู ูุฐุช ุฎููุฏู ู ุดฺฏูุช ุฒุฏู ุดุฏู ุฑู ุงุฒ ูุง ูฺฏุฑู.ููุฏูู ุฑู ฺฉู ุฎููุฏู ุฏฺฏู ูุฌุงู ูุงุณู ุฎููุฏู ููุงุดูุงูู ูุฏุงุดุชู.ุดูุง ุงฺฏู ุฎูุงุณุชู ุจุฎููู ููุฏูู ุฑู ุจุฒุงุฑู ุงุฎุฑ ุณุฑ.\n",
            "ู ููุงุดูุงููู ฺฉูุชุงู ฺฉู ุจู ูุธุฑ ูู ุจุฑุง ุดุฑูุน ุขุซุงุฑ ฺฉุงูู ู ุขุดูุง ุดุฏู ุจุง ูููุดููุ ุชุง ุญุฏูุฏ ููุงุณุจู.\n",
            "ุชุฑุฌูู ุงูุชุถุงุญู ุฌูุฑ ฺฉู ู ุณุฑ ุฏุงููฺฏ ูุงุฑู ุจุนุฏ ุงุฒ ฺูุฏุจุงุฑ ุฎููุฏู ุจุงุฒูู ููุชูู ุจููู ู ูุฌุจูุฑ ุงุฒุดูู ุฑุฏ ุจุด.ุงุฒ ุฌูุงู ุขู ุงุญูุฏ ุงูุชุธุงุฑ ู ุชุฑุฌูู ุฎูุจ ุฑู ุฏุงุดุชู.(ุงูุจุชู ุงููู ุชุฑุฌูู ุงู ฺฉู ุงุฒ ุงุดูู ูุฎููู ู ููุฏููู ุจูู ุงุดูู ูู ุงูุทูุฑู ุง ูู.)\n",
            "ู ุณุชุงุฑู ฺฉู ูุงุณู ุชุฑุฌูู ฺฉู ฺฉุฑุฏู ฺฉ ุฏฺฏู ุจุฑุง ููุฏูู:|\n",
            "ุชู ููุฏูู ุฏุฑ ฺฉ ุฏู ุจูุฏ ฺฉู ุฏุงุณุชุงู ุฑู ูู ูุฏู ู ูุฐุช ุฎููุฏู ู ุดฺฏูุช ุฒุฏู ุดุฏู ุฑู ุงุฒ ูุง ูฺฏุฑู.ููุฏูู ุฑู ฺฉู ุฎููุฏู ุฏฺฏู ูุฌุงู ูุงุณู ุฎููุฏู ููุงุดูุงูู ูุฏุงุดุชู.ุดูุง ุงฺฏู ุฎูุงุณุชู ุจุฎููู ููุฏูู ุฑู ุจุฒุงุฑู ุงุฎุฑ ุณุฑ.\n",
            "ฺุฑุง ุฏุฑ ููุฏูู ุจุงุฏ ุฏุงุณุชุงู ูู ุฏุงุฏู ุจุดูุ!ุ! ุงุตูุง ุฏุฑฺฉ ููฺฉูู :/\n",
            "ุชุฑุฌูู ุฎู ุงุฑุงุฏ ุฏุงุดุช. ุฎู ุงุฒ ุฌููุงุช ู ฺฉููุงุช ุงุตูุง ุงุฑุชุจุงุท ูุนูุง ููุดุฏ ุจูุดูู ุจุฑูุฑุงุฑ ฺฉุฑุฏ!\n",
            "ู ุงูุจุชู ูู ฺฉุงูู ุฑู ุฏุฑฺฉ ููฺฉูู.. ุงู ุฏุงููฺฏุง ูุงุฑุชุง ฺ ุจูุฏ ุจุนุฏ ุงุฒ ฺฉุดุชู ุจุฑุงุฏุฑุด ุ!ุ! ุจูุธุฑู ุจุงุฏ ุจุฑู ูุชู ุงุตู ุฑู ุฎูุฏู ุจุฎููู. ููุช ุชูู ฺฉุฑุฏู ุจูุฏ\n",
            "ฺุฑุง ุฏุฑ ููุฏูู ุจุงุฏ ุฏุงุณุชุงู ูู ุฏุงุฏู ุจุดูุ!ุ! ุงุตูุง ุฏุฑฺฉ ููฺฉูู :/\n",
            "ุชุฑุฌูู ุฎู ุงุฑุงุฏ ุฏุงุดุช. ุฎู ุงุฒ ุฌููุงุช ู ฺฉููุงุช ุงุตูุง ุงุฑุชุจุงุท ูุนูุง ููุดุฏ ุจูุดูู ุจุฑูุฑุงุฑ ฺฉุฑุฏ!\n",
            "ู ุงูุจุชู ูู ฺฉุงูู ุฑู ุฏุฑฺฉ ููฺฉูู.. ุงู ุฏุงููฺฏุง ูุงุฑุชุง ฺ ุจูุฏ ุจุนุฏ ุงุฒ ฺฉุดุชู ุจุฑุงุฏุฑุด ุ!ุ! ุจูุธุฑู ุจุงุฏ ุจุฑู ูุชู ุงุตู ุฑู ุฎูุฏู ุจุฎููู. ููุช ุชูู ฺฉุฑุฏู ุจูุฏ\n",
            "ฺฉูุงุณฺฉ ู ุฎุงุต ูพุณูุฏ ุจุง ูุถุง ุงุจุฒูุฑุฏ ู ฺฉุงูฺฉุง\n",
            "ุชุฑุฌููโุง ููุชูุจุ ุฏุฑฺฏุฑ ู ุฏุงุฑ ุงูุงูุชุฏุงุฑ\n",
            "ฺฉูุงุณฺฉ ู ุฎุงุต ูพุณูุฏ ุจุง ูุถุง ุงุจุฒูุฑุฏ ู ฺฉุงูฺฉุง\n",
            "ุชุฑุฌููโุง ููุชูุจุ ุฏุฑฺฏุฑ ู ุฏุงุฑ ุงูุงูุชุฏุงุฑ\n",
            "ุฎูุดู ูููุฏ\n",
            "ุฎูุดู ูููุฏ\n",
            "ุชุฑุฌูู ุฎูุจ ูุฏุงุดุช ุงูุง ุจุงุฒ ูู ููุดู ุงุฒ ูุฏุฑุช ฺฉุงูู ฺฏุฐุดุช. ุงฺฏู ุจู ุชุฑุฌูู ุนุงุฏุช ฺฉูุฏ ุฎู ุณุฑุน ุฌุฐุจ ุฏุงุณุชุงู ู ุดุฏ. ููุฏูู ฺฉุชุงุจ ุฑู ูู ุขุฎุฑ ุจุฎููุฏ ุจูุชุฑู ุจู ูุธุฑู. ุญุณ ู ุญุงู ุฏุงุณุชุงู ุจู ุฎุตูุต ุตูุญุงุช ุขุฎุฑ ุทูุฑ ุขุฏู ุฑู ุบุฑู ุฎูุฏุด ูโฺฉูู ฺฉู ุงูฺฏุงุฑ ุชูุงู ุงุชูุงูุงุช ุฑู ุงุฒ ูุฒุฏฺฉ ุชูุงุดุง ฺฉุฑุฏู.\n",
            "ุชุฑุฌูู ุฎูุจ ูุฏุงุดุช ุงูุง ุจุงุฒ ูู ููุดู ุงุฒ ูุฏุฑุช ฺฉุงูู ฺฏุฐุดุช. ุงฺฏู ุจู ุชุฑุฌูู ุนุงุฏุช ฺฉูุฏ ุฎู ุณุฑุน ุฌุฐุจ ุฏุงุณุชุงู ู ุดุฏ. ููุฏูู ฺฉุชุงุจ ุฑู ูู ุขุฎุฑ ุจุฎููุฏ ุจูุชุฑู ุจู ูุธุฑู. ุญุณ ู ุญุงู ุฏุงุณุชุงู ุจู ุฎุตูุต ุตูุญุงุช ุขุฎุฑ ุทูุฑ ุขุฏู ุฑู ุบุฑู ุฎูุฏุด ูโฺฉูู ฺฉู ุงูฺฏุงุฑ ุชูุงู ุงุชูุงูุงุช ุฑู ุงุฒ ูุฒุฏฺฉ ุชูุงุดุง ฺฉุฑุฏู.\n",
            "ุชุฑุฌูู ุงูุชุถุงุญ! ุญุณ ูฺฉูู ุงุตูุง ูุชููุณุช ุงููุทูุฑ ฺฉู ุดุงุฏ ู ุจุงุฏ ููููู ุฑู ุจุฑูุณููู ุฏุฑ ุชุฑุฌูุด ู ุฏุงุณุชุงู ุฑู ฺฉุงููุง ุฎุฑุงุจ ฺฉุฑุฏู!\n",
            "ุงููุด ูู ฺฉู ุชู ููุฏูู ุฏุงุณุชุงู ุฑู ูู ูุฏู! ููุฏููู ูุดฺฉู ุงุฒ ูุงุดุฑ ุจูุฏู ู ุง ููุท ูุชุฑุฌู!\n",
            "ุชุฑุฌูู ุงูุชุถุงุญ! ุญุณ ูฺฉูู ุงุตูุง ูุชููุณุช ุงููุทูุฑ ฺฉู ุดุงุฏ ู ุจุงุฏ ููููู ุฑู ุจุฑูุณููู ุฏุฑ ุชุฑุฌูุด ู ุฏุงุณุชุงู ุฑู ฺฉุงููุง ุฎุฑุงุจ ฺฉุฑุฏู!\n",
            "ุงููุด ูู ฺฉู ุชู ููุฏูู ุฏุงุณุชุงู ุฑู ูู ูุฏู! ููุฏููู ูุดฺฉู ุงุฒ ูุงุดุฑ ุจูุฏู ู ุง ููุท ูุชุฑุฌู!\n",
            "ุงุงุงุงุงุงู ูุณุฎุฑู ุจูุฏ ุงุฒ ฒุฎุท ุงููุดู ูุนููู ุจูุฏ@^_^@\n",
            "ุงุงุงุงุงุงู ูุณุฎุฑู ุจูุฏ ุงุฒ ฒุฎุท ุงููุดู ูุนููู ุจูุฏ@^_^@\n",
            "ฺูุฏ ุตูุญู ุงูู ุนู ุจุนุถ ุงุฒ ุตูุญุงุช ฺฉุชุงุจ ุจฺฏุงูู ููู ููุณูุฏุณ ฺฉู ุงู ุงุชูุงูุงุช ู ูพุฏุงฺฉุฑุฏู ุฑูุฒูุงูู ุฏุฑ ุฏูุฑู ูุญฺฉููุช ูุฑุณู ุดุฎุตุช ุฏุงุณุชุงู ุจฺฏุงูู ุงุณุช\n",
            "ฺูุฏ ุตูุญู ุงูู ุนู ุจุนุถ ุงุฒ ุตูุญุงุช ฺฉุชุงุจ ุจฺฏุงูู ููู ููุณูุฏุณ ฺฉู ุงู ุงุชูุงูุงุช ู ูพุฏุงฺฉุฑุฏู ุฑูุฒูุงูู ุฏุฑ ุฏูุฑู ูุญฺฉููุช ูุฑุณู ุดุฎุตุช ุฏุงุณุชุงู ุจฺฏุงูู ุงุณุช\n",
            "ุงุฒ ูุญุชูุง ู ููุถูุน ุฏุงุณุชุงู ุฎูุดู ุงููุฏ ู ุชุง ูุฏุชูุง ุฐููู ุฏุฑฺฏุฑุด ุจูุฏ ูู  ุฌุงูุง ุงููุฏ ุชุฑุฌูู ูุญุดุชูุงฺฉ ุจูุฏ ฺฉ ุงููุฌุงูุงุฑู ููุฎููุฏู. ุณุชุงุฑู ููุท ุจ ูุญุชูุง\n",
            "ุงุฒ ูุญุชูุง ู ููุถูุน ุฏุงุณุชุงู ุฎูุดู ุงููุฏ ู ุชุง ูุฏุชูุง ุฐููู ุฏุฑฺฏุฑุด ุจูุฏ ูู  ุฌุงูุง ุงููุฏ ุชุฑุฌูู ูุญุดุชูุงฺฉ ุจูุฏ ฺฉ ุงููุฌุงูุงุฑู ููุฎููุฏู. ุณุชุงุฑู ููุท ุจ ูุญุชูุง\n",
            "ุชุฑุฌูู ููุงูุทูุฑ ฺฉู ุฎูุฏ ุฌูุงู ูู ฺฏูุชู ุจูุฏุฺฉู ุณุฎุช ุจูุฏ ุงูุง ูุฐุช ูููุฏูุด ุฌุงู ุงุฏู ุฑุง ุชุงุฒู ูฺฉุฑุฏุููุถูุน ุฏุงุณุชุงู ุฌุฏุฏ ุจูุฏ ุ ุญุชูุง ุจุฎูุงูุฏ\n",
            "ุชุฑุฌูู ููุงูุทูุฑ ฺฉู ุฎูุฏ ุฌูุงู ูู ฺฏูุชู ุจูุฏุฺฉู ุณุฎุช ุจูุฏ ุงูุง ูุฐุช ูููุฏูุด ุฌุงู ุงุฏู ุฑุง ุชุงุฒู ูฺฉุฑุฏุููุถูุน ุฏุงุณุชุงู ุฌุฏุฏ ุจูุฏ ุ ุญุชูุง ุจุฎูุงูุฏ\n",
            "ุฏุงุณุชุงู ุฌุงูุจ . ููุดุชู ูุง ุฎูุจ ุชุง ุงุฎุฑู ุฎููุฏู ูู ูฺุณุจุฏ ุจูู . ุฏูู ูุฎุงุณุช ุตุญูู ูุชูุดู ุจูุชุฑ ุจุงุฒฺฏู ูฺฉุฑุฏ . ฺูุฏุฑู ุงู ุฏุฎุชุฑู ูุงุฏุฑ ุจุงูู ุจุฎูุฏ ุญุฑู ูุฒุฏู ๐๐\n",
            "ุฏุงุณุชุงู ุฌุงูุจ . ููุดุชู ูุง ุฎูุจ ุชุง ุงุฎุฑู ุฎููุฏู ูู ูฺุณุจุฏ ุจูู . ุฏูู ูุฎุงุณุช ุตุญูู ูุชูุดู ุจูุชุฑ ุจุงุฒฺฏู ูฺฉุฑุฏ . ฺูุฏุฑู ุงู ุฏุฎุชุฑู ูุงุฏุฑ ุจุงูู ุจุฎูุฏ ุญุฑู ูุฒุฏู \n",
            "ฺฉ ููุงุดูุงูู ุฎูููุจ...\n",
            "ฺฉ ููุงุดูุงูู ุฎูููุจ...\n",
            "ููุงุดูุงูู ุณูฺฏู ุจูุฏุ ูู ุจู ุฎุงุทุฑ ููุงุน ู ุชุนุฏุฏ ุจุงุฒฺฏุฑูุงุด ฺฉู ุงุชูุงูุง ููู ฺูุฏ ููุฑ ูู ุฒุงุฏ ุจูุฏูุฏ!..ุฏุงุณุชุงู ุบู ุจุณุงุฑ ููุฑุงู ุฎูุฏุด ุฏุงุฑูุ ุบู ฺฉู ููุช ุดุฑุงุท ุจู ุงูุณุงู ุณุฎุช ุจฺฏุฑู ุฒูุฏฺฏ ฺูุฏุฑ ูพูฺ ู ุฎุทุฑูุงฺฉ ูุดู ุจุฑุง ุฎูุฏุด ู ุฏฺฏุฑุงู... ู ฺฉููุงุช ู ููุณูู ุจุงู ุดุฎุตุชูุงุด ูู ูุฑฺู ุชูุงุด ฺฉุฑุฏูุฏ ุงุฒ ุงูุฏูู ู ุจุงุฑ ฺฏูุงู ุฏุงุณุชุงู ฺฉู ฺฉููุฏ ูุดุฏ ฺฉู ูุดุฏ.\n",
            "ุฎูุงุตู ฺฉู ุงุฑุฒุด ุฎููุฏู ุฏุงุดุช ุงูุง ุฑุฏ ุบูุด ุชุง ูุฏุช ููุจ ุขุฏู ุฑู ูฺุงูู ูฺฉูู.\n",
            "ู ููู ูุซู ุฎู ุงุฒ ุฏูุณุชุงู ฺฉุชุงุจุฎูู ฺฉู ฺฉ ฺฉุชุงุจ ุฑู ุงุฒ ุจ ุจุณู ุงููู ุชุง ุชูุด ูุฎููู ุจุง ุฎููุฏู ููุฏูู ฺฉู ุฏุงุณุชุงูุด ุจุฑุงููู ูู ุฑูุชุ ุงูุง ุฌุงูุจู ฺฉู ุจุงุฒ ูู ุจู ูุฏุฑ ฺฉุงู ฺฉุดุด ุฏุงุดุช.\n",
            "ุงูุง ูุทุนุง ุชูุตู ุงู ุงูู ฺฉู ููุฏูู ุงุด ุฑู ูุฎููุฏ!\n",
            "ููุงุดูุงูู ุณูฺฏู ุจูุฏุ ูู ุจู ุฎุงุทุฑ ููุงุน ู ุชุนุฏุฏ ุจุงุฒฺฏุฑูุงุด ฺฉู ุงุชูุงูุง ููู ฺูุฏ ููุฑ ูู ุฒุงุฏ ุจูุฏูุฏ!..ุฏุงุณุชุงู ุบู ุจุณุงุฑ ููุฑุงู ุฎูุฏุด ุฏุงุฑูุ ุบู ฺฉู ููุช ุดุฑุงุท ุจู ุงูุณุงู ุณุฎุช ุจฺฏุฑู ุฒูุฏฺฏ ฺูุฏุฑ ูพูฺ ู ุฎุทุฑูุงฺฉ ูุดู ุจุฑุง ุฎูุฏุด ู ุฏฺฏุฑุงู... ู ฺฉููุงุช ู ููุณูู ุจุงู ุดุฎุตุชูุงุด ูู ูุฑฺู ุชูุงุด ฺฉุฑุฏูุฏ ุงุฒ ุงูุฏูู ู ุจุงุฑ ฺฏูุงู ุฏุงุณุชุงู ฺฉู ฺฉููุฏ ูุดุฏ ฺฉู ูุดุฏ.\n",
            "ุฎูุงุตู ฺฉู ุงุฑุฒุด ุฎููุฏู ุฏุงุดุช ุงูุง ุฑุฏ ุบูุด ุชุง ูุฏุช ููุจ ุขุฏู ุฑู ูฺุงูู ูฺฉูู.\n",
            "ู ููู ูุซู ุฎู ุงุฒ ุฏูุณุชุงู ฺฉุชุงุจุฎูู ฺฉู ฺฉ ฺฉุชุงุจ ุฑู ุงุฒ ุจ ุจุณู ุงููู ุชุง ุชูุด ูุฎููู ุจุง ุฎููุฏู ููุฏูู ฺฉู ุฏุงุณุชุงูุด ุจุฑุงููู ูู ุฑูุชุ ุงูุง ุฌุงูุจู ฺฉู ุจุงุฒ ูู ุจู ูุฏุฑ ฺฉุงู ฺฉุดุด ุฏุงุดุช.\n",
            "ุงูุง ูุทุนุง ุชูุตู ุงู ุงูู ฺฉู ููุฏูู ุงุด ุฑู ูุฎููุฏ!\n",
            "ุฏุงุณุชุงู ุฌุงูุจ ุฏุงุดุช.ูู ุฏุฑ ููุงุช ุนฺฉุณ ุงูุนูู ูุงุฏุฑ ุฑู ุฏุฑฺฉ ูฺฉุฑุฏู(ุจุนุฏ ุงุฒ ุงู ฺฉู ูููุฏ ฺุงู ูพุณุฑุด ุจูุฏู)ุุฏุฑุณุชู ฺฉู ุณุงู ูุง ุฌูุงุช ู ฺฉุฑุฏู ูู ุงุฒ ุตุญุจุช ูุงุด ูุนููู ุจูุฏ ฺฉู ูููุฒ ฺฉู ุงุญุณุงุณ ุชู ูุฌูุฏุด ูุณุช(ุจุฑุฎูุงู ุฏุฎุชุฑุด)ุูู ุจุด ุงุฒ ุงูุฏุงุฒู ุณุฑุฏ ุจุฑุฎูุฑุฏ ฺฉุฑุฏ ุจุนุฏ ุงุฒ ุงูฺฉู ูุชูุฌู ุดุฏ ฺุงู ูพุณุฑุดู.ูุจู ูุธุฑู ุงู ฺฉ ุชูุงูุถ ุชู ุดุฎุตุช ูุงุฏุฑ ุจูุฏ.ู ูฺฉุชู ุฏฺฏู ุงู ฺฉู ฺฉุงุด ู ฺฉู ุฑูุงู ุชุฑ ุชุฑุฌูู ูุดุฏ.ุจู ูุธุฑู ูุชู ุงุตู ููุงุดูุงูู ุฑู ุจุฎููู ุฌุงูุจ ุชุฑ ุจุงุดู.ูู ุฏุฑ ฺฉู ุฎูุจ ุจูุฏ\n",
            "ุฏุงุณุชุงู ุฌุงูุจ ุฏุงุดุช.ูู ุฏุฑ ููุงุช ุนฺฉุณ ุงูุนูู ูุงุฏุฑ ุฑู ุฏุฑฺฉ ูฺฉุฑุฏู(ุจุนุฏ ุงุฒ ุงู ฺฉู ูููุฏ ฺุงู ูพุณุฑุด ุจูุฏู)ุุฏุฑุณุชู ฺฉู ุณุงู ูุง ุฌูุงุช ู ฺฉุฑุฏู ูู ุงุฒ ุตุญุจุช ูุงุด ูุนููู ุจูุฏ ฺฉู ูููุฒ ฺฉู ุงุญุณุงุณ ุชู ูุฌูุฏุด ูุณุช(ุจุฑุฎูุงู ุฏุฎุชุฑุด)ุูู ุจุด ุงุฒ ุงูุฏุงุฒู ุณุฑุฏ ุจุฑุฎูุฑุฏ ฺฉุฑุฏ ุจุนุฏ ุงุฒ ุงูฺฉู ูุชูุฌู ุดุฏ ฺุงู ูพุณุฑุดู.ูุจู ูุธุฑู ุงู ฺฉ ุชูุงูุถ ุชู ุดุฎุตุช ูุงุฏุฑ ุจูุฏ.ู ูฺฉุชู ุฏฺฏู ุงู ฺฉู ฺฉุงุด ู ฺฉู ุฑูุงู ุชุฑ ุชุฑุฌูู ูุดุฏ.ุจู ูุธุฑู ูุชู ุงุตู ููุงุดูุงูู ุฑู ุจุฎููู ุฌุงูุจ ุชุฑ ุจุงุดู.ูู ุฏุฑ ฺฉู ุฎูุจ ุจูุฏ\n",
            "ุฎูุฏ ูุชุฑุฌู ุฏูู ุงู ุฌูุฑ ุชุฑุฌูู ฺฉุฑุฏูุด ุฑู ฺฏูุชูุูู ุจู ูุธุฑู ุงุตูุง ุฎูุจ ุฏุฑ ูููุฏู.ุจู ูุธุฑู ุงฺฏู ุฑููู ุชุฑ ุชุฑุฌูู ูฺฉุฑุฏ ุจูุชุฑ ุงุฒ ุขุจ ุฏุฑ ูููุฏ...\n",
            "ุฎูุฏ ูุชุฑุฌู ุฏูู ุงู ุฌูุฑ ุชุฑุฌูู ฺฉุฑุฏูุด ุฑู ฺฏูุชูุูู ุจู ูุธุฑู ุงุตูุง ุฎูุจ ุฏุฑ ูููุฏู.ุจู ูุธุฑู ุงฺฏู ุฑููู ุชุฑ ุชุฑุฌูู ูฺฉุฑุฏ ุจูุชุฑ ุงุฒ ุขุจ ุฏุฑ ูููุฏ...\n",
            "ุนุงู๐๐ป\n",
            "ุนุงู\n",
            "ูพุดููุงุฏ ูุฏู ูุจู ุงุฒ ุงูฺฉู ุงู ฺฉุชุงุจ ุฑู ุจุฎููุฏ ุงุตูุง ฺฉุชุงุจ ุจฺฏุงูู ู ูพุดฺฏูุชุงุฑ ููู ฺฉุชุงุจ ุฑู ูุฎููุฏ ฺูู ุฏุงุณุชุงู ฺฉุชุงุจ ูู ูโุฑู ู ุจุฑุงุชูู ุจ ูุฒู ูุดู\n",
            "ูพุดููุงุฏ ูุฏู ูุจู ุงุฒ ุงูฺฉู ุงู ฺฉุชุงุจ ุฑู ุจุฎููุฏ ุงุตูุง ฺฉุชุงุจ ุจฺฏุงูู ู ูพุดฺฏูุชุงุฑ ููู ฺฉุชุงุจ ุฑู ูุฎููุฏ ฺูู ุฏุงุณุชุงู ฺฉุชุงุจ ูู ูโุฑู ู ุจุฑุงุชูู ุจ ูุฒู ูุดู\n",
            "ูู ุชุงุฒู ูุฎูุงู ฺฉุชุงุจ ุฑู ุดุฑูุน ฺฉูู. ฺูุฏ ฺฉููู ุชูุถุญ ุฌูุงู ฺฉู ูู ุนุงุดู ูููุด ูุณุชูุ ู ุฌูุฑุง ุฏุงุณุชุงู ุฑู ุงุณูพูู ฺฉุฑุฏ ุจู ูุธุฑู. ุญุงูุง ุจุงุฏ ุดุฑูุน ฺฉุฑุฏ ู ุฏุฏ ุฎูุฏ ุงุซุฑ ฺู! ุฏุฑ ฺฉู ุชูุตู ูฺฉูู ุชูุถุญุงุช ูุชุฑุฌู ุฑู ุจุนุฏ ุงุฒ ุฎููุฏู ฺฉุชุงุจ ุจุฎููุฏ.\n",
            "ูู ุชุงุฒู ูุฎูุงู ฺฉุชุงุจ ุฑู ุดุฑูุน ฺฉูู. ฺูุฏ ฺฉููู ุชูุถุญ ุฌูุงู ฺฉู ูู ุนุงุดู ูููุด ูุณุชูุ ู ุฌูุฑุง ุฏุงุณุชุงู ุฑู ุงุณูพูู ฺฉุฑุฏ ุจู ูุธุฑู. ุญุงูุง ุจุงุฏ ุดุฑูุน ฺฉุฑุฏ ู ุฏุฏ ุฎูุฏ ุงุซุฑ ฺู! ุฏุฑ ฺฉู ุชูุตู ูฺฉูู ุชูุถุญุงุช ูุชุฑุฌู ุฑู ุจุนุฏ ุงุฒ ุฎููุฏู ฺฉุชุงุจ ุจุฎููุฏ.\n",
            "ฺฉุงุด ููุฏูู ุฑู ููุฎููุฏู ุชุง ุงุฎุฑ ุฏุงุณุชุงู ุงู ุงูุณูุณ ููุฑุงู ุจูุฏ ุจ ุนููุงู  ุฏุงุณุชุงู ูุชูุงูุช ู ููุงุดูุงูู ุฎูุจ ุจูุฏ ูู ุจุงู ุชุตูุฑ ูุฏุงุดุช ูู ฺฉุงูฺฏููุง ุนุงู ุจูุฏ ุงุฒู ูุธุฑ\n",
            "ฺฉุงุด ููุฏูู ุฑู ููุฎููุฏู ุชุง ุงุฎุฑ ุฏุงุณุชุงู ุงู ุงูุณูุณ ููุฑุงู ุจูุฏ ุจ ุนููุงู  ุฏุงุณุชุงู ูุชูุงูุช ู ููุงุดูุงูู ุฎูุจ ุจูุฏ ูู ุจุงู ุชุตูุฑ ูุฏุงุดุช ูู ฺฉุงูฺฏููุง ุนุงู ุจูุฏ ุงุฒู ูุธุฑ\n",
            "wow ุนุงู ุจูุฏ\n",
            "wow ุนุงู ุจูุฏ\n",
            "ุดุงูฺฉุงุฑ ุจูุฏ\n",
            "ุดุงูฺฉุงุฑ ุจูุฏ\n",
            "ุงุฒ ุฎุฏุง ุฎูุฏุชุงู ุจุฎูุงูุฏ ฺฉู ุดูุง ุฑุง ููฺูู ุณูฺฏ ฺฉูุฏ ( ุญุฑู ูุง ูุงฺฏูุชู ุ ุณูุก ุชูุงูู ูุง ุ ูุถุงูุช ูุง ุ ุจุฑููุช ุฑุงุจุทู ุ ุงูุฒูุง ุ ูุจูุฏ ุนุดู ) ุ ู ุฏุฑ ุขุฎุฑ ูุฑฺฏ ูพูฺ\n",
            "ุงุฒ ุฎุฏุง ุฎูุฏุชุงู ุจุฎูุงูุฏ ฺฉู ุดูุง ุฑุง ููฺูู ุณูฺฏ ฺฉูุฏ ( ุญุฑู ูุง ูุงฺฏูุชู ุ ุณูุก ุชูุงูู ูุง ุ ูุถุงูุช ูุง ุ ุจุฑููุช ุฑุงุจุทู ุ ุงูุฒูุง ุ ูุจูุฏ ุนุดู ) ุ ู ุฏุฑ ุขุฎุฑ ูุฑฺฏ ูพูฺ\n",
            "ู ุณูุงู\n",
            "ฺุฑุง ุงุฒ ุงู ููุงุดูุงูู ุฏู ุชุง ูุณุชุุ\n",
            "ุจุนุฏ ุงู ุฑุงฺฏุงู ู ุงูู ูพููู\n",
            "ุนู ุจุงูู ูุฑู ูฺฉููุุุ\n",
            "ู ุณูุงู\n",
            "ฺุฑุง ุงุฒ ุงู ููุงุดูุงูู ุฏู ุชุง ูุณุชุุ\n",
            "ุจุนุฏ ุงู ุฑุงฺฏุงู ู ุงูู ูพููู\n",
            "ุนู ุจุงูู ูุฑู ูฺฉููุุุ\n",
            "ุฏุงุณุชุงู ุฎู ุฎูุจ ุฏุงุดุช .ฺฉุงูู ุนุงูู\n",
            "ุฏุงุณุชุงู ุฎู ุฎูุจ ุฏุงุดุช .ฺฉุงูู ุนุงูู\n",
            "ุนุงุงุงุงุงุงู ุฎู ุฏุงุณุชุงู ุฌุงูุจ ุฏุงุดุชู\n",
            "ุนุงุงุงุงุงุงู ุฎู ุฏุงุณุชุงู ุฌุงูุจ ุฏุงุดุชู\n",
            "ูุง ูู ฺฉ ุฎู ุฏูุณุช ุฏุงุดุชู ู ุงุญุชุงุฌ ุฏุงุฑู ฺฉ ุจุงุฑ ุฏฺฏู ุจุฎููู ฺูุฏุฑ ุณุงุฏู ู ูุชูุงูุช. ุฏุฎุชุฑ ู ูุงุฏุฑ ฺูุฏุฑ ุบุฑุจ ุจูุฏูุฏ.\n",
            "ูุง ูู ฺฉ ุฎู ุฏูุณุช ุฏุงุดุชู ู ุงุญุชุงุฌ ุฏุงุฑู ฺฉ ุจุงุฑ ุฏฺฏู ุจุฎููู ฺูุฏุฑ ุณุงุฏู ู ูุชูุงูุช. ุฏุฎุชุฑ ู ูุงุฏุฑ ฺูุฏุฑ ุบุฑุจ ุจูุฏูุฏ.\n",
            "ุฎูุจ ุจูุฏ ๐๐\n",
            "ุฎูุจ ุจูุฏ \n",
            "ุงูฺฉู ุจุนุถ ุงุฒ ุฏูุณุชุงู ูฺฏู ฺฉุดุด ูุฏุงุฑู ุฏููุด ุดุงุฏ ุงูู ฺฉู ุฑูุงู ูุณุช...ุจุนููุงู ฺฉ ููุงุดูุงูู ุฎูุจู ูู ฺฉุงุด ููุฏูู ุฑู ููุฎููุฏู๐\n",
            "ุงูฺฉู ุจุนุถ ุงุฒ ุฏูุณุชุงู ูฺฏู ฺฉุดุด ูุฏุงุฑู ุฏููุด ุดุงุฏ ุงูู ฺฉู ุฑูุงู ูุณุช...ุจุนููุงู ฺฉ ููุงุดูุงูู ุฎูุจู ูู ฺฉุงุด ููุฏูู ุฑู ููุฎููุฏู\n",
            "ุขูุจุฑ ฺฉุงูู ฺูุฑูโุง ูุชูฺฉุฑ ุงุณุช ู ุฏุฑ ยซุณูุกโุชูุงููยป ูุงููุฏ ุฏฺฏุฑ ุขุซุงุฑ ุฎูุฏุ ุชูุงู ุชูุงุด ุฎูุดุชู ุฑุง ุฏุงุฑุฏ ุชุง ุฎูุงููุฏู ุฑุง ุจู ุชูฺฉุฑ ูุงุฏุงุฑุฏ. ุงู ููุงุด ุชฺฉุงูโุฏููุฏู ุฎูู ูโฺฉูุฏ ู ุงุฒ ุฏูู ูุงุฌุฑุง ููุงุดุ ุงูุจูู ุณูุงูุงุช ฺฏููุงฺฏูู ูพุด ูโฺฉุดุฏ: ุฎุงููุงุฏู ู ุฌุงฺฏุงู ุขู ุฑุง ุฒุฑู ุณูุงู ูโุจุฑุฏ. ุฑูุงุจุท ุงูุณุงู ู ุฑูุงูุง ุจุดุฑ ุฑุง ุฒุฑู ุณูุงู ูโุจุฑุฏ. ุฎูุฏู ุจุดุฑ ู ุฎููุงุช ุงู ุฑุง ุฒุฑู ุณูุงู ูโุจุฑุฏ ู ููู ุงููุง ููุงุดูุงูู ุง ุจุณุงุฑ ุชฺฉุงู ุฏููุฏู ู ุณุงุฒุฏ ุ ุฏุฑุจุงุฑู ููู ูุง ุงูุณุงููุง.\n",
            "ุขูุจุฑ ฺฉุงูู ฺูุฑูโุง ูุชูฺฉุฑ ุงุณุช ู ุฏุฑ ยซุณูุกโุชูุงููยป ูุงููุฏ ุฏฺฏุฑ ุขุซุงุฑ ุฎูุฏุ ุชูุงู ุชูุงุด ุฎูุดุชู ุฑุง ุฏุงุฑุฏ ุชุง ุฎูุงููุฏู ุฑุง ุจู ุชูฺฉุฑ ูุงุฏุงุฑุฏ. ุงู ููุงุด ุชฺฉุงูโุฏููุฏู ุฎูู ูโฺฉูุฏ ู ุงุฒ ุฏูู ูุงุฌุฑุง ููุงุดุ ุงูุจูู ุณูุงูุงุช ฺฏููุงฺฏูู ูพุด ูโฺฉุดุฏ: ุฎุงููุงุฏู ู ุฌุงฺฏุงู ุขู ุฑุง ุฒุฑู ุณูุงู ูโุจุฑุฏ. ุฑูุงุจุท ุงูุณุงู ู ุฑูุงูุง ุจุดุฑ ุฑุง ุฒุฑู ุณูุงู ูโุจุฑุฏ. ุฎูุฏู ุจุดุฑ ู ุฎููุงุช ุงู ุฑุง ุฒุฑู ุณูุงู ูโุจุฑุฏ ู ููู ุงููุง ููุงุดูุงูู ุง ุจุณุงุฑ ุชฺฉุงู ุฏููุฏู ู ุณุงุฒุฏ ุ ุฏุฑุจุงุฑู ููู ูุง ุงูุณุงููุง.\n",
            "ูู ุงููู ฺฉุชุงุจ ฺฉู ุฎููุฏู ุงู ฺฉุชุงุจ ุจูุฏ ฺฉู ูุงูุนุง ูุฐุช ุจุฑุฏู ุงุฒ ุฎููุฏูุด ู ุจุงุนุซ ุดุฏ ุจุดุชุฑ ฺฉุชุงุจูุง ฺฉุงูู ุฑู ุจุฎููู ู ููฺูู ุฏฺฏุฑ ููุณูุฏฺฏุงู ุฑู ุจูุชูู ูพุดููุงุฏ ูฺฉูู ุญุชูุง ุจุฎููู\n",
            "ูู ุงููู ฺฉุชุงุจ ฺฉู ุฎููุฏู ุงู ฺฉุชุงุจ ุจูุฏ ฺฉู ูุงูุนุง ูุฐุช ุจุฑุฏู ุงุฒ ุฎููุฏูุด ู ุจุงุนุซ ุดุฏ ุจุดุชุฑ ฺฉุชุงุจูุง ฺฉุงูู ุฑู ุจุฎููู ู ููฺูู ุฏฺฏุฑ ููุณูุฏฺฏุงู ุฑู ุจูุชูู ูพุดููุงุฏ ูฺฉูู ุญุชูุง ุจุฎููู\n",
            "ุฏูุณุชุงู ุจุฑุง ูุทุงูุนู ุงู ฺฉุชุงุจ ุชูุตู ูฺฉูู ููุฏูู ุฑู ูุฎููุฏ ู ุจู ูุงุดุฑ ูู ุชูุตู ูฺฉูู ูุชู ูุชุฑุฌู ุฑู ุจู ุนููุงู ูุคุฎุฑู ุฏุฑ ฺฉุชุงุจ ุจุงูุฑูุฏ.\n",
            "ุฏูุณุชุงู ุจุฑุง ูุทุงูุนู ุงู ฺฉุชุงุจ ุชูุตู ูฺฉูู ููุฏูู ุฑู ูุฎููุฏ ู ุจู ูุงุดุฑ ูู ุชูุตู ูฺฉูู ูุชู ูุชุฑุฌู ุฑู ุจู ุนููุงู ูุคุฎุฑู ุฏุฑ ฺฉุชุงุจ ุจุงูุฑูุฏ.\n",
            "ุนุงู ุจูุฏ ููุท ูพุดููุงุฏ ูุดู ููุฏูุด ุฑู ุงุจุชุฏุง ูุฎููุฏ ฺูู ุฏุงุณุชุงู ูู ูุฑู\n",
            "ุนุงู ุจูุฏ ููุท ูพุดููุงุฏ ูุดู ููุฏูุด ุฑู ุงุจุชุฏุง ูุฎููุฏ ฺูู ุฏุงุณุชุงู ูู ูุฑู\n",
            "ููุงุดูุงูู ููู ู ุฌุงูุจ ูุณุช ุจุง ุงูฺฉู ุงุตูุง ููุงุดูุงูู ุฏูุณุช ูุฏุงุฑู..\n",
            "ููุงุดูุงูู ููู ู ุฌุงูุจ ูุณุช ุจุง ุงูฺฉู ุงุตูุง ููุงุดูุงูู ุฏูุณุช ูุฏุงุฑู..\n",
            "ฺฉุชุงุจ ููู ุงูุนุงุฏู ุง ูุณุชุด . ููุท ุญู ฺฉู ุฏุงุณุชุงู ุชู ููุฏูู ูู ุฑูุช ู ุงูฺฏุฑู ุฎูุงููุฏู ุจุฑุง ุฎูุงูุฏู ุฌุฒุฆุงุช ุฑู ฺฏุฑูุช.\n",
            "ุญูุงุณุชูู ุจุงุดู ููุฏูู ุฑู ูุฎููุฏ\n",
            "ฺฉุชุงุจ ููู ุงูุนุงุฏู ุง ูุณุชุด . ููุท ุญู ฺฉู ุฏุงุณุชุงู ุชู ููุฏูู ูู ุฑูุช ู ุงูฺฏุฑู ุฎูุงููุฏู ุจุฑุง ุฎูุงูุฏู ุฌุฒุฆุงุช ุฑู ฺฏุฑูุช.\n",
            "ุญูุงุณุชูู ุจุงุดู ููุฏูู ุฑู ูุฎููุฏ\n",
            "ุนุฌุจ ุณู ุชูุงูู! ุงููู ุจุงุฑ ุจูุฏ ููุงุดูุงูู ูุฎููุฏูุุจุฏ ูุจูุฏ.\n",
            "ุนุฌุจ ุณู ุชูุงูู! ุงููู ุจุงุฑ ุจูุฏ ููุงุดูุงูู ูุฎููุฏูุุจุฏ ูุจูุฏ.\n",
            "ูุดูฺฏ ุจูุฏ ๐\n",
            "ูุดูฺฏ ุจูุฏ \n",
            "ุงููู ฺฉุชุงุจ ุจูุฏ ฺฉู ุงุฒ ุงู ููุณูุฏู ูุฎููุฏู.ฺฉุชุงุจ ูุฑูุงุช ููุฑุฏ ูพุณูุฏู ุจูุฏ ููุฐุช ุจุฑุฏู\n",
            "ุงููู ฺฉุชุงุจ ุจูุฏ ฺฉู ุงุฒ ุงู ููุณูุฏู ูุฎููุฏู.ฺฉุชุงุจ ูุฑูุงุช ููุฑุฏ ูพุณูุฏู ุจูุฏ ููุฐุช ุจุฑุฏู\n",
            "ููุฏูู ุบุฑ ุญุฑููโุง ฺฉู ุชุง ุขุฎุฑ ุฏุงุณุชุงู ุฑู ุฏุฑ ฺูุฏ ุฌููู ูู ุฏุงุฏ.\n",
            "ููุฏูู ุบุฑ ุญุฑููโุง ฺฉู ุชุง ุขุฎุฑ ุฏุงุณุชุงู ุฑู ุฏุฑ ฺูุฏ ุฌููู ูู ุฏุงุฏ.\n",
            "ููุฏูู ุฑุง ุขุฎุฑ ฺฉุงุฑ ุจุฎูุงูุฏ ฺูู ุฏุงุณุชุงู ฺฉุงููุง ูู ูุฑูุฏ.\n",
            "ููุฏูู ุฑุง ุขุฎุฑ ฺฉุงุฑ ุจุฎูุงูุฏ ฺูู ุฏุงุณุชุงู ฺฉุงููุง ูู ูุฑูุฏ.\n",
            "ุงููุง : ุฌูุงู ุงู ุงุญูุฏ ฺฏู ฺฉุงุดุชู\n",
            "ุฏููุง : ุงููุง ฺฉู ุงูู ุชุฆุงุชุฑ ูุณุชูุฏ ูพุดููุงุฏ ูุฏู ุญุชูุง ุจุฎููู\n",
            "ุณููุง : ุฏุฑ ฺฉู ุฎูุจ ุจูุฏ ุ\n",
            "ุงููุง : ุฌูุงู ุงู ุงุญูุฏ ฺฏู ฺฉุงุดุชู\n",
            "ุฏููุง : ุงููุง ฺฉู ุงูู ุชุฆุงุชุฑ ูุณุชูุฏ ูพุดููุงุฏ ูุฏู ุญุชูุง ุจุฎููู\n",
            "ุณููุง : ุฏุฑ ฺฉู ุฎูุจ ุจูุฏ ุ\n",
            "ุฏุงุณุชุงู ูฺฺฏููู ุฌุฐุงุจุช ูุฏุงุฑูุ ูู ูุงูุนุง ุจู ุฒูุฑ ุชูููุด ฺฉุฑุฏู ุจุนุฏ 2ูุงูุ ฺูู ุฑุบุจุช ุชู ูู ุงุฌุงุฏ ููฺฉุฑุฏุ ุงูุง ูู ุจู ุฎุงุทุฑ ุชุฑุฌูู ุฌูุงู ุขู ุงุญูุฏุ ุฎูุฏ ูุชู ุขูุจุฑฺฉุงูู ุซูู ู ุจู ฺฏููู ุง ูุฏู ุจูุฏ ู ุณุฑ ุฏุงุณุชุงู ูู ฺฉูุฏ ู ุงุฒ ุฌุฐุงุจุชุด ุจู ุดุฏุช ฺฉุงุณุชู ุจูุฏ...\n",
            "ุงูุง ุงุฒ ุฌูุงู ุขู ุงุญูุฏ ุจุนุฏ ุจูุฏ ฺฉู ฺฉู ุฏุงุณุชุงูู ุชู ููุฏูู ุด ูู ุจุฏู ุชุญุช ุนููุงู ุชุญููุ ุขุฎู ุจุฑุงุฏุฑ ูู ุชุญููุชู ุจุฐุงุฑ ุขุฎุฑ ฺฉุชุงุจ\n",
            "ุญุงูุง ูฺฉ ฺฉูู ู ููฺู ฺฉุชุงุจ ูุงุฌุฐุงุจ ุชูุดู ุจุฏูููุ ุฏฺฏู ฺ ูุฎูุงุฏ ฺฉุดุด ุงุฌุงุฏ ฺฉูู ูู ููุฏููู! ุจุฒุฑฺฏูุงุฑ ุฌูุงู ุขู ุงุญูุฏ ุชุฑุฎูุงุตู ุฒุฏ ุจุง ุงู ฺฉุงุฑุดุ ุดุงุฏู ุนูุฏุง ุฎูุงุตู ุดู ุงูู ฺฏูุชู ฺฉู ููุชููู ุชูู ูุดู ุจุฎูุฏ ฺฉุชุงุจู ุจุฎููู!!\n",
            "ุจู ูุฑุญุงู ุงฺฏู ุจุง ุชูุงู ุงู ุญุฑูุง ุจุงุฒู ุงุตุฑุงุฑ ุจู ุฎููุฏูุด ุฏุงุฑุฏ ูพุดููุงุฏ ูฺฉูู ููุฏูู ุฑู ุขุฎุฑ ุจุฎููุฏ ุง ุงุตู ูุฎููุฏุ ฺู ฺฉุงุฑู\n",
            "ุฏุฑุถูู ุงูู ู ุณุชุงุฑู ุฑููู ุงุฒ ุฑู ุงุฌุจุงุฑ ุฏุงุฏู!\n",
            "ุฏุงุณุชุงู ูฺฺฏููู ุฌุฐุงุจุช ูุฏุงุฑูุ ูู ูุงูุนุง ุจู ุฒูุฑ ุชูููุด ฺฉุฑุฏู ุจุนุฏ 2ูุงูุ ฺูู ุฑุบุจุช ุชู ูู ุงุฌุงุฏ ููฺฉุฑุฏุ ุงูุง ูู ุจู ุฎุงุทุฑ ุชุฑุฌูู ุฌูุงู ุขู ุงุญูุฏุ ุฎูุฏ ูุชู ุขูุจุฑฺฉุงูู ุซูู ู ุจู ฺฏููู ุง ูุฏู ุจูุฏ ู ุณุฑ ุฏุงุณุชุงู ูู ฺฉูุฏ ู ุงุฒ ุฌุฐุงุจุชุด ุจู ุดุฏุช ฺฉุงุณุชู ุจูุฏ...\n",
            "ุงูุง ุงุฒ ุฌูุงู ุขู ุงุญูุฏ ุจุนุฏ ุจูุฏ ฺฉู ฺฉู ุฏุงุณุชุงูู ุชู ููุฏูู ุด ูู ุจุฏู ุชุญุช ุนููุงู ุชุญููุ ุขุฎู ุจุฑุงุฏุฑ ูู ุชุญููุชู ุจุฐุงุฑ ุขุฎุฑ ฺฉุชุงุจ\n",
            "ุญุงูุง ูฺฉ ฺฉูู ู ููฺู ฺฉุชุงุจ ูุงุฌุฐุงุจ ุชูุดู ุจุฏูููุ ุฏฺฏู ฺ ูุฎูุงุฏ ฺฉุดุด ุงุฌุงุฏ ฺฉูู ูู ููุฏููู! ุจุฒุฑฺฏูุงุฑ ุฌูุงู ุขู ุงุญูุฏ ุชุฑุฎูุงุตู ุฒุฏ ุจุง ุงู ฺฉุงุฑุดุ ุดุงุฏู ุนูุฏุง ุฎูุงุตู ุดู ุงูู ฺฏูุชู ฺฉู ููุชููู ุชูู ูุดู ุจุฎูุฏ ฺฉุชุงุจู ุจุฎููู!!\n",
            "ุจู ูุฑุญุงู ุงฺฏู ุจุง ุชูุงู ุงู ุญุฑูุง ุจุงุฒู ุงุตุฑุงุฑ ุจู ุฎููุฏูุด ุฏุงุฑุฏ ูพุดููุงุฏ ูฺฉูู ููุฏูู ุฑู ุขุฎุฑ ุจุฎููุฏ ุง ุงุตู ูุฎููุฏุ ฺู ฺฉุงุฑู\n",
            "ุฏุฑุถูู ุงูู ู ุณุชุงุฑู ุฑููู ุงุฒ ุฑู ุงุฌุจุงุฑ ุฏุงุฏู!\n",
            "ุฏุงุณุชุงู ุบูโุงูฺฏุฒ ุจูุฏ... ุฏุฑุงู ุฎูุจ ุจูุฏ ูู ฺฉุดุด ููโุง ูุฏุงุดุช.\n",
            "ุฏุงุณุชุงู ุบูโุงูฺฏุฒ ุจูุฏ... ุฏุฑุงู ุฎูุจ ุจูุฏ ูู ฺฉุดุด ููโุง ูุฏุงุดุช.\n",
            "167 ุตูุญู ุงุณุ ุญุณ ูฺฉูู ุงุฏุงูู ุฏุงุดุชู\n",
            "167 ุตูุญู ุงุณุ ุญุณ ูฺฉูู ุงุฏุงูู ุฏุงุดุชู\n",
            "ููฺู ุนูุฏู ุง ุฏุฑ ุงูู ูฺฉุงู ู ุฒูุงู ูุดุงูู  ูพูฺ ุฎู ูฺฉุงู ู ุฒูุงู ู ูุฑููฺฏ ุขูุจุฑ ฺฉุงูู ุงุณุช. ูุงูุนุง ุฎู ุฎูุจ ุชููุณุชู ุบู ุฏุงุณุชุงู ุฑู ุงูุชูุงู ุจุฏู\n",
            "ููฺู ุนูุฏู ุง ุฏุฑ ุงูู ูฺฉุงู ู ุฒูุงู ูุดุงูู  ูพูฺ ุฎู ูฺฉุงู ู ุฒูุงู ู ูุฑููฺฏ ุขูุจุฑ ฺฉุงูู ุงุณุช. ูุงูุนุง ุฎู ุฎูุจ ุชููุณุชู ุบู ุฏุงุณุชุงู ุฑู ุงูุชูุงู ุจุฏู\n",
            "ุจุณุงุฑ ุฒุจุง ู ุฏุฑุงูุงุชฺฉ\n",
            "ุจุณุงุฑ ุฒุจุง ู ุฏุฑุงูุงุชฺฉ\n",
            "ุงููู ฺฉุชุงุจู ฺฉู ุงุฒ ุขูุจุฑฺฉุงูู ูุฎููู... ุฌุฐุจ ููุน ุงูฺฉุงุฑ ู ููุดุชู ูุงุด ุดุฏู .... ุดฺฉ ูุฏุงุฑู ฺฉู ฺฉู ุงููู ุงุฒ ููุณูุฏู ูุง ููุฑุฏ ุนูุงูู ู ูุฏููู.\n",
            "ุงููู ฺฉุชุงุจู ฺฉู ุงุฒ ุขูุจุฑฺฉุงูู ูุฎููู... ุฌุฐุจ ููุน ุงูฺฉุงุฑ ู ููุดุชู ูุงุด ุดุฏู .... ุดฺฉ ูุฏุงุฑู ฺฉู ฺฉู ุงููู ุงุฒ ููุณูุฏู ูุง ููุฑุฏ ุนูุงูู ู ูุฏููู.\n",
            "ุฏูุณุชุงู ุชุฑุฌูุด ุฎูุจูุุ\n",
            "ุฏูุณุชุงู ุชุฑุฌูุด ุฎูุจูุุ\n",
            "ุงููู ฺฉุชุงุจ ฺฉ ุจุนุฏ ูุฏุชูุง ุฎููุฏู ุฌุงูุจ ุจูุฏ ูู ููุฏูู ุฏุฑุฎุงุชูู ุฎูุงูุฏู ุดูุฏ..\n",
            "ุงููู ฺฉุชุงุจ ฺฉ ุจุนุฏ ูุฏุชูุง ุฎููุฏู ุฌุงูุจ ุจูุฏ ูู ููุฏูู ุฏุฑุฎุงุชูู ุฎูุงูุฏู ุดูุฏ..\n",
            "ฺฉุชุงุจ ุบูฺฏู ู ุชุงุซุฑ ฺฏุฐุงุฑุูุจุงุฏ ุชูุฏ ุฑูุช\n",
            "ฺฉุชุงุจ ุบูฺฏู ู ุชุงุซุฑ ฺฏุฐุงุฑุูุจุงุฏ ุชูุฏ ุฑูุช\n",
            "ุบูฺฏู ู ุฒุจุง:(\n",
            "ุบูฺฏู ู ุฒุจุง:(\n",
            "ูุฑุณ ฺฉู ฺฏูุชุฏ ููุฏูู ุฑู ุงูู ูุฎููุฏ.ููุงุดูุงูู ุฎููุฏู ุฎู ุฌุฐุงุจ ุชุฑู ุงุฒ ุงู ุฌูุช ฺฉู ููู  ุจุฑุฏุงุดุช ูุง ุจุง ุฎูุงููุฏู ุงุณุช .\n",
            "ูุฑุณ ฺฉู ฺฏูุชุฏ ููุฏูู ุฑู ุงูู ูุฎููุฏ.ููุงุดูุงูู ุฎููุฏู ุฎู ุฌุฐุงุจ ุชุฑู ุงุฒ ุงู ุฌูุช ฺฉู ููู  ุจุฑุฏุงุดุช ูุง ุจุง ุฎูุงููุฏู ุงุณุช .\n",
            "ููุฏูู ุฑู ุงูู ูุฎููุฏูุชุงุณูุงูู ู ฺฉู ุงุฒ ููุฏูู ุฑู ุฎููุฏู ฺฉู ุฏุงุณุชุงู ู ูู ุฏุงุฏ ู ฺฉุดุด ููุฌุงูุด ูุงุฒุจู ุจุฑุฏ\n",
            "ููุฏูู ุฑู ุงูู ูุฎููุฏูุชุงุณูุงูู ู ฺฉู ุงุฒ ููุฏูู ุฑู ุฎููุฏู ฺฉู ุฏุงุณุชุงู ู ูู ุฏุงุฏ ู ฺฉุดุด ููุฌุงูุด ูุงุฒุจู ุจุฑุฏ\n",
            "ูุงฺฏูุชู ููุงูุฏ ฺฉู ุณู ุชูุงูู ฺฉ ูุดฺฉู ฺฉูุดู ุง ุฏุฑ ุฒูุฏฺฏ ุงุณุช ฺฉู ุจู ุดฺฉู ูุง ูุชููุน ุฏุฑ ุตุญูู ููุงุด ุฒูุฏฺฏ ุจุฑุงูุงู ุฑุฎ ู ุฏูุฏ.\n",
            " ุงู ฺฉุชุงุจ ฺฉ ุชุฑุงฺุฏ ุจูุฏ ุฏุฑ ูุงูุน ฺฉ ุตุญูู ุง ุจูุฏ ฺฉู ุจฺุงุฑฺฏ ุงูุฑุงุฏ ุงุฒ ุฌุงูุนู ุฑุง ูุดุงู ูุฏูุฏ ฺฉู ุขูุช ุจุฑุง ุฎูุดุญุงู ู ุงุญุณุงุณ ุฎูุดุจุฎุช ูุฏุงุฑูุฏ. ูุชุงุณูุงูู ฺฉ ูุดฺฉู ุจุงุฑุฒ ุงู ููุฏูู ุจูุฏ ( ุฌุงูุจ ูุจูุฏ ). \n",
            "ููุณูุฏู ุณุน ฺฉุฑุฏ ูุดุงู ุฏูุฏ ฺฉู ุฑุงู ุญู ุญุงุช ุนุดู ุจู ุฒุจุง ูุง ุงุณุช. ู ุชูุงู ูููุฏ ฺฉู ููุณูุฏู ูุตุฏ ุฏุงุดุช ุฒูุฏฺฏ ุฑุง ุณุจฺฉ ูุดุงู ุฏูุฏ. \n",
            "ุฏุฑ ฺฉู ููุถูุน ุฌุงูุจ ุจุฑุง ุฎูุงูุฏู ุงุณุช.\n",
            "ูุงฺฏูุชู ููุงูุฏ ฺฉู ุณู ุชูุงูู ฺฉ ูุดฺฉู ฺฉูุดู ุง ุฏุฑ ุฒูุฏฺฏ ุงุณุช ฺฉู ุจู ุดฺฉู ูุง ูุชููุน ุฏุฑ ุตุญูู ููุงุด ุฒูุฏฺฏ ุจุฑุงูุงู ุฑุฎ ู ุฏูุฏ.\n",
            " ุงู ฺฉุชุงุจ ฺฉ ุชุฑุงฺุฏ ุจูุฏ ุฏุฑ ูุงูุน ฺฉ ุตุญูู ุง ุจูุฏ ฺฉู ุจฺุงุฑฺฏ ุงูุฑุงุฏ ุงุฒ ุฌุงูุนู ุฑุง ูุดุงู ูุฏูุฏ ฺฉู ุขูุช ุจุฑุง ุฎูุดุญุงู ู ุงุญุณุงุณ ุฎูุดุจุฎุช ูุฏุงุฑูุฏ. ูุชุงุณูุงูู ฺฉ ูุดฺฉู ุจุงุฑุฒ ุงู ููุฏูู ุจูุฏ ( ุฌุงูุจ ูุจูุฏ ). \n",
            "ููุณูุฏู ุณุน ฺฉุฑุฏ ูุดุงู ุฏูุฏ ฺฉู ุฑุงู ุญู ุญุงุช ุนุดู ุจู ุฒุจุง ูุง ุงุณุช. ู ุชูุงู ูููุฏ ฺฉู ููุณูุฏู ูุตุฏ ุฏุงุดุช ุฒูุฏฺฏ ุฑุง ุณุจฺฉ ูุดุงู ุฏูุฏ. \n",
            "ุฏุฑ ฺฉู ููุถูุน ุฌุงูุจ ุจุฑุง ุฎูุงูุฏู ุงุณุช.\n",
            "#ูุณุฆูู ุจุฒุฑฺฏ ฺฉู ุจุงุฏ \"ุนููุง\" ุญู ฺฉุฑุฏ:\n",
            "ุขุง ูุชูุงู ุฎูุดุจุฎุช ู ุชููุง ุจูุฏุ\n",
            "(ุขูุจุฑ ฺฉุงูู). .\n",
            "ุจุงุญุงู ุจูุฏใ\n",
            "#ูุณุฆูู ุจุฒุฑฺฏ ฺฉู ุจุงุฏ \"ุนููุง\" ุญู ฺฉุฑุฏ:\n",
            "ุขุง ูุชูุงู ุฎูุดุจุฎุช ู ุชููุง ุจูุฏุ\n",
            "(ุขูุจุฑ ฺฉุงูู). .\n",
            "ุจุงุญุงู ุจูุฏ\n",
            "ูู ููุฏููู  ุงูุชุงุฒ ุงู ููุงุดูุงูู ฺุฑุง ุงููุฏุฑ ูพุงูู ...\n",
            "ุงุฒ ูุธุฑ ูู  ฺฉู  ุจ ูุธุฑู\n",
            "ูู ููุฏููู  ุงูุชุงุฒ ุงู ููุงุดูุงูู ฺุฑุง ุงููุฏุฑ ูพุงูู ...\n",
            "ุงุฒ ูุธุฑ ูู  ฺฉู  ุจ ูุธุฑู\n",
            "ุฌุงูุจ ุจูุฏ ู ูุฌุงู.\n",
            "ุฌุงูุจ ุจูุฏ ู ูุฌุงู.\n",
            "ุนุงู\n",
            "ุนุงู\n",
            "ุดุฎุตุช ูพุฑุฏุงุฒ ูุง ุฎูุจ ู ุงุฏู ุฌุงูุจ\n",
            "ุชุฑุฌูู ุฑูุงู ุฏุงุฑู\n",
            "ุดุฎุตุช ูพุฑุฏุงุฒ ูุง ุฎูุจ ู ุงุฏู ุฌุงูุจ\n",
            "ุชุฑุฌูู ุฑูุงู ุฏุงุฑู\n",
            "ููุท ูุชููู ุจฺฏู ุจุฏ ูุจูุฏ\n",
            "ูู ุนุงู ุจูุฏ ูู ูุฒุฎุฑูุ ุจุฏูุจูุฏ\n",
            "ููุท ูุชููู ุจฺฏู ุจุฏ ูุจูุฏ\n",
            "ูู ุนุงู ุจูุฏ ูู ูุฒุฎุฑูุ ุจุฏูุจูุฏ\n",
            "ุจูุธุฑู ุนุงู ุจูุฏ ุจุฎุตูุต ูุชุฌุด ฺฉู ุฏุฑุฏูุงฺฉ ุชููู ุดุฏ ุจูุชุฑุด ฺฉุฑุฏู ุจูุฏ.ุฎู ุฏูุณุช ุฏุงุดุชู ูพุดููุงุฏ ูฺฉูู ุจุฎููุฏ\n",
            "ุจูุธุฑู ุนุงู ุจูุฏ ุจุฎุตูุต ูุชุฌุด ฺฉู ุฏุฑุฏูุงฺฉ ุชููู ุดุฏ ุจูุชุฑุด ฺฉุฑุฏู ุจูุฏ.ุฎู ุฏูุณุช ุฏุงุดุชู ูพุดููุงุฏ ูฺฉูู ุจุฎููุฏ\n",
            "ุจู ูุธุฑ ูู ุงูููุฏุฑ ูุงู ุฌุงูุจ ูุจูุฏ....\n",
            "ูฺฉุฑ ููฺฉุฑุฏู ุงููุฏุฑ ุจุฏ ุชููู ุจุดู \n",
            "ฺฉุงููุง ูุฌุงู ุจูุฏ .ุงูุงูุชุฌู ุงุด ูุณุฎุฑู ุจูุฏ\n",
            "ุจู ูุธุฑ ูู ุงูููุฏุฑ ูุงู ุฌุงูุจ ูุจูุฏ....\n",
            "ูฺฉุฑ ููฺฉุฑุฏู ุงููุฏุฑ ุจุฏ ุชููู ุจุดู \n",
            "ฺฉุงููุง ูุฌุงู ุจูุฏ .ุงูุงูุชุฌู ุงุด ูุณุฎุฑู ุจูุฏ\n",
            "๐๐\n",
            "\n",
            "ุงููู ููุงุดูุงููโุง ฺฉู ุชุง ุงูุงู ุฎููุฏู. ุนุงู\n",
            "ุงููู ููุงุดูุงููโุง ฺฉู ุชุง ุงูุงู ุฎููุฏู. ุนุงู\n",
            "ุจูุธุฑ ูู ููุณูุฏู ุฏุฑ ุงู ููุงุดูุงูู ุจุณุงุฑ ุฏุฑ ูพ ุฏูุจุงู ฺฉุฑุฏู ุงุฏู ุจุฑุชููุช ุจุฑุดุช ุฏุฑ ููุงุดูุงูู ุงุณุชุซูุง ู ูุงุนุฏู ุจูุฏ ุงฺฏู ุงูู ููุงุดูุงูู ุฑู ูุทุงูุนู ฺฉุฑุฏู ุจุงุดู ุฎูุงูุช ุงุฒ ูุธุฑ ููููู ูุฒ ููุดู ุจูฺฉู ุจุณุงุฑ ูู ุถุนู ุชุฑ ุจุงู ุดุฏู. ููุณูุฏู ุฏุฑ ูพ ูุงุฑุฏ ฺฉุฑุฏู ููุด ุนุดู ุจุฑุง ุฑุจุท ุงุณุชุซูุง ุจู ฺฉ ุฑุฎุฏุงุฏ ุจูุฏู ฺฉู ุฏุฑ ุญุงูุช ุนุงุฏ ฺฉุงููุง ุฏูุฑ ุงุฒ ูุงุนุฏู ุฌุงูุนู ุงุณุช. ฺฉู ุจู ูุธุฑ ูู ุจู ุฎูุจ ุฌููู ูฺฉุฑุฏู. ุฏุฑ ฺฉู ููููู ุณูุชูุงูู ฺฉู ูุงุด ุงุฒ ุจุฑุฏุงุดุช ูุง ุงูุณุงููุง ู ุนูู ุจู ูุทุน ุจูุฏู ุจุฑุฏุงุดุช ูุงูููู ุฎูุจ ุจุงู ุดุฏู ู ุจูุธุฑ ูู ุฏุฑ ุงู ฺฉุงุฑ ูููู ุธุงูุฑ ุดุฏู.\n",
            "ุจูุธุฑ ูู ููุณูุฏู ุฏุฑ ุงู ููุงุดูุงูู ุจุณุงุฑ ุฏุฑ ูพ ุฏูุจุงู ฺฉุฑุฏู ุงุฏู ุจุฑุชููุช ุจุฑุดุช ุฏุฑ ููุงุดูุงูู ุงุณุชุซูุง ู ูุงุนุฏู ุจูุฏ ุงฺฏู ุงูู ููุงุดูุงูู ุฑู ูุทุงูุนู ฺฉุฑุฏู ุจุงุดู ุฎูุงูุช ุงุฒ ูุธุฑ ููููู ูุฒ ููุดู ุจูฺฉู ุจุณุงุฑ ูู ุถุนู ุชุฑ ุจุงู ุดุฏู. ููุณูุฏู ุฏุฑ ูพ ูุงุฑุฏ ฺฉุฑุฏู ููุด ุนุดู ุจุฑุง ุฑุจุท ุงุณุชุซูุง ุจู ฺฉ ุฑุฎุฏุงุฏ ุจูุฏู ฺฉู ุฏุฑ ุญุงูุช ุนุงุฏ ฺฉุงููุง ุฏูุฑ ุงุฒ ูุงุนุฏู ุฌุงูุนู ุงุณุช. ฺฉู ุจู ูุธุฑ ูู ุจู ุฎูุจ ุฌููู ูฺฉุฑุฏู. ุฏุฑ ฺฉู ููููู ุณูุชูุงูู ฺฉู ูุงุด ุงุฒ ุจุฑุฏุงุดุช ูุง ุงูุณุงููุง ู ุนูู ุจู ูุทุน ุจูุฏู ุจุฑุฏุงุดุช ูุงูููู ุฎูุจ ุจุงู ุดุฏู ู ุจูุธุฑ ูู ุฏุฑ ุงู ฺฉุงุฑ ูููู ุธุงูุฑ ุดุฏู.\n",
            "ฺฉ ุงุฏู ุจฺฉุฑ ู ุฌุฐุงุจ ฺฉู ุชูุณุท ูุญู ุฏุงุณุชุงู ู ุงุณุชูุงุฏู ุงุฒ ฺฉููุงุช ุบุฑุญุณ ูุฑุจุงู ูุดูุฏ! ู ุฏุฑ ููุงุช ุญุงุตูุด ูุดูุฏ ฺฉ ุงุซุฑ ฺฉุงููุง ูุชูุณุท!!\n",
            "ฺฉ ุงุฏู ุจฺฉุฑ ู ุฌุฐุงุจ ฺฉู ุชูุณุท ูุญู ุฏุงุณุชุงู ู ุงุณุชูุงุฏู ุงุฒ ฺฉููุงุช ุบุฑุญุณ ูุฑุจุงู ูุดูุฏ! ู ุฏุฑ ููุงุช ุญุงุตูุด ูุดูุฏ ฺฉ ุงุซุฑ ฺฉุงููุง ูุชูุณุท!!\n",
            "ุณูุก ุชูุงููุ ุงูู ูู ฺู ุณูุก ุชูุงูู!\n",
            " ุฏุฑ ููุฑุฏ ููุงุดูุงูู ุจุดุชุฑ ุงุฒ ุงู ุฏู ฺฉููู ฺุฒ ููุชููู ุจฺฏู: ุบู ุงูฺฏุฒ ู ุชฺฉุงู ุฏููุฏู.\n",
            "ุงูุง ุจู ุฌุฑุงุช ูุดู ฺฏูุช ุณูุก ุชูุงูู ุฏุฑ ุฒูุฏฺฏ ููู ูุง ุงุชูุงู ูููุชูุ ุญุงูุง ุฏุฑ ุงุจุนุงุฏ ู ุงูุณุงู ูุฎุชููุ ุฏุฑ ุฑูฺฏ ูุง ู  ุงุดฺฉุงู ูุชูุงูุช.\n",
            "ุฏุฑ ููุฑุฏ ุชุฑุฌูู: ุฒุงุฏ ุชฺฉูู ุฏุงุฑู.\n",
            "ุจู ูุธุฑู ุงูุชุฎุงุจ ฺฉููู ููุงุณุจ ุจู ุทูุฑ ฺฉู ุชุบุฑ ุฏุฑ ููุธูุฑ ููุณูุฏู ุงุฌุงุฏ ูฺฉูู ู ุงุฒ ุทุฑู ุฏุฑ ุฒุจุงู ููุตุฏ (ุงูุฌุง ูุงุฑุณ) ูู ุฌุงุงูุชุงุฏู ุจุงุดูุ ุงุฒ ุงุตู ุชุฑู ูุธุงู ฺฉ ูุชุฑุฌูู!\n",
            " ุจู ุนููุงู ฺฉ ููููู ุงุฒ ูุฒุงุฑุงู:\n",
            "ุฏุฑ ุฌุง ฺุงู ูฺฏู \"ุดูุง ู ุชูุงูุณุชุฏ ุชูู ุณูุฑ ุฎูุฏ ุฑุง ุจุจูุฏ\"\n",
            "ุฏุฑ ุงู ุฌููู ุงฺฏุฑ ุจู ุฌุง ฺฉููู ุชููุ ุชุฏุงุฑฺฉ ุฌุงฺฏุฒู ูุดุฏุ ุจูุชุฑ ูุจูุฏุ!\n",
            "ุฏุฑ ููุฑุฏ ฺูุฏ ฺฉููู ุชูุถุญ ุขูุง ุฌูุงู ุขู ุงุญูุฏ: ุจูุชุฑ ุจูุฏ ุงู ูุณูุช ุฑู ุจุนุฏ ุงุฒ ููุงุดูุงูู ูุฑุงุฑ ุจุฏุฏุ ุทุงูฺู!\n",
            "ุณูุก ุชูุงููุ ุงูู ูู ฺู ุณูุก ุชูุงูู!\n",
            " ุฏุฑ ููุฑุฏ ููุงุดูุงูู ุจุดุชุฑ ุงุฒ ุงู ุฏู ฺฉููู ฺุฒ ููุชููู ุจฺฏู: ุบู ุงูฺฏุฒ ู ุชฺฉุงู ุฏููุฏู.\n",
            "ุงูุง ุจู ุฌุฑุงุช ูุดู ฺฏูุช ุณูุก ุชูุงูู ุฏุฑ ุฒูุฏฺฏ ููู ูุง ุงุชูุงู ูููุชูุ ุญุงูุง ุฏุฑ ุงุจุนุงุฏ ู ุงูุณุงู ูุฎุชููุ ุฏุฑ ุฑูฺฏ ูุง ู  ุงุดฺฉุงู ูุชูุงูุช.\n",
            "ุฏุฑ ููุฑุฏ ุชุฑุฌูู: ุฒุงุฏ ุชฺฉูู ุฏุงุฑู.\n",
            "ุจู ูุธุฑู ุงูุชุฎุงุจ ฺฉููู ููุงุณุจ ุจู ุทูุฑ ฺฉู ุชุบุฑ ุฏุฑ ููุธูุฑ ููุณูุฏู ุงุฌุงุฏ ูฺฉูู ู ุงุฒ ุทุฑู ุฏุฑ ุฒุจุงู ููุตุฏ (ุงูุฌุง ูุงุฑุณ) ูู ุฌุงุงูุชุงุฏู ุจุงุดูุ ุงุฒ ุงุตู ุชุฑู ูุธุงู ฺฉ ูุชุฑุฌูู!\n",
            " ุจู ุนููุงู ฺฉ ููููู ุงุฒ ูุฒุงุฑุงู:\n",
            "ุฏุฑ ุฌุง ฺุงู ูฺฏู \"ุดูุง ู ุชูุงูุณุชุฏ ุชูู ุณูุฑ ุฎูุฏ ุฑุง ุจุจูุฏ\"\n",
            "ุฏุฑ ุงู ุฌููู ุงฺฏุฑ ุจู ุฌุง ฺฉููู ุชููุ ุชุฏุงุฑฺฉ ุฌุงฺฏุฒู ูุดุฏุ ุจูุชุฑ ูุจูุฏุ!\n",
            "ุฏุฑ ููุฑุฏ ฺูุฏ ฺฉููู ุชูุถุญ ุขูุง ุฌูุงู ุขู ุงุญูุฏ: ุจูุชุฑ ุจูุฏ ุงู ูุณูุช ุฑู ุจุนุฏ ุงุฒ ููุงุดูุงูู ูุฑุงุฑ ุจุฏุฏุ ุทุงูฺู!\n",
            "ุฎู ุนุงู ู ูพุฑ ุงุฒ ุบู ุจูุฏ\n",
            "ู ุงูุจุชู ุจู ูุธุฑ ูู ููุฏูู ุจุดุชุฑ ูุฌุงู ุจู ุฏุงุณุชุงู ูุฌุงู ุฏุงุฏ.\n",
            "ุฎู ุนุงู ู ูพุฑ ุงุฒ ุบู ุจูุฏ\n",
            "ู ุงูุจุชู ุจู ูุธุฑ ูู ููุฏูู ุจุดุชุฑ ูุฌุงู ุจู ุฏุงุณุชุงู ูุฌุงู ุฏุงุฏ.\n",
            "ุชูุตู ูฺฉูู ููุฏูู ุงู ููุงุดูุงูู ุญุฐู ุจุดู ุง ุฎููุฏู ูุดูโ. ฺฉ ููุฏูู  ุฎุณุชู ฺฉููุฏู ู ุทููุงู ฺฉ ฺฉู ุฏุงุณุชุงู ุฑู ูู ุฏุงุฏ ู ุจุงุนุซ ุดุฏ ุงุตู ููุงุดูุงูู ุฑู ฺฉุงูู ูุฎููู:/\n",
            "ุชูุตู ูฺฉูู ููุฏูู ุงู ููุงุดูุงูู ุญุฐู ุจุดู ุง ุฎููุฏู ูุดูโ. ฺฉ ููุฏูู  ุฎุณุชู ฺฉููุฏู ู ุทููุงู ฺฉ ฺฉู ุฏุงุณุชุงู ุฑู ูู ุฏุงุฏ ู ุจุงุนุซ ุดุฏ ุงุตู ููุงุดูุงูู ุฑู ฺฉุงูู ูุฎููู:/\n",
            "ฺฉุงุด ุงู ููุฏูู ฺฉู ูู ุฑูุชู ฺฉู ุฏุงุณุชุงู ุฑู  ุจู ููุฑุง ุฏุงุฑู ูุจูุฏ\n",
            "ฺฉุงุด ุงู ููุฏูู ฺฉู ูู ุฑูุชู ฺฉู ุฏุงุณุชุงู ุฑู  ุจู ููุฑุง ุฏุงุฑู ูุจูุฏ\n",
            "ุฏุฏุงุฑ ุฏูุจุงุฑู ุจุนุฏ ุงุฒ ฒฐ ุณุงู  ุฺฉุดุชู ฺฉ ุขุฏู ุูููุฏู ูุณุจุช ููุชูู ุจุง ุฎูุฏุดุงูุุงุนุชุฑุงู ุจู ูุชู ู ... ููู ุจุฏูู ูุฌุงู!ุงูุจุชู ุจฺฏุงูู ุขูุจุฑฺฉุงูู ูู ููู ุทูุฑ ุจูุฏ ุงูุง ูู ุจฺฏุงูู ุฑู ุจุดุชุฑ ูพุณูุฏุฏู.ุฏุฑ ุถูู ุฎููุฏู ููุฏูู ุงุดุชุจุงูู ฺูู ุฏุงุณุชุงู ุฑุง ฺฉุงูู ูู ู ุฏูุฏ.\n",
            "ุฏุฏุงุฑ ุฏูุจุงุฑู ุจุนุฏ ุงุฒ ฒฐ ุณุงู  ุฺฉุดุชู ฺฉ ุขุฏู ุูููุฏู ูุณุจุช ููุชูู ุจุง ุฎูุฏุดุงูุุงุนุชุฑุงู ุจู ูุชู ู ... ููู ุจุฏูู ูุฌุงู!ุงูุจุชู ุจฺฏุงูู ุขูุจุฑฺฉุงูู ูู ููู ุทูุฑ ุจูุฏ ุงูุง ูู ุจฺฏุงูู ุฑู ุจุดุชุฑ ูพุณูุฏุฏู.ุฏุฑ ุถูู ุฎููุฏู ููุฏูู ุงุดุชุจุงูู ฺูู ุฏุงุณุชุงู ุฑุง ฺฉุงูู ูู ู ุฏูุฏ.\n",
            "ุชูุฑุจุง ูุชููู ุจฺฏู ู ุฌฺฏูู ุฎูู ุจูุฏ\n",
            "ุชูุฑุจุง ูุชููู ุจฺฏู ู ุฌฺฏูู ุฎูู ุจูุฏ\n",
            "ุฎูุจ ุจูุฏ ุงูุจุชู ุจุฑุง ุงูุฑุงุฏ ูุชูฺฉุฑ .ุจู ุงูุฑุงุฏ ุจุงููุด ุชูุตู ูฺฉูู ุจุฎููู\n",
            "ุฎูุจ ุจูุฏ ุงูุจุชู ุจุฑุง ุงูุฑุงุฏ ูุชูฺฉุฑ .ุจู ุงูุฑุงุฏ ุจุงููุด ุชูุตู ูฺฉูู ุจุฎููู\n",
            "ฺุฑุช  ูุทูู ุงููุฏุฑ ูุฒุฎุฑู ุจูุฏ ฺฉู ุจู ุฒูุฑ ุฎูุงูุฏูุด ฺฏูุชู ุนุฌุจ ฺฉุชุงุจ ฺฉุงูู ูุฌุงู ุจุงุดุฏ\n",
            "ฺุฑุช  ูุทูู ุงููุฏุฑ ูุฒุฎุฑู ุจูุฏ ฺฉู ุจู ุฒูุฑ ุฎูุงูุฏูุด ฺฏูุชู ุนุฌุจ ฺฉุชุงุจ ฺฉุงูู ูุฌุงู ุจุงุดุฏ\n",
            "ูุฑุณ ูุงูุนุง ุนุงู ุจูุฏ\n",
            "ูุฑุณ ูุงูุนุง ุนุงู ุจูุฏ\n",
            "ูุงุทูู ูุญุณู ูพูุฑ :ูุฑุณ ูุงูุนุง ุนุงู ุจูุฏ\n",
            "ูุงุทูู ูุญุณู ูพูุฑ :ูุฑุณ ูุงูุนุง ุนุงู ุจูุฏ\n",
            "ููู ุงูุนุงุฏุณุช ุขุซุงุฑ ฺฉุงูู ูุฎุตูุตุง ุดุงูฺฉุงุฑุด ุจฺฏุงูู\n",
            "ููู ุงูุนุงุฏุณุช ุขุซุงุฑ ฺฉุงูู ูุฎุตูุตุง ุดุงูฺฉุงุฑุด ุจฺฏุงูู\n",
            "ุฏููู ุงุซุฑ ูุณุชุด ฺฉู ุงุฒ ฺฉุงูู ูุฎููู ุฎูุจ ุจูุฏ\n",
            "ุฏููู ุงุซุฑ ูุณุชุด ฺฉู ุงุฒ ฺฉุงูู ูุฎููู ุฎูุจ ุจูุฏ\n",
            "ุชุฑุฌูู ุฒุงุฏ ุฎูุจ ูุจูุฏ \n",
            "ุงูุง ุงุซุฑ ุฒุจุง ุจูุฏ. \n",
            "ููุช ูุงุฏุฑ ูููุฏ ูพุณุฑุด ุฑู ฺฉุดุชู ูุงูุนุง ุจู ุชู ุฎุท ุฑุณุฏ. ฺุฒ ฺฉู ุจู ุฐูู ูู ุงููุฏ ุงู ุจูุฏ ฺฉู ฺุทูุฑ ุจุฑุง ุจูู  ฺฉุณุง ฺฉู ฺฉุดุชู ุจูุฏ ุงุฑุฒุด ูุงุฆู ููุดุฏุ ูฺฏู ุงููุง ุฎุงููุงุฏู ูุฏุงุดุชูุ ุญุงูุง ฺฉู ุจู ุณุฑ ุฎูุฏุด ุงููุฏู ูุฑู ุฎูุฏุดู ูฺฉุดู... \n",
            "ุงุฒ  ุงู ูฺฏุงู \"ูพูฺ ุจูุฏู ุฒูุฏฺฏ\" ูู ฺฉู ุชู ุงุซุฑ ุจูุฏ ุงุตูุง ุฎูุดู ูููุฏ. ุจู ูฺ ูุฌู ุญุณ ูุฒุฏฺฉ ููฺฉุฑุฏู ุจู ุงู ุฏุฏฺฏุงู. ูุชุฌู ุง ฺฉู ูู ุงุฒ ุฎููุฏูุด ฺฏุฑูุชู ุงูฺฏุงุฑ ุจุง ุจูู ูุฑู ุฏุงุฑู ูู ูู ุงุฏ ฺฉุงุฑูุง ุงูุชุงุฏู. ุงูฺฉู ูุฑฺฉุงุฑ ฺฉู ูุชุฌุด ุจู ุณุฑ ุฎูุฏุช ูุงุฏ. ูพุณ ุญูุงุณุช ุจู ุงุนูุงูุช ุจุงุดู. ุฎู ุฌุงูุจ ุจูุฏ ฺฉู ุท ุชูุงู ุฎุทูุท ฺฉู ูุฎููุฏู ุงูู ุฏู ุชุง ุฒู ุฏุงุดุชู ููุดู  ูุชู ฺฉ ุงุฒ ุงุนุถุง ุฎุงููุงุฏู  ุฎูุฏุดูู ุฑู ูฺฉุดุฏู! \n",
            "ุชุฑุฌูู ุฒุงุฏ ุฎูุจ ูุจูุฏ \n",
            "ุงูุง ุงุซุฑ ุฒุจุง ุจูุฏ. \n",
            "ููุช ูุงุฏุฑ ูููุฏ ูพุณุฑุด ุฑู ฺฉุดุชู ูุงูุนุง ุจู ุชู ุฎุท ุฑุณุฏ. ฺุฒ ฺฉู ุจู ุฐูู ูู ุงููุฏ ุงู ุจูุฏ ฺฉู ฺุทูุฑ ุจุฑุง ุจูู  ฺฉุณุง ฺฉู ฺฉุดุชู ุจูุฏ ุงุฑุฒุด ูุงุฆู ููุดุฏุ ูฺฏู ุงููุง ุฎุงููุงุฏู ูุฏุงุดุชูุ ุญุงูุง ฺฉู ุจู ุณุฑ ุฎูุฏุด ุงููุฏู ูุฑู ุฎูุฏุดู ูฺฉุดู... \n",
            "ุงุฒ  ุงู ูฺฏุงู \"ูพูฺ ุจูุฏู ุฒูุฏฺฏ\" ูู ฺฉู ุชู ุงุซุฑ ุจูุฏ ุงุตูุง ุฎูุดู ูููุฏ. ุจู ูฺ ูุฌู ุญุณ ูุฒุฏฺฉ ููฺฉุฑุฏู ุจู ุงู ุฏุฏฺฏุงู. ูุชุฌู ุง ฺฉู ูู ุงุฒ ุฎููุฏูุด ฺฏุฑูุชู ุงูฺฏุงุฑ ุจุง ุจูู ูุฑู ุฏุงุฑู ูู ูู ุงุฏ ฺฉุงุฑูุง ุงูุชุงุฏู. ุงูฺฉู ูุฑฺฉุงุฑ ฺฉู ูุชุฌุด ุจู ุณุฑ ุฎูุฏุช ูุงุฏ. ูพุณ ุญูุงุณุช ุจู ุงุนูุงูุช ุจุงุดู. ุฎู ุฌุงูุจ ุจูุฏ ฺฉู ุท ุชูุงู ุฎุทูุท ฺฉู ูุฎููุฏู ุงูู ุฏู ุชุง ุฒู ุฏุงุดุชู ููุดู  ูุชู ฺฉ ุงุฒ ุงุนุถุง ุฎุงููุงุฏู  ุฎูุฏุดูู ุฑู ูฺฉุดุฏู! \n",
            "ูพุด ฺฏูุชุงุฑ ูุชุฑุฌู ุงูุชุถุงุญ ุจูุฏ.ุชูุงู ุฏุงุณุชุงู ุชู ฺูุฏ ุตูุญู ุชุนุฑู ูฺฉูู ู ุดูู ุฎููุฏู ู ฺฉูุฌฺฉุงู ุชุง ูพุงุงู ุฏุงุณุชุงู ุงุฒ ุขุฏู ูฺฏุฑู.\n",
            "ูพุด ฺฏูุชุงุฑ ูุชุฑุฌู ุงูุชุถุงุญ ุจูุฏ.ุชูุงู ุฏุงุณุชุงู ุชู ฺูุฏ ุตูุญู ุชุนุฑู ูฺฉูู ู ุดูู ุฎููุฏู ู ฺฉูุฌฺฉุงู ุชุง ูพุงุงู ุฏุงุณุชุงู ุงุฒ ุขุฏู ูฺฏุฑู.\n",
            "ุชูุฎ ุจูุฏ :(\n",
            "ุชูุฎ ุจูุฏ :(\n",
            "ูุฐุช ุจุฑุฏู ุงุฒ ูุทุงูุนู ุงู ฺฉุชุงุจ ููฺูู ุฏฺฏุฑ ุขุซุงุฑ ฺฉุงูู.\n",
            "ูุฐุช ุจุฑุฏู ุงุฒ ูุทุงูุนู ุงู ฺฉุชุงุจ ููฺูู ุฏฺฏุฑ ุขุซุงุฑ ฺฉุงูู.\n",
            "ููููู. ุนุงู ุจูุฏ.\n",
            "ููููู. ุนุงู ุจูุฏ.\n",
            "ฺฉ ฺฉุงุฑ ูุชูุณุท ุงุฒ ฺฉุงูู.  ุงุฑุฒุด ฺฉ ุจุงุฑ ุฎูุงูุฏู ุฑุง ุฏุงุฑุฏ.\n",
            "ฺฉ ฺฉุงุฑ ูุชูุณุท ุงุฒ ฺฉุงูู.  ุงุฑุฒุด ฺฉ ุจุงุฑ ุฎูุงูุฏู ุฑุง ุฏุงุฑุฏ.\n",
            "ุนุงุงุงุงู\n",
            "ุนุงุงุงุงู\n",
            "๐๐๐๐๐๐๐๐\n",
            "\n",
            "ููููู ุจูุงูุงุตูู ู ุฒุงุฑูุด ุชู ุทุงูฺู\n",
            "ููููู ุจูุงูุงุตูู ู ุฒุงุฑูุด ุชู ุทุงูฺู\n",
            "ุฎู ุฌุงูููููููุจ ู ูพุฑ ูููููุ\n",
            "ุงูุจุชู ูุตู ุงูู ุจุฑุง ูู ุฌุฐุงุจุช ุจุดุชุฑ ุฏุงุดุช๐๐\n",
            "ุฎู ุฌุงูููููููุจ ู ูพุฑ ูููููุ\n",
            "ุงูุจุชู ูุตู ุงูู ุจุฑุง ูู ุฌุฐุงุจุช ุจุดุชุฑ ุฏุงุดุช\n",
            "\"ุจุง ฺฉุงุฑูุงู ุญููู\"ุงุซุฑ ุงูุฏ ููุฏ ูฺุงุฏ ุฺฉุชุงุจ ุงุณุช ุจู ุธุงูุฑ _ูุขู ฺฏููู ฺฉู ุจุฑ ุฌูุฏ ฺฉุชุงุจ ููุดุชู ุดุฏู_ุทูุฒุ ฺฉู ุฏุฑ ุณู ูพุฑุฏู ู ุฏุฑ ุฏู ูุงู ูพุฑุฏู ุณุน ูฺฉูุฏ ุฎูุฏู ุฑุง ุจู ูุจ ุฎูุงููุฏู ฺฉุชุงุจุด ุจุงูุฑุฏ ูู ุฏุฑ ุงู ฺฉุงุฑ ฺูุฏุงู ูููู ูุจูุฏู ุงุณุช. ุฏุฑ ูพุฑุฏู ุงูู_ูุญูู ุงูุณ_ุจู ููู ููุณูุฏู \"ุจู ุดุฑุญ ู ุชุงูู ฺูุฏ ุดุงูฺฉุงุฑ ุดุนุฑ ู ุชุฑุงูู ู ุบุฑู  ูุนุงุตุฑ ูพุฑุฏุงุฎุชู ุงู ู ุจุณุชู ุจู ุญุงููุงู ุฏุฑ ูพุฑูุณู ุฎูู ุงุซุฑ ููุฑ ุดุฑฺฉุช ุฌุณุชู ุงู.\"\n",
            "ุฏุฑ ูุงู ูพุฑุฏู ุงูู_ููู ฺุฒ ุดูุงุณ ูุฑฺฏ_ุขุฎุฑู ุฏุณุช ููุดุชู ูพุฑููุณูุฑ ุฌุงู ุชุฑุงููุชุง ุฑุง ู ุจูุฏ ฺฉู ูพุด ุงุฒ ูุฑฺฏ ุฏุฑ ุงุฎุชุงุฑ ูุชุฑุฌู ูุฑุงุฑ ุฏุงุฏู ุงุณุช.\"ุฏุฑ ุงู ูุชู ูพุฑููุณูุฑ ุชุฑุงููุชุง ุจุง ุจูุฑู ฺฏุฑ ุงุฒ ูพุดูู ูุทุงูุนุงุช ููุณู ู ุนุฑูุงู ุจู ุฏุณุช ุขูุฏู ุงุฒ ุณุงููุง ุชุญูู ู ุชูุญุต ุฏุฑ ุงุฑุงู ู ููุฏ ู ฺฏููุ ููู ุชุฑู ูุณุงุฆู ูพุฑุงููู ูพุฏุฏู ูุฑฺฏ ุฑุง ููุฑุฏ ูุงฺฉุงุฑ ูุฑุงุฑ ูุฏูุฏ\"\n",
            "ุงุฒ ูพุฑุฏู ุฏูู_ูุงููุงูู ุญุงูุธ_(ุจู ููู ููุณูุฏู)ูุชูุงูุฏ ุจู ุนููุงู ูุงููุงูู ูุงูุน ุงุณุชูุงุฏู ฺฉูุฏ ุฒุฑุง ุงุดุนุงุฑ ุญุงูุธ ุจู ููุฑุงู ุดุฑุญ ู ุชูุณุฑ ุทูุฒ ุขููุง ุฏุฑ ุงู ฺฉุชุงุจ ุขูุฏู ุงุณุช.\n",
            "ุฏุฑ ูุงู ูพุฑุฏู ุฏูู _ฺฉ ุงูุฌูู ุงุฏุจ_ููุณูุฏู ุงุฒ ุงูุฌูู ุงุฏุจ ุงุซุฑุงูุฏู ุงุฎุณฺฉุช ฺฉู ุฏุฑ ุณุงู ฺูู ู ฺูุงุฑ ุชุงุณุณ ุดุฏู ุตุญุจุช ูฺฉูุฏ.ู ุฏุฑ ููุงุช ุฏุฑ ูพุฑุฏู ุณูู_ฺฉุชุงุจุณุฑุง_ููุณูุฏู ุจู ูุนุฑู ุจูุชุฑู ฺฉุชุงุจูุง ุทูุฒ ูพุฑุฏุงุฎุชู ู ุจุฑุง ูุฑ ฺฉุฏุงู ุชูุถุญ ุทูุฒ ูุฑุงุฑ ุฏุงุฏู ุงุณุช.\n",
            "ุจู ูุธุฑ ูู ุงู ฺฉุชุงุจ ุจู ูฺ ูุฌู ูู ุชูุงูุฏ ุฏุฑ ุจู ฺฉุชุงุจูุง ุทูุฒ ูุฑุงุฑ ฺฏุฑุฏ ุฒุฑุง ูู ููุณูุฏู ุทูุฒ ูพุฑุฏุงุฒ ุฎูุจ ุงุณุช ู ูู ุชูุงุด ุงู ุจุฑุง ุฎูู ุตุญูู ูุง ุฎูุฏู ุฏุงุฑ ููุฏ ูุงูุน ุดุฏู ุงุณุช.\n",
            "ฺฉ ุณุชุงุฑู ุจุฑุง ุซุจุช ูุธุฑโ.\n",
            "***\n",
            "ุฏุฑ ุจุฎุด ุงุฒ ฺฉุชุงุจ ูุฎูุงูู:\n",
            ".\n",
            ".\n",
            "๐ณุจุง ุนุฑุถ ูพูุฒุด ุจู ุฏูู ูุจูุฏู ูุณูุช ุฌุฐุงุจ ู ุทูุฒ ุฏุฑ ุงู ฺฉุชุงุจ ุงุฒ ููุดุชู ุงู ุจุฎุด ุงุฒ ูุธุฑู ูุนุฐูุฑู\n",
            "\"ุจุง ฺฉุงุฑูุงู ุญููู\"ุงุซุฑ ุงูุฏ ููุฏ ูฺุงุฏ ุฺฉุชุงุจ ุงุณุช ุจู ุธุงูุฑ _ูุขู ฺฏููู ฺฉู ุจุฑ ุฌูุฏ ฺฉุชุงุจ ููุดุชู ุดุฏู_ุทูุฒุ ฺฉู ุฏุฑ ุณู ูพุฑุฏู ู ุฏุฑ ุฏู ูุงู ูพุฑุฏู ุณุน ูฺฉูุฏ ุฎูุฏู ุฑุง ุจู ูุจ ุฎูุงููุฏู ฺฉุชุงุจุด ุจุงูุฑุฏ ูู ุฏุฑ ุงู ฺฉุงุฑ ฺูุฏุงู ูููู ูุจูุฏู ุงุณุช. ุฏุฑ ูพุฑุฏู ุงูู_ูุญูู ุงูุณ_ุจู ููู ููุณูุฏู \"ุจู ุดุฑุญ ู ุชุงูู ฺูุฏ ุดุงูฺฉุงุฑ ุดุนุฑ ู ุชุฑุงูู ู ุบุฑู  ูุนุงุตุฑ ูพุฑุฏุงุฎุชู ุงู ู ุจุณุชู ุจู ุญุงููุงู ุฏุฑ ูพุฑูุณู ุฎูู ุงุซุฑ ููุฑ ุดุฑฺฉุช ุฌุณุชู ุงู.\"\n",
            "ุฏุฑ ูุงู ูพุฑุฏู ุงูู_ููู ฺุฒ ุดูุงุณ ูุฑฺฏ_ุขุฎุฑู ุฏุณุช ููุดุชู ูพุฑููุณูุฑ ุฌุงู ุชุฑุงููุชุง ุฑุง ู ุจูุฏ ฺฉู ูพุด ุงุฒ ูุฑฺฏ ุฏุฑ ุงุฎุชุงุฑ ูุชุฑุฌู ูุฑุงุฑ ุฏุงุฏู ุงุณุช.\"ุฏุฑ ุงู ูุชู ูพุฑููุณูุฑ ุชุฑุงููุชุง ุจุง ุจูุฑู ฺฏุฑ ุงุฒ ูพุดูู ูุทุงูุนุงุช ููุณู ู ุนุฑูุงู ุจู ุฏุณุช ุขูุฏู ุงุฒ ุณุงููุง ุชุญูู ู ุชูุญุต ุฏุฑ ุงุฑุงู ู ููุฏ ู ฺฏููุ ููู ุชุฑู ูุณุงุฆู ูพุฑุงููู ูพุฏุฏู ูุฑฺฏ ุฑุง ููุฑุฏ ูุงฺฉุงุฑ ูุฑุงุฑ ูุฏูุฏ\"\n",
            "ุงุฒ ูพุฑุฏู ุฏูู_ูุงููุงูู ุญุงูุธ_(ุจู ููู ููุณูุฏู)ูุชูุงูุฏ ุจู ุนููุงู ูุงููุงูู ูุงูุน ุงุณุชูุงุฏู ฺฉูุฏ ุฒุฑุง ุงุดุนุงุฑ ุญุงูุธ ุจู ููุฑุงู ุดุฑุญ ู ุชูุณุฑ ุทูุฒ ุขููุง ุฏุฑ ุงู ฺฉุชุงุจ ุขูุฏู ุงุณุช.\n",
            "ุฏุฑ ูุงู ูพุฑุฏู ุฏูู _ฺฉ ุงูุฌูู ุงุฏุจ_ููุณูุฏู ุงุฒ ุงูุฌูู ุงุฏุจ ุงุซุฑุงูุฏู ุงุฎุณฺฉุช ฺฉู ุฏุฑ ุณุงู ฺูู ู ฺูุงุฑ ุชุงุณุณ ุดุฏู ุตุญุจุช ูฺฉูุฏ.ู ุฏุฑ ููุงุช ุฏุฑ ูพุฑุฏู ุณูู_ฺฉุชุงุจุณุฑุง_ููุณูุฏู ุจู ูุนุฑู ุจูุชุฑู ฺฉุชุงุจูุง ุทูุฒ ูพุฑุฏุงุฎุชู ู ุจุฑุง ูุฑ ฺฉุฏุงู ุชูุถุญ ุทูุฒ ูุฑุงุฑ ุฏุงุฏู ุงุณุช.\n",
            "ุจู ูุธุฑ ูู ุงู ฺฉุชุงุจ ุจู ูฺ ูุฌู ูู ุชูุงูุฏ ุฏุฑ ุจู ฺฉุชุงุจูุง ุทูุฒ ูุฑุงุฑ ฺฏุฑุฏ ุฒุฑุง ูู ููุณูุฏู ุทูุฒ ูพุฑุฏุงุฒ ุฎูุจ ุงุณุช ู ูู ุชูุงุด ุงู ุจุฑุง ุฎูู ุตุญูู ูุง ุฎูุฏู ุฏุงุฑ ููุฏ ูุงูุน ุดุฏู ุงุณุช.\n",
            "ฺฉ ุณุชุงุฑู ุจุฑุง ุซุจุช ูุธุฑ.\n",
            "***\n",
            "ุฏุฑ ุจุฎุด ุงุฒ ฺฉุชุงุจ ูุฎูุงูู:\n",
            ".\n",
            ".\n",
            "ุจุง ุนุฑุถ ูพูุฒุด ุจู ุฏูู ูุจูุฏู ูุณูุช ุฌุฐุงุจ ู ุทูุฒ ุฏุฑ ุงู ฺฉุชุงุจ ุงุฒ ููุดุชู ุงู ุจุฎุด ุงุฒ ูุธุฑู ูุนุฐูุฑู\n",
            "ูุตู ูุงููุงูู ุญุงูุธ ูุงูุนุง ุฌุงูุจ ุจูุฏ!\n",
            "ูุตู ูุงููุงูู ุญุงูุธ ูุงูุนุง ุฌุงูุจ ุจูุฏ!\n",
            "ูุชูุณุท\n",
            "ูุชูุณุท\n",
            "ุนุงู.....\n",
            "ุฏุฒููู ููุฑูุงู ุฑุง ุจูุชุฑ ุจุดูุงุณุฏ......\n",
            "ุดูุฑ ฺฉู ุงุณูู  ููุงูุช ุงุฑุงู ุงุณุช ุฏุฑ ุฑูุฒฺฏุงุฑ ฺฏู ุตุฏุงู (ูุนูุช ุงููู ุนูู) ุฏุณุชูุฑ ุญููู ุฑุง ุจุง '' ุงูู_ุฏุฒููู ุขุบุงุฒ ู ฺฉุฑุฏ!\n",
            "ุนุงู.....\n",
            "ุฏุฒููู ููุฑูุงู ุฑุง ุจูุชุฑ ุจุดูุงุณุฏ......\n",
            "ุดูุฑ ฺฉู ุงุณูู  ููุงูุช ุงุฑุงู ุงุณุช ุฏุฑ ุฑูุฒฺฏุงุฑ ฺฏู ุตุฏุงู (ูุนูุช ุงููู ุนูู) ุฏุณุชูุฑ ุญููู ุฑุง ุจุง '' ุงูู_ุฏุฒููู ุขุบุงุฒ ู ฺฉุฑุฏ!\n",
            "ฺฉุชุงุจ ุงุณุช ฺฉู ุฏุงุณุชุงููุงุด ุงุฒ ุฐููุช ุญูู ุฏูุฑ ุงุณุช ู ููุดุชู ุจุฑ ุงุณุงุณ ุณุงุฎุชุงุฑ ููุถูุนุช ูุณุช ู ุชููุง ูฺฉุชู ูุซุจุช ุขู ฺฏุฑู ู ุตููุช ุฏุงุณุชุงู ุงุณุช\n",
            "ฺฉุชุงุจ ุงุณุช ฺฉู ุฏุงุณุชุงููุงุด ุงุฒ ุฐููุช ุญูู ุฏูุฑ ุงุณุช ู ููุดุชู ุจุฑ ุงุณุงุณ ุณุงุฎุชุงุฑ ููุถูุนุช ูุณุช ู ุชููุง ูฺฉุชู ูุซุจุช ุขู ฺฏุฑู ู ุตููุช ุฏุงุณุชุงู ุงุณุช\n",
            "ฺฉุชุงุจ\"ุนฺฉุณ ูพุดู ุง\"ุงุฒุฏู ุฏุงุณุชุงู ฺฉูุชุงู ุฏุฑุจุงุฑู ูพุณุฑ ููุช ุณุงูู ุจู ูุงู\"ุณุนุฏู\"ุงุณุช ฺฉู ุฏุฑ ุฎูุฒุณุชุงู ุฒูุฏฺฏ ูฺฉูุฏ ู ููู ุชุฑู ุนูุงู ุงู ูุงูฺฏุฑ ู ูุฏู ุฒุฏู ุฏุฑ ูุฎูุณุชุงู ุงุณุช ฺฉู ุฏุฑ ุฏุงุณุชุงููุง ฺฉุชุงุจ ุจู ุขู ูพุฑุฏุงุฎุชู ู ุดูุฏ.\n",
            "ุจุฑุฎูุงู ุทุจูู ุจูุฏ ฺฉุชุงุจูุง ุฏุฑ ุทุงูฺู-ฺฉู ุงู ฺฉุชุงุจ ุฑุง ุฌุฒู ฺฉุชุงุจูุง ููุฌูุงู ูุฑุงุฑ ุฏุงุฏู ุงุณุช-ุงู ฺฉุชุงุจ ูุชุนูู ุจู ฺฏุฑูู ุณู'ุฌ'ุนู ุณุงููุง ูพุงุงู ุฏุจุณุชุงู(ูพูุฌู ู ุดุดู ุฏุจุณุชุงู)ุงุณุช.\n",
            "ฺฉ ุงุฒ ููู ุชุฑู ูฺฉุงุช ุฏุฑ ฺฉุชุงุจูุง ุงู ุฑุฏู ุณู ุจุงุฏ ุชุตูุฑฺฏุฑ ุฌุฐุงุจ ุขููุง ุจุงุดุฏ ฺฉู ูุชุงุณูุงูู ุฏุฑ ุงู ฺฉุชุงุจ ุงู ุฌุฐุงุจุช ูุฌูุฏ ูุฏุงุดุช.ููุทู ุถุนู ุฏฺฏุฑ ุงู ฺฉุชุงุจ ูุฒ ูพุงุงู ุจุงุฒ ู ูู ฺูุฏุงู ุฏู ฺุณุจ ฺฉุชุงุจ ุจูุฏ.\n",
            "ฺฉุชุงุจ\"ุนฺฉุณ ูพุดู ุง\"ุงุฒุฏู ุฏุงุณุชุงู ฺฉูุชุงู ุฏุฑุจุงุฑู ูพุณุฑ ููุช ุณุงูู ุจู ูุงู\"ุณุนุฏู\"ุงุณุช ฺฉู ุฏุฑ ุฎูุฒุณุชุงู ุฒูุฏฺฏ ูฺฉูุฏ ู ููู ุชุฑู ุนูุงู ุงู ูุงูฺฏุฑ ู ูุฏู ุฒุฏู ุฏุฑ ูุฎูุณุชุงู ุงุณุช ฺฉู ุฏุฑ ุฏุงุณุชุงููุง ฺฉุชุงุจ ุจู ุขู ูพุฑุฏุงุฎุชู ู ุดูุฏ.\n",
            "ุจุฑุฎูุงู ุทุจูู ุจูุฏ ฺฉุชุงุจูุง ุฏุฑ ุทุงูฺู-ฺฉู ุงู ฺฉุชุงุจ ุฑุง ุฌุฒู ฺฉุชุงุจูุง ููุฌูุงู ูุฑุงุฑ ุฏุงุฏู ุงุณุช-ุงู ฺฉุชุงุจ ูุชุนูู ุจู ฺฏุฑูู ุณู'ุฌ'ุนู ุณุงููุง ูพุงุงู ุฏุจุณุชุงู(ูพูุฌู ู ุดุดู ุฏุจุณุชุงู)ุงุณุช.\n",
            "ฺฉ ุงุฒ ููู ุชุฑู ูฺฉุงุช ุฏุฑ ฺฉุชุงุจูุง ุงู ุฑุฏู ุณู ุจุงุฏ ุชุตูุฑฺฏุฑ ุฌุฐุงุจ ุขููุง ุจุงุดุฏ ฺฉู ูุชุงุณูุงูู ุฏุฑ ุงู ฺฉุชุงุจ ุงู ุฌุฐุงุจุช ูุฌูุฏ ูุฏุงุดุช.ููุทู ุถุนู ุฏฺฏุฑ ุงู ฺฉุชุงุจ ูุฒ ูพุงุงู ุจุงุฒ ู ูู ฺูุฏุงู ุฏู ฺุณุจ ฺฉุชุงุจ ุจูุฏ.\n",
            "ูู ุฎูุดู ูููุฏ ฺฉุณู ฺฉููุฏู ุจูุฏ\n",
            "ูู ุฎูุดู ูููุฏ ฺฉุณู ฺฉููุฏู ุจูุฏ\n",
            "ุนุงูู ุ ููุท ุฏู ุชุง ุงุฒ ุฏุงุณุชุงูุง ุฌุฐุงุจ ูุจูุฏู ุ ุชุฑุฌูู ูู ุฑููููู\n",
            "ุนุงูู ุ ููุท ุฏู ุชุง ุงุฒ ุฏุงุณุชุงูุง ุฌุฐุงุจ ูุจูุฏู ุ ุชุฑุฌูู ูู ุฑููููู\n",
            "ุฎุณุชู ฺฉููุฏู ุจูุฏ ุชูุถุญุงุช ุจ ููุฑุฏ ุฏุงุดุช ู ูุญูุดู ูุซู ูุญู ูพุฑ ุดูุฑ ูุงุทูุฑุฏุดุช ูุจูุฏ\n",
            "ุฎุณุชู ฺฉููุฏู ุจูุฏ ุชูุถุญุงุช ุจ ููุฑุฏ ุฏุงุดุช ู ูุญูุดู ูุซู ูุญู ูพุฑ ุดูุฑ ูุงุทูุฑุฏุดุช ูุจูุฏ\n",
            "ุงููู ฺฉุชุงุจ ุจูุฏ ฺฉู ุงุฒ ุณููุฌุฑ ูุฎููุฏู ุฎูุดู ูููุฏ\n",
            "ุงููู ฺฉุชุงุจ ุจูุฏ ฺฉู ุงุฒ ุณููุฌุฑ ูุฎููุฏู ุฎูุดู ูููุฏ\n",
            "ุจุณุงุฑ ุฌุงูุจ ุจูุฏ\n",
            "ุจุณุงุฑ ุฌุงูุจ ุจูุฏ\n",
            "ูู ฺฉู ูุฐุช ุจุฑุฏู\n",
            "ูู ฺฉู ูุฐุช ุจุฑุฏู\n",
            "ุฎู ฺฉุชุงุจ ุฎูุจ ู  ูุดูฺฏู\n",
            "ุฎู ฺฉุชุงุจ ุฎูุจ ู  ูุดูฺฏู\n",
            "ุงู ฺฉุชุงุจ ุฑุง ุฌุงุฒู ูู ุจุฑุฏู ุงุณุช. ุฌุงุฒู ุจูุชุฑู ุจุงุฒููุณ ฺฉุงููู ูพุฑูุฑุด.\n",
            "ุงู ฺฉุชุงุจ ุฑุง ุฌุงุฒู ูู ุจุฑุฏู ุงุณุช. ุฌุงุฒู ุจูุชุฑู ุจุงุฒููุณ ฺฉุงููู ูพุฑูุฑุด.\n",
            "ุทุงูฺู ูุฑุณ ฺฉู ุฏุงุณุชุงููุง ุฎูุจู ููุงุณุจ ุจฺู ูุง ฺฏุฐุงุดุช\n",
            "ุทุงูฺู ูุฑุณ ฺฉู ุฏุงุณุชุงููุง ุฎูุจู ููุงุณุจ ุจฺู ูุง ฺฏุฐุงุดุช\n",
            "ูุฌููุนู ฺฉุชุงุจูุง ุฑูุฒฺฏุงุฑุงู ุนุงูู... ุนุงู... ุง ฺฉุงุด ูุฒุงุฑุงู ูุฒุงุฑ ุงุฒ ุงู ุฎุงุทุฑุงุช ุจุง ููู ููู ุซุจุช ูุดุฏ\n",
            "ููุดู ุชู ฺฉุชุงุจุฎูููโุงู ูุณุชู. ูุฑููุช ุจุฑุดูู ูุฏุงุฑู ุญุชูุง ฺฉ ุฏูุชุง ุงุฒ ุฎุงุทุฑุงุชุด ุฑู ูุฎููู... ู ุงูุจุชู ูฺููุช ูููู ููุดู ุจู ฺฉ ุฏูุชุง ุจุณูุฏู ฺฉูู ุ)\n",
            "ูุฌููุนู ฺฉุชุงุจูุง ุฑูุฒฺฏุงุฑุงู ุนุงูู... ุนุงู... ุง ฺฉุงุด ูุฒุงุฑุงู ูุฒุงุฑ ุงุฒ ุงู ุฎุงุทุฑุงุช ุจุง ููู ููู ุซุจุช ูุดุฏ\n",
            "ููุดู ุชู ฺฉุชุงุจุฎูููโุงู ูุณุชู. ูุฑููุช ุจุฑุดูู ูุฏุงุฑู ุญุชูุง ฺฉ ุฏูุชุง ุงุฒ ุฎุงุทุฑุงุชุด ุฑู ูุฎููู... ู ุงูุจุชู ูฺููุช ูููู ููุดู ุจู ฺฉ ุฏูุชุง ุจุณูุฏู ฺฉูู ุ)\n",
            "ุฒุงุฏ ุฌุงูุจ ูุจูุฏ ุฎู ฺฉูุชุงู ุจูุฏูุฏ ุฎุงุทุฑุงุช.\n",
            "ุฒุงุฏ ุฌุงูุจ ูุจูุฏ ุฎู ฺฉูุชุงู ุจูุฏูุฏ ุฎุงุทุฑุงุช.\n",
            "ุงฺฏุฑ ูุงุฑุณ ุจูุฏ ูุจูุฏูุ ุจุฑุง ุฎูุงูุฏู ุงู ฺฉุชุงุจ ุงุฏ ู ฺฏุฑูุชูุ ฺฉุชุงุจ ุจุณุงุฑ ุนุงู ุงุณุช\n",
            "ุงฺฏุฑ ูุงุฑุณ ุจูุฏ ูุจูุฏูุ ุจุฑุง ุฎูุงูุฏู ุงู ฺฉุชุงุจ ุงุฏ ู ฺฏุฑูุชูุ ฺฉุชุงุจ ุจุณุงุฑ ุนุงู ุงุณุช\n",
            "ุนุฌุจู ููุช ูุจูู ฺฉุชุงุจ ุจู ุงู ุฎูุจ ูฺ ฺฉุงููุช ูุฏุงุฑู \n",
            "ุงู ฺฉุชุงุจ ุฎู ุนุงูู\n",
            "ุนุฌุจู ููุช ูุจูู ฺฉุชุงุจ ุจู ุงู ุฎูุจ ูฺ ฺฉุงููุช ูุฏุงุฑู \n",
            "ุงู ฺฉุชุงุจ ุฎู ุนุงูู\n",
            "ููููู ุงุฒ ุฎุฏูุงุช ุดูุง\n",
            "ููููู ุงุฒ ุฎุฏูุงุช ุดูุง\n",
            "ุณูุงู ุ ฺฺฏููู ูุชููู ฺฉุชุงุจ ุฑุง ุจู ุตูุฑุช ูพ ุฏ ุงู ุฑู ฺฏูุด ุง ฺฉุงูพูุชุฑ ุฏุงุดุชู ุจุงุดู ุุ\n",
            "ุณูุงู ุ ฺฺฏููู ูุชููู ฺฉุชุงุจ ุฑุง ุจู ุตูุฑุช ูพ ุฏ ุงู ุฑู ฺฏูุด ุง ฺฉุงูพูุชุฑ ุฏุงุดุชู ุจุงุดู ุุ\n",
            "ุชูุตูุด ุฒุงุฏูุ ุจุงุฏ ุญุฑู ุฎูุฏุดู ูุฒุฏ ุฏฺฏู ฺูุฏ ุจูู ุฑู ููุฏ ฺฉุฑุฏู..\n",
            "ุชูุตูุด ุฒุงุฏูุ ุจุงุฏ ุญุฑู ุฎูุฏุดู ูุฒุฏ ุฏฺฏู ฺูุฏ ุจูู ุฑู ููุฏ ฺฉุฑุฏู..\n",
            "ูุดุฑู ุฏุงุฑุง ูุญุชูุง ุจุณุงุฑ ุฎูุจ ู ุจุงุดุฏ ุจุง ุชูุฌู ุจู ุงูฺฉู ูุงููุฏ ุณุงุฑ ูุฌูุงุช ุงู ุญูุฒู ุฏุงุฑุง ุชุจูุบุงุช ุจ ุดูุงุฑ ูุณุช \n",
            "ูุดุฑู ุฏุงุฑุง ูุญุชูุง ุจุณุงุฑ ุฎูุจ ู ุจุงุดุฏ ุจุง ุชูุฌู ุจู ุงูฺฉู ูุงููุฏ ุณุงุฑ ูุฌูุงุช ุงู ุญูุฒู ุฏุงุฑุง ุชุจูุบุงุช ุจ ุดูุงุฑ ูุณุช \n",
            "ุจู ูุธุฑ ูู ูุฌูู ุฌุงูุจ ุจูุฏ\n",
            "ุจู ูุธุฑ ูู ูุฌูู ุฌุงูุจ ุจูุฏ\n",
            "ูู ุจู ูุธุฑ ูู ุฎู ุฎูุจู. ุงู ูุงููุงูู ฺฉุงููุง ุชุฎุตุตู. ุดุงุฏ ุนฺฉุณ ูุฏุงุดุชู ุจุงุดู ฺฉู ฺฉุณ ุฎูุดุด ุจุงุฏ ุง ูู. ฺุฒ ฺฉู ูููู ูุญุชูุง ูุงููุงูู ูุณุช\n",
            "ูู ุจู ูุธุฑ ูู ุฎู ุฎูุจู. ุงู ูุงููุงูู ฺฉุงููุง ุชุฎุตุตู. ุดุงุฏ ุนฺฉุณ ูุฏุงุดุชู ุจุงุดู ฺฉู ฺฉุณ ุฎูุดุด ุจุงุฏ ุง ูู. ฺุฒ ฺฉู ูููู ูุญุชูุง ูุงููุงูู ูุณุช\n",
            "ุงูุชุถุงุญู\n",
            "ุงูุชุถุงุญู\n",
            "ูู ุฎู ุงุฒ ุฏุงุณุชุงู ูุงุด ุฎูุดู ู ุงุฏ\n",
            "ูู ุฎู ุงุฒ ุฏุงุณุชุงู ูุงุด ุฎูุดู ู ุงุฏ\n",
            "ุจุงุณูุงู\n",
            "ุฎู ููุช ุจูุฏ ฺฉู ุฏูุจุงู ฺฉ ฺฉุชุงุจ ููุฏุ ุขููุฒูุฏู ุจุฑุง ูุตู ูุง ูุฑ ุดุจ ูพุณุฑู ู ฺฏุดุชู.\n",
            "ููุช ฺูุฏ ุฑูุฒ ูุจู ุชู ุชููุฒูู ุชุฒุฑ ููู ฺฉุงุฑุชูู ฺฉููู ู ุฏููู ุฑุง ุฏุฏูุ ุงุฏ ุจุฎุด ุงุฒ ุงู ฺฉุชุงุจ ุชู ุฏูุฑู ูุฏุฑุณู ุงูุชุงุฏู. ูุงุณู ููู ุฏุงูููุฏุด ฺฉุฑุฏู ู ูุฑ ุดุจ ุฏุงุฑู ุงุฒ ูุตู ูุงุด ูุฐุช ู ุจุฑู.\n",
            "ุจุงุชุดฺฉุฑ\n",
            "ุจุงุณูุงู\n",
            "ุฎู ููุช ุจูุฏ ฺฉู ุฏูุจุงู ฺฉ ฺฉุชุงุจ ููุฏุ ุขููุฒูุฏู ุจุฑุง ูุตู ูุง ูุฑ ุดุจ ูพุณุฑู ู ฺฏุดุชู.\n",
            "ููุช ฺูุฏ ุฑูุฒ ูุจู ุชู ุชููุฒูู ุชุฒุฑ ููู ฺฉุงุฑุชูู ฺฉููู ู ุฏููู ุฑุง ุฏุฏูุ ุงุฏ ุจุฎุด ุงุฒ ุงู ฺฉุชุงุจ ุชู ุฏูุฑู ูุฏุฑุณู ุงูุชุงุฏู. ูุงุณู ููู ุฏุงูููุฏุด ฺฉุฑุฏู ู ูุฑ ุดุจ ุฏุงุฑู ุงุฒ ูุตู ูุงุด ูุฐุช ู ุจุฑู.\n",
            "ุจุงุชุดฺฉุฑ\n",
            "ฺฉุชุงุจ ูุดูฺฏู.\n",
            "ุญููู ูุง ุฌูฺฏู ุงูฺฏุงุฑ ูุฑ ฺฉุฏููุดูู ฺฉ ุขุฏูู ุจุง ุฑูุญุงุช ูุฎุชูู:)\n",
            "ฺฉุชุงุจ ูุดูฺฏู.\n",
            "ุญููู ูุง ุฌูฺฏู ุงูฺฏุงุฑ ูุฑ ฺฉุฏููุดูู ฺฉ ุขุฏูู ุจุง ุฑูุญุงุช ูุฎุชูู:)\n",
            "ฺฉ ุงุฒ ูพุฑ ุจุงุฑ ุชุฑู ุฏุงุณุชุงู ูุง ุงุฑุงู.. ุจุนุฏ ุฏูุณุชููู ูฺฏู ููุช ุฒุงุฏู ุจู ูุณุจุช ูุญุชู!!!\n",
            "ฺฉ ุงุฒ ูพุฑ ุจุงุฑ ุชุฑู ุฏุงุณุชุงู ูุง ุงุฑุงู.. ุจุนุฏ ุฏูุณุชููู ูฺฏู ููุช ุฒุงุฏู ุจู ูุณุจุช ูุญุชู!!!\n",
            "ูุดูฺฏู ุงูุง ููุชุด ุฒุงุฏู ุจู ูุณุจุช ูุญุชูุงุด\n",
            "ูุดูฺฏู ุงูุง ููุชุด ุฒุงุฏู ุจู ูุณุจุช ูุญุชูุงุด\n",
            "ุฎููุฏูุดูู ุจุฑุง ุจฺู ูุง ุนุงูู\n",
            "ุฎููุฏูุดูู ุจุฑุง ุจฺู ูุง ุนุงูู\n",
            "ฺฉุชุจ ุงุฏฺฏุงุฑุงู ุฎู ุฎูุจ ูุณุชุฏ ููุท ู ุจุฏ ฺฉู ุฏุงุฑูุฏ ุงูู ฺฉู ุจุนุถ ุงุฒ ุฎุงุทุฑู ูุง ุฑู ููุดู ูุชูุฌู ุดุฏ ุงุฒ ุฒุจุงู ฺู ฺฉุณ ูุณุช.\n",
            "ฺฉุชุจ ุงุฏฺฏุงุฑุงู ุฎู ุฎูุจ ูุณุชุฏ ููุท ู ุจุฏ ฺฉู ุฏุงุฑูุฏ ุงูู ฺฉู ุจุนุถ ุงุฒ ุฎุงุทุฑู ูุง ุฑู ููุดู ูุชูุฌู ุดุฏ ุงุฒ ุฒุจุงู ฺู ฺฉุณ ูุณุช.\n",
            "ฺฉุชุงุจ ุฑู ุฏูุณุช ุฏุงุดุชู ฺูู ููุณูุฏู ุจ ูฺ ฺฉูุดู ุง ู ุฏุฑ ูุงูุจ ฺฉ ุฏุงุณุชุงู ููุงุฏู ุจุง ุฑูุงุช ุฌุฐุงุจ ู ุดุฎุตุช ูพุฑุฏุงุฒ ูู ุฑูุฌ ูุง ฺฉ ููุช ุฑู ุจุงู ฺฉุฑุฏู ุจูุฏ ุฎู ุฎูุจ ุดุฎุตุช ูุง ุฑู ุจู ูู ุฑุจุท ุฏุงุฏ ู ุบุงููฺฏุฑ ุฎูุจ ุฏุงุดุช ุฏุฑ ุงูุงุฎุฑ ุฏุงุณุชุงู ุฏุฑ ุถูู ุชุฑุฌูู ุฎู ุฎูุจ ู ุฑูุงู ุจูุฏ\n",
            "ฺฉุชุงุจ ุฑู ุฏูุณุช ุฏุงุดุชู ฺูู ููุณูุฏู ุจ ูฺ ฺฉูุดู ุง ู ุฏุฑ ูุงูุจ ฺฉ ุฏุงุณุชุงู ููุงุฏู ุจุง ุฑูุงุช ุฌุฐุงุจ ู ุดุฎุตุช ูพุฑุฏุงุฒ ูู ุฑูุฌ ูุง ฺฉ ููุช ุฑู ุจุงู ฺฉุฑุฏู ุจูุฏ ุฎู ุฎูุจ ุดุฎุตุช ูุง ุฑู ุจู ูู ุฑุจุท ุฏุงุฏ ู ุบุงููฺฏุฑ ุฎูุจ ุฏุงุดุช ุฏุฑ ุงูุงุฎุฑ ุฏุงุณุชุงู ุฏุฑ ุถูู ุชุฑุฌูู ุฎู ุฎูุจ ู ุฑูุงู ุจูุฏ\n",
            "ุชููุง ฺฉุชุงุจู ฺฉู ูุฑ ุณุงู ูุฎูููุด ู ุญุณ ุฎูุจ ุจูู ูุฏู\n",
            "ุชููุง ฺฉุชุงุจู ฺฉู ูุฑ ุณุงู ูุฎูููุด ู ุญุณ ุฎูุจ ุจูู ูุฏู\n",
            "ุชููุง ฺฉุชุงุจ ฺฉู ูพูุฌ ุณุงู ุงุฒ ุฎููุฏูุด ฺฏุฐุดุชู ู ูููููุฒ ุจุฑุงู ุฌุฐุงุจู\n",
            "ุชููุง ฺฉุชุงุจ ฺฉู ูพูุฌ ุณุงู ุงุฒ ุฎููุฏูุด ฺฏุฐุดุชู ู ูููููุฒ ุจุฑุงู ุฌุฐุงุจู\n",
            "ุชูุฌู: ุงูุ ฺฉ ฺฉุชุงุจ ุนุงุฏ ูุณุช! ุขุฎุฑู ุงูุงุฑ ุฏูุงุ ุฏูุง ุงุฒ ุณูุจู ูุง ู ุงุณุชุนุงุฑู ูุงุณุช.. ูุทูุง ุจุง ุงุญุชุงุท ุจุฎูุงูุฏ. ูุทูุง ุนูู ุจุฎูุงูุฏ.\n",
            "ุชูุฌู: ุงูุ ฺฉ ฺฉุชุงุจ ุนุงุฏ ูุณุช! ุขุฎุฑู ุงูุงุฑ ุฏูุงุ ุฏูุง ุงุฒ ุณูุจู ูุง ู ุงุณุชุนุงุฑู ูุงุณุช.. ูุทูุง ุจุง ุงุญุชุงุท ุจุฎูุงูุฏ. ูุทูุง ุนูู ุจุฎูุงูุฏ.\n",
            "ฺฉุชุงุจ ุฎู ุฎู ุฎูุจ ุจูุฏ.\n",
            "ููุถูุนุงุช ูุซู ุฌูฺฏุูุญุฑููุชุุชู ู ....ุฑู ุฏุฑ ูุงูุจ ููุงุฏ ูุง ุณุฑุงุณ ูุงููุฏ ู ูุญูุฏ ุฏู ุดุดู ุง ู...ูุดูู ูุฏู.ุฎู ฺฉุชุงุจ ุฎูุจู.\n",
            "ูู ุฑู ุฎู ุงุฏ ฺฉุชุงุจ ุจุงุฏุจุงุฏฺฉโุจุงุฒ ุงูุฏุงุฎุช.ุงููู ูุซู ููู ฺฉุชุงุจ ุฎู ุฎูุจู\n",
            "ฺฉุชุงุจ ุฎู ุฎู ุฎูุจ ุจูุฏ.\n",
            "ููุถูุนุงุช ูุซู ุฌูฺฏุูุญุฑููุชุุชู ู ....ุฑู ุฏุฑ ูุงูุจ ููุงุฏ ูุง ุณุฑุงุณ ูุงููุฏ ู ูุญูุฏ ุฏู ุดุดู ุง ู...ูุดูู ูุฏู.ุฎู ฺฉุชุงุจ ุฎูุจู.\n",
            "ูู ุฑู ุฎู ุงุฏ ฺฉุชุงุจ ุจุงุฏุจุงุฏฺฉโุจุงุฒ ุงูุฏุงุฎุช.ุงููู ูุซู ููู ฺฉุชุงุจ ุฎู ุฎูุจู\n",
            "ููููู ุงุฒ ุจุงุจุช ุชุฎูู๐\n",
            "ููููู ุงุฒ ุจุงุจุช ุชุฎูู\n",
            "ฺฉุชุงุจ ุฑุฆุงูุณู ุฌุงุฏู ุจ ูุธุฑ ุฏุงุฑู ุฎูุงููุฏู ุฑู ูพุง ุจู ูพุง ุฎูุฏุด ูุงู ุณููู ุงููุฑุงุฏ ุตุฎุฑู ูุงู.. ู ฺฉุดููู\n",
            "ูุชุฑุฌู(ูุฑูุงู ุญูุจฺู ุง) ุชุณูุท ฺฉุงูู ุจุฑ ูุฑ ุฏู ุฒุจูู ุฏุงุฑู ู ฺฉุงููุง ุจุฑ ูุชู ุชุฑุฌูู ุณูุงุฑู ูุชุงุณูุงูู ูุชุฑุฌู ูุง ุฏฺฏู ูุณุจุชุง ุชุญุช ุงููุธ ุชุฑุฌูู ฺฉุฑุฏู ุจุนุฏ ุจุฏููู ุญุช ุฎูุฏุดูู ูู ุจูููู ฺ ุชุฑุฌูู ฺฉุฑุฏู\n",
            "ฺฉุชุงุจ ุฑุฆุงูุณู ุฌุงุฏู ุจ ูุธุฑ ุฏุงุฑู ุฎูุงููุฏู ุฑู ูพุง ุจู ูพุง ุฎูุฏุด ูุงู ุณููู ุงููุฑุงุฏ ุตุฎุฑู ูุงู.. ู ฺฉุดููู\n",
            "ูุชุฑุฌู(ูุฑูุงู ุญูุจฺู ุง) ุชุณูุท ฺฉุงูู ุจุฑ ูุฑ ุฏู ุฒุจูู ุฏุงุฑู ู ฺฉุงููุง ุจุฑ ูุชู ุชุฑุฌูู ุณูุงุฑู ูุชุงุณูุงูู ูุชุฑุฌู ูุง ุฏฺฏู ูุณุจุชุง ุชุญุช ุงููุธ ุชุฑุฌูู ฺฉุฑุฏู ุจุนุฏ ุจุฏููู ุญุช ุฎูุฏุดูู ูู ุจูููู ฺ ุชุฑุฌูู ฺฉุฑุฏู\n",
            "ุจู ูุงุณุทู ุญุถูุฑ ฺูุฏู ุณุงููโู ุฏุฑ ุงุณุชุงู ฺฉุฑุฏุณุชุงู ู ุฏุฑฺฉ ูุฑููฺฏ ุงู ููู ููุฑููุฏ ู ุนูุงููโู ุจู ุงุฏุจุงุช ู ูุฑููฺฏ ุงู ุฎุทู ุจุงุฏ ุนุฑุถ ฺฉูู ฺฉู ุจู ูุธุฑ ูู ุจุฎุชุงุฑ ุนู ู ุดุฑุฒุงุฏ ุญุณู ุฑู ูุดู ุฌุฒุก ุจูุชุฑู ููุณูุฏูโูุง ฺฉุฑุฏ ุฒุจุงู ุญุณุงุจ ฺฉุฑุฏ.\n",
            "ููฺูู ุจุง ุชูุฌู ุจู ุฎูุงูุด ฺูุฏู ุชุฑุฌูู ุงุฒ ฺฉุชุงุจูุง ุงู ุนุฒุฒุงู ุจู ููู ุณุงุฑ ูุชุฑุฌููุ ุจุงุฏ ุจฺฏู ุชุฑุฌููโูุง ุขูุง ูุฑูุงู ุญูุจฺูโุง ุนุงูู.\n",
            "ุฎููุฏู ุงู ฺฉุชุงุจ ู ฺฉุชุงุจ \"ุญุตุงุฑ ู ุณฺฏูุง ูพุฏุฑ\" ุงุฒ ุงุณุชุงุฏ ุดุฑุฒุงุฏ ุญุณู ุฑู ุจู ุดุฏุช ุชูุตู ูฺฉูู.\n",
            "ุจู ูุงุณุทู ุญุถูุฑ ฺูุฏู ุณุงููโู ุฏุฑ ุงุณุชุงู ฺฉุฑุฏุณุชุงู ู ุฏุฑฺฉ ูุฑููฺฏ ุงู ููู ููุฑููุฏ ู ุนูุงููโู ุจู ุงุฏุจุงุช ู ูุฑููฺฏ ุงู ุฎุทู ุจุงุฏ ุนุฑุถ ฺฉูู ฺฉู ุจู ูุธุฑ ูู ุจุฎุชุงุฑ ุนู ู ุดุฑุฒุงุฏ ุญุณู ุฑู ูุดู ุฌุฒุก ุจูุชุฑู ููุณูุฏูโูุง ฺฉุฑุฏ ุฒุจุงู ุญุณุงุจ ฺฉุฑุฏ.\n",
            "ููฺูู ุจุง ุชูุฌู ุจู ุฎูุงูุด ฺูุฏู ุชุฑุฌูู ุงุฒ ฺฉุชุงุจูุง ุงู ุนุฒุฒุงู ุจู ููู ุณุงุฑ ูุชุฑุฌููุ ุจุงุฏ ุจฺฏู ุชุฑุฌููโูุง ุขูุง ูุฑูุงู ุญูุจฺูโุง ุนุงูู.\n",
            "ุฎููุฏู ุงู ฺฉุชุงุจ ู ฺฉุชุงุจ \"ุญุตุงุฑ ู ุณฺฏูุง ูพุฏุฑ\" ุงุฒ ุงุณุชุงุฏ ุดุฑุฒุงุฏ ุญุณู ุฑู ุจู ุดุฏุช ุชูุตู ูฺฉูู.\n",
            "ุฏุฑุณุชู ุงุฑุฒุด ฺฉุชุงุจ ุจุงูุงุณุช\n",
            "ุงูุงู ุฎูุงูุด ุฏุงุฑู ุงููู ุงูู ฺฉู ฺฉุชุงุจุง ุฑุงฺฏุงู ุจุดุชุฑ ุจุฒุงุฑุฏ\n",
            "ุฎุนู ุฎุนู ููููู ูุดู๐\n",
            "ูุชุฃุณูุงูู ูพูู ูุฏุงุดุชู ุงู ฺฉุชุงุจู ุจุฎุฑู ูู ฺฺฉุฏู ูุง ุงุฒูุชูุดู ุฎููุฏู ุฎุนู ูุดูฺฏ ุจูุฏ\n",
            "ูุฎู ูุดุชุงูู ฺฉู ุงู ฺฉุชุงุจู ฺฉุงูู ุจุฎููู๐\n",
            "ุฏุฑุณุชู ุงุฑุฒุด ฺฉุชุงุจ ุจุงูุงุณุช\n",
            "ุงูุงู ุฎูุงูุด ุฏุงุฑู ุงููู ุงูู ฺฉู ฺฉุชุงุจุง ุฑุงฺฏุงู ุจุดุชุฑ ุจุฒุงุฑุฏ\n",
            "ุฎุนู ุฎุนู ููููู ูุดู\n",
            "ูุชุฃุณูุงูู ูพูู ูุฏุงุดุชู ุงู ฺฉุชุงุจู ุจุฎุฑู ูู ฺฺฉุฏู ูุง ุงุฒูุชูุดู ุฎููุฏู ุฎุนู ูุดูฺฏ ุจูุฏ\n",
            "ูุฎู ูุดุชุงูู ฺฉู ุงู ฺฉุชุงุจู ฺฉุงูู ุจุฎููู\n",
            "ุดฺฉ ูฺฉูุฏ ุงู ุชุฑุฌูู ุจูุชุฑู ุงุณุช\n",
            "ุชุฑุฌูู ุขูุง ุณูุฌุงุจ ููุฏุงุฑ ุฒุงุฏ ุญุฐูุงุช ุฏุงุฑุฏ\n",
            "ุดฺฉ ูฺฉูุฏ ุงู ุชุฑุฌูู ุจูุชุฑู ุงุณุช\n",
            "ุชุฑุฌูู ุขูุง ุณูุฌุงุจ ููุฏุงุฑ ุฒุงุฏ ุญุฐูุงุช ุฏุงุฑุฏ\n",
            "ฺุทูุฑ ุจุงุฏ ุณูุงุฑุด ุจุฏู ฺฉ ุจูุฑุณุชู ูุงุณู ุฏู ุฎูููุ\n",
            "ฺุทูุฑ ุจุงุฏ ุณูุงุฑุด ุจุฏู ฺฉ ุจูุฑุณุชู ูุงุณู ุฏู ุฎูููุ\n",
            "ุจู ุฏูุณุชุงู ฺฉู ุงู ฺฉุชุงุจ ุฑู ูุฎููุฏู ุจู ุดุฏุช ุชูุตู ุด ูฺฉูู. ุนุงู ุนุงู ุนุงู. ๐๐๐\n",
            "ุจู ุฏูุณุชุงู ฺฉู ุงู ฺฉุชุงุจ ุฑู ูุฎููุฏู ุจู ุดุฏุช ุชูุตู ุด ูฺฉูู. ุนุงู ุนุงู ุนุงู. \n",
            "ุฏุฑ ุจุฎุด ุฌุฒุงุช ฺฉุชุงุจ ุชูุถุญุงุช ุฎู ุฎูุจ ุฏุฑ ุจุงุจ ฺฉุชุงุจ ุฐฺฉุฑ ุดุฏู .\n",
            "ุฏุฑ ุงู ฺฉุชุงุจ ููุณูุฏู ุจุฑุง ุฏุฑฺฉ ุจูุชุฑ ุงุญูุงู ุฏุฑูู ุดุฎุตุชูุง ุฏุงุณุชุงู ูุซุงู ูุง ุงุญุณุงุณ ุฒุงุฏ ุฑุง ุฑูุงุช ู ฺฉูุฏฺฉู ููุน ุดุงุนุฑุงูฺฏ ุฒุจุง ุฑุง ุฎูู ูฺฉูุฏ\n",
            "ุจุฎุชุงุฑ ุนู ุจุง ุงู ฺฉุชุงุจ ูุงุฑุง ุจุง ุนูุงูุจ ุฌูฺฏ _ุจูฺู ุฌูฺฏ ุฏุงุฎู_ ุขุดูุง ูฺฉูุฏ.\n",
            "ฺฉุชุงุจ ุจุดุฏุช ููุ ุฏุฑ ุชุฑุณู ุงุญุณุงุณ ูุง\n",
            "ุฏุฑ ูุฐูุช ุฌูฺฏ ู ุฌูฺฏุงูุฑุงู ุฏุฑ ุณุชุงุด ุนุดู\n",
            "ุฏุฑ ุชูุตู ุชููุง\n",
            "ุฏุฑ ุจุฎุด ุฌุฒุงุช ฺฉุชุงุจ ุชูุถุญุงุช ุฎู ุฎูุจ ุฏุฑ ุจุงุจ ฺฉุชุงุจ ุฐฺฉุฑ ุดุฏู .\n",
            "ุฏุฑ ุงู ฺฉุชุงุจ ููุณูุฏู ุจุฑุง ุฏุฑฺฉ ุจูุชุฑ ุงุญูุงู ุฏุฑูู ุดุฎุตุชูุง ุฏุงุณุชุงู ูุซุงู ูุง ุงุญุณุงุณ ุฒุงุฏ ุฑุง ุฑูุงุช ู ฺฉูุฏฺฉู ููุน ุดุงุนุฑุงูฺฏ ุฒุจุง ุฑุง ุฎูู ูฺฉูุฏ\n",
            "ุจุฎุชุงุฑ ุนู ุจุง ุงู ฺฉุชุงุจ ูุงุฑุง ุจุง ุนูุงูุจ ุฌูฺฏ _ุจูฺู ุฌูฺฏ ุฏุงุฎู_ ุขุดูุง ูฺฉูุฏ.\n",
            "ฺฉุชุงุจ ุจุดุฏุช ููุ ุฏุฑ ุชุฑุณู ุงุญุณุงุณ ูุง\n",
            "ุฏุฑ ูุฐูุช ุฌูฺฏ ู ุฌูฺฏุงูุฑุงู ุฏุฑ ุณุชุงุด ุนุดู\n",
            "ุฏุฑ ุชูุตู ุชููุง\n",
            "ูุซุฑ ู ูุถุงุณุงุฒ ุนุงู.\n",
            "ูุซุฑ ู ูุถุงุณุงุฒ ุนุงู.\n",
            "ฺฉูุฏูู ุชุฑุฌูู ู ุงูุชุดุงุฑุงุช ุจูุชุฑู ูุงุณู ุงู ฺฉุชุงุจุุ\n",
            "ฺฉูุฏูู ุชุฑุฌูู ู ุงูุชุดุงุฑุงุช ุจูุชุฑู ูุงุณู ุงู ฺฉุชุงุจุุ\n",
            "ูุงูุนุง ฺฉุชุงุจ ุจ ูุธุฑ ุจูุฏ. ุจูุชุฑู ุฑูุงู ุจูุฏ ฺฉู ุชุง ุญุงูุง ุฎููุฏู\n",
            "ูุงูุนุง ฺฉุชุงุจ ุจ ูุธุฑ ุจูุฏ. ุจูุชุฑู ุฑูุงู ุจูุฏ ฺฉู ุชุง ุญุงูุง ุฎููุฏู\n",
            "ุฏุฑ ุท ฺฉ ุงุฒ ุฌูฺฏ ูุง ฺฉุฑุฏุณุชุงูุ ุฏู ุฏูุณุช ุจู ูุงู ูุง \"ูุธูุฑ ุตุจุญุฏู\" ู \"ุนููุจ ุตููุจุฑ\" ุฏุฑ ุขุณุชุงูู  ุฏุณุชฺฏุฑ ุจู ูุณูู  ุฏุดูู ูุฑุงุฑ ูฺฏุฑู. ูุธูุฑ ุตุจุญุฏู ูุฏุงฺฉุงุฑ ูฺฉูู ู ุชู ุจู ุงุณุงุฑุช ูุฏู ุชุง ุนููุจ ุตููุจุฑ ูุฑุตุช ูุฑุงุฑ ูพุฏุง ฺฉูู. ู ููุท ุงุฒ ุงูู ุฎูุงูุด ูฺฉูู ุชุง ูุฑุงูุจ ูพุณุฑ ุชุงุฒู ูุชููุฏ ุดุฏู ู ุจ ูุงุฏุฑุด \"ุณุฑุงุณ ุตุจุญุฏู\" ุจุงุดู. ูุธูุฑ ุตุจุญุฏู ุจุณุช ู ฺฉ ุณุงู ุฒูุฏุงู ูุดู ู ุท ุงู ุณุงู ูุง ุงุชูุงูุงุช ู ุฌูฺฏ ูุง ูุชุนุฏุฏ ุฑุฎ ูุฏู ุุญุฒุจ ุงูู ูุง ูพุฑูุฒ ูุดู ู ุนููุจ ุตููุจุฑ ุจู ุนููุงู ุฑูุจุฑ ุจู ูุฏุฑุช ูุฑุณู. ุงูุง ูุธูุฑ ุตุจุญุฏู ุจุนุฏ ุงุฒ ุขุฒุงุฏ ูุชูุฌู ูุดู ฺฉู ููู ฺุฒ ฺฉุงููุง ุชุบุฑ ฺฉุฑุฏู ู ุจุง ุชุตูุฑุงุช ุงูู ูุชูุงูุชู. ุจุนุฏ ุงุฒ ุขุฒุงุฏ ุชูุงุด ูฺฉูู ุชุง ูพุณุฑุด ุฑู ูพุฏุง ฺฉูู ู ุงู ุณุฑุขุบุงุฒ ุฏุงุณุชุงู ูุง ู ุงุชูุงูุงุช ูุชุนุฏุฏู ฺฉู ุงูุชุธุงุฑุด ุฑู ูฺฉุดู. ุฑุงุฒ ูุง ูุชุนุฏุฏ ฺฉู ูุงุฒ ุจู ุฑูุฒฺฏุดุง ู ฺฉุดู ุดุฏู ุฏุงุฑู.\n",
            "\n",
            "ฺฉุชุงุจ ุฏุฑ ูุฐูุช ุฌูฺฏ ููุดุชู ุดุฏู. ุงูฺฉู ุฌูฺฏ ูุง ุจุง ูุฑ ูุฏู ูู ฺฉู ุงูุฌุงู ุจุดูุ ุญุงุตู ุฌุฒ ุชุจุงูุ ุณุงูุ ูุฑุงูุ ููุฑุ ุณูุฎุชฺฏ ู ูุงุจูุฏ ุงูุณุงู ูุง ุจ ฺฏูุงู ูุฏุงุฑู. ุงฺฏุฑฺู ููุถูุน ุฌุฐุงุจู ู ุงูุจุชู ุงู ฺฉุชุงุจ ุจู ุดุฏุช ูุนุฑูููุ ูู ุฎู ุงุฒุด ูุฐุช ูุจุฑุฏู. ุจูุธุฑู ฺฉุชุงุจ ูุง ุฎู ุฌุฐุงุจ ุชุฑ ู ุชฺฉุงู ุฏููุฏู ุชุฑ ูู ุฏุฑ ุงู ุฒููู ู ููุถูุน ูุฌูุฏ ุฏุงุฑู. ุจุฎุตูุต ุงูฺฉูุ ุจุง ูุฌูุฏ ูุณูุชุง ุงุณุฑุงุฑุขูุฒ ู ุชุฎู ุฏุฑูู ฺฉุชุงุจุ ุงูุชุธุงุฑ ูพุงุงู ูุชูุงูุช ุชุฑ ู ุบุฑูุงุจู ูพุด ุจู ุชุฑ ุฏุงุดุชู. ุงูุจุชู ฺฉุชุงุจ ูพุฑ ุงุฒ ุฌููุงุช ูุบุฒ ู ูพุฑูููููู ฺฉู ุฏูู ุชุฑ ุฎููุฏูุด ูุชููู ุจุงุนุซ ุจุดู ููุงูู ุนูู ุชุฑ ุงุฒ ฺฉุชุงุจ ุจุฑุฏุงุดุช ุจุดู.\n",
            "ุฏุฑ ุท ฺฉ ุงุฒ ุฌูฺฏ ูุง ฺฉุฑุฏุณุชุงูุ ุฏู ุฏูุณุช ุจู ูุงู ูุง \"ูุธูุฑ ุตุจุญุฏู\" ู \"ุนููุจ ุตููุจุฑ\" ุฏุฑ ุขุณุชุงูู  ุฏุณุชฺฏุฑ ุจู ูุณูู  ุฏุดูู ูุฑุงุฑ ูฺฏุฑู. ูุธูุฑ ุตุจุญุฏู ูุฏุงฺฉุงุฑ ูฺฉูู ู ุชู ุจู ุงุณุงุฑุช ูุฏู ุชุง ุนููุจ ุตููุจุฑ ูุฑุตุช ูุฑุงุฑ ูพุฏุง ฺฉูู. ู ููุท ุงุฒ ุงูู ุฎูุงูุด ูฺฉูู ุชุง ูุฑุงูุจ ูพุณุฑ ุชุงุฒู ูุชููุฏ ุดุฏู ู ุจ ูุงุฏุฑุด \"ุณุฑุงุณ ุตุจุญุฏู\" ุจุงุดู. ูุธูุฑ ุตุจุญุฏู ุจุณุช ู ฺฉ ุณุงู ุฒูุฏุงู ูุดู ู ุท ุงู ุณุงู ูุง ุงุชูุงูุงุช ู ุฌูฺฏ ูุง ูุชุนุฏุฏ ุฑุฎ ูุฏู ุุญุฒุจ ุงูู ูุง ูพุฑูุฒ ูุดู ู ุนููุจ ุตููุจุฑ ุจู ุนููุงู ุฑูุจุฑ ุจู ูุฏุฑุช ูุฑุณู. ุงูุง ูุธูุฑ ุตุจุญุฏู ุจุนุฏ ุงุฒ ุขุฒุงุฏ ูุชูุฌู ูุดู ฺฉู ููู ฺุฒ ฺฉุงููุง ุชุบุฑ ฺฉุฑุฏู ู ุจุง ุชุตูุฑุงุช ุงูู ูุชูุงูุชู. ุจุนุฏ ุงุฒ ุขุฒุงุฏ ุชูุงุด ูฺฉูู ุชุง ูพุณุฑุด ุฑู ูพุฏุง ฺฉูู ู ุงู ุณุฑุขุบุงุฒ ุฏุงุณุชุงู ูุง ู ุงุชูุงูุงุช ูุชุนุฏุฏู ฺฉู ุงูุชุธุงุฑุด ุฑู ูฺฉุดู. ุฑุงุฒ ูุง ูุชุนุฏุฏ ฺฉู ูุงุฒ ุจู ุฑูุฒฺฏุดุง ู ฺฉุดู ุดุฏู ุฏุงุฑู.\n",
            "\n",
            "ฺฉุชุงุจ ุฏุฑ ูุฐูุช ุฌูฺฏ ููุดุชู ุดุฏู. ุงูฺฉู ุฌูฺฏ ูุง ุจุง ูุฑ ูุฏู ูู ฺฉู ุงูุฌุงู ุจุดูุ ุญุงุตู ุฌุฒ ุชุจุงูุ ุณุงูุ ูุฑุงูุ ููุฑุ ุณูุฎุชฺฏ ู ูุงุจูุฏ ุงูุณุงู ูุง ุจ ฺฏูุงู ูุฏุงุฑู. ุงฺฏุฑฺู ููุถูุน ุฌุฐุงุจู ู ุงูุจุชู ุงู ฺฉุชุงุจ ุจู ุดุฏุช ูุนุฑูููุ ูู ุฎู ุงุฒุด ูุฐุช ูุจุฑุฏู. ุจูุธุฑู ฺฉุชุงุจ ูุง ุฎู ุฌุฐุงุจ ุชุฑ ู ุชฺฉุงู ุฏููุฏู ุชุฑ ูู ุฏุฑ ุงู ุฒููู ู ููุถูุน ูุฌูุฏ ุฏุงุฑู. ุจุฎุตูุต ุงูฺฉูุ ุจุง ูุฌูุฏ ูุณูุชุง ุงุณุฑุงุฑุขูุฒ ู ุชุฎู ุฏุฑูู ฺฉุชุงุจุ ุงูุชุธุงุฑ ูพุงุงู ูุชูุงูุช ุชุฑ ู ุบุฑูุงุจู ูพุด ุจู ุชุฑ ุฏุงุดุชู. ุงูุจุชู ฺฉุชุงุจ ูพุฑ ุงุฒ ุฌููุงุช ูุบุฒ ู ูพุฑูููููู ฺฉู ุฏูู ุชุฑ ุฎููุฏูุด ูุชููู ุจุงุนุซ ุจุดู ููุงูู ุนูู ุชุฑ ุงุฒ ฺฉุชุงุจ ุจุฑุฏุงุดุช ุจุดู.\n",
            "ูุงูุนุง ฺฉู ูุฐุช ุจุฑุฏู\n",
            "ูุงูุนุง ฺฉู ูุฐุช ุจุฑุฏู\n",
            "ุงู ฺฉุชุงุจ ุนุงูู ูู ุจุงุฑ ุฎููุฏูุด ูู ุจุงุฒ ุฏูุจุงูุด ุจูุฏู ฺฉ ุจุฎูููุด:)\n",
            "ุงู ฺฉุชุงุจ ุนุงูู ูู ุจุงุฑ ุฎููุฏูุด ูู ุจุงุฒ ุฏูุจุงูุด ุจูุฏู ฺฉ ุจุฎูููุด:)\n",
            "ุชุนุฑู ุงู ฺฉุชุงุจู ุฒุงุฏ ุดูุฏู.ู\n",
            "ฺฉุงุด ุฑุงฺฏุงู ุจุดู\n",
            "ุชุนุฑู ุงู ฺฉุชุงุจู ุฒุงุฏ ุดูุฏู.ู\n",
            "ฺฉุงุด ุฑุงฺฏุงู ุจุดู\n",
            "ุนุงูู ...ูุณุฎู  ุฒุจุงู ุงุตูุด ุงฺฏุฑ ุจุงุดู ุนุงูู..ูุทูุง ุจุฐุงุฑุฏ\n",
            "ุนุงูู ...ูุณุฎู  ุฒุจุงู ุงุตูุด ุงฺฏุฑ ุจุงุดู ุนุงูู..ูุทูุง ุจุฐุงุฑุฏ\n",
            "ุฎู ฺฏุฑุงู ูู ููุชููู ุจุฎุฑูุด ูพูู ูุฏุงุฑู ูุทูุงู ฺฉูฺฉู ฺฉูุฏ ุชุฎูู ุจุฏุฏ\n",
            "ุฎู ฺฏุฑุงู ูู ููุชููู ุจุฎุฑูุด ูพูู ูุฏุงุฑู ูุทูุงู ฺฉูฺฉู ฺฉูุฏ ุชุฎูู ุจุฏุฏ\n",
            "ูู ุชุฑุฌูู ุขุฑุด ุณูุฌุงุจ ุจูุชุฑู. ุนู ุนุงูู.\n",
            "ูู ุชุฑุฌูู ุขุฑุด ุณูุฌุงุจ ุจูุชุฑู. ุนู ุนุงูู.\n",
            "ฺฉุชุงุจ ุนุงูู . ูู ุฎู ฺฏุฑููู. ุงูุฏูุงุฑู ุชุฌุฏุฏ ูุธุฑ ุจุดู . ุดุฑฺฉู ุจ ฺฉู ุณ ูพุดููุงุฏ ุงู ฺฉุชุงุจู ฺฉุฑุฏู ฺฉู ุญุชูุง ูุจู ุงุฒ ูุฑฺฏ ุจุฎููุฏ .\n",
            "ฺฉุชุงุจ ุนุงูู . ูู ุฎู ฺฏุฑููู. ุงูุฏูุงุฑู ุชุฌุฏุฏ ูุธุฑ ุจุดู . ุดุฑฺฉู ุจ ฺฉู ุณ ูพุดููุงุฏ ุงู ฺฉุชุงุจู ฺฉุฑุฏู ฺฉู ุญุชูุง ูุจู ุงุฒ ูุฑฺฏ ุจุฎููุฏ .\n",
            "ุฒุงุฏ ฺฏุฑูู ูุณุช ุ\n",
            "ุฒุงุฏ ฺฏุฑูู ูุณุช ุ\n",
            "ุชุนุฑู ุงู ฺฉุชุงุจ ุฑู ุฎู ุดูุฏู ุจูุฏู, ุฏูุจุงูุด ุจูุฏู ุจุฎุฑูุด, ุฎุฏุงุฑู ุดฺฉุฑ ฺฉู ุงููุฏ ุฑู ุทุงูฺู\n",
            "ุชุนุฑู ุงู ฺฉุชุงุจ ุฑู ุฎู ุดูุฏู ุจูุฏู, ุฏูุจุงูุด ุจูุฏู ุจุฎุฑูุด, ุฎุฏุงุฑู ุดฺฉุฑ ฺฉู ุงููุฏ ุฑู ุทุงูฺู\n",
            "ุฌููุงุช ุงุฒ \"ุณุงููุฆู ุจฺฉุช\" ุ\n",
            "-ูุฌ ฺุฒ ุจุงูุฒู ุชุฑ ุงุฒ ุดุงุฏ ุจูุฏู ูุณุช.\n",
            "ูุทูุฆู ุจุงุดุฏุุจููุุจููุ ุดุงุฏ \"ูุจูุฏู\"  ูุณุฎุฑู ุชุฑู ฺุฒ ุฏูุงุณุช.\n",
            "\n",
            "-ฺฏุงู ููุท ุจุงุฏ ูุจุฎูุฏ ุจุฒู ู ุฑุฏ ุดู.ุจฺฏุฐุงุฑ ูฺฉุฑ ฺฉููุฏ ููููุฏ.\n",
            "ุฌููุงุช ุงุฒ \"ุณุงููุฆู ุจฺฉุช\" ุ\n",
            "-ูุฌ ฺุฒ ุจุงูุฒู ุชุฑ ุงุฒ ุดุงุฏ ุจูุฏู ูุณุช.\n",
            "ูุทูุฆู ุจุงุดุฏุุจููุุจููุ ุดุงุฏ \"ูุจูุฏู\"  ูุณุฎุฑู ุชุฑู ฺุฒ ุฏูุงุณุช.\n",
            "\n",
            "-ฺฏุงู ููุท ุจุงุฏ ูุจุฎูุฏ ุจุฒู ู ุฑุฏ ุดู.ุจฺฏุฐุงุฑ ูฺฉุฑ ฺฉููุฏ ููููุฏ.\n",
            "ุจฺฉุช ูุงูุนุง ุฎูุจู\n",
            "ุจฺฉุช ูุงูุนุง ุฎูุจู\n",
            "ฺฉุชุงุจ ููู ุงูุนุงุฏู ุฌุงูุจู .ูู ฺฉู ุฎูุดู ุงููุฏ. \n",
            "ฺฉุชุงุจ ููู ุงูุนุงุฏู ุฌุงูุจู .ูู ฺฉู ุฎูุดู ุงููุฏ. \n",
            "ุฎููุฏูุด ุญุณ ุฎูุจ ุจูู ูุฏุงุฏ ู ุจุนุถ ุฌุงูุงุด ุฎู ุชุนุฌุจ ฺฉุฑุฏู!\n",
            "ุฎููุฏูุด ุญุณ ุฎูุจ ุจูู ูุฏุงุฏ ู ุจุนุถ ุฌุงูุงุด ุฎู ุชุนุฌุจ ฺฉุฑุฏู!\n",
            "ูุงูุนุงฺฉุชุงุจ ุฌุงูุจ ุจูุฏ...ฺฉูุชุงู ูู ูพุฑูุญุชูุงููุฐุช ุจุฎุด๐๐\n",
            "ุดุฎุตุช ุดูุฏุฒู ุงูุฏู ุชุงุญุฏูุฏ ุฏุณุชู ุงููุฏ ฺฉ ุงูุณุงู ุขุฑูู ููุฑุจูู ุจุงฺุดูุงู ูุงูุฐูููุจ ุฏุฑุง...\n",
            "ุฎููุฏู ุงู ฺฉุชุงุจ ุฑูุจู ููู ุชูุตู ูฺฉูู\n",
            "ุดุงุฏ ุฑูุญ ููู ุดูุฏุงุตููุงุช\n",
            "ูุงูุนุงฺฉุชุงุจ ุฌุงูุจ ุจูุฏ...ฺฉูุชุงู ูู ูพุฑูุญุชูุงููุฐุช ุจุฎุด\n",
            "ุดุฎุตุช ุดูุฏุฒู ุงูุฏู ุชุงุญุฏูุฏ ุฏุณุชู ุงููุฏ ฺฉ ุงูุณุงู ุขุฑูู ููุฑุจูู ุจุงฺุดูุงู ูุงูุฐูููุจ ุฏุฑุง...\n",
            "ุฎููุฏู ุงู ฺฉุชุงุจ ุฑูุจู ููู ุชูุตู ูฺฉูู\n",
            "ุดุงุฏ ุฑูุญ ููู ุดูุฏุงุตููุงุช\n",
            "ูู ุฏู ุฌูุฏ ุงุฒ ูุฌููุนู ูุง ููู  ูพููุงู ูุงู ู ุขุณูุงู ู ุงูฺฉ ุดูฺฉุฑุงู ุฑู ุฎููุฏู. ฺฉ ุงุฒ ฺฉ ุจูุชุฑู\n",
            "ูู ุฏู ุฌูุฏ ุงุฒ ูุฌููุนู ูุง ููู  ูพููุงู ูุงู ู ุขุณูุงู ู ุงูฺฉ ุดูฺฉุฑุงู ุฑู ุฎููุฏู. ฺฉ ุงุฒ ฺฉ ุจูุชุฑู\n",
            "ูุณุฎู ฺุงูพ ุจุง epub ฺฉ ููุช!!!ุ\n",
            "ูุณุฎู ฺุงูพ ุจุง epub ฺฉ ููุช!!!ุ\n",
            "ุชูุตูโูฺฉูู ููู ูพููุงูฑ ฺูุฑุงู ุจู ุฑูุงุช ููุณุฑ ุดูุฏ ุฑู ูุทุงูุนู ฺฉูุฏ.\n",
            "ุชูุตูโูฺฉูู ููู ูพููุงูฑ ฺูุฑุงู ุจู ุฑูุงุช ููุณุฑ ุดูุฏ ุฑู ูุทุงูุนู ฺฉูุฏ.\n",
            "ูู ุงู ฺฉุชุงุจ ุฑู ุฎููุฏู. ุฏูุณุช ุนุฒุฒ ฺฉู ูฺฏู ฺุงุฎุงู ูุณุช ูุชุงุณูุงูู ุจ ุฑุงู ููฺฏู. ฺูู ูุฑุฏ ูุตุงุญุจู ฺฉููุฏู ุจุง ููุณุฑ ุดูุฏ ุฏุฑ ูุฏุช ุซุจุช ู ุถุจุท ุฎุงุทุฑุงุชุ ุจุง ูุงุดุฑ ุจู ูุดฺฉู ุจุฑ ูุฎูุฑู ู ฺฉุงุฑ ุฑู ูู ูฺฉูู.  ุจุนุฏ ฺฉ ููุณูุฏู ุฏฺฏู ูุงุฏ ู ุฎุงุทุฑุงุช ุฑู ุชุจุฏู ุจู ฺฉุชุงุจ ูฺฉูู ุฏุฑุญุงู ฺฉู ุงุฒ ููุณุฑ ุดูุฏ ฺฉุณุจ ุงุฌุงุฒู ูุดุฏู ุจูุฏู ู ฺฉ ููุฏุงุฑ ุญุฑู ูุง ุบูุท ุบููุท ุฏุงุฎู ุฏุฑ  ุฑูุงุช ุฒูุฏฺฏ ูุดู... ูู ุงู ุฑู ุงุฒ ูุฑุฏ ููุฑุฏ ูุซูู ุดูุฏู ฺูู ุฎูุฏู ุจุนุฏ ุงุฒ ุฎููุฏู ฺฉุชุงุจ ุฏูพุฑุณ ุดุฏู ู ุงุตูุง ุงุนุตุงุจู ุจู ูู ุฑุฎุช ู ุดูุฏ ุฒู ุงูุฏู ุฑู ุฏฺฏู ุฏูุณุช ูุฏุงุดุชู. ูู ุจุนุฏุง ูููุฏู ุจุฏุชุฑู ฺฉุชุงุจ ฺฉู ููฺฉู ุจูุฏ ููุดุชู ุจุดู ุงุฒ ุฒุจุงู ฺฉ ููุณุฑ ุดูุฏุ  ููู ุจูุฏู ู ูุณุช!\n",
            "ูู ุงู ฺฉุชุงุจ ุฑู ุฎููุฏู. ุฏูุณุช ุนุฒุฒ ฺฉู ูฺฏู ฺุงุฎุงู ูุณุช ูุชุงุณูุงูู ุจ ุฑุงู ููฺฏู. ฺูู ูุฑุฏ ูุตุงุญุจู ฺฉููุฏู ุจุง ููุณุฑ ุดูุฏ ุฏุฑ ูุฏุช ุซุจุช ู ุถุจุท ุฎุงุทุฑุงุชุ ุจุง ูุงุดุฑ ุจู ูุดฺฉู ุจุฑ ูุฎูุฑู ู ฺฉุงุฑ ุฑู ูู ูฺฉูู.  ุจุนุฏ ฺฉ ููุณูุฏู ุฏฺฏู ูุงุฏ ู ุฎุงุทุฑุงุช ุฑู ุชุจุฏู ุจู ฺฉุชุงุจ ูฺฉูู ุฏุฑุญุงู ฺฉู ุงุฒ ููุณุฑ ุดูุฏ ฺฉุณุจ ุงุฌุงุฒู ูุดุฏู ุจูุฏู ู ฺฉ ููุฏุงุฑ ุญุฑู ูุง ุบูุท ุบููุท ุฏุงุฎู ุฏุฑ  ุฑูุงุช ุฒูุฏฺฏ ูุดู... ูู ุงู ุฑู ุงุฒ ูุฑุฏ ููุฑุฏ ูุซูู ุดูุฏู ฺูู ุฎูุฏู ุจุนุฏ ุงุฒ ุฎููุฏู ฺฉุชุงุจ ุฏูพุฑุณ ุดุฏู ู ุงุตูุง ุงุนุตุงุจู ุจู ูู ุฑุฎุช ู ุดูุฏ ุฒู ุงูุฏู ุฑู ุฏฺฏู ุฏูุณุช ูุฏุงุดุชู. ูู ุจุนุฏุง ูููุฏู ุจุฏุชุฑู ฺฉุชุงุจ ฺฉู ููฺฉู ุจูุฏ ููุดุชู ุจุดู ุงุฒ ุฒุจุงู ฺฉ ููุณุฑ ุดูุฏุ  ููู ุจูุฏู ู ูุณุช!\n",
            "ููุด ฺุงุฎุงูู\n",
            "ููุด ฺุงุฎุงูู\n",
            "ุณูุงู ...ุนุงูู ุนุงูู...\n",
            "ุณูุงู ...ุนุงูู ุนุงูู...\n",
            "ุณูุงู ุงฺฏู ููุดู ูุฌููุนู ููู ูพููุงู ูุงู ุงุฒุดูุงุฑู 1 ุชุงุขุฎุฑู ุดูุงุฑู ุงุด ุฑูุจุฒุงุฑุฏฺูู ูุงูุนุงู ูุฌููุนู  ูุธุฑู\n",
            "ุณูุงู ุงฺฏู ููุดู ูุฌููุนู ููู ูพููุงู ูุงู ุงุฒุดูุงุฑู 1 ุชุงุขุฎุฑู ุดูุงุฑู ุงุด ุฑูุจุฒุงุฑุฏฺูู ูุงูุนุงู ูุฌููุนู  ูุธุฑู\n",
            "ุจุณุงุฑ ุนุงู\n",
            "ูุทูุง ุจุดุชุฑ ุงุฒ  ฺฉุชุงุจ ูุง ููู  ูพููุงู ูุงู ุจฺฏุฐุงุฑุฏ\n",
            "ุจุณุงุฑ ุนุงู\n",
            "ูุทูุง ุจุดุชุฑ ุงุฒ  ฺฉุชุงุจ ูุง ููู  ูพููุงู ูุงู ุจฺฏุฐุงุฑุฏ\n",
            "ฺฉุชุงุจ ูุง ููู ูพููุงู ูุงู ุนุงู ูุณุชูุ ุงฺฉุงุด ููู ูุฌููุนู ุดู ุจฺฏุฐุงุฑุฏ\n",
            "ฺฉุชุงุจ ูุง ููู ูพููุงู ูุงู ุนุงู ูุณุชูุ ุงฺฉุงุด ููู ูุฌููุนู ุดู ุจฺฏุฐุงุฑุฏ\n",
            "ููุดุชูโูุง ฺฏุฑุง ุงู ุดูุงุฑู :\n",
            "ฑ.ุชูุฑุงูุงู ุฏุฑ ฺฏุฐุฑ ุชุงุฑุฎ (ุจุญุซ ุจุฑ ุณุฑ ุงูฺฉู ูุฑุฏู ุชูุฑุงู ฺฉุฌุง ุฒูุฏฺฏ ูโฺฉุฑุฏูุฏ ู ุชุฑฺฉ ูุจูุฏู ุงูุฏ. )\n",
            "ฒ.ุฑุงุฒฺฏุดุง ุงุฒ ุงุณุชูุฑูู ุงฺุฏูุง ฺฉูุดููโุฑูุฏ.\n",
            "ููุดุชูโูุง ฺฏุฑุง ุงู ุดูุงุฑู :\n",
            "ฑ.ุชูุฑุงูุงู ุฏุฑ ฺฏุฐุฑ ุชุงุฑุฎ (ุจุญุซ ุจุฑ ุณุฑ ุงูฺฉู ูุฑุฏู ุชูุฑุงู ฺฉุฌุง ุฒูุฏฺฏ ูโฺฉุฑุฏูุฏ ู ุชุฑฺฉ ูุจูุฏู ุงูุฏ. )\n",
            "ฒ.ุฑุงุฒฺฏุดุง ุงุฒ ุงุณุชูุฑูู ุงฺุฏูุง ฺฉูุดููโุฑูุฏ.\n",
            "ุณูพุฏู ุฏุงูุง ู ุฏฺฉุชุฑ ูุญููุฏ ฺฏูุฒุงุฑ ุนู ูุฑุดุชู ูุง ุฑุงูููุง ู ูุฑุงุฏ ุญููุช ุจุฏูู ูพุฑุฏู ู ุฏูุณูุฒ ุฌูุงููุง ุจูุณู ุจุฑ ุฏุณุชูุง ูพุฑ ููุฑุชูู ู ุฏูุณุชุงู ุทุงูฺู ฺฉู ุฎูุด ุณููฺฏ ฺฉุฑุฏู ู ุณูพุฏู ุฑู ุจู ุฌูุน ุทุงูฺู ุงูุฑุฏู ุชุง ูุง ููุดู ููุฑุงูุดูู ุจุงุดู\n",
            "ุณูพุฏู ุฏุงูุง ู ุฏฺฉุชุฑ ูุญููุฏ ฺฏูุฒุงุฑ ุนู ูุฑุดุชู ูุง ุฑุงูููุง ู ูุฑุงุฏ ุญููุช ุจุฏูู ูพุฑุฏู ู ุฏูุณูุฒ ุฌูุงููุง ุจูุณู ุจุฑ ุฏุณุชูุง ูพุฑ ููุฑุชูู ู ุฏูุณุชุงู ุทุงูฺู ฺฉู ุฎูุด ุณููฺฏ ฺฉุฑุฏู ู ุณูพุฏู ุฑู ุจู ุฌูุน ุทุงูฺู ุงูุฑุฏู ุชุง ูุง ููุดู ููุฑุงูุดูู ุจุงุดู\n",
            "ุงุฒ  ุฏฺฉุชุฑ ุนู ูุถ ุจุงุจุช ูุทุงูุจ ุฎูุจ ฺฉู ุฏุฑ ุงู ุดูุงุฑู ููุดุชู ุงูุฏ ูุชุดฺฉุฑู\n",
            "ุงุฒ  ุฏฺฉุชุฑ ุนู ูุถ ุจุงุจุช ูุทุงูุจ ุฎูุจ ฺฉู ุฏุฑ ุงู ุดูุงุฑู ููุดุชู ุงูุฏ ูุชุดฺฉุฑู\n",
            "ุชููุฏุช ูุจุงุฑฺฉ ฺฉูฺฉ ุนุงู ูุณุช ููุท ุฌูฺฏ ุณุชุงุฑฺฏุงู ุจุฑุง xbox 360 ฺฉ ูุงุฏ ููููู\n",
            "ุชููุฏุช ูุจุงุฑฺฉ ฺฉูฺฉ ุนุงู ูุณุช ููุท ุฌูฺฏ ุณุชุงุฑฺฏุงู ุจุฑุง xbox 360 ฺฉ ูุงุฏ ููููู\n",
            "ุทุงูฺู ุจูุชุฑู ุจุฑูุงูู ุงุฑุงุงูู\n",
            "ุฎูุงูุด ฺฉุชุงุจ ูุง ุฑูุงูุดูุงุณุฒุชุญุตู ู ุจุฑูุงูู ููุณ ุจุฒุงุฑุฏ\n",
            "ุทุงูฺู ุจูุชุฑู ุจุฑูุงูู ุงุฑุงุงูู\n",
            "ุฎูุงูุด ฺฉุชุงุจ ูุง ุฑูุงูุดูุงุณุฒุชุญุตู ู ุจุฑูุงูู ููุณ ุจุฒุงุฑุฏ\n",
            "ูู ุงู ฺฉุชุงุจ ุฑู ุจู ุตูุฑุช ฺุงูพ ุฎุฑุฏู ุนุงู ุจูุฏ ูููููโค\n",
            "ูู ุงู ฺฉุชุงุจ ุฑู ุจู ุตูุฑุช ฺุงูพ ุฎุฑุฏู ุนุงู ุจูุฏ ููููู\n",
            "ุณูุงู ูุทูุง ุฑุงฺฏุงู ฺฉูุฏ ููููู .๐ูู ฺฉ ูุณูุช ุฏฺฏุฑ  ุงุฒ ุงู ูุฌููุนู ุฎููุฏูู ุนุงู ุจูุฏ  ๐\n",
            "ุณูุงู ูุทูุง ุฑุงฺฏุงู ฺฉูุฏ ููููู .ูู ฺฉ ูุณูุช ุฏฺฏุฑ  ุงุฒ ุงู ูุฌููุนู ุฎููุฏูู ุนุงู ุจูุฏ  \n",
            "ุณูุงู ุจูุธุฑ ูู ุฒุงุฏ ุฌุงูุจ ูุจูุฏุ  ูุซุฑ ุงู ฺฉุชุงุจ ุจุฏุฑุฏ ุจฺู ูุง ุฏุจุณุชุงู ูุฎูุฑูุ ุฒุงุฏ ุณุงุฏุด ฺฉุฑุฏุฏุ ุขุฏู ุฏูุณุช ุฏุงุฑู ุฏุงุณุชุงู ูุง ุณุนุฏ ุฑู ุจุง ุงุฏุจุงุช ุฎูุฏุด ุจุฎูููุ ุงุตูุง ูุฐุช ุจุฎุด ูุณุชุ ูู ุงู ฺฉุชุงุจู ููุท ุจู ุงูุฑุงุฏ ุฒุฑ ฑต ุณุงู ุชูุตู ูฺฉูู\n",
            "ุณูุงู ุจูุธุฑ ูู ุฒุงุฏ ุฌุงูุจ ูุจูุฏุ  ูุซุฑ ุงู ฺฉุชุงุจ ุจุฏุฑุฏ ุจฺู ูุง ุฏุจุณุชุงู ูุฎูุฑูุ ุฒุงุฏ ุณุงุฏุด ฺฉุฑุฏุฏุ ุขุฏู ุฏูุณุช ุฏุงุฑู ุฏุงุณุชุงู ูุง ุณุนุฏ ุฑู ุจุง ุงุฏุจุงุช ุฎูุฏุด ุจุฎูููุ ุงุตูุง ูุฐุช ุจุฎุด ูุณุชุ ูู ุงู ฺฉุชุงุจู ููุท ุจู ุงูุฑุงุฏ ุฒุฑ ฑต ุณุงู ุชูุตู ูฺฉูู\n",
            "ูุฑูุงูุฏู ุฌูุงู ู ูุงุจุบู ฺฉู ุฌูฺฏ ูุฏูู ุงุณุชุฑุงุชฺ ูุง ุงู ุจูุฏ\n",
            "ูุฑูุงูุฏู ุฌูุงู ู ูุงุจุบู ฺฉู ุฌูฺฏ ูุฏูู ุงุณุชุฑุงุชฺ ูุง ุงู ุจูุฏ\n",
            "\"ุขูุง ุณุฑุจุงุฒ\"ุฒูุฏฺฏ ูุงูู ุฌุงูุจุงุฒ ุดูุง ,ุตุงุฏู ุฑูุดู ุงุณุช. ุจุง ุงูฺฉู ุฑุงู ูุชูุงูุณุช ุจุง ุชูุถุญ ู ุชูุตู ุจุดุชุฑ ููุงุน ู ุณุฎุชูุง ฺฉู ุฎูุฏ ู ุฎุงููุงุฏู ุงุด ุชุญูู ฺฉุฑุฏู ุงูุฏ ู ุงูุฒูุฏู ุขูุจูู ุชุตุงูุฑ,ฺฉุชุงุจ ุฑุง ุฌุฐุงุจุชุฑ ฺฉูุฏ;ุงูุง ุจุงุฒูู \"ุขูุง ุณุฑุจุงุฒ\"ุฒุจุงุณุช.ู ูุงู ฺฉุชุงุจ ูู ุจุณุงุฑ ููุฑููุฏุงูู ุงูุชุฎุงุจ ุดุฏู ุงุณุช.\n",
            "โกโกโก\n",
            "ุฏุฑ ุจุฎุด ุงุฒ ฺฉุชุงุจ ูุฎูุงูู:\n",
            "\"...ฺฉ ุฑูุฒ ุฏูุชุง ุฎุงูู ุจู ููุงูุงุชู ุขูุฏูุฏ.ฺฉ ุดุงู ุฏุฎุชุฑ ุจฺู ููุฌูุงู ุจูุฏ ู ุฏฺฏุฑ ุญุฏูุฏ ฺูู ุณุงู ุณู ุฏุงุดุช.ุฏุฎุชุฑุฎุงูู ุฏุฑุญุงู ฺฉู ุฎุฑู ุฎุฑู ุจู ุตูุฑุช ุชุงูู ุฒุฏู ุงู ูฺฏุงู ูฺฉุฑุฏ,ฺฏูุช:\n",
            "ุตูุฑุช ุดูุง ฺ ุดุฏูุ\n",
            "ุจุง ูุจุฎูุฏ ฺฏูุชู:\n",
            "ฺุฒ ุฎุงุต ูุดุฏู,ฺฉ ููุฏุงุฑ ุดูุง ุฎูุฑุฏู ุงู.\n",
            "ุฏุฎุชุฑุฎุงูู ูพุฑุณุฏ:\n",
            "ุจุฑุง ฺ ุฑูุชุฏ ุฌุจูู ฺฉู ุงูุฌูุฑ ูุฌุฑูุญ ุดูุฏ ู ุญุงูุง ุฑู ุชุฎุช ุจูุงุฑุณุชุงู ุจุงุดุฏุ\n",
            "ูุจุฎูุฏ ุฒุฏู ู ุจุฑุง ฺูุฏูุญุธู ุณฺฉูุช ฺฉุฑุฏู.ุจุนุฏ ฺฏูุชู:ุงฺฏุฑ ูู ููุฑูุชู ูพุณ ฺู ฺฉุณ ุจุงุฏ ูุฑูุชุฺู ฺฉุณ ุจุงุฏ ุงุฒ ุฏู ู ฺฉุดูุฑ ู ููุช ุฏูุงุน ูฺฉุฑุฏุ...\"\n",
            "(ุขูุง ุณุฑุจุงุฒ/ุณุฏ ูุญูุฏ ูุฑููุณู/ุตูุญู124-125ุงุฒ ูุณุฎู ุงูฺฉุชุฑููฺฉ)\n",
            "\"ุขูุง ุณุฑุจุงุฒ\"ุฒูุฏฺฏ ูุงูู ุฌุงูุจุงุฒ ุดูุง ,ุตุงุฏู ุฑูุดู ุงุณุช. ุจุง ุงูฺฉู ุฑุงู ูุชูุงูุณุช ุจุง ุชูุถุญ ู ุชูุตู ุจุดุชุฑ ููุงุน ู ุณุฎุชูุง ฺฉู ุฎูุฏ ู ุฎุงููุงุฏู ุงุด ุชุญูู ฺฉุฑุฏู ุงูุฏ ู ุงูุฒูุฏู ุขูุจูู ุชุตุงูุฑ,ฺฉุชุงุจ ุฑุง ุฌุฐุงุจุชุฑ ฺฉูุฏ;ุงูุง ุจุงุฒูู \"ุขูุง ุณุฑุจุงุฒ\"ุฒุจุงุณุช.ู ูุงู ฺฉุชุงุจ ูู ุจุณุงุฑ ููุฑููุฏุงูู ุงูุชุฎุงุจ ุดุฏู ุงุณุช.\n",
            "\n",
            "ุฏุฑ ุจุฎุด ุงุฒ ฺฉุชุงุจ ูุฎูุงูู:\n",
            "\"...ฺฉ ุฑูุฒ ุฏูุชุง ุฎุงูู ุจู ููุงูุงุชู ุขูุฏูุฏ.ฺฉ ุดุงู ุฏุฎุชุฑ ุจฺู ููุฌูุงู ุจูุฏ ู ุฏฺฏุฑ ุญุฏูุฏ ฺูู ุณุงู ุณู ุฏุงุดุช.ุฏุฎุชุฑุฎุงูู ุฏุฑุญุงู ฺฉู ุฎุฑู ุฎุฑู ุจู ุตูุฑุช ุชุงูู ุฒุฏู ุงู ูฺฏุงู ูฺฉุฑุฏ,ฺฏูุช:\n",
            "ุตูุฑุช ุดูุง ฺ ุดุฏูุ\n",
            "ุจุง ูุจุฎูุฏ ฺฏูุชู:\n",
            "ฺุฒ ุฎุงุต ูุดุฏู,ฺฉ ููุฏุงุฑ ุดูุง ุฎูุฑุฏู ุงู.\n",
            "ุฏุฎุชุฑุฎุงูู ูพุฑุณุฏ:\n",
            "ุจุฑุง ฺ ุฑูุชุฏ ุฌุจูู ฺฉู ุงูุฌูุฑ ูุฌุฑูุญ ุดูุฏ ู ุญุงูุง ุฑู ุชุฎุช ุจูุงุฑุณุชุงู ุจุงุดุฏุ\n",
            "ูุจุฎูุฏ ุฒุฏู ู ุจุฑุง ฺูุฏูุญุธู ุณฺฉูุช ฺฉุฑุฏู.ุจุนุฏ ฺฏูุชู:ุงฺฏุฑ ูู ููุฑูุชู ูพุณ ฺู ฺฉุณ ุจุงุฏ ูุฑูุชุฺู ฺฉุณ ุจุงุฏ ุงุฒ ุฏู ู ฺฉุดูุฑ ู ููุช ุฏูุงุน ูฺฉุฑุฏุ...\"\n",
            "(ุขูุง ุณุฑุจุงุฒ/ุณุฏ ูุญูุฏ ูุฑููุณู/ุตูุญู124-125ุงุฒ ูุณุฎู ุงูฺฉุชุฑููฺฉ)\n",
            "ูู ูุณุฎู ฺุงูพููููููููููู ุฑู ุฏุงุฑู\n",
            "ุจู ุดููููููููููุฏุช ุงูุชุถูููููููููููููููููููููููููุงุญุ ู ุจููููููููููู ููููููููููููููุฒู\n",
            "ูู ูุณุฎู ฺุงูพููููููููููู ุฑู ุฏุงุฑู\n",
            "ุจู ุดููููููููููุฏุช ุงูุชุถูููููููููููููููููููููููููุงุญุ ู ุจููููููููููู ููููููููููููููุฒู\n",
            "ููุท ููููู ุฑู ุฎููุฏู ู ุฎูุดู ูููุฏุ ุทูุฒ ุจ ูุฒู ุง ุจูุฏุ ุฏุฑ ุญุฏ  ููุณูุฏู ูุจูุฏ!\n",
            "ููุท ููููู ุฑู ุฎููุฏู ู ุฎูุดู ูููุฏุ ุทูุฒ ุจ ูุฒู ุง ุจูุฏุ ุฏุฑ ุญุฏ  ููุณูุฏู ูุจูุฏ!\n",
            "ดนุฏุงุณุชุงู ฺฉูุชุงู ุจุฑฺฏุฒุฏูุ ุฏุฑ ุฏูุฑู ูุง ูุฎุชูู ุฌุดููุงุฑู ุทูุฒ ูฺฉุชูุจ.\n",
            "\n",
            "ูู ุงุฒ ุฏุงุณุชุงู ูุง \"ุฏููฺฉุฑุงุณ ุฏุฑ ููู ุฌุงุ ุทูุงู ุฏุฑ ุงููู ุฑูุฒ ุงุฒุฏูุงุฌ ุ  ุงู ู ุงูู ุ ฺฉ ุฏุงุณุชุงู ุชูุฏู\" ู..ุฎูุดู ุงููุฏ.ุงูุง ุจุนุถ ุงุฒ ุฏุงุณุชุงู ูุง ูู ุงุตูุง ุฎูุจ ูุจูุฏูุฏ ู ูุชููุณุชู ุชูููุดูู ฺฉูู.\n",
            "ุฏุฑ ฺฉู ุฎู ุฎูุจ ูุจูุฏุูุชููุณุช ุจูุชุฑู ุจุงุดู ุจุง ุชูุฌู ุจู ุงูฺฉู ุจุงู ุดุฏู ุจูุฏ ฺฉู ุขุซุงุฑ ุดุงุฎุต ุงูุชุฎุงุจ ุดุฏู.\n",
            "ดนุฏุงุณุชุงู ฺฉูุชุงู ุจุฑฺฏุฒุฏูุ ุฏุฑ ุฏูุฑู ูุง ูุฎุชูู ุฌุดููุงุฑู ุทูุฒ ูฺฉุชูุจ.\n",
            "\n",
            "ูู ุงุฒ ุฏุงุณุชุงู ูุง \"ุฏููฺฉุฑุงุณ ุฏุฑ ููู ุฌุงุ ุทูุงู ุฏุฑ ุงููู ุฑูุฒ ุงุฒุฏูุงุฌ ุ  ุงู ู ุงูู ุ ฺฉ ุฏุงุณุชุงู ุชูุฏู\" ู..ุฎูุดู ุงููุฏ.ุงูุง ุจุนุถ ุงุฒ ุฏุงุณุชุงู ูุง ูู ุงุตูุง ุฎูุจ ูุจูุฏูุฏ ู ูุชููุณุชู ุชูููุดูู ฺฉูู.\n",
            "ุฏุฑ ฺฉู ุฎู ุฎูุจ ูุจูุฏุูุชููุณุช ุจูุชุฑู ุจุงุดู ุจุง ุชูุฌู ุจู ุงูฺฉู ุจุงู ุดุฏู ุจูุฏ ฺฉู ุขุซุงุฑ ุดุงุฎุต ุงูุชุฎุงุจ ุดุฏู.\n",
            "ูู ุฎูุดู ูููุฏ.ุทูุฒ ุฏุงุณุชุงู ูุงุด ูุซ ุจุฑูุงูู ูุง ุทูุฒ ุฏูู ููุชุงุฏ ุจูุฏ!\n",
            "ูู ุฎูุดู ูููุฏ.ุทูุฒ ุฏุงุณุชุงู ูุงุด ูุซ ุจุฑูุงูู ูุง ุทูุฒ ุฏูู ููุชุงุฏ ุจูุฏ!\n",
            "ูู  ููููุดู ุฎููุฏู ุฎูุจ ุจูุฏ\n",
            "ูู ูู ุงุฑุฒูุููุชุด ุฒุงุฏู\n",
            "ูู  ููููุดู ุฎููุฏู ุฎูุจ ุจูุฏ\n",
            "ูู ูู ุงุฑุฒูุููุชุด ุฒุงุฏู\n",
            "ุฎู ููุช ูพุด ุงู ฺฉุชุงุจู ุชู ุทุงูฺู ุฎููุฏูุฺฉุชุงุจ ุฌุฐุงุจ ูุณุชุูู ุฎูุดู ูููุฏ.....ุงูุจุชู ุงู ูุธุฑ ููู .....\n",
            "ุฎู ููุช ูพุด ุงู ฺฉุชุงุจู ุชู ุทุงูฺู ุฎููุฏูุฺฉุชุงุจ ุฌุฐุงุจ ูุณุชุูู ุฎูุดู ูููุฏ.....ุงูุจุชู ุงู ูุธุฑ ููู .....\n",
            "ูุนููู ุจูุฏ\n",
            "ูุนููู ุจูุฏ\n",
            "ุฏุงุณุชุงู ุฌุงูุจ ุฏุงุดุช \n",
            "ุงูุง ุฏุงุณุชุงู ุจ ูุฒู ูู ุฏุงุดุช\n",
            "ุฏุงุณุชุงู ุฌุงูุจ ุฏุงุดุช \n",
            "ุงูุง ุฏุงุณุชุงู ุจ ูุฒู ูู ุฏุงุดุช\n",
            "ฺฉุชุงุจ ุฎู ุฎูุจู . ูู ฺฉู ุฎูุดู ุงููุฏ .\n",
            "ฺฉุชุงุจ ุฎู ุฎูุจู . ูู ฺฉู ุฎูุดู ุงููุฏ .\n",
            "ฺฉูุงุฑ ุจุง ููุง๐๐\n",
            "ฺฉูุงุฑ ุจุง ููุง\n",
            "ฺฉ ุงุฒ ุจูุชุฑู ูุง ุจูุชูุงุฑ\n",
            "ฺฉ ุงุฒ ุจูุชุฑู ูุง ุจูุชูุงุฑ\n",
            "ุนุฑุถ ุงุฏุจ.\n",
            "ฺุฒูุง ฺฉู ุฏุณุช ฺฉู ู ฺฏุฑูุุงูุณุงู ุฏฺฏุฑ ุจุฑุง ุจู ุฏุณุช ุขูุฑุฏูุด ุุจุง ุฎุฏุง ุฑุงุฒ ู ูุงุฒ ู ฺฉูุฏ.\n",
            "ูุงุฏุฑ.\n",
            "ุนุฑุถ ุงุฏุจ.\n",
            "ฺุฒูุง ฺฉู ุฏุณุช ฺฉู ู ฺฏุฑูุุงูุณุงู ุฏฺฏุฑ ุจุฑุง ุจู ุฏุณุช ุขูุฑุฏูุด ุุจุง ุฎุฏุง ุฑุงุฒ ู ูุงุฒ ู ฺฉูุฏ.\n",
            "ูุงุฏุฑ.\n",
            "ุฎู ุจฺู ฺฏููู....  ูุงุณู ุณู ุฏุจุณุชุงู ูุง ุฎูุจู... ุงูุง ููููู ุจุงุจุช ุฒุญูุช ฺฉู ฺฉุดุฏุฏ.  ุงฺฏู ูุดู ุชู ูุณูุช ุงุทูุงุนุงุช ุจุดุชุฑุ  ูุงุณู ูุฑ ฺฉุชุงุจ ฺฏุฑูู ุณู ุงุด ุฑู ูู ุจุฐุงุฑู.  ุชุดฺฉุฑ\n",
            "ุฎู ุจฺู ฺฏููู....  ูุงุณู ุณู ุฏุจุณุชุงู ูุง ุฎูุจู... ุงูุง ููููู ุจุงุจุช ุฒุญูุช ฺฉู ฺฉุดุฏุฏ.  ุงฺฏู ูุดู ุชู ูุณูุช ุงุทูุงุนุงุช ุจุดุชุฑุ  ูุงุณู ูุฑ ฺฉุชุงุจ ฺฏุฑูู ุณู ุงุด ุฑู ูู ุจุฐุงุฑู.  ุชุดฺฉุฑ\n",
            "ุฏุงุณุชุงู ูุง ูุซูู ูพุฑ ุงุฒ ุญฺฉูุชู.ุฏุฑ ุงู ฺฉุชุงุจ ุจู ุฒุจุงู ุณุงุฏู ุงู ุฏุงุณุชุงู ูุง ุจุงู ุดุฏู...ุจุณุงุฑ ฺฉุชุงุจ ุฎูุจู\n",
            "ุฏุงุณุชุงู ูุง ูุซูู ูพุฑ ุงุฒ ุญฺฉูุชู.ุฏุฑ ุงู ฺฉุชุงุจ ุจู ุฒุจุงู ุณุงุฏู ุงู ุฏุงุณุชุงู ูุง ุจุงู ุดุฏู...ุจุณุงุฑ ฺฉุชุงุจ ุฎูุจู\n",
            "ุฎูุจู ๐\n",
            "ุฎูุจู \n",
            "ฺฉุชุงุจูุงยซ ุฒุจุงู ุจุฏูยป ุฑุดุฏ ุฒุงุฏ ฺฉุฑุฏู ู ุชูุฑุจุง ุจู ุญุงูุช ุงุดุจุงุน ุฑุณุฏู ฺฉู ูุดููุฑุชุฑู ุขููุง ูู ูุฑุจูุท ุจู ุขูู ูพุฒ ูุณุช.ููุชู ฺฉ ููุฑุฏ ูู ูุณุช ฺฉู ููฺฉูู ูุถู ุฑุง ูพฺุฏู ฺฉูู ู ุงูู ุขฺฏุงู ููฺฏุงู ุงุฒ ุงู ุณุจฺฉ ุฑูุงูุดูุงุฎุช ุงุณุช ฺฉู ููฺฉูู ููุฌุฑ ุจู ูููุฏุณ ูุนฺฉูุณ ุจุดู ุ ุนู ูุฑุฏ ฺฉ ุณุฑ ุฑูุชุงุฑูุง ุฎุงุต ู ุญุณุงุจ ุดุฏู ุฑุง ุจู ุทูุฑ ุขฺฏุงูุงูู ุฏุฑ ูพุด ุจฺฏุฑู ุชุง ุดุฎุตุช ุงุฒ ูพุด ุฎูุงุณุชู ู ุทุฑุงุญ ุดุฏู ุฑุง ุฏุฑ ุฐูู ูุฎุงุทุจุด ุงููุงุก ฺฉูู\n",
            "ุง ฺฉุชุงุจูุง ฺฉู ุฏุฑุจุงุฑู ุชุฃุซุฑุงุช ุงุฌุชูุงุน ุดุฎุตุช ู ุฏุงุดุชู ูููุฐ ฺฉูุงู ุง ุฏุงุดุชู ุดุฎุตุช ฺฉุงุฑุฒูุงุชฺฉ ูุณุชูุฏ ู ูุถุนุช ุฑุง ุจฺฏููู ุง ุจุบุฑูุฌ ูฺฉูู ุงฺฏู ููู ุจุฎูุงููุฏ ุจุฑ ููุฏฺฏู ุชุฃุซุฑ ุจุฐุงุฑูุฏ ุ ุฎุจ ุฏุฑ ุงูุตูุฑุช ฺู ฺฉุณ ุชุฃุซุฑ ู ูพุฐุฑูุุุ\n",
            "ฺฉุชุงุจูุงยซ ุฒุจุงู ุจุฏูยป ุฑุดุฏ ุฒุงุฏ ฺฉุฑุฏู ู ุชูุฑุจุง ุจู ุญุงูุช ุงุดุจุงุน ุฑุณุฏู ฺฉู ูุดููุฑุชุฑู ุขููุง ูู ูุฑุจูุท ุจู ุขูู ูพุฒ ูุณุช.ููุชู ฺฉ ููุฑุฏ ูู ูุณุช ฺฉู ููฺฉูู ูุถู ุฑุง ูพฺุฏู ฺฉูู ู ุงูู ุขฺฏุงู ููฺฏุงู ุงุฒ ุงู ุณุจฺฉ ุฑูุงูุดูุงุฎุช ุงุณุช ฺฉู ููฺฉูู ููุฌุฑ ุจู ูููุฏุณ ูุนฺฉูุณ ุจุดู ุ ุนู ูุฑุฏ ฺฉ ุณุฑ ุฑูุชุงุฑูุง ุฎุงุต ู ุญุณุงุจ ุดุฏู ุฑุง ุจู ุทูุฑ ุขฺฏุงูุงูู ุฏุฑ ูพุด ุจฺฏุฑู ุชุง ุดุฎุตุช ุงุฒ ูพุด ุฎูุงุณุชู ู ุทุฑุงุญ ุดุฏู ุฑุง ุฏุฑ ุฐูู ูุฎุงุทุจุด ุงููุงุก ฺฉูู\n",
            "ุง ฺฉุชุงุจูุง ฺฉู ุฏุฑุจุงุฑู ุชุฃุซุฑุงุช ุงุฌุชูุงุน ุดุฎุตุช ู ุฏุงุดุชู ูููุฐ ฺฉูุงู ุง ุฏุงุดุชู ุดุฎุตุช ฺฉุงุฑุฒูุงุชฺฉ ูุณุชูุฏ ู ูุถุนุช ุฑุง ุจฺฏููู ุง ุจุบุฑูุฌ ูฺฉูู ุงฺฏู ููู ุจุฎูุงููุฏ ุจุฑ ููุฏฺฏู ุชุฃุซุฑ ุจุฐุงุฑูุฏ ุ ุฎุจ ุฏุฑ ุงูุตูุฑุช ฺู ฺฉุณ ุชุฃุซุฑ ู ูพุฐุฑูุุุ\n",
            "ฺฉุชุงุจ ุฌุฐุงุจ ู\n",
            "ฺฉุชุงุจ ุฌุฐุงุจ ู\n",
            "ุชุง ุญุฏ ุฒุงุฏ ุงุดุงุฑู ุจู ุจุฏูุงุช ู ููุงุฑุฏ ูุณุช ฺฉู ููู ูุง ุชุง ุจู ุญุงู ูุชูุฌู ุดุฏู ูู ูุทูุฆูุง ุฎููุฏูุด ุจุงุนุซ ุชุซุจุช ููู ุฏุงูุณุชู ูุง ูุดู ู ฺฉุงุจุฑุฏุดูู ุฑู ูพุฑ ุฑูฺฏ ุชุฑ ูฺฉูู.ุงฺฏุฑ ูุณุฆููู ุณุงุช ฺฉุชุงุจ ููุฑ ููุดู ุจุฑ ุญู ุจูุฏู ูู ุฑู ุณุงุช ุจุฐุงุฑู ุจุฑุง ุนูุงูู ููุฏุงู ฺูู ููุถูุน ูุง ุจุฏูู ุดฺฉ ุจุณุงุฑ ุจุณุงุฑ ฺฉุชุงุจ ุฌุงูุจ ุฎูุงูุฏ ุจูุฏ. \n",
            "ุชุง ุญุฏ ุฒุงุฏ ุงุดุงุฑู ุจู ุจุฏูุงุช ู ููุงุฑุฏ ูุณุช ฺฉู ููู ูุง ุชุง ุจู ุญุงู ูุชูุฌู ุดุฏู ูู ูุทูุฆูุง ุฎููุฏูุด ุจุงุนุซ ุชุซุจุช ููู ุฏุงูุณุชู ูุง ูุดู ู ฺฉุงุจุฑุฏุดูู ุฑู ูพุฑ ุฑูฺฏ ุชุฑ ูฺฉูู.ุงฺฏุฑ ูุณุฆููู ุณุงุช ฺฉุชุงุจ ููุฑ ููุดู ุจุฑ ุญู ุจูุฏู ูู ุฑู ุณุงุช ุจุฐุงุฑู ุจุฑุง ุนูุงูู ููุฏุงู ฺูู ููุถูุน ูุง ุจุฏูู ุดฺฉ ุจุณุงุฑ ุจุณุงุฑ ฺฉุชุงุจ ุฌุงูุจ ุฎูุงูุฏ ุจูุฏ. \n",
            "ุจุง ฑฐฐ ุฎุงุทุฑู  ฺฉูุชุงู ุงุฒ ุงุณุงุฑุช ุฌูฺฏ ููุฑุงู ุจุดุฏ.....\n",
            "ุชูุฎู ุญููุชุง! ...ุบุฑุจุช ู ุฏูุฑ ุ ุดฺฉูุฌู ุ ฺฏุฑุณูฺฏ ุ ุจูุงุฑ ู ุฌุฑุงุญุช ุ ูุจูุฏ ุงุจุชุฏุง ุชุฑู ุงูฺฉุงูุงุช....\n",
            "ุงูุง ุงู ูุณุท ฺฉุฏุจุงูู ุงุณุฑุง ุนุฒุฒููู ูู ุฌุงูุจู!\n",
            "..................\n",
            "ูุฑ ุขุณุงุดฺฏุงู ฺฉ ุชฺฉู ุฒูู ฺฉูฺฺฉ ุฏุงุดุช ฺฉู ุชูุด ฺฉุดุงูุฑุฒ ูฺฉุฑุฏูุฏ.ุณุจุฒ ูฺฉุงุดุชูุฏ ุ ฺฉุงูู ู ฺุฒูุง ุฏฺฏุฑ.\n",
            "ุบุฐุง ุฏุฑุณุช ูฺฉุฑุฏู ุจุง ุณุจุฒ...ฺฉู ู ุขูุฏ ุฺฉุงูู ูุฑุฎุชู! ุจุงุฒ ูู ฺฉู ู ุขูุฏ ูุฑ ฺุฒ ุณุจุฒ ฺฉู ุฏุฑ ุขูุฏู ุจูุฏ ุ ูุฑุฎุชู ุชูุด!!\n",
            "๐๐\n",
            "ูพ.ู : ุงุฏ ุขุดูพุฒูุง ุฏุงูุดฺฏุงู ููู ุงูุชุงุฏู!\n",
            "ุจุง ฑฐฐ ุฎุงุทุฑู  ฺฉูุชุงู ุงุฒ ุงุณุงุฑุช ุฌูฺฏ ููุฑุงู ุจุดุฏ.....\n",
            "ุชูุฎู ุญููุชุง! ...ุบุฑุจุช ู ุฏูุฑ ุ ุดฺฉูุฌู ุ ฺฏุฑุณูฺฏ ุ ุจูุงุฑ ู ุฌุฑุงุญุช ุ ูุจูุฏ ุงุจุชุฏุง ุชุฑู ุงูฺฉุงูุงุช....\n",
            "ุงูุง ุงู ูุณุท ฺฉุฏุจุงูู ุงุณุฑุง ุนุฒุฒููู ูู ุฌุงูุจู!\n",
            "..................\n",
            "ูุฑ ุขุณุงุดฺฏุงู ฺฉ ุชฺฉู ุฒูู ฺฉูฺฺฉ ุฏุงุดุช ฺฉู ุชูุด ฺฉุดุงูุฑุฒ ูฺฉุฑุฏูุฏ.ุณุจุฒ ูฺฉุงุดุชูุฏ ุ ฺฉุงูู ู ฺุฒูุง ุฏฺฏุฑ.\n",
            "ุบุฐุง ุฏุฑุณุช ูฺฉุฑุฏู ุจุง ุณุจุฒ...ฺฉู ู ุขูุฏ ุฺฉุงูู ูุฑุฎุชู! ุจุงุฒ ูู ฺฉู ู ุขูุฏ ูุฑ ฺุฒ ุณุจุฒ ฺฉู ุฏุฑ ุขูุฏู ุจูุฏ ุ ูุฑุฎุชู ุชูุด!!\n",
            "\n",
            "ูพ.ู : ุงุฏ ุขุดูพุฒูุง ุฏุงูุดฺฏุงู ููู ุงูุชุงุฏู!\n",
            "100ุฎุงุทุฑู ฺฉูุชุงู ุงุฒ ุงูุณุฑุง ุฎุงุทุฑุงุช ุงุฒ ุตุจุฑ ู ููุงููุช ุงู ุนุฒุฒุงู.\n",
            "ฺฏูุชู ุจูุฏ ูุชุฑุฌู ููุฎูุงู ุฎูุฏู ุฏุฑุฏู ุฑู ูฺฏู\n",
            "ุดฺฉู ุฏุฑุฏ ุฏุงุดุช ุฏฺฉุชุฑ ุจู ุด  ฺฏูุชู ุจูุฏ ฺุชูุ\n",
            "ุจู ุดฺฉูุด ุงุดุงุฑู ฺฉุฑุฏู ุจูุฏ ู ฺฏูุชู ุจูุฏ :\n",
            "\n",
            "\"ู ููููุจูู ููุฑูุถุง \" ุฏฺฉุชุฑ ูู ุจูุด ฺฏูุชู ุจูุฏ \" ููุฒุงุฏููููู\n",
            "\n",
            " ุงููููู ููุฑูุถุง\n",
            " **************\n",
            "ฺฉูุฑุฏ  ุจูุฏ ฺฏูู ู ุจุงูุช ฺูุงู ุจุง ุฏูุช ุฒุฑูพูุด ูุง ูุฎ ุฑุง ู ุดฺฉุงูุช ฺฉู ู ุดุฏ ฺฉ ูุฎ ุจููุฏ ุงุฒ ุงู ุณุฑ ุงุฑุฏูฺฏุงู ุชุง ุขู ุณุฑ ุจุนุฏ ูุฎ ูุง ุฑู ู ูพฺุฏ ุฏู ุฑูุฒ ุทูู ูฺฉุดุฏ ุจุนุฏ ุขููุง ุฑุง ฺูุงุฑ ูุง ูฺฉุฑุฏ .ฺฉ ุชฺฉู ุณู ุฎุงุฑุฏุงุฑ ุตุงู ู ฺฉุฑุฏ ู ุณุฑุด ุฑุง ูู ุจุฑ ู ฺฏุฑุฏุงูุฏ ู ุดุฏ ุณูุฒู .\n",
            "\n",
            "ุฏููพุง ูุง ุฑุง ูพุงุฑู ู ฺฉุฑุฏ ุฑู ฺฉูููุด ฺฏูู ู ุจุงูุช ุงู ุขุฎุฑูุง ฺฉู ู ุขูุฏู ุฎู ูุง ุจูุฏ ุจูุฏู ฺฏูู ุจุจุงููุฏ.\n",
            "100ุฎุงุทุฑู ฺฉูุชุงู ุงุฒ ุงูุณุฑุง ุฎุงุทุฑุงุช ุงุฒ ุตุจุฑ ู ููุงููุช ุงู ุนุฒุฒุงู.\n",
            "ฺฏูุชู ุจูุฏ ูุชุฑุฌู ููุฎูุงู ุฎูุฏู ุฏุฑุฏู ุฑู ูฺฏู\n",
            "ุดฺฉู ุฏุฑุฏ ุฏุงุดุช ุฏฺฉุชุฑ ุจู ุด  ฺฏูุชู ุจูุฏ ฺุชูุ\n",
            "ุจู ุดฺฉูุด ุงุดุงุฑู ฺฉุฑุฏู ุจูุฏ ู ฺฏูุชู ุจูุฏ :\n",
            "\n",
            "\"ู ููููุจูู ููุฑูุถุง \" ุฏฺฉุชุฑ ูู ุจูุด ฺฏูุชู ุจูุฏ \" ููุฒุงุฏููููู\n",
            "\n",
            " ุงููููู ููุฑูุถุง\n",
            " **************\n",
            "ฺฉูุฑุฏ  ุจูุฏ ฺฏูู ู ุจุงูุช ฺูุงู ุจุง ุฏูุช ุฒุฑูพูุด ูุง ูุฎ ุฑุง ู ุดฺฉุงูุช ฺฉู ู ุดุฏ ฺฉ ูุฎ ุจููุฏ ุงุฒ ุงู ุณุฑ ุงุฑุฏูฺฏุงู ุชุง ุขู ุณุฑ ุจุนุฏ ูุฎ ูุง ุฑู ู ูพฺุฏ ุฏู ุฑูุฒ ุทูู ูฺฉุดุฏ ุจุนุฏ ุขููุง ุฑุง ฺูุงุฑ ูุง ูฺฉุฑุฏ .ฺฉ ุชฺฉู ุณู ุฎุงุฑุฏุงุฑ ุตุงู ู ฺฉุฑุฏ ู ุณุฑุด ุฑุง ูู ุจุฑ ู ฺฏุฑุฏุงูุฏ ู ุดุฏ ุณูุฒู .\n",
            "\n",
            "ุฏููพุง ูุง ุฑุง ูพุงุฑู ู ฺฉุฑุฏ ุฑู ฺฉูููุด ฺฏูู ู ุจุงูุช ุงู ุขุฎุฑูุง ฺฉู ู ุขูุฏู ุฎู ูุง ุจูุฏ ุจูุฏู ฺฏูู ุจุจุงููุฏ.\n",
            "ุงุตูู ูุนููู ูุณุช ฺฉู ุทุฑู ฺฉ ูุณุชู :)))\n",
            "ุงุตูู ูุนููู ูุณุช ฺฉู ุทุฑู ฺฉ ูุณุชู :)))\n",
            "ฺฉุงููุง ุฌูุช ุฏุงุฑ ูููุณูุฏ\n",
            "ฺฉุงููุง ุฌูุช ุฏุงุฑ ูููุณูุฏ\n",
            "ุฏูุณุชุงู ฺฉุชุงุจ ุฎูุจู ุจุฎุฑูุด ุุ\n",
            "ุฏูุณุชุงู ฺฉุชุงุจ ุฎูุจู ุจุฎุฑูุด ุุ\n",
            "ุงู ฺฉุชุงุจ ูุงูุนุง ุนุงูู\n",
            "ุงู ฺฉุชุงุจ ูุงูุนุง ุนุงูู\n",
            "ฺฉุชุงุจู ุฌุงูุจ ุจูุฏ ูุณุฎู ฺุงูพุด ุฑู ุญุฏูุฏฒูุงู ูพุด ุฎููุฏู ูู ุญู ฺฉู ุจูุฏ ุฒูุฏ ุชููู ุดุฏ๐\n",
            "ฺฉุชุงุจู ุฌุงูุจ ุจูุฏ ูุณุฎู ฺุงูพุด ุฑู ุญุฏูุฏฒูุงู ูพุด ุฎููุฏู ูู ุญู ฺฉู ุจูุฏ ุฒูุฏ ุชููู ุดุฏ\n",
            "ุฏุฏ ุฌุงูุจ ุฏุงุดุช\n",
            "ุฏุฏ ุฌุงูุจ ุฏุงุดุช\n",
            "ูุดูฺฏ ุจูุฏ ูู ุฏู ุชุง ุนุจ ุฏุงุดุช ฺฉ ุงูฺฉู ฺฉู ุจูุฏ ุฏฺฏุฑ ุงูู ุงูููุฏุฑ ุงุฒุด ุงูุชุธุงุฑ ุฏุงุดุชู ูุจูุฏ\n",
            "ูุดูฺฏ ุจูุฏ ูู ุฏู ุชุง ุนุจ ุฏุงุดุช ฺฉ ุงูฺฉู ฺฉู ุจูุฏ ุฏฺฏุฑ ุงูู ุงูููุฏุฑ ุงุฒุด ุงูุชุธุงุฑ ุฏุงุดุชู ูุจูุฏ\n",
            "ุนุงูู ูู ฺฉู\n",
            "ุนุงูู ูู ฺฉู\n",
            "ุงู ฺฉุชุงุจ ุนุงูู ูู ูุณุฎู ฺุงูพุดู ุฎููุฏู . ุงุฒ ุฏูุชุฑ ุฎุงุทุฑุงุช ุงูุงุบ ุฎู ุฌุงูุจู๐๐ ูุงูุนุง ุนุงูู โค\n",
            "ุงู ฺฉุชุงุจ ุนุงูู ูู ูุณุฎู ฺุงูพุดู ุฎููุฏู . ุงุฒ ุฏูุชุฑ ุฎุงุทุฑุงุช ุงูุงุบ ุฎู ุฌุงูุจู ูุงูุนุง ุนุงูู \n",
            "ููุงู ุทูุฑ ฺฉู ุงุฒ ุงุณู ฺฉุชุงุจ ูุดุฎุต ุงุณุช \"ุฏูุชุฑ ุฎุงุทุฑุงุช ุญูุงูุงุช \"ูุฌููุนู ุฎุงุทุฑุงุช ุงุฒ ุญูุงูุงุช ุงุณุช ฺฉู ุจุฑ ุฑู ูพูุณุช ูุงุฑฺฏู ููุดุชู ุดุฏู ู ุนูุฑุถุง ุบูุงุฑ ุฏุฑ ูุฑุตุช ฺฉูุชุงู ฺฉู ุจู ุฏุณุช ุขูุฑุฏู ุจูุฏ ุจุง ุงุตุฑุงุฑ ูุฑุงูุงู ุชูุงูุณุชู ุงุฒ ูุฑ ุฏูุชุฑ ุฎุงุทุฑุงุช ฺฉ ุฑุง ุงูุชุฎุงุจ ู ุฏุฑ ุงู ฺฉุชุงุจ ุจุงูุฑุฏ.\n",
            "ฺฉุชุงุจ ุทูุฒ ุฌุฐุงุจ ุงุณุช ุงุฒ ุฒุจุงู ุญูุงูุงุช ู ฺฏุงู ููุฏ ุจุฑ ุฒูุฏฺฏ ุงูุณุงููุง ุจุง ุงุณุชูุงุฏู ุงุฒ ุฌุฒุงุช ฺฉู ุงู ฺฉุชุงุจ ุฑุง ุงุฒ ุณุงุฑ ุขุซุงุฑ ุทูุฒ ูุชูุงูุช ฺฉุฑุฏู ุงุณุช.\n",
            "โกโกโก\n",
            "\"ุงุฒ ุฏูุชุฑ ุฎุงุทุฑุงุช ฺฉ ุฑูุจุงู\n",
            "ุฏุงุณุชุงู ูุฑุจ\n",
            "ูุตู ุจุงูุฑ ุงุณุช\n",
            "ุฎุฑูุณ ูุงุฏุงู ูุงุฒ ุจู ูุฑูฺฏ ูุฏุงุฑุฏ!\n",
            "ุงูุฑูุฒ ุจุฑุง ุณุฑ ุดุฏู\n",
            "ุจุงุฏ ุฑุงุณุช ุจฺฏูู\n",
            "ฺฏุฑุณูู ุงู!\"(ุตูุญู91)\n",
            "\"ุงุฒ ุฏูุชุฑ ุฎุงุทุฑุงุช ฺฉ ุดุงููพุงูุฒู\n",
            "...ุงูุฑูุฒ ฺฉ ุงุฒ ุขุฏููุง ุฏุฑุญุงู ฺฉู ฺฉุชุงุจ ูุทูุฑ ุฑุง ูุฑู ูุฒุฏ,ุงุตุฑุงุฑ ุฏุงุดุช ุจู ุฏูุณุช ููุฑุงูุด ุซุงุจุช ฺฉูุฏ ฺฉู ุจุง ูุง ูุงูู ูุณุชูุฏ ู ุฏุฑ ฺฉ ุฌูุด ุชุงุฑุฎ ุฏู ุฎูุฏ ุฑุง ุงุฒ ุฏุณุช ุฏุงุฏู ุงูุฏ!\n",
            "ุงูุง ูู ุจู ุดุฏุช ุงู ุฑุงุจุทู ุฑุง ุชฺฉุฐุจ ูฺฉูู!\"(ุตูุญู47)\n",
            "\"ุงุฒ ุฏูุชุฑ ุฎุงุทุฑุงุช ฺฉ ุฒูุจูุฑ\n",
            "ุงูุฑูุฒ ููฺฉู ุจุณุงุฑ ุนุตุจุงู ุจูุฏ ู ุจุฑุนฺฉุณ ุนููู ุจุณุงุฑ ุฎูุดุญุงู!ุงู ุฑุง ููุช ูููุฏู ฺฉู ูููุน ุนุจูุฑ ุงุฒ ููุงุจู ููฺฉู ุจู ุฏุณุชูุฑ ุงู ฺฉู ุชููู ฺฉุฑุฏ,ูพุงูุงุด ุฑุง ุจู ูู ูุงูุฏ,ูฺฏุงู ุจู ฺุดูุงู ุฎูุงุฑ ููฺฉู ฺฉุฑุฏ ู ุฒุฑ ูุจ ฺฏูุช:ูุฒุฒ...\"(ุตูุญู19)\n",
            "ููุงู ุทูุฑ ฺฉู ุงุฒ ุงุณู ฺฉุชุงุจ ูุดุฎุต ุงุณุช \"ุฏูุชุฑ ุฎุงุทุฑุงุช ุญูุงูุงุช \"ูุฌููุนู ุฎุงุทุฑุงุช ุงุฒ ุญูุงูุงุช ุงุณุช ฺฉู ุจุฑ ุฑู ูพูุณุช ูุงุฑฺฏู ููุดุชู ุดุฏู ู ุนูุฑุถุง ุบูุงุฑ ุฏุฑ ูุฑุตุช ฺฉูุชุงู ฺฉู ุจู ุฏุณุช ุขูุฑุฏู ุจูุฏ ุจุง ุงุตุฑุงุฑ ูุฑุงูุงู ุชูุงูุณุชู ุงุฒ ูุฑ ุฏูุชุฑ ุฎุงุทุฑุงุช ฺฉ ุฑุง ุงูุชุฎุงุจ ู ุฏุฑ ุงู ฺฉุชุงุจ ุจุงูุฑุฏ.\n",
            "ฺฉุชุงุจ ุทูุฒ ุฌุฐุงุจ ุงุณุช ุงุฒ ุฒุจุงู ุญูุงูุงุช ู ฺฏุงู ููุฏ ุจุฑ ุฒูุฏฺฏ ุงูุณุงููุง ุจุง ุงุณุชูุงุฏู ุงุฒ ุฌุฒุงุช ฺฉู ุงู ฺฉุชุงุจ ุฑุง ุงุฒ ุณุงุฑ ุขุซุงุฑ ุทูุฒ ูุชูุงูุช ฺฉุฑุฏู ุงุณุช.\n",
            "\n",
            "\"ุงุฒ ุฏูุชุฑ ุฎุงุทุฑุงุช ฺฉ ุฑูุจุงู\n",
            "ุฏุงุณุชุงู ูุฑุจ\n",
            "ูุตู ุจุงูุฑ ุงุณุช\n",
            "ุฎุฑูุณ ูุงุฏุงู ูุงุฒ ุจู ูุฑูฺฏ ูุฏุงุฑุฏ!\n",
            "ุงูุฑูุฒ ุจุฑุง ุณุฑ ุดุฏู\n",
            "ุจุงุฏ ุฑุงุณุช ุจฺฏูู\n",
            "ฺฏุฑุณูู ุงู!\"(ุตูุญู91)\n",
            "\"ุงุฒ ุฏูุชุฑ ุฎุงุทุฑุงุช ฺฉ ุดุงููพุงูุฒู\n",
            "...ุงูุฑูุฒ ฺฉ ุงุฒ ุขุฏููุง ุฏุฑุญุงู ฺฉู ฺฉุชุงุจ ูุทูุฑ ุฑุง ูุฑู ูุฒุฏ,ุงุตุฑุงุฑ ุฏุงุดุช ุจู ุฏูุณุช ููุฑุงูุด ุซุงุจุช ฺฉูุฏ ฺฉู ุจุง ูุง ูุงูู ูุณุชูุฏ ู ุฏุฑ ฺฉ ุฌูุด ุชุงุฑุฎ ุฏู ุฎูุฏ ุฑุง ุงุฒ ุฏุณุช ุฏุงุฏู ุงูุฏ!\n",
            "ุงูุง ูู ุจู ุดุฏุช ุงู ุฑุงุจุทู ุฑุง ุชฺฉุฐุจ ูฺฉูู!\"(ุตูุญู47)\n",
            "\"ุงุฒ ุฏูุชุฑ ุฎุงุทุฑุงุช ฺฉ ุฒูุจูุฑ\n",
            "ุงูุฑูุฒ ููฺฉู ุจุณุงุฑ ุนุตุจุงู ุจูุฏ ู ุจุฑุนฺฉุณ ุนููู ุจุณุงุฑ ุฎูุดุญุงู!ุงู ุฑุง ููุช ูููุฏู ฺฉู ูููุน ุนุจูุฑ ุงุฒ ููุงุจู ููฺฉู ุจู ุฏุณุชูุฑ ุงู ฺฉู ุชููู ฺฉุฑุฏ,ูพุงูุงุด ุฑุง ุจู ูู ูุงูุฏ,ูฺฏุงู ุจู ฺุดูุงู ุฎูุงุฑ ููฺฉู ฺฉุฑุฏ ู ุฒุฑ ูุจ ฺฏูุช:ูุฒุฒ...\"(ุตูุญู19)\n",
            "ุจุงุญุงูู ๐๐๐๐๐๐๐๐\n",
            "ุจุงุญุงูู \n",
            "ุจุงุญุงู ุจูุฏ\n",
            "ุจุงุญุงู ุจูุฏ\n",
            "ุฌุงูุจ ู ุจุงุญุงูู๐๐๐\n",
            "ุฌุงูุจ ู ุจุงุญุงูู\n",
            "ุณูุงู \n",
            "ุงุนูุงู ุจุฑูุฏู ูุง ูุณุงุจูู ุฑู ฺุฑุง ููุด ุนูุจ ููุฏุงุฒุฏ\n",
            "ูุณุฎุฑู ุงุด ุฏุฑุขูุฑุฏุฏ\n",
            "ุณูุงู \n",
            "ุงุนูุงู ุจุฑูุฏู ูุง ูุณุงุจูู ุฑู ฺุฑุง ููุด ุนูุจ ููุฏุงุฒุฏ\n",
            "ูุณุฎุฑู ุงุด ุฏุฑุขูุฑุฏุฏ\n",
            "ุจุฑุง 96 ุตูุญู ููุชุด ุฒุงุฏู\n",
            "ุจุฑุง 96 ุตูุญู ููุชุด ุฒุงุฏู\n",
            "ุฑูุญุช ุดุงุฏ ุง ุดูุฏ ุจุฒุฑฺฏูุงุฑ  ฺฏุฐุฑ ฺฉูุชุงู ุงุฒ ุฒูุฏฺฏ ุงู ุดูุฏ ุฏุฑ ูุงูุจ ุฎุงุทุฑุงุช ฺฉูุชุงู ฺฉู ุฏฺฏุฑุงู ุงุฒ ุงุดุงู ุฏุงุดุชูุฏ ูุงูุนุงู  ฺฉู ุงูุณุงู ุจุฒุฑฺฏ ุจูุฏูุฏ\n",
            "ุฑูุญุช ุดุงุฏ ุง ุดูุฏ ุจุฒุฑฺฏูุงุฑ  ฺฏุฐุฑ ฺฉูุชุงู ุงุฒ ุฒูุฏฺฏ ุงู ุดูุฏ ุฏุฑ ูุงูุจ ุฎุงุทุฑุงุช ฺฉูุชุงู ฺฉู ุฏฺฏุฑุงู ุงุฒ ุงุดุงู ุฏุงุดุชูุฏ ูุงูุนุงู  ฺฉู ุงูุณุงู ุจุฒุฑฺฏ ุจูุฏูุฏ\n",
            "ุฎู ฺฉุชุงุจ ุฌุงูุจู\n",
            "ุชุฑุฌูู ุฎู ุฎูุจ ูู ุฏุงุฑู\n",
            "ุฏุฑ  ุฒุจุงู ูุงุฑุณ ุฏุฑ ููุฑุฏ ุชุฆุงุชุฑ ูุณุชูุฏ ฺฉุชุงุจ ุฎู ุฎู ฺฉู ูุณุช ู ุงู ูุทุนุง ฺฉ ุงุฒ ุจูุชุฑู ูุงุณุช\n",
            "ุฎู ฺฉุชุงุจ ุฌุงูุจู\n",
            "ุชุฑุฌูู ุฎู ุฎูุจ ูู ุฏุงุฑู\n",
            "ุฏุฑ  ุฒุจุงู ูุงุฑุณ ุฏุฑ ููุฑุฏ ุชุฆุงุชุฑ ูุณุชูุฏ ฺฉุชุงุจ ุฎู ุฎู ฺฉู ูุณุช ู ุงู ูุทุนุง ฺฉ ุงุฒ ุจูุชุฑู ูุงุณุช\n",
            "ูุฌููุนู ฺฏุฒุงุฑุด ุดุงูฺฉุงุฑ ุงุฒ ฺฉ ูุงุจุบู ุจุง ุชุฑุฌูู ุง ููู ุงูุนุงุฏู ุฎูุจ. ููููู ุงุฒ ูุชุฑุฌู\n",
            "ูุฌููุนู ฺฏุฒุงุฑุด ุดุงูฺฉุงุฑ ุงุฒ ฺฉ ูุงุจุบู ุจุง ุชุฑุฌูู ุง ููู ุงูุนุงุฏู ุฎูุจ. ููููู ุงุฒ ูุชุฑุฌู\n",
            "ูุชุงุณูุงูู ุญุช ุงู ุชุฑุฌูู ูู ุฎูุจ ู ุฑูุงู ูุจูุฏุ ููฺูุงู ุชุฑุฌูู  ููู ฺฉุชุงุจ ุฑู ุจุง ุนููุงู ููุงูุฏู ุจุง ุชุฑุฌูู  ููุฏ ููุฏ ูพุดููุงุฏ ูฺฉูู.\n",
            "ูุชุงุณูุงูู ุญุช ุงู ุชุฑุฌูู ูู ุฎูุจ ู ุฑูุงู ูุจูุฏุ ููฺูุงู ุชุฑุฌูู  ููู ฺฉุชุงุจ ุฑู ุจุง ุนููุงู ููุงูุฏู ุจุง ุชุฑุฌูู  ููุฏ ููุฏ ูพุดููุงุฏ ูฺฉูู.\n",
            "ุงุฒ ุฏูุณุชุงู ฺฉุณ ูุฏููู ุชุฑุฌูู ุณู ุจูุชุฑู ุง ุงูุ\n",
            "ุงุฒ ุฏูุณุชุงู ฺฉุณ ูุฏููู ุชุฑุฌูู ุณู ุจูุชุฑู ุง ุงูุ\n",
            "ุจู ููู ุฎูุฏ ููุณูุฏูุ ุขูุง ฺฉุงุธูุ ุงู ฺฉุชุงุจ ุจุง ฺฉุชุงุจูุง ยซุงุญูุฏ ุงุญูุฏยป ู ยซุฎุงุทุฑุงุช ุนุฒุช ุดุงูยป ุณู ฺฏุงูู ุง ุฑุง ุดฺฉู ู ุฏููุฏ ฺฉู ูููพูุดุงู ุฒุงุฏ ุฏุงุฑูุฏ. ุญุฏูุฏ ฑฒ ุณุงู ูพุด ุฎุงุทุฑุงุช ุงุญูุฏ ุงุญูุฏ ุฑุง ุฎูุงูุฏู ฺฉู ุงููู ฺฉุชุงุจ ุงุฒ ุฎุงุทุฑุงุช ูพุด ุงุฒ ุงูููุงุจ ุจูุฏ (ุงูุจุชู ุจุนุฏุด ูู ุฎุงุทุฑุงุช ูุฑุถู ุญุฏุฏู ฺ ุฑุง ุฎูุงูุฏู).... ูู ฺฉุชุงุจ ุนุฒุช ุดุงู ฺุฒ ุฏฺฏุฑ ุจูุฏ... ุงู ฺฉุชุงุจ ุฏุฑ ุจุณุงุฑ ุงุฒ ุจุฎุด ูุง ูุดุงุจู ุนุฒุช ุดุงู ุงุณุช (ฺูู ุฏุฑ ุฒูุฏุงู ู ฺฏุฐุฑุฏ ู ุนููุง ุญูุงุฏุซ ุฑุง ูุฑูุฑ ู ฺฉูุฏ ู ุจุดุชุฑ ุฑู ุดุฎุตุช ูุง ุชูุถุญ ู ุฏูุฏ) ุ ุงูุง ุงุตูุง ูุงุฑุฏ ุฌุฒุงุช ูู ุดูุฏ ู ุงุฒ ุงู ูุธุฑ ูุฌุงู ูุฏุงุฑุฏ... ูุซูุง ู ฺฏูุฏ ูู ุฑุง ฺฉ ููุชู ุดฺฉูุญู ฺฉุฑุฏูุฏ ู ูฺ ุชูุถุญ ุฏุฑุจุงุฑู ูุญูู  ุงุชูุงูุงุช ูู ุฏูุฏ.. ุงฺฏุฑ ุฒุฑููุณ ูุง ูุจูุฏ ฺฉุชุงุจ ุฎู ุจ ูุงู ู ุดุฏ... ุจู ูุฑ ุญุงู ูู ุงฺฏุฑ ุจุฎูุงูู ฺฉุชุงุจ ูพุฑุญุฌู ุจุฑุง ูุจุงุฑุฒุงุช ูพุด ุงุฒ ุงูููุงุจ ู ุขุดูุง ุจุง ูุฌุงูุฏู ูุนุฑู ฺฉููุ ูุทุนุง ุฎุงุทุฑุงุช ุนุฒุช ุดุงู ุฑุง ุชุฑุฌุญ ู ุฏูู ฺูู ูุงูุนุง ุฌุฐุงุจ ู ุฏูู ู ฺฉุงูู ููุดุชู ุดุฏู ุงุณุช...ุงูุจุชู ูฺฉุงุช ุฌุฏุฏ ูู ุฏุงุดุช ุงู ฺฉุชุงุจ ูู ุจุง ูุงุตูู ุฒุงุฏุ ูพุงู ุชุฑ ุงุฒ ุฎุงุทุฑุงุช ุนุฒุช ุดุงู ูุฑุงุฑ ูฺฏุฑู ุฏุฑ ุงู ุณู ฺฏุงูู ุชุงุฑุฎ ุงูุจุชู ูุฑ ุณู ุงู ฺฉุชุงุจ ูุง ุจู ุนููุงู ฺฉุงุฑูุง ุขูุง ฺฉุงุธู ุฌุง ุชูุฏุฑ ุฏุงุฑูุฏ... ุงุดุงู ุจุง ูพุงูุฑู ูุง ุฏูู ู ุบุฑุญุงูุจุฏุงุฑุงูู ุดุงู ุ ูุชุฌู ฺฉุงุฑ ุฑุง ฺฉ ูุทุงูุนู ุนูู ุชุงุฑุฎ ฺฉุฑุฏู ุงูุฏ\n",
            "ุจู ููู ุฎูุฏ ููุณูุฏูุ ุขูุง ฺฉุงุธูุ ุงู ฺฉุชุงุจ ุจุง ฺฉุชุงุจูุง ยซุงุญูุฏ ุงุญูุฏยป ู ยซุฎุงุทุฑุงุช ุนุฒุช ุดุงูยป ุณู ฺฏุงูู ุง ุฑุง ุดฺฉู ู ุฏููุฏ ฺฉู ูููพูุดุงู ุฒุงุฏ ุฏุงุฑูุฏ. ุญุฏูุฏ ฑฒ ุณุงู ูพุด ุฎุงุทุฑุงุช ุงุญูุฏ ุงุญูุฏ ุฑุง ุฎูุงูุฏู ฺฉู ุงููู ฺฉุชุงุจ ุงุฒ ุฎุงุทุฑุงุช ูพุด ุงุฒ ุงูููุงุจ ุจูุฏ (ุงูุจุชู ุจุนุฏุด ูู ุฎุงุทุฑุงุช ูุฑุถู ุญุฏุฏู ฺ ุฑุง ุฎูุงูุฏู).... ูู ฺฉุชุงุจ ุนุฒุช ุดุงู ฺุฒ ุฏฺฏุฑ ุจูุฏ... ุงู ฺฉุชุงุจ ุฏุฑ ุจุณุงุฑ ุงุฒ ุจุฎุด ูุง ูุดุงุจู ุนุฒุช ุดุงู ุงุณุช (ฺูู ุฏุฑ ุฒูุฏุงู ู ฺฏุฐุฑุฏ ู ุนููุง ุญูุงุฏุซ ุฑุง ูุฑูุฑ ู ฺฉูุฏ ู ุจุดุชุฑ ุฑู ุดุฎุตุช ูุง ุชูุถุญ ู ุฏูุฏ) ุ ุงูุง ุงุตูุง ูุงุฑุฏ ุฌุฒุงุช ูู ุดูุฏ ู ุงุฒ ุงู ูุธุฑ ูุฌุงู ูุฏุงุฑุฏ... ูุซูุง ู ฺฏูุฏ ูู ุฑุง ฺฉ ููุชู ุดฺฉูุญู ฺฉุฑุฏูุฏ ู ูฺ ุชูุถุญ ุฏุฑุจุงุฑู ูุญูู  ุงุชูุงูุงุช ูู ุฏูุฏ.. ุงฺฏุฑ ุฒุฑููุณ ูุง ูุจูุฏ ฺฉุชุงุจ ุฎู ุจ ูุงู ู ุดุฏ... ุจู ูุฑ ุญุงู ูู ุงฺฏุฑ ุจุฎูุงูู ฺฉุชุงุจ ูพุฑุญุฌู ุจุฑุง ูุจุงุฑุฒุงุช ูพุด ุงุฒ ุงูููุงุจ ู ุขุดูุง ุจุง ูุฌุงูุฏู ูุนุฑู ฺฉููุ ูุทุนุง ุฎุงุทุฑุงุช ุนุฒุช ุดุงู ุฑุง ุชุฑุฌุญ ู ุฏูู ฺูู ูุงูุนุง ุฌุฐุงุจ ู ุฏูู ู ฺฉุงูู ููุดุชู ุดุฏู ุงุณุช...ุงูุจุชู ูฺฉุงุช ุฌุฏุฏ ูู ุฏุงุดุช ุงู ฺฉุชุงุจ ูู ุจุง ูุงุตูู ุฒุงุฏุ ูพุงู ุชุฑ ุงุฒ ุฎุงุทุฑุงุช ุนุฒุช ุดุงู ูุฑุงุฑ ูฺฏุฑู ุฏุฑ ุงู ุณู ฺฏุงูู ุชุงุฑุฎ ุงูุจุชู ูุฑ ุณู ุงู ฺฉุชุงุจ ูุง ุจู ุนููุงู ฺฉุงุฑูุง ุขูุง ฺฉุงุธู ุฌุง ุชูุฏุฑ ุฏุงุฑูุฏ... ุงุดุงู ุจุง ูพุงูุฑู ูุง ุฏูู ู ุบุฑุญุงูุจุฏุงุฑุงูู ุดุงู ุ ูุชุฌู ฺฉุงุฑ ุฑุง ฺฉ ูุทุงูุนู ุนูู ุชุงุฑุฎ ฺฉุฑุฏู ุงูุฏ\n",
            "\"ุงฺฏุฑ ุญุฑฺฉุช ูุจุงุดุฏ,ู ููุท ุณฺฉูุช ู ุณฺฉูู;ูุนูุงุด ุงู ูุณุช ฺฉู ุขุจ ุงุฒ ุขุจ ุชฺฉุงู ููุฎูุฑุฏ.ุญุฑฺฉุช ุฏุฑ ุฑูุชู ูุงุฒูู ุงุด ุชฺฉุงู ู ูุฑุฒุด ุงุณุช;ฺฏุงู ฺฉูุฏ ฺฏุงู ุชูุฏ...ูุนูุง ุงู ูู ููุท ุจ ูุฑุงุฑ ูุณุช.ุจูฺฉู ููู ูุฑุงุฑ ุงุณุช,ู ููู ุชุฑ ุจ ูุฑุงุฑ ูุง ฺฉู ูุฑุงุฑ ู ุขูุฑููุฏ...\"(ุตูุญู381)\n",
            "ยคยคยค\n",
            "\"ุณุงููุง ุจ ูุฑุงุฑ\"ุฎุงุทุฑุงุช ุฌูุงุฏ ููุตูุฑ ุงุณุช.ุฌูุงู ฺฉู ุณุงููุง ุณุงู ุจุง ุฑฺู ุทุงุบูุช ูุจุงุฑุฒู ฺฉุฑุฏ ู ุฏุฑ ุงู ุฑุงู ูู ุฑูุฌ ุฒูุฏุงู ุฑุง ฺุดุฏ,ูู ุชุจุนุฏ ุฑุง ;ููู ุฏุฑุฏ ู ุฒุฎููุง ุฑุง ฺฉู ุฏุฑ ุดฺฉูุฌู ฺฏุงู ูุง ุจุฑ ุฌุณู ู ุฑูุญุด ูุดุณุช...ุฌูุงุฏ ููุตูุฑ ฺฉ ุงุฒ ุขู ุฌูุงููุง ุงุณุช ฺฉู ุชุง ุงฺฉููู ูพุง ุงุนุชูุงุฏุงุชุด ุงุณุชุงุฏู ุงุณุช. ุงู ฺฉุชุงุจ ุฎุงุทุฑุงุช ุงูุณุช ฺฉู ููฺฏุงู ุญุถูุฑ ุฏุฑ ุงุณูุงู ุขุจุงุฏ ุจู ุชุญุฑุฑ ุฏุฑ ุขูุฏู ุงุณุช ู ุจุง ุชูุงูููุฏ ูุง ู ุฏุงูุณุชู ูุง ูุญุณู ฺฉุงุธู ุฏุฑ ุชุฏูู ุขู ุจู ฺฉ ููุจุน ููุซู ุฏุฑ ููุฑุฏ ุณุงุฒูุงููุง ู ฺฏุฑููฺฉูุง,ุดุฎุตุชูุง ,ุญฺฉููุชูุง ู...ุจุฏู ุดุฏู ุงุณุช.\n",
            "ยคยคยค\n",
            "\"...ูู ูุนุชูุฏู ูฺ ููุดุชู ู ุชุตูุฑ ููุชูุงูุฏ ุชูุงู ุขูฺู ุฑุง ฺฉู ุฏุฑ ุงู ูุฏุช[ ููุจุงุฑุฒุงุช ุงูููุงุจ]ฺฏุฐุดุช,ุจุงุชูุงู ุงุจุนุงุฏ ุขู ุจุงู ฺฉูุฏ ู ูุดุงู ุฏูุฏ.ุนูุฏู ูุง ูุฑููุง ู ูุณููุง ฺฏุดูุฏู ุดุฏ,ุงูุชุธุงุฑ ุทููุงู ฺฉ ููุช ุจู ูพุงุงู ุฑุณุฏ;ูุฑฺูุฏ ูู ุชุง ููู ูุง ุดุจ[ ูุจุณุช ู ุฏู ุจููู]ุฏุฑ ุฎุงุจุงููุง ุจูุฏู ู ุตุญูู ูุง ูุฑุงููุด ูุงุดุฏู ุฒุงุฏ ุฏุฏู,ูู ุจุนุฏ ูุฏุงูู ฺฉู ูุงุฏุฑ ุจู ููุดุชู[ููู] ุขููุง ุจุงุดู...\"(ุตูุญู448)\n",
            "ยคยคยค\n",
            "\"...ูุนูููู ฺฉู ูุฑฺฉ ุชู ุฒูุฏฺฏุด ุจู ุฎุงุทุฑ ุฑุงู ฺฉู ูุฑู ,ูพุงูุงุด ุฎุณุชู ูุดู,ุฒุฎู ูุดู;ูุฑ ฺ ุฑุงู ูพุฑูพฺ ู ุฎู ุชุฑ,ุฒุฎููุง ูู ุนูู ุชุฑ,ุจุนุถ ุฒุฎููุง ุจุง ุงูฺฉู ุฌุงุดูู ููููู ุงูุง ุฎูุจ ูุดูุฏ;ุจุนุถ ุฒุฎููุง ุจุง ุงูฺฉู ุฌุงุดูู ูููููู,ูู ูฺ ููุช ุฎูุจ ููุดูุฏ...\"(ุตูุญู215)\n",
            "\"...ฺฏุงู ุงุญุณุงุณ ูฺฉูู ูพุงูุง ุฏูู ุฎุณุชู ุดุฏู ุงูุฏ!ุฎุณุชู ุงุฒุฑูุฒฺฏุงุฑ ู ุจุฏุนูุฏ ูุงุด...ฺู ุดุจูุง ู ุฑูุฒูุง ฺฉู ุจุง ุงู ูพุงูุง ุฏูุฏู;ุจู ุงู ุทุฑู...ุจู ุขู ุทุฑู...;ุฏุฑ ููุตุฏ ู ุฏุฑ ูุงูู ุฑุงู ุจู ูุฑฺฉูู ุฑุณุฏู ูุฑุงุฏ ฺฉุฑุฏู,ููุณ ุจู ููุณุดุงู ุฏุงุฏู,ู ุฌุงู ฺฏุฑูุชู ู ุฑูุชู.ุงูุง ุงูุงู ุงุณุชุงุฏู ุงู ุชุง ุฎุณุชฺฏ ูพุงูุงู ุฑุง ุฏุฑฺฉูู ู ููุณ ุฏูุจุงุฑู ุจฺฏุฑู ุชุง...\"(ุตูุญู165)\n",
            "\"ุงฺฏุฑ ุญุฑฺฉุช ูุจุงุดุฏ,ู ููุท ุณฺฉูุช ู ุณฺฉูู;ูุนูุงุด ุงู ูุณุช ฺฉู ุขุจ ุงุฒ ุขุจ ุชฺฉุงู ููุฎูุฑุฏ.ุญุฑฺฉุช ุฏุฑ ุฑูุชู ูุงุฒูู ุงุด ุชฺฉุงู ู ูุฑุฒุด ุงุณุช;ฺฏุงู ฺฉูุฏ ฺฏุงู ุชูุฏ...ูุนูุง ุงู ูู ููุท ุจ ูุฑุงุฑ ูุณุช.ุจูฺฉู ููู ูุฑุงุฑ ุงุณุช,ู ููู ุชุฑ ุจ ูุฑุงุฑ ูุง ฺฉู ูุฑุงุฑ ู ุขูุฑููุฏ...\"(ุตูุญู381)\n",
            "ยคยคยค\n",
            "\"ุณุงููุง ุจ ูุฑุงุฑ\"ุฎุงุทุฑุงุช ุฌูุงุฏ ููุตูุฑ ุงุณุช.ุฌูุงู ฺฉู ุณุงููุง ุณุงู ุจุง ุฑฺู ุทุงุบูุช ูุจุงุฑุฒู ฺฉุฑุฏ ู ุฏุฑ ุงู ุฑุงู ูู ุฑูุฌ ุฒูุฏุงู ุฑุง ฺุดุฏ,ูู ุชุจุนุฏ ุฑุง ;ููู ุฏุฑุฏ ู ุฒุฎููุง ุฑุง ฺฉู ุฏุฑ ุดฺฉูุฌู ฺฏุงู ูุง ุจุฑ ุฌุณู ู ุฑูุญุด ูุดุณุช...ุฌูุงุฏ ููุตูุฑ ฺฉ ุงุฒ ุขู ุฌูุงููุง ุงุณุช ฺฉู ุชุง ุงฺฉููู ูพุง ุงุนุชูุงุฏุงุชุด ุงุณุชุงุฏู ุงุณุช. ุงู ฺฉุชุงุจ ุฎุงุทุฑุงุช ุงูุณุช ฺฉู ููฺฏุงู ุญุถูุฑ ุฏุฑ ุงุณูุงู ุขุจุงุฏ ุจู ุชุญุฑุฑ ุฏุฑ ุขูุฏู ุงุณุช ู ุจุง ุชูุงูููุฏ ูุง ู ุฏุงูุณุชู ูุง ูุญุณู ฺฉุงุธู ุฏุฑ ุชุฏูู ุขู ุจู ฺฉ ููุจุน ููุซู ุฏุฑ ููุฑุฏ ุณุงุฒูุงููุง ู ฺฏุฑููฺฉูุง,ุดุฎุตุชูุง ,ุญฺฉููุชูุง ู...ุจุฏู ุดุฏู ุงุณุช.\n",
            "ยคยคยค\n",
            "\"...ูู ูุนุชูุฏู ูฺ ููุดุชู ู ุชุตูุฑ ููุชูุงูุฏ ุชูุงู ุขูฺู ุฑุง ฺฉู ุฏุฑ ุงู ูุฏุช[ ููุจุงุฑุฒุงุช ุงูููุงุจ]ฺฏุฐุดุช,ุจุงุชูุงู ุงุจุนุงุฏ ุขู ุจุงู ฺฉูุฏ ู ูุดุงู ุฏูุฏ.ุนูุฏู ูุง ูุฑููุง ู ูุณููุง ฺฏุดูุฏู ุดุฏ,ุงูุชุธุงุฑ ุทููุงู ฺฉ ููุช ุจู ูพุงุงู ุฑุณุฏ;ูุฑฺูุฏ ูู ุชุง ููู ูุง ุดุจ[ ูุจุณุช ู ุฏู ุจููู]ุฏุฑ ุฎุงุจุงููุง ุจูุฏู ู ุตุญูู ูุง ูุฑุงููุด ูุงุดุฏู ุฒุงุฏ ุฏุฏู,ูู ุจุนุฏ ูุฏุงูู ฺฉู ูุงุฏุฑ ุจู ููุดุชู[ููู] ุขููุง ุจุงุดู...\"(ุตูุญู448)\n",
            "ยคยคยค\n",
            "\"...ูุนูููู ฺฉู ูุฑฺฉ ุชู ุฒูุฏฺฏุด ุจู ุฎุงุทุฑ ุฑุงู ฺฉู ูุฑู ,ูพุงูุงุด ุฎุณุชู ูุดู,ุฒุฎู ูุดู;ูุฑ ฺ ุฑุงู ูพุฑูพฺ ู ุฎู ุชุฑ,ุฒุฎููุง ูู ุนูู ุชุฑ,ุจุนุถ ุฒุฎููุง ุจุง ุงูฺฉู ุฌุงุดูู ููููู ุงูุง ุฎูุจ ูุดูุฏ;ุจุนุถ ุฒุฎููุง ุจุง ุงูฺฉู ุฌุงุดูู ูููููู,ูู ูฺ ููุช ุฎูุจ ููุดูุฏ...\"(ุตูุญู215)\n",
            "\"...ฺฏุงู ุงุญุณุงุณ ูฺฉูู ูพุงูุง ุฏูู ุฎุณุชู ุดุฏู ุงูุฏ!ุฎุณุชู ุงุฒุฑูุฒฺฏุงุฑ ู ุจุฏุนูุฏ ูุงุด...ฺู ุดุจูุง ู ุฑูุฒูุง ฺฉู ุจุง ุงู ูพุงูุง ุฏูุฏู;ุจู ุงู ุทุฑู...ุจู ุขู ุทุฑู...;ุฏุฑ ููุตุฏ ู ุฏุฑ ูุงูู ุฑุงู ุจู ูุฑฺฉูู ุฑุณุฏู ูุฑุงุฏ ฺฉุฑุฏู,ููุณ ุจู ููุณุดุงู ุฏุงุฏู,ู ุฌุงู ฺฏุฑูุชู ู ุฑูุชู.ุงูุง ุงูุงู ุงุณุชุงุฏู ุงู ุชุง ุฎุณุชฺฏ ูพุงูุงู ุฑุง ุฏุฑฺฉูู ู ููุณ ุฏูุจุงุฑู ุจฺฏุฑู ุชุง...\"(ุตูุญู165)\n",
            "ุจุง ุณูุงู.ุงุฒ ฺฉุชุงุจ ุจุณุงุฑ ุฎูุจ ุดูุง ููููู\n",
            "ุจุง ุณูุงู.ุงุฒ ฺฉุชุงุจ ุจุณุงุฑ ุฎูุจ ุดูุง ููููู\n",
            "ุงุตูุง  ุขุฏู ุฑู ุฌุฐุจ ููฺฉูู ุฒุงุฏ ุจ ุณุฑู ุชูู ุฏุงุณุชุงููุงุด ูู ฺฉู ฺูุฏุชุง ุงููุด ุฑู ุฎููุฏู ุฏฺฏู ุงุฏุงูู ูุฏุงุฏู\n",
            "ุงุตูุง  ุขุฏู ุฑู ุฌุฐุจ ููฺฉูู ุฒุงุฏ ุจ ุณุฑู ุชูู ุฏุงุณุชุงููุงุด ูู ฺฉู ฺูุฏุชุง ุงููุด ุฑู ุฎููุฏู ุฏฺฏู ุงุฏุงูู ูุฏุงุฏู\n",
            "ูุงูุนุง ุงู ฺฉุชุงุจ ฺุงูพ ุดุฏู ุจุง ุงู ููู ุงููุงุธ ุฑฺฉฺฉ\n",
            "ู ุฏุงุณุชุงููุง ุฒุดุช ู ุจ ูุนู\n",
            "ู ุณุงุณุช ุฒุฏู\n",
            "ูุงูุนุง ุงู ฺฉุชุงุจ ฺุงูพ ุดุฏู ุจุง ุงู ููู ุงููุงุธ ุฑฺฉฺฉ\n",
            "ู ุฏุงุณุชุงููุง ุฒุดุช ู ุจ ูุนู\n",
            "ู ุณุงุณุช ุฒุฏู\n",
            "ฺฉุชุงุจ ฺูุฏุงู ูู ูุณุช ู ุฏุงุณุชุงู ูุงุด ุฌุฐุงุจุช ูุฏุงุฑู\n",
            "ฺฉุชุงุจ ฺูุฏุงู ูู ูุณุช ู ุฏุงุณุชุงู ูุงุด ุฌุฐุงุจุช ูุฏุงุฑู\n",
            "ููุงุท ูุซุจุช : ุงุฒ ุจ ฺฉุงุฑ ุจูุชุฑู\n",
            "ููุงุท ููู: ู ูููุฏ ูุฑ ฺฉุชุงุจ ุงุฑุฒุด ุฎููุฏู ูุฏุงุฑู...ูุนู ุบุจุทู ุฎูุฑุฏู ุงุฒ ุนูุฑ ุฑุง ุฏุฑฺฉ ู ฺฉูุฏ....ุฏุงุณุชุงู ูุง ุชู ูุฏุงุฑูุฏ...ุจ ุงุฏุจ ูู ุชูุด ูุณุช\n",
            "ููุงุท ูุซุจุช : ุงุฒ ุจ ฺฉุงุฑ ุจูุชุฑู\n",
            "ููุงุท ููู: ู ูููุฏ ูุฑ ฺฉุชุงุจ ุงุฑุฒุด ุฎููุฏู ูุฏุงุฑู...ูุนู ุบุจุทู ุฎูุฑุฏู ุงุฒ ุนูุฑ ุฑุง ุฏุฑฺฉ ู ฺฉูุฏ....ุฏุงุณุชุงู ูุง ุชู ูุฏุงุฑูุฏ...ุจ ุงุฏุจ ูู ุชูุด ูุณุช\n",
            "ุตูุฑ ุงุฒ ุตุฏ\n",
            "ุจ ูุฏู \n",
            "\n",
            "ฺฉุงููุง ุจ ุงุณุชุนุฏุงุฏ ุฏุฑ ููุณูุฏฺฏ\n",
            "ุงูุดุงุก ุฏูุฑุงู ุฏุจุณุชุงูู ุฎููุฏู ุชุฑ ุงุฒ ุงู ฺฉุชุงุจู\n",
            "ุตูุฑ ุงุฒ ุตุฏ\n",
            "ุจ ูุฏู \n",
            "\n",
            "ฺฉุงููุง ุจ ุงุณุชุนุฏุงุฏ ุฏุฑ ููุณูุฏฺฏ\n",
            "ุงูุดุงุก ุฏูุฑุงู ุฏุจุณุชุงูู ุฎููุฏู ุชุฑ ุงุฒ ุงู ฺฉุชุงุจู\n",
            "ุฏุฑ ุถูู ููุช ฺฉุชุงุจ ูู ุฎู ุฎูููุจู\n",
            "ููููู ุทุงูฺู ู ุจูุชูุงุฑ\n",
            "ุฏุฑ ุถูู ููุช ฺฉุชุงุจ ูู ุฎู ุฎูููุจู\n",
            "ููููู ุทุงูฺู ู ุจูุชูุงุฑ\n",
            "ูุฌููุน ุฏุงุณุชุงู ุนุงู ู ฺฉู ููุต ฺฉู ุชฺฉ ุชฺฉ ุฏุงุณุชุงู ูุงุด ุฎููุฏูู .\n",
            "ููุฑุงู ุงุจุงุฏ ุงูุฏู  ุฎู ุฎูุจ ุฏุฑ ุงุฏุจุงุช ุฏุงุณุชุงู ุฎูุงูุฏ ุฏุงุดุช\n",
            "ูุฌููุน ุฏุงุณุชุงู ุนุงู ู ฺฉู ููุต ฺฉู ุชฺฉ ุชฺฉ ุฏุงุณุชุงู ูุงุด ุฎููุฏูู .\n",
            "ููุฑุงู ุงุจุงุฏ ุงูุฏู  ุฎู ุฎูุจ ุฏุฑ ุงุฏุจุงุช ุฏุงุณุชุงู ุฎูุงูุฏ ุฏุงุดุช\n",
            "ฺฉุชุงุจ ูุซุฑ ุดุงุนุฑุงูู ุง ุฏุงุฑุฏ ... ุจุณุงุฑ ุฒุจุงุณุช ... ูุงููุฏ ุฎูุงูุฏู ฺฉ ุดุนุฑ ุจููุฏ \n",
            "ูุถุง ุฏุงุณุชุงู ุดุจู ุฑูุงุช ฺฉ ุฎูุงุจ ุจููุฏ ุงุณุช ...\n",
            "ฺฉุชุงุจ ูุซุฑ ุดุงุนุฑุงูู ุง ุฏุงุฑุฏ ... ุจุณุงุฑ ุฒุจุงุณุช ... ูุงููุฏ ุฎูุงูุฏู ฺฉ ุดุนุฑ ุจููุฏ \n",
            "ูุถุง ุฏุงุณุชุงู ุดุจู ุฑูุงุช ฺฉ ุฎูุงุจ ุจููุฏ ุงุณุช ...\n",
            "ุงฺฏู ูุฎูุงุฏ ุฑูุงู ุจุฎููุฏ ุง ุญุชุง ู ุฏุงุณุชุงู ุจููุฏ ุง ฺฉูุชุงู ุงุตูู ูพุดููุงุฏ ููฺฉูู.\n",
            "ฺฉูู ูู ุงฺฏู ูุฎููุฏ ูฺ ุฑู ุงุฒ ุฏุณุช ูุฏุงุฏู.\n",
            "ุงฺฏู ูุฎูุงุฏ ุฑูุงู ุจุฎููุฏ ุง ุญุชุง ู ุฏุงุณุชุงู ุจููุฏ ุง ฺฉูุชุงู ุงุตูู ูพุดููุงุฏ ููฺฉูู.\n",
            "ฺฉูู ูู ุงฺฏู ูุฎููุฏ ูฺ ุฑู ุงุฒ ุฏุณุช ูุฏุงุฏู.\n",
            "ุจู ุจู ุจู ุนุงุงุงุงุงูู  ููููู ุงุฒ ุทุงูฺู ู ุซุงูุซ\n",
            "ุงุฒ ุฑูุงู ูุง ู ูุฌููุนู ุดุนุฑูุง ุงุญูุฏุฑุถุง ุงุญูุฏ ุจุงุฒ ูู ุฑู ุทุงูฺู ุจฺฏุฐุงุฑุฏ\n",
            "ุจู ุจู ุจู ุนุงุงุงุงุงูู  ููููู ุงุฒ ุทุงูฺู ู ุซุงูุซ\n",
            "ุงุฒ ุฑูุงู ูุง ู ูุฌููุนู ุดุนุฑูุง ุงุญูุฏุฑุถุง ุงุญูุฏ ุจุงุฒ ูู ุฑู ุทุงูฺู ุจฺฏุฐุงุฑุฏ\n",
            "ุงู ุนุงูู !\n",
            "ุงู ุนุงูู !\n",
            "ุฏฺฉุชุฑ ุดุฑูู ูฺฉู ุฏุฑุณ ุฎูุงูุฏู  ุฌุงูุนู ุดูุงุณ ุงุณุช ู ุจุง ุชุงุฑุฎ ุงุฑุงู ูุฒ ุขุดูุง ุฏุงุฑุฏ. \n",
            "ุงู ุฏุฑ ุงู ฺฉุชุงุจ ุจุฑุง ุชุญูู ุชุงุฑุฎ ู ููุช ููุช ุงุฑุงู ููุทู ุนุฒูุช ุฎูุฏ ุฑุง ุจุฑ ุงุณุทูุฑู  ูุนุฌุฒู ููุงู ุจุงุณุชุงู ฺฏุฐุงุดุชู ุงุณุช ฺฉู ฺฺฏููู ุฎุงุณุชฺฏุงู ู ุงุณุงุณ ุชุญูู ููุช ุฏุฑ ุฌูุงู ูุฑุงุฑ ฺฏุฑูุชู ุงุณุช. \n",
            "ุจุฏูู ุชุฑุฏุฏ ฺฉุชุงุจ ุจุณุงุฑ ุงุฑุฒุดููุฏ ุงุณุช ู ุณุทุญ ุงุฒ ุชุญูู ุฑุง ุฏุฑ ูุฑุงุฑู ุฎูุงููุฏู ูุฑุงุฑ ูุฏูุฏ.\n",
            "ุฏฺฉุชุฑ ุดุฑูู ูฺฉู ุฏุฑุณ ุฎูุงูุฏู  ุฌุงูุนู ุดูุงุณ ุงุณุช ู ุจุง ุชุงุฑุฎ ุงุฑุงู ูุฒ ุขุดูุง ุฏุงุฑุฏ. \n",
            "ุงู ุฏุฑ ุงู ฺฉุชุงุจ ุจุฑุง ุชุญูู ุชุงุฑุฎ ู ููุช ููุช ุงุฑุงู ููุทู ุนุฒูุช ุฎูุฏ ุฑุง ุจุฑ ุงุณุทูุฑู  ูุนุฌุฒู ููุงู ุจุงุณุชุงู ฺฏุฐุงุดุชู ุงุณุช ฺฉู ฺฺฏููู ุฎุงุณุชฺฏุงู ู ุงุณุงุณ ุชุญูู ููุช ุฏุฑ ุฌูุงู ูุฑุงุฑ ฺฏุฑูุชู ุงุณุช. \n",
            "ุจุฏูู ุชุฑุฏุฏ ฺฉุชุงุจ ุจุณุงุฑ ุงุฑุฒุดููุฏ ุงุณุช ู ุณุทุญ ุงุฒ ุชุญูู ุฑุง ุฏุฑ ูุฑุงุฑู ุฎูุงููุฏู ูุฑุงุฑ ูุฏูุฏ.\n",
            "ุจูุดุงู ฺฏูุชู ุจูุฏูุฏ: ุดูุง ฺฉู ุฒุฏูุฏุ ุงฺฏู ูุงุณฺฉ ูุจูุฏุ ุงฺฏู ุฑูุฏุฎุงููโุงุ ฺุงูู  ุขุจ ุฏูุฑูุจุฑ ุจูุฏุ ุจูพุฑุฏ ุชู ุขุจ! ุดูุง ุชู ุขุจ ุจ ุงุซุฑ ูุดูุฏ.\n",
            "***\n",
            "ุตูุฑุชุดุ ุฏุณุชูุงุด ุชุง ุขุฑูุฌ ู ุฑู ูพุงูุงุด ุชุงูู ุฒุฏู ุจูุฏ. ุจุง ุขุจ ููุฑ ูุถู ฺฏุฑูุชู ุจูุฏ... ๐\n",
            "_____________________\n",
            "ุงุฒ ุตุจุญ ูุฑฺ ุนุฑุงูู ุฒุฎู ุขูุฑุฏูุฏุ ุฏุงุฏู ุงู ุนูู ฺฉุฑุฏ. ุดุงฺฉ ุดุฏุ ฺฏูุช:\n",
            "ุจูุดุช ูุงุด ุฑู ุฎูุฏุชูู ุนูู ูฺฉูุฏุ ุฌููู ูุงุด ุฑู ูุฏู ุจู ููุ! ๐ ๐\n",
            "(ููุจุน: ฺฉุชุงุจ ูพุฒุดฺฉุงู)\n",
            "_____________________\n",
            "ฺฉุชุงุจ ุดุงูู ุตุฏ ุฎุงุทุฑูโ ฺฉูุชุงู ู ุดุฑู ุงูุฒ ุดูุฏุง/ุฌุงูุจุงุฒุงู ฺฏุฑุงููุฏุฑุณ ฺฉู ุฎู ุณุงุฏู ู ุดฺฉ ู ุจู ุฏู ููุดู ุจุงู ุดุฏู ุข ุจุดุชุฑุดู ุฏุณุช ูุงู  ุทูุฒ ุฏุงุฑูุฏ ๐\n",
            "ุงูุตุงูุง ูพุดููุงุฏ ูฺฉููู:)\n",
            "ุจูุดุงู ฺฏูุชู ุจูุฏูุฏ: ุดูุง ฺฉู ุฒุฏูุฏุ ุงฺฏู ูุงุณฺฉ ูุจูุฏุ ุงฺฏู ุฑูุฏุฎุงููโุงุ ฺุงูู  ุขุจ ุฏูุฑูุจุฑ ุจูุฏุ ุจูพุฑุฏ ุชู ุขุจ! ุดูุง ุชู ุขุจ ุจ ุงุซุฑ ูุดูุฏ.\n",
            "***\n",
            "ุตูุฑุชุดุ ุฏุณุชูุงุด ุชุง ุขุฑูุฌ ู ุฑู ูพุงูุงุด ุชุงูู ุฒุฏู ุจูุฏ. ุจุง ุขุจ ููุฑ ูุถู ฺฏุฑูุชู ุจูุฏ... \n",
            "_____________________\n",
            "ุงุฒ ุตุจุญ ูุฑฺ ุนุฑุงูู ุฒุฎู ุขูุฑุฏูุฏุ ุฏุงุฏู ุงู ุนูู ฺฉุฑุฏ. ุดุงฺฉ ุดุฏุ ฺฏูุช:\n",
            "ุจูุดุช ูุงุด ุฑู ุฎูุฏุชูู ุนูู ูฺฉูุฏุ ุฌููู ูุงุด ุฑู ูุฏู ุจู ููุ!  \n",
            "(ููุจุน: ฺฉุชุงุจ ูพุฒุดฺฉุงู)\n",
            "_____________________\n",
            "ฺฉุชุงุจ ุดุงูู ุตุฏ ุฎุงุทุฑูโ ฺฉูุชุงู ู ุดุฑู ุงูุฒ ุดูุฏุง/ุฌุงูุจุงุฒุงู ฺฏุฑุงููุฏุฑุณ ฺฉู ุฎู ุณุงุฏู ู ุดฺฉ ู ุจู ุฏู ููุดู ุจุงู ุดุฏู ุข ุจุดุชุฑุดู ุฏุณุช ูุงู  ุทูุฒ ุฏุงุฑูุฏ \n",
            "ุงูุตุงูุง ูพุดููุงุฏ ูฺฉููู:)\n",
            "ุจุง ุชุฑุฌูู ุง ุงูฺฉู...\n",
            "ุจุง ุชุฑุฌูู ุง ุงูฺฉู...\n",
            "ุฏุงุณุชุงูุฎูุจ ุจูุฏ\n",
            "ุฏุงุณุชุงูุฎูุจ ุจูุฏ\n",
            "ูฺฉุฑ ููฺฉุฑุฏู ุจู ุงู ุฒูุฏ ุชุฑุฌูู ุงุฎุฑู ุฑูุงู ููุฏุงูู ุฑู ุงุฒ ุทุงูฺู ุจุชููู ุจุฎููู\n",
            "ูุถุง ุฏุงุณุชุงู ูุซู ุจูู ููุดุชู ูุง ููุฏุงูู ููู ุงูุนุงุฏุณุช\n",
            "ูฺฉุฑ ููฺฉุฑุฏู ุจู ุงู ุฒูุฏ ุชุฑุฌูู ุงุฎุฑู ุฑูุงู ููุฏุงูู ุฑู ุงุฒ ุทุงูฺู ุจุชููู ุจุฎููู\n",
            "ูุถุง ุฏุงุณุชุงู ูุซู ุจูู ููุดุชู ูุง ููุฏุงูู ููู ุงูุนุงุฏุณุช\n",
            "ูู ุงุตูุง ุฏูุณุด ูุฏุงุดุชู !! ููุถูุนุด ุฎุงุต ูุจูุฏ ุฏููุง ุฌุงุฒู ุฑู ุจ ฺฉุฌุงุด ุฏุงุฏูุุุุ\n",
            "ูู ุงุตูุง ุฏูุณุด ูุฏุงุดุชู !! ููุถูุนุด ุฎุงุต ูุจูุฏ ุฏููุง ุฌุงุฒู ุฑู ุจ ฺฉุฌุงุด ุฏุงุฏูุุุุ\n",
            "ุงู ููุงุดูุงูู ฺุฌูุฑ ุงู ููู ุฌุงุฒู ุฏุงุดุชุ ุฎู ูุนููู ุจูุฏ.\n",
            "ูู ูุชู ฺฉุดุด ุฏุงุดุช\n",
            "ุงู ููุงุดูุงูู ฺุฌูุฑ ุงู ููู ุฌุงุฒู ุฏุงุดุชุ ุฎู ูุนููู ุจูุฏ.\n",
            "ูู ูุชู ฺฉุดุด ุฏุงุดุช\n",
            "ุชุฎูู 10 ุฏุฑุตุฏ:\n",
            "SB9866ZC7FKYV5\n",
            "ุชุฎูู 10 ุฏุฑุตุฏ:\n",
            "SB9866ZC7FKYV5\n",
            "ูุบูู ูุง ุจุฎุด ุงุฒ ุชุงุฑุฎ ุฌูุงู  ู ุชุงุฑุฎ ุงุฑุงู ุฏุฑ ูุฑู ููุชู ูุฌุฑ ูุณุชูุฏ ฺฉู ุชุฃุซุฑ ุงุช ุขููุง ุจุฑ ุชุงุฑุฎ ุงุฑุงู ุฏุงุฑุง ุชูุงุณุฑ ฺูุฏฺฏุงูู ุง ุงุณุช.\n",
            "ุขููุง ุงุฒ ฺฉ ุทุฑู ุฏุฑ ุฒูุงู ุฎูุงุฑุฒูุดุงูุงู  ุจู ุฎุงุทุฑ ุชุญุฑฺฉ ุขููุง  ุจู ุฎุงฺฉ ุงุฑุงู ูุฌูู ุขูุฑุฏู ู ููุงุทู ุดุฑู ุงุฑุงู ุฑุง  ูุฑุงู ุณุงุฎุชูุฏ. ุงูุง ุงุฒ ุณู ุฏฺฏุฑ ุชุญุช ุชุงุซุฑ ูุฒุฑุง ุงูุฏุดููุฏ ุงุฑุงู ุฎูุฏ  ูุณููุงู ุดุฏู ู ุจุงุนุซ ุฎุฏูุงุช ูุฑููฺฏ ุงุฑุฒุดููุฏ ุฏุฑ ุงุฑุงู ุดุฏูุฏ.\n",
            "ุงุฒ ูุจุงุญุซ ุจุณุงุฑ ููู ู ุงุณุงุณ ุฏุฑ ุชุงุฑุฎ ู ูุฑููฺฏ ูุบูู  ูุง ุฏุฑ ุชูุฏู ุงุณูุงู ุ ุจุฑุงูุฏุงุฒ ุฎูุงูุช ุนุธู ุนุจุงุณ ู ูพุงุงู ุฏุงุฏู ุจู ุนุตุฑ ุดุจ ูุง ยซ ูุฒุงุฑ ู ฺฉุดุจ ยป ุฏุฑ ุดูุฑ ุงูุณุงูู ุง ุจุบุฏุงุฏ ุงุณุช. ุงฺฏุฑฺู  ุฏุงุณุชุงู ูุง ูุฒุงุฑ ู ฺฉุดุจ ูุฑุจูุท ุจู ุนุตุฑ ูุงุฑูู ุงูุฑุดุฏ ุงุณุช.\n",
            "\n",
            "ุฏุฑ ุจุงุฑู ุชุงุฑุฎ ูุบูู ุง ุงูุฎุงูุงู ฺฉุชุงุจูุง ุงุฑุฒุดููุฏ ุฒุงุฏ ููุดุชู ุดุฏู ุง ุชุญููุงุช ูุฑุงูุงู ุตูุฑุช ฺฏุฑูุชู ุงุณุช.\n",
            "ุงุฒ ููุงุจุน ุงุฑุฒุดููุฏ ุฏุฑ ุงู ุจุงุฑู ูุชูุงู ุจู ุขุซุงุฑ ุงุฑุฒุดููุฏ ุฒุฑ ุงุดุงุฑู ฺฉุฑุฏ:\n",
            "ุฑูู ฺฏุฑูุณู : ุงููพุฑุงุทูุฑ ุตุญุฑุงููุฑุฏุงู\n",
            "ุงูุจุงู ุขุดุชุงู : ุชุงุฑุฎ ูุบูู \n",
            "ุจุงุฑุชูุฏ : ุงููพุฑุงุทูุฑ ูุบูู ู ุญฺฉููุช ุฌุบุชุง\n",
            "ูุงุฎู ุจุงุฑฺฉูุงูุฒู : ุงููพุฑุงุทูุฑ ุฒุฑุฏ\n",
            "ุฎุงูู ุดุฑู ุจุงู : ูุธุงู ุงุฌุชูุงุน ูุบูู \n",
            "ุดุฑฺฉ ุงูู : ุงุตุทูุงุญุงุช ุฏูุงู ุนุตุฑ ูุบูู\n",
            "ูพุฑููุณูุฑ ุงุดูพููุฑ : ุชุงุฑุฎ ูุบูู ( ฺฉุชุงุจ ุญุงุถุฑ )\n",
            "\n",
            "ูพุฑููุณูุฑ ุงุดูพููุฑ ุฏุฑ ุงู ฺฉุชุงุจ ูุงููุฏ ฺฉุชุงุจ  ุงุฑุฒุดููุฏ ยซ ุงุฑุงู ุฏุฑ ูุฑูู ูุฎุณุชู ุงุณูุงู ยป ุจุง ุฏูุช ู ุฑูุญู ุนูู  ู ุฑูุด ุดูุงุณ ุชุงุฑุฎ ุจู ุจุฑุขูุฏู ูุบูู ุฏุฑ ุงุฑุงู ุ ุฌุงฺฏุงู ู ุณุฑุฒูู ุ ูฺุงุฏ  ู ูุงูุช ุชุงุฑุฎ  ุขูุงู ุฏุฑ ุชุงุฑุฎ ูุดุฑู ุฒูู ุฎุงุตู ุดุฑู ูุฒุฏฺฉ ู ุดูุงู ุบุฑุจ ฺฉุดูุฑ ฺู ู ุฌููุจ ุงุณุชูพ ูุง  ุณุจุฑ  ูพุฑุฏุงุฎุชู  ู ุฌุงฺฏุงู ุชุงุฑุฎ ุขูุงู ุฑุง ููุฑุฏ ุจุฑุฑุณ ูุฑุงุฑ ุฏุงุฏู ุงุณุช.\n",
            "ุจุฏูู ุชุฑุฏุฏ ฺฉุชุงุจ ุญุงุถุฑ ฺฉุชุงุจ ุงุฑุฒุดููุฏ ุงุณุช .\n",
            "\n",
            "ููุช ููุฑ\n",
            "ูุบูู ูุง ุจุฎุด ุงุฒ ุชุงุฑุฎ ุฌูุงู  ู ุชุงุฑุฎ ุงุฑุงู ุฏุฑ ูุฑู ููุชู ูุฌุฑ ูุณุชูุฏ ฺฉู ุชุฃุซุฑ ุงุช ุขููุง ุจุฑ ุชุงุฑุฎ ุงุฑุงู ุฏุงุฑุง ุชูุงุณุฑ ฺูุฏฺฏุงูู ุง ุงุณุช.\n",
            "ุขููุง ุงุฒ ฺฉ ุทุฑู ุฏุฑ ุฒูุงู ุฎูุงุฑุฒูุดุงูุงู  ุจู ุฎุงุทุฑ ุชุญุฑฺฉ ุขููุง  ุจู ุฎุงฺฉ ุงุฑุงู ูุฌูู ุขูุฑุฏู ู ููุงุทู ุดุฑู ุงุฑุงู ุฑุง  ูุฑุงู ุณุงุฎุชูุฏ. ุงูุง ุงุฒ ุณู ุฏฺฏุฑ ุชุญุช ุชุงุซุฑ ูุฒุฑุง ุงูุฏุดููุฏ ุงุฑุงู ุฎูุฏ  ูุณููุงู ุดุฏู ู ุจุงุนุซ ุฎุฏูุงุช ูุฑููฺฏ ุงุฑุฒุดููุฏ ุฏุฑ ุงุฑุงู ุดุฏูุฏ.\n",
            "ุงุฒ ูุจุงุญุซ ุจุณุงุฑ ููู ู ุงุณุงุณ ุฏุฑ ุชุงุฑุฎ ู ูุฑููฺฏ ูุบูู  ูุง ุฏุฑ ุชูุฏู ุงุณูุงู ุ ุจุฑุงูุฏุงุฒ ุฎูุงูุช ุนุธู ุนุจุงุณ ู ูพุงุงู ุฏุงุฏู ุจู ุนุตุฑ ุดุจ ูุง ยซ ูุฒุงุฑ ู ฺฉุดุจ ยป ุฏุฑ ุดูุฑ ุงูุณุงูู ุง ุจุบุฏุงุฏ ุงุณุช. ุงฺฏุฑฺู  ุฏุงุณุชุงู ูุง ูุฒุงุฑ ู ฺฉุดุจ ูุฑุจูุท ุจู ุนุตุฑ ูุงุฑูู ุงูุฑุดุฏ ุงุณุช.\n",
            "\n",
            "ุฏุฑ ุจุงุฑู ุชุงุฑุฎ ูุบูู ุง ุงูุฎุงูุงู ฺฉุชุงุจูุง ุงุฑุฒุดููุฏ ุฒุงุฏ ููุดุชู ุดุฏู ุง ุชุญููุงุช ูุฑุงูุงู ุตูุฑุช ฺฏุฑูุชู ุงุณุช.\n",
            "ุงุฒ ููุงุจุน ุงุฑุฒุดููุฏ ุฏุฑ ุงู ุจุงุฑู ูุชูุงู ุจู ุขุซุงุฑ ุงุฑุฒุดููุฏ ุฒุฑ ุงุดุงุฑู ฺฉุฑุฏ:\n",
            "ุฑูู ฺฏุฑูุณู : ุงููพุฑุงุทูุฑ ุตุญุฑุงููุฑุฏุงู\n",
            "ุงูุจุงู ุขุดุชุงู : ุชุงุฑุฎ ูุบูู \n",
            "ุจุงุฑุชูุฏ : ุงููพุฑุงุทูุฑ ูุบูู ู ุญฺฉููุช ุฌุบุชุง\n",
            "ูุงุฎู ุจุงุฑฺฉูุงูุฒู : ุงููพุฑุงุทูุฑ ุฒุฑุฏ\n",
            "ุฎุงูู ุดุฑู ุจุงู : ูุธุงู ุงุฌุชูุงุน ูุบูู \n",
            "ุดุฑฺฉ ุงูู : ุงุตุทูุงุญุงุช ุฏูุงู ุนุตุฑ ูุบูู\n",
            "ูพุฑููุณูุฑ ุงุดูพููุฑ : ุชุงุฑุฎ ูุบูู ( ฺฉุชุงุจ ุญุงุถุฑ )\n",
            "\n",
            "ูพุฑููุณูุฑ ุงุดูพููุฑ ุฏุฑ ุงู ฺฉุชุงุจ ูุงููุฏ ฺฉุชุงุจ  ุงุฑุฒุดููุฏ ยซ ุงุฑุงู ุฏุฑ ูุฑูู ูุฎุณุชู ุงุณูุงู ยป ุจุง ุฏูุช ู ุฑูุญู ุนูู  ู ุฑูุด ุดูุงุณ ุชุงุฑุฎ ุจู ุจุฑุขูุฏู ูุบูู ุฏุฑ ุงุฑุงู ุ ุฌุงฺฏุงู ู ุณุฑุฒูู ุ ูฺุงุฏ  ู ูุงูุช ุชุงุฑุฎ  ุขูุงู ุฏุฑ ุชุงุฑุฎ ูุดุฑู ุฒูู ุฎุงุตู ุดุฑู ูุฒุฏฺฉ ู ุดูุงู ุบุฑุจ ฺฉุดูุฑ ฺู ู ุฌููุจ ุงุณุชูพ ูุง  ุณุจุฑ  ูพุฑุฏุงุฎุชู  ู ุฌุงฺฏุงู ุชุงุฑุฎ ุขูุงู ุฑุง ููุฑุฏ ุจุฑุฑุณ ูุฑุงุฑ ุฏุงุฏู ุงุณุช.\n",
            "ุจุฏูู ุชุฑุฏุฏ ฺฉุชุงุจ ุญุงุถุฑ ฺฉุชุงุจ ุงุฑุฒุดููุฏ ุงุณุช .\n",
            "\n",
            "ููุช ููุฑ\n",
            "ุฑูุงู ุจุณุงุฑ ุฒุจุง ู ุดุงุนุฑุงูู ฺฉู ุจุงูฺฏุงู ุฎูุงูุงูู ุฌูฺฏ ู ุชุงุซุฑุงุช ุขู ุจุฑ ูุฑุฏู ุฑุง ุจู ุชุตูุฑ ฺฉุดุฏู ุงุณุช.\n",
            "\n",
            "...ู ฺูุฏุฑ ุฏูฺฏุฑ ุงุณุช ุดูุฑ ุจ ฺฉุจูุชุฑ.\n",
            "ุฑูุงู ุจุณุงุฑ ุฒุจุง ู ุดุงุนุฑุงูู ฺฉู ุจุงูฺฏุงู ุฎูุงูุงูู ุฌูฺฏ ู ุชุงุซุฑุงุช ุขู ุจุฑ ูุฑุฏู ุฑุง ุจู ุชุตูุฑ ฺฉุดุฏู ุงุณุช.\n",
            "\n",
            "...ู ฺูุฏุฑ ุฏูฺฏุฑ ุงุณุช ุดูุฑ ุจ ฺฉุจูุชุฑ.\n",
            "ูุงูุนุงู ฺฉุชุงุจ ุฌุงูุจู . ูู ู ุฎูุงุณุชู ุงุฒ ุชูุงู ฺฉุณุงู ฺฉู ุฏุฑ ุณุงุฎุช ุจุฑูุงูู ุทุงูฺู  ููุด ุฏุงุดุชู ุงูุฏ ุ ุตููุงูู ุชุดฺฉุฑ ฺฉูู . ุฌุฏุงู ุจุฑูุงูู ููู ุงูุนุงุฏู ุฌุงูุจู ู ููู ุชุฑ ุงุฒ ุขู ฺฉู ฺฏุงู ุจุฒุฑฺฏ ุฏุฑ ุฑุดุฏ ู ุชูุณุนู ุตูุนุช ฺฉุชุงุจ ู ฺฉุชุงุจุฎูุงู ุจุฑุฏุงุดุชู ุงุณุช .\n",
            "ูุงูุนุงู ฺฉุชุงุจ ุฌุงูุจู . ูู ู ุฎูุงุณุชู ุงุฒ ุชูุงู ฺฉุณุงู ฺฉู ุฏุฑ ุณุงุฎุช ุจุฑูุงูู ุทุงูฺู  ููุด ุฏุงุดุชู ุงูุฏ ุ ุตููุงูู ุชุดฺฉุฑ ฺฉูู . ุฌุฏุงู ุจุฑูุงูู ููู ุงูุนุงุฏู ุฌุงูุจู ู ููู ุชุฑ ุงุฒ ุขู ฺฉู ฺฏุงู ุจุฒุฑฺฏ ุฏุฑ ุฑุดุฏ ู ุชูุณุนู ุตูุนุช ฺฉุชุงุจ ู ฺฉุชุงุจุฎูุงู ุจุฑุฏุงุดุชู ุงุณุช .\n",
            "ฺฉ ุฎููุฏุดุ\n",
            "ุจฺฏุฏ ฺุฌูุฑู ุ\n",
            "ฺฉ ุฎููุฏุดุ\n",
            "ุจฺฏุฏ ฺุฌูุฑู ุ\n",
            "ุงุณู ฺฉุชุงุจ ุจุงูุฒู ุงุณ\n",
            "ุงุณู ฺฉุชุงุจ ุจุงูุฒู ุงุณ\n",
            "ฺู ฺฏุฑูููุุุุ๐๐๐\n",
            "ฺู ฺฏุฑูููุุุุ\n",
            "ูุดูฺฏู..\n",
            "ูุดูฺฏู..\n",
            "ุฏูุณุช ุฏุงุดุชู๐\n",
            "ุฏูุณุช ุฏุงุดุชู\n",
            "ูุงุฌูุงููุฑุฏุงูู ฺฏุฑููู\n",
            "ูุงุฌูุงููุฑุฏุงูู ฺฏุฑููู\n",
            "ูุฎูุงู ฺฉุชุงุจ ุฑู ุฏุฑุงูุช ฺฉูู ฺฉููู ุนุจูุฑ ูุฎูุงุฏ ูุณูุช ูพุฑุฏุงุฎุช ุงุฒ ฺฉุฌุง ุจุงุฏ ฺฉููู ุนุจูุฑ ุฑู ูพุฏุง ฺฉููุ\n",
            "ูุฎูุงู ฺฉุชุงุจ ุฑู ุฏุฑุงูุช ฺฉูู ฺฉููู ุนุจูุฑ ูุฎูุงุฏ ูุณูุช ูพุฑุฏุงุฎุช ุงุฒ ฺฉุฌุง ุจุงุฏ ฺฉููู ุนุจูุฑ ุฑู ูพุฏุง ฺฉููุ\n",
            "ููุช ู ฺุฒ ุงุฒ ุจฺฉุช ุฑู ุดุฑูุน ูฺฉู ุชููุน ูุฏุงุฑ ฺฉู ุฌุฒ ุดุงูฺฉุงุฑ ุจุง ฺุฒ ุฏฺฏู ุง ุทุฑู ุจุงุด!! ุฒูุฏู ุจูุฏ ูุฑูุชู ุจุบูุด ูฺฉุฑุฏู! \n",
            "ููุช ู ฺุฒ ุงุฒ ุจฺฉุช ุฑู ุดุฑูุน ูฺฉู ุชููุน ูุฏุงุฑ ฺฉู ุฌุฒ ุดุงูฺฉุงุฑ ุจุง ฺุฒ ุฏฺฏู ุง ุทุฑู ุจุงุด!! ุฒูุฏู ุจูุฏ ูุฑูุชู ุจุบูุด ูฺฉุฑุฏู! \n",
            "ุทุฑุญ ุฌูุฏุด ุนุงููุ ุญุช ูุดูฺฏโุชุฑ ุงุฒ ุฒุจุงู ุงุตูุด ุดุฏู\n",
            "ุทุฑุญ ุฌูุฏุด ุนุงููุ ุญุช ูุดูฺฏโุชุฑ ุงุฒ ุฒุจุงู ุงุตูุด ุดุฏู\n",
            "ุนุงู! ฺุฒ ุฏฺฏุฑ ููุดู ฺฏูุช\n",
            "ุนุงู! ฺุฒ ุฏฺฏุฑ ููุดู ฺฏูุช\n",
            "ูู ููููู ุดู ุฎููุฏู ฺฏุงู ูุซุฑ ุฎูุฏููู ูุดุฏ ู ูุญุงูุฑู .ุจุนุถ ุฌุงูุง ูุญุงูุฑู ู ฺฉุชุงุจ ๐ุงูฺฏุงุฑ ุงูุณุฌุงู ูุฏุงุดุช .ฺูุฏู ุจุฏ ููุธ ููุดุชู ุจูุฏูุฏ .ูุซูุง ุฑุงุฌุจ ุดููุฑุด .ุญุช ุงฺฏู ุงู ุงุฏู ูุงูุน ูุจุงุดู ูุจุงุฏ ุชูฺฉุชุงุจ ุงููุฏ ุฑุงุฌุจ ู ุงุฏู ฺฉู ุจุงูุงุด ุฒูุฏฺฏ ฺฉุฑุฏ ุจุฏ ุจฺฏ ูุงูู ุฑู ุฎูุจู ุญุช ุชู ุฏุงุณุชุงู ูพุฑุฏุงุฒ .ุฎูุจ ฺฉุชุงุจ ุงูฺฏู ูุดู ุจุฑุง ู ุนุฏู ุงุฏู ..ูุฎูุงุณุชู ฺฉุชุงุจู ุจุฎุฑู ุจุฎููู ูู ุชุฑุฌุญ ุฏุงุฏู.ูุฎููู\n",
            "ูู ููููู ุดู ุฎููุฏู ฺฏุงู ูุซุฑ ุฎูุฏููู ูุดุฏ ู ูุญุงูุฑู .ุจุนุถ ุฌุงูุง ูุญุงูุฑู ู ฺฉุชุงุจ ุงูฺฏุงุฑ ุงูุณุฌุงู ูุฏุงุดุช .ฺูุฏู ุจุฏ ููุธ ููุดุชู ุจูุฏูุฏ .ูุซูุง ุฑุงุฌุจ ุดููุฑุด .ุญุช ุงฺฏู ุงู ุงุฏู ูุงูุน ูุจุงุดู ูุจุงุฏ ุชูฺฉุชุงุจ ุงููุฏ ุฑุงุฌุจ ู ุงุฏู ฺฉู ุจุงูุงุด ุฒูุฏฺฏ ฺฉุฑุฏ ุจุฏ ุจฺฏ ูุงูู ุฑู ุฎูุจู ุญุช ุชู ุฏุงุณุชุงู ูพุฑุฏุงุฒ .ุฎูุจ ฺฉุชุงุจ ุงูฺฏู ูุดู ุจุฑุง ู ุนุฏู ุงุฏู ..ูุฎูุงุณุชู ฺฉุชุงุจู ุจุฎุฑู ุจุฎููู ูู ุชุฑุฌุญ ุฏุงุฏู.ูุฎููู\n",
            "ูู ููููู ุฑู ุฎููุฏูุ ุงุฒ ููุถูุนุด ุฎูุดู ุงููุฏ ู ุญุช ุงุฒ ููู ููุณูุฏูุ ูู ุจุฏุฒุจูู ุฑุงู ู ฺฉู ุงุฐุช ฺฉููุฏู ุณ.. ูุซู ุฑูุงูุง ุณุงุช 98ุงุณุช.. ูุชููุณุชู ุฑุงุถ ฺฉูู ุฎูุฏูู ฺฉู ุจุฎุฑูุด\n",
            "ูู ููููู ุฑู ุฎููุฏูุ ุงุฒ ููุถูุนุด ุฎูุดู ุงููุฏ ู ุญุช ุงุฒ ููู ููุณูุฏูุ ูู ุจุฏุฒุจูู ุฑุงู ู ฺฉู ุงุฐุช ฺฉููุฏู ุณ.. ูุซู ุฑูุงูุง ุณุงุช 98ุงุณุช.. ูุชููุณุชู ุฑุงุถ ฺฉูู ุฎูุฏูู ฺฉู ุจุฎุฑูุด\n",
            "ูุฒุฎุฑู ุชุฑู ฺฉุชุงุจ ุจูุฏ ฺฉู ุชุง ุญุงูุง ุฎููุฏู\n",
            "ููุท ฺฉ ุจู ูู ุจฺฏู ุงู ุฎุงููู ฺูุฏ ุชุง ุดููุฑ ุฏุงุดุช ู ุงู ุฏููููููุง ูุงู ฺฉุฏูู ุดููุฑุด ุจูุฏู\n",
            "ุจุฏุชุฑู ุชุตูุฑ ฺฉู ุงุฒ ฺฉ ุฒู ุงุฑุงู ู ุดุฏ ุจู ุชุตูุฑ ฺฉุดุฏ\n",
            "ูุฒุฎุฑู ุชุฑู ฺฉุชุงุจ ุจูุฏ ฺฉู ุชุง ุญุงูุง ุฎููุฏู\n",
            "ููุท ฺฉ ุจู ูู ุจฺฏู ุงู ุฎุงููู ฺูุฏ ุชุง ุดููุฑ ุฏุงุดุช ู ุงู ุฏููููููุง ูุงู ฺฉุฏูู ุดููุฑุด ุจูุฏู\n",
            "ุจุฏุชุฑู ุชุตูุฑ ฺฉู ุงุฒ ฺฉ ุฒู ุงุฑุงู ู ุดุฏ ุจู ุชุตูุฑ ฺฉุดุฏ\n",
            "ฺฏูุง ููุณูุฏู ฺฉุชุงุจุด ุฑุง ุจุฑ ุงุณุงุณ ุงุณุทูุฑู ุฒุฑ ูุงู ููุดุชู ุุฏุฑ ุฑูุงุช ุงุณุงุทุฑ ุฒุฑ ูุงู ุขูุฏู ุฒุฑ ูุงู ูุฒุงุฑ ุณุงู ูุฑุจุงู ฺฉุฑุฏ ู ุฏุฑ ุงูุชุธุงุฑ ูพุณุฑ ูุงูุฏ ุฒูุงู ุฏุฑุงุฒ ูุฑุจุงู ู ุงูุชุธุงุฑ ุทููุงู ุงู ุฑุง ุฏุฑ ุจุงุจ ุชุงุซุฑ ุงู (ฺฏูุงููุฏู)) ุณุงุฎุช ุฏุฑุณุช ุฏุฑ ููุงู ูุญุธู ฺฏูุงููุฏ ุฏู ููุฌูุฏ ุฏุฑ ุจุทู ุงู ุฌุงู ฺฏุฑูุช ูุฑูุฒุฏ ุจู ูพุงุณ ูุฑุจุงู ฺฉุฑุฏู ู ุงูุชุธุงุฑ ุงูุฑูู ุจู ุณุฒุง ฺฏูุงููุฏ ู ูุงุดฺฉุจุง ุฒุฑ ูุงู ูุณู ุงุฏฺฉุฑุฏ ฺฉู ุงฺฏุฑ ูุฑ ฺฉุฏุงู ุฒูุฏุชุฑ ูพุง ุจู ูุณุช ุจฺฏุฐุงุฑุฏ ูุฑูุงูุฑูุง ุฌูุงู ุฑุง ุจู ุงู ูุฏูุฏ ุงูุจุชู ุงูู ูุฑูุฒุฏ ุฑุง ู ุฎูุงุณุช ูุจุฑุง ุงู ูุฑุจุงู ฺฉุฑุฏู ุจูุฏ ู ู ูพูุฏุงุดุช ูุฑูุฒุฏ ุฒูุฏุชุฑ ุงุฒ ุจุทูุด ุจุฑูู ู ุขุฏ ูู ูุฑูุฒุฏ ฺูู ูฺฉ ุณุฑุดุช ุจูุฏ ุงู ุฑุง ุจุง ุจุฑุงุฏุฑุด ุฏุฑ ูุงู ฺฏุฐุงุดุช ู ุงูุฑูู ุฒุดุช ุฎู ุจุง ุชุฑููุฏ ุฒูุฏุชุฑ ุจุฑูู ุงูุฏ ู ุฒุฑูุงู ุดุงุฎู ุง ุจุฑุณู ุจู ูุฑูุฒุฏ ุฏุงุฏ ู ฺฏูุช ุชุง ุงูุงู ูู ุจุฑุง ุชู ูุฑุจุงู ฺฉุฑุฏู ุจุนุฏ ุงุฒ ุงู ุชู ุจุฑุง ูู ูุฑุจุงู ฺฉู ุงู ุดุฏ ุฌูฺฏ ุจู ูุฑูุฒุฏ ู ุงูุฑูู ุขุบุงุฒ ุดุฏ . ุจูุงุจุฑุงู ุฏุฑ ุงู ุจุงุณุชุงู ุฒุฑูุงู ุฑุง ุฎุงุณุชฺฏุงู ููู ฺุฒ ู ุฏุงูุณุชู ุงูุฏ ฺฉู ููู ฺุฒ ุงุฒ ุงู ุขุบุงุฒ ู ุดูุฏ ุฏุฑ ุญุงู ฺฉู ุฎูุฏ ุฎุงุณุชฺฏุงู ู ุขุบุงุฒ ูุฏุงุฑุฏ . ฺฉุชุงุจ ููุถูุน ุฌุงูุจ ุฏุงุดุช ุงูุจุชู ูฺฏุงุฑุด ุถุนู ุฏุงุดุช ุชฺฉู ฺฉูุงููุง ุฒุดุช ู ูุงูุฑุจูุท ฺุงูู ูุฏุงู ุดุฎุดุช ุฒู ฺฉุชุงุจ ุงุฑุฒุด ฺฉุชุงุจ ุฑู ูพุงู ุขูุฑุฏู ู ูู ุงุฑุฒุด ุงู ุงุณุทูุฑู ูุฏู ุฑุง ู ุชูุงุณุจ ุจุง ูู ูุฏุงุฑูุฏ.ุงุฒ ููุณูุฏู ูุง ุฎุงูู ุจุด ุงุฒ ุงู ุงูุชุธุงุฑ ูู ุฑูุฏ\n",
            "ฺฏูุง ููุณูุฏู ฺฉุชุงุจุด ุฑุง ุจุฑ ุงุณุงุณ ุงุณุทูุฑู ุฒุฑ ูุงู ููุดุชู ุุฏุฑ ุฑูุงุช ุงุณุงุทุฑ ุฒุฑ ูุงู ุขูุฏู ุฒุฑ ูุงู ูุฒุงุฑ ุณุงู ูุฑุจุงู ฺฉุฑุฏ ู ุฏุฑ ุงูุชุธุงุฑ ูพุณุฑ ูุงูุฏ ุฒูุงู ุฏุฑุงุฒ ูุฑุจุงู ู ุงูุชุธุงุฑ ุทููุงู ุงู ุฑุง ุฏุฑ ุจุงุจ ุชุงุซุฑ ุงู (ฺฏูุงููุฏู)) ุณุงุฎุช ุฏุฑุณุช ุฏุฑ ููุงู ูุญุธู ฺฏูุงููุฏ ุฏู ููุฌูุฏ ุฏุฑ ุจุทู ุงู ุฌุงู ฺฏุฑูุช ูุฑูุฒุฏ ุจู ูพุงุณ ูุฑุจุงู ฺฉุฑุฏู ู ุงูุชุธุงุฑ ุงูุฑูู ุจู ุณุฒุง ฺฏูุงููุฏ ู ูุงุดฺฉุจุง ุฒุฑ ูุงู ูุณู ุงุฏฺฉุฑุฏ ฺฉู ุงฺฏุฑ ูุฑ ฺฉุฏุงู ุฒูุฏุชุฑ ูพุง ุจู ูุณุช ุจฺฏุฐุงุฑุฏ ูุฑูุงูุฑูุง ุฌูุงู ุฑุง ุจู ุงู ูุฏูุฏ ุงูุจุชู ุงูู ูุฑูุฒุฏ ุฑุง ู ุฎูุงุณุช ูุจุฑุง ุงู ูุฑุจุงู ฺฉุฑุฏู ุจูุฏ ู ู ูพูุฏุงุดุช ูุฑูุฒุฏ ุฒูุฏุชุฑ ุงุฒ ุจุทูุด ุจุฑูู ู ุขุฏ ูู ูุฑูุฒุฏ ฺูู ูฺฉ ุณุฑุดุช ุจูุฏ ุงู ุฑุง ุจุง ุจุฑุงุฏุฑุด ุฏุฑ ูุงู ฺฏุฐุงุดุช ู ุงูุฑูู ุฒุดุช ุฎู ุจุง ุชุฑููุฏ ุฒูุฏุชุฑ ุจุฑูู ุงูุฏ ู ุฒุฑูุงู ุดุงุฎู ุง ุจุฑุณู ุจู ูุฑูุฒุฏ ุฏุงุฏ ู ฺฏูุช ุชุง ุงูุงู ูู ุจุฑุง ุชู ูุฑุจุงู ฺฉุฑุฏู ุจุนุฏ ุงุฒ ุงู ุชู ุจุฑุง ูู ูุฑุจุงู ฺฉู ุงู ุดุฏ ุฌูฺฏ ุจู ูุฑูุฒุฏ ู ุงูุฑูู ุขุบุงุฒ ุดุฏ . ุจูุงุจุฑุงู ุฏุฑ ุงู ุจุงุณุชุงู ุฒุฑูุงู ุฑุง ุฎุงุณุชฺฏุงู ููู ฺุฒ ู ุฏุงูุณุชู ุงูุฏ ฺฉู ููู ฺุฒ ุงุฒ ุงู ุขุบุงุฒ ู ุดูุฏ ุฏุฑ ุญุงู ฺฉู ุฎูุฏ ุฎุงุณุชฺฏุงู ู ุขุบุงุฒ ูุฏุงุฑุฏ . ฺฉุชุงุจ ููุถูุน ุฌุงูุจ ุฏุงุดุช ุงูุจุชู ูฺฏุงุฑุด ุถุนู ุฏุงุดุช ุชฺฉู ฺฉูุงููุง ุฒุดุช ู ูุงูุฑุจูุท ฺุงูู ูุฏุงู ุดุฎุดุช ุฒู ฺฉุชุงุจ ุงุฑุฒุด ฺฉุชุงุจ ุฑู ูพุงู ุขูุฑุฏู ู ูู ุงุฑุฒุด ุงู ุงุณุทูุฑู ูุฏู ุฑุง ู ุชูุงุณุจ ุจุง ูู ูุฏุงุฑูุฏ.ุงุฒ ููุณูุฏู ูุง ุฎุงูู ุจุด ุงุฒ ุงู ุงูุชุธุงุฑ ูู ุฑูุฏ\n",
            "ูููุฒ ูุฎููุฏู ุจู ูุธุฑู ุฎู ูุดูฺฏู ุฎูุงุตุดู ุฎููุฏู๐\n",
            "ูููุฒ ูุฎููุฏู ุจู ูุธุฑู ุฎู ูุดูฺฏู ุฎูุงุตุดู ุฎููุฏู\n",
            "ูุดูฺฏฺฏฺฏฺฏ ุจูุฏ\n",
            "ูุดูฺฏฺฏฺฏฺฏ ุจูุฏ\n",
            "ูู ูููุฒ ูุฎููุฏู ูู ูููุฌูุฑุด ุงุฒ ุงุณู ุฏุงุณุชุงู ูุนูููู ุฒุจุงุณุช\n",
            "ูู ูููุฒ ูุฎููุฏู ูู ูููุฌูุฑุด ุงุฒ ุงุณู ุฏุงุณุชุงู ูุนูููู ุฒุจุงุณุช\n",
            "ุจุงุณูุงู ฺฉุชุงุจ ุฎู ุฒุจุง ุจูุฏ ูุงูุนุง ุฌุฐุงุจ ูฺฏุฑุงุฺฏุงู ฺฏุฌ ฺฉููุฏู ูุดุฏูู ุจุงุฒูู ุฌุฐุงุจุชุด ุฑุงุฏุงุดุชุุชุดฺฉุฑุงุฒููุณูุฏู ฺฏุฑุงู\n",
            "ุจุงุณูุงู ฺฉุชุงุจ ุฎู ุฒุจุง ุจูุฏ ูุงูุนุง ุฌุฐุงุจ ูฺฏุฑุงุฺฏุงู ฺฏุฌ ฺฉููุฏู ูุดุฏูู ุจุงุฒูู ุฌุฐุงุจุชุด ุฑุงุฏุงุดุชุุชุดฺฉุฑุงุฒููุณูุฏู ฺฏุฑุงู\n",
            "ุงู ฺฉุชุงุจ ููู ุงูุนุงุฏู ุ ุจู ูุฏุฑ ุฑูุงู ู ุฒุจุงุณุช ฺฉู ุชุง ุชูููุด ุฑู ูุฎููุฏ ุงูู ุฑู ุฒูู ููุฒุงุฑุฏ.\n",
            "ุงู ฺฉุชุงุจ ููู ุงูุนุงุฏู ุ ุจู ูุฏุฑ ุฑูุงู ู ุฒุจุงุณุช ฺฉู ุชุง ุชูููุด ุฑู ูุฎููุฏ ุงูู ุฑู ุฒูู ููุฒุงุฑุฏ.\n",
            "ุณูพุงุณ ุงุฒ ุฎุงูู ุฎุฑู ุจุฑุง ูฺฏุงุดุชู ุงู ฺฉุชุงุจ. ุงุฒ ุฎููุฏูุด ูุฐุช ุจุฑุฏู. ฺฉุงุฑ ุฒุจุง ุจูุฏ. \n",
            "ุณูพุงุณ ุงุฒ ุฎุงูู ุฎุฑู ุจุฑุง ูฺฏุงุดุชู ุงู ฺฉุชุงุจ. ุงุฒ ุฎููุฏูุด ูุฐุช ุจุฑุฏู. ฺฉุงุฑ ุฒุจุง ุจูุฏ. \n",
            "ุณูุงู ุฏูุณุชุงู ุนุฒุฒ\n",
            "ุงูุชุดุงุฑุงุช ุขูุฑูฺฏุงู(ูุงุดุฑ ุชุฎุตุต ฺฉูุฏฺฉ ู ููุฌูุงู) ู ุงูุชุดุงุฑุงุช ููุง(ูุงุดุฑ ุชุฎุตุต ุฏุงุณุชุงู ู ุงุฏุจุงุช) ุงุฒุฑ ูุฌููุนูโูุง ุงูุชุดุงุฑุงุช ููููุณ ูุณุชูุฏ ฺฉู ุงููุฑ ูุจู ุงุฒ ฺุงูพ ู ุชูุฒุน ุขู ุฏุฑ ฺฏุฑูู ุงูุชุดุงุฑุงุช ููููุณ ุตูุฑุช ูโฺฏุฑุฏ.\n",
            "ุณูุงู ุฏูุณุชุงู ุนุฒุฒ\n",
            "ุงูุชุดุงุฑุงุช ุขูุฑูฺฏุงู(ูุงุดุฑ ุชุฎุตุต ฺฉูุฏฺฉ ู ููุฌูุงู) ู ุงูุชุดุงุฑุงุช ููุง(ูุงุดุฑ ุชุฎุตุต ุฏุงุณุชุงู ู ุงุฏุจุงุช) ุงุฒุฑ ูุฌููุนูโูุง ุงูุชุดุงุฑุงุช ููููุณ ูุณุชูุฏ ฺฉู ุงููุฑ ูุจู ุงุฒ ฺุงูพ ู ุชูุฒุน ุขู ุฏุฑ ฺฏุฑูู ุงูุชุดุงุฑุงุช ููููุณ ุตูุฑุช ูโฺฏุฑุฏ.\n",
            "ุฏูุณุช ุนุฒุฒ ุงูุชุดุงุฑุงุช ุขูุฑูฺฏุงู ู ุงูุชุดุงุฑุงุช ููุง ุฒุฑ ูุฌููุนู ุงูุชุดุงุฑุช ููููุณ ูุณุชูุฏ\n",
            "ุชู ุตูุญู ุฏุฑุจุงุฑู ูุง ูุจุณุงุช ููููุณ ูู ุงูู ุชูุถุญ ุฏุงุฏู\n",
            "ุฏูุณุช ุนุฒุฒ ุงูุชุดุงุฑุงุช ุขูุฑูฺฏุงู ู ุงูุชุดุงุฑุงุช ููุง ุฒุฑ ูุฌููุนู ุงูุชุดุงุฑุช ููููุณ ูุณุชูุฏ\n",
            "ุชู ุตูุญู ุฏุฑุจุงุฑู ูุง ูุจุณุงุช ููููุณ ูู ุงูู ุชูุถุญ ุฏุงุฏู\n",
            "ููุท ูุทููุฏ ุงู ฺฉุชุงุจ ูุงู ููููุณ ุ\n",
            "ุฑู ุฌูุฏุด ฺฉู ุฒุฏู ููุง !!!\n",
            "ุชู ุณุงุช ููููุณู ูุณุช ุงุตูุง...\n",
            "ููุท ูุทููุฏ ุงู ฺฉุชุงุจ ูุงู ููููุณ ุ\n",
            "ุฑู ุฌูุฏุด ฺฉู ุฒุฏู ููุง !!!\n",
            "ุชู ุณุงุช ููููุณู ูุณุช ุงุตูุง...\n",
            "ุนุงู\n",
            "๐๐๐ท๐ท๐๐๐น๐น\n",
            "ุนุงู\n",
            "\n",
            "ฺฉุงุด ุทุงูฺู ุงูฺฉุงู ูุฏู ุฏุงุฏู ฺฉุชุงุจ ุฑู ุงุถุงูู ูโฺฉุฑุฏ ฺูู ุงููู ฺุฒ ฺฉู ุจุนุฏ ุงุฒ ุฎููุฏู ุงู ฺฉุชุงุจ ุจู ุฐููู ูโุฑุณุฏ ุงู ุจูุฏ ฺฉู ุจู ฺูุฏ ููุฑ ุญุชูุง ูุฏู ุจุฏูุด. ุนุงู ุจูุฏ. ุงูุฏูุงุฑู ุงุฒ ุงู ููุณูุฏู ุจุงุฒ ูู ฺฉุชุงุจ ุฑู ุทุงูฺู ูุฑุงุฑ ุจุฏุฏ.\n",
            "ฺฉุงุด ุทุงูฺู ุงูฺฉุงู ูุฏู ุฏุงุฏู ฺฉุชุงุจ ุฑู ุงุถุงูู ูโฺฉุฑุฏ ฺูู ุงููู ฺุฒ ฺฉู ุจุนุฏ ุงุฒ ุฎููุฏู ุงู ฺฉุชุงุจ ุจู ุฐููู ูโุฑุณุฏ ุงู ุจูุฏ ฺฉู ุจู ฺูุฏ ููุฑ ุญุชูุง ูุฏู ุจุฏูุด. ุนุงู ุจูุฏ. ุงูุฏูุงุฑู ุงุฒ ุงู ููุณูุฏู ุจุงุฒ ูู ฺฉุชุงุจ ุฑู ุทุงูฺู ูุฑุงุฑ ุจุฏุฏ.\n",
            "ฺฉุชุงุจ ุฌุงูุจู . ูู ฺฉู ุฎูุดู ุงููุฏ .\n",
            "ฺฉุชุงุจ ุฌุงูุจู . ูู ฺฉู ุฎูุดู ุงููุฏ .\n",
            "ฺู ุฌุงูุจ.... ูุงููุงูู  ูุฌูู ฺฉู ุฏูุจุงูุด ูฺฉูู ุฑูุฒ ุชููุฏ ููู ุจูุฏู! ุฏุฑ ููุฑุฏ ฺฺฏููฺฏ ุชุดฺฉู ูุงู ู ุฎูุฑุดุฏู...ุฏุฑ ููุฑุฏ ุณูุฑ ู ุณููู ุจู ุฎูุฑุดุฏ!\n",
            "ุงูููููุน ูุฏููุณุชู ู ุฑูุฒ ุฑู ุฌูุฏุดูู ูุฒูู ุงูฺฉุงู ุฏุงุฑุฏ ุฏุฑ ููุฑ ุงูุณูุงุฏูุณ ุณุงุฑู  ุฒุญู ุญุงุช ูุฌูุฏ ุฏุงุดุชู ุจุงุดุฏุ ุง ุงูฺฉู ุฌูุงููุง ููุงุฒ ูุชููู ูุงูุน ุจุงุดูุ ุง ุงูฺฉู ุฌูุงู ุฏุงุฑู ุจุง ุณุฑุนุช ุบุฑฺฉููุงุฎุช ููุจุณุท ูุดูุ ุงูููููุน ูุฌฺฉุฏูู ุงุฒ ุงููุง ูุฌูุฏ ูุฏุงุดุชู....\n",
            "ฺู ุฌุงูุจ.... ูุงููุงูู  ูุฌูู ฺฉู ุฏูุจุงูุด ูฺฉูู ุฑูุฒ ุชููุฏ ููู ุจูุฏู! ุฏุฑ ููุฑุฏ ฺฺฏููฺฏ ุชุดฺฉู ูุงู ู ุฎูุฑุดุฏู...ุฏุฑ ููุฑุฏ ุณูุฑ ู ุณููู ุจู ุฎูุฑุดุฏ!\n",
            "ุงูููููุน ูุฏููุณุชู ู ุฑูุฒ ุฑู ุฌูุฏุดูู ูุฒูู ุงูฺฉุงู ุฏุงุฑุฏ ุฏุฑ ููุฑ ุงูุณูุงุฏูุณ ุณุงุฑู  ุฒุญู ุญุงุช ูุฌูุฏ ุฏุงุดุชู ุจุงุดุฏุ ุง ุงูฺฉู ุฌูุงููุง ููุงุฒ ูุชููู ูุงูุน ุจุงุดูุ ุง ุงูฺฉู ุฌูุงู ุฏุงุฑู ุจุง ุณุฑุนุช ุบุฑฺฉููุงุฎุช ููุจุณุท ูุดูุ ุงูููููุน ูุฌฺฉุฏูู ุงุฒ ุงููุง ูุฌูุฏ ูุฏุงุดุชู....\n",
            "ุจุณุงุฑ ุนุงู ุจูุฏ ุขูุง ูุงููุฑ ฺฉุณ ุจูุฏู ฺฉู ุฏุฑ ูุณุท ูุณุงุฏ ููุงุฒ ุชูุฌุฏ ุดูู ูุถุง ูู ุดุฏ ูู ูุงูุนุง ุงุฒ ุดุนุฑ ูุง ุงุดูู ูุฐุช ูุจุฑู\n",
            "ุจุณุงุฑ ุนุงู ุจูุฏ ุขูุง ูุงููุฑ ฺฉุณ ุจูุฏู ฺฉู ุฏุฑ ูุณุท ูุณุงุฏ ููุงุฒ ุชูุฌุฏ ุดูู ูุถุง ูู ุดุฏ ูู ูุงูุนุง ุงุฒ ุดุนุฑ ูุง ุงุดูู ูุฐุช ูุจุฑู\n",
            "ูู ุนุงุดู ุดุนุฑ ูุง ุงูุจุงู ูุงููุฑ ูุณุชู ุจุณุงุฑ ุนุงู ูุณุชุด\n",
            "ูู ุนุงุดู ุดุนุฑ ูุง ุงูุจุงู ูุงููุฑ ูุณุชู ุจุณุงุฑ ุนุงู ูุณุชุด\n",
            "...ุณูุงูู ุฑุง ู ุงู ุฌุงู ุฌู ฺฉุฑุฏ,,,ุฏุฑูู ูุทุฑู ุงู ูพูุดุฏู ู ฺฉุฑุฏ ุฎุฑุฏ ุงูุฏุฑ ุณุฑู ุจุชุฎุงูู ุง ุฑุฎุช,,,ุฎูู ุนุดู ุฏุฑู ุฑุง ุญุฑู ฺฉุฑุฏ. ุฏุฑูุฏ ุจฺฉุฑุงู ุจู ุฑูุญ ุจุง ุนุธูุช ุดุงุนุฑ ูุชูฺฉุฑ,ุญฺฉู ุขุฒุงุฏู..ุดุงุนุฑ ุงูุณุงูุช ููุนูุง ุนูุงูู ุงูุจุงู.\n",
            "...ุณูุงูู ุฑุง ู ุงู ุฌุงู ุฌู ฺฉุฑุฏ,,,ุฏุฑูู ูุทุฑู ุงู ูพูุดุฏู ู ฺฉุฑุฏ ุฎุฑุฏ ุงูุฏุฑ ุณุฑู ุจุชุฎุงูู ุง ุฑุฎุช,,,ุฎูู ุนุดู ุฏุฑู ุฑุง ุญุฑู ฺฉุฑุฏ. ุฏุฑูุฏ ุจฺฉุฑุงู ุจู ุฑูุญ ุจุง ุนุธูุช ุดุงุนุฑ ูุชูฺฉุฑ,ุญฺฉู ุขุฒุงุฏู..ุดุงุนุฑ ุงูุณุงูุช ููุนูุง ุนูุงูู ุงูุจุงู.\n",
            "ุณูุงู ูุนุฑุถ ุงุฏุจ\n",
            "ฺฉุชุงุจ ุจุณุงุฑ ุฒุจุง ูุญฺฉูุงูู.\n",
            "ุณูุงู ูุนุฑุถ ุงุฏุจ\n",
            "ฺฉุชุงุจ ุจุณุงุฑ ุฒุจุง ูุญฺฉูุงูู.\n",
            "ฺู ุดุนุฑูุง ุญฺฉูุงูู ุง ุฏุงุฑุฏ ุงู ุงูุจุงู ูุงููุฑ....\n",
            "ุงูุญู ฺฉู ุดุนุฑูุงุด ุขูู ุง ุงุฒ ุฐูู ูุชูฺฉุฑ ู ุญฺฉูุช ุงูุฏุด ุงู ูุณุช\n",
            "ููุช ุดุนุฑูุงุด ุฑุง ูุฎูุงู ฺฏู ุฏุฑ ฺฉูุงุณ ุญฺฉูุช ู ุชุงูู ูุดุณุชู ุง ู ฺู ูฺฉ ุขููุฒฺฏุงุฑ ุงุณุช ุงู ุงูุจุงู ูุงููุฑ.\n",
            "ฺู ุดุนุฑูุง ุญฺฉูุงูู ุง ุฏุงุฑุฏ ุงู ุงูุจุงู ูุงููุฑ....\n",
            "ุงูุญู ฺฉู ุดุนุฑูุงุด ุขูู ุง ุงุฒ ุฐูู ูุชูฺฉุฑ ู ุญฺฉูุช ุงูุฏุด ุงู ูุณุช\n",
            "ููุช ุดุนุฑูุงุด ุฑุง ูุฎูุงู ฺฏู ุฏุฑ ฺฉูุงุณ ุญฺฉูุช ู ุชุงูู ูุดุณุชู ุง ู ฺู ูฺฉ ุขููุฒฺฏุงุฑ ุงุณุช ุงู ุงูุจุงู ูุงููุฑ.\n",
            "ุง ูุธุฑ ุจุฑ ุญุณู ุชุฑุณุง ุฒุงุฏู ุง\n",
            "ุง ุฒ ุฑุงู ฺฉุนุจู ุฏูุฑ ุงูุชุงุฏู ุง \n",
            "ุทุฑุญ ุนุดู ุงูุฏุงุฒ ุงูุฏุฑ ุฌุงู ุฎูุด\n",
            "ุชุงุฒู ฺฉู ุจุง ูุตุทู ูพูุงู ุฎูุด\n",
            "\n",
            "ุจุณุงุฑ ุจุณุงุฑ ุนุงู.ุจุง ุชุดฺฉุฑ ุงุฒ ุทุงูฺู\n",
            "ุง ูุธุฑ ุจุฑ ุญุณู ุชุฑุณุง ุฒุงุฏู ุง\n",
            "ุง ุฒ ุฑุงู ฺฉุนุจู ุฏูุฑ ุงูุชุงุฏู ุง \n",
            "ุทุฑุญ ุนุดู ุงูุฏุงุฒ ุงูุฏุฑ ุฌุงู ุฎูุด\n",
            "ุชุงุฒู ฺฉู ุจุง ูุตุทู ูพูุงู ุฎูุด\n",
            "\n",
            "ุจุณุงุฑ ุจุณุงุฑ ุนุงู.ุจุง ุชุดฺฉุฑ ุงุฒ ุทุงูฺู\n",
            "ูุทุนุง ุงุดุนุงุฑ ุงูุจุงู ุงุฑุฒุด ูุฑูุฑ ุฑุง ุฏุงุฑูุฏุ ูุงูุนุง ุฌุง ุฏุงุฑุฏ ฺฉ ุงุฒ ุงู ุญุฑฺฉุช ุชุดฺฉุฑ ูฺู ุง ุดูุฏุ ุงูุดุงุกุงููู ฺฉ ุงุดุนุงุฑ ุจูู ูู ฺฉูฺฉู ุจ ุงู ุดูู ููุชุดุฑ ุดููุฏ.\n",
            "ูุทุนุง ุงุดุนุงุฑ ุงูุจุงู ุงุฑุฒุด ูุฑูุฑ ุฑุง ุฏุงุฑูุฏุ ูุงูุนุง ุฌุง ุฏุงุฑุฏ ฺฉ ุงุฒ ุงู ุญุฑฺฉุช ุชุดฺฉุฑ ูฺู ุง ุดูุฏุ ุงูุดุงุกุงููู ฺฉ ุงุดุนุงุฑ ุจูู ูู ฺฉูฺฉู ุจ ุงู ุดูู ููุชุดุฑ ุดููุฏ.\n",
            "ุงุณู ฺฉุชุงุจ ุฏููุง ุจุง ุญุงู ู ููุง ุฏุงุฎูุด ููุฎูุงู ุฏุงุฑู. ุฎููุฏู ุงู ูุตู ูุง ุจู ูุง ุงุฏุขูุฑ ูฺฉูู ุฏุฑ ุทูู ุชุงุฑุฎ ฺู ฺุฒุง ุจุฑุง ูุฑุฏู ูุง ุงุฑุฒุด ุจู ุญุณุงุจ ูููุฏู ู ูุฑุฏู ูุง ุฏุฑุณุช ู ุบูุท ุฑู ฺุทูุฑ ูุนู ูฺฉุฑุฏู. ูุตู ูุงุด ุจู ูุถูุญ ุนุงูุงูู ุงู ูู ุจุนุถ ููุชุง ุจู ุฎูุจ ุฎูุงููุฏู ุฑู ุฌุฐุจ ูฺฉูู ุทูุฑ ฺฉู ฺฏุฐุฑ ุฒูุงู ุฑู ููููู\n",
            "ุงุณู ฺฉุชุงุจ ุฏููุง ุจุง ุญุงู ู ููุง ุฏุงุฎูุด ููุฎูุงู ุฏุงุฑู. ุฎููุฏู ุงู ูุตู ูุง ุจู ูุง ุงุฏุขูุฑ ูฺฉูู ุฏุฑ ุทูู ุชุงุฑุฎ ฺู ฺุฒุง ุจุฑุง ูุฑุฏู ูุง ุงุฑุฒุด ุจู ุญุณุงุจ ูููุฏู ู ูุฑุฏู ูุง ุฏุฑุณุช ู ุบูุท ุฑู ฺุทูุฑ ูุนู ูฺฉุฑุฏู. ูุตู ูุงุด ุจู ูุถูุญ ุนุงูุงูู ุงู ูู ุจุนุถ ููุชุง ุจู ุฎูุจ ุฎูุงููุฏู ุฑู ุฌุฐุจ ูฺฉูู ุทูุฑ ฺฉู ฺฏุฐุฑ ุฒูุงู ุฑู ููููู\n",
            "ุฏุฑ ุฏุงุณุชุงู ุฏูู ุฌููู ุง ุฒุจุง ูุฌูุฏ ุฏุงุฑุฏ. ุุุงฺฏุฑ ุดูุฏุง ุจู ูพุด ุฎุฏุง ู ุฑููุฏ ฺุฑุง ูุงุฏุฑุดุงู ุจุฑุงุดุงู ฺฏุฑู ูฺฉููุฏุุ ุฌููู ุง ุจุณุงุฑ ุชุงูู ุจุฑุงูฺฏุฒ :-)\n",
            "ุฏุฑ ุฏุงุณุชุงู ุฏูู ุฌููู ุง ุฒุจุง ูุฌูุฏ ุฏุงุฑุฏ. ุุุงฺฏุฑ ุดูุฏุง ุจู ูพุด ุฎุฏุง ู ุฑููุฏ ฺุฑุง ูุงุฏุฑุดุงู ุจุฑุงุดุงู ฺฏุฑู ูฺฉููุฏุุ ุฌููู ุง ุจุณุงุฑ ุชุงูู ุจุฑุงูฺฏุฒ :-)\n",
            "ุจุงุณูุงู ุฏุงุณุชุงู ุฌุฐุงุจ ูุจุณุงุฑุฎูุงูุฏู ุจูุฏุุชูุตู ูฺฉูู ุญุชูุงุจุฎููุฏุด\n",
            "ุจุงุณูุงู ุฏุงุณุชุงู ุฌุฐุงุจ ูุจุณุงุฑุฎูุงูุฏู ุจูุฏุุชูุตู ูฺฉูู ุญุชูุงุจุฎููุฏุด\n",
            "100ุฎุงุทุฑู  ฺฉูุชุงู ุฏุฑุจุงุฑู  ุดูุฏ ุฏฺฉุชุฑ ูุตุทู ฺูุฑุงู...\n",
            "ุฎุงุทุฑุงุช ุจู ฺฏููู ุง ุงูุชุฎุงุจ ุดุฏู ฺฉู ููู ุฌูุฑ ุงุญุณุงุณ ุฑู ูุชููุฏ ุจุงูุงุดูู ุชุฌุฑุจู ฺฉูุฏ:ุนุดูุุงุญุณุงุณุุบูุุงูุฏููุูุจุฎูุฏ ู...\n",
            "ุฎููุฏูุด ุฑู ุจุนุฏ ุงุฒ ฺฉุชุงุจุฺูุฑุงู ุจู ุฑูุงุช ููุณุฑ ุดูุฏ ูพุดููุงุฏ ูฺฉูู๐\n",
            "ุจุณุงุฑ ูุฐุช ุจุฎุดู...\n",
            "100ุฎุงุทุฑู  ฺฉูุชุงู ุฏุฑุจุงุฑู  ุดูุฏ ุฏฺฉุชุฑ ูุตุทู ฺูุฑุงู...\n",
            "ุฎุงุทุฑุงุช ุจู ฺฏููู ุง ุงูุชุฎุงุจ ุดุฏู ฺฉู ููู ุฌูุฑ ุงุญุณุงุณ ุฑู ูุชููุฏ ุจุงูุงุดูู ุชุฌุฑุจู ฺฉูุฏ:ุนุดูุุงุญุณุงุณุุบูุุงูุฏููุูุจุฎูุฏ ู...\n",
            "ุฎููุฏูุด ุฑู ุจุนุฏ ุงุฒ ฺฉุชุงุจุฺูุฑุงู ุจู ุฑูุงุช ููุณุฑ ุดูุฏ ูพุดููุงุฏ ูฺฉูู\n",
            "ุจุณุงุฑ ูุฐุช ุจุฎุดู...\n",
            "ุงุฒ ุงูู ฺฉุชุงุจูุงู ฺฉู ุฏุฑ ุญู ูุฑูุฑ ุจุฑููโุง ุงุฒ ุชุงุฑุฎ ุฏูุงุน ููุฏุณ ุฏุฑ ุงุซูุง ุขู ุนุงุดูุงูู ุง ูู ุฏุฑุฌุฑุงููโ. ูุดูฺฏู .ุฒูุฏฺฏ ููุดู ุฌุฑุงู ุฏุงุฑู!\n",
            "ุงุฒ ุงูู ฺฉุชุงุจูุงู ฺฉู ุฏุฑ ุญู ูุฑูุฑ ุจุฑููโุง ุงุฒ ุชุงุฑุฎ ุฏูุงุน ููุฏุณ ุฏุฑ ุงุซูุง ุขู ุนุงุดูุงูู ุง ูู ุฏุฑุฌุฑุงููโ. ูุดูฺฏู .ุฒูุฏฺฏ ููุดู ุฌุฑุงู ุฏุงุฑู!\n",
            "ฺูุฏ ุณุงู ูพุด ุฎููุฏู ุจูุฏูุด.ฺฉ ุงุฒ ุงูู ฺฉุชุงุจูุง ูุณุช ฺฉู ุฏุฑ ุฎุงุทุฑู ููุงูุฏ.ุนุงู ุจูุฏ\n",
            "ฺูุฏ ุณุงู ูพุด ุฎููุฏู ุจูุฏูุด.ฺฉ ุงุฒ ุงูู ฺฉุชุงุจูุง ูุณุช ฺฉู ุฏุฑ ุฎุงุทุฑู ููุงูุฏ.ุนุงู ุจูุฏ\n",
            "ูู ุงูุฑูุฒ ุชูููุด ฺฉุฑุฏู ุฎู ุขุฎุฑุด ุบู ุงูฺฏุฒ ุจูุฏ ๐ญ๐ญ\n",
            "ูู ุงูุฑูุฒ ุชูููุด ฺฉุฑุฏู ุฎู ุขุฎุฑุด ุบู ุงูฺฏุฒ ุจูุฏ \n",
            "ูู ูุชูุฌู ูุดุฏู ุงุฎุฑุด\n",
            "ุฌุดูุด ฺฉ ุฎูุจ ุดุฏุ\n",
            "ุฏุงุณุชุงู ุจุง ฺุดูู ุดุฑูุน ุดุฏ ุงูุง ุจุนุฏ ูุญู ุดุฏุุุ\n",
            "ูุงุณู  ูุนูุง ุดุฏู ฺฉ ฺุดูู ฺ ุดุฏ ุจูุงุฎุฑูุุ\n",
            "ุฏุฑ ฺฉู ฺฉุชุงุจ ุฎู ูุดูฺฏ ุจูุฏ\n",
            "ุชูุตู ูฺฉูู ุจุฎูููุด\n",
            "ูู ูุชูุฌู ูุดุฏู ุงุฎุฑุด\n",
            "ุฌุดูุด ฺฉ ุฎูุจ ุดุฏุ\n",
            "ุฏุงุณุชุงู ุจุง ฺุดูู ุดุฑูุน ุดุฏ ุงูุง ุจุนุฏ ูุญู ุดุฏุุุ\n",
            "ูุงุณู  ูุนูุง ุดุฏู ฺฉ ฺุดูู ฺ ุดุฏ ุจูุงุฎุฑูุุ\n",
            "ุฏุฑ ฺฉู ฺฉุชุงุจ ุฎู ูุดูฺฏ ุจูุฏ\n",
            "ุชูุตู ูฺฉูู ุจุฎูููุด\n",
            "ฺฉุชุงุจ ุจุณุงุฑ ุฌุงูุจ ุงุณุช ู ูุฎููุท ุงุฒ ุฏูุงุน ููุฏุณ ู ุนุงุดูุงูู ุง ุฌุงูุจ ุจู ููุฑุงู  ุณุฎุช ูุง ูุณุฑ:\n",
            "ฺฉู ุนุดู ุงูู ูููุฏ ุขุณุงู ูู ุงูุชุงุฏ ูุดฺฉููุง\n",
            "ฺฉุชุงุจ ุจุณุงุฑ ุฌุงูุจ ุงุณุช ู ูุฎููุท ุงุฒ ุฏูุงุน ููุฏุณ ู ุนุงุดูุงูู ุง ุฌุงูุจ ุจู ููุฑุงู  ุณุฎุช ูุง ูุณุฑ:\n",
            "ฺฉู ุนุดู ุงูู ูููุฏ ุขุณุงู ูู ุงูุชุงุฏ ูุดฺฉููุง\n",
            "ฺฉ ุฏุงุณุชุงู ูุงูุน ู ุจู ุดุฏุช ุนุงุดูุงูู ุจุง ูพุงุงู ุจุณุงุฑ ุชุงูู ุจุฑุงูฺฏุฒ.\n",
            "ุฏุฑ ุฌุงูุง ุงุฒ ฺฉุชุงุจ ู ุฎูุงูู ฺฉู ฺฺฏููู ุฒูุฏุงู ู ุฒูุฏุงูุจุงู ุงุฒ ุฌูุง ุฑูุฒฺฏุงุฑุ  ุฏุณุช ุฏุฑ ฺฏุฑุฏู ูู ุงูุฏุงุฎุชู ู ฺฏุฑู ูฺฉููุฏุ ฺฉุณุงู ฺฉู ุฑูุฒ ุจู ุฎูู ูู ุชุดูู ุจูุฏูุฏุ ฺฺฏููู ุฏุฑ ุงุบูุด ฺฉุฏฺฏุฑ ฺฏุฑู ูฺฉููุฏ ู ุชููุง ฺฉ ฺุฒ ุฏุฑ ุงู ูุงู ูุงุถุญ ุงุณุช: \n",
            "ููุฑู ุจุฑ ุฌูฺฏ ู ุฏุฑฺฏุฑ ู ููุฑู ุจุฑ ูุฏุฑุช ุทูุจ ูุง ุณุงุณุ ฺฉู ฺฺฏููู ุงูุณุงููุง ุนุงุฏ ู ุจฺฏูุงู ุฑุง ุจู ุจุฏุจุฎุช ู ููุงฺฉุช ู ุฏุฑ ุจู ุฏุฑ ูฺฉุดุงูุฏ.\n",
            "ุงู ฺฉุชุงุจ ุจุณุงุฑ ุฑู ูู ุชุงุซุฑ ฺฏุฐุงุดุช. ุฎูุงูุฏูุด ุฑุง ุจู ูุฑ ุงูุณุงู ุญู ุทูุจ ู ฺุฑู ุงูุฏุด ุชูุตู ูฺฉูู.\n",
            "ฺฉ ุฏุงุณุชุงู ูุงูุน ู ุจู ุดุฏุช ุนุงุดูุงูู ุจุง ูพุงุงู ุจุณุงุฑ ุชุงูู ุจุฑุงูฺฏุฒ.\n",
            "ุฏุฑ ุฌุงูุง ุงุฒ ฺฉุชุงุจ ู ุฎูุงูู ฺฉู ฺฺฏููู ุฒูุฏุงู ู ุฒูุฏุงูุจุงู ุงุฒ ุฌูุง ุฑูุฒฺฏุงุฑุ  ุฏุณุช ุฏุฑ ฺฏุฑุฏู ูู ุงูุฏุงุฎุชู ู ฺฏุฑู ูฺฉููุฏุ ฺฉุณุงู ฺฉู ุฑูุฒ ุจู ุฎูู ูู ุชุดูู ุจูุฏูุฏุ ฺฺฏููู ุฏุฑ ุงุบูุด ฺฉุฏฺฏุฑ ฺฏุฑู ูฺฉููุฏ ู ุชููุง ฺฉ ฺุฒ ุฏุฑ ุงู ูุงู ูุงุถุญ ุงุณุช: \n",
            "ููุฑู ุจุฑ ุฌูฺฏ ู ุฏุฑฺฏุฑ ู ููุฑู ุจุฑ ูุฏุฑุช ุทูุจ ูุง ุณุงุณุ ฺฉู ฺฺฏููู ุงูุณุงููุง ุนุงุฏ ู ุจฺฏูุงู ุฑุง ุจู ุจุฏุจุฎุช ู ููุงฺฉุช ู ุฏุฑ ุจู ุฏุฑ ูฺฉุดุงูุฏ.\n",
            "ุงู ฺฉุชุงุจ ุจุณุงุฑ ุฑู ูู ุชุงุซุฑ ฺฏุฐุงุดุช. ุฎูุงูุฏูุด ุฑุง ุจู ูุฑ ุงูุณุงู ุญู ุทูุจ ู ฺุฑู ุงูุฏุด ุชูุตู ูฺฉูู.\n",
            "ุนุงูุุฏุงุณุชุงู ุฎู ุฎูุจุณ ุฏุงุฑู.ูู ูุณุฎู ฺุงูพ ุฑู ุฏูุณู ุณุงู ูพุด ุฎููุฏู\n",
            "ุนุงูุุฏุงุณุชุงู ุฎู ุฎูุจุณ ุฏุงุฑู.ูู ูุณุฎู ฺุงูพ ุฑู ุฏูุณู ุณุงู ูพุด ุฎููุฏู\n",
            "ุชููพ ุชููพ.ุงุตูุง ููุชููุณุชู ฺฉุชุงุจู ุจุฐุงุฑู ุฒูู.ู ูุงุฌุฑุง ุนุดู ุชู ุฏู ุงุณุงุฑุช.ุฏูุช ฺฏุฑู ฺฉุงููุด ุฌูู!\n",
            "ุขูุง ฺฏูุฒุงุฑ ุฑุงุบุจุุงูุงู ุฏุฏู ู ฺฉุชุงุจ ุฏฺฏู ูู ููุดุชุฏ.ุจุงุฒู ฺฉุชุงุจ ุจููุณู.\n",
            "ุชููพ ุชููพ.ุงุตูุง ููุชููุณุชู ฺฉุชุงุจู ุจุฐุงุฑู ุฒูู.ู ูุงุฌุฑุง ุนุดู ุชู ุฏู ุงุณุงุฑุช.ุฏูุช ฺฏุฑู ฺฉุงููุด ุฌูู!\n",
            "ุขูุง ฺฏูุฒุงุฑ ุฑุงุบุจุุงูุงู ุฏุฏู ู ฺฉุชุงุจ ุฏฺฏู ูู ููุดุชุฏ.ุจุงุฒู ฺฉุชุงุจ ุจููุณู.\n",
            "ุงู ฺฉุชุงุจ ุฒุจุงุณุช ุงุฑุฒุด ฺฉุชุงุจ ุฎููุฏูุด ุฑุง ุฏุงุฑุฏ\n",
            "ุงู ฺฉุชุงุจ ุฒุจุงุณุช ุงุฑุฒุด ฺฉุชุงุจ ุฎููุฏูุด ุฑุง ุฏุงุฑุฏ\n",
            "\"ูุฎูุงููุช ุฏุงุดุช ุชุง ูุฑุงููุดุช ูฺฉูู \" ุขุฎู ุงูู ุดุฏ ุญุฑู!\n",
            "\"ูุฎูุงููุช ุฏุงุดุช ุชุง ูุฑุงููุดุช ูฺฉูู \" ุขุฎู ุงูู ุดุฏ ุญุฑู!\n",
            "ุงู ฺฉุชุงุจ ุนุงููุ ุฏุงุณุชุงู ุงุณุงุฑุช ฺฉู ููุฌุฑ ุจู ุนุดู ุณูุฒูุฏู ู ูุงูุฑุฌุงู ูุดู. ุชูุตู ูุดูุฏ ุฎูุงูุฏุด\n",
            "ุงู ฺฉุชุงุจ ุนุงููุ ุฏุงุณุชุงู ุงุณุงุฑุช ฺฉู ููุฌุฑ ุจู ุนุดู ุณูุฒูุฏู ู ูุงูุฑุฌุงู ูุดู. ุชูุตู ูุดูุฏ ุฎูุงูุฏุด\n",
            "ูู ุฎู ูฺฏุฑุงู ุฒุฎู ฺุดู ฺฉุงููุด ุจูุฏูุูู ูฺ ุฑุงุฌุน ุจูุด ูฺฏูุชุฺฉ ุฏู ุชุง ุงุดุชุจุงู ูู ุฏุงุดุช ุูุซูุง ุญุณู ูุฑุงุฏ ุจุง ุจุฑุงุฏุฑุด ุดูุฏ ุดุฏู ุจูุฏ ูู ูฺฏู ูููุน ุขุฒุงุฏ ุงููุฏ ุงุณุชูุจุงูู ู....\n",
            "ูู ุฎู ูฺฏุฑุงู ุฒุฎู ฺุดู ฺฉุงููุด ุจูุฏูุูู ูฺ ุฑุงุฌุน ุจูุด ูฺฏูุชุฺฉ ุฏู ุชุง ุงุดุชุจุงู ูู ุฏุงุดุช ุูุซูุง ุญุณู ูุฑุงุฏ ุจุง ุจุฑุงุฏุฑุด ุดูุฏ ุดุฏู ุจูุฏ ูู ูฺฏู ูููุน ุขุฒุงุฏ ุงููุฏ ุงุณุชูุจุงูู ู....\n",
            "ุงู ฺูุ ุนุตุฑูุง ฺฉุฑุณฺฉุงู ฺูุ๐ฎ ู ุฎุงุทุฑู ุฏู ฺฉุชุงุจุ! ฺฉุณ ูุฑ ุฏู ุฑู ุฎููุฏูุ\n",
            "ุงู ฺูุ ุนุตุฑูุง ฺฉุฑุณฺฉุงู ฺูุ ู ุฎุงุทุฑู ุฏู ฺฉุชุงุจุ! ฺฉุณ ูุฑ ุฏู ุฑู ุฎููุฏูุ\n",
            "ุงู ฺฉุชุงุจ ุฑู ุจู ุฏูุณุชุงู ุชูุตู ูฺฉููุ ูุถุง ุนุงุดูุงูู ุชุฑฺฉุจ ุดุฏู ุจุง ุญุงู ููุง ุฌูฺฏ ู ุงุณุงุฑุช ุฏุฑ ุงู ุฏุงุณุชุงู ุฎู ุฌุฐุงุจ ู ุฒุจุงุณุช.\n",
            "ุงู ฺฉุชุงุจ ุฑู ุจู ุฏูุณุชุงู ุชูุตู ูฺฉููุ ูุถุง ุนุงุดูุงูู ุชุฑฺฉุจ ุดุฏู ุจุง ุญุงู ููุง ุฌูฺฏ ู ุงุณุงุฑุช ุฏุฑ ุงู ุฏุงุณุชุงู ุฎู ุฌุฐุงุจ ู ุฒุจุงุณุช.\n",
            "ุจูู ุขูุง ูุญุฏ\n",
            "ุชุงุฒู ุขุฏู ููููู ฺูุฏุฑ ููู ูุณุช ฺฉู ุจุงุฏ ุณุงุฎุชู ุจุดู... ุงูุจุชู ุจู ูุธุฑ ุญุถุฑุชุช ฺฉููุฏุงุฑ ฺุงูุด ููู ูุจูู ุง ุงุฌุงุฏ ููฺฉููุ\n",
            "ุจูู ุขูุง ูุญุฏ\n",
            "ุชุงุฒู ุขุฏู ููููู ฺูุฏุฑ ููู ูุณุช ฺฉู ุจุงุฏ ุณุงุฎุชู ุจุดู... ุงูุจุชู ุจู ูุธุฑ ุญุถุฑุชุช ฺฉููุฏุงุฑ ฺุงูุด ููู ูุจูู ุง ุงุฌุงุฏ ููฺฉููุ\n",
            "ูู ฺฉุชุงุจ ุฏุฑุจุงุฑู ุฌูฺฏ ุฎู ุฎููุฏูุ ุงูุง ุงูุตุงูุง ุงู ุฎู ุฎูุจ ู ุฎุงุต ุจูุฏ ู ุฎู ูู ุฌุง ุฏุงุฑู ุญุช ุชุจุฏู ุจ ููู ุจุดูุ\n",
            "ูู ฺฉุชุงุจ ุฏุฑุจุงุฑู ุฌูฺฏ ุฎู ุฎููุฏูุ ุงูุง ุงูุตุงูุง ุงู ุฎู ุฎูุจ ู ุฎุงุต ุจูุฏ ู ุฎู ูู ุฌุง ุฏุงุฑู ุญุช ุชุจุฏู ุจ ููู ุจุดูุ\n",
            "ุจูู ุขูุง ุงุจูุฐุฑ\n",
            "ูุงูุนุง ูููุทูุฑู\n",
            "ุจูู ุขูุง ุงุจูุฐุฑ\n",
            "ูุงูุนุง ูููุทูุฑู\n",
            "ุนุงูุูพุดููุงุฏ ูฺฉูู ุจุฎููู.\n",
            "ุนุงูุูพุดููุงุฏ ูฺฉูู ุจุฎููู.\n",
            "ุจุงุณูุงู\n",
            "ูุงูุนุง  ฺฉุชุงุจ ุฎูุจู\n",
            "ุจุงุณูุงู\n",
            "ูุงูุนุง  ฺฉุชุงุจ ุฎูุจู\n",
            "ูุงูุนุง ูุจู ุงุฒ ุฎููุฏู ฺฉุชุงุจ ูฺฉุฑ ููโฺฉุฑุฏู ุจุง ฺูู ุงุซุฑ ฺฏุฑุง ููุงุฌู ุจุดู. ุฏุงุณุชุงู ููุท ุฑูุงุช ุณุงุฏูโ ู ุฑุฒููุฏู ุงุฒ ุฏูุฑุงู ุฌุจูู ุง ุงุณุงุฑุช ูุณุช. ููุณูุฏู ุจุฏูู ูุถุงูุช ฺฉุฑุฏู ู ููุท ุจุง ุฐฺฉุฑ ุฎุฑุฏู ุฏุงุณุชุงูโูุง ูุงูุนุ ุฎูุงููุฏู ุฑู ุจู ุฏุฑฺฉ ูุงูุนโฺฏุฑุงุงูู ุง ุงุฒ  ุฏุบุฏุบูโูุง ู ุฑูุญุงุช ุงุฌุชูุงุน ุฏุฑ ุณุงูโูุง ุงูู ุงูููุงุจ ูโุฑุณููู. ูุถุงู ุจุฑ ุงู ุฎูุงูุฏู ุฏุฑฺฏุฑ ุนูุงุทู ุดุฎุต ุดุฎุตุชโูุง ูู ูโุดู ฺฉู ุงุฒ ุงู ุญุซ ุชูู ุจู ุชูู ุฏุงุณุชุงูโูุง ูพุฑุชุจโูุชุงุจ ูุงูููุฏ ูโุฒููุ ุจุง ุงู ุชูุงูุช ฺฉู ุฎูุงููุฏู ูโุฏููู ุจุง ุฑูุงุช ุญูู ุทุฑู ูุณุชุ ูู ฺฉ ุงูุณุงูู.\n",
            "ูุงูุนุง ูุจู ุงุฒ ุฎููุฏู ฺฉุชุงุจ ูฺฉุฑ ููโฺฉุฑุฏู ุจุง ฺูู ุงุซุฑ ฺฏุฑุง ููุงุฌู ุจุดู. ุฏุงุณุชุงู ููุท ุฑูุงุช ุณุงุฏูโ ู ุฑุฒููุฏู ุงุฒ ุฏูุฑุงู ุฌุจูู ุง ุงุณุงุฑุช ูุณุช. ููุณูุฏู ุจุฏูู ูุถุงูุช ฺฉุฑุฏู ู ููุท ุจุง ุฐฺฉุฑ ุฎุฑุฏู ุฏุงุณุชุงูโูุง ูุงูุนุ ุฎูุงููุฏู ุฑู ุจู ุฏุฑฺฉ ูุงูุนโฺฏุฑุงุงูู ุง ุงุฒ  ุฏุบุฏุบูโูุง ู ุฑูุญุงุช ุงุฌุชูุงุน ุฏุฑ ุณุงูโูุง ุงูู ุงูููุงุจ ูโุฑุณููู. ูุถุงู ุจุฑ ุงู ุฎูุงูุฏู ุฏุฑฺฏุฑ ุนูุงุทู ุดุฎุต ุดุฎุตุชโูุง ูู ูโุดู ฺฉู ุงุฒ ุงู ุญุซ ุชูู ุจู ุชูู ุฏุงุณุชุงูโูุง ูพุฑุชุจโูุชุงุจ ูุงูููุฏ ูโุฒููุ ุจุง ุงู ุชูุงูุช ฺฉู ุฎูุงููุฏู ูโุฏููู ุจุง ุฑูุงุช ุญูู ุทุฑู ูุณุชุ ูู ฺฉ ุงูุณุงูู.\n",
            "ฺฉุชุงุจ ุฎูุจุ ุขุฏู ุขุฎุฑุด ุฏุฑฺฏุฑ ููููู ุจุงุฒู...\n",
            "ฺฉุชุงุจ ุฎูุจุ ุขุฏู ุขุฎุฑุด ุฏุฑฺฏุฑ ููููู ุจุงุฒู...\n",
            "ุงู ฺฉุชุงุจ ุงุฒ ุฒุจุงู ฺฉููู ูู ุจู ุฑุงุญุช ูุฑุงู ูุงุฆูุฆุณู ุฑุง ุชุฎุฑุจ ฺฉุฑุฏู ุงุณุช \n",
            "ุฏุฑ ุญุงู ฺฉู ฺฉุดูุฑ ูพููุงูุฑ ฺู ูุฑุงู ูุงุฆู ุฑุง ูพุฐุฑูุชู ุงุณุช\n",
            "ูู ูู ูู ุจุง ูุธุฑ ุดูุงู ุฏุฑุจุงุฑู ฺฉููู ูู ููุงูู ูุณุชู\n",
            "ุงู ฺฉุชุงุจ ุงุฒ ุฒุจุงู ฺฉููู ูู ุจู ุฑุงุญุช ูุฑุงู ูุงุฆูุฆุณู ุฑุง ุชุฎุฑุจ ฺฉุฑุฏู ุงุณุช \n",
            "ุฏุฑ ุญุงู ฺฉู ฺฉุดูุฑ ูพููุงูุฑ ฺู ูุฑุงู ูุงุฆู ุฑุง ูพุฐุฑูุชู ุงุณุช\n",
            "ูู ูู ูู ุจุง ูุธุฑ ุดูุงู ุฏุฑุจุงุฑู ฺฉููู ูู ููุงูู ูุณุชู\n",
            "ฺฉุชุงุจุ ููู ุงูุนุงุฏู ุณุชุ ุงูุจุชู ุงุฒ ูุธุฑ ูฺฏุงุฑุด ู ููุน ุซุจุช ู ุฑูุงุช ุดุงุฏ ูุดฺฉูุงุช ุฏุงุดุชู ุจุงุดูุ ูู ุฑููุฏ ฺฉุชุงุจ ุงููุฏุฑ ฺฏุฑุงุณุช ฺฉู ุงู ฺุฒูุง ุฒุงุฏ ุชุงุซุฑ ูุฏุงุฑู.\n",
            "ุจุง ุงูฺฉู ฺฉุชุงุจ ุชููู ุดุฏู ูู ููุน ูู ุจุฑุง ุงู ฺฉุชุงุจ ุชูุงู ูุดุฏู\n",
            "ฺฉุชุงุจุ ููู ุงูุนุงุฏู ุณุชุ ุงูุจุชู ุงุฒ ูุธุฑ ูฺฏุงุฑุด ู ููุน ุซุจุช ู ุฑูุงุช ุดุงุฏ ูุดฺฉูุงุช ุฏุงุดุชู ุจุงุดูุ ูู ุฑููุฏ ฺฉุชุงุจ ุงููุฏุฑ ฺฏุฑุงุณุช ฺฉู ุงู ฺุฒูุง ุฒุงุฏ ุชุงุซุฑ ูุฏุงุฑู.\n",
            "ุจุง ุงูฺฉู ฺฉุชุงุจ ุชููู ุดุฏู ูู ููุน ูู ุจุฑุง ุงู ฺฉุชุงุจ ุชูุงู ูุดุฏู\n",
            "ฺฉุชุงุจ ุฎูุจุณุช\n",
            "\n",
            "ฺฉุชุงุจ ุฃููุ ุฃูู ูุชู ุจุชุนุฑู ูุง ุฌุฑ ู ฺฉูุฑุฏุณุชุงู ุฅุฑุงู ู ูุดุฏุฏู ุณู ุจ\"ฺฉููู ูู\" ูุนูู ูุงูฺฉุชุงุจ ู ุฃูุถู ูุฅุฎูุงููุง ุงููุนุงูุฏู ุฃู ูุฆูู ููุขุฎุฑู ุจุงูุบุฉ ุงูุนุฑุจุฉ\n",
            "ู ูู ุงูุณูุงู ู ุดฺฉู ูุงฺฉู\n",
            "ฺฉุชุงุจ ุฎูุจุณุช\n",
            "\n",
            "ฺฉุชุงุจ ุฃููุ ุฃูู ูุชู ุจุชุนุฑู ูุง ุฌุฑ ู ฺฉูุฑุฏุณุชุงู ุฅุฑุงู ู ูุดุฏุฏู ุณู ุจ\"ฺฉููู ูู\" ูุนูู ูุงูฺฉุชุงุจ ู ุฃูุถู ูุฅุฎูุงููุง ุงููุนุงูุฏู ุฃู ูุฆูู ููุขุฎุฑู ุจุงูุบุฉ ุงูุนุฑุจุฉ\n",
            "ู ูู ุงูุณูุงู ู ุดฺฉู ูุงฺฉู\n",
            "ุจุฏ ูุจูุฏ\n",
            "ุนุงู ูู ูุจูุฏ๐\n",
            "ุจุฏ ูุจูุฏ\n",
            "ุนุงู ูู ูุจูุฏ\n",
            "ุงุณู ฺฉุชุงุจ ุฌุงูุจ ุงุณุช ู ุญุช ุนฺฉุณุด ู ุฎูุฏ ุงู ุจุงุนุซ ู ุดูุฏ ฺฉู ุฎูุงููุฏู ุฌุฐุจ ุดูุฏ\n",
            "ุงุณู ฺฉุชุงุจ ุฌุงูุจ ุงุณุช ู ุญุช ุนฺฉุณุด ู ุฎูุฏ ุงู ุจุงุนุซ ู ุดูุฏ ฺฉู ุฎูุงููุฏู ุฌุฐุจ ุดูุฏ\n",
            "ููููู ุงุฒ ุทุงูฺู ฺฉุงุฑ ุงุฑุฒุดููุฏ ุงูุฌุงู ุฏุงุฏ...\n",
            "ููููู ุงุฒ ุทุงูฺู ฺฉุงุฑ ุงุฑุฒุดููุฏ ุงูุฌุงู ุฏุงุฏ...\n",
            "ููููู ฺฉู ุฑุงฺฏุงู ุจูุฏ.ุงุณุชูุงุฏู ฺฉุฑุฏู ;-))\n",
            "ููููู ฺฉู ุฑุงฺฏุงู ุจูุฏ.ุงุณุชูุงุฏู ฺฉุฑุฏู ;-))\n",
            "ูู ูุฏุฏู ูุฌูู ุฑู ูู ุงุฒ ุฑู ุฌูุฏุด ู ุนูุงูู ูุดู ฺฏูุช ูุฌูู ููุช ุถุนู ุจูุธุฑ ูุงุฏ ฺฉู ุณุน ุฏุฑ ูุฌุฒ ฺฏู ุฏุงุฑุฏ\n",
            "ูู ูุฏุฏู ูุฌูู ุฑู ูู ุงุฒ ุฑู ุฌูุฏุด ู ุนูุงูู ูุดู ฺฏูุช ูุฌูู ููุช ุถุนู ุจูุธุฑ ูุงุฏ ฺฉู ุณุน ุฏุฑ ูุฌุฒ ฺฏู ุฏุงุฑุฏ\n",
            "ุจุง ุณูุงู ุจุณุงุฑ ุนุงู ู ููุงุณุจ \n",
            "\n",
            "ุจุง ุณูุงู ุจุณุงุฑ ุนุงู ู ููุงุณุจ \n",
            "\n",
            "ูุงูุนุง ููุด ุฏุฑุณุชู ุฎู ุงู ูุฌูู ุฎูุจู ูุงูุนุง ุฏุฑุณุชู ุฎู ูพูู ูุง ุฎุฑุฌ ูฺฉูู\n",
            "ูุงูุนุง ููุด ุฏุฑุณุชู ุฎู ุงู ูุฌูู ุฎูุจู ูุงูุนุง ุฏุฑุณุชู ุฎู ูพูู ูุง ุฎุฑุฌ ูฺฉูู\n",
            "ุจุนุฏ ุชุญููุงุช ูุซู ูู ูุชูุฌู ูุดู ฺฉู ุขูุฏู ูุฏุงุฑู__ ููููู\n",
            "ุจุนุฏ ุชุญููุงุช ูุซู ูู ูุชูุฌู ูุดู ฺฉู ุขูุฏู ูุฏุงุฑู__ ููููู\n",
            "ุฏูุณุชุงู ูุฑู ุจุงุฒ ุงูุฌุง ุฌูุน ุดุฏูุ ุงูุฏูุงุฑู ุฌุจููู ุฑู ุฎุงู ูฺฉููุฏ. ุทุฑู ุดูุงุฑุดู ูู ฺฏุฐุดุชู ุชุง ุฒุฑุดุงุฎู ุฌูุน ฺฉูู๐\n",
            "ุฏูุณุชุงู ูุฑู ุจุงุฒ ุงูุฌุง ุฌูุน ุดุฏูุ ุงูุฏูุงุฑู ุฌุจููู ุฑู ุฎุงู ูฺฉููุฏ. ุทุฑู ุดูุงุฑุดู ูู ฺฏุฐุดุชู ุชุง ุฒุฑุดุงุฎู ุฌูุน ฺฉูู\n",
            "ูู ุฏุงู ฺฉุฑุฏู ูุงูุนุง ุนุงูู\n",
            "ุงูุจุชู ุงฺฏู ุจุฎูุงูุฏ ฺฉ ุงุฒ ุจูุชุฑููุง ุจุงุดุฏ \n",
            "\n",
            "ูู ุฏุงู ฺฉุฑุฏู ูุงูุนุง ุนุงูู\n",
            "ุงูุจุชู ุงฺฏู ุจุฎูุงูุฏ ฺฉ ุงุฒ ุจูุชุฑููุง ุจุงุดุฏ \n",
            "\n",
            "ฺฉุชุงุจ ุฎูุจ ูุณุชุ ุจุง ุฎููุฏูุด ูฺฉุชู ุจุฑุฏุงุฑ ฺฉุฑุฏู.ุงูุฌูุฑ ุขุฏู ููููู ฺู ุดุฑฺฉุช ฺฉุงุฑุด ุฏุฑุณุชู ู ุงูฺฉู ฺุทูุฑ ูพุดุฑูุช ฺฉูู.ุฎุฏุงุงุฑุชุงู.\n",
            "ฺฉุชุงุจ ุฎูุจ ูุณุชุ ุจุง ุฎููุฏูุด ูฺฉุชู ุจุฑุฏุงุฑ ฺฉุฑุฏู.ุงูุฌูุฑ ุขุฏู ููููู ฺู ุดุฑฺฉุช ฺฉุงุฑุด ุฏุฑุณุชู ู ุงูฺฉู ฺุทูุฑ ูพุดุฑูุช ฺฉูู.ุฎุฏุงุงุฑุชุงู.\n",
            "ุจุงุฒุงุฑุงุจ ฺูุฏ ุณุทุญ (mlm )ฺฉ ุงุณุชุฑุงุชฺ ุจุงุฒุงุฑุงุจ ูุฑูุด ูุณุชูู ุงุณุช ฺฉู ุฏุฑ ุขู ุจุงุฒุงุฑุงุจ ุนูุงูู ุจุฑ ูพุงุฏุงุด ฺฉู ุจุงุจุช ูุฑูุด ูุณุชูู ูุญุตูู ุฏุฑุงูุช ู ฺฉูุฏ ุจุงุจุช ูุฑูุด ุงูุฑุงุฏ ฺฉู ุชูุณุท ุงู ุงุณุชุฎุฏุงู ุดุฏู ุงูุฏ ูุฒ ุฏุฑุขูุฏฺฉุณุจ ูฺฉูุฏ.ุงูุฑุงุฏ ฺฉู ุชูุณุท ุจุงุฒุงุฑุงุจ ุงุณุชุฎุฏุงู ุดุฏู ุงูุฏ ุฒุฑ ูุฌููุนู ุงู ูุงูุฏู ูุดููุฏ ู ุดุฎุต ุจุงุฒุงุฑุงุจ ุจุงุจุช ูุฑูุด ฺฉู ุฒุฑ ูุฌููุนู ูุง ุงู ุฏุงุดุชู ุงูุฏ ูุฒ ูพุงุฏุงุด ุฏุฑุงูุช ูฺฉูุฏ.ุงู ุฒุฑ ูุฌููุนู ูุง ูุชูุงููุฏ ุชุง ฺูุฏ ุณุทุญ ูุฒ ุงุฏุงูู ุฏุงุดุชู ุจุงุดูุฏ. ูุฑุฏ ุจุงุฒุงุฑุงุจ ุจุง ุฏุงุดุชู ุฒุฑ ูุฌููุนู ูุง ุจุดุชุฑ ูุชูุงูุฏ ุณูุฏ ุจุดุชุฑ ฺฉุณุจ ฺฉูุฏ.\n",
            "ูุชูุงู ุงุฒ ุดุฑฺฉุช \"ุจุงุฏุฑุงู ฺฏุณุชุฑุงู\"ุจุนููุงู ฺฉ ุงุฒ ูุฏุฑุชููุฏุชุฑู ู ุงููู ุดุฑฺฉุช ูุง ุงู ุญูุฒู ูุงู ุจุฑุฏ ฺฉู ุจุง  ูุฌูุฒ  ูุฒุงุฑุช ุตูุนุช ,ูุนุฏู ูุชุฌุงุฑุช ุฏุฑ ุงุฑุงู ูุนุงูุช ูฺฉูุฏ.\n",
            "ุจุงุฒุงุฑุงุจ ฺูุฏ ุณุทุญ (mlm )ฺฉ ุงุณุชุฑุงุชฺ ุจุงุฒุงุฑุงุจ ูุฑูุด ูุณุชูู ุงุณุช ฺฉู ุฏุฑ ุขู ุจุงุฒุงุฑุงุจ ุนูุงูู ุจุฑ ูพุงุฏุงุด ฺฉู ุจุงุจุช ูุฑูุด ูุณุชูู ูุญุตูู ุฏุฑุงูุช ู ฺฉูุฏ ุจุงุจุช ูุฑูุด ุงูุฑุงุฏ ฺฉู ุชูุณุท ุงู ุงุณุชุฎุฏุงู ุดุฏู ุงูุฏ ูุฒ ุฏุฑุขูุฏฺฉุณุจ ูฺฉูุฏ.ุงูุฑุงุฏ ฺฉู ุชูุณุท ุจุงุฒุงุฑุงุจ ุงุณุชุฎุฏุงู ุดุฏู ุงูุฏ ุฒุฑ ูุฌููุนู ุงู ูุงูุฏู ูุดููุฏ ู ุดุฎุต ุจุงุฒุงุฑุงุจ ุจุงุจุช ูุฑูุด ฺฉู ุฒุฑ ูุฌููุนู ูุง ุงู ุฏุงุดุชู ุงูุฏ ูุฒ ูพุงุฏุงุด ุฏุฑุงูุช ูฺฉูุฏ.ุงู ุฒุฑ ูุฌููุนู ูุง ูุชูุงููุฏ ุชุง ฺูุฏ ุณุทุญ ูุฒ ุงุฏุงูู ุฏุงุดุชู ุจุงุดูุฏ. ูุฑุฏ ุจุงุฒุงุฑุงุจ ุจุง ุฏุงุดุชู ุฒุฑ ูุฌููุนู ูุง ุจุดุชุฑ ูุชูุงูุฏ ุณูุฏ ุจุดุชุฑ ฺฉุณุจ ฺฉูุฏ.\n",
            "ูุชูุงู ุงุฒ ุดุฑฺฉุช \"ุจุงุฏุฑุงู ฺฏุณุชุฑุงู\"ุจุนููุงู ฺฉ ุงุฒ ูุฏุฑุชููุฏุชุฑู ู ุงููู ุดุฑฺฉุช ูุง ุงู ุญูุฒู ูุงู ุจุฑุฏ ฺฉู ุจุง  ูุฌูุฒ  ูุฒุงุฑุช ุตูุนุช ,ูุนุฏู ูุชุฌุงุฑุช ุฏุฑ ุงุฑุงู ูุนุงูุช ูฺฉูุฏ.\n",
            "ุฎูุจ ูุจูุฏ\n",
            "ุฎูุจ ูุจูุฏ\n",
            "ุฎูุจ ูุจูุฏ...\n",
            "ุฎูุจ ูุจูุฏ...\n",
            "ู ฺุฒ ุฌุงูุจ ุจฺฏู: ุงฺฏู ุฏูุช ฺฉูุฏ ุฑู ุณุฑ ูุฌุณูู ุญุถุฑุช ููุณ ฺฉู ุฑู ฺฉุชุงุจ ูุณุชุ ุฏู ุชุง ุดุงุฎ ูุฌูุฏ ุฏุงุฑู. ุณุงุฒูุฏู ูุฌุณูู ฺฉููู karnayim ฺฉู ูู ูุนู ุฏุฑุฎุดุด ู ููุฑุงู ุฑู ูุฏู ู ูู ูุนู ุดุงุฎ ุฑู ูุฏู ุฑู ุดุงุฎ ูููุฏู.ููุดุชู ุจูุฏู ฺฉู ูพุฑุชู ูุง ููุฑ ุงุฒ ุณุฑ ุงู ู ุชุงุจุฏู ุงูู ูฺฉุฑ ฺฉุฑุฏู ููุดุชู ุดุงุฎ ุฏุฑ ุณุฑ ุฏุงุดุชู๐๐๐\n",
            "ู ฺุฒ ุฌุงูุจ ุจฺฏู: ุงฺฏู ุฏูุช ฺฉูุฏ ุฑู ุณุฑ ูุฌุณูู ุญุถุฑุช ููุณ ฺฉู ุฑู ฺฉุชุงุจ ูุณุชุ ุฏู ุชุง ุดุงุฎ ูุฌูุฏ ุฏุงุฑู. ุณุงุฒูุฏู ูุฌุณูู ฺฉููู karnayim ฺฉู ูู ูุนู ุฏุฑุฎุดุด ู ููุฑุงู ุฑู ูุฏู ู ูู ูุนู ุดุงุฎ ุฑู ูุฏู ุฑู ุดุงุฎ ูููุฏู.ููุดุชู ุจูุฏู ฺฉู ูพุฑุชู ูุง ููุฑ ุงุฒ ุณุฑ ุงู ู ุชุงุจุฏู ุงูู ูฺฉุฑ ฺฉุฑุฏู ููุดุชู ุดุงุฎ ุฏุฑ ุณุฑ ุฏุงุดุชู\n",
            "ุฏุฑูุบฺฏููุง ูุชููุจ\n",
            "ุฏุฑูุบฺฏููุง ูุชููุจ\n",
            "ฺู ุจุง ููฺฉู ุนููุงู ุงู ฺฉุชุงุจ๐\n",
            "ุฏูุฑ ุงุฒ ุฌูู ุงู ุฌูุน,ูุงูุนุง ุจุนุถุง ุงูุฌูุฑู๐ฑ๐\n",
            "ฺู ุจุง ููฺฉู ุนููุงู ุงู ฺฉุชุงุจ\n",
            "ุฏูุฑ ุงุฒ ุฌูู ุงู ุฌูุน,ูุงูุนุง ุจุนุถุง ุงูุฌูุฑู\n",
            "ุฎู ุฏูุณุช ุฏุงุดุชู ุงู ฺฉุชุงุจู.ููุณูุฏู ูุซุฑ ุฑูุงู ู ุฎูุจ ุฏุงุฑู.ุดุฎุตุช ูพุฑุฏุงุฒ ูุงุด ูู ูุดูฺฏ ุจูุฏ.ูุฎุตูุตุง ุฏุงุณุชุงู ุงูู ุฑู ุฎู ุฏูุณุช ุฏุงุดุชู.ุชูุตู ูฺฉูู ุจุฎูุชุฏ.\n",
            "ุฎู ุฏูุณุช ุฏุงุดุชู ุงู ฺฉุชุงุจู.ููุณูุฏู ูุซุฑ ุฑูุงู ู ุฎูุจ ุฏุงุฑู.ุดุฎุตุช ูพุฑุฏุงุฒ ูุงุด ูู ูุดูฺฏ ุจูุฏ.ูุฎุตูุตุง ุฏุงุณุชุงู ุงูู ุฑู ุฎู ุฏูุณุช ุฏุงุดุชู.ุชูุตู ูฺฉูู ุจุฎูุชุฏ.\n",
            "ฺูุฏุฑ ู ฺฏูุชู \"ุงุณุช\"\n",
            "ฺูุฏุฑ ู ฺฏูุชู \"ุงุณุช\"\n",
            "ููู ุงูุนุงุฏู ุฒุจุง ู ุดูุฏู\n",
            "ููู ุงูุนุงุฏู ุฒุจุง ู ุดูุฏู\n",
            "ุฎู ุฒุจุง ู ุชุงุซุฑฺฏุฐุงุฑ. ููููู ุจุงุจุช ููฺู ฺฉุชุงุจ.\n",
            "ุฎู ุฒุจุง ู ุชุงุซุฑฺฏุฐุงุฑ. ููููู ุจุงุจุช ููฺู ฺฉุชุงุจ.\n",
            "ูุฌููุนู ฺุงูพุด 70 ุชูููู:/\n",
            "ูุฌููุนู ฺุงูพุด 70 ุชูููู:/\n",
            "ฺฉุชุงุจ ุฎูุจ ุจูุฏ ุงุฒ ุฎูุงูุฏูุด ูุฐุช ุจุฑุฏู\n",
            "ฺฉุชุงุจ ุฎูุจ ุจูุฏ ุงุฒ ุฎูุงูุฏูุด ูุฐุช ุจุฑุฏู\n",
            "ฺฉุชุงุจ ููู ุงูุนุงุฏู ุง ูุณุช\n",
            "ุชูุตู ูฺฉูู ุญุชูุง ุจุฎููุฏ ุชุง ฺฺฏููฺฏ ุฎูุดุจุฎุช ุจุง ุญุฏุงูู ฺุฒ ูุง ุฑู ููุณ ฺฉูุฏ\n",
            "ุนุงู ุจูุฏ ุนุงู ุจูุฏ\n",
            "ฺฉุชุงุจ ููู ุงูุนุงุฏู ุง ูุณุช\n",
            "ุชูุตู ูฺฉูู ุญุชูุง ุจุฎููุฏ ุชุง ฺฺฏููฺฏ ุฎูุดุจุฎุช ุจุง ุญุฏุงูู ฺุฒ ูุง ุฑู ููุณ ฺฉูุฏ\n",
            "ุนุงู ุจูุฏ ุนุงู ุจูุฏ\n",
            "ฺฉุงุด ุชูุงู ฺฉุชุงุจ ูุง ููู  ูพููุงู ูุงู ุฑู ุจฺฏุฐุงุฑุฏ ุชู ุทุงูฺู. ุฎู ุฎูุจู :)\n",
            "ฺฉุงุด ุชูุงู ฺฉุชุงุจ ูุง ููู  ูพููุงู ูุงู ุฑู ุจฺฏุฐุงุฑุฏ ุชู ุทุงูฺู. ุฎู ุฎูุจู :)\n",
            "ูุง ุดูุฏ ุชุฌูุง ุนุงูู ุ ฺฉุชุงุจ ูุงูุนุง ุงุฑุฒุดููุฏู\n",
            "ูุง ุดูุฏ ุชุฌูุง ุนุงูู ุ ฺฉุชุงุจ ูุงูุนุง ุงุฑุฒุดููุฏู\n",
            "ฺฉุชุงุจูุง ููู ูพููุงู ูุงู ฺฉุชุงุจูุง ุจุณุงุฑ ุฎูุจุณุช...\n",
            "ฺฉุชุงุจูุง ููู ูพููุงู ูุงู ฺฉุชุงุจูุง ุจุณุงุฑ ุฎูุจุณุช...\n",
            "ุจุง ุณูุงู ูุขุฑุฒู ููููุช. ูุทูุง ุณุงู ูุดุฑ ฺฉุชุงุจ ุฑุง ูู ุจููุณุฏ. ุงุฒ ุงุจุชฺฉุงุฑ ุงุฑุฒูุฏู  ุดูุง ุณูพุงุณฺฏุฒุงุฑู.\n",
            "ุจุง ุณูุงู ูุขุฑุฒู ููููุช. ูุทูุง ุณุงู ูุดุฑ ฺฉุชุงุจ ุฑุง ูู ุจููุณุฏ. ุงุฒ ุงุจุชฺฉุงุฑ ุงุฑุฒูุฏู  ุดูุง ุณูพุงุณฺฏุฒุงุฑู.\n",
            "ูุฑุณ ูุดุฑ ุฌุงู\n",
            "ูุฑุณ ูุดุฑ ุฌุงู\n",
            "ุจุงุณูุงู ูุทูุง ฺฉุชุงุจ ูุง ฺฉู ูุญุชูุง ุฎูุจ ู ุฌุงูุจ ุฏุงุฑูุฏ ุฑู ูุทูุง ุฑุงฺฏุงู ูู ุจุฐุงุฑู ฺูู ูู ูู ุชููู ุงุฒ ฺฉุชุง ุจ ูุง ฺฉู ูพูู ูุณุชู ุงุณุชูุงุฏู ฺฉูู ฺูู ูุนูููุง ฺฉุชุง ุจูุง ูพุดููุงุฏ ุทุงูฺู ูพูู ูุณุชู. ุจุงุชุดฺฉุฑ\n",
            "ุจุงุณูุงู ูุทูุง ฺฉุชุงุจ ูุง ฺฉู ูุญุชูุง ุฎูุจ ู ุฌุงูุจ ุฏุงุฑูุฏ ุฑู ูุทูุง ุฑุงฺฏุงู ูู ุจุฐุงุฑู ฺูู ูู ูู ุชููู ุงุฒ ฺฉุชุง ุจ ูุง ฺฉู ูพูู ูุณุชู ุงุณุชูุงุฏู ฺฉูู ฺูู ูุนูููุง ฺฉุชุง ุจูุง ูพุดููุงุฏ ุทุงูฺู ูพูู ูุณุชู. ุจุงุชุดฺฉุฑ\n",
            "ุฏูุชูู ฺฏุฑู ุฎู ุญุงู ฺฉุฑุฏู. ุงูุฏูุงุฑู ุณุงุฑ ฺฉุชุงุจูุง ุดุงููู ุฑู ูู ุจุฒุงุฑุฏ\n",
            "ุฏูุชูู ฺฏุฑู ุฎู ุญุงู ฺฉุฑุฏู. ุงูุฏูุงุฑู ุณุงุฑ ฺฉุชุงุจูุง ุดุงููู ุฑู ูู ุจุฒุงุฑุฏ\n",
            "ุง ูุง! ุง ูุง ูู! ุนุงูู ุงู ฺฉุชุงุจ! ูููููู ุงุฒ ุดูุง ู  ูุฑูุงุฑุฏ\n",
            "ุง ูุง! ุง ูุง ูู! ุนุงูู ุงู ฺฉุชุงุจ! ูููููู ุงุฒ ุดูุง ู  ูุฑูุงุฑุฏ\n",
            "ฺุฑุง ฺฉุงููุช ููู ูพุงฺฉ ูโฺฉูุฏุ ูุงูุนู ุจุนุถโูุง ูพุฏุง ูโุดู ฺฉู ุงู ูุฐุฎุฑูุงุชู ุจุฎูููุ\n",
            "ฺุฑุง ฺฉุงููุช ููู ูพุงฺฉ ูโฺฉูุฏุ ูุงูุนู ุจุนุถโูุง ูพุฏุง ูโุดู ฺฉู ุงู ูุฐุฎุฑูุงุชู ุจุฎูููุ\n",
            "ฺูุฏุฑ ุฒุงุฏู ฺฏู๐๐ฃ\n",
            "ุฎูุจ ุดุฏ ููููู ุดุนุฑ ุฑู ูู ุงูุฑุฏู ุจูุฏ ฺฉู ูุทูู ุจุดู ุงู ุฒุงุฏู ฺฏู ูุงููุฏ ุงุฒ ูุชู ุงุตู ูุจูุฏู\n",
            "ฺุฑุง ุขุฎู\n",
            "ฺฉ ุฏุงุณุชุงู ฺฉ ุตูุญู ุง ุฑู ุฏุฑ ุจุฏุชุฑู ุญุงูุช ุจุณุช ุตูุญู ฺฉุฑุฏู ฺฉู ููฺฏุงู ุฎููุฏู ุฎูุงุจุช ุจฺฏุฑูโน\n",
            "ฺูุฏุฑ ุฒุงุฏู ฺฏู\n",
            "ุฎูุจ ุดุฏ ููููู ุดุนุฑ ุฑู ูู ุงูุฑุฏู ุจูุฏ ฺฉู ูุทูู ุจุดู ุงู ุฒุงุฏู ฺฏู ูุงููุฏ ุงุฒ ูุชู ุงุตู ูุจูุฏู\n",
            "ฺุฑุง ุขุฎู\n",
            "ฺฉ ุฏุงุณุชุงู ฺฉ ุตูุญู ุง ุฑู ุฏุฑ ุจุฏุชุฑู ุญุงูุช ุจุณุช ุตูุญู ฺฉุฑุฏู ฺฉู ููฺฏุงู ุฎููุฏู ุฎูุงุจุช ุจฺฏุฑู\n",
            "ูุจูุง ุฏุจุฑ ุงุฏุจุงุชููู ุจุฑุงููู ูุตู ุดู ฺฏูุชู ุจูุฏ. ุงูุงูู ฺฉู ุฎููุฏู ุฎู ุจุงุญุงู ุจูุฏ. ุญุชูุง ุจุฎููุจู. ุฎู ุงุฑุฒุด ุฎููุฏู ุฏุงุฑููููููู\n",
            "ูุจูุง ุฏุจุฑ ุงุฏุจุงุชููู ุจุฑุงููู ูุตู ุดู ฺฏูุชู ุจูุฏ. ุงูุงูู ฺฉู ุฎููุฏู ุฎู ุจุงุญุงู ุจูุฏ. ุญุชูุง ุจุฎููุจู. ุฎู ุงุฑุฒุด ุฎููุฏู ุฏุงุฑููููููู\n",
            "ูุฑฺฉุณ ุงู ฺฉุชุงุจู ูุฎููุฏู ู ุจูุฑู ุจู ูุฑฺฏ ุฌุงููุช ูุฑุฏูุุชุฑุฌูุด ูู ุจู ุฏุณุช ฺฉุณ ุจูุฏู ฺฉู ููุดู ูุซุงู ุจุฑุงุด ุขูุฑุฏ\n",
            "ูุฑฺฉุณ ุงู ฺฉุชุงุจู ูุฎููุฏู ู ุจูุฑู ุจู ูุฑฺฏ ุฌุงููุช ูุฑุฏูุุชุฑุฌูุด ูู ุจู ุฏุณุช ฺฉุณ ุจูุฏู ฺฉู ููุดู ูุซุงู ุจุฑุงุด ุขูุฑุฏ\n",
            "ฺฉุชุงุจ ุจุณุงุฑ ููุฏ ูุณุชุด\n",
            "ฺฉุชุงุจ ุจุณุงุฑ ููุฏ ูุณุชุด\n",
            "ูุญูู ุงุณุชุฏูุงู ุณูุฑุงุท ุฒุจุง ุจูุฏ.\n",
            "ูุญูู ุงุณุชุฏูุงู ุณูุฑุงุท ุฒุจุง ุจูุฏ.\n",
            "ุนุดู ุฒุจุง ูุณุช ูู ุจู ุฏูุจุงู ุฒุจุง ุงุณุช...\n",
            "ูู ุงุฒ ุงู ฺฉุชุงุจ ุงุฏ ฺฏุฑูุชู ฺฉู :\n",
            "ุนุดู ฺฉู ุฏุฑ ุขู ูุชูุงู ุจู ุฎุงุทุฑ ุนุดู ุงุฒ ุนุดู ฺฏุฐุดุช ุ ุนุดู ูุณุช ุ ุนุดู ุนู ุจู ุฎุงุทุฑ ุนุดู ุงุฒ ุนุดู ูุง ุจฺฏุฐุฑู....\n",
            "ุนุดู ุฒุจุง ูุณุช ูู ุจู ุฏูุจุงู ุฒุจุง ุงุณุช...\n",
            "ูู ุงุฒ ุงู ฺฉุชุงุจ ุงุฏ ฺฏุฑูุชู ฺฉู :\n",
            "ุนุดู ฺฉู ุฏุฑ ุขู ูุชูุงู ุจู ุฎุงุทุฑ ุนุดู ุงุฒ ุนุดู ฺฏุฐุดุช ุ ุนุดู ูุณุช ุ ุนุดู ุนู ุจู ุฎุงุทุฑ ุนุดู ุงุฒ ุนุดู ูุง ุจฺฏุฐุฑู....\n",
            "ุงุฒ ฺฉุชุงุจโูุง ฺฉูุงุณฺฉ ฺฉู ูุฑ ฺฉู ุฏุฑ ุฑุดุชูโูุง ุนููู ุงูุณุงู ุชุญุตู ู ูุทุงูุนู ูโฺฉูุฏุ ุจุงุฏุด ุจุฎูุงูุฏ.\n",
            "ุงุฒ ฺฉุชุงุจโูุง ฺฉูุงุณฺฉ ฺฉู ูุฑ ฺฉู ุฏุฑ ุฑุดุชูโูุง ุนููู ุงูุณุงู ุชุญุตู ู ูุทุงูุนู ูโฺฉูุฏุ ุจุงุฏุด ุจุฎูุงูุฏ.\n",
            "ูู ุงู ฺฉุชุงุจ ุฑู ูุณุฎู ฺุงูพุด ุฑู ุฎููุฏู.\n",
            "ู ฺฉุชุงุจ ููุณู ุฏุงุณุชุงู...\n",
            "ุฌุงูุจู ูู ุฎุณุชู ฺฉููุฏุณ.\n",
            "ูู ุงู ฺฉุชุงุจ ุฑู ูุณุฎู ฺุงูพุด ุฑู ุฎููุฏู.\n",
            "ู ฺฉุชุงุจ ููุณู ุฏุงุณุชุงู...\n",
            "ุฌุงูุจู ูู ุฎุณุชู ฺฉููุฏุณ.\n",
            "ุฑุดุชู ุชุฌุฑุจ ุจูุฏ ู ุจุฑุง ฺฉูฺฉูุฑ ุงูุณุงู ุดุฑฺฉุช ฺฉุฑุฏู.ุงูุงู ุฎุฏุงุฑู ูุฒุงุฑ ูุฑุชุจู ุดฺฉุฑ ูฺฉูู ฺฉู ูุชููู ุขุซุงุฑ ููุณู ู ููุทู ุฑู ุจุง ูููู ููุฏูุงุช ุฏุจุฑุณุชุงู ุจูููู ู ุงุณุชูุงุฏู ฺฉูู.\n",
            "ุจู ูุธุฑู ุจุฑุฏ ฺฉุชุงุจ ููุณูู ู ููุทู ุงูุณุงู ุฑู ุจฺฏุฑุฏ ู ุจุฎููุฏ ูุงูุนุง ููุฏ ู ฺฉุงุฑุจุฑุฏู.\n",
            "ฺฉุงููุง ูุชูุฌู ูุบูุทู ูุง ูุดุฏ ู ุฏฺฏู ุจู ุฑุงุญุช ุญุฑู ฺฉุณุฑู ูููพุฐุฑุฏ ูฺฏู ุงูฺฉู ุจู ุฑุงุณุชุชุด ูพ ุจุจุฑุฏ\n",
            "ุฑุดุชู ุชุฌุฑุจ ุจูุฏ ู ุจุฑุง ฺฉูฺฉูุฑ ุงูุณุงู ุดุฑฺฉุช ฺฉุฑุฏู.ุงูุงู ุฎุฏุงุฑู ูุฒุงุฑ ูุฑุชุจู ุดฺฉุฑ ูฺฉูู ฺฉู ูุชููู ุขุซุงุฑ ููุณู ู ููุทู ุฑู ุจุง ูููู ููุฏูุงุช ุฏุจุฑุณุชุงู ุจูููู ู ุงุณุชูุงุฏู ฺฉูู.\n",
            "ุจู ูุธุฑู ุจุฑุฏ ฺฉุชุงุจ ููุณูู ู ููุทู ุงูุณุงู ุฑู ุจฺฏุฑุฏ ู ุจุฎููุฏ ูุงูุนุง ููุฏ ู ฺฉุงุฑุจุฑุฏู.\n",
            "ฺฉุงููุง ูุชูุฌู ูุบูุทู ูุง ูุดุฏ ู ุฏฺฏู ุจู ุฑุงุญุช ุญุฑู ฺฉุณุฑู ูููพุฐุฑุฏ ูฺฏู ุงูฺฉู ุจู ุฑุงุณุชุชุด ูพ ุจุจุฑุฏ\n",
            "ุฌุฒ ุฒุจุงุชุฑู ฺฉุชุงุจ ูุง ฺฉู ุฎููุฏู ุจุง ุงุฑุฒุด ุจุง ูุชู ุฑุงุญุช ููุงุจู ููู ุฏุฑ ููุฑุฏ ุนุดู\n",
            "ุงุญุณูุช ุจู ุณูุฑุงุท\n",
            "ุฌุฒ ุฒุจุงุชุฑู ฺฉุชุงุจ ูุง ฺฉู ุฎููุฏู ุจุง ุงุฑุฒุด ุจุง ูุชู ุฑุงุญุช ููุงุจู ููู ุฏุฑ ููุฑุฏ ุนุดู\n",
            "ุงุญุณูุช ุจู ุณูุฑุงุท\n",
            "ุฎู ุณุฎุชู ูููุฏูุด ..\n",
            "ฺฉู ุชุฎุตุตู\n",
            "ุฎู ุณุฎุชู ูููุฏูุด ..\n",
            "ฺฉู ุชุฎุตุตู\n",
            "ุณูุงู. ุงู ฺฉุชุงุจ ุงููู ูพูุฌุฑู  ูุงุจ ุจูุฏ ฺฉู ุจู ุฏูุง ุนุดู ุจุงุฒ ุดุฏ ุจุฑุงู\n",
            "ุณูุงู. ุงู ฺฉุชุงุจ ุงููู ูพูุฌุฑู  ูุงุจ ุจูุฏ ฺฉู ุจู ุฏูุง ุนุดู ุจุงุฒ ุดุฏ ุจุฑุงู\n",
            "ูุงูุนุง ุจุง ุงุฎุชูุงู 200 ุชุง ุชฺฉ ุชููู ฺุฑุง ุจุงุฏ ุจู ุฌุง ุฎุฑุฏ ูุณุฎู ฺุงูพุ ุฏุงูููุฏุด ฺฉุฑุฏุ!..ุงู ุฑูุด ููุช ฺฏุฐุงุฑ ุจ ูุนูู!!!\n",
            "ูุงูุนุง ุจุง ุงุฎุชูุงู 200 ุชุง ุชฺฉ ุชููู ฺุฑุง ุจุงุฏ ุจู ุฌุง ุฎุฑุฏ ูุณุฎู ฺุงูพุ ุฏุงูููุฏุด ฺฉุฑุฏุ!..ุงู ุฑูุด ููุช ฺฏุฐุงุฑ ุจ ูุนูู!!!\n",
            "ุชุนุฏุงุฏ ุตูุญุงุช ฺฉุชุงุจ ุฑู ููุดุชุฏ 144 ุ ุฏุฑ ุตูุฑุช ฺฉู ุฏุฑ ูุงู46 ุตูุญู ุจุดุชุฑ ูุณุช. ุฏุฑ ุชูุถุญุงุช ููุดุชุฏ ฺฉุชุงุจ ุฑูุงุช ุงุฒ ุนุดู ุงุณุช ฺฉู ุงููุงุทูู ู ุจุฒุฑฺฏุงู ููุงู ุขู ุฑุง ุฑูุงุช ู ฺฉููุฏ. ุฏุฑ ุตูุฑุช ฺฉู ุงุฒ ููู 46 ุตูุญู ุงฺฉุซุฑุง ุชูุถุญุงุชุณุช ุงุฒ ุฒูุฏฺฏูุงูู ู ฺฉุงุฑูุง ุงููุงุทูู ู ุฏฺฏุฑ ุจุฒุฑฺฏุงู ููุงู...\n",
            "ุชุนุฏุงุฏ ุตูุญุงุช ฺฉุชุงุจ ุฑู ููุดุชุฏ 144 ุ ุฏุฑ ุตูุฑุช ฺฉู ุฏุฑ ูุงู46 ุตูุญู ุจุดุชุฑ ูุณุช. ุฏุฑ ุชูุถุญุงุช ููุดุชุฏ ฺฉุชุงุจ ุฑูุงุช ุงุฒ ุนุดู ุงุณุช ฺฉู ุงููุงุทูู ู ุจุฒุฑฺฏุงู ููุงู ุขู ุฑุง ุฑูุงุช ู ฺฉููุฏ. ุฏุฑ ุตูุฑุช ฺฉู ุงุฒ ููู 46 ุตูุญู ุงฺฉุซุฑุง ุชูุถุญุงุชุณุช ุงุฒ ุฒูุฏฺฏูุงูู ู ฺฉุงุฑูุง ุงููุงุทูู ู ุฏฺฏุฑ ุจุฒุฑฺฏุงู ููุงู...\n",
            "ฺฉุชุงุจ ุฎูุจ ู ุฌุงูุจ ุจูุฏ.\n",
            "ฺฉุชุงุจ ุฎูุจ ู ุฌุงูุจ ุจูุฏ.\n",
            "ููู ุงูุนุงุฏู ุงุณุช.ุงููุงุทูู ุฑู ุจุงุฏ ุณุชูุฏ.\n",
            "ููู ุงูุนุงุฏู ุงุณุช.ุงููุงุทูู ุฑู ุจุงุฏ ุณุชูุฏ.\n",
            "ุขุฎู ฺ ฺฉุงุฑู ุจุง ุงู ููุช ุฎุจ ูุณุฎู ฺุงูพ ูุฎุฑู ฺุดูุงูู ุงุฐุช ููฺฉูู ูุฑูุด ฒฐฐ ุฎุฎุฎ\n",
            "ุขุฎู ฺ ฺฉุงุฑู ุจุง ุงู ููุช ุฎุจ ูุณุฎู ฺุงูพ ูุฎุฑู ฺุดูุงูู ุงุฐุช ููฺฉูู ูุฑูุด ฒฐฐ ุฎุฎุฎ\n",
            "ุจุงุฑ ุงูู ุจู ุฏูู ููุดุณุช ูู ุจุงุฑ ุฏูู ูุดุณุช ูุจุฑูู ูุฑูุช,  ุณุฎูุงู ุณูุฑุงุท ุฏุฑ ุชุนุฑู ุนุดู ูุฌุฏ ุขูุฑ ูุณุชูุฏ\n",
            "ุจุงุฑ ุงูู ุจู ุฏูู ููุดุณุช ูู ุจุงุฑ ุฏูู ูุดุณุช ูุจุฑูู ูุฑูุช,  ุณุฎูุงู ุณูุฑุงุท ุฏุฑ ุชุนุฑู ุนุดู ูุฌุฏ ุขูุฑ ูุณุชูุฏ\n",
            "ุฎู ฺฉุชุงุจ ุฎูุจ ู ุฌุงูุจ ุจูุฏ.\n",
            "ุฎู ฺฉุชุงุจ ุฎูุจ ู ุฌุงูุจ ุจูุฏ.\n",
            "ุจุง ุณูุงู\n",
            "ุงู ฺฉุชุงุจ ูุงูุนุง ฺฉุชุงุจ ุจุณุงุฑ ุชุงุซุฑ ฺฏุฐุงุฑ ูุณุช ุจุฑ ุทุฑูู  ูฺฏุงู ููุณููุงู ู ุนุงุฑูุงู ุณุฑุฒูู ุฎูุฏูุงู ู ุญุช ุจู ุนู ุณูุง  ุจุฒุฑฺฏ ูู ุงุฒ ุทุฑุฒ ุชูฺฉุฑ ุงููุงุทูู ุฏุฑุจุงุฑู  ุนุดู ุฏุฑ ฺฉุชุงุจ ููุณู ุฎูุฏุด ุงุณุชูุงุฏู ฺฉุฑุฏู ุงุณุช ู ฺฉุงููุง ูุงุถุญ ุงุณุช ฺฉู ุงู ุทุฑุฒ ูฺฉุฑ ู ุงูุฏุดู ุฏุฑ ุงุฏุจุงุช ูุงุฑุณ ูู ูููุฏ ูพุฏุง ฺฉุฑุฏู ุงุณุช .\n",
            "ุฎูุงูุฏู ุงู ฺฉุชุงุจ ุจู ุดุฏุช ุชูุตู ู ุดูุฏ.\n",
            "ุจุง ุณูุงู\n",
            "ุงู ฺฉุชุงุจ ูุงูุนุง ฺฉุชุงุจ ุจุณุงุฑ ุชุงุซุฑ ฺฏุฐุงุฑ ูุณุช ุจุฑ ุทุฑูู  ูฺฏุงู ููุณููุงู ู ุนุงุฑูุงู ุณุฑุฒูู ุฎูุฏูุงู ู ุญุช ุจู ุนู ุณูุง  ุจุฒุฑฺฏ ูู ุงุฒ ุทุฑุฒ ุชูฺฉุฑ ุงููุงุทูู ุฏุฑุจุงุฑู  ุนุดู ุฏุฑ ฺฉุชุงุจ ููุณู ุฎูุฏุด ุงุณุชูุงุฏู ฺฉุฑุฏู ุงุณุช ู ฺฉุงููุง ูุงุถุญ ุงุณุช ฺฉู ุงู ุทุฑุฒ ูฺฉุฑ ู ุงูุฏุดู ุฏุฑ ุงุฏุจุงุช ูุงุฑุณ ูู ูููุฏ ูพุฏุง ฺฉุฑุฏู ุงุณุช .\n",
            "ุฎูุงูุฏู ุงู ฺฉุชุงุจ ุจู ุดุฏุช ุชูุตู ู ุดูุฏ.\n",
            "ุณูุงู\n",
            "ูุทูุง ุตูุญู ูุดุฎุตุงุช ฺฉุชุงุจ ุฑู ุฏุงุฎู ฺฉุชุงุจ ุงูฺฉุชุฑููฺฉ ูุฑุงุฑ ุจุฏุฏ! ุณุงู ฺุงูพ ู ูุงุดุฑ ู ูุชุฑุฌู ู ...\n",
            "ุณูุงู\n",
            "ูุทูุง ุตูุญู ูุดุฎุตุงุช ฺฉุชุงุจ ุฑู ุฏุงุฎู ฺฉุชุงุจ ุงูฺฉุชุฑููฺฉ ูุฑุงุฑ ุจุฏุฏ! ุณุงู ฺุงูพ ู ูุงุดุฑ ู ูุชุฑุฌู ู ...\n",
            "\"ฺฏุฒูุด ุงุฏุจุงุช ุขูุฑฺฉุง ูุงุชู ุจู ุงู ุฏูู ุจูุฏ ฺฉู ุฏุฏู ุงู ููุณูุฏฺฏุงู ุณุจฺฉ ู ุญุฑู ุชุงุฒู ุฏุงุฑูุฏ ู ุฏุฑุนูโุญุงู ุดุงุนุฑุงูฺฏ ุณุจฺฉ ู ุณุฎู ุจุนุถโูุงุดุงู ูุซู ููุฆูุชุณ ุง ุขุณุชูุฑุงุณ ู ุฑูุฆุงุจุงุณุชูุณ ูุฑุง ุดูุชู ฺฉุฑุฏ. ุงุฒ ุทุฑู ุฏฺฏุฑ  ุฏูู 1970 ุจู ุจุนุฏ ุบุฑ ุงุฒ ุงุณุชุซูุงุฆุงุช ูุนุฏูุฏุ ุฑุงุณุชุด ฺุฒ ุฏูุฏุงูโฺฏุฑ ุฏุฑ ุงุฏุจุงุช ุบุฑุจ (ุจู ูุนูุง ุงุฑููพุง ุบุฑุจ ู ุงุงูุงุช ูุชุญุฏู) ููโุงูุชู ู ูููุฒ ูู ููโุงุจู.\"ุนุจุฏุง.. ฺฉูุซุฑ\n",
            "ุงุฒ ูุชุฑุฌู ุจู ุฎุงุทุฑ ุชุฑุฌูู ุนุงู ุงุฒ ุงูุชุดุงุฑุงุช ู ุทุงูฺู ูุชุดฺฉุฑู. ุจููุงูู ูุญุจูุจุชุฑู ููุณูุฏู ุฎุงุฑุฌ ูู ูุณุช ู ูุงูุนุง ูุฐุช ุจุฑุฏู.\n",
            "\"ฺฏุฒูุด ุงุฏุจุงุช ุขูุฑฺฉุง ูุงุชู ุจู ุงู ุฏูู ุจูุฏ ฺฉู ุฏุฏู ุงู ููุณูุฏฺฏุงู ุณุจฺฉ ู ุญุฑู ุชุงุฒู ุฏุงุฑูุฏ ู ุฏุฑุนูโุญุงู ุดุงุนุฑุงูฺฏ ุณุจฺฉ ู ุณุฎู ุจุนุถโูุงุดุงู ูุซู ููุฆูุชุณ ุง ุขุณุชูุฑุงุณ ู ุฑูุฆุงุจุงุณุชูุณ ูุฑุง ุดูุชู ฺฉุฑุฏ. ุงุฒ ุทุฑู ุฏฺฏุฑ  ุฏูู 1970 ุจู ุจุนุฏ ุบุฑ ุงุฒ ุงุณุชุซูุงุฆุงุช ูุนุฏูุฏุ ุฑุงุณุชุด ฺุฒ ุฏูุฏุงูโฺฏุฑ ุฏุฑ ุงุฏุจุงุช ุบุฑุจ (ุจู ูุนูุง ุงุฑููพุง ุบุฑุจ ู ุงุงูุงุช ูุชุญุฏู) ููโุงูุชู ู ูููุฒ ูู ููโุงุจู.\"ุนุจุฏุง.. ฺฉูุซุฑ\n",
            "ุงุฒ ูุชุฑุฌู ุจู ุฎุงุทุฑ ุชุฑุฌูู ุนุงู ุงุฒ ุงูุชุดุงุฑุงุช ู ุทุงูฺู ูุชุดฺฉุฑู. ุจููุงูู ูุญุจูุจุชุฑู ููุณูุฏู ุฎุงุฑุฌ ูู ูุณุช ู ูุงูุนุง ูุฐุช ุจุฑุฏู.\n",
            "ููุฏููู ฺุฑุง ุงู ฺฉุชุงุจุง ูุฌูุฒ ูฺฏุฑู. ุงููุง ฺุฒ ุฌุฒ ุฏุฑูุบ ูุจูุฏ. ุฏููุง ุงุตูุง ูฺ ูุนูุง ู ูุงุฏู ุง ูุฏุงุดุช ุจุฏุชุฑู ุฑูุงู ุจูุฏ ฺฉู ุชุง ุงูุขู ุฎููุฏู ุจูุฏู.\n",
            "ููุฏููู ฺุฑุง ุงู ฺฉุชุงุจุง ูุฌูุฒ ูฺฏุฑู. ุงููุง ฺุฒ ุฌุฒ ุฏุฑูุบ ูุจูุฏ. ุฏููุง ุงุตูุง ูฺ ูุนูุง ู ูุงุฏู ุง ูุฏุงุดุช ุจุฏุชุฑู ุฑูุงู ุจูุฏ ฺฉู ุชุง ุงูุขู ุฎููุฏู ุจูุฏู.\n",
            "ูฺ ูุฑู ูุฏุงุฑู ฺฉุชุงุจูุง ูููุชุณ ุจุง ฺู ุชุฑุชุจ ุฎููุฏู ูุดู !  ููุดู ูุทููู ฺฉู ฺฉุชุงุจ ุจุนุฏ ฺฉ ุดุงูฺฉุงุฑ ุฏฺฏู ุณุช ฺฉู ุญุช ุงุฒ ุงูู ุจูุชุฑู!!! ุนุงู. ููููู.\n",
            "ูฺ ูุฑู ูุฏุงุฑู ฺฉุชุงุจูุง ูููุชุณ ุจุง ฺู ุชุฑุชุจ ุฎููุฏู ูุดู !  ููุดู ูุทููู ฺฉู ฺฉุชุงุจ ุจุนุฏ ฺฉ ุดุงูฺฉุงุฑ ุฏฺฏู ุณุช ฺฉู ุญุช ุงุฒ ุงูู ุจูุชุฑู!!! ุนุงู. ููููู.\n",
            "ุฎู ฺฏุฑููู ุจุงุจุงุ ูุดุช ูุฒุงุฑ ุชููู!!! ูุทูุง ุชุฎูู ุจุดุชุฑ ุจุฐุงุฑุฏ. ููููู\n",
            "ุฎู ฺฏุฑููู ุจุงุจุงุ ูุดุช ูุฒุงุฑ ุชููู!!! ูุทูุง ุชุฎูู ุจุดุชุฑ ุจุฐุงุฑุฏ. ููููู\n",
            "ุจููุงุช ูุฒุฎุฑู ู ุญูุตูู ุณุฑ ุจุฑ\n",
            "ุจููุงุช ูุฒุฎุฑู ู ุญูุตูู ุณุฑ ุจุฑ\n",
            "ฺฉุชุงุจ ุฎู ุญูุตูู ุณุฑ ุจุฑ ู ุจู ุฏุฑุฏ ูุฎูุฑูุ ุงุตูุง ุงุฑุฒุด ุฎููุฏู ูุฏุงุฑู\n",
            "ฺฉุชุงุจ ุฎู ุญูุตูู ุณุฑ ุจุฑ ู ุจู ุฏุฑุฏ ูุฎูุฑูุ ุงุตูุง ุงุฑุฒุด ุฎููุฏู ูุฏุงุฑู\n",
            "ุจู ูุธุฑู ูุซุฑ ููุณูุฏู ู ูฺฏุงูุด ุจู ููุงุฌุฑุงู ููุฏ ุฏุฑ  ุงูุฑฺฉุง ุจุณุงุฑ ุนุงู ุงุณุช ู ุงูุจุชู ุชุฑุฌูู ูู ุจุณุงุฑ ุฎูุจ ุงุณุช. ุฏู ุฏุงุณุชุงู ุงูู ุงูุจุชู ุชุตูุฑ ุชูุฎ ุฏุงุดุชูุฏ ู ุดุงุฏ ุงู ุชูุฎ ุฏุฑ ุญูุตูู  ูุฑ ฺฉุณ ูฺฏูุฌุฏ.\n",
            "ุจู ูุธุฑู ูุซุฑ ููุณูุฏู ู ูฺฏุงูุด ุจู ููุงุฌุฑุงู ููุฏ ุฏุฑ  ุงูุฑฺฉุง ุจุณุงุฑ ุนุงู ุงุณุช ู ุงูุจุชู ุชุฑุฌูู ูู ุจุณุงุฑ ุฎูุจ ุงุณุช. ุฏู ุฏุงุณุชุงู ุงูู ุงูุจุชู ุชุตูุฑ ุชูุฎ ุฏุงุดุชูุฏ ู ุดุงุฏ ุงู ุชูุฎ ุฏุฑ ุญูุตูู  ูุฑ ฺฉุณ ูฺฏูุฌุฏ.\n",
            "ุขูุง ูููู ุฌ  ูุฑ ุฏู ฺฉุชุงุจ ุชุฑุฌูู ุง ุงุฒ ฺฉุชุงุจ Unaccustomed earth ูุณุชู \n",
            "ุขูุง ูููู ุฌ  ูุฑ ุฏู ฺฉุชุงุจ ุชุฑุฌูู ุง ุงุฒ ฺฉุชุงุจ Unaccustomed earth ูุณุชู \n",
            "ุงู ุฒูู ูุง ุขุดูุง ูููู ุฎุงฺฉ ุบุฑุจ ูุณุช ฺฉู ุงุฒ ุงูุชุดุงุฑุงุช ูุงู ฺุงูพ ุดุฏู ุ\n",
            "ุงู ุฒูู ูุง ุขุดูุง ูููู ุฎุงฺฉ ุบุฑุจ ูุณุช ฺฉู ุงุฒ ุงูุชุดุงุฑุงุช ูุงู ฺุงูพ ุดุฏู ุ\n",
            "ูฺฉุฑ ูฺฉุฑุฏู ฺฉุชุงุจุง ุฎูุจ ูุฑุงุฑ ูุณุช ุชู ุงู ุทุฑุญ ุจุงุฏ ุ ูู ุจุง ุงู ฺฉุชุงุจ ุซุงุจุช ฺฉุฑุฏุฏ ุงุฒ ุงู ุฎุจุฑุง ูุณุชุ ุงู ฺฉู ุนุงุงุงุงูู (ุงูุจุชู ุงุฒ ฺฉุชุงุจุง ูุจู ุฎุจุฑ ูุฏุงุฑู ฺูู ุชุงุฒู ูุตุจ ฺฉุฑุฏู ุทุงูฺู ุฑู)\n",
            "ูฺฉุฑ ูฺฉุฑุฏู ฺฉุชุงุจุง ุฎูุจ ูุฑุงุฑ ูุณุช ุชู ุงู ุทุฑุญ ุจุงุฏ ุ ูู ุจุง ุงู ฺฉุชุงุจ ุซุงุจุช ฺฉุฑุฏุฏ ุงุฒ ุงู ุฎุจุฑุง ูุณุชุ ุงู ฺฉู ุนุงุงุงุงูู (ุงูุจุชู ุงุฒ ฺฉุชุงุจุง ูุจู ุฎุจุฑ ูุฏุงุฑู ฺูู ุชุงุฒู ูุตุจ ฺฉุฑุฏู ุทุงูฺู ุฑู)\n",
            "ุนุฌุจ ฺฉุชุงุจ ูพุณุฑ!!!ุ ู ุงู ูฅู ุฏุฑุตุฏ ุชุฎูู ุจูุชุฑู ุชุฎูู ุจูุฏู ุชุง ุงูุงู. ุทุงูฺู ูุงุฏุฑุ ุงูู ุฎุฑ ุงุฒ ุฌูููุช ุจุจู ฺฉูพูู. \n",
            "ุนุฌุจ ฺฉุชุงุจ ูพุณุฑ!!!ุ ู ุงู ูฅู ุฏุฑุตุฏ ุชุฎูู ุจูุชุฑู ุชุฎูู ุจูุฏู ุชุง ุงูุงู. ุทุงูฺู ูุงุฏุฑุ ุงูู ุฎุฑ ุงุฒ ุฌูููุช ุจุจู ฺฉูพูู. \n",
            "ูู ุฏุงุณุชุงู ยซููุง ู ฺฉุงุดฺฉ ยป ุฑุง ุฏูุณุช ุฏุงุดุชู.\n",
            "ุณุฑููุดุช ุง ูุชุฌู ุงุนูุงู ูุง  !!!\n",
            "ูู ุฏุงุณุชุงู ยซููุง ู ฺฉุงุดฺฉ ยป ุฑุง ุฏูุณุช ุฏุงุดุชู.\n",
            "ุณุฑููุดุช ุง ูุชุฌู ุงุนูุงู ูุง  !!!\n",
            "ูููุฒ ุงูุงู ฺฉุชุงุจู...ุชุง ุงูุฌุงุด ฺฉู ุฌุฐุงุจ ุจูุฏ. ููููู ุงุฒ ุชุฎูู : )\n",
            "ูููุฒ ุงูุงู ฺฉุชุงุจู...ุชุง ุงูุฌุงุด ฺฉู ุฌุฐุงุจ ุจูุฏ. ููููู ุงุฒ ุชุฎูู : )\n",
            "ฺฉ ูุฌููุนู ุฏุงุณุชุงู ุจ ูุธุฑ... ุงุฒ ุจุฒุฑฺฏ ุชุฑู ููุณูุฏฺฏุงู ฺุงูพู... ฺุงูพู ุฑุง ุฏุฑ ุงู ฺฉุชุงุจ ุจุง ุจุฒุฑฺฏ ุชุฑู ููุณูุฏฺฏุงูุด ููุณูุฑ ุดูุฏ... ฺฉ ุงุฒ ุจูุชุฑู ูุฌููุนู ุฏุงุณุชุงู ูุง ุณุงููุง ุงุฎุฑ.... ุนุงู... ูุงูุนู ุนุงู\n",
            "ฺฉ ูุฌููุนู ุฏุงุณุชุงู ุจ ูุธุฑ... ุงุฒ ุจุฒุฑฺฏ ุชุฑู ููุณูุฏฺฏุงู ฺุงูพู... ฺุงูพู ุฑุง ุฏุฑ ุงู ฺฉุชุงุจ ุจุง ุจุฒุฑฺฏ ุชุฑู ููุณูุฏฺฏุงูุด ููุณูุฑ ุดูุฏ... ฺฉ ุงุฒ ุจูุชุฑู ูุฌููุนู ุฏุงุณุชุงู ูุง ุณุงููุง ุงุฎุฑ.... ุนุงู... ูุงูุนู ุนุงู\n",
            "ุดุงุนู ู ููุด ุฒูุงู\n",
            "ฺฏูุชู ู ุดูุฏ ฺฉู ุฒูุงู ุจุฑุง ุดุงุนู ูพุฑุงฺฉู ุขูุงุฏฺฏ ุฏุงุฑูุฏุ ู ูุฒ ูุฑุถ ุจุฑ ุงู ุงุณุช ฺฉู ุฑูุดููฺฉุฑุงู ูููุงุฑู ุฏุฑุจุงุฑู ุดุงุนุงุช ููุงููุช ู ฺฉููุฏ.\n",
            "ุณุฎู ฺฏูุชู ุฏุฑุจุงุฑู ุฒูุงู ู ุดุงุนูุ ุงูุณุงู ุฑุง ุฏุฑ ูุนุฑุถ ุฎุทุฑ ุงุชูุงู ุชุจุนุถ ู ุบูุทุฏู ุฏุฑ ูุฑุทู  ุฒู ุณุชุฒุ ูุฑุงุฑ ู ุฏูุฏ. ุจุง ุงู ุญุงูุ ุญููุช ุงู ุงุณุช ฺฉู ุฏุฑ ูุฑููฺฏ ูุฑุฏูุ ุฑุงุจุทู ุง ุจู ุฒูุงู ู ุดุงุนู ูุฌูุฏ ุฏุงุฑุฏ. ุฏุฑ ุงู ุฌุง ุงฺฏุฑ ูุชูุงูู ุจู ุงูฺฏุฒู ูุง ุจูพุฑุฏุงุฒูุ ุจู ุฑุดู ู ุชูุงูู.\n",
            "ฺฉููู  ยซ Commerage ยป ุจู ูุนู ยซูพฺ ูพฺยป ุง ุบุจุช ุฏุฑ ููุฑุฏ ุฒูุฏฺฏ ุฎุตูุต ุขุดูุงุงู ู ุฏุฑ ู ููุณุงูุ ุงุฒ ูุงฺู  Commater ูุงุชู ุจู ูุนูุง ูุงุฏุฑ ุฎูุงูุฏู ุขูุฏู ุงุณุช. ฺฉููู  ุงูฺฏูุณ gossip ูุฒ ุจู ููุงู ูุนูุงุ ุฑุดู  ูุดุงุจู ุฏุงุฑุฏ ู ุงุฒ god_sib ุจู ูุนูุง ูุงุฏุฑ ุฎูุงูุฏู ู ุขุฏ.\n",
            "( ุฏุฑ ูุงุฑุณ ูุฒ ุจุง ุงุณุชูุงุฏู ุงุฒ ุงุตุทูุงุญ ยซุญุฑู ูุง ุฎุงูู ุฒูฺฉยป ุจู ุงู ููุน ุญุฑู ูุง ููุช ุฒูุงูู ุฏุงุฏู ุงู. )\n",
            "ุงุญุชูุงูุงูุ ุงูุญุฑุงู ฺฉู ุฏุฑ ููููู ฺฉููู ุงุฌุงุฏ ุดุฏู ุงุณุชุ ุงุฒ ุขู ุฌุง ูุดุฃุช ู ฺฏุฑุฏ ฺฉู ุฑุงุจุทู ูุฒุฏฺฉ ู ฺฏุฑู ุจุง ูุงุฏุฑ ุฎูุงูุฏู  ูุฑุฒูุฏุงู ( ุง ุจุง ุฎุงูู  ูุฑุฒูุฏุงู )ุ ุจุงุนุซ ู ุดุฏ ูุงุฏุฑุงู ุฎูุฏ ุฑุง ูุฌุงุฒ ุจุฏุงููุฏ ฺฉู ุจุง ุขูุงู ูพุฑุงููู ุงุญุณุงุณุงุช ุฎูุฏ ุฏุฑุจุงุฑู  ุงูุฑุงุฏู ูุญุท ุดุงูุ ุณุฎู ุจฺฏููุฏ. ูุชุฎุตุตุงู ุฑุดู ุดูุงุณ ูุบุงุช ุงูฺฏูุณ ุชูุถุญ ุฏุงุฏู ุงูุฏ ฺฉู ุงู ุงูุญุฑุงู ูุงุด ุงุฒ ุจุญุซ ูุง ุจูุฏู ุงุณุช ฺฉู ุฒูุงูุ ููฺฏุงู ฺฏุฑุฏููุง ุฏุฑ ุฎุงูู ฺฉ ุงุฒ ุงููุงูุ ฺฉู ุฏุฑ ุขู ููุฒุงุฏ ูุชููุฏ ู ุดุฏู ุงุณุชุ ูุทุฑุญ ู ฺฉุฑุฏู ุงูุฏ. ุญุช ุงฺฏุฑ ุงู ุชูุถุญู ุฑุดู ุดูุงุฎุช ุตุญุญ ุจุงุดุฏุ ูู ุชูุงูุฏ ุจุฑุง ุจุงุฑ ููู ุง ฺฉู ุงู ุนุจุงุฑุช ุจู ุฎูุฏ ฺฏุฑูุชู ุชูุถุญ ุจุฏูุฏ. ูุจุงุฏ ูุฑุงููุด ฺฉุฑุฏ ฺฉู ุฑูุงุฌ ุงู ููุน ุญุฑู ูุง ุฏุฑ ูุงู ุฒูุงูุ ุฏุฑ ุนู ุญุงู ูุดุงู ุฑูุดู ุงุฒ ููุจุณุชฺฏ ุขูุงู ุงุณุช ุฒุฑุง ุณุฎู ุจุง ุฏฺฏุฑุงู ฺฏูุชู ู ุดูุฏ ูู ุจุง ุฎูุฏ. ุขุง ุฌูุงูุน ูพุฏุฑ ุณุงูุงุฑ ุงุฒ ุงู ููุจุณุชฺฏ ูุงุฎุฑุณูุฏ ุจูุฏู ุงูุฏ ฺฉู ฺูู ูุงู ุจุฑ ุขู ฺฏุฐุงุดุชู ุงูุฏุ ุฏุฑ ุญููุช ุขูุงู ุฒูุงู ุฑุง ุงุฒ ฺฉูู ูุนุงูุช ูุง ุนููู ุญุฐู ฺฉุฑุฏู ุจูุฏูุฏ ู ุฒูุงู ูฺ ุญู ุฑุณู ุจุฑุง ุจุญุซ ูพุฑุงููู ุงููุฑ ุดูุฑ ุฎูุฏ ุฑุง ูุฏุงุดุชูุฏ ูุฐุงุ ุงุฒ ุทุฑู ุงู ููุน ุญุฑู ูุงุ ุขู ฺู ุฑุง ฺฉู ูุฑุฏุงู ุจุฑ ุขู ูุง ุชุญุฑู ฺฉุฑุฏู ุจูุฏูุฏุ ุจู ุฏุณุช ู ุขูุฑุฏูุฏ ู ูู ุชููุง ุฏุฑุจุงุฑู  ฺฉุงุฑ ู ฺฉุณุจ ุดูุฑุ ุจูฺฉู ุฏุฑุจุงุฑู  ูุณุงู ุฎูุดุงูุฏ ุขู ( ุฎูุงู ฺฉุงุฑ ูุงุ ุฌูุงุงุช ู ุบุฑู ) ูุฒ ุตุญุจุช ู ฺฉุฑุฏูุฏ. ุงุฒ ุขู ุฌุง ฺฉู ุงุฒ ุฒูุฏฺฏ ุนููู ูุญุฑูู ุดุฏู ุจูุฏูุฏุ ุฒูุฏฺฏ ุฎุตูุต ุฑุง ุนููู ฺฉุฑุฏูุฏ. ููฺฉู ุงุณุช ุงุฒ ุงู ุฌุง ุนุงุฏุช ุฏุฑุงุฒ ูุฏุช ุฏุฑ ุฒูุงู ูพุฏุฏ ุขูุฏู ุจุงุดุฏ ู ุจู ุดุงุนู ุฎู ฺฏุฑูุชู ุจุงุดูุฏ. ุงูุง ุฏุฑ ูุฑ ุตูุฑุช ุนูุชู ุงุตูุ ุงูุฒูุง ุชุญูู ุจูุฏู ุงุณุช. ููุฑู ูุชูุฌู ุดุฏ ฺฉู ุฏุฑ ุดุงุนู ุชุฌุงุฑุช ุจุฑุฏฺฏุงู ุณูุฏ ุฏุฑ ุดูุฑ ุงูุฑูุฆุงูุ ุฏุฑ ุณุงู 1969ุ ูุฑุฏุงู ุดุงุนู ุฑุง ููพุฐุฑูุชูุฏุ ู ูุชุฌู ฺฏุฑูุช ฺฉู ุงู ูุงุจุงูุฑุ ูุงุด ุงุฒ ุชุฌุฑุจู ูุฑุฏุงู ุงุณุช. ฺฏุฑุงุด ูุฑุฏุงู ุจู ุฌุณุช ู ุฌู ุดูุงูุฏ ุจุด ุชุฑ ุจุฑุง ูพุฐุฑูุชู ฺฉ ุดุงุนู ูุงุด ุงุฒ ุขุฒุงุฏ ุง ุงุณุช ฺฉู ุฏุฑ ูุนุงูุช ูุง ุฎูุฏ ุฏุฑ ุดูุฑุ ุงุฒ ุขู ุจูุฑู ููุฏูุฏุ ุชุง ูุชุฌู  ฺฉ ุฑูุญู ููุชูุฏุงูู ู ุชุญูู ฺฏุฑ.\n",
            "ููุจุน:\n",
            "ฺฉุชุงุจ: ุดุงุนูุ ฺุงู ููุฆู ฺฉุงูพูุฑุฑุ ุฎุฏุงุฏุงุฏ ููููุฑุ ฺุงูพ ุงููุ 1380\n",
            "ุดุงุนู ู ููุด ุฒูุงู\n",
            "ฺฏูุชู ู ุดูุฏ ฺฉู ุฒูุงู ุจุฑุง ุดุงุนู ูพุฑุงฺฉู ุขูุงุฏฺฏ ุฏุงุฑูุฏุ ู ูุฒ ูุฑุถ ุจุฑ ุงู ุงุณุช ฺฉู ุฑูุดููฺฉุฑุงู ูููุงุฑู ุฏุฑุจุงุฑู ุดุงุนุงุช ููุงููุช ู ฺฉููุฏ.\n",
            "ุณุฎู ฺฏูุชู ุฏุฑุจุงุฑู ุฒูุงู ู ุดุงุนูุ ุงูุณุงู ุฑุง ุฏุฑ ูุนุฑุถ ุฎุทุฑ ุงุชูุงู ุชุจุนุถ ู ุบูุทุฏู ุฏุฑ ูุฑุทู  ุฒู ุณุชุฒุ ูุฑุงุฑ ู ุฏูุฏ. ุจุง ุงู ุญุงูุ ุญููุช ุงู ุงุณุช ฺฉู ุฏุฑ ูุฑููฺฏ ูุฑุฏูุ ุฑุงุจุทู ุง ุจู ุฒูุงู ู ุดุงุนู ูุฌูุฏ ุฏุงุฑุฏ. ุฏุฑ ุงู ุฌุง ุงฺฏุฑ ูุชูุงูู ุจู ุงูฺฏุฒู ูุง ุจูพุฑุฏุงุฒูุ ุจู ุฑุดู ู ุชูุงูู.\n",
            "ฺฉููู  ยซ Commerage ยป ุจู ูุนู ยซูพฺ ูพฺยป ุง ุบุจุช ุฏุฑ ููุฑุฏ ุฒูุฏฺฏ ุฎุตูุต ุขุดูุงุงู ู ุฏุฑ ู ููุณุงูุ ุงุฒ ูุงฺู  Commater ูุงุชู ุจู ูุนูุง ูุงุฏุฑ ุฎูุงูุฏู ุขูุฏู ุงุณุช. ฺฉููู  ุงูฺฏูุณ gossip ูุฒ ุจู ููุงู ูุนูุงุ ุฑุดู  ูุดุงุจู ุฏุงุฑุฏ ู ุงุฒ god_sib ุจู ูุนูุง ูุงุฏุฑ ุฎูุงูุฏู ู ุขุฏ.\n",
            "( ุฏุฑ ูุงุฑุณ ูุฒ ุจุง ุงุณุชูุงุฏู ุงุฒ ุงุตุทูุงุญ ยซุญุฑู ูุง ุฎุงูู ุฒูฺฉยป ุจู ุงู ููุน ุญุฑู ูุง ููุช ุฒูุงูู ุฏุงุฏู ุงู. )\n",
            "ุงุญุชูุงูุงูุ ุงูุญุฑุงู ฺฉู ุฏุฑ ููููู ฺฉููู ุงุฌุงุฏ ุดุฏู ุงุณุชุ ุงุฒ ุขู ุฌุง ูุดุฃุช ู ฺฏุฑุฏ ฺฉู ุฑุงุจุทู ูุฒุฏฺฉ ู ฺฏุฑู ุจุง ูุงุฏุฑ ุฎูุงูุฏู  ูุฑุฒูุฏุงู ( ุง ุจุง ุฎุงูู  ูุฑุฒูุฏุงู )ุ ุจุงุนุซ ู ุดุฏ ูุงุฏุฑุงู ุฎูุฏ ุฑุง ูุฌุงุฒ ุจุฏุงููุฏ ฺฉู ุจุง ุขูุงู ูพุฑุงููู ุงุญุณุงุณุงุช ุฎูุฏ ุฏุฑุจุงุฑู  ุงูุฑุงุฏู ูุญุท ุดุงูุ ุณุฎู ุจฺฏููุฏ. ูุชุฎุตุตุงู ุฑุดู ุดูุงุณ ูุบุงุช ุงูฺฏูุณ ุชูุถุญ ุฏุงุฏู ุงูุฏ ฺฉู ุงู ุงูุญุฑุงู ูุงุด ุงุฒ ุจุญุซ ูุง ุจูุฏู ุงุณุช ฺฉู ุฒูุงูุ ููฺฏุงู ฺฏุฑุฏููุง ุฏุฑ ุฎุงูู ฺฉ ุงุฒ ุงููุงูุ ฺฉู ุฏุฑ ุขู ููุฒุงุฏ ูุชููุฏ ู ุดุฏู ุงุณุชุ ูุทุฑุญ ู ฺฉุฑุฏู ุงูุฏ. ุญุช ุงฺฏุฑ ุงู ุชูุถุญู ุฑุดู ุดูุงุฎุช ุตุญุญ ุจุงุดุฏุ ูู ุชูุงูุฏ ุจุฑุง ุจุงุฑ ููู ุง ฺฉู ุงู ุนุจุงุฑุช ุจู ุฎูุฏ ฺฏุฑูุชู ุชูุถุญ ุจุฏูุฏ. ูุจุงุฏ ูุฑุงููุด ฺฉุฑุฏ ฺฉู ุฑูุงุฌ ุงู ููุน ุญุฑู ูุง ุฏุฑ ูุงู ุฒูุงูุ ุฏุฑ ุนู ุญุงู ูุดุงู ุฑูุดู ุงุฒ ููุจุณุชฺฏ ุขูุงู ุงุณุช ุฒุฑุง ุณุฎู ุจุง ุฏฺฏุฑุงู ฺฏูุชู ู ุดูุฏ ูู ุจุง ุฎูุฏ. ุขุง ุฌูุงูุน ูพุฏุฑ ุณุงูุงุฑ ุงุฒ ุงู ููุจุณุชฺฏ ูุงุฎุฑุณูุฏ ุจูุฏู ุงูุฏ ฺฉู ฺูู ูุงู ุจุฑ ุขู ฺฏุฐุงุดุชู ุงูุฏุ ุฏุฑ ุญููุช ุขูุงู ุฒูุงู ุฑุง ุงุฒ ฺฉูู ูุนุงูุช ูุง ุนููู ุญุฐู ฺฉุฑุฏู ุจูุฏูุฏ ู ุฒูุงู ูฺ ุญู ุฑุณู ุจุฑุง ุจุญุซ ูพุฑุงููู ุงููุฑ ุดูุฑ ุฎูุฏ ุฑุง ูุฏุงุดุชูุฏ ูุฐุงุ ุงุฒ ุทุฑู ุงู ููุน ุญุฑู ูุงุ ุขู ฺู ุฑุง ฺฉู ูุฑุฏุงู ุจุฑ ุขู ูุง ุชุญุฑู ฺฉุฑุฏู ุจูุฏูุฏุ ุจู ุฏุณุช ู ุขูุฑุฏูุฏ ู ูู ุชููุง ุฏุฑุจุงุฑู  ฺฉุงุฑ ู ฺฉุณุจ ุดูุฑุ ุจูฺฉู ุฏุฑุจุงุฑู  ูุณุงู ุฎูุดุงูุฏ ุขู ( ุฎูุงู ฺฉุงุฑ ูุงุ ุฌูุงุงุช ู ุบุฑู ) ูุฒ ุตุญุจุช ู ฺฉุฑุฏูุฏ. ุงุฒ ุขู ุฌุง ฺฉู ุงุฒ ุฒูุฏฺฏ ุนููู ูุญุฑูู ุดุฏู ุจูุฏูุฏุ ุฒูุฏฺฏ ุฎุตูุต ุฑุง ุนููู ฺฉุฑุฏูุฏ. ููฺฉู ุงุณุช ุงุฒ ุงู ุฌุง ุนุงุฏุช ุฏุฑุงุฒ ูุฏุช ุฏุฑ ุฒูุงู ูพุฏุฏ ุขูุฏู ุจุงุดุฏ ู ุจู ุดุงุนู ุฎู ฺฏุฑูุชู ุจุงุดูุฏ. ุงูุง ุฏุฑ ูุฑ ุตูุฑุช ุนูุชู ุงุตูุ ุงูุฒูุง ุชุญูู ุจูุฏู ุงุณุช. ููุฑู ูุชูุฌู ุดุฏ ฺฉู ุฏุฑ ุดุงุนู ุชุฌุงุฑุช ุจุฑุฏฺฏุงู ุณูุฏ ุฏุฑ ุดูุฑ ุงูุฑูุฆุงูุ ุฏุฑ ุณุงู 1969ุ ูุฑุฏุงู ุดุงุนู ุฑุง ููพุฐุฑูุชูุฏุ ู ูุชุฌู ฺฏุฑูุช ฺฉู ุงู ูุงุจุงูุฑุ ูุงุด ุงุฒ ุชุฌุฑุจู ูุฑุฏุงู ุงุณุช. ฺฏุฑุงุด ูุฑุฏุงู ุจู ุฌุณุช ู ุฌู ุดูุงูุฏ ุจุด ุชุฑ ุจุฑุง ูพุฐุฑูุชู ฺฉ ุดุงุนู ูุงุด ุงุฒ ุขุฒุงุฏ ุง ุงุณุช ฺฉู ุฏุฑ ูุนุงูุช ูุง ุฎูุฏ ุฏุฑ ุดูุฑุ ุงุฒ ุขู ุจูุฑู ููุฏูุฏุ ุชุง ูุชุฌู  ฺฉ ุฑูุญู ููุชูุฏุงูู ู ุชุญูู ฺฏุฑ.\n",
            "ููุจุน:\n",
            "ฺฉุชุงุจ: ุดุงุนูุ ฺุงู ููุฆู ฺฉุงูพูุฑุฑุ ุฎุฏุงุฏุงุฏ ููููุฑุ ฺุงูพ ุงููุ 1380\n",
            "ููุด ุดุงุนู ูพุฑุงฺฉู ู ุธุฑู ุดุณุชู ุฏุฑ ุทูู ุนูุฑ ุฒูุงู\n",
            "ุฎุงููยุงุณุชูุงู ุจุฑุงูู ุงุฒ ุฏุงูุดฺฏุงู ูุดฺฏุงู ุ ุฑุงุฌุน ุจู ุงุซุฑุงุช ูุซุจุช ยซุธุฑู ุดุณุชู ุฎุงููโูุง ุจุง ููยป ู ยซฺฏูพ ุฒุฏู ู ุดุงุนูโูพุฑุฏุงุฒ ุจโุฎุทุฑยป ุจุฑ ุฑู ยซุงูุฒุงุด ุทูู ุนูุฑ ุฎุงููโูุงยป ูุทุงูุนู ุง ฺฉุฑุฏู ู ููุงูู ุง ุงุฑุงุฆู ุฏุงุฏู ฺฉู ุฎูุงุตู ุง ุงุฒ ุงูู ุฑุง ุงุฒ ุณุงุช ุงุณุชุงุฏ ูุญูุฏุฑุถุง ุดุนุจุงูุนู ุงูุฌุง ูุฒุงุฑู.\n",
            "โ ุงูฺฉู ยซฺฉูฺฉ ฺฉุฑุฏู ุจู ุฏฺฏุฑุงูยป ู ยซุงูุฌุงู ุฑูุชุงุฑูุง ฺฉู ุญุณ ุฏูุณุช ู ูุฒุฏฺฉ ูุง ุจู ุงุทุฑุงูุงู ุฑุง ุชููุช ูโฺฉูุฏยป ููุฌุจ ุชุฑุดุญ ุจุดุชุฑยูพุฑูฺุณุชุฑููยูโุดูุฏ.\n",
            "โ ุงูฺฉู ฺฉยุงุฒ ุฎุงุตุชโูุง ูุซุจุช ุดุงุนู ูพุฑุฏุงุฒ ู ุดุงุนู ูพุฑุงฺฉู ุฏุฑ ฺฉูุงุฑ ุงุซุฑุงุช ููู ุขูุ ุงุฌุงุฏ ยซุงุญุณุงุณ ุฏูุณุชยป ู ยซูพููุฏ ุจุดุชุฑยป ุจู ุดูููุฏู ู ฺฏููุฏูโ ุดุงุนู ุงุณุช ฺฉู ุงู ยซุงุญุณุงุณ ูุฒุฏฺฉ ู ูพููุฏยป ุชุฑุดุญ ููุฑููู ูพุฑูฺุณุชุฑูู ุฑุง ุงูุฒุงุด ุฏุงุฏู ู ููุฌุจ ฺฉุงูุด ยซุงุถุทุฑุงุจ ู ุงุณุชุฑุณยป ุฏุฑ ุฒูุงู ูโฺฏุฑุฏุฏ.\n",
            "โ ุงูฺฉู ุจุญุซ ฺฉุฑุฏู ุฑู ุดุงุนูโูุง ู ูพุดุช ุณุฑ ุฏฺฏุฑุงูุ ุฏุฑ ููุฑุฏ ุฒูุงู ูโุชูุงูุฏ ููุฌุจ ุทูู ุนูุฑ ุดูุฏ ุงูุง ุฏุฑ ููุฑุฏ ูุฑุฏุงูุ ฺูู ุงุซุฑ ูุฏุงุฑุฏ ู ุญุช ููุฌุจ ุงูุฒุงุด ุงุณุชุฑุณ ู ุงุถุทุฑุงุจ ูโุดูุฏ. ุจู ุฏูู ุงูฺฉู ุจุฑ ุฎูุงู ุฒูุงูุ ฺฉู ุชุนุฑู ฺฉ ุฎุจุฑ (ุจู ููู ูุง ุฎุงูู ุฒูฺฉ)โ ุจุดุชุฑ ุงุฒ ุงุตู ุฎุจุฑ ุจู ูุนูุง ุงุนูุงู ุฏูุณุช ุจุง ุทุฑู ููุงุจู ุงุณุช (ุขููุฏุฑ ุฏูุณุชุช ุฏุงุฑู ฺฉู ุงูุงู ุจู ุชู ฺฉ ุฎุจุฑ ุฎู ุฌุงูุจ ุฑุงุฌุน ุจู ููุงู ูโฺฏูู!) ุฏุฑ ููุฑุฏ ูุฑุฏุงูุ ุชุนุฑู ุดุงุนู โ ุฎุตูุตุงู ุฏุฑ ูุญุท ฺฉุงุฑ โ ุนูููุงู ุจุฎุด ุงุฒุฑูุชุงุฑูุง ุณุงุณยุงุณุชยฺฉู ุจุฑุง ุทุฑู ููุงุจู ฺฉ ูุนูุง ุฏุงุฑุฏ: ยซุจุฏุจุฎุช! ุจุจู ฺู ุฎุจุฑูุง ุฑุง ุฏุงุฑู ฺฉู ุชู ูุฏุงุฑ! ูู ุฎู ููู ุชุฑ ู ูุทูุนโุชุฑ ุงุฒ ุชู ูุณุชู!ยป. ุจู ููู ุฏูู ูุฑุฏูุง ุฏุฑ ุดุงุนู ูพุฑุงฺฉู ุงุฒ ยซุทูู ุนูุฑ ุฎูุฏยป ูุฒูู ูโฺฉููุฏ!\n",
            "ููุด ุดุงุนู ูพุฑุงฺฉู ู ุธุฑู ุดุณุชู ุฏุฑ ุทูู ุนูุฑ ุฒูุงู\n",
            "ุฎุงููยุงุณุชูุงู ุจุฑุงูู ุงุฒ ุฏุงูุดฺฏุงู ูุดฺฏุงู ุ ุฑุงุฌุน ุจู ุงุซุฑุงุช ูุซุจุช ยซุธุฑู ุดุณุชู ุฎุงููโูุง ุจุง ููยป ู ยซฺฏูพ ุฒุฏู ู ุดุงุนูโูพุฑุฏุงุฒ ุจโุฎุทุฑยป ุจุฑ ุฑู ยซุงูุฒุงุด ุทูู ุนูุฑ ุฎุงููโูุงยป ูุทุงูุนู ุง ฺฉุฑุฏู ู ููุงูู ุง ุงุฑุงุฆู ุฏุงุฏู ฺฉู ุฎูุงุตู ุง ุงุฒ ุงูู ุฑุง ุงุฒ ุณุงุช ุงุณุชุงุฏ ูุญูุฏุฑุถุง ุดุนุจุงูุนู ุงูุฌุง ูุฒุงุฑู.\n",
            "โ ุงูฺฉู ยซฺฉูฺฉ ฺฉุฑุฏู ุจู ุฏฺฏุฑุงูยป ู ยซุงูุฌุงู ุฑูุชุงุฑูุง ฺฉู ุญุณ ุฏูุณุช ู ูุฒุฏฺฉ ูุง ุจู ุงุทุฑุงูุงู ุฑุง ุชููุช ูโฺฉูุฏยป ููุฌุจ ุชุฑุดุญ ุจุดุชุฑยูพุฑูฺุณุชุฑููยูโุดูุฏ.\n",
            "โ ุงูฺฉู ฺฉยุงุฒ ุฎุงุตุชโูุง ูุซุจุช ุดุงุนู ูพุฑุฏุงุฒ ู ุดุงุนู ูพุฑุงฺฉู ุฏุฑ ฺฉูุงุฑ ุงุซุฑุงุช ููู ุขูุ ุงุฌุงุฏ ยซุงุญุณุงุณ ุฏูุณุชยป ู ยซูพููุฏ ุจุดุชุฑยป ุจู ุดูููุฏู ู ฺฏููุฏูโ ุดุงุนู ุงุณุช ฺฉู ุงู ยซุงุญุณุงุณ ูุฒุฏฺฉ ู ูพููุฏยป ุชุฑุดุญ ููุฑููู ูพุฑูฺุณุชุฑูู ุฑุง ุงูุฒุงุด ุฏุงุฏู ู ููุฌุจ ฺฉุงูุด ยซุงุถุทุฑุงุจ ู ุงุณุชุฑุณยป ุฏุฑ ุฒูุงู ูโฺฏุฑุฏุฏ.\n",
            "โ ุงูฺฉู ุจุญุซ ฺฉุฑุฏู ุฑู ุดุงุนูโูุง ู ูพุดุช ุณุฑ ุฏฺฏุฑุงูุ ุฏุฑ ููุฑุฏ ุฒูุงู ูโุชูุงูุฏ ููุฌุจ ุทูู ุนูุฑ ุดูุฏ ุงูุง ุฏุฑ ููุฑุฏ ูุฑุฏุงูุ ฺูู ุงุซุฑ ูุฏุงุฑุฏ ู ุญุช ููุฌุจ ุงูุฒุงุด ุงุณุชุฑุณ ู ุงุถุทุฑุงุจ ูโุดูุฏ. ุจู ุฏูู ุงูฺฉู ุจุฑ ุฎูุงู ุฒูุงูุ ฺฉู ุชุนุฑู ฺฉ ุฎุจุฑ (ุจู ููู ูุง ุฎุงูู ุฒูฺฉ)โ ุจุดุชุฑ ุงุฒ ุงุตู ุฎุจุฑ ุจู ูุนูุง ุงุนูุงู ุฏูุณุช ุจุง ุทุฑู ููุงุจู ุงุณุช (ุขููุฏุฑ ุฏูุณุชุช ุฏุงุฑู ฺฉู ุงูุงู ุจู ุชู ฺฉ ุฎุจุฑ ุฎู ุฌุงูุจ ุฑุงุฌุน ุจู ููุงู ูโฺฏูู!) ุฏุฑ ููุฑุฏ ูุฑุฏุงูุ ุชุนุฑู ุดุงุนู โ ุฎุตูุตุงู ุฏุฑ ูุญุท ฺฉุงุฑ โ ุนูููุงู ุจุฎุด ุงุฒุฑูุชุงุฑูุง ุณุงุณยุงุณุชยฺฉู ุจุฑุง ุทุฑู ููุงุจู ฺฉ ูุนูุง ุฏุงุฑุฏ: ยซุจุฏุจุฎุช! ุจุจู ฺู ุฎุจุฑูุง ุฑุง ุฏุงุฑู ฺฉู ุชู ูุฏุงุฑ! ูู ุฎู ููู ุชุฑ ู ูุทูุนโุชุฑ ุงุฒ ุชู ูุณุชู!ยป. ุจู ููู ุฏูู ูุฑุฏูุง ุฏุฑ ุดุงุนู ูพุฑุงฺฉู ุงุฒ ยซุทูู ุนูุฑ ุฎูุฏยป ูุฒูู ูโฺฉููุฏ!\n",
            "ูุดูฺฏ\n",
            "ูุดูฺฏ\n",
            "ุฏุฑ ุงู ฺฉุชุงุจ ุฎุตูุตุงุช ฺฉ ูุนูู ุจู ุนููุงู ฺฉ ุงูุณุงู ู ูู ููุท ฺุฑุฎ ุฏูุฏู ุง ุฏุฑ ูุงุดู ุขููุฒุด ูฺฏุงู ู ุดูุฏ ู ุจู ฺฉูฺฺฉุชุฑู ูุดฺฉูุงุช ฺฉู ููฺฉู ุงุณุช ุฏุฑ ุทูู ุนูุฑ ุชุฏุฑุณ ุฎูุฏ ุจุง ุขู ููุงุฌู ุดูุฏ ู ูพุฑุฏุงุฒุฏ ู ุฑุงู ูุง ูุฎุชูู ุจุฑุง ุฑูุง ุงุฒ ุขู ูุง ุฐฺฉุฑ ู ฺฉูุฏ.\n",
            "โข\n",
            "ูู ุฎูุฏู ุตุฑูุง ูู ุจู ุฎุงุทุฑ ุงูฺฉู ุจู ูุนูู ุนูุงูู ุฏุงุดุชู ุจุงุดู ุงู ฺฉุชุงุจ ุฑู ุฎููุฏู ุจูฺฉู ุจุฎุงุทุฑ ุงูฺฉู ุจุชููู ุจู ูุดฺฉูุงุช ฺฉู ุฏุฑ ุณุฑ ุฑุงู ุงู ุดุบู ูุฑุงุฑ ุฏุงุฑู ูพ ุจุจุฑู ู ุจุง ุฏุฏ ูุณุน ุชุฑ ุจู ููุฏ ูุนููุงู ุฎูุฏู ุจูพุฑุฏุงุฒู๐๐๐\n",
            "ุจู ุงูุฏ ุชุบุฑ ุงุณุงุณ ู ูุซุจุช ุฏุฑ ูุธุงู ุขููุฒุด ู ูพุฑูุฑุด ุงููู๐๐ท\n",
            "ุฏุฑ ุงู ฺฉุชุงุจ ุฎุตูุตุงุช ฺฉ ูุนูู ุจู ุนููุงู ฺฉ ุงูุณุงู ู ูู ููุท ฺุฑุฎ ุฏูุฏู ุง ุฏุฑ ูุงุดู ุขููุฒุด ูฺฏุงู ู ุดูุฏ ู ุจู ฺฉูฺฺฉุชุฑู ูุดฺฉูุงุช ฺฉู ููฺฉู ุงุณุช ุฏุฑ ุทูู ุนูุฑ ุชุฏุฑุณ ุฎูุฏ ุจุง ุขู ููุงุฌู ุดูุฏ ู ูพุฑุฏุงุฒุฏ ู ุฑุงู ูุง ูุฎุชูู ุจุฑุง ุฑูุง ุงุฒ ุขู ูุง ุฐฺฉุฑ ู ฺฉูุฏ.\n",
            "โข\n",
            "ูู ุฎูุฏู ุตุฑูุง ูู ุจู ุฎุงุทุฑ ุงูฺฉู ุจู ูุนูู ุนูุงูู ุฏุงุดุชู ุจุงุดู ุงู ฺฉุชุงุจ ุฑู ุฎููุฏู ุจูฺฉู ุจุฎุงุทุฑ ุงูฺฉู ุจุชููู ุจู ูุดฺฉูุงุช ฺฉู ุฏุฑ ุณุฑ ุฑุงู ุงู ุดุบู ูุฑุงุฑ ุฏุงุฑู ูพ ุจุจุฑู ู ุจุง ุฏุฏ ูุณุน ุชุฑ ุจู ููุฏ ูุนููุงู ุฎูุฏู ุจูพุฑุฏุงุฒู\n",
            "ุจู ุงูุฏ ุชุบุฑ ุงุณุงุณ ู ูุซุจุช ุฏุฑ ูุธุงู ุขููุฒุด ู ูพุฑูุฑุด ุงููู\n",
            "ุขุง ุจุฑุง ุฏุงูุด ุขููุฒุงู ูุฒ ฺฉุชุงุจ ฺฏุฑุงู ุจูุง ุงุณุชุุ!!!\n",
            "ุขุง ุจุฑุง ุฏุงูุด ุขููุฒุงู ูุฒ ฺฉุชุงุจ ฺฏุฑุงู ุจูุง ุงุณุชุุ!!!\n",
            "ุจุฑุง ูุนููุงู ฺฉุชุงุจ ุงุฑุฒุดููุฏ ุงุณุช\n",
            "ุจุฑุง ูุนููุงู ฺฉุชุงุจ ุงุฑุฒุดููุฏ ุงุณุช\n",
            "ูพุชุฑ ฺฉุฑ ุนุงูู...\n",
            "ูพุชุฑ ฺฉุฑ ุนุงูู...\n",
            "ููุช ุงุฏ ุทูุท ฺฉ ุงุฒ ุฑุงูุงู ุฑูุงู ู ุงูุชูุ ุฏูู ู ุฎูุงุณุช ุฏุฑ ุฑฺฉุงุจ ุงูฺฉุณ ุฏู ุชูฺฉูู ุจุงุดู. ุฑูุงู ุนุงู ุจุง ุชุฑุฌูู ุง ุฎูุจ. ุงุฒ ููุณูุฏู ุง ุจุฒุฑฺฏ. ุฒูุฏู ุจุงุฏ ูพุชุฑ ฺฉุฑ.\n",
            "ููุช ุงุฏ ุทูุท ฺฉ ุงุฒ ุฑุงูุงู ุฑูุงู ู ุงูุชูุ ุฏูู ู ุฎูุงุณุช ุฏุฑ ุฑฺฉุงุจ ุงูฺฉุณ ุฏู ุชูฺฉูู ุจุงุดู. ุฑูุงู ุนุงู ุจุง ุชุฑุฌูู ุง ุฎูุจ. ุงุฒ ููุณูุฏู ุง ุจุฒุฑฺฏ. ุฒูุฏู ุจุงุฏ ูพุชุฑ ฺฉุฑ.\n",
            "ูฺฉุฑ ู ฺฉูู ููุณูุฏู  ุงุณุช ฺฉู ููู ุฏู ุณู ุณุงู ุขูุฏู ุจู ุด ููุจู ุจุฏููุฏ...\n",
            "ุฌุง ุฎูุด ููุช ุงุณุช ฺฉู ููุณูุฏู  ฺฉู ุฏู ุชุง ุจูฺฉุฑ ุฏุฑ ฺฉุงุฑูุงูู ุงุฏุจ ุด ุฏุงุฑู ูู ุจุงูุงุฎุฑู ุจู ูุงุฑุณ ุชุฑุฌูู ุดุฏู...\n",
            "ูพุชุฑ ฺฉุฑ ุฏุฑ  ุงูุฏ ุจู ุงุฑุงูุ ุงูุง ุฎูุด ุงูุฏ... ูพุชุฑ ฺฉุฑ ุจู ููู ูพู ุขุณุชุฑุ ุฎุฏุง ูุตู ฺฏู ุงุณุช...\n",
            "ูฺฉุฑ ู ฺฉูู ููุณูุฏู  ุงุณุช ฺฉู ููู ุฏู ุณู ุณุงู ุขูุฏู ุจู ุด ููุจู ุจุฏููุฏ...\n",
            "ุฌุง ุฎูุด ููุช ุงุณุช ฺฉู ููุณูุฏู  ฺฉู ุฏู ุชุง ุจูฺฉุฑ ุฏุฑ ฺฉุงุฑูุงูู ุงุฏุจ ุด ุฏุงุฑู ูู ุจุงูุงุฎุฑู ุจู ูุงุฑุณ ุชุฑุฌูู ุดุฏู...\n",
            "ูพุชุฑ ฺฉุฑ ุฏุฑ  ุงูุฏ ุจู ุงุฑุงูุ ุงูุง ุฎูุด ุงูุฏ... ูพุชุฑ ฺฉุฑ ุจู ููู ูพู ุขุณุชุฑุ ุฎุฏุง ูุตู ฺฏู ุงุณุช...\n",
            "ูพุชุฑ ฺฉุฑ ุนุงู ุงุณุช.... ูุซุฑุด ุนุงู... ูุตู ุด ุนุงู... ููุณูุฏู  ุจู ุงู ุจุฒุฑฺฏ ฺฉู ูุชุงุณูุงูู ุณุงููุง ูุบููู ูุงูุฏู ุจูุฏ ุฏุฑ ุงุฑุงู... ุฎูุดุจุฎุชุงูู ุญุงูุง ูพุชุฑ ฺฉุฑ ุฑุง ุฏุงุฑู ู ูุฐุช ุฎูุงูุด ุงู ุฑุง ูู ุญุงูุง ุฏุงุฑู.... ุชุจุฑฺฉ ุจู ุฎูุฏูุงู\n",
            "ูพุชุฑ ฺฉุฑ ุนุงู ุงุณุช.... ูุซุฑุด ุนุงู... ูุตู ุด ุนุงู... ููุณูุฏู  ุจู ุงู ุจุฒุฑฺฏ ฺฉู ูุชุงุณูุงูู ุณุงููุง ูุบููู ูุงูุฏู ุจูุฏ ุฏุฑ ุงุฑุงู... ุฎูุดุจุฎุชุงูู ุญุงูุง ูพุชุฑ ฺฉุฑ ุฑุง ุฏุงุฑู ู ูุฐุช ุฎูุงูุด ุงู ุฑุง ูู ุญุงูุง ุฏุงุฑู.... ุชุจุฑฺฉ ุจู ุฎูุฏูุงู\n",
            "ุงุฒ ุงูุฏูุง ุงุตู ููุจู\n",
            "ุงุฒ ุงูุฏูุง ุงุตู ููุจู\n",
            "ุทุงูฺู, ูุฑ ุฑูุฒ ุจูุชุฑ ุงุฒ ุฏุฑูุฒ\n",
            "ููููู ุทุงูฺู\n",
            "ฺฉุชุงุจูุง ููุฒู ุฑู ูู ุจุงุฑู ูุทูุง\n",
            "ุทุงูฺู, ูุฑ ุฑูุฒ ุจูุชุฑ ุงุฒ ุฏุฑูุฒ\n",
            "ููููู ุทุงูฺู\n",
            "ฺฉุชุงุจูุง ููุฒู ุฑู ูู ุจุงุฑู ูุทูุง\n",
            "ุนุงูู ูุทูุง ุฌูุฏ ูพุดุช ูุฌูู ูู ุจุฒุงุฑุฏ ููููู ูุดู&\n",
            "ุนุงูู ูุทูุง ุฌูุฏ ูพุดุช ูุฌูู ูู ุจุฒุงุฑุฏ ููููู ูุดู&\n",
            "ุฏฺฉุชุฑ ููุตูุฑ ููู ุงูุนุงุฏู ุณุ ุงู ฺฉุงุฑุด ุฎุฏูุช ุจู ูุฌูู ฺฉุดูุฑ ุจูุฏู ู ูุณุช\n",
            "ุฏฺฉุชุฑ ููุตูุฑ ููู ุงูุนุงุฏู ุณุ ุงู ฺฉุงุฑุด ุฎุฏูุช ุจู ูุฌูู ฺฉุดูุฑ ุจูุฏู ู ูุณุช\n",
            "ุนุงูู.\n",
            "ุนุงูู.\n",
            "ุฎู ูููููุ ูู ุงฺฏู ุชูุณู ุจูุฏ ุจู ุตูุฑุช ุฌุฒุก ุจู ุฌุฒุก ูู ุฏุงุดุช ุจูุชุฑ ูุดุฏ.\n",
            "ุฎู ูููููุ ูู ุงฺฏู ุชูุณู ุจูุฏ ุจู ุตูุฑุช ุฌุฒุก ุจู ุฌุฒุก ูู ุฏุงุดุช ุจูุชุฑ ูุดุฏ.\n",
            "ุงุฒุงูุชุดุงุฑ ูุฑุขู ูุงูุนุง ูููููู ุฎู ุจุงุงุฑุฒุดู ูู ุง ฺฉุงุด ูุดุฏ ูุงููุง ูพ ุฏ ุงู ูุฌุงู ุฑู ฺฉูพ ฺฉุฑุฏ ฺฉู ุจุฑุง ููุดู ุฏุงุดุชู ุจุงุดู\n",
            "ุงุฒุงูุชุดุงุฑ ูุฑุขู ูุงูุนุง ูููููู ุฎู ุจุงุงุฑุฒุดู ูู ุง ฺฉุงุด ูุดุฏ ูุงููุง ูพ ุฏ ุงู ูุฌุงู ุฑู ฺฉูพ ฺฉุฑุฏ ฺฉู ุจุฑุง ููุดู ุฏุงุดุชู ุจุงุดู\n",
            "ูุณุจุช ุจู ุจูู ุจูุชุฑู\n",
            "ูุณุจุช ุจู ุจูู ุจูุชุฑู\n",
            "๐ุงููู ุนุฌู ูููฺฉ ุงููุฑุฌ ๐\n",
            "ุงููู ุนุฌู ูููฺฉ ุงููุฑุฌ \n",
            "ูุงูุนุง ูุดูฺฏ ุจูุฏ\n",
            "ูุงูุนุง ูุดูฺฏ ุจูุฏ\n",
            "ุฌุงูู ูุฏุง ูุฑุขู\n",
            "ุฌุงูู ูุฏุง ูุฑุขู\n",
            "ุจุงุฏ ููฺฏุงู ูุทุงูุนู ูุถู ุฏุงุดุชุ\n",
            "ุจุงุฏ ููฺฏุงู ูุทุงูุนู ูุถู ุฏุงุดุชุ\n",
            "ุฌุงู ูู ูุฏุง ูุฑุขู\n",
            "ุฌุงู ูู ูุฏุง ูุฑุขู\n",
            "ุงุฒ ููู ููุณูุฏู ุฏุฑ ุทุงูฺู ุณู ฺฉุชุงุจ ุฏฺฏุฑ ููุชุดุฑ ุดุฏู ุงูุง ุงุณู ุช ูุงุฑู ุงฺฉุฑ ุจูโฺฏููู ุฏฺฏุฑ ููุดุชู ุดุฏู ฺฉู ุงูุฏูุงุฑู ูุฑุงุด ุจุดู.\n",
            "ุงุฒ ููู ููุณูุฏู ุฏุฑ ุทุงูฺู ุณู ฺฉุชุงุจ ุฏฺฏุฑ ููุชุดุฑ ุดุฏู ุงูุง ุงุณู ุช ูุงุฑู ุงฺฉุฑ ุจูโฺฏููู ุฏฺฏุฑ ููุดุชู ุดุฏู ฺฉู ุงูุฏูุงุฑู ูุฑุงุด ุจุดู.\n",
            "ุจู ูุธุฑู ุจุดุชุฑ ุชุจูุบ ููุงุด ูุงุดู.\n",
            "ฺฉุชุงุจ ุจุฑุชุฑ ุฎูู ุง ููุช ุนุงุฏุช ูุฑุฏูุงู ูููู ุง ุดุงุฏ ุญูู ฺฉุงุฑุจุฑุฏ ุชุฑ ูุณุชูุฏ.\n",
            "ุจู ูุธุฑู ุจุดุชุฑ ุชุจูุบ ููุงุด ูุงุดู.\n",
            "ฺฉุชุงุจ ุจุฑุชุฑ ุฎูู ุง ููุช ุนุงุฏุช ูุฑุฏูุงู ูููู ุง ุดุงุฏ ุญูู ฺฉุงุฑุจุฑุฏ ุชุฑ ูุณุชูุฏ.\n",
            "ุญุณ ุฎูุจ ุจู ุขุฏู ูุฏูุ ูููุฒ ุชูููุด ูฺฉุฑุฏู\n",
            "ฺฉุณุง ฺฉู ุฎููุฏู ุชููุณุชู ูพูู ุฏุฑ ุจุงุฑูุ!\n",
            "ุญุณ ุฎูุจ ุจู ุขุฏู ูุฏูุ ูููุฒ ุชูููุด ูฺฉุฑุฏู\n",
            "ฺฉุณุง ฺฉู ุฎููุฏู ุชููุณุชู ูพูู ุฏุฑ ุจุงุฑูุ!\n",
            "ุงฺฏุฑ ุฏุฑ ุงุจุชุฏุง ูุณุฑ ููููุช ูุณุชุฏ ู ุชุง ุจุญุงู ฺฉุชุงุจ ูุฎููุฏุฏุ ุฎููุฏูุด ุจุฑุง ฑ ุจุงุฑ ุฎุงู ุงุฒ ูุทู ูุณุช. ูู ุงฺฏุฑ ฺฉุชุงุจ ูุง ุจูุชุฑ ุฎููุฏุฏ ุจุง ูุฎููุฏูุด ฺุฒ ุงุณุช ุฏุณุช ููุฏุฏ.\n",
            "ุงฺฏุฑ ุฏุฑ ุงุจุชุฏุง ูุณุฑ ููููุช ูุณุชุฏ ู ุชุง ุจุญุงู ฺฉุชุงุจ ูุฎููุฏุฏุ ุฎููุฏูุด ุจุฑุง ฑ ุจุงุฑ ุฎุงู ุงุฒ ูุทู ูุณุช. ูู ุงฺฏุฑ ฺฉุชุงุจ ูุง ุจูุชุฑ ุฎููุฏุฏ ุจุง ูุฎููุฏูุด ฺุฒ ุงุณุช ุฏุณุช ููุฏุฏ.\n",
            "ฺฉุชุงุจ ฺฉู ูุฑ ฺฉุณ ุญุฏุงูู ฺฉ ุจุงุฑ ุจุงุฏ ุจุฎููุชุด.ู ูุทุนุง ุฏุฑ ุฒููู ูุง ุฏฺฏู ูู ฺฉูฺฉ ฺฉููุฏุณ\n",
            "ฺฉุชุงุจ ฺฉู ูุฑ ฺฉุณ ุญุฏุงูู ฺฉ ุจุงุฑ ุจุงุฏ ุจุฎููุชุด.ู ูุทุนุง ุฏุฑ ุฒููู ูุง ุฏฺฏู ูู ฺฉูฺฉ ฺฉููุฏุณ\n",
            "ุจุฎููู ุจุฏ ูุณ ุญุฏุงูู ุงูุฏูุงุฑ ุชูุด ูุณุช\n",
            "ุจุฎููู ุจุฏ ูุณ ุญุฏุงูู ุงูุฏูุงุฑ ุชูุด ูุณุช\n",
            "ฺฉุชุงุจ ุจุฏ ูุจูุฏ ูู ุงฺฏู ยซ ูพุฏุฑ ูพููุฏุงุฑ ูพุฏุฑ ุจูพูู ยปุฑู ุฎููุฏู ุจุงุดู ุฏููุง ุงูฺฏุงุฑ ุฏุงุดุช ุญุฑูุง ุงููู ูุดุฎูุงุฑ ูฺฉุฑุฏ ุจู ุนูุงูู ุงูฺฉู ู ุชุจูุบ ุณููุงุฑูุง ู ููุงุดูุง ุฎูุฏุดู ูฺฉุฑุฏ ฺฉู ุงู ฺฉุงุฑุด ุงุตูุง ุฌุงูุจ ูุจูุฏ ู ุญุฑุต ุขุฏูู ุฏุฑูุงูุฑุฏ. ูู ุญุฑู ูุง ุฌุฏุฏ ู ุฌุงูุจ ูู ุจุฑุง ฺฏูุชู ุฏุงุดุช.\n",
            "ฺฉุชุงุจ ุจุฏ ูุจูุฏ ูู ุงฺฏู ยซ ูพุฏุฑ ูพููุฏุงุฑ ูพุฏุฑ ุจูพูู ยปุฑู ุฎููุฏู ุจุงุดู ุฏููุง ุงูฺฏุงุฑ ุฏุงุดุช ุญุฑูุง ุงููู ูุดุฎูุงุฑ ูฺฉุฑุฏ ุจู ุนูุงูู ุงูฺฉู ู ุชุจูุบ ุณููุงุฑูุง ู ููุงุดูุง ุฎูุฏุดู ูฺฉุฑุฏ ฺฉู ุงู ฺฉุงุฑุด ุงุตูุง ุฌุงูุจ ูุจูุฏ ู ุญุฑุต ุขุฏูู ุฏุฑูุงูุฑุฏ. ูู ุญุฑู ูุง ุฌุฏุฏ ู ุฌุงูุจ ูู ุจุฑุง ฺฏูุชู ุฏุงุดุช.\n",
            "ุจู ูุธุฑ ูู ฺฉุชุงุจ ุจุฏ ูุณุช ู ุงุฑุฒุด ฺฉุจุงุฑ ุฎููุฏู ุฏุงุฑูุ ุดุงุฏ ุชู ุซุฑูุช ฺฉูฺฉ ูฺฉููุ ุงูุง ู ุชููู ุฏุฑ ููุงุฑุฏ ุฏฺฏู ุฒูุฏฺฏ ุจู ุฏุฑุฏ ุงุฏู ุจุฎูุฑู โ\n",
            "ุจู ูุธุฑ ูู ฺฉุชุงุจ ุจุฏ ูุณุช ู ุงุฑุฒุด ฺฉุจุงุฑ ุฎููุฏู ุฏุงุฑูุ ุดุงุฏ ุชู ุซุฑูุช ฺฉูฺฉ ูฺฉููุ ุงูุง ู ุชููู ุฏุฑ ููุงุฑุฏ ุฏฺฏู ุฒูุฏฺฏ ุจู ุฏุฑุฏ ุงุฏู ุจุฎูุฑู \n",
            "ฺฉุชุงุจ ุฎู ุฎูุจ ู ฺฉุงุฑุจุฑุฏ ูุณุช. ูู ฺฉุงููุง ุฑุงุถ ุจูุฏู\n",
            "ฺฉุชุงุจ ุฎู ุฎูุจ ู ฺฉุงุฑุจุฑุฏ ูุณุช. ูู ฺฉุงููุง ุฑุงุถ ุจูุฏู\n",
            "ุจุฑุง ฺฉุณ ฺฉู ุจุง ุฌููุงุช ุชุงฺฉุฏ ุญุงู ููฺฉูู ู ุฎุณุชู ุณุช ุงุฒ ฺฉุชุงุจุง ูุซู ูุงููู ุชูุงูฺฏุฑ ฺฉุงุชุฑู ูพุงูุฏุฑ ฺฉู ุขุฎุฑุด ูู ุฑุงู ุญู ุฏุฑุณุช ู ุญุณุงุจ ู ูุงุจู ุงุนุชูุงุฏ ุฏุณุชฺฏุฑ ุขุฏู ููุดูุ ุฎู ฺฉุชุงุจ ุฎูุจู ู ุฎููุฏู ฺูุฏู ุจุงุฑู ุด ุชูุตู  ููู :)\n",
            "ูุชุดฺฉุฑ\n",
            "ุจุฑุง ฺฉุณ ฺฉู ุจุง ุฌููุงุช ุชุงฺฉุฏ ุญุงู ููฺฉูู ู ุฎุณุชู ุณุช ุงุฒ ฺฉุชุงุจุง ูุซู ูุงููู ุชูุงูฺฏุฑ ฺฉุงุชุฑู ูพุงูุฏุฑ ฺฉู ุขุฎุฑุด ูู ุฑุงู ุญู ุฏุฑุณุช ู ุญุณุงุจ ู ูุงุจู ุงุนุชูุงุฏ ุฏุณุชฺฏุฑ ุขุฏู ููุดูุ ุฎู ฺฉุชุงุจ ุฎูุจู ู ุฎููุฏู ฺูุฏู ุจุงุฑู ุด ุชูุตู  ููู :)\n",
            "ูุชุดฺฉุฑ\n",
            "ุนุงูู. ุจุณุงุฑ ุนุงู. ุญุชูุง ุจุฎููู\n",
            "ุนุงูู. ุจุณุงุฑ ุนุงู. ุญุชูุง ุจุฎููู\n",
            "ุงูุฑู ุฎูุดู ุงููุฏฺฉุชุงุจ ุฎูุจ ุจูุฏ\n",
            "ุงูุฑู ุฎูุดู ุงููุฏฺฉุชุงุจ ุฎูุจ ุจูุฏ\n",
            "ุจ ูุธุฑ ุ ฺฉุงููุง ุฏุฑ ุฑูู ุฒูุฏฺฏ ูู ุชุงุซุฑ ูุซุจุช ุฏุงุดุช.\n",
            "ุจ ูุธุฑ ุ ฺฉุงููุง ุฏุฑ ุฑูู ุฒูุฏฺฏ ูู ุชุงุซุฑ ูุซุจุช ุฏุงุดุช.\n",
            "ูฺฉุชู ุฏฺฏู ูู ุงูู ฺฉู ุงุฑุฒุด ูุงุฏุงุช ุฑู ุชู ุขุฏู ุจุงูุง ูุจุฑู ู ุงูุณุงู ุฑู ุงุฒ ูุนููุงุช ุฏูุฑ ูฺฉูู. ู ุงุฒ ุงูุณุงู ู ููุฌูุฏ ุญุฑุต ู ูพูู ุฏูุณุช ูุณุงุฒู.\n",
            "ูฺฉุชู ุฏฺฏู ูู ุงูู ฺฉู ุงุฑุฒุด ูุงุฏุงุช ุฑู ุชู ุขุฏู ุจุงูุง ูุจุฑู ู ุงูุณุงู ุฑู ุงุฒ ูุนููุงุช ุฏูุฑ ูฺฉูู. ู ุงุฒ ุงูุณุงู ู ููุฌูุฏ ุญุฑุต ู ูพูู ุฏูุณุช ูุณุงุฒู.\n",
            "ุงฺฉุซุฑ ฺฉุชุงุจูุง ููููุช ุจู ุฎุตูุต ุงู ฺฉุชุงุจ ุญุณ ุฎูุฏุฎูุงู ู ุฒุงุฏู ุทูุจ ุฐู ุฏุฑ ุขุฏู ุงุฌุงุฏ ูฺฉููุฏ. ุขุฑุฒููุง ุฑู ูู ุฏุฑูู ุงูุณุงู ุงุฌุงุฏ ูฺฉููุฏ ูู ฺูู ูุงูุน ูุดุงู ููุฏููุฏ ุฏูุง ุฑุง ุจุง ูุฑุณุฏู ุจู ุขุฑุฒููุงุด ุงูุณุฑุฏู ูุดูุฏ. ุงูุณุงู ูููููุฏ ฺฉู ุงู ุฏูุง ุจุดุชุฑ ุขุฑุฒููุง ูุญูู ููุดููุฏ ู ูุจุงุฏ ุจู ุขููุง ุฏู ุจุณุช.\n",
            "ุงฺฉุซุฑ ฺฉุชุงุจูุง ููููุช ุจู ุฎุตูุต ุงู ฺฉุชุงุจ ุญุณ ุฎูุฏุฎูุงู ู ุฒุงุฏู ุทูุจ ุฐู ุฏุฑ ุขุฏู ุงุฌุงุฏ ูฺฉููุฏ. ุขุฑุฒููุง ุฑู ูู ุฏุฑูู ุงูุณุงู ุงุฌุงุฏ ูฺฉููุฏ ูู ฺูู ูุงูุน ูุดุงู ููุฏููุฏ ุฏูุง ุฑุง ุจุง ูุฑุณุฏู ุจู ุขุฑุฒููุงุด ุงูุณุฑุฏู ูุดูุฏ. ุงูุณุงู ูููููุฏ ฺฉู ุงู ุฏูุง ุจุดุชุฑ ุขุฑุฒููุง ูุญูู ููุดููุฏ ู ูุจุงุฏ ุจู ุขููุง ุฏู ุจุณุช.\n",
            "ูุงูุนุง ฺฉุชุงุจ ุฎูุจู\n",
            "ูุงูุนุง ฺฉุชุงุจ ุฎูุจู\n",
            "ุนู ฺฉุชุงุจ ุฑู ุจฺฏุฑูุุุุ\n",
            "ุนู ฺฉุชุงุจ ุฑู ุจฺฏุฑูุุุุ\n",
            "ูู ฺฉุชุงุจูุง ุฒุงุฏ ุฏุฑ ุฒููู ููููุช ฺฉุงุฑ ูุทุงูุนู ฺฉุฑุฏู ูุชููู ุจุฏูู ุดฺฉ ุจฺฏู ููุชุฑู ู ุชุงุซุฑ ฺฏุฐุงุฑุชุฑู ฺฉุชุงุจ ฺฉู ุฎููุฏู ุจูุฏ ู ุฒููู ูฺฉุฑ ูู ุฑู ุฑุงุฌุจ ฺฉุงุฑู ู ุฎูุฏู ุชุบุฑ ุฏุงุฏ  ู ุงุฒ  ุฒูุงู ฺฉู ุฏุณุช ุจู ุงุฌุฑุง ูุงููุง ูุงูุด ุชู ุฒูุฏฺฏู ุฒุฏู ุชู  ูุฏุช ุฎู ฺฉู ูุชูุฌู ุชุงุซุฑ ุญุฑุช ุงูฺฏุฒุด ุดุฏู \n",
            "ูพุดููุงุฏ ูฺฉูู ุญุช ุงฺฏู ุงุญุณุงุณ ูฺฉูุฏ ููููุฏ ุจุงุฒู ุงู ฺฉุชุงุจ ุงุฑุฒุดููุฏู ุงุฒ ุฏุณุช ูุฏุฏ\n",
            " ุจุง ุชุดฺฉุฑ ุงุฒ ุทุงูฺู\n",
            "ูู ฺฉุชุงุจูุง ุฒุงุฏ ุฏุฑ ุฒููู ููููุช ฺฉุงุฑ ูุทุงูุนู ฺฉุฑุฏู ูุชููู ุจุฏูู ุดฺฉ ุจฺฏู ููุชุฑู ู ุชุงุซุฑ ฺฏุฐุงุฑุชุฑู ฺฉุชุงุจ ฺฉู ุฎููุฏู ุจูุฏ ู ุฒููู ูฺฉุฑ ูู ุฑู ุฑุงุฌุจ ฺฉุงุฑู ู ุฎูุฏู ุชุบุฑ ุฏุงุฏ  ู ุงุฒ  ุฒูุงู ฺฉู ุฏุณุช ุจู ุงุฌุฑุง ูุงููุง ูุงูุด ุชู ุฒูุฏฺฏู ุฒุฏู ุชู  ูุฏุช ุฎู ฺฉู ูุชูุฌู ุชุงุซุฑ ุญุฑุช ุงูฺฏุฒุด ุดุฏู \n",
            "ูพุดููุงุฏ ูฺฉูู ุญุช ุงฺฏู ุงุญุณุงุณ ูฺฉูุฏ ููููุฏ ุจุงุฒู ุงู ฺฉุชุงุจ ุงุฑุฒุดููุฏู ุงุฒ ุฏุณุช ูุฏุฏ\n",
            " ุจุง ุชุดฺฉุฑ ุงุฒ ุทุงูฺู\n",
            "ููู ุงูุนุงุฏู....\n",
            "ููู ุงูุนุงุฏู....\n",
            "ุจู ุชูุงู ุฏูุณุชุง ฺฉู ุชู ูุณุงุจูู  ฺฉุชุงุจุฎูู ุจุฑูุฏู ูุดุฏู ูพุดููุงุฏ ู ฺฉูู ุญุชูุง ุงู ฺฉุชุงุจ ุฑู ุจุฎููู ุดุงุฏ ุงูุฌูุฑ ุฏุณุช ุงุฒ ุณุฑ ุฑุงูุจุฏ ุนุฒุฒ ุจุฑุฏุงุฑู\n",
            "ุจู ุชูุงู ุฏูุณุชุง ฺฉู ุชู ูุณุงุจูู  ฺฉุชุงุจุฎูู ุจุฑูุฏู ูุดุฏู ูพุดููุงุฏ ู ฺฉูู ุญุชูุง ุงู ฺฉุชุงุจ ุฑู ุจุฎููู ุดุงุฏ ุงูุฌูุฑ ุฏุณุช ุงุฒ ุณุฑ ุฑุงูุจุฏ ุนุฒุฒ ุจุฑุฏุงุฑู\n",
            "ฺฉ ุจู ูู ุจฺฏู ฺฉุชุงุจ ุฎูุจ ุจูุฏ ุง ุนุงู ุจูุฏุูู ุจู ฺฉุชุงุจุง ุฑูุงูุดูุงุณ ููููุช ุนูุงูู ุฏุงุฑู ููุฏููู ุจุฎุฑู\n",
            "ฺฉ ุจู ูู ุจฺฏู ฺฉุชุงุจ ุฎูุจ ุจูุฏ ุง ุนุงู ุจูุฏุูู ุจู ฺฉุชุงุจุง ุฑูุงูุดูุงุณ ููููุช ุนูุงูู ุฏุงุฑู ููุฏููู ุจุฎุฑู\n",
            "ูุงุงุงุง\n",
            "ูพููุดู ูุฒุงุฑู ุชู ุฌุจู ุจู ุฌุง ุฎุฑุฏู ฺฉุชุงุจ ฺฉูุ ฺฉู ููููุฑ ูุดู\n",
            "ูุงูุงุงุงุง\n",
            "ูุงุงุงุง\n",
            "ูพููุดู ูุฒุงุฑู ุชู ุฌุจู ุจู ุฌุง ุฎุฑุฏู ฺฉุชุงุจ ฺฉูุ ฺฉู ููููุฑ ูุดู\n",
            "ูุงูุงุงุงุง\n",
            "ุจุฒูุฏ ูุงุณุด ุฏุณ ูุดูฺฉุฑู ฺฉุชุงุจ ุฎูุจ ุจูุฏ\n",
            "ุจุฒูุฏ ูุงุณุด ุฏุณ ูุดูฺฉุฑู ฺฉุชุงุจ ุฎูุจ ุจูุฏ\n",
            "ฺฉุชุงุจ ูพุฑ ุงุฒ ุฌููุงุช ูุซุจุช ููุท.  ฺฉุงููุง ูุนููู. ุชุจูุบ ุณููุงุฑูุง ูููุชุฑ ุดุฏู. ุฏุฑฺฉ ฺฉููู ุงุฑุฒุด ุตุฑู ููุช ฺฏุฑุงูุจูุง ุฑู ูุฏุงุฑุฏ\n",
            "ฺฉุชุงุจ ูพุฑ ุงุฒ ุฌููุงุช ูุซุจุช ููุท.  ฺฉุงููุง ูุนููู. ุชุจูุบ ุณููุงุฑูุง ูููุชุฑ ุดุฏู. ุฏุฑฺฉ ฺฉููู ุงุฑุฒุด ุตุฑู ููุช ฺฏุฑุงูุจูุง ุฑู ูุฏุงุฑุฏ\n",
            "ฺฉุชุงุจ ุฎู ุนุงู ูุณุช ุงุฒ ูุธุฑ ูุญุชูุง ูู ...\n",
            "ฺุฒ ฺฉู ุงููุช ุฎู ุจุงูุง ุฏุงุฑู ุนูู ฺฉุฑุฏู ุจู ุฑุงูฺฉุงุฑูุง ู ุนุจุงุฑุช ูุง ุชุงฺฉุฏ ฺฉุชุงุจ ูุณุช .\n",
            "ุงูฺฉู ูุฑ ุฑูุฒ ุงูู ุตุจุญ ู ูุฑ ุดุจ ูุจู ุงุฒ ุฎูุงุจ ุชฺฉุฑุงุฑ ฺฉูู ู ุจฺฏู : ูู ฺฉ ุฐูู ููููุฑ ุฏุงุฑู .\n",
            "ู ฺฏุฑูู ุฎูุงูุฏู ฺฉุชุงุจ ฺฉู ุฑุงุญุช ุชุฑู ฺฉุงุฑ ูุณุชุด .\n",
            "ุฑุงู ุซุฑูุช ู ุซุฑูุชููุฏ ุดุฏู ุณุฎุชู.\n",
            "ฺฉุชุงุจ ุฎู ุนุงู ูุณุช ุงุฒ ูุธุฑ ูุญุชูุง ูู ...\n",
            "ฺุฒ ฺฉู ุงููุช ุฎู ุจุงูุง ุฏุงุฑู ุนูู ฺฉุฑุฏู ุจู ุฑุงูฺฉุงุฑูุง ู ุนุจุงุฑุช ูุง ุชุงฺฉุฏ ฺฉุชุงุจ ูุณุช .\n",
            "ุงูฺฉู ูุฑ ุฑูุฒ ุงูู ุตุจุญ ู ูุฑ ุดุจ ูุจู ุงุฒ ุฎูุงุจ ุชฺฉุฑุงุฑ ฺฉูู ู ุจฺฏู : ูู ฺฉ ุฐูู ููููุฑ ุฏุงุฑู .\n",
            "ู ฺฏุฑูู ุฎูุงูุฏู ฺฉุชุงุจ ฺฉู ุฑุงุญุช ุชุฑู ฺฉุงุฑ ูุณุชุด .\n",
            "ุฑุงู ุซุฑูุช ู ุซุฑูุชููุฏ ุดุฏู ุณุฎุชู.\n",
            "ุจูุชุฑู ฺฉุชุงุจู ฺฉู ุชูุนูุฑู ุฎููุฏู ููููู ูุงุฑู ุนุฒุฒ ูููููู ุทุงูฺู\n",
            "ุจูุชุฑู ฺฉุชุงุจู ฺฉู ุชูุนูุฑู ุฎููุฏู ููููู ูุงุฑู ุนุฒุฒ ูููููู ุทุงูฺู\n",
            "ุจุง ุณูุงู.ุฎุฏูุช ููู ุฏุณุช ุงูุฏุฑฺฉุงุฑุงู ุทุงูฺู.ุจุณุงุฑ ููููู ุงุฒ ููุชูุง ููุตูุงูู ู ููฺูู ุชุฎูู ูุง ุนุงู ฺฉู ุจุงุจุช ููุงุดฺฏุงู ฺฉุชุงุจ ูุฑุงุฑ ุฏุงุฏุฏ.ุฎูุงุณุชู ุชุดฺฉุฑ ฺฉุฑุฏู ุจุงุดู ูุงูฺฉู ุจู ููู ุฑุงู ุจุง ูุฏุฑุช ุงุฏุงูู ุจุฏุฏ. ู ุจุง ฺฏุฐุดุช ุฒูุงู. ููุชุง ุจุงูุง ูุฑู.ุงู ฺฉุชุงุจู ุนุงูู.\n",
            "ุจุง ุณูุงู.ุฎุฏูุช ููู ุฏุณุช ุงูุฏุฑฺฉุงุฑุงู ุทุงูฺู.ุจุณุงุฑ ููููู ุงุฒ ููุชูุง ููุตูุงูู ู ููฺูู ุชุฎูู ูุง ุนุงู ฺฉู ุจุงุจุช ููุงุดฺฏุงู ฺฉุชุงุจ ูุฑุงุฑ ุฏุงุฏุฏ.ุฎูุงุณุชู ุชุดฺฉุฑ ฺฉุฑุฏู ุจุงุดู ูุงูฺฉู ุจู ููู ุฑุงู ุจุง ูุฏุฑุช ุงุฏุงูู ุจุฏุฏ. ู ุจุง ฺฏุฐุดุช ุฒูุงู. ููุชุง ุจุงูุง ูุฑู.ุงู ฺฉุชุงุจู ุนุงูู.\n",
            "ูู ุชุงุฒู ฺฉุชุงุจ ุฑู ุฏุงูููุฏ ฺฉุฑุฏููู ููุฏูู ุงุด ููู ูุดุชุงู ุฎููุฏู ฺฉุฑุฏ. ุงูุฏูุงุฑู ุฒูุฏฺฏ ูู ู ุฏูุณุชุงู ุฏฺุงุฑ ุชุบุฑุงุช ุฎูุดุงูุฏ ุจุดู\n",
            "ูู ุชุงุฒู ฺฉุชุงุจ ุฑู ุฏุงูููุฏ ฺฉุฑุฏููู ููุฏูู ุงุด ููู ูุดุชุงู ุฎููุฏู ฺฉุฑุฏ. ุงูุฏูุงุฑู ุฒูุฏฺฏ ูู ู ุฏูุณุชุงู ุฏฺุงุฑ ุชุบุฑุงุช ุฎูุดุงูุฏ ุจุดู\n",
            "ูููุงูุนุงุฏู ุนุงู!\n",
            "ูููุงูุนุงุฏู ุนุงู!\n",
            "ููู ฺฉุชุงุจู ุชุนุฑู ฺฉุฑุฏู ูู ฺฉ ูฺฏูุช ฺฉู ุจุง ุนูู ุจูุด ุชุงุซุฑ ุฏุงุดุชู ุจุฑุงุดุุุุุ\n",
            "ููู ฺฉุชุงุจู ุชุนุฑู ฺฉุฑุฏู ูู ฺฉ ูฺฏูุช ฺฉู ุจุง ุนูู ุจูุด ุชุงุซุฑ ุฏุงุดุชู ุจุฑุงุดุุุุุ\n",
            "ุดุฏุฏุง ุชูุตู ูุดู :)\n",
            "ุดุฏุฏุง ุชูุตู ูุดู :)\n",
            "ฺฉุชุงุจ ุนุงู ุจูุฏ.ูู ุงฺฏู ูุดู ฺฉุชุงุจูุง ุจุดุชุฑ ุจุฐุงุฑุฏ.\n",
            "ฺฉุชุงุจ ุนุงู ุจูุฏ.ูู ุงฺฏู ูุดู ฺฉุชุงุจูุง ุจุดุชุฑ ุจุฐุงุฑุฏ.\n",
            "ฺฉุชุงุจ ููู ุงูุนุงุฏู ฺฉุงุฑุจุฑุฏ. ูุฑ ุตูุญู ุงุด ุฌุง ุชูฺฉุฑ ุฏุงุฑู.  ุงุฑุฒุด ุฎููุฏู ุฏุงุฑู.\n",
            "ฺฉุชุงุจ ููู ุงูุนุงุฏู ฺฉุงุฑุจุฑุฏ. ูุฑ ุตูุญู ุงุด ุฌุง ุชูฺฉุฑ ุฏุงุฑู.  ุงุฑุฒุด ุฎููุฏู ุฏุงุฑู.\n",
            "ุงฺฏู ูุฑุงุฑ ุจุงุดู ุขุฏู ู ฺฉุชุงุจู ุฏุฑุณุช ุชู ุฒูุฏฺฏุด ุจุฎููู ููู ฺฉุชุงุจู.ูุฑ ุตูุญู ูุฎูู ฺฉูุฌฺฉุงู ูุด ุจุดุชุฑ ุจุฑ ุฌูู.ููู ุงูุนุงุฏุณ\n",
            "ุงฺฏู ูุฑุงุฑ ุจุงุดู ุขุฏู ู ฺฉุชุงุจู ุฏุฑุณุช ุชู ุฒูุฏฺฏุด ุจุฎููู ููู ฺฉุชุงุจู.ูุฑ ุตูุญู ูุฎูู ฺฉูุฌฺฉุงู ูุด ุจุดุชุฑ ุจุฑ ุฌูู.ููู ุงูุนุงุฏุณ\n",
            "ุฎู ุฑุงูฺฉุงุฑูุง ููุซุฑ ุงุฑุงุฆู ูุฏู ุฎู ฺฉุชุงุจ ุซุงุซุฑ ฺฏุฐุงุฑ ู ุฎูุจู.....ุงุฒ ุงู ฺฉุชุงุจูุง ุจุดุชุฑ ุจุฐุงุฑ ุทุงูฺู ุฌุงู\n",
            "ุฎู ุฑุงูฺฉุงุฑูุง ููุซุฑ ุงุฑุงุฆู ูุฏู ุฎู ฺฉุชุงุจ ุซุงุซุฑ ฺฏุฐุงุฑ ู ุฎูุจู.....ุงุฒ ุงู ฺฉุชุงุจูุง ุจุดุชุฑ ุจุฐุงุฑ ุทุงูฺู ุฌุงู\n",
            "ุงู ฺฉุชุงุจู ฺฉู ูุฎูู ูุจู ุชูุฑุจุง ููู ุฎุตูุตุงุช ุฑูุญ ุงูุณุงููุง ููุฑู ุฏุงุฑ ู ุชุงุฒู ูููู ฺฉู ุงุดุชุจุงูุงุชุช ฺู. ุจู ูุงูุน ฺฉู ุจุฑุง ฺฉุณุจ ุซุฑ ุช ู ููููุช ุจุงุฏ ุฐููุชุดู ุฏุงุดุช. ููููู ุงุฒ ุทุงูฺู ุงู ฺฉุชุงุจ ุชุงุซุฑ ุฒุง ุฏ ุฑู ูู ุฏุงุดุชู\n",
            "ุงู ฺฉุชุงุจู ฺฉู ูุฎูู ูุจู ุชูุฑุจุง ููู ุฎุตูุตุงุช ุฑูุญ ุงูุณุงููุง ููุฑู ุฏุงุฑ ู ุชุงุฒู ูููู ฺฉู ุงุดุชุจุงูุงุชุช ฺู. ุจู ูุงูุน ฺฉู ุจุฑุง ฺฉุณุจ ุซุฑ ุช ู ููููุช ุจุงุฏ ุฐููุชุดู ุฏุงุดุช. ููููู ุงุฒ ุทุงูฺู ุงู ฺฉุชุงุจ ุชุงุซุฑ ุฒุง ุฏ ุฑู ูู ุฏุงุดุชู\n",
            "ฺฉุงุด ูุงุจูุช ุจูฺฉ ูุงุฑฺฉ ฺฉุฑุฏู ุตูุญุงุช ุฑู ูู ุงุถุงูู ฺฉูุฏ. ฺฏุงู ุขุฏู ูุงุฒ ุฏุงุฑู ุตูุญุงุช ุฎุงุต ุฑู ูุฑูุฑ ฺฉูู.\n",
            "ฺฉุงุด ูุงุจูุช ุจูฺฉ ูุงุฑฺฉ ฺฉุฑุฏู ุตูุญุงุช ุฑู ูู ุงุถุงูู ฺฉูุฏ. ฺฏุงู ุขุฏู ูุงุฒ ุฏุงุฑู ุตูุญุงุช ุฎุงุต ุฑู ูุฑูุฑ ฺฉูู.\n",
            "ุจูุฒุงุฏ ุฌุงู\n",
            "ุงฺฏู ุขุฏู  ูุฏููู ฺุทูุฑ ูฺฉุฑ ฺฉูู\n",
            "ฺุทูุฑ ูุบุฒุดู ุจฺฉุชุฑ ุจูุฏุงุฒู ู ุชูุงุด ฺฉููุ\n",
            "ุฎูุง ูุณุชู ฺฉู ูู ุชูุงุด ูฺฉูู ูู ูฺฉุฑุดูู ฺฉุงุฑ ูฺฉูู\n",
            "ูู ููุดู ูุดุชุดูู ฺฏุฑู ููโุดููู!!!\n",
            "ูุจุนุถุง ูู ุจุฑุนฺฉุณ ุงูู.\n",
            "ูพุณ ุจู ุฐููุช ู ุทุฑุฒ ูฺฉุฑ ุขุฏูุง ูุฑุจูุทู ู ุงู ฺฉุชุงุจ ูู ูููู ูุฎูุงุฏ ุจุฑุชููู ุฑูุดู ฺฉูู.\n",
            "ุจูุฒุงุฏ ุฌุงู\n",
            "ุงฺฏู ุขุฏู  ูุฏููู ฺุทูุฑ ูฺฉุฑ ฺฉูู\n",
            "ฺุทูุฑ ูุบุฒุดู ุจฺฉุชุฑ ุจูุฏุงุฒู ู ุชูุงุด ฺฉููุ\n",
            "ุฎูุง ูุณุชู ฺฉู ูู ุชูุงุด ูฺฉูู ูู ูฺฉุฑุดูู ฺฉุงุฑ ูฺฉูู\n",
            "ูู ููุดู ูุดุชุดูู ฺฏุฑู ููโุดููู!!!\n",
            "ูุจุนุถุง ูู ุจุฑุนฺฉุณ ุงูู.\n",
            "ูพุณ ุจู ุฐููุช ู ุทุฑุฒ ูฺฉุฑ ุขุฏูุง ูุฑุจูุทู ู ุงู ฺฉุชุงุจ ูู ูููู ูุฎูุงุฏ ุจุฑุชููู ุฑูุดู ฺฉูู.\n",
            "ุนุฒุฒู ูู ุฎูุงุฏ ูุงุณู ุงูุฌูุฑ ูุณุงุกู ฺฉุชุงุจ ุจุฎูู . ููุท ูุบุฒุชู ุจู ฺฉุงุฑ ุจูุฏุงุฒ ู ุชูุงุดุชู ุจฺฉู. ููู .\n",
            "ุนุฒุฒู ูู ุฎูุงุฏ ูุงุณู ุงูุฌูุฑ ูุณุงุกู ฺฉุชุงุจ ุจุฎูู . ููุท ูุบุฒุชู ุจู ฺฉุงุฑ ุจูุฏุงุฒ ู ุชูุงุดุชู ุจฺฉู. ููู .\n",
            "ุณูุงู ููููู ุจุงุจุช ุจุฐูุงูู ุฎูุจ ู ฺฉุชุงุจ ุฎูุจุชูู ูู ููุช ู ุฎูุงู ฺฉุชุงุจู ุจุฎููู ุงุฒู ุตูุญู ุง ุจุจุนุฏ ุงุฒ ฺฉุชุงุจ ุฎุงุฑุฌ ูุดู ูุทูุง ุฑุณุฏฺฏ ฺฉูู ููููู ู\n",
            "ุณูุงู ููููู ุจุงุจุช ุจุฐูุงูู ุฎูุจ ู ฺฉุชุงุจ ุฎูุจุชูู ูู ููุช ู ุฎูุงู ฺฉุชุงุจู ุจุฎููู ุงุฒู ุตูุญู ุง ุจุจุนุฏ ุงุฒ ฺฉุชุงุจ ุฎุงุฑุฌ ูุดู ูุทูุง ุฑุณุฏฺฏ ฺฉูู ููููู ู\n",
            "ุงู ฺฉุชุงุจ ูุฎูุงุฏ ุจฺฏู ฺฉู ููุฑ ูุงุฏ ุงุฒ ููุฑ ุฐูู ู ูฺฉุฑ ุขุฏูู.\n",
            "ุงู ฺฉุชุงุจ ูุฎูุงุฏ ุจฺฏู ฺฉู ููุฑ ูุงุฏ ุงุฒ ููุฑ ุฐูู ู ูฺฉุฑ ุขุฏูู.\n",
            "ุจู ูุธุฑูุงู ฺฉุชุงุจ  ุจุณุงุฑ ุฎูุจ ุชูุงูุณุชู ุงุญุณุงุณุงุช ู ุญุงูุงุช ุชูุงู ููุฑุงู ู ุซุฑูุชููุฏุงู ุฑุง ุจุงู ฺฉูู ู ูุธุฑุงุช ุงุดุชุจุงู ุฑู ุจู ฺุงูุด ุจฺฉุดู\n",
            "ุจู ูุธุฑูุงู ฺฉุชุงุจ  ุจุณุงุฑ ุฎูุจ ุชูุงูุณุชู ุงุญุณุงุณุงุช ู ุญุงูุงุช ุชูุงู ููุฑุงู ู ุซุฑูุชููุฏุงู ุฑุง ุจุงู ฺฉูู ู ูุธุฑุงุช ุงุดุชุจุงู ุฑู ุจู ฺุงูุด ุจฺฉุดู\n",
            "ุงู ฺฉุชุงุจ ูููุงูุนุงุฏุณุช ู  ูพุดููุงุฏ ูฺฉูู ุงุฒ ุฏุณุชุด ูุฏุฏ!\n",
            "ุงู ฺฉุชุงุจ ูููุงูุนุงุฏุณุช ู  ูพุดููุงุฏ ูฺฉูู ุงุฒ ุฏุณุชุด ูุฏุฏ!\n",
            "ุจุง ุชุดฺฉุฑ ุงุฒ ุจุฑูุงูู ุทุงูฺู ุจุงุจุช ุงุฑุงุฆู ูุณุฎู ุงูฺฉุชุฑููฺฉ ุงู ฺฉุชุงุจ ุฌุฐุงุจ \n",
            "ู ุณูุงู ุจู ููู ฺฉุณุงู ฺฉู ูุตุฏ ุชุญูู ุฏุฑ ุฒูุฏฺฏ ุฑุง ุฏุงุฑูุฏ!\n",
            "ุงฺฏุฑ ุชุง ุจู ุงูุฑูุฒ ุจู ุงู ูุชุฌู ุฑุณุฏูโุงุฏ ฺฉู ุฒูุฏฺฏ ุดูุง ูููู ฺฉู ุฏุฑ ุญุงู ุญุงุถุฑ ูุฌูุฏ ุฏุงุฑูุ ูพุณ ุฎูุงูุฏู ุงู ฺฉุชุงุจ ุฑุง ุจู ุดูุง ูพุดููุงุฏ ู ฺฉูู. \n",
            "ุจุง ุขุฑุฒู ฺฉุชุงุจ ุฎูุงู ุดุฏู ุจุฑุง ููู!\n",
            "ุจุง ุชุดฺฉุฑ ุงุฒ ุจุฑูุงูู ุทุงูฺู ุจุงุจุช ุงุฑุงุฆู ูุณุฎู ุงูฺฉุชุฑููฺฉ ุงู ฺฉุชุงุจ ุฌุฐุงุจ \n",
            "ู ุณูุงู ุจู ููู ฺฉุณุงู ฺฉู ูุตุฏ ุชุญูู ุฏุฑ ุฒูุฏฺฏ ุฑุง ุฏุงุฑูุฏ!\n",
            "ุงฺฏุฑ ุชุง ุจู ุงูุฑูุฒ ุจู ุงู ูุชุฌู ุฑุณุฏูโุงุฏ ฺฉู ุฒูุฏฺฏ ุดูุง ูููู ฺฉู ุฏุฑ ุญุงู ุญุงุถุฑ ูุฌูุฏ ุฏุงุฑูุ ูพุณ ุฎูุงูุฏู ุงู ฺฉุชุงุจ ุฑุง ุจู ุดูุง ูพุดููุงุฏ ู ฺฉูู. \n",
            "ุจุง ุขุฑุฒู ฺฉุชุงุจ ุฎูุงู ุดุฏู ุจุฑุง ููู!\n",
            "ุงู ฺฉุชุงุจ ููู ุงูุนุงุฏุณ . ุจ ููุงุช ุงูฺฏุฒู ูุฏู . ุทุฑุฒ ูฺฉุฑู ูุชุญูู ุดุฏ.\n",
            "ุงู ฺฉุชุงุจ ููู ุงูุนุงุฏุณ . ุจ ููุงุช ุงูฺฏุฒู ูุฏู . ุทุฑุฒ ูฺฉุฑู ูุชุญูู ุดุฏ.\n",
            "ูู ูุณุฎู ฺุงูพ ุฑู ุฏุงุฑูุ ุงููุฏฺฉู ุงุฒุด ุฎูุดู ุงููุฏ ุงุฒุงูุฌุงูู ุฎุฑุฏู ุชุงููุดู ููุฑุงู ุจุงุดู. ุทุงูฺู ุฌูู ุงฺฏู ฺฉุชุงุจูุง ุฎุงูู ุฏุจ ููุฑุฏ ูู ุจุฐุงุฑ ููููู ูุดู :)\n",
            "ูู ูุณุฎู ฺุงูพ ุฑู ุฏุงุฑูุ ุงููุฏฺฉู ุงุฒุด ุฎูุดู ุงููุฏ ุงุฒุงูุฌุงูู ุฎุฑุฏู ุชุงููุดู ููุฑุงู ุจุงุดู. ุทุงูฺู ุฌูู ุงฺฏู ฺฉุชุงุจูุง ุฎุงูู ุฏุจ ููุฑุฏ ูู ุจุฐุงุฑ ููููู ูุดู :)\n",
            "ุจู ูุธุฑู ุฎู ฺฉุชุงุจ ุฌุงูุจ ุจูุฏุ ูุฎุตูุตุงู ุงูู ุจุฎุด ฺฉู ุฏุฑุจุงุฑู ุฐููุช ุญุฑู ูุฒุฏ ู ุงู ฺฉู ุจุง ฺู ุฐููุช ูุง ุจุฒุฑฺฏ ู ุดู ฺฉู ูุงูุบ ูพุดุฑูุช ูุง ู ุดู!\n",
            "ุจู ูุธุฑู ุฎู ฺฉุชุงุจ ุฌุงูุจ ุจูุฏุ ูุฎุตูุตุงู ุงูู ุจุฎุด ฺฉู ุฏุฑุจุงุฑู ุฐููุช ุญุฑู ูุฒุฏ ู ุงู ฺฉู ุจุง ฺู ุฐููุช ูุง ุจุฒุฑฺฏ ู ุดู ฺฉู ูุงูุบ ูพุดุฑูุช ูุง ู ุดู!\n",
            "ุนุงูู ุจุง ุขุฑุฒู ููููุช ูุงุณู ุฎูุฏู ู ุงููุง ฺฉู ุงู ฺฉุชุงุจู ูุฎููู\n",
            "ุนุงูู ุจุง ุขุฑุฒู ููููุช ูุงุณู ุฎูุฏู ู ุงููุง ฺฉู ุงู ฺฉุชุงุจู ูุฎููู\n",
            "ฺฉุชุงุจ ุฎู ุฎูุจู\n",
            "ูุฑุณ ุทุงูฺู\n",
            "ฺฉุชุงุจ ุฎู ุฎูุจู\n",
            "ูุฑุณ ุทุงูฺู\n",
            "ุนุงู ุจูุฏ..ฺฉุงุด ุฌูุฏ ุฏูู ู ุณููุดู ุจุฒุงุฑุฏ..ฺฉุชุงุจ ุขูุงุชูู ูพ ุฏ ุงู ูุณ ูุงูุนุง ฺฉู ููู ุฌุง ุจุชููู ุฏูุจุงูููู ุฏุงุดุชู ุจุงุดู๐\n",
            "ุนุงู ุจูุฏ..ฺฉุงุด ุฌูุฏ ุฏูู ู ุณููุดู ุจุฒุงุฑุฏ..ฺฉุชุงุจ ุขูุงุชูู ูพ ุฏ ุงู ูุณ ูุงูุนุง ฺฉู ููู ุฌุง ุจุชููู ุฏูุจุงูููู ุฏุงุดุชู ุจุงุดู\n",
            "ูุทูุง ุขูุงุชูู ฺฏุฑ ุจุฐุงุฑุฏ\n",
            "ูุทูุง ุขูุงุชูู ฺฏุฑ ุจุฐุงุฑุฏ\n",
            "ฺฉุชุงุจ ุงุณูู ฺฉุชุงุจ ุฎูุจู ุ ูู ูุจูุง ฺฏุฑ ุฎููุฏู . ุชุตุงูุฑ ฺฏุฑ ุจูุชุฑู ุงูุง ุงุณูู ููููุทูุฑ ฺฉู ุงุฒ ุงุณูโุงุด ูุนูููู ุจุดุชุฑ ุจู ูุจุงุญุซ ุจุงูู ูพุฑุฏุงุฎุชู.\n",
            "ูพ.ู:ูุชุงุณูุงูู ุชุนุฏุงุฏ ฺฉุชุจ ุขููุฒุด ูพุฒุดฺฉ ุทุงูฺู ุฎู ฺฉูู!\n",
            "ฺฉุชุงุจ ุงุณูู ฺฉุชุงุจ ุฎูุจู ุ ูู ูุจูุง ฺฏุฑ ุฎููุฏู . ุชุตุงูุฑ ฺฏุฑ ุจูุชุฑู ุงูุง ุงุณูู ููููุทูุฑ ฺฉู ุงุฒ ุงุณูโุงุด ูุนูููู ุจุดุชุฑ ุจู ูุจุงุญุซ ุจุงูู ูพุฑุฏุงุฎุชู.\n",
            "ูพ.ู:ูุชุงุณูุงูู ุชุนุฏุงุฏ ฺฉุชุจ ุขููุฒุด ูพุฒุดฺฉ ุทุงูฺู ุฎู ฺฉูู!\n",
            "ูุงูุนุง ฺฉุชุงุจ ุถุนู ุฏุฑ ุฒููู ุขูุงุชูู ูุณุชุด\n",
            "ูุงูุนุง ฺฉุชุงุจ ุถุนู ุฏุฑ ุฒููู ุขูุงุชูู ูุณุชุด\n",
            "ูุทูุงู ุทุงูฺู ุฑู ุงุฒ ูุธุฑ ฺฉุชุงุจุง ูพุฒุดฺฉ ุชููุช ฺฉูุฏุ ุญูู ููฺู ุจุฑูุงูู ุง ฺฉุชุงุจุง ูุญุฏูุฏ ุฏุฑ ุงู ุฒููู ุงุฑุงุฆู ุจุฏูุ ููููู \n",
            "ูุทูุงู ุทุงูฺู ุฑู ุงุฒ ูุธุฑ ฺฉุชุงุจุง ูพุฒุดฺฉ ุชููุช ฺฉูุฏุ ุญูู ููฺู ุจุฑูุงูู ุง ฺฉุชุงุจุง ูุญุฏูุฏ ุฏุฑ ุงู ุฒููู ุงุฑุงุฆู ุจุฏูุ ููููู \n",
            "ูุทูุง ุณุงุฑ ุฌูุฏูุง ุงู ฺฉุชุงุจ ุฑุง ูู ุจุฒุงุฑุฏ \n",
            "ฺฉุชุงุจ ุจุฑ ู ฺฉูู ูู ุจุฒุงุฑุฏ ููุงุจุน ุงุตู ูพุฒุดฺฉ ู ูพุฑุงูพุฒุดฺฉุชูู ุฎู ฺฉู ู ูุงูุนุชุจุฑ ูุณุชูุฏ ูุทูุง ุฏุฑ ุงู ุฒููู ุทุงูฺู ุฑุง ุชููุช ฺฉูุฏ\n",
            "ูุทูุง ุณุงุฑ ุฌูุฏูุง ุงู ฺฉุชุงุจ ุฑุง ูู ุจุฒุงุฑุฏ \n",
            "ฺฉุชุงุจ ุจุฑ ู ฺฉูู ูู ุจุฒุงุฑุฏ ููุงุจุน ุงุตู ูพุฒุดฺฉ ู ูพุฑุงูพุฒุดฺฉุชูู ุฎู ฺฉู ู ูุงูุนุชุจุฑ ูุณุชูุฏ ูุทูุง ุฏุฑ ุงู ุฒููู ุทุงูฺู ุฑุง ุชููุช ฺฉูุฏ\n",
            "ุณูุงู ูู ฺฉุชุงุจ ุขูุงุชูู ุงุณูู ุฑู ุฎุฑุฏู ุงูุง pdf  ุขู ุชู ฺฏูุดู ุฐุฎุฑู ูุดุฏู\n",
            "ูุทูุง ุฑุงูููุงู ฺฉูุฏ\n",
            "ุณูุงู ูู ฺฉุชุงุจ ุขูุงุชูู ุงุณูู ุฑู ุฎุฑุฏู ุงูุง pdf  ุขู ุชู ฺฏูุดู ุฐุฎุฑู ูุดุฏู\n",
            "ูุทูุง ุฑุงูููุงู ฺฉูุฏ\n",
            "ูุงุฒููุฏ ุดุฏุฏ ุฌูุฏูุง ุฏฺฏู ุงู ูุทูุง ูุฑ ฺู ุณุฑุนุชุฑ ุจุง ุชุดฺฉุฑ \n",
            "ูุงุฒููุฏ ุดุฏุฏ ุฌูุฏูุง ุฏฺฏู ุงู ูุทูุง ูุฑ ฺู ุณุฑุนุชุฑ ุจุง ุชุดฺฉุฑ \n",
            "ุณูุงู ุจุจุฎุดุฏ ูู ุฏุงูููุฏ ฺฉุฑุฏู ู ุฎุฑุฏู ูู ุงู ฺฉุชุงุจู ูู ฺฉุชุงุจ ูพุฑุณุชุงุฑุจููุด ุฌูุฏ ุงูู ุงูุง ูุชุงุณูุงูู ุชู ฺฏูุดู ูุฑูุณ ฺฉุด ฺฉุฑุฏู ุงูฺฏุงุฑ ุงุทูุงุนุงุช ุจุฑูุงูู ุทุงูฺู ูู ูพุฑุฏ ุฏูุจุงุฑู ูุตุจ ฺฉุฑุฏู ุงูุงู ฺฉุชุงุจุง ูุณุชู ู ุฒุฏู ฺฉู ุจุงุฏ ุจุฎุฑู . ุนู ุชู ุญุณุงุจ ฺฉุงุฑุจุฑ ูู ุซุจุช ููุดู ฺ ฺฉุชุงุจุง ุฎุฑุฏู ุ ุจุตูุฑุช ูพ ุฏ ุงูู ฺฉู ุชู ฺฏูุด ุณู ููุดู ุฎุงุฑุฌ ุงุฒ ุจุฑูุงูู . ูุทูุง ุฑุงูููุง ฺฉูุฏ .ููููู\n",
            "ุณูุงู ุจุจุฎุดุฏ ูู ุฏุงูููุฏ ฺฉุฑุฏู ู ุฎุฑุฏู ูู ุงู ฺฉุชุงุจู ูู ฺฉุชุงุจ ูพุฑุณุชุงุฑุจููุด ุฌูุฏ ุงูู ุงูุง ูุชุงุณูุงูู ุชู ฺฏูุดู ูุฑูุณ ฺฉุด ฺฉุฑุฏู ุงูฺฏุงุฑ ุงุทูุงุนุงุช ุจุฑูุงูู ุทุงูฺู ูู ูพุฑุฏ ุฏูุจุงุฑู ูุตุจ ฺฉุฑุฏู ุงูุงู ฺฉุชุงุจุง ูุณุชู ู ุฒุฏู ฺฉู ุจุงุฏ ุจุฎุฑู . ุนู ุชู ุญุณุงุจ ฺฉุงุฑุจุฑ ูู ุซุจุช ููุดู ฺ ฺฉุชุงุจุง ุฎุฑุฏู ุ ุจุตูุฑุช ูพ ุฏ ุงูู ฺฉู ุชู ฺฏูุด ุณู ููุดู ุฎุงุฑุฌ ุงุฒ ุจุฑูุงูู . ูุทูุง ุฑุงูููุง ฺฉูุฏ .ููููู\n",
            "ุณูุงู ูู ุฎุฑุฏู ุฏุงูููุฏู ฺฉุฑุฏู ุงูุง ุชู ฺฏูุดู ูุณุชุด ฺฉู ุจุฎุงู ุฒูุงู ุงููุงู ุจุฎูููุด ุ ุงฺฏู ูุดู ุฑุงูููุง ฺฉูุฏ\n",
            "ุณูุงู ูู ุฎุฑุฏู ุฏุงูููุฏู ฺฉุฑุฏู ุงูุง ุชู ฺฏูุดู ูุณุชุด ฺฉู ุจุฎุงู ุฒูุงู ุงููุงู ุจุฎูููุด ุ ุงฺฏู ูุดู ุฑุงูููุง ฺฉูุฏ\n",
            "ุจูู ุฌูุฏ ูุงุดู ุจุงุฑุฏ ุฏฺฏ ูุทูุง\n",
            "ุจูู ุฌูุฏ ูุงุดู ุจุงุฑุฏ ุฏฺฏ ูุทูุง\n",
            "ููุฏููู ุฏุงุณุชุงู ูุง ุจ ูุนู ู ููููู ุจูุฏ ุง ูู ฺุฒ ุงุฒุดูู ููููุฏูุ ฺฉูุง ุฏูุชุงุดู ุจุดุชุฑ ูุชููุณุชู ุจุฎููู ุญุงูู ุจุฏ ุดุฏ\n",
            "ููุฏููู ุฏุงุณุชุงู ูุง ุจ ูุนู ู ููููู ุจูุฏ ุง ูู ฺุฒ ุงุฒุดูู ููููุฏูุ ฺฉูุง ุฏูุชุงุดู ุจุดุชุฑ ูุชููุณุชู ุจุฎููู ุญุงูู ุจุฏ ุดุฏ\n",
            "ูพุฑ ุงุฒ ููุณุชุงูฺ ุฏุฑุฏูุงฺฉ ุจูุฏ ู ุชุตุงูุฑ ุดุงุนุฑุงูู ุฒุจุง ุงู ูุฌููุนู ุดุนุฑ ฺฉูุชุงู ุฑู ุญุชูุง ูุทุงูุนู ฺฉูุฏ ุทุงูฺู ุฌุงู ุฏุฑ ูุณูุช ุช ุถุญุงุช ุชุนุฏุงุฏ ุตูุญุงุช ุจู ุงุดุชุจุงู ููุดุชู ุดุฏู ุณุช . ุจุง ุณูพุงุณ\n",
            "ูพุฑ ุงุฒ ููุณุชุงูฺ ุฏุฑุฏูุงฺฉ ุจูุฏ ู ุชุตุงูุฑ ุดุงุนุฑุงูู ุฒุจุง ุงู ูุฌููุนู ุดุนุฑ ฺฉูุชุงู ุฑู ุญุชูุง ูุทุงูุนู ฺฉูุฏ ุทุงูฺู ุฌุงู ุฏุฑ ูุณูุช ุช ุถุญุงุช ุชุนุฏุงุฏ ุตูุญุงุช ุจู ุงุดุชุจุงู ููุดุชู ุดุฏู ุณุช . ุจุง ุณูพุงุณ\n",
            "ูู ุฏูุจุงู ฺฉุชุงุจ ูุจุชุฏ ู ูุงุจู ุฏุฑฺฉ ููุณู ุฏุฑ ููุฑุฏ ูุณุช ุจูุฏู ฺฉุชุงุจ ููุงุณุจ ุจุฑุงู ูุจูุฏ\n",
            "ูู ุฏูุจุงู ฺฉุชุงุจ ูุจุชุฏ ู ูุงุจู ุฏุฑฺฉ ููุณู ุฏุฑ ููุฑุฏ ูุณุช ุจูุฏู ฺฉุชุงุจ ููุงุณุจ ุจุฑุงู ูุจูุฏ\n",
            "ุชุฑุฌูู ุฑูุงู ููุถูุน ุจฺฉุฑ ูุชู ุงุนุฌุงุจ ุงูฺฏุฒ ุงู ฺฉุชุงุจ  ุฑุง ุญูุงูุฏู ฺฉุฑุฏู ุงุณุช ุฑูุญ ุงุญูุฏ ุดุงููู ุดุงุฏ\n",
            "ุชุฑุฌูู ุฑูุงู ููุถูุน ุจฺฉุฑ ูุชู ุงุนุฌุงุจ ุงูฺฏุฒ ุงู ฺฉุชุงุจ  ุฑุง ุญูุงูุฏู ฺฉุฑุฏู ุงุณุช ุฑูุญ ุงุญูุฏ ุดุงููู ุดุงุฏ\n",
            "ุฒูุฏู ุงุฏ ูพุฑูุฒ ุฎุณุฑูุงู ุจุง ุชุงุณุณ ุชุงุฌ ุฌุง ุฎูุฏุด ุฑู ุชุง ุงุจุฏ ุฏุฑ ููุจ ูุตู ุฌูุนุช ุงุฑุงู ุจุงุฒ ฺฉุฑุฏ ...ุฑูุญุช ุดุงุฏ ุง ุจุฒุฑฺฏูุฑุฏ .....ูุทูุฆูู ฺฉู ุชุงุฏ ููฺฉูุฏ\n",
            "ุฒูุฏู ุงุฏ ูพุฑูุฒ ุฎุณุฑูุงู ุจุง ุชุงุณุณ ุชุงุฌ ุฌุง ุฎูุฏุด ุฑู ุชุง ุงุจุฏ ุฏุฑ ููุจ ูุตู ุฌูุนุช ุงุฑุงู ุจุงุฒ ฺฉุฑุฏ ...ุฑูุญุช ุดุงุฏ ุง ุจุฒุฑฺฏูุฑุฏ .....ูุทูุฆูู ฺฉู ุชุงุฏ ููฺฉูุฏ\n",
            "๐ธ๐ธ๐ธูุณุงุจูู ฺฉุชุงุจ ุฎูุงู ุชูุณุฑ ุณูุฑู ุญูุฏ ุฏุฑ ุงูพูฺฉุดู ุดูุฏ ูุทูุฑ\n",
            "ฺฉุชุงุจ ุขุดูุง ุจุง ูุฑุขู ุฌูุฏ ุฏูู ุงุฒ ุดูุฏ ูุทูุฑ๐ธ๐ธ๐ธ\n",
            "ูุณุงุจูู ฺฉุชุงุจ ุฎูุงู ุชูุณุฑ ุณูุฑู ุญูุฏ ุฏุฑ ุงูพูฺฉุดู ุดูุฏ ูุทูุฑ\n",
            "ฺฉุชุงุจ ุขุดูุง ุจุง ูุฑุขู ุฌูุฏ ุฏูู ุงุฒ ุดูุฏ ูุทูุฑ\n",
            "ฺุฑุง ูพ ุฏ ุงููุ\n",
            "ููุงุชุญ ฺฉู ูุณ\n",
            "ููุฌ ุงูุจูุงุบู ฺฉู ูุณ\n",
            "ูุฑุขูู ฺฉู ูุณ\n",
            "...\n",
            "ฺุฑุง ูพ ุฏ ุงููุ\n",
            "ููุงุชุญ ฺฉู ูุณ\n",
            "ููุฌ ุงูุจูุงุบู ฺฉู ูุณ\n",
            "ูุฑุขูู ฺฉู ูุณ\n",
            "...\n",
            "ููููู ุนุงูู\n",
            "ููููู ุนุงูู\n",
            "ฺูุฏูู ูุงู ุฑูุถูู ุจู ุตูุฑุช ูพุงูพูุุุ ฺฉู ุงููุฏ ฺฏุฑูุชุงุฑ ุจูุฏู...\n",
            "ุจุงุฒู ูุชููุณุชู ุชูููุด ฺฉูู\n",
            "ูโุฏููู ุจู ููู ู ุฑุณูุฎ ุฏุฑ ุฏู ู ุงู ุญุฑูุงุณุ ุจู ุฎููุฏูู ุทูุทโูุงุฑ ู ุชููู ฺฉุฑุฏูู ูููโุฌูุฑ ูุณุ ุงูุง ุฏูู ูโุฎูุงุณ ุชูููุด ฺฉูู๐\n",
            "ฺูุฏูู ูุงู ุฑูุถูู ุจู ุตูุฑุช ูพุงูพูุุุ ฺฉู ุงููุฏ ฺฏุฑูุชุงุฑ ุจูุฏู...\n",
            "ุจุงุฒู ูุชููุณุชู ุชูููุด ฺฉูู\n",
            "ูโุฏููู ุจู ููู ู ุฑุณูุฎ ุฏุฑ ุฏู ู ุงู ุญุฑูุงุณุ ุจู ุฎููุฏูู ุทูุทโูุงุฑ ู ุชููู ฺฉุฑุฏูู ูููโุฌูุฑ ูุณุ ุงูุง ุฏูู ูโุฎูุงุณ ุชูููุด ฺฉูู\n",
            "ฺฉุงุด ูููู ุตูุญู ุง ฺฉู ูุฎูุงุณุชู ููููุฏ ู ุฎูุฏุด ุจู ุณูุฑู ูุง ุจุนุฏ ููุฑูุช\n",
            "ฺฉุงุด ูููู ุตูุญู ุง ฺฉู ูุฎูุงุณุชู ููููุฏ ู ุฎูุฏุด ุจู ุณูุฑู ูุง ุจุนุฏ ููุฑูุช\n",
            "ูพ ุฏ ุงู ฺุฑุชูุ ุงุตู ููุดู ุฎููุฏ!  ุณุชุงุฑู ูู ุฒุงุฏู\n",
            "ูพ ุฏ ุงู ฺุฑุชูุ ุงุตู ููุดู ุฎููุฏ!  ุณุชุงุฑู ูู ุฒุงุฏู\n",
            "ุงุนุฑุงุจ ุจุฑุฎ ุขุงุช ุดฺฉุงู ุฏุงุดุช ุจุนุถ ุญุฑูู ุงุนุฑุงุจุดุงู ุฌุง ุงูุชุงุฏู ุจูุฏ\n",
            "ุฎุท ุงูู ุชูุงู ุขุงุช ุงุนุฑุงุจุด ููุงุด ุฏุงุฏู ููโุดุฏ ุงูุฏูุงุฑู ุงู ูุดฺฉูุงุช ุฑู ุฑูุน ุจูุฑูุงุฏ\n",
            "ุงุนุฑุงุจ ุจุฑุฎ ุขุงุช ุดฺฉุงู ุฏุงุดุช ุจุนุถ ุญุฑูู ุงุนุฑุงุจุดุงู ุฌุง ุงูุชุงุฏู ุจูุฏ\n",
            "ุฎุท ุงูู ุชูุงู ุขุงุช ุงุนุฑุงุจุด ููุงุด ุฏุงุฏู ููโุดุฏ ุงูุฏูุงุฑู ุงู ูุดฺฉูุงุช ุฑู ุฑูุน ุจูุฑูุงุฏ\n",
            "ุทุจ ุงูฺฉุชุจ\n",
            "ุทุจ ุงูฺฉุชุจ\n",
            "ุจูุงู ุญุถุฑุช ุฏูุณุช...ุจุณุงุฑ ุฒุจุง ู ุฌุงูุจู . ุทุงูฺู ูููููุชูโฅ\n",
            "ฺู ฺฉุชุงุจ ูุชูุงูุฏ ุจุฑุชุฑ ุงุฒ ฺฉุชุงุจ ุจุงุดุฏ ฺฉู ููุณูุฏู ุงุด ุฎุฏุงุณุช\n",
            ".\n",
            "ุง ุนู ๐\n",
            "ุจูุงู ุญุถุฑุช ุฏูุณุช...ุจุณุงุฑ ุฒุจุง ู ุฌุงูุจู . ุทุงูฺู ูููููุชู\n",
            "ฺู ฺฉุชุงุจ ูุชูุงูุฏ ุจุฑุชุฑ ุงุฒ ฺฉุชุงุจ ุจุงุดุฏ ฺฉู ููุณูุฏู ุงุด ุฎุฏุงุณุช\n",
            ".\n",
            "ุง ุนู \n",
            "ุจุง ุณูุงู ุฎุฏูุช ููู ุฏุณุช ุงูุฏุฑ ฺฉุงุฑุงู ูุฑููฺฏ ู ุงุฏุจ ฺฉุชุงุจ ููู ูุชุงุณูุงูู ุฏุฑ ุจุฑุฎ ฺฉููุงุช ูุงูุฏ ุงุนุฑุงุจ ุจูุฏู ู ููฺฉู ุงุณุช ุฏุฑ ูุฑุงุฆุช ูุงุตุญุญ ูุนุงู ูุชูุงูุช ูพุฏุง ู ฺฉูุฏ. ูุฐุง ุงุฒ ุนุฒุฒุงู ุฎูุงูุดููุฏู ูุณุจุช ุจู ุงุตูุงุญ pdfููุฌูุฏ ูพุฑุฏุงุฎุชู ุณูพุณ ุฏุฑ ุฏุณุชุฑุณ ุนููู ูุฑุงุฑ ุฏูุฏ. ุจุง ุชุดฺฉุฑ ููู ุงููู ุงูุชููู\n",
            "ุจุง ุณูุงู ุฎุฏูุช ููู ุฏุณุช ุงูุฏุฑ ฺฉุงุฑุงู ูุฑููฺฏ ู ุงุฏุจ ฺฉุชุงุจ ููู ูุชุงุณูุงูู ุฏุฑ ุจุฑุฎ ฺฉููุงุช ูุงูุฏ ุงุนุฑุงุจ ุจูุฏู ู ููฺฉู ุงุณุช ุฏุฑ ูุฑุงุฆุช ูุงุตุญุญ ูุนุงู ูุชูุงูุช ูพุฏุง ู ฺฉูุฏ. ูุฐุง ุงุฒ ุนุฒุฒุงู ุฎูุงูุดููุฏู ูุณุจุช ุจู ุงุตูุงุญ pdfููุฌูุฏ ูพุฑุฏุงุฎุชู ุณูพุณ ุฏุฑ ุฏุณุชุฑุณ ุนููู ูุฑุงุฑ ุฏูุฏ. ุจุง ุชุดฺฉุฑ ููู ุงููู ุงูุชููู\n",
            "ูุฑุขู ุซูู ุงฺฉุจุฑู ู ุนุชุฑุช ุซูู ุงุตุบุฑุ ูุฑุงููุด ูฺฉูู ู ุฌุง ุจุฒุฑฺฏโุชุฑ ู ฺฉูฺฺฉโุชุฑ ุฑู ุฌุงุจูโุฌุง ูฺฉูู...\n",
            "ูุฑุขู ุซูู ุงฺฉุจุฑู ู ุนุชุฑุช ุซูู ุงุตุบุฑุ ูุฑุงููุด ูฺฉูู ู ุฌุง ุจุฒุฑฺฏโุชุฑ ู ฺฉูฺฺฉโุชุฑ ุฑู ุฌุงุจูโุฌุง ูฺฉูู...\n",
            "ุณู ุณุชุงุฑู ูุฏู ฺูู ูพ ุฏ ุงูู ุฎู ุณุฎุชู ุฎููุฏุด. ูุงูุง ุชุฑุฌูู ุขูุง ูููุงููุฏ ฺฉู ุฎู ุฎููุจู. ูู ุจุง ุชุฑุฌูู ูฺฉุงุฑููฌุจูุฑุงู ูพูุฑูฌุงูุตุงุฑุงู ู ููุงุณู ุฏุฑ ุญุฏ ุฎูุฏู (ุฎุนู ุงุจุชุฏุง) ฺฉุฑุฏู ู ุงูู ุจูุชุฑ ุฏุฏู.\n",
            "ุชุฑุฌูู ูููุงููุฏ ุจู ุชุญุช ุงููุธ ู ูุญุชูุงู ูฌููุงุฏุงุฑ ุจุดุชุฑ ูุณุจุช ุจู ูุชู ู ููฺูู ุณุงุฎุชุงุฑ ุขู ูุง ุฏุงุฑู. ูู ูุซู ุชุญุช ุงููุธ ุจ ูุนูู ู ูู ูุซู ูุญุชูุง (ุชุฑุฌูู ูฺฉุงุฑู) ูููู ุงุฒ ูพุฑุงูุชุฒ ู ุจุฑุฏุงุดุช ูุชุฑุฌูู. ู ุชุฑุฌูู ูุฑุงู ุฏฺฏู ูู ุงุฒ ุขูุง ูุญูุฏ ุนู ฺฉูุดุง ุงูุณุงู ุจุงูุงุฎุฑู ููุชุดุฑ ูุดู ฺฉู ุงุฒ ููู ุงููุง ุจูุชุฑู!\n",
            "ุณู ุณุชุงุฑู ูุฏู ฺูู ูพ ุฏ ุงูู ุฎู ุณุฎุชู ุฎููุฏุด. ูุงูุง ุชุฑุฌูู ุขูุง ูููุงููุฏ ฺฉู ุฎู ุฎููุจู. ูู ุจุง ุชุฑุฌูู ูฺฉุงุฑููฌุจูุฑุงู ูพูุฑูฌุงูุตุงุฑุงู ู ููุงุณู ุฏุฑ ุญุฏ ุฎูุฏู (ุฎุนู ุงุจุชุฏุง) ฺฉุฑุฏู ู ุงูู ุจูุชุฑ ุฏุฏู.\n",
            "ุชุฑุฌูู ูููุงููุฏ ุจู ุชุญุช ุงููุธ ู ูุญุชูุงู ูฌููุงุฏุงุฑ ุจุดุชุฑ ูุณุจุช ุจู ูุชู ู ููฺูู ุณุงุฎุชุงุฑ ุขู ูุง ุฏุงุฑู. ูู ูุซู ุชุญุช ุงููุธ ุจ ูุนูู ู ูู ูุซู ูุญุชูุง (ุชุฑุฌูู ูฺฉุงุฑู) ูููู ุงุฒ ูพุฑุงูุชุฒ ู ุจุฑุฏุงุดุช ูุชุฑุฌูู. ู ุชุฑุฌูู ูุฑุงู ุฏฺฏู ูู ุงุฒ ุขูุง ูุญูุฏ ุนู ฺฉูุดุง ุงูุณุงู ุจุงูุงุฎุฑู ููุชุดุฑ ูุดู ฺฉู ุงุฒ ููู ุงููุง ุจูุชุฑู!\n",
            "ุญูุฑููููุชู ุนููููฺฉููู ุงูููููุชูุฉู ููุงูุฏูููู ููููุญููู ุงููุฎูููุฒูุฑู ููููุง ุฃูููููู ููุบููุฑู ุงูููููู ุจููู ููุงููููููุฎูููููุฉู ููุงูููููููููุฐูุฉู ููุงููููุชูุฑูุฏูููุฉู ููุงููููุทูุญูุฉู ููููุง ุฃูฺฉููู ุงูุณููุจูุนู ุฅููููุง ููุง ุฐูฺฉูููุชููู ููููุง ุฐูุจูุญู ุนููู ุงููููุตูุจู ููุฃููู ุชูุณูุชูููุณููููุง ุจูุงููุฃูุฒูููุงูู  ุฐููฐููฺฉููู ููุณููู  ุงููููููู ูุฆูุณู ุงูููุฐููู ฺฉูููุฑููุง ูููู ุฏูููฺฉููู ููููุง ุชูุฎูุดููููููู ููุงุฎูุดููููู  ุงููููููู ุฃูฺฉูููููุชู ููฺฉููู ุฏูููฺฉููู ููุฃูุชูููููุชู ุนููููฺฉููู ููุนูููุชู ููุฑูุถูุชู ููฺฉููู ุงููุฅูุณูููุงูู ุฏูููุง  ูููููู ุงุถูุทูุฑูู ูู ููุฎูููุตูุฉู ุบููุฑู ููุชูุฌูุงูููู ููุฅูุซููู  ููุฅูููู ุงูููููู ุบููููุฑู ุฑูุญููู\n",
            "ุนุงุดู ุขู ูพุงู ูุณุชู ฺฉู ุฎุฏุงููุฏ ุฏุฑ ุฏู ุงู ุขู ูพููุงู ฺฉุฑุฏู ุงุณุช. ููููู ุฑุง ููุฏ ู ุฏูุฏ ุจู ฺฉุงูู ฺฉุฑุฏู ุฏู ู ูุงุงูุฏ ฺฉุงูุฑุงู... ุณูุงู ุจุฑ ุงูุฑุงููููููุ ุณูุงู ุจุฑ ูุฑุฒูุฏุด ููุฏ ู ุณูุงู ุจุฑ ุดุนุงูุด ฺฉู ูุงุฑุซุงู ุฒูู ุฎูุงููุฏ ุจูุฏ ู ูุงุจูุฏ ฺฉููุฏู ฺฉุงูุฑุงู...\n",
            "ุญูุฑููููุชู ุนููููฺฉููู ุงูููููุชูุฉู ููุงูุฏูููู ููููุญููู ุงููุฎูููุฒูุฑู ููููุง ุฃูููููู ููุบููุฑู ุงูููููู ุจููู ููุงููููููุฎูููููุฉู ููุงูููููููููุฐูุฉู ููุงููููุชูุฑูุฏูููุฉู ููุงููููุทูุญูุฉู ููููุง ุฃูฺฉููู ุงูุณููุจูุนู ุฅููููุง ููุง ุฐูฺฉูููุชููู ููููุง ุฐูุจูุญู ุนููู ุงููููุตูุจู ููุฃููู ุชูุณูุชูููุณููููุง ุจูุงููุฃูุฒูููุงูู  ุฐููฐููฺฉููู ููุณููู  ุงููููููู ูุฆูุณู ุงูููุฐููู ฺฉูููุฑููุง ูููู ุฏูููฺฉููู ููููุง ุชูุฎูุดููููููู ููุงุฎูุดููููู  ุงููููููู ุฃูฺฉูููููุชู ููฺฉููู ุฏูููฺฉููู ููุฃูุชูููููุชู ุนููููฺฉููู ููุนูููุชู ููุฑูุถูุชู ููฺฉููู ุงููุฅูุณูููุงูู ุฏูููุง  ูููููู ุงุถูุทูุฑูู ูู ููุฎูููุตูุฉู ุบููุฑู ููุชูุฌูุงูููู ููุฅูุซููู  ููุฅูููู ุงูููููู ุบููููุฑู ุฑูุญููู\n",
            "ุนุงุดู ุขู ูพุงู ูุณุชู ฺฉู ุฎุฏุงููุฏ ุฏุฑ ุฏู ุงู ุขู ูพููุงู ฺฉุฑุฏู ุงุณุช. ููููู ุฑุง ููุฏ ู ุฏูุฏ ุจู ฺฉุงูู ฺฉุฑุฏู ุฏู ู ูุงุงูุฏ ฺฉุงูุฑุงู... ุณูุงู ุจุฑ ุงูุฑุงููููููุ ุณูุงู ุจุฑ ูุฑุฒูุฏุด ููุฏ ู ุณูุงู ุจุฑ ุดุนุงูุด ฺฉู ูุงุฑุซุงู ุฒูู ุฎูุงููุฏ ุจูุฏ ู ูุงุจูุฏ ฺฉููุฏู ฺฉุงูุฑุงู...\n",
            "ู ูุทุนุง ุจุฑุง ุดูุง ุฏุฑ ุฒูู ูุฏุฑุช ุนูู ู ูุณุงู ูุนุดุช ูุฑุงุฑ ุฏุงุฏู ...!\n",
            "ุงูุง ุฎู ฺฉู ุดฺฉุฑฺฏุฐุงุฑ ูฺฉูุฏ ...!\n",
            "ุงุนุฑุงู /ูกู ุงฺฏู ุชู ููู ุขู ุชููุง ูฺฉุฑ ฺฉูุฏ ุฒูุฏฺฏุชูู ุฑู ูกูจู ุฏุฑุฌู ุชุบุฑ ูุฏู\n",
            "ู ูุทุนุง ุจุฑุง ุดูุง ุฏุฑ ุฒูู ูุฏุฑุช ุนูู ู ูุณุงู ูุนุดุช ูุฑุงุฑ ุฏุงุฏู ...!\n",
            "ุงูุง ุฎู ฺฉู ุดฺฉุฑฺฏุฐุงุฑ ูฺฉูุฏ ...!\n",
            "ุงุนุฑุงู /ูกู ุงฺฏู ุชู ููู ุขู ุชููุง ูฺฉุฑ ฺฉูุฏ ุฒูุฏฺฏุชูู ุฑู ูกูจู ุฏุฑุฌู ุชุบุฑ ูุฏู\n",
            "ุญุงูุธู ุฒุงุฏ ูุฎูุงุฏ\n",
            "ุญุงูุธู ุฒุงุฏ ูุฎูุงุฏ\n",
            "ฺฉุงุด ูพ ุฏ ุงู ูุจูุฏ ุ ุฎูุงุณุชู ุจุฎููู ุงุตู ูู ุดุฏ\n",
            "ฺฉุงุด ูพ ุฏ ุงู ูุจูุฏ ุ ุฎูุงุณุชู ุจุฎููู ุงุตู ูู ุดุฏ\n",
            "\"ููููุฏ ุฎููููููุง ุงูุงูุณุงูู ู ฺฉูุจูุฏ\"\n",
            "*ููุงูุง ุงูุณุงู ุฑุง ุฏุฑ ุฑูุฌ ุขูุฑุฏู\n",
            "ุฎุฏุง ูุง ุฑู ูุฌุงุช ุจุฏู ุงุฒ ุจ ุฏุฑุฏ...\n",
            "ููุช ุจ ุฏุฑุฏ ุดุฏู ุจุงุฏ ุจุชุฑุณู ุงุฒ ุฎูุฏูููุ ฺฉู ุงุฒ ููุงู ุงูุณุงูุช ูพุงู ูููุฏู ุจุงุดู\n",
            "ู ุฎุฏุง ฺฉููุ ุฎุฏุง! ุจู ูุง ุฏุฑุฏุง ูุดูฺฏ ุจุฏูุ ูู ุฏุฑุฏุง ฺฉูฺฺฉ ู ุจ ุงุฑุฒุด...\n",
            "\"ููููุฏ ุฎููููููุง ุงูุงูุณุงูู ู ฺฉูุจูุฏ\"\n",
            "*ููุงูุง ุงูุณุงู ุฑุง ุฏุฑ ุฑูุฌ ุขูุฑุฏู\n",
            "ุฎุฏุง ูุง ุฑู ูุฌุงุช ุจุฏู ุงุฒ ุจ ุฏุฑุฏ...\n",
            "ููุช ุจ ุฏุฑุฏ ุดุฏู ุจุงุฏ ุจุชุฑุณู ุงุฒ ุฎูุฏูููุ ฺฉู ุงุฒ ููุงู ุงูุณุงูุช ูพุงู ูููุฏู ุจุงุดู\n",
            "ู ุฎุฏุง ฺฉููุ ุฎุฏุง! ุจู ูุง ุฏุฑุฏุง ูุดูฺฏ ุจุฏูุ ูู ุฏุฑุฏุง ฺฉูฺฺฉ ู ุจ ุงุฑุฒุด...\n",
            "ููุงุฒ ุฑูุฒู ูุงุชูู ูุจูู ุจุงุดู ููฺฏ...\n",
            "ุนุฌุจ ูุงู... ุนุฌุจ ุญุงู ู ููุง โบ๏ธ\n",
            "ููุงุฒ ุฑูุฒู ูุงุชูู ูุจูู ุจุงุดู ููฺฏ...\n",
            "ุนุฌุจ ูุงู... ุนุฌุจ ุญุงู ู ููุง \n",
            "ูุณุฎู epub ูุฑุขู ฺฉุฑู ุงุฒ ููฺฉ ุฒุฑ ูุงุจู ุฏุฑุงูุช ุงุณุช.\n",
            "______________________________\n",
            ".\n",
            ".\n",
            "https://taaghche.ir/book/2679\n",
            "ูุณุฎู epub ูุฑุขู ฺฉุฑู ุงุฒ ููฺฉ ุฒุฑ ูุงุจู ุฏุฑุงูุช ุงุณุช.\n",
            "______________________________\n",
            ".\n",
            ".\n",
            "https://taaghche.ir/book/2679\n",
            "ููู  ฺฉุชุงุจ ูุง ุนุงู ุฑู ุฏุงุฑู ุญุงูุธ ุณูุฏ ูุฑุงู ุดุงููุงูู ููุดู ุฑุงฺฏุงูู\n",
            "ููู  ฺฉุชุงุจ ูุง ุนุงู ุฑู ุฏุงุฑู ุญุงูุธ ุณูุฏ ูุฑุงู ุดุงููุงูู ููุดู ุฑุงฺฏุงูู\n",
            "ูุฑุขูุ ุนูู ุชุฑู ู ุฑุงุฒุขููุฏ ุชุฑู ฺฉุชุงุจ ุฌูุงูู. ูุง ุจู ุญุงู ุงูุซุงู ููุ ฺฉู ูุงุณู ุฎููุฏู ฺฉุชุงุจ ูุง ุฏฺฏู ูุดุชุงูู ู ูุณุจุช ุจู ูุฑุขูุ ุจ ุฑุบุจุช ...\n",
            "ูุฑุขูุ ุนูู ุชุฑู ู ุฑุงุฒุขููุฏ ุชุฑู ฺฉุชุงุจ ุฌูุงูู. ูุง ุจู ุญุงู ุงูุซุงู ููุ ฺฉู ูุงุณู ุฎููุฏู ฺฉุชุงุจ ูุง ุฏฺฏู ูุดุชุงูู ู ูุณุจุช ุจู ูุฑุขูุ ุจ ุฑุบุจุช ...\n",
            "ฺฉุงุด ุบุฑุจ ุชุฑู ฺฉุชุงุจ ุงุฒ ุบุฑุจุช ุจุฑูู ุจุงุฏ\n",
            "ฺฉุงุด ุบุฑุจ ุชุฑู ฺฉุชุงุจ ุงุฒ ุบุฑุจุช ุจุฑูู ุจุงุฏ\n",
            "very good\n",
            "very good\n",
            "ุฏุณุช ุขูุง ูููุงุฏููุฏ ุฏุฑุฏูฺฉูู ุจุง ุชุฑุฌูู ุจุณุงุฑ ุฎูุจุด ูุงูุนุง ุฎู ุฎู ุนุงูู ูพูุฌ ุณุชุงุฑู ฺฉูู ูุงุณู ุงู ฺฉุชุงุจ ุจุง ุงุฑุฒุด\n",
            "ุฏุณุช ุขูุง ูููุงุฏููุฏ ุฏุฑุฏูฺฉูู ุจุง ุชุฑุฌูู ุจุณุงุฑ ุฎูุจุด ูุงูุนุง ุฎู ุฎู ุนุงูู ูพูุฌ ุณุชุงุฑู ฺฉูู ูุงุณู ุงู ฺฉุชุงุจ ุจุง ุงุฑุฒุด\n",
            "ุจูุชุฑู ุชุฑุฌูู ุง ฺฉู ุชุง ุญุงูุง ุฏุฏู!\n",
            "ุจูุชุฑู ุชุฑุฌูู ุง ฺฉู ุชุง ุญุงูุง ุฏุฏู!\n",
            "ุฑุงู ฺฉู ุจุฑุง ุฐูุช ูุง ุฏุดูู ุงูุชุฎุงุจ ฺฉุฑุฏู ุงุณุชุ ุจูุชุฑู ุฑุงูููุง ุงุณุช ุชุง ุจุฑุง ุนุฒุช ุฎูุด ุงูุชุฎุงุจ ฺฉูู.\n",
            "ุจุงุฒฺฏุดุชู ุฏุฑุณุช ุงุฒ ููุงู ุฑุงู ฺฉู ุงู ูุงุฑุง ุจุฑุฏู ุงุณุช.\n",
            "ุจุงุฒ ุขูุฑุฏู ูุฑุขู ุงุฒ ูุจุฑุณุชุงู ุจู ุดูุฑุ ุชูุงูุช ุขู ุงุฒ ุงู ูพุณ ุจุฑุง ุฒูุฏฺฏุงู! ู ูุฑูุฏ ุขูุฑุฏู ูุฑุขู ุงุฒ ุจุงูุง ุฑู ู ฺฏุดูุฏูุด ุฏุฑ ูพุด ุฑู ุฏุฑุณ.\n",
            "ูุฑุขู ุฑุง ูุชูุงูุณุชูุฏ ูุงุจูุฏ ฺฉููุฏ ุจุณุชูุฏ ู ฺฉุชุงุจ ุฑุง ฺฉ ุด ูุชุจุฑฺฉ ฺฉุฑุฏูุฏ.\n",
            "ุขู ุฑุง ุฏูุจุงุฑู ฺฉุชุงุจ ฺฉูู ูฺฉุชุงุจู ุฎูุงูุฏู! ฺฉู ูุฑุขู ุนู ฺฉุชุงุจู ุฎูุงูุฏู...\n",
            "ุญุฌ/ุฏฺฉุชุฑ ุนู ุดุฑุนุช\n",
            "ุฑุงู ฺฉู ุจุฑุง ุฐูุช ูุง ุฏุดูู ุงูุชุฎุงุจ ฺฉุฑุฏู ุงุณุชุ ุจูุชุฑู ุฑุงูููุง ุงุณุช ุชุง ุจุฑุง ุนุฒุช ุฎูุด ุงูุชุฎุงุจ ฺฉูู.\n",
            "ุจุงุฒฺฏุดุชู ุฏุฑุณุช ุงุฒ ููุงู ุฑุงู ฺฉู ุงู ูุงุฑุง ุจุฑุฏู ุงุณุช.\n",
            "ุจุงุฒ ุขูุฑุฏู ูุฑุขู ุงุฒ ูุจุฑุณุชุงู ุจู ุดูุฑุ ุชูุงูุช ุขู ุงุฒ ุงู ูพุณ ุจุฑุง ุฒูุฏฺฏุงู! ู ูุฑูุฏ ุขูุฑุฏู ูุฑุขู ุงุฒ ุจุงูุง ุฑู ู ฺฏุดูุฏูุด ุฏุฑ ูพุด ุฑู ุฏุฑุณ.\n",
            "ูุฑุขู ุฑุง ูุชูุงูุณุชูุฏ ูุงุจูุฏ ฺฉููุฏ ุจุณุชูุฏ ู ฺฉุชุงุจ ุฑุง ฺฉ ุด ูุชุจุฑฺฉ ฺฉุฑุฏูุฏ.\n",
            "ุขู ุฑุง ุฏูุจุงุฑู ฺฉุชุงุจ ฺฉูู ูฺฉุชุงุจู ุฎูุงูุฏู! ฺฉู ูุฑุขู ุนู ฺฉุชุงุจู ุฎูุงูุฏู...\n",
            "ุญุฌ/ุฏฺฉุชุฑ ุนู ุดุฑุนุช\n",
            "ุนุฏ ูุทุฑ ุฑุง ูพุดุงูพุด ุจู ุชูุงู ุฑูุฒุฏุงุฑุงู ุชุจุฑฺฉ ู ฺฏูู\n",
            "ุงูุชูุงุณ ุฏุนุง\n",
            "ุนุฏ ูุทุฑ ุฑุง ูพุดุงูพุด ุจู ุชูุงู ุฑูุฒุฏุงุฑุงู ุชุจุฑฺฉ ู ฺฏูู\n",
            "ุงูุชูุงุณ ุฏุนุง\n",
            "ูุฑุขูโูุง ุงูฺฉุชุฑฺฉ ู ููุดููุฏ ุนุงู ุงุณุช \n",
            "ููู ุฌุง ุจุง ุฎูุฏูุงู ุฏุงุฑู \n",
            "ูุงูุนุง ุนุงูููููู ุงุณุช\n",
            "ูุฑุขูโูุง ุงูฺฉุชุฑฺฉ ู ููุดููุฏ ุนุงู ุงุณุช \n",
            "ููู ุฌุง ุจุง ุฎูุฏูุงู ุฏุงุฑู \n",
            "ูุงูุนุง ุนุงูููููู ุงุณุช\n",
            "ุงุจู ุงุณุญุงู ฺฉูุฏุ ููุณูู ุนุฑุงู ุจูุฏ ฺฉู ุฏุฑ ููู ูุฑู ุณูู ูุฌุฑ ู ููุฒูุงู ุจุง ุนุตุฑ ุงูุงู ุญุณู ุนุณฺฉุฑ(ุนูู ุงูุณูุงู) ู ุฒุณุช. ุงู ุจู ุชูููู ุชูุงูุถ ู ุงุฎุชูุงู ุฏุฑ ุขุงุช ูุฑุขูุ ูุดุบูู ุฌูุน โุขูุฑ ุขุงุช ุดุฏ. ู ุขูโูุง ุฑุง ุจู ุตูุฑุช ุฑุณุงูู ุชุฏูู ฺฉุฑุฏ. ฺูู ุงูุงู ุญุณู ุนุณฺฉุฑ(ุนูู ุงูุณูุงู) ุชูุณูุท ฺฉ ุงุฒ ุดุงฺฏุฑุฏุงู ุงู ุงุฒ ุงู ูุทูุจ ุขฺฏุงู ุดุฏุ ูุฑููุฏ: ุขุง ูู ุชูุงูุฏ ุงุณุชุงุฏุชุงู ุฑุง ุงุฒ ุงู ฺฉุงุฑ ููุตุฑู ฺฉูุฏ. ุฏุฑ ุงุฏุงูู ุญุถุฑุช ุจู ฺฉ ุงุฒ ุดุงฺฏุฑุฏุงู ุงุจู ุงุณุญุงู ฺฉูุฏ ูุฑููุฏ: ยซุจุฑู ู ุงุฒ ุงุณุชุงุฏุช ุจูพุฑุณ: ุขุง ุงูฺฉุงู ุฏุงุฑุฏ ุฑูุฒ ุฎุฏุงููุฏ ุจฺฏูุฏ ฺฉู ูู ุงุฒ ุขุงุช ูุฑุขูุ ูุฏู ุบุฑ ุงุฒ ุขูฺู ุชู ูููุฏ ุฏุงุดุชูุ ฺูุงูฺู ูพุฐุฑูุชุ ุจฺฏู: ูพุณ ฺฺฏููู ูุฏูุน ุชูุงูุถ ุจู ุขุงุช ูุฑุขู ูุณุชุยป. ุดุงฺฏุฑุฏ ุฏุฑ ุฎุฏูุช ุงุณุชุงุฏุ ููู ูุทุงูุจ ุฑุง ุจุงุฒฺฏู ฺฉุฑุฏ. ุงู ฺฉู ุงุฒ ุงู ุงุณุชุฏูุงู ุดฺฏูุช ุฒุฏู ุดุฏู ุจูุฏุ ุขุชุด ุงูุฑูุฎุช ู ุฏุณุช ููุดุชู โูุงุด ุฑุง ุฏุฑ ุขู ุงูฺฉูุฏ.\n",
            "\n",
            "ููุจุน:ูพุงฺฏุงู ุงุทูุงุน ุฑุณุงู ุฏูุชุฑ ุญุถุฑุช ุขุช ุงููู ูฺฉุงุฑู ุดุฑุงุฒ/ูุณูุช ฺฉุชุงุจ ู ููุงูุงุช/ุจุฎุด ููุงูุงุช/ููุงูู \"ฺฏูุงู ุชูุงูุถ ุฏุฑ ูุฑุขู\"\n",
            "ุงุจู ุงุณุญุงู ฺฉูุฏุ ููุณูู ุนุฑุงู ุจูุฏ ฺฉู ุฏุฑ ููู ูุฑู ุณูู ูุฌุฑ ู ููุฒูุงู ุจุง ุนุตุฑ ุงูุงู ุญุณู ุนุณฺฉุฑ(ุนูู ุงูุณูุงู) ู ุฒุณุช. ุงู ุจู ุชูููู ุชูุงูุถ ู ุงุฎุชูุงู ุฏุฑ ุขุงุช ูุฑุขูุ ูุดุบูู ุฌูุน โุขูุฑ ุขุงุช ุดุฏ. ู ุขูโูุง ุฑุง ุจู ุตูุฑุช ุฑุณุงูู ุชุฏูู ฺฉุฑุฏ. ฺูู ุงูุงู ุญุณู ุนุณฺฉุฑ(ุนูู ุงูุณูุงู) ุชูุณูุท ฺฉ ุงุฒ ุดุงฺฏุฑุฏุงู ุงู ุงุฒ ุงู ูุทูุจ ุขฺฏุงู ุดุฏุ ูุฑููุฏ: ุขุง ูู ุชูุงูุฏ ุงุณุชุงุฏุชุงู ุฑุง ุงุฒ ุงู ฺฉุงุฑ ููุตุฑู ฺฉูุฏ. ุฏุฑ ุงุฏุงูู ุญุถุฑุช ุจู ฺฉ ุงุฒ ุดุงฺฏุฑุฏุงู ุงุจู ุงุณุญุงู ฺฉูุฏ ูุฑููุฏ: ยซุจุฑู ู ุงุฒ ุงุณุชุงุฏุช ุจูพุฑุณ: ุขุง ุงูฺฉุงู ุฏุงุฑุฏ ุฑูุฒ ุฎุฏุงููุฏ ุจฺฏูุฏ ฺฉู ูู ุงุฒ ุขุงุช ูุฑุขูุ ูุฏู ุบุฑ ุงุฒ ุขูฺู ุชู ูููุฏ ุฏุงุดุชูุ ฺูุงูฺู ูพุฐุฑูุชุ ุจฺฏู: ูพุณ ฺฺฏููู ูุฏูุน ุชูุงูุถ ุจู ุขุงุช ูุฑุขู ูุณุชุยป. ุดุงฺฏุฑุฏ ุฏุฑ ุฎุฏูุช ุงุณุชุงุฏุ ููู ูุทุงูุจ ุฑุง ุจุงุฒฺฏู ฺฉุฑุฏ. ุงู ฺฉู ุงุฒ ุงู ุงุณุชุฏูุงู ุดฺฏูุช ุฒุฏู ุดุฏู ุจูุฏุ ุขุชุด ุงูุฑูุฎุช ู ุฏุณุช ููุดุชู โูุงุด ุฑุง ุฏุฑ ุขู ุงูฺฉูุฏ.\n",
            "\n",
            "ููุจุน:ูพุงฺฏุงู ุงุทูุงุน ุฑุณุงู ุฏูุชุฑ ุญุถุฑุช ุขุช ุงููู ูฺฉุงุฑู ุดุฑุงุฒ/ูุณูุช ฺฉุชุงุจ ู ููุงูุงุช/ุจุฎุด ููุงูุงุช/ููุงูู \"ฺฏูุงู ุชูุงูุถ ุฏุฑ ูุฑุขู\"\n",
            "ุฎู ุฎูุจ ุงุณุช๐\n",
            "ุฎู ุฎูุจ ุงุณุช\n",
            "ุฎูุจู ูู ุฌุง ฺฉ ูุณุฎู epub ุงุฒ ูุฑุขู ุฏุฑ ุงุฑุงู ู ุทุงูฺู ุฎุงูู\n",
            "ุฎูุจู ูู ุฌุง ฺฉ ูุณุฎู epub ุงุฒ ูุฑุขู ุฏุฑ ุงุฑุงู ู ุทุงูฺู ุฎุงูู\n",
            "ุจุฑุง ุงูฺฉู ุดููุบฺฉุงุฑ ูุดู ุ ูุธุฑ ฺูุฏ ุฏุงูุดููุฏ ุง ุงุฏุจ ุฑู ฺฉู ุงุฒ ฺฉุชุงุจ ุฏุฑ ุญุฏุซ ุฏฺฏุฑุงู ุ ููุดุชู ุฑู ุฏุฑ ูพุงุณุฎ ูุง ุงู ูุธุฑ ูุฑุงุฑ ูุฏู.\n",
            "ุจุฑุง ุงูฺฉู ุดููุบฺฉุงุฑ ูุดู ุ ูุธุฑ ฺูุฏ ุฏุงูุดููุฏ ุง ุงุฏุจ ุฑู ฺฉู ุงุฒ ฺฉุชุงุจ ุฏุฑ ุญุฏุซ ุฏฺฏุฑุงู ุ ููุดุชู ุฑู ุฏุฑ ูพุงุณุฎ ูุง ุงู ูุธุฑ ูุฑุงุฑ ูุฏู.\n",
            "ุฏฺฉุชุฑ ุนุจุฏุงูฺฉุฑู ุณุฑูุด(ููุงูุฏุด ุฏู) ุจุฑ ุงู ุจุงูุฑ ุงุณุช ฺฉู ูุฑุขู ุนูู ูุณุช.\n",
            "ุงู ูุนุชูุฏ ุงุณุช ฺฉู ูุณุจุช ุฏุงุฏู ูุฑุขู ุจู  ุนูู ุจู ุจุงุฒ ุญุฑู ุชู ุฏุงุฏู ุงุณุช.\n",
            "ู ูุชุฌู ุง ุฌุฒ ุดฺฉุณุช ูุฏุงุฑุฏ.\n",
            "\n",
            "ุฏฺฉุชุฑ ุณุฑูุด ุฏุฑ ฺฉุชุงุจ ุนูู ฺุณุชุ ููุณูู ฺุณุชุ\n",
            "ุงูุทูุฑ ูฺฏูุ\n",
            "ใู ฺู ุงูุฏูู ุจุงุฑ ู ุฑูุฌ ุขูุฑ ุงุณุช ฺฉู ู ุจูู ฺฉุณุงู ูููุฏุงูู ู ุนุงูุงูู ุจู ุฏูุงุน ุงุฒ ุนูู ุจูุฏู ุงุณูุงู ู ุงูุงู ุจุฑุฎูุงุณุชู ุงูุฏ.\n",
            "ู ุฏุฑ ุบุงุช ุฎุงู ู ุณุงุฏู ููุญ ุชู ุจู ุงูุณูู ุฑูุจ ุฏุงุฏู ุงูุฏ.ใ\n",
            "ุฏฺฉุชุฑ ุนุจุฏุงูฺฉุฑู ุณุฑูุด(ููุงูุฏุด ุฏู) ุจุฑ ุงู ุจุงูุฑ ุงุณุช ฺฉู ูุฑุขู ุนูู ูุณุช.\n",
            "ุงู ูุนุชูุฏ ุงุณุช ฺฉู ูุณุจุช ุฏุงุฏู ูุฑุขู ุจู  ุนูู ุจู ุจุงุฒ ุญุฑู ุชู ุฏุงุฏู ุงุณุช.\n",
            "ู ูุชุฌู ุง ุฌุฒ ุดฺฉุณุช ูุฏุงุฑุฏ.\n",
            "\n",
            "ุฏฺฉุชุฑ ุณุฑูุด ุฏุฑ ฺฉุชุงุจ ุนูู ฺุณุชุ ููุณูู ฺุณุชุ\n",
            "ุงูุทูุฑ ูฺฏูุ\n",
            "ู ฺู ุงูุฏูู ุจุงุฑ ู ุฑูุฌ ุขูุฑ ุงุณุช ฺฉู ู ุจูู ฺฉุณุงู ูููุฏุงูู ู ุนุงูุงูู ุจู ุฏูุงุน ุงุฒ ุนูู ุจูุฏู ุงุณูุงู ู ุงูุงู ุจุฑุฎูุงุณุชู ุงูุฏ.\n",
            "ู ุฏุฑ ุบุงุช ุฎุงู ู ุณุงุฏู ููุญ ุชู ุจู ุงูุณูู ุฑูุจ ุฏุงุฏู ุงูุฏ.\n",
            "ุฑุงู ูุทุฑุช\n",
            "\n",
            "ุฑุงู ูุงูุน ุจุฑุง ุงูุณุงู ุฏุฑ ูุณุฑ ุฒูุฏฺฏ ููุงู ุงุณุช ฺฉู ุขูุฑูุด ูฺูโ ู ุจู ุณู ุขู ุฏุนูุช ู ฺฉูุฏ ู ููุฑุฑุงุช ุฑุง ุฏุฑ ุฒูุฏฺฏ ูุฑุฏ ู ุงุฌุชูุงุน ุฎูุฏ ุจุงุฏ ุจู ฺฉุงุฑ ุจูุฏุฏ ฺฉู ุทุจุนุช ฺฉ ุงูุณุงู ูุทุฑ (ุทุจุน) ุจู ุณู ุขููุง ูุฏุงุช ูโฺฉูุฏ ูู ุงูุณุงููุง ฺฉู ุจู ููุง ู ููุณ ุขููุฏู ู ุฏุฑ ุจุฑุงุจุฑ ุนูุงุทู ู ุงุญุณุงุณุงุช ุงุณุฑ ุฏุณุช ุจุณุชู ู ุจุงุดุฏ.\n",
            "\n",
            "ููุชุถุง ุฏู ูุทุฑ ุงู ุงุณุช ฺฉู ุชุฌูุฒุงุช ูุฌูุฏ ุงูุณุงู ุงูุบุง ูุดูุฏ ู ุญู ูุฑ ฺฉ ุงุฒ ุขููุง ุงุฏุง ุดูุฏ ู ุฌูุงุฒุงุช ูุฎุชูู ู ูุชุถุงุฏ ูุงููุฏ ููุง ฺฏููุงฺฏูู ุนุงุทู ู ุงุญุณุงุณ ฺฉู ุฏุฑ  ู ุจู ูุฏุนู ฺฏุฐุงุฑุฏู ุดุฏู ุชุนุฏู ุดุฏู ุจู ูุฑฺฉุฏุงู ุงุฒ ุขููุง ุชุง ุงูุฏุงุฒู ุง ฺฉู ูุฒุงุญู ุญุงู ุฏฺฏุฑุงู ูุดูุฏ ุฑุฎุตุช ุนูู ุฏุงุฏู ุดูุฏ.\n",
            "ู ุจุงูุงุฎุฑู ุฏุฑ ูุฌูุฏ ุงูุณุงู ุนูู ุญฺฉููุช ฺฉูุฏ ูู ุฎูุงุณุช ููุณ ู ูู ุบูุจู ุนุงุทูู ู ุงุญุณุงุณ .\n",
            "\n",
            "๐ูุฑุขู ุฏุฑ ุงุณูุงู ุ ุนูุงูู ุทุจุงุทุจุงุ ุณุฏูุงุฏ ุฎุณุฑู ุดุงู\n",
            "ุฑุงู ูุทุฑุช\n",
            "\n",
            "ุฑุงู ูุงูุน ุจุฑุง ุงูุณุงู ุฏุฑ ูุณุฑ ุฒูุฏฺฏ ููุงู ุงุณุช ฺฉู ุขูุฑูุด ูฺูโ ู ุจู ุณู ุขู ุฏุนูุช ู ฺฉูุฏ ู ููุฑุฑุงุช ุฑุง ุฏุฑ ุฒูุฏฺฏ ูุฑุฏ ู ุงุฌุชูุงุน ุฎูุฏ ุจุงุฏ ุจู ฺฉุงุฑ ุจูุฏุฏ ฺฉู ุทุจุนุช ฺฉ ุงูุณุงู ูุทุฑ (ุทุจุน) ุจู ุณู ุขููุง ูุฏุงุช ูโฺฉูุฏ ูู ุงูุณุงููุง ฺฉู ุจู ููุง ู ููุณ ุขููุฏู ู ุฏุฑ ุจุฑุงุจุฑ ุนูุงุทู ู ุงุญุณุงุณุงุช ุงุณุฑ ุฏุณุช ุจุณุชู ู ุจุงุดุฏ.\n",
            "\n",
            "ููุชุถุง ุฏู ูุทุฑ ุงู ุงุณุช ฺฉู ุชุฌูุฒุงุช ูุฌูุฏ ุงูุณุงู ุงูุบุง ูุดูุฏ ู ุญู ูุฑ ฺฉ ุงุฒ ุขููุง ุงุฏุง ุดูุฏ ู ุฌูุงุฒุงุช ูุฎุชูู ู ูุชุถุงุฏ ูุงููุฏ ููุง ฺฏููุงฺฏูู ุนุงุทู ู ุงุญุณุงุณ ฺฉู ุฏุฑ  ู ุจู ูุฏุนู ฺฏุฐุงุฑุฏู ุดุฏู ุชุนุฏู ุดุฏู ุจู ูุฑฺฉุฏุงู ุงุฒ ุขููุง ุชุง ุงูุฏุงุฒู ุง ฺฉู ูุฒุงุญู ุญุงู ุฏฺฏุฑุงู ูุดูุฏ ุฑุฎุตุช ุนูู ุฏุงุฏู ุดูุฏ.\n",
            "ู ุจุงูุงุฎุฑู ุฏุฑ ูุฌูุฏ ุงูุณุงู ุนูู ุญฺฉููุช ฺฉูุฏ ูู ุฎูุงุณุช ููุณ ู ูู ุบูุจู ุนุงุทูู ู ุงุญุณุงุณ .\n",
            "\n",
            "ูุฑุขู ุฏุฑ ุงุณูุงู ุ ุนูุงูู ุทุจุงุทุจุงุ ุณุฏูุงุฏ ุฎุณุฑู ุดุงู\n",
            "ุณูุงู ุจุฑ ููู ุนุฒุฒุงู\n",
            "\n",
            "ูุงุฌุฑุง ุงุชุตุงู ุฏุฑุงูุง ฺุณุชุ\n",
            "\n",
            "ฺูุฏ ููุช ูพุด ุฌูุงุจ ุฑูุญ ุงููู ฺฉ ฺฉููพ ุฑู ุจุฑุง ูู ูุฑุณุชุงุฏ ฺฉู ุจู ุนููุงู ูุนุฌุฒู ูุฑุขู ูุทุฑุญ ุดุฏู.\n",
            "\n",
            "ูุชุงุณูุงูู ุงุฒ ุงููุฌุง ฺฉู ูุจูุง ูู ฺฏูุชู ุจุณุงุฑ ุงุฒ ุนุฒุฒุงู ุฏูุจุงู ุนูู ูุณุชูุ ุฏูุดูู ุจู ุดุจู ุนูู ุฎูุดู\n",
            "ุงุฒ ุฑุงู ูุง ุดูุงุณุง ุดุจู ุนูู ููู ูุดุฑ ฺฉููพ ูุง ุฌูุฌุงูู.\n",
            "\n",
            "ุฎุจ ุฏุฑ ุงุฏุงูู ูุฎูุงู ุจู ุงู ููุถูุน ุจูพุฑุฏุงุฒู ฺฉู ุขุง ูุงูุนุง ููฺู ฺุฒ ูุณุชุุ\n",
            "\n",
            "ุขุง ูุงูุนุง ฺฏูุชู ุงู ุนุฒุฒุงู ุตุญุช ุฏุงุฑูุุุ\n",
            "\n",
            "ูู ูุทุงูุจ ุฑู ุนููุงู ูฺฉูู ุตุฑูุง ุฌูุช ุฑูุดูฺฏุฑ\n",
            "ูุฑฺฉุฏูู ุงุฒ ุนุฒุฒุงู ูู ุงุดฺฉุงู ุฏุฑ ฺฏูุชู ูุง ูู ูพุฏุง ฺฉุฑุฏู ุจฺฏู.\n",
            "\n",
            "\n",
            "\n",
            "ฺูุฏ ุณุงู ุงุณุช ุนฺฉุณ ู ูููโูุง ุฏุฑ ุดุจฺฉูโูุง ุงุฌุชูุงุน ุจู ุทุฑุฒ ุจุงูุฑูฺฉุฑุฏู ููุชุดุฑ ูโุดูุฏ ฺฉู ุงุฏุนุง ูโฺฉูุฏ ุชุตุงูุฑ ุงุฒ ุจุฑุฎูุฑุฏ ุฏู ุฏุฑุง ุจุงูุชฺฉ ู ุฏุฑุง ุดูุงู ุจู ฺฉุฏฺฏุฑ ุงุณุช ู ุขุจ ุงู ุฏู ุฏุฑุง ุจุง ฺฉุฏฺฏุฑ ุชุฑฺฉุจ ููโุดูุฏ ู ุทุจู ูุนููู ูู ุนุฏูโุง ฺฉู ฺฉุงุฑุดุงู ุฑุจุท ุฏุงุฏู ุงููุงุน ูุณุงุฆู ุงุณุช ฺฉู ุญุฏุงูู ฑฐูช ุจุง ูู ุดุจุงูุช ุฏุงุฑูุฏ ฺฉูุฑ ููุช ุจุณุชูุฏ ู ุจุง ุฒูุฑ ู ุถุฑุจ ุงู ุฑูุฏุงุฏ ุทุจุน ุฑุง ุจู ูุนุฌุฒุงุช ู ุขุงุช ูุฑุขู ูุฑุชุจุท ฺฉุฑุฏูโุงูุฏ! ูุชู ฺฉู ุจู ููุฑุงู ุงู ุนฺฉุณ ููุชุดุฑ ูโุดูุฏ ูุถููู ุงูฺูู ุฏุงุฑุฏ:\n",
            "ยซุฏุฑ ุดูุงู ุชุฑู ุดูุฑ ุฏุงููุงุฑฺฉ ู ุชูุงู ฺฉ ูุดุงูู ูุฑุขู ุฑุง ุฏุฏ. ุฏุฑ ุดูุฑ ุชูุฑุณุช ุงุณฺฉุงฺฏู ุงู ุฒุจุง ุฑุง ู ุชูุงู ุฏุฑ ุณุฌู ุฏุฏ. ุฌุง ฺฉู ุฏุฑุง ุจุงูุชฺฉ ู ุฏุฑุง ุดูุงู ุจูู ู ูพููุฏูุฏ. ุฏู ุฏุฑุง ูุฎุชูู ุจุง ูู ฺฉ ูู ุดููุฏ ู ุจูุงุจุฑู ุงู ูพุฏุฏู ุฒุจุง ุจูุฌูุฏ ู ุขุฏ ู ุงู ููุงู ฺุฒ ุงุณุช ฺฉู ุฏุฑ ูุฑุขู ุขูุฏู ุงุณุช.ยป ู ูพุณ ุงุฒ ุขู ุขุงุช ุฒุฑ ุฑุง ุงุฒ ูุฑุขู ุฏุฑ ุงุฑุชุจุงุท ุจุง ุงู ุฑูุฏุงุฏ ุจุงู ูโฺฉููุฏ:\n",
            "ุณูุงู ุจุฑ ููู ุนุฒุฒุงู\n",
            "\n",
            "ูุงุฌุฑุง ุงุชุตุงู ุฏุฑุงูุง ฺุณุชุ\n",
            "\n",
            "ฺูุฏ ููุช ูพุด ุฌูุงุจ ุฑูุญ ุงููู ฺฉ ฺฉููพ ุฑู ุจุฑุง ูู ูุฑุณุชุงุฏ ฺฉู ุจู ุนููุงู ูุนุฌุฒู ูุฑุขู ูุทุฑุญ ุดุฏู.\n",
            "\n",
            "ูุชุงุณูุงูู ุงุฒ ุงููุฌุง ฺฉู ูุจูุง ูู ฺฏูุชู ุจุณุงุฑ ุงุฒ ุนุฒุฒุงู ุฏูุจุงู ุนูู ูุณุชูุ ุฏูุดูู ุจู ุดุจู ุนูู ุฎูุดู\n",
            "ุงุฒ ุฑุงู ูุง ุดูุงุณุง ุดุจู ุนูู ููู ูุดุฑ ฺฉููพ ูุง ุฌูุฌุงูู.\n",
            "\n",
            "ุฎุจ ุฏุฑ ุงุฏุงูู ูุฎูุงู ุจู ุงู ููุถูุน ุจูพุฑุฏุงุฒู ฺฉู ุขุง ูุงูุนุง ููฺู ฺุฒ ูุณุชุุ\n",
            "\n",
            "ุขุง ูุงูุนุง ฺฏูุชู ุงู ุนุฒุฒุงู ุตุญุช ุฏุงุฑูุุุ\n",
            "\n",
            "ูู ูุทุงูุจ ุฑู ุนููุงู ูฺฉูู ุตุฑูุง ุฌูุช ุฑูุดูฺฏุฑ\n",
            "ูุฑฺฉุฏูู ุงุฒ ุนุฒุฒุงู ูู ุงุดฺฉุงู ุฏุฑ ฺฏูุชู ูุง ูู ูพุฏุง ฺฉุฑุฏู ุจฺฏู.\n",
            "\n",
            "\n",
            "\n",
            "ฺูุฏ ุณุงู ุงุณุช ุนฺฉุณ ู ูููโูุง ุฏุฑ ุดุจฺฉูโูุง ุงุฌุชูุงุน ุจู ุทุฑุฒ ุจุงูุฑูฺฉุฑุฏู ููุชุดุฑ ูโุดูุฏ ฺฉู ุงุฏุนุง ูโฺฉูุฏ ุชุตุงูุฑ ุงุฒ ุจุฑุฎูุฑุฏ ุฏู ุฏุฑุง ุจุงูุชฺฉ ู ุฏุฑุง ุดูุงู ุจู ฺฉุฏฺฏุฑ ุงุณุช ู ุขุจ ุงู ุฏู ุฏุฑุง ุจุง ฺฉุฏฺฏุฑ ุชุฑฺฉุจ ููโุดูุฏ ู ุทุจู ูุนููู ูู ุนุฏูโุง ฺฉู ฺฉุงุฑุดุงู ุฑุจุท ุฏุงุฏู ุงููุงุน ูุณุงุฆู ุงุณุช ฺฉู ุญุฏุงูู ฑฐูช ุจุง ูู ุดุจุงูุช ุฏุงุฑูุฏ ฺฉูุฑ ููุช ุจุณุชูุฏ ู ุจุง ุฒูุฑ ู ุถุฑุจ ุงู ุฑูุฏุงุฏ ุทุจุน ุฑุง ุจู ูุนุฌุฒุงุช ู ุขุงุช ูุฑุขู ูุฑุชุจุท ฺฉุฑุฏูโุงูุฏ! ูุชู ฺฉู ุจู ููุฑุงู ุงู ุนฺฉุณ ููุชุดุฑ ูโุดูุฏ ูุถููู ุงูฺูู ุฏุงุฑุฏ:\n",
            "ยซุฏุฑ ุดูุงู ุชุฑู ุดูุฑ ุฏุงููุงุฑฺฉ ู ุชูุงู ฺฉ ูุดุงูู ูุฑุขู ุฑุง ุฏุฏ. ุฏุฑ ุดูุฑ ุชูุฑุณุช ุงุณฺฉุงฺฏู ุงู ุฒุจุง ุฑุง ู ุชูุงู ุฏุฑ ุณุฌู ุฏุฏ. ุฌุง ฺฉู ุฏุฑุง ุจุงูุชฺฉ ู ุฏุฑุง ุดูุงู ุจูู ู ูพููุฏูุฏ. ุฏู ุฏุฑุง ูุฎุชูู ุจุง ูู ฺฉ ูู ุดููุฏ ู ุจูุงุจุฑู ุงู ูพุฏุฏู ุฒุจุง ุจูุฌูุฏ ู ุขุฏ ู ุงู ููุงู ฺุฒ ุงุณุช ฺฉู ุฏุฑ ูุฑุขู ุขูุฏู ุงุณุช.ยป ู ูพุณ ุงุฒ ุขู ุขุงุช ุฒุฑ ุฑุง ุงุฒ ูุฑุขู ุฏุฑ ุงุฑุชุจุงุท ุจุง ุงู ุฑูุฏุงุฏ ุจุงู ูโฺฉููุฏ:\n",
            "ุฏูุณุชุงู ูุธุฑุชูู ฺู ู ฺฏุฑูู ุจุฒูู ุจุฑุง ุชุจุงุฏู ูุธุฑุงุช \n",
            "ุฏูุณุชุงู ูุธุฑุชูู ฺู ู ฺฏุฑูู ุจุฒูู ุจุฑุง ุชุจุงุฏู ูุธุฑุงุช \n",
            "โ โุงุฑูุณุช ุฑูุงู (ูุฑุงูุณู):\n",
            "\n",
            "ุฏุฑ ฺฉุชุงุจุฎุงูู ุดุฎุต ูู ูุฒุงุฑุงู ุฌูุฏ ฺฉุชุงุจ ุณุงุณุ ุงุฌุชูุงุนุ ุงุฏุจ ู... ูุฌูุฏ ุฏุงุฑุฏ ฺฉู ููู ุขููุง ุฑุง ุจุดุชุฑ ุงุฒ ฺฉ ุจุงุฑ ูุทุงูุนู ูฺฉุฑุฏู ุงู ู ฺู ุจุณุง ฺฉุชุงุจูุง ฺฉู ููุท ุฒูุช ฺฉุชุงุจุฎุงูู ูู ู ุจุงุดูุฏ ูู ฺฉ ุฌูุฏ ฺฉุชุงุจ ุงุณุช ฺฉู ููุดู ูููุณ ูู ุงุณุช ู ูุฑ ููุช ุฎุณุชู ู ุดูู ู ู ุฎูุงูู ุฏุฑูุง ุงุฒ ูุนุงู ู ฺฉูุงู ุจุฑ ุฑู ูู ุจุงุฒ ุดูุฏ ุขู ุฑุง ูุทุงูุนู ู ฺฉูู ู ุงุฒ ูุทุงูุนู ุฒุงุฏ ุขู ุฎุณุชู ู ูููู ูู ุดูู. ุงู ฺฉุชุงุจุ ูุฑุขูุ ฺฉุชุงุจ ุขุณูุงู ูุณููู ุงุณุช.\n",
            "\n",
            "\n",
            "\n",
            "๐ุญุฏุซ ุฏฺฏุฑุงูุ ูุฑุงูุฑุฒ ูุฑุดฺฉุงุฑ\n",
            "#ูุฑุขู_ฺฉุฑู\n",
            " ุงุฑูุณุช ุฑูุงู (ูุฑุงูุณู):\n",
            "\n",
            "ุฏุฑ ฺฉุชุงุจุฎุงูู ุดุฎุต ูู ูุฒุงุฑุงู ุฌูุฏ ฺฉุชุงุจ ุณุงุณุ ุงุฌุชูุงุนุ ุงุฏุจ ู... ูุฌูุฏ ุฏุงุฑุฏ ฺฉู ููู ุขููุง ุฑุง ุจุดุชุฑ ุงุฒ ฺฉ ุจุงุฑ ูุทุงูุนู ูฺฉุฑุฏู ุงู ู ฺู ุจุณุง ฺฉุชุงุจูุง ฺฉู ููุท ุฒูุช ฺฉุชุงุจุฎุงูู ูู ู ุจุงุดูุฏ ูู ฺฉ ุฌูุฏ ฺฉุชุงุจ ุงุณุช ฺฉู ููุดู ูููุณ ูู ุงุณุช ู ูุฑ ููุช ุฎุณุชู ู ุดูู ู ู ุฎูุงูู ุฏุฑูุง ุงุฒ ูุนุงู ู ฺฉูุงู ุจุฑ ุฑู ูู ุจุงุฒ ุดูุฏ ุขู ุฑุง ูุทุงูุนู ู ฺฉูู ู ุงุฒ ูุทุงูุนู ุฒุงุฏ ุขู ุฎุณุชู ู ูููู ูู ุดูู. ุงู ฺฉุชุงุจุ ูุฑุขูุ ฺฉุชุงุจ ุขุณูุงู ูุณููู ุงุณุช.\n",
            "\n",
            "\n",
            "\n",
            "ุญุฏุซ ุฏฺฏุฑุงูุ ูุฑุงูุฑุฒ ูุฑุดฺฉุงุฑ\n",
            "#ูุฑุขู_ฺฉุฑู\n",
            "ุฏุฑ ูุฌููุนู ฺฉุชุงุจูุง ุทุงูฺู ุ ฺฉุชุงุจ ยซ ุงููุฑุงู ุงูฺฉุฑูยป ุจุง ุชุฑุฌูู ุขุช ุงููู ูฺฉุงุฑู ุดุฑุงุฒ ูู ูุณุช ฺฉู ูู ุฏุฑ ูุณูุช ฺฉุชุงุจูุงู ุฏุงุฑู ูู ุฏุฑ ูุณุช ุฏุฑุฎุช ฺฉุชุงุจูุง ูุณุช ุงุตูุง ูุณูุช ุฌุณุชุฌู ูู ููุงุฑู ู ุญุช ูุธุฑุงุชุดู ูู ููุงุฑู.ุฎูุฏูู ุงุฒ ุทุฑู ูุธุฑุงุช ฺฉ ุงุฒ ฺฉุงุฑุจุฑุงู ุจุทูุฑ ุบุฑูุณุชูู ูุงุฑุฏ ุตูุญู ุฏุงูููุฏุด ุดุฏู.ุงูฺฏุงุฑ ุณุณุชู ุงุฏุฑุณ ุฏู ุงูู ุญุฐู ุดุฏู๐ฎ\n",
            "ุฏุฑ ูุฌููุนู ฺฉุชุงุจูุง ุทุงูฺู ุ ฺฉุชุงุจ ยซ ุงููุฑุงู ุงูฺฉุฑูยป ุจุง ุชุฑุฌูู ุขุช ุงููู ูฺฉุงุฑู ุดุฑุงุฒ ูู ูุณุช ฺฉู ูู ุฏุฑ ูุณูุช ฺฉุชุงุจูุงู ุฏุงุฑู ูู ุฏุฑ ูุณุช ุฏุฑุฎุช ฺฉุชุงุจูุง ูุณุช ุงุตูุง ูุณูุช ุฌุณุชุฌู ูู ููุงุฑู ู ุญุช ูุธุฑุงุชุดู ูู ููุงุฑู.ุฎูุฏูู ุงุฒ ุทุฑู ูุธุฑุงุช ฺฉ ุงุฒ ฺฉุงุฑุจุฑุงู ุจุทูุฑ ุบุฑูุณุชูู ูุงุฑุฏ ุตูุญู ุฏุงูููุฏุด ุดุฏู.ุงูฺฏุงุฑ ุณุณุชู ุงุฏุฑุณ ุฏู ุงูู ุญุฐู ุดุฏู\n",
            "ูุฑุขู ู ฺฉุชุงุจ ุขุณููู ูุณ ฺฉ ุชุง ุจู ุงูุฑูุฒ ูุง ุจุดุชุฑ ุฏุฑูุงู _ุฑุงู ู ุฑูุด ุฒูุฏฺฏ _ุนุงูุจุช ฺฉุงุฑูุง ููุดู ุงุฒ ุงู ฺฉุชุงุจ ุงุฏ ฺฏุฑูุชู ูู ูุฎูุงู ููููู ุจู ุงู ฺฉุชุงุจ ุงุฑุฒุด ูุงุนู ุจุงุดู ู ููููู ุงุฒ ุจุฑูุงูู ุฎูุจุชูู๐ป\n",
            "ูุฑุขู ู ฺฉุชุงุจ ุขุณููู ูุณ ฺฉ ุชุง ุจู ุงูุฑูุฒ ูุง ุจุดุชุฑ ุฏุฑูุงู _ุฑุงู ู ุฑูุด ุฒูุฏฺฏ _ุนุงูุจุช ฺฉุงุฑูุง ููุดู ุงุฒ ุงู ฺฉุชุงุจ ุงุฏ ฺฏุฑูุชู ูู ูุฎูุงู ููููู ุจู ุงู ฺฉุชุงุจ ุงุฑุฒุด ูุงุนู ุจุงุดู ู ููููู ุงุฒ ุจุฑูุงูู ุฎูุจุชูู\n",
            "\"...ููุณ ุุชู ูู ุชูุงู ูุนูุง ุฎุฏุงููุฏ ุฑุง ุฏุฑ ฺฉูุงุฑ ุจูู  ูุนูุงูุง ุฒูุฏฺฏ ุงุช ุจฺู.ููุช ุฎุฏุงููุฏ ุฏุฑ ูุนุตููุช ฺฉูุฏฺฉุงู ุูุซู ุจุฑู ุฒูุณุชุงู ู ุฏุฑุฎุดุฏ ุชู ฺฉุฌุง ููุณุูุงูุนุง ุชู ฺฉุฌุง ุุดุงุฏ ุฎุฏุงููุฏ ุฏุฑ ูฺ ุฌุง ุฏฺฏุฑ ูุณุช ูุซู ูุนุตููุช ฺฉูุฏฺฉุุฎูุฏุด ุฑุง ุงู ฺฏููู ุขุดฺฉุงุฑ ูฺฉุฑุฏู ุจุงุดุฏ.ูู ฺฏุงู ุงุฒ ุดุฏุช ูุถูุญ ุฎุฏุงููุฏ ุฏุฑ ฺฉูุฏฺฉุงู ุูพุฑ ุงุฒ ูุฑุงุณ ู ุดูู ู ุฏู ุงู ุดุฑูุน ู ฺฉูุฏ ุจู ุชูพุฏู.ุฏู ุงู ุขููุฏุฑ ุจููุฏ ุจููุฏ ู ุชูพุฏ ฺฉู ุจูุช ุฒุฏู ู ุฏูู ุชุง ุงุฒ ูุง ุงูฺฏุดุชุงู ฺฉูุฏฺฉุงูุุฎุฏุงููุฏ ุฑุง ุจุฑฺฏุฑู.ฺฉุฌุง ููุณุุตุฏุง ูุฑุง ู ุดููุ...\"\n",
            "(ุฑู ูุงู ุฎุฏุงููุฏ ุฑุง ุจุจูุณุูุตุทู ูุณุชูุฑุุตูุญู 111)\n",
            "\"...ููุณ ุุชู ูู ุชูุงู ูุนูุง ุฎุฏุงููุฏ ุฑุง ุฏุฑ ฺฉูุงุฑ ุจูู  ูุนูุงูุง ุฒูุฏฺฏ ุงุช ุจฺู.ููุช ุฎุฏุงููุฏ ุฏุฑ ูุนุตููุช ฺฉูุฏฺฉุงู ุูุซู ุจุฑู ุฒูุณุชุงู ู ุฏุฑุฎุดุฏ ุชู ฺฉุฌุง ููุณุูุงูุนุง ุชู ฺฉุฌุง ุุดุงุฏ ุฎุฏุงููุฏ ุฏุฑ ูฺ ุฌุง ุฏฺฏุฑ ูุณุช ูุซู ูุนุตููุช ฺฉูุฏฺฉุุฎูุฏุด ุฑุง ุงู ฺฏููู ุขุดฺฉุงุฑ ูฺฉุฑุฏู ุจุงุดุฏ.ูู ฺฏุงู ุงุฒ ุดุฏุช ูุถูุญ ุฎุฏุงููุฏ ุฏุฑ ฺฉูุฏฺฉุงู ุูพุฑ ุงุฒ ูุฑุงุณ ู ุดูู ู ุฏู ุงู ุดุฑูุน ู ฺฉูุฏ ุจู ุชูพุฏู.ุฏู ุงู ุขููุฏุฑ ุจููุฏ ุจููุฏ ู ุชูพุฏ ฺฉู ุจูุช ุฒุฏู ู ุฏูู ุชุง ุงุฒ ูุง ุงูฺฏุดุชุงู ฺฉูุฏฺฉุงูุุฎุฏุงููุฏ ุฑุง ุจุฑฺฏุฑู.ฺฉุฌุง ููุณุุตุฏุง ูุฑุง ู ุดููุ...\"\n",
            "(ุฑู ูุงู ุฎุฏุงููุฏ ุฑุง ุจุจูุณุูุตุทู ูุณุชูุฑุุตูุญู 111)\n",
            "ุฅูู ุชุงุฑฺฉู ูฺฉููู ุงูุซูููููููุ ูุง ุฅู ุชูููุณููฺฉุชูู ุจููุง ููู ุชูุถูููุง: ฺฉุชุงุจู ุงูููู ูู ุนุชุฑูุช ุฃููู ุจูุชุ ููุฅููููููุง ููู ูุชูุฑูุง ุญูุชู ุฑุฏุง ุนููู ุงูุญููุถูุ\n",
            "\n",
            "ูู ุฏุฑ ูุงู ุดูุง ุฏู ฺุฒ ฺฏุฑุงู ุจูุง ุจู ุงุฏฺฏุงุฑ ู ฺฏุฐุงุฑู. ุงฺฏุฑ ุจู ุขู ุฏู ฺูฺฏ ุฒูุฏุ ูุฑฺฏุฒ ฺฏูุฑุงู ูู ุดูุฏ: ฺฉุชุงุจ ุฎุฏุง ู ุนุชุฑุชูุ [ุนู] ุฏูุฏูุงูู. ุงู ุฏู ุงุฒ ูู ุฌุฏุง ูู ุดููุฏ ุชุง ุฏุฑ ฺฉูุงุฑ ุญูุถ [ฺฉูุซุฑ] ุจุฑ ูู ูุงุฑุฏุดููุฏ\n",
            "\"ุญุฏุซ ุซููู\"\n",
            "ุฅูู ุชุงุฑฺฉู ูฺฉููู ุงูุซูููููููุ ูุง ุฅู ุชูููุณููฺฉุชูู ุจููุง ููู ุชูุถูููุง: ฺฉุชุงุจู ุงูููู ูู ุนุชุฑูุช ุฃููู ุจูุชุ ููุฅููููููุง ููู ูุชูุฑูุง ุญูุชู ุฑุฏุง ุนููู ุงูุญููุถูุ\n",
            "\n",
            "ูู ุฏุฑ ูุงู ุดูุง ุฏู ฺุฒ ฺฏุฑุงู ุจูุง ุจู ุงุฏฺฏุงุฑ ู ฺฏุฐุงุฑู. ุงฺฏุฑ ุจู ุขู ุฏู ฺูฺฏ ุฒูุฏุ ูุฑฺฏุฒ ฺฏูุฑุงู ูู ุดูุฏ: ฺฉุชุงุจ ุฎุฏุง ู ุนุชุฑุชูุ [ุนู] ุฏูุฏูุงูู. ุงู ุฏู ุงุฒ ูู ุฌุฏุง ูู ุดููุฏ ุชุง ุฏุฑ ฺฉูุงุฑ ุญูุถ [ฺฉูุซุฑ] ุจุฑ ูู ูุงุฑุฏุดููุฏ\n",
            "\"ุญุฏุซ ุซููู\"\n",
            "ูุฎูุงููุฏ ููุฑ ุฑุง ุจุง ููุช ุฎุงููุด ฺฉููุฏ  ุ ุงูุง ููุฏุงููุฏ ฺฉู ููุฑ ุจุง ููุช  ุฎุงููุด ููุดูุฏ.\n",
            "ูุฎูุงููุฏ ููุฑ ุฑุง ุจุง ููุช ุฎุงููุด ฺฉููุฏ  ุ ุงูุง ููุฏุงููุฏ ฺฉู ููุฑ ุจุง ููุช  ุฎุงููุด ููุดูุฏ.\n",
            "ุจุฑุง ุฑูุฒ ูุจุงุฏุงุ ุญุงุฌ ุจู ูุฐูุจ ูู ูุนุชูุฏ ุจูุฏ. ุงฺฏุฑฺู ุจุง ุฎูุฏุด ู ฺฏูุช: ยซ ฺฉ ุงุฒ ุขู ุฏูุง ุจุฑฺฏุดุชูุ ุงฺฏุฑ ุฑุงุณุช ุจุงุดู! ยป ู ูุซู ุนูุงุฏ ุณุงุณุด ุจู ุขู ุฏูุง ูู ุงุนุชูุงุฏ ูุญฺฉู ูุฏุงุดุช. ูฺฏุฑ ุจุง ูพูู ููโุดุฏ ุญุฌ ู ููุงุฒ ู ุฑูุฒู ุฑุง ุฎุฑุฏุ ูพุณ ูุฑฺฉุณ ูพูู ุฏุงุดุช ุฏู ุฏูุง ุฑุง ุฏุงุดุช.\n",
            "\n",
            "ุญุงุฌ ุขูุง\n",
            "ุตุงุฏู ูุฏุงุช\n",
            "ุจุฑุง ุฑูุฒ ูุจุงุฏุงุ ุญุงุฌ ุจู ูุฐูุจ ูู ูุนุชูุฏ ุจูุฏ. ุงฺฏุฑฺู ุจุง ุฎูุฏุด ู ฺฏูุช: ยซ ฺฉ ุงุฒ ุขู ุฏูุง ุจุฑฺฏุดุชูุ ุงฺฏุฑ ุฑุงุณุช ุจุงุดู! ยป ู ูุซู ุนูุงุฏ ุณุงุณุด ุจู ุขู ุฏูุง ูู ุงุนุชูุงุฏ ูุญฺฉู ูุฏุงุดุช. ูฺฏุฑ ุจุง ูพูู ููโุดุฏ ุญุฌ ู ููุงุฒ ู ุฑูุฒู ุฑุง ุฎุฑุฏุ ูพุณ ูุฑฺฉุณ ูพูู ุฏุงุดุช ุฏู ุฏูุง ุฑุง ุฏุงุดุช.\n",
            "\n",
            "ุญุงุฌ ุขูุง\n",
            "ุตุงุฏู ูุฏุงุช\n",
            "ุฎุฏุงุง ุจุฎุฏุง ุฎู ุฎูุจ\n",
            "ุฎุฏุงุง ุจุฎุฏุง ุฎู ุฎูุจ\n",
            "ุงููู ุงฺฉุจุฑ\n",
            "ุงููู ุงฺฉุจุฑ\n",
            "๐ธุฅูููุง ุนูุฑูุถูููุง ุงููุฃูููุงููุฉู ุนููู ุงูุณููููุงููุงุชู ููุงููุฃูุฑูุถู ููุงููุฌูุจูุงูู ููุฃูุจูููู ุฃูู ูุญูููููููููุง ููุฃูุดููููููู ููููููุง ููุญูููููููุง ุงููุฅููุณูุงูู ุฅูููููู ฺฉูุงูู ุธููููููุง ุฌููููููุง๐ธ \n",
            "\n",
            "๏ปณ๏ป๏ปด๏ปจ๏บ ๏ปฃ๏บ ๏บ๏ปฃ๏บ๏ปง๏บุฑุง ๏บ๏บฎ ๏บ๏บณ๏ปค๏บ๏ปฅ ๏ปซ๏บ ๏ปญ ๏บฏ๏ปฃ๏ปด๏ปฆ ๏ปญ ๏ป๏ปฎ๏ปฉ ๏ปซ๏บ ๏ป๏บฎ๏บฟ๏ปช ๏ป๏บฎ๏บฉ๏ปณ๏ปข ๏ปญ ๏บ๏ปง๏ปฌ๏บ ๏บ๏บฏ ๏บ๏ปช ๏ป๏ปฌ๏บช๏ปฉ ๏ฎ๏บฎ๏ป๏บ๏ปจ๏บถ [ ๏บ๏ปช ๏บณ๏บ๏บ ๏บ๏ปณ๏ปจ๏ป๏ปช ๏บ๏บณ๏บ๏ป๏บช๏บ๏บฉ๏บต ๏บญ๏บ ๏ปง๏บช๏บ๏บท๏บ๏ปจ๏บช ] ๏บ๏ปฃ๏บ๏ปจ๏บ๏ป ๏ปญ๏บญ๏บฏ๏ปณ๏บช๏ปง๏บช ๏ปญ ๏บ๏บฏ ๏บ๏ปฅ ูุฑุงุณุฏูุฏ ุ ๏ปญ ๏บ๏ปง๏บด๏บ๏ปฅ ๏บ๏ปฅ ๏บญ๏บ ๏ญ๏บฌ๏ปณ๏บฎ๏ป๏บ ๏บ๏ปฐ ๏บ๏บฎ๏บฉ๏ปณ๏บช ๏บ๏ปญ [๏บฉ๏บญ ๏บฃ๏ป ๏บง๏ปฎ๏ปณ๏บถ ] ๏บณ๏บ๏ปค๏ป๏บ๏บญ ู ๏ปง๏บ๏บฉ๏บู ๏บ๏ปฎ๏บฉ.(ูุฏุฑ ุงู ููุงู ุนุธู ุฑุง ูุดูุงุฎุช.)\n",
            "\n",
            "ุงุญุฒุงุจ ุทฒ\n",
            "\n",
            "๐นุงุดุงุฑู ุชููุญ ุญุงูุธ ุจู ุงู ุขู ุฏุฑ ุดุนุฑ ุฒุฑ:\n",
            "\n",
            "ุฏูุด ุฏุฏู ฺฉู ููุงฺฉ ุฏุฑ ูุฎุงูู ุฒุฏูุฏ\n",
            "ฺฏู ุขุฏู ุจุณุฑุดุชูุฏ ู ุจู ูพูุงูู ุฒุฏูุฏ\n",
            "\n",
            "ุณุงฺฉูุงู ุญุฑู ุณุชุฑ ู ุนูุงู ููฺฉูุช\n",
            "ุจุง ูู ุฑุงู ูุดู ุจุงุฏู ูุณุชุงูู ุฒุฏูุฏ\n",
            "\n",
            "๐ุขุณูุงู ุจุงุฑ ุงูุงูุช ูุชูุงูุณุช ฺฉุดุฏ\n",
            "ูุฑุนู ฺฉุงุฑ ุจู ูุงู ูู ุฏูุงูู ุฒุฏูุฏ๐\n",
            "\n",
            "ุฌูฺฏ ููุชุงุฏ ู ุฏู ููุช ููู ุฑุง ุนุฐุฑ ุจูู\n",
            "ฺูู ูุฏุฏูุฏ ุญููุช ุฑู ุงูุณุงูู ุฒุฏูุฏ\n",
            "\n",
            "ุดฺฉุฑ ุงุฒุฏ ฺฉู ูุงู ูู ู ุงู ุตูุญ ุงูุชุงุฏ\n",
            "ุตููุงู ุฑูุต ฺฉูุงู ุณุงุบุฑ ุดฺฉุฑุงูู ุฒุฏูุฏ\n",
            "\n",
            "ุขุชุด ุขู ูุณุช ฺฉู ุงุฒ ุดุนูู ุงู ุฎูุฏุฏ ุดูุน\n",
            "ุขุชุด ุขู ุงุณุช ฺฉู ุฏุฑ ุฎุฑูู ูพุฑูุงูู ุฒุฏูุฏ\n",
            "\n",
            "ฺฉุณ ฺู ุญุงูุธ ูฺฏุดุงุฏ ุงุฒ ุฑุฎ ุงูุฏุดู ููุงุจ\n",
            "ุชุง ุณุฑ ุฒูู ุณุฎู ุฑุง ุจู ููู ุดุงูู ุฒุฏูุฏ\n",
            "#ูุฑุขู_ฺฉุฑู\n",
            "ุฅูููุง ุนูุฑูุถูููุง ุงููุฃูููุงููุฉู ุนููู ุงูุณููููุงููุงุชู ููุงููุฃูุฑูุถู ููุงููุฌูุจูุงูู ููุฃูุจูููู ุฃูู ูุญูููููููููุง ููุฃูุดููููููู ููููููุง ููุญูููููููุง ุงููุฅููุณูุงูู ุฅูููููู ฺฉูุงูู ุธููููููุง ุฌููููููุง \n",
            "\n",
            "  ุฑุง                 [       ]      ูุฑุงุณุฏูุฏ ุ         [   ]  ู ู .(ูุฏุฑ ุงู ููุงู ุนุธู ุฑุง ูุดูุงุฎุช.)\n",
            "\n",
            "ุงุญุฒุงุจ ุทฒ\n",
            "\n",
            "ุงุดุงุฑู ุชููุญ ุญุงูุธ ุจู ุงู ุขู ุฏุฑ ุดุนุฑ ุฒุฑ:\n",
            "\n",
            "ุฏูุด ุฏุฏู ฺฉู ููุงฺฉ ุฏุฑ ูุฎุงูู ุฒุฏูุฏ\n",
            "ฺฏู ุขุฏู ุจุณุฑุดุชูุฏ ู ุจู ูพูุงูู ุฒุฏูุฏ\n",
            "\n",
            "ุณุงฺฉูุงู ุญุฑู ุณุชุฑ ู ุนูุงู ููฺฉูุช\n",
            "ุจุง ูู ุฑุงู ูุดู ุจุงุฏู ูุณุชุงูู ุฒุฏูุฏ\n",
            "\n",
            "ุขุณูุงู ุจุงุฑ ุงูุงูุช ูุชูุงูุณุช ฺฉุดุฏ\n",
            "ูุฑุนู ฺฉุงุฑ ุจู ูุงู ูู ุฏูุงูู ุฒุฏูุฏ\n",
            "\n",
            "ุฌูฺฏ ููุชุงุฏ ู ุฏู ููุช ููู ุฑุง ุนุฐุฑ ุจูู\n",
            "ฺูู ูุฏุฏูุฏ ุญููุช ุฑู ุงูุณุงูู ุฒุฏูุฏ\n",
            "\n",
            "ุดฺฉุฑ ุงุฒุฏ ฺฉู ูุงู ูู ู ุงู ุตูุญ ุงูุชุงุฏ\n",
            "ุตููุงู ุฑูุต ฺฉูุงู ุณุงุบุฑ ุดฺฉุฑุงูู ุฒุฏูุฏ\n",
            "\n",
            "ุขุชุด ุขู ูุณุช ฺฉู ุงุฒ ุดุนูู ุงู ุฎูุฏุฏ ุดูุน\n",
            "ุขุชุด ุขู ุงุณุช ฺฉู ุฏุฑ ุฎุฑูู ูพุฑูุงูู ุฒุฏูุฏ\n",
            "\n",
            "ฺฉุณ ฺู ุญุงูุธ ูฺฏุดุงุฏ ุงุฒ ุฑุฎ ุงูุฏุดู ููุงุจ\n",
            "ุชุง ุณุฑ ุฒูู ุณุฎู ุฑุง ุจู ููู ุดุงูู ุฒุฏูุฏ\n",
            "#ูุฑุขู_ฺฉุฑู\n",
            "ุงฺฉุซุฑุง ููุฑู ูพูุฌ ุฏุงุฏู! ูู ฺูู ูู ุณุฑ ุดูุฎ ุฑู ุจุง ุฎุงูู ุจุงุฒ ฺฉุฑุฏู ูพุณ ฺฉ ูุฏูุ ฺูู ุตูุฑ ูุฏุงุดุช.\n",
            " ุฑุงุจุทููู ฺฉู ุดฺฉุฑ ุขุจ ุดุฏูุ ุงุฒ ฺู ุญุณ ุจู ฺู ุญุณ ุฑุณุฏูุ ฺู ุงุฏุนุงูุง ุฏุงุดุชู ู ุญุงูุง ูุฒุงุฑ ุชุง ุณูุงู ุจ ุฌูุงุจุ ูุฒุงุฑ ุชุง ุดฺฉ ู ุชุฑุฏุฏุ ูู ุจู ุชูุ ุจู ุฎูุฏูุ ุฏฺฉุชุฑ ูุฑููฺฏ ูฺฏู ุงฺฏู ุจูุช ูุงูู ุจููุณู ุฌูุงุจ ูุฏุ ูุงูู ููุดุชู ู ฺฏู ุดุฏุ \n",
            "ุฎู ฺุฒูุงุฑู ุงุฒ ุฏุณุช ุฏุงุฏู ู ุงููุด ุฎูุฏ ุชู ุจูุฏุ ุจู ุฎู ฺุฒูุง ุงุนุชูุงุฏ ุฏุงุดุชูุ ููุด ุจู ุจุงุฏ ุฑูุชุ ุงููุด ูู ุฎูุฏู ุจูุฏู. \n",
            "ุญุงูุช ุงูู ุจุงูุง ุฎูุจูุ ูุง ฺฉู ุฎุณุชู ุงู ู ฺฏูุดุฏูุ ุงุฒ ูู ฺฉู ฺฏุฐุดุชุ ุจูู ุฑู ูุฑุงููุด ูฺฉู!\n",
            "ุงฺฉุซุฑุง ููุฑู ูพูุฌ ุฏุงุฏู! ูู ฺูู ูู ุณุฑ ุดูุฎ ุฑู ุจุง ุฎุงูู ุจุงุฒ ฺฉุฑุฏู ูพุณ ฺฉ ูุฏูุ ฺูู ุตูุฑ ูุฏุงุดุช.\n",
            " ุฑุงุจุทููู ฺฉู ุดฺฉุฑ ุขุจ ุดุฏูุ ุงุฒ ฺู ุญุณ ุจู ฺู ุญุณ ุฑุณุฏูุ ฺู ุงุฏุนุงูุง ุฏุงุดุชู ู ุญุงูุง ูุฒุงุฑ ุชุง ุณูุงู ุจ ุฌูุงุจุ ูุฒุงุฑ ุชุง ุดฺฉ ู ุชุฑุฏุฏุ ูู ุจู ุชูุ ุจู ุฎูุฏูุ ุฏฺฉุชุฑ ูุฑููฺฏ ูฺฏู ุงฺฏู ุจูุช ูุงูู ุจููุณู ุฌูุงุจ ูุฏุ ูุงูู ููุดุชู ู ฺฏู ุดุฏุ \n",
            "ุฎู ฺุฒูุงุฑู ุงุฒ ุฏุณุช ุฏุงุฏู ู ุงููุด ุฎูุฏ ุชู ุจูุฏุ ุจู ุฎู ฺุฒูุง ุงุนุชูุงุฏ ุฏุงุดุชูุ ููุด ุจู ุจุงุฏ ุฑูุชุ ุงููุด ูู ุฎูุฏู ุจูุฏู. \n",
            "ุญุงูุช ุงูู ุจุงูุง ุฎูุจูุ ูุง ฺฉู ุฎุณุชู ุงู ู ฺฏูุดุฏูุ ุงุฒ ูู ฺฉู ฺฏุฐุดุชุ ุจูู ุฑู ูุฑุงููุด ูฺฉู!\n",
            "๐ธ ูููุฏ ุฎูููููุง ุงูุงูุณุงูู ู ุงูุญุณู ุชููู \n",
            "\n",
            "\" ๏บ๏ป๏ปฎ๏ปณ๏ปข\" ๏บ๏ปช ๏ปฃ๏ป๏ปจ๏ปฐ ๏บฉ๏บญ ๏บ๏ปญ๏บญ๏บฉ๏ปฅ ๏ญผ๏ปด๏บฐ๏ปฏ ๏บ๏ปช ๏บป๏ปฎ๏บญ๏บ ๏ปฃ๏ปจ๏บ๏บณ๏บุ ๏ปญ ๏ปง๏ป๏บู ๏ปฃ๏ป๏บ๏บช๏ป ๏ปญ ๏ป๏ปด๏ป๏ปด๏บ ๏บท๏บ๏ปณ๏บด๏บ๏ปช ๏บ๏บณ๏บุ ๏ปญ ๏ฎ๏บด๏บ๏บฎ๏บฉ๏ฎ๏ปฐ ๏ปฃ๏ป๏ปฌ๏ปฎู ๏บ๏ปฅ ๏บ๏บท๏บ๏บญ๏ปฉ ๏บ๏ปช ๏บ๏ปณ๏ปฆ ๏บ๏บณ๏บ ๏ป๏ปช ๏บง๏บช๏บ๏ปญ๏ปง๏บช ๏บ๏ปง๏บด๏บ๏ปฅ ๏บญ๏บ ๏บ๏บฏ ๏ปซ๏บฎ ๏ปง๏ป๏บฎ ๏ปฃ๏ปฎ๏บฏ๏ปญ๏ปฅ ๏ปญ ๏บท๏บ๏ปณ๏บด๏บ๏ปช ๏บ๏ป๏บฎ๏ปณ๏บชุ ๏ปซ๏ปข ๏บ๏บฏ ๏ปง๏ป๏บฎ ๏บ๏บด๏ปค๏ปฐุ ๏ปญ ๏ปซ๏ปข ๏บ๏บฏ ๏ปง๏ป๏บฎ ๏บญ๏ปญ๏บฃ๏ปฐ ๏ปญ ๏ป๏ป๏ป๏ปฐุ ๏ญผ๏บฎ๏บ ๏ป๏ปช ๏ปซ๏บฎ ๏ฎ๏ปฎ๏ปง๏ปช ๏บ๏บณ๏บ๏ป๏บช๏บ๏บฉ๏ปฏ ๏บญ๏บ ๏บฉ๏บญ ๏ปญ๏บ๏ปฎ๏บฉ ๏บ๏ปญ ๏ป๏บฎ๏บ๏บญ ๏บฉ๏บ๏บฉ๏ปฉุ ๏ปญ ๏บ๏ปญ ๏บญ๏บ ๏บ๏บฎ๏บ๏ปฏ ๏ญ๏ปด๏ปค๏ปฎ๏บฉ๏ปฅ ๏ป๏ปฎ๏บฑ ๏บป๏ป๏ปฎ๏บฉ๏ปฏ ๏บ๏บด๏ปด๏บ๏บญ ๏ป๏ป๏ปด๏ปค๏ปฐ ๏บ๏ปฃ๏บ๏บฉ๏ปฉ ๏บณ๏บ๏บง๏บ๏ปชุ ๏ปญ ๏บ๏บ ๏บ๏ปณ๏ปจ๏ป๏ปช ๏บ๏ปง๏บด๏บ๏ปฅ\" ๏บ๏บฎู ๏บป๏ป๏ปด๏บฎ๏ปฏ\" ๏บ๏บณ๏บุ\" ๏ป๏บ๏ป๏ปข ๏ป๏บ๏ปด๏บฎ\" ๏บญ๏บ ๏บฉ๏บญ ๏บ๏ปญ ๏บ๏บ ๏บฉ๏บ๏บฉ๏ปฉ ๏ปญ ๏บ๏ปฅ ๏ป๏บช๏บญ ๏บท๏บ๏ปณ๏บด๏บ๏ฎ๏ปด๏ปฌ๏บ ๏บ๏ปช ๏บ๏ปญ ๏บ๏บจ๏บธ๏ปด๏บช๏ปฉ ๏ป๏ปช ๏ป๏บ๏ปณ๏ป ๏บง๏ป๏ป๏บ ๏ปญู ๏ปู๏ปู๏บชู ๏ปู๏บฎูู๏ปฃู๏ปจ๏บ ๏บู๏ปจู๏ปฐ ๏บ๏บฉููู\" ๏ปฃ๏บ ๏ป๏บฎ๏บฏ๏ปง๏บช๏บ๏ปฅ ๏บ๏บฉู ๏บญ๏บ ๏ป๏บฎ๏บ๏ปฃ๏บ ๏ปญ ๏ป๏ป๏ปค๏บ ๏บ๏บจ๏บธ๏ปด๏บช๏ปณ๏ปข (๏บณ๏ปฎ๏บญ๏ปฉ ๏บ๏บณ๏บฎ๏บุก ๏บ๏ปณ๏ปช 70) ๏บท๏บช๏ปฉ ๏บ๏บณ๏บ ๏ปซ๏ปค๏บ๏ปฅ ๏บ๏ปง๏บด๏บ๏ปง๏ปฐ ๏ป๏ปช ๏บ๏ป๏บช ๏บ๏บฏ ๏บ๏บ๏ปค๏บู ๏บง๏ป๏ป๏บ๏บถ ๏ปฃ๏ปฐ ๏ป๏บฎ๏ปฃ๏บ๏ปณ๏บช: ๏ปู๏บู๏บ๏บ๏บญู๏ปู ๏บ๏ป๏ปูู๏ปชู ๏บู๏บฃู๏บดู๏ปฆู ๏บ๏ปู๏บจ๏บ๏ปู๏ปู๏ปด๏ปฆู\" ๏ญ๏บฒ ๏บ๏บฐ๏บญ๏ฎ ๏ปญ ๏ญ๏บฎ ๏บ๏บฎ๏ป๏บ ๏บ๏บณ๏บ ๏บง๏บช๏บ๏ปณ๏ปฐ ๏ป๏ปช ๏บ๏ปฌ๏บ๏บฎ๏ปณ๏ปฆ ๏บง๏ป๏ป ๏ป๏ปจ๏ปจ๏บช๏ฎ๏บ๏ปฅ ๏บ๏บณ๏บ\"!\n",
            "\n",
            "\n",
            "\n",
            "๐ุชูุณุฑ ููููู ุฐู ุขู ด ุณูุฑู ุงูุชู\n",
            "#ูุฑุขู \n",
            "๐ธูุฏุฑ ุฎูุฏุชุงู ุฑุง ุจุฏุงูุฏ.\n",
            "\n",
            "๐ @ ๐๐ผ\n",
            " ูููุฏ ุฎูููููุง ุงูุงูุณุงูู ู ุงูุญุณู ุชููู \n",
            "\n",
            "\" \"        ุ  ู     ุ   ู                ุ    ุ       ุ           ุ           ุ    \" ู \" ุ\"  \"                ู ููู ูููู ูู ููู\"   ู      ( ุก  70)        ู   : ูููู ููู ูููู ูููู\"            \"!\n",
            "\n",
            "\n",
            "\n",
            "ุชูุณุฑ ููููู ุฐู ุขู ด ุณูุฑู ุงูุชู\n",
            "#ูุฑุขู \n",
            "ูุฏุฑ ุฎูุฏุชุงู ุฑุง ุจุฏุงูุฏ.\n",
            "\n",
            " @ \n",
            "ูุบุฒุดฺฏุงููุง ุงูุฏุดู ุงุฒ ูุธุฑ ูุฑุขู \n",
            "\n",
            "\n",
            "ูุฑุขู ูุฌุฏ ฺฉู ุฏุนูุช ุจู ุชูฺฉุฑ ู ูุชุฌู ฺฏุฑ ูฺฉุฑ ูโฺฉูุฏ ู ุชูฺฉุฑ ุฑุง ุนุจุงุฏุชโ \n",
            "ูโุดูุงุฑุฏ ู ุงุตูู ุนูุงุฏ ุฑุง ุฌุฒ ุจุง ุชูฺฉุฑ ููุทู ุ ุตุญุญ ููโุฏุงูุฏ ุ ุจู ฺฉ ูุทูุจโ \n",
            "ุงุณุงุณ ุชูุฌู ฺฉุฑุฏู ุงุณุช ู ุขู ุงูฺฉู ูุบุฒุดูุง ูฺฉุฑ ุจุดุฑ ุงุฒ ฺฉุฌุง ุณุฑฺุดูู ูโฺฏุฑุฏ \n",
            "ู ุฑุดู ุงุตู ุฎุทุงูุง ู ฺฏูุฑุงููุง ุฏุฑ ฺฉุฌุงุณุช ุ\n",
            "\n",
            "๐ธุชฺฉู ุจุฑ ุธู ู ฺฏูุงู ุจุฌุง ุนูู ู ูู \n",
            "ูุฑุขู ูโฺฏูุฏ : \n",
            "ุงฺฉุซุฑ ูุฑุฏู ฺููโุงูุฏ ฺฉู ุงฺฏุฑ ุจุฎูุงู ูพุฑู ุขููุง ุจุงุด ุชู ุฑุง ุงุฒ ุฑุงู ุญู ฺฏูุฑุงูโ \n",
            "ูโฺฉููุฏ ุ ุจุฑุง ุงูฺฉู ุชฺฉู ุดุงู ุจุฑ ุธู ู ฺฏูุงู ุงุณุช ู ( ูู ุจุฑ ูู ) ุ ุชููุง \n",
            "ุจุง ุญุฏุณ ู ุชุฎูู ฺฉุงุฑ ูโฺฉููุฏ  . \n",
            "ูุฑุขู ฺฉุฑู ุฏุฑ ุขุงุช ุฒุงุฏ ุจู ุดุฏุช ุจุง ูพุฑู ุงุฒ ุธู ู ฺฏูุงู ูุฎุงููุช ูโฺฉูุฏ \n",
            "ู ูโฺฏูุฏ : ูุงุฏุงู ฺฉู ุจู ฺุฒ ุนูู ู ูู ุญุงุตู ูฺฉุฑุฏูโุง ุขูุฑุง ุฏูุจุงู ูฺฉู .\n",
            "\n",
            "๐ธูููุง ู ููุงูุง ููุณุงู \n",
            "ุงูุณุงู ุงฺฏุฑ ุจุฎูุงูุฏ ุตุญุญ ูุถุงูุช ฺฉูุฏ ุจุงุฏ ุฏุฑ ููุฑุฏ ูุทูุจ ฺฉู ูโุงูุฏุดุฏ ฺฉุงููุง \n",
            "ุจ ุทุฑู ุฎูุฏ ุฑุง ุญูุธ ฺฉูุฏ ุ ุนู ฺฉูุดุด ฺฉูุฏ ฺฉู ุญููุช ุฎูุงู ุจุงุดุฏ ู ุฎูุดุชูโ \n",
            "ุฑุง ุชุณูู ุฏูููุง ู ูุฏุงุฑฺฉ ููุงุฏ ุ ุฏุฑุณุช ูุงููุฏ ฺฉ ูุงุถ ฺฉู ุฑู ูพุฑููุฏูโุงโ \n",
            "ูุทุงูุนู ูโฺฉูุฏ ุ ุจุงุฏ ูุณุจุช ุจู ุทุฑูู ุฏุนูุง ุจ ุทุฑู ุจุงุดุฏ . \n",
            "ุงูุณุงู ุฏุฑ ุชูฺฉุฑุงุช ุฎูุฏ ุงฺฏุฑ ุจ ุทุฑู ุฎูุฏ ุฑุง ูุณุจุช ุจู ูู ุง ุงุซุจุงุช ูุทูุจโ \n",
            "ุญูุธ ูฺฉูุฏ ู ูู ููุณุงูุด ุจู ฺฉ ุทุฑู ุจุงุดุฏ ุ ุฎูุงูโูุงุฎูุงู ู ุจุฏูู ุขูฺฉูโ \n",
            "ุฎูุฏุด ูุชูุฌู ุดูุฏ ุนูุฑุจู ูฺฉุฑุด ุจู ุฌุงูุจ ูู ู ุฎูุงูุด ููุณุงูุด ูุชูุงูโ \n",
            "ูโุดูุฏ ุงู ุงุณุช ฺฉู ูุฑุขู ููุง ููุณ ุฑุง ูุฒ ูุงููุฏ ุชฺฉู ุจุฑ ุธู ู ฺฏูุงู ฺฉ ุงุฒ \n",
            "ุนูุงูู ูุบุฒุด ูโุดูุงุฑุฏ .\n",
            "\n",
            "๐ธุดุชุงุจุฒุฏฺฏ \n",
            "ูุฑ ูุถุงูุช ู ุงุธูุงุฑ ูุธุฑ ููุฏุงุฑ ูุนู ูุฏุงุฑฺฉ ูุงุฒู ุฏุงุฑุฏ ู ุชุง ูุฏุงุฑฺฉ ุจูโ \n",
            "ูุฏุฑ ฺฉุงู ุฏุฑ ฺฉ ูุณุงูู ุฌูุน ูุดูุฏ ูุฑฺฏููู ุงุธูุงุฑ ูุธุฑ ุ ุดุชุงุจุฒุฏฺฏ ู ููุฌุจ ูุบุฒุด ุงูุฏุดู ุงุณุช ูุฑุขู ฺฉุฑู ูฺฉุฑุฑ ุจู ุงูุฏฺฉ ุจูุฏู ุณุฑูุงูโ \n",
            "ุนูู ุจุดุฑ ู ฺฉุงู ูุจูุฏูุด ุจุฑุง ุจุฑุฎ ูุถุงูุชูุง ุจุฒุฑฺฏ ุงุดุงุฑู ูโฺฉูุฏ ู ุงุธูุงุฑ \n",
            "ุฌุฒู ุฑุง ุฏูุฑ ุงุฒ ุงุญุชุงุท ุชูู ูโููุงุฏ . \n",
            "\n",
            "๐ธุณูุช ฺฏุฑุงุฆ ู ฺฏุฐุดุชู ูฺฏุฑ \n",
            "ุงูุณุงู ุจู ุญฺฉู ุทุจุน ุงูู ุฎูุฏ ููฺฏุงู ฺฉู ูโุจูุฏ ฺฉ ูฺฉุฑ ู ุนูุฏู ุฎุงุต ููุฑุฏ \n",
            "ูุจูู ูุณููุง ฺฏุฐุดุชู ุจูุฏู ุงุณุช ุฎูุฏุจุฎูุฏ ุจุฏูู ุขูฺฉู ูุฌุงู ุจู ุงูุฏุดู ุฎูุฏ ุจุฏูุฏ \n",
            "ุขู ุฑุง ูโูพุฐุฑุฏ ูุฑุขู ุงุฏุขูุฑ ูโฺฉูุฏ ฺฉู ูพุฐุฑูุชูโูุง ู ุจุงูุฑูุง ฺฏุฐุดุชฺฏุงู ุฑุง \n",
            "ูุงุฏุงู ฺฉู ุจุง ูุนุงุฑ ุนูู ูุณูุฌุฏูโุงุฏ ููพุฐุฑุฏ ุ ุฏุฑ ููุงุจู ุจุงูุฑูุง ฺฏุฐุดุชฺฏุงูโ \n",
            "ุงุณุชููุงู ูฺฉุฑ ุฏุงุดุชู ุจุงุดุฏ . \n",
            "\n",
            "๐ธุดุฎุตุช ฺฏุฑุงุฆ \n",
            "ฺฉ ุฏฺฏุฑ ุงุฒ ููุฌุจุงุช ูุบุฒุด ุงูุฏุดู ุ ฺฏุฑุงุด ุจู ุดุฎุตุชูุง ุงุณุช ุดุฎุตุชูุงโ \n",
            "ุจุฒุฑฺฏ ุชุงุฑุฎ ุง ูุนุงุตุฑ ุงุฒ ูุธุฑ ุนุธูุช ฺฉู ุฏุฑ ูููุณ ุฏุงุฑูุฏ ุจุฑ ุฑู ูฺฉุฑ ู ุงูุฏุดู ู ุชุตูู ู ุงุฑุงุฏู ุฏฺฏุฑุงู ุงุซุฑ ูโฺฏุฐุงุฑูุฏ ู ุฏุฑ ุญููุช ููโ \n",
            "ูฺฉุฑ ู ูู ุงุฑุงุฏู ุฏฺฏุฑุงู ุฑุง ุชุณุฎุฑ ูโฺฉููุฏ ุ ุฏฺฏุฑุงู ุขูฺูุงู ูโุงูุฏุดูุฏ ฺฉูโ \n",
            "ุขููุง ูโุงูุฏุดูุฏ ู ุขูฺูุงู ุชุตูู ูโฺฏุฑูุฏ ฺฉู ุขููุง ูโฺฏุฑูุฏ ุ ุฏฺฏุฑุงู ุฏุฑ \n",
            "ููุงุจู ุขููุง ุงุณุชููุงู ูฺฉุฑ ู ุงุฑุงุฏู ุฎูุฏ ุฑุง ุงุฒ ุฏุณุช ูโุฏููุฏ .\n",
            "\n",
            "๐ุงูุณุงู ู ุงูุงู ุ ุดูุฏ ูุทูุฑ \n",
            "\n",
            "๐ @\n",
            "ูุบุฒุดฺฏุงููุง ุงูุฏุดู ุงุฒ ูุธุฑ ูุฑุขู \n",
            "\n",
            "\n",
            "ูุฑุขู ูุฌุฏ ฺฉู ุฏุนูุช ุจู ุชูฺฉุฑ ู ูุชุฌู ฺฏุฑ ูฺฉุฑ ูโฺฉูุฏ ู ุชูฺฉุฑ ุฑุง ุนุจุงุฏุชโ \n",
            "ูโุดูุงุฑุฏ ู ุงุตูู ุนูุงุฏ ุฑุง ุฌุฒ ุจุง ุชูฺฉุฑ ููุทู ุ ุตุญุญ ููโุฏุงูุฏ ุ ุจู ฺฉ ูุทูุจโ \n",
            "ุงุณุงุณ ุชูุฌู ฺฉุฑุฏู ุงุณุช ู ุขู ุงูฺฉู ูุบุฒุดูุง ูฺฉุฑ ุจุดุฑ ุงุฒ ฺฉุฌุง ุณุฑฺุดูู ูโฺฏุฑุฏ \n",
            "ู ุฑุดู ุงุตู ุฎุทุงูุง ู ฺฏูุฑุงููุง ุฏุฑ ฺฉุฌุงุณุช ุ\n",
            "\n",
            "ุชฺฉู ุจุฑ ุธู ู ฺฏูุงู ุจุฌุง ุนูู ู ูู \n",
            "ูุฑุขู ูโฺฏูุฏ : \n",
            "ุงฺฉุซุฑ ูุฑุฏู ฺููโุงูุฏ ฺฉู ุงฺฏุฑ ุจุฎูุงู ูพุฑู ุขููุง ุจุงุด ุชู ุฑุง ุงุฒ ุฑุงู ุญู ฺฏูุฑุงูโ \n",
            "ูโฺฉููุฏ ุ ุจุฑุง ุงูฺฉู ุชฺฉู ุดุงู ุจุฑ ุธู ู ฺฏูุงู ุงุณุช ู ( ูู ุจุฑ ูู ) ุ ุชููุง \n",
            "ุจุง ุญุฏุณ ู ุชุฎูู ฺฉุงุฑ ูโฺฉููุฏ  . \n",
            "ูุฑุขู ฺฉุฑู ุฏุฑ ุขุงุช ุฒุงุฏ ุจู ุดุฏุช ุจุง ูพุฑู ุงุฒ ุธู ู ฺฏูุงู ูุฎุงููุช ูโฺฉูุฏ \n",
            "ู ูโฺฏูุฏ : ูุงุฏุงู ฺฉู ุจู ฺุฒ ุนูู ู ูู ุญุงุตู ูฺฉุฑุฏูโุง ุขูุฑุง ุฏูุจุงู ูฺฉู .\n",
            "\n",
            "ูููุง ู ููุงูุง ููุณุงู \n",
            "ุงูุณุงู ุงฺฏุฑ ุจุฎูุงูุฏ ุตุญุญ ูุถุงูุช ฺฉูุฏ ุจุงุฏ ุฏุฑ ููุฑุฏ ูุทูุจ ฺฉู ูโุงูุฏุดุฏ ฺฉุงููุง \n",
            "ุจ ุทุฑู ุฎูุฏ ุฑุง ุญูุธ ฺฉูุฏ ุ ุนู ฺฉูุดุด ฺฉูุฏ ฺฉู ุญููุช ุฎูุงู ุจุงุดุฏ ู ุฎูุดุชูโ \n",
            "ุฑุง ุชุณูู ุฏูููุง ู ูุฏุงุฑฺฉ ููุงุฏ ุ ุฏุฑุณุช ูุงููุฏ ฺฉ ูุงุถ ฺฉู ุฑู ูพุฑููุฏูโุงโ \n",
            "ูุทุงูุนู ูโฺฉูุฏ ุ ุจุงุฏ ูุณุจุช ุจู ุทุฑูู ุฏุนูุง ุจ ุทุฑู ุจุงุดุฏ . \n",
            "ุงูุณุงู ุฏุฑ ุชูฺฉุฑุงุช ุฎูุฏ ุงฺฏุฑ ุจ ุทุฑู ุฎูุฏ ุฑุง ูุณุจุช ุจู ูู ุง ุงุซุจุงุช ูุทูุจโ \n",
            "ุญูุธ ูฺฉูุฏ ู ูู ููุณุงูุด ุจู ฺฉ ุทุฑู ุจุงุดุฏ ุ ุฎูุงูโูุงุฎูุงู ู ุจุฏูู ุขูฺฉูโ \n",
            "ุฎูุฏุด ูุชูุฌู ุดูุฏ ุนูุฑุจู ูฺฉุฑุด ุจู ุฌุงูุจ ูู ู ุฎูุงูุด ููุณุงูุด ูุชูุงูโ \n",
            "ูโุดูุฏ ุงู ุงุณุช ฺฉู ูุฑุขู ููุง ููุณ ุฑุง ูุฒ ูุงููุฏ ุชฺฉู ุจุฑ ุธู ู ฺฏูุงู ฺฉ ุงุฒ \n",
            "ุนูุงูู ูุบุฒุด ูโุดูุงุฑุฏ .\n",
            "\n",
            "ุดุชุงุจุฒุฏฺฏ \n",
            "ูุฑ ูุถุงูุช ู ุงุธูุงุฑ ูุธุฑ ููุฏุงุฑ ูุนู ูุฏุงุฑฺฉ ูุงุฒู ุฏุงุฑุฏ ู ุชุง ูุฏุงุฑฺฉ ุจูโ \n",
            "ูุฏุฑ ฺฉุงู ุฏุฑ ฺฉ ูุณุงูู ุฌูุน ูุดูุฏ ูุฑฺฏููู ุงุธูุงุฑ ูุธุฑ ุ ุดุชุงุจุฒุฏฺฏ ู ููุฌุจ ูุบุฒุด ุงูุฏุดู ุงุณุช ูุฑุขู ฺฉุฑู ูฺฉุฑุฑ ุจู ุงูุฏฺฉ ุจูุฏู ุณุฑูุงูโ \n",
            "ุนูู ุจุดุฑ ู ฺฉุงู ูุจูุฏูุด ุจุฑุง ุจุฑุฎ ูุถุงูุชูุง ุจุฒุฑฺฏ ุงุดุงุฑู ูโฺฉูุฏ ู ุงุธูุงุฑ \n",
            "ุฌุฒู ุฑุง ุฏูุฑ ุงุฒ ุงุญุชุงุท ุชูู ูโููุงุฏ . \n",
            "\n",
            "ุณูุช ฺฏุฑุงุฆ ู ฺฏุฐุดุชู ูฺฏุฑ \n",
            "ุงูุณุงู ุจู ุญฺฉู ุทุจุน ุงูู ุฎูุฏ ููฺฏุงู ฺฉู ูโุจูุฏ ฺฉ ูฺฉุฑ ู ุนูุฏู ุฎุงุต ููุฑุฏ \n",
            "ูุจูู ูุณููุง ฺฏุฐุดุชู ุจูุฏู ุงุณุช ุฎูุฏุจุฎูุฏ ุจุฏูู ุขูฺฉู ูุฌุงู ุจู ุงูุฏุดู ุฎูุฏ ุจุฏูุฏ \n",
            "ุขู ุฑุง ูโูพุฐุฑุฏ ูุฑุขู ุงุฏุขูุฑ ูโฺฉูุฏ ฺฉู ูพุฐุฑูุชูโูุง ู ุจุงูุฑูุง ฺฏุฐุดุชฺฏุงู ุฑุง \n",
            "ูุงุฏุงู ฺฉู ุจุง ูุนุงุฑ ุนูู ูุณูุฌุฏูโุงุฏ ููพุฐุฑุฏ ุ ุฏุฑ ููุงุจู ุจุงูุฑูุง ฺฏุฐุดุชฺฏุงูโ \n",
            "ุงุณุชููุงู ูฺฉุฑ ุฏุงุดุชู ุจุงุดุฏ . \n",
            "\n",
            "ุดุฎุตุช ฺฏุฑุงุฆ \n",
            "ฺฉ ุฏฺฏุฑ ุงุฒ ููุฌุจุงุช ูุบุฒุด ุงูุฏุดู ุ ฺฏุฑุงุด ุจู ุดุฎุตุชูุง ุงุณุช ุดุฎุตุชูุงโ \n",
            "ุจุฒุฑฺฏ ุชุงุฑุฎ ุง ูุนุงุตุฑ ุงุฒ ูุธุฑ ุนุธูุช ฺฉู ุฏุฑ ูููุณ ุฏุงุฑูุฏ ุจุฑ ุฑู ูฺฉุฑ ู ุงูุฏุดู ู ุชุตูู ู ุงุฑุงุฏู ุฏฺฏุฑุงู ุงุซุฑ ูโฺฏุฐุงุฑูุฏ ู ุฏุฑ ุญููุช ููโ \n",
            "ูฺฉุฑ ู ูู ุงุฑุงุฏู ุฏฺฏุฑุงู ุฑุง ุชุณุฎุฑ ูโฺฉููุฏ ุ ุฏฺฏุฑุงู ุขูฺูุงู ูโุงูุฏุดูุฏ ฺฉูโ \n",
            "ุขููุง ูโุงูุฏุดูุฏ ู ุขูฺูุงู ุชุตูู ูโฺฏุฑูุฏ ฺฉู ุขููุง ูโฺฏุฑูุฏ ุ ุฏฺฏุฑุงู ุฏุฑ \n",
            "ููุงุจู ุขููุง ุงุณุชููุงู ูฺฉุฑ ู ุงุฑุงุฏู ุฎูุฏ ุฑุง ุงุฒ ุฏุณุช ูโุฏููุฏ .\n",
            "\n",
            "ุงูุณุงู ู ุงูุงู ุ ุดูุฏ ูุทูุฑ \n",
            "\n",
            " @\n",
            "ุฎุฏุงุง! ฺูุฏุฑ ุจุง ุชู ุจูุฏู ุฑุง ุฏูุณุช ุฏุงุฑู!\n",
            "ุชูุงู ูุญุธู ูุง ฺฉู ุจุง ุชู ุณูพุฑ ู ฺฉููุ\n",
            "ุขู ุฏูุงุฆู ฺฉูุชุงู ฺฉู ุจุฑุง ุตุญุจุช ุจุง ุชู ู ฺฏุฐุงุฑูุ\n",
            "ุญุช ุขู ูุญุธู ูุง ุณุฑุฏุฑฺฏู ู ูพุฑ ุงุฒ ูฺฉุฑ ู ุฎุงู ุฑุง ุจุง ุชู ุฏูุณุช ุฏุงุฑู\n",
            "ุฎุฏุง ูู!\n",
            "ุฎูุงูุฏูุช ูพุงุณุฎู ฺฏูุช\n",
            "ุงุฒ ุชู ุฎูุงุณุชู ุนุทุงู ฺฉุฑุฏ\n",
            "ุจู ุณู ุชู ุขูุฏู ุขุบูุด ุฑุญูุช ฺฏุดูุฏ\n",
            "ุจู ุชู ุชฺฉู ฺฉุฑุฏู ูุฌุงุชู ุฏุงุฏ\n",
            "ุจู ุชู ูพูุงู ุขูุฑุฏู ฺฉูุงุชู ฺฉุฑุฏ\n",
            "ุฎุฏุง ูู! \n",
            "ุฏูุณุช ุฏุงุฑู ....ุฏุณุชุงูู ุฑุง ุฑูุง ูฺฉู.\n",
            "ุฎุฏุงุง! ฺูุฏุฑ ุจุง ุชู ุจูุฏู ุฑุง ุฏูุณุช ุฏุงุฑู!\n",
            "ุชูุงู ูุญุธู ูุง ฺฉู ุจุง ุชู ุณูพุฑ ู ฺฉููุ\n",
            "ุขู ุฏูุงุฆู ฺฉูุชุงู ฺฉู ุจุฑุง ุตุญุจุช ุจุง ุชู ู ฺฏุฐุงุฑูุ\n",
            "ุญุช ุขู ูุญุธู ูุง ุณุฑุฏุฑฺฏู ู ูพุฑ ุงุฒ ูฺฉุฑ ู ุฎุงู ุฑุง ุจุง ุชู ุฏูุณุช ุฏุงุฑู\n",
            "ุฎุฏุง ูู!\n",
            "ุฎูุงูุฏูุช ูพุงุณุฎู ฺฏูุช\n",
            "ุงุฒ ุชู ุฎูุงุณุชู ุนุทุงู ฺฉุฑุฏ\n",
            "ุจู ุณู ุชู ุขูุฏู ุขุบูุด ุฑุญูุช ฺฏุดูุฏ\n",
            "ุจู ุชู ุชฺฉู ฺฉุฑุฏู ูุฌุงุชู ุฏุงุฏ\n",
            "ุจู ุชู ูพูุงู ุขูุฑุฏู ฺฉูุงุชู ฺฉุฑุฏ\n",
            "ุฎุฏุง ูู! \n",
            "ุฏูุณุช ุฏุงุฑู ....ุฏุณุชุงูู ุฑุง ุฑูุง ูฺฉู.\n",
            "ุดุงู ุชูุงู ฺฉุชุงุจ ูุง ุฌูุงู ๐๐๐\n",
            "ุดุงู ุชูุงู ฺฉุชุงุจ ูุง ุฌูุงู \n",
            "ููุท ุฎุฏุง\n",
            "ููุท ุฎุฏุง\n",
            "ุฎู ุฎูุจู ฺฉู ุงูุทูุฑ ููู ุฌุง ฺฉุชุงุจ ูุฑุขู ฺฉุฑู ุจุง ุชุฑุฌูู ููุดู ููุฑุงูุชู ู ู ุชูู ุจูุด ู ูฺฏุงู ุจูุฏุงุฒ ุชุง ุฏูุช ุชู ุฏุงูุดฺฏุงู ุ ุงุฏุงุฑู ุ ุง ููุงูุน ฺฉู ุฏูุชูฺฏ ุฎุฏุง ฺฉูุงูุดู ุจุฎูู ุชุง ุขุฑูู ุจุด ู ุฏูุจุงุฑู ุจุง ุงู ฺฉู ุดฺฉุณุช ุฎูุฑุฏ ุจุง ูุฏุฑุช ูพุงุด ู ุงุฏุงูู ุจุฏ ุ ุงุฒ ููฺฉุงุฑุงู ฺฏุฑุงู ุจุณุงุฑ ุณูพุงุณ ฺฏุฒุงุฑู . ุง ุนู .\n",
            "ุฎู ุฎูุจู ฺฉู ุงูุทูุฑ ููู ุฌุง ฺฉุชุงุจ ูุฑุขู ฺฉุฑู ุจุง ุชุฑุฌูู ููุดู ููุฑุงูุชู ู ู ุชูู ุจูุด ู ูฺฏุงู ุจูุฏุงุฒ ุชุง ุฏูุช ุชู ุฏุงูุดฺฏุงู ุ ุงุฏุงุฑู ุ ุง ููุงูุน ฺฉู ุฏูุชูฺฏ ุฎุฏุง ฺฉูุงูุดู ุจุฎูู ุชุง ุขุฑูู ุจุด ู ุฏูุจุงุฑู ุจุง ุงู ฺฉู ุดฺฉุณุช ุฎูุฑุฏ ุจุง ูุฏุฑุช ูพุงุด ู ุงุฏุงูู ุจุฏ ุ ุงุฒ ููฺฉุงุฑุงู ฺฏุฑุงู ุจุณุงุฑ ุณูพุงุณ ฺฏุฒุงุฑู . ุง ุนู .\n",
            "ุฎูุดุญุงูู ฺฉู ุทุงูฺู ฺฉุชุงุจ ูุง ุฎูุจ ุฑู ูุงููุฏ ูุฑุขู ฺฉุฑู ู ุดุงููุงูู ูุฑุฏูุณ ุฑุงฺฏุงู ุฏุฑ ุงุฎุชุงุฑ ูุง ูุฑุงุฑ ู ุฏูุฏ\n",
            "ุฎูุดุญุงูู ฺฉู ุทุงูฺู ฺฉุชุงุจ ูุง ุฎูุจ ุฑู ูุงููุฏ ูุฑุขู ฺฉุฑู ู ุดุงููุงูู ูุฑุฏูุณ ุฑุงฺฏุงู ุฏุฑ ุงุฎุชุงุฑ ูุง ูุฑุงุฑ ู ุฏูุฏ\n",
            "ุฏูุณุชุงู ุทุงูฺู ุฏุฑุฒููู ฺฉุชุจ ูุฐูุจ ุ ูฺฉุฑูฺฉูู ฺฉู ูุทู ฺฉุฑุฏูุฏ ุชููุน ุฒุงุฏูุณุชุ ุณุงุช ูุตุงู ฺฉุชุงุจ ูุง ุฑู ุฏุฑุงู ุฒููู ุจู ุตูุฑุช ุฑุงฺฏุงู ูุฑุงุฑุฏุงุฏูุฏ ุจู ุนูุงูู ููุฏุงู ูพุดููุงุฏ ูฺฉูู ุจู ุงู ุณุงุช ูุฑุงุฌุนู ฺฉูุฏ.\n",
            "ุฏูุณุชุงู ุทุงูฺู ุฏุฑุฒููู ฺฉุชุจ ูุฐูุจ ุ ูฺฉุฑูฺฉูู ฺฉู ูุทู ฺฉุฑุฏูุฏ ุชููุน ุฒุงุฏูุณุชุ ุณุงุช ูุตุงู ฺฉุชุงุจ ูุง ุฑู ุฏุฑุงู ุฒููู ุจู ุตูุฑุช ุฑุงฺฏุงู ูุฑุงุฑุฏุงุฏูุฏ ุจู ุนูุงูู ููุฏุงู ูพุดููุงุฏ ูฺฉูู ุจู ุงู ุณุงุช ูุฑุงุฌุนู ฺฉูุฏ.\n",
            "ุจุฑุง ุณูุงูุช ุขูุงุฑ ูุง ูุฑุดฺฏุงู ูพูุงุณฺฉู ุชูุฑุงู  ู ุขุชุด ูุดุงูุงู  ููุฑูุงู ฺฉุดูุฑููู ฺฉู ุฌุงู ุฎูุฏ ุฑุง ุฏุงุฏู ุ ุจุฎููุฏ ูุฑุขู ู ูุงุชุญู ู ุตูุงุช.\n",
            "ุจุฑุง ุณูุงูุช ุขูุงุฑ ูุง ูุฑุดฺฏุงู ูพูุงุณฺฉู ุชูุฑุงู  ู ุขุชุด ูุดุงูุงู  ููุฑูุงู ฺฉุดูุฑููู ฺฉู ุฌุงู ุฎูุฏ ุฑุง ุฏุงุฏู ุ ุจุฎููุฏ ูุฑุขู ู ูุงุชุญู ู ุตูุงุช.\n",
            "ุณูุงู.ุฎุชู ุขู ุงูฺฉุฑุณ ฺฏุฑูุชู ุจุฑุง ุขุชุด ูุดุงูุงู ู ูููุทูุงู ฺฉู ุฒุฑ ุขูุงุฑ ูุงูุฏู ุงูุฏ.ุจุฑุง ุณูุงูุช ู ุฒูุฏู ุจูุฏูุดุงู.ุณูู ุดูุง ุฏู ุชุง.ูุทูุง ุจู ุฏูุณุชุงู ุฎูุฏ ุจฺฏูุฏุุชุง ุจู ูุช ฑด ูุนุตููุุฎุฏุงููุฏ ูุธุฑ ููุงุฏ.\n",
            "ุณูุงู.ุฎุชู ุขู ุงูฺฉุฑุณ ฺฏุฑูุชู ุจุฑุง ุขุชุด ูุดุงูุงู ู ูููุทูุงู ฺฉู ุฒุฑ ุขูุงุฑ ูุงูุฏู ุงูุฏ.ุจุฑุง ุณูุงูุช ู ุฒูุฏู ุจูุฏูุดุงู.ุณูู ุดูุง ุฏู ุชุง.ูุทูุง ุจู ุฏูุณุชุงู ุฎูุฏ ุจฺฏูุฏุุชุง ุจู ูุช ฑด ูุนุตููุุฎุฏุงููุฏ ูุธุฑ ููุงุฏ.\n",
            "ูุฑุขู ุดุงูฺฉุงุฑ ุจ ูุงููุฏ ุฒุจุงู ุนุฑุจ ุงุณุช ู ุจุงุฏ ุงุนุชุฑุงู ฺฉุฑุฏ ฺฉู ุฌูุงู ุตูุฑ ุขู ุจุง ุนุธูุช ูุนูู ุงุด ุจุฑุงุจุฑ ุงุณุช... .\n",
            "ูุฑุขู ุจุง ุณุจฺฉ ุฎุงุต ุฎูุด ุฏุงุฑุง ูุจุงุญุซ ูุฎุชูู ู ููุงุฏ ูุชุนุฏุฏ ุงุณุช: ูู ุณุฑูุฏ ูุฐูุจ ุงุณุช ูู ุณุชุงุด ุงุฒุฏุ ู ูู ูุชุถูู ุงุตููุ ููุงุนุฏ ู ููุงูู ูุฏู ู ุฌุฒุง ุงุณุชุ ูู ุจุดุฑ ู ูุฐุฑ ุงุณุช ู ูู ูพูุฏุขููุฒ ู ุงูุฏุฑุฒฺฏูุ ูู ูุคููุงู ุฑุง ุจู ุตุฑุงุท ูุณุชูู ูุฏุงุช ู ฺฉูุฏ ู ูู ูุตู ู ุฏุงุณุชุงู ู ุงูุซุงู ู ุญฺฉู ุจุงู ู ฺฉูุฏ... .\n",
            "ุฏุฑ ุชูุตู ุงููุช ุงู ฺฉุชุงุจ ููู ูุฏุฑ ฺฉุงู ุงุณุช ฺฉู ุงุนุฑุงุจ ุจุง ูุฌูุฏ ููุงู ู ุนูุงุฏ ู ูุฌุงุฌ ุฒุงุฏ ฺฉู ุฏุฑ ุณุฑุดุช ุขู ููู ุงุณุช ู ุจุง ูุตู ุงูฺฉู ููุฑ ุจู ุบุฑ ุงุฒ ูุตุงุญุช ู ุจูุงุบุช ู ุณุฎู ุณูุฌ ูุฏุงุดุชูุฏ ุฏุฑ ูพุด ูุฑุขู ุฒุงูู ุจุฑ ุฒูู ุฒุฏูุฏุ ุขู ุฑุง ฺฉูุงู ุงูู ุฏุงูุณุชู ู ุจู ุฐู ููุง ุขู ุฏุณุช ุฒุฏูุฏ.\n",
            "\n",
            "(ุจุงุฑุชูู ุณูุช ููุฑุ ูุญูุฏ ู ูุฑุขูุ ุต188-187)\n",
            "ูุฑุขู ุดุงูฺฉุงุฑ ุจ ูุงููุฏ ุฒุจุงู ุนุฑุจ ุงุณุช ู ุจุงุฏ ุงุนุชุฑุงู ฺฉุฑุฏ ฺฉู ุฌูุงู ุตูุฑ ุขู ุจุง ุนุธูุช ูุนูู ุงุด ุจุฑุงุจุฑ ุงุณุช... .\n",
            "ูุฑุขู ุจุง ุณุจฺฉ ุฎุงุต ุฎูุด ุฏุงุฑุง ูุจุงุญุซ ูุฎุชูู ู ููุงุฏ ูุชุนุฏุฏ ุงุณุช: ูู ุณุฑูุฏ ูุฐูุจ ุงุณุช ูู ุณุชุงุด ุงุฒุฏุ ู ูู ูุชุถูู ุงุตููุ ููุงุนุฏ ู ููุงูู ูุฏู ู ุฌุฒุง ุงุณุชุ ูู ุจุดุฑ ู ูุฐุฑ ุงุณุช ู ูู ูพูุฏุขููุฒ ู ุงูุฏุฑุฒฺฏูุ ูู ูุคููุงู ุฑุง ุจู ุตุฑุงุท ูุณุชูู ูุฏุงุช ู ฺฉูุฏ ู ูู ูุตู ู ุฏุงุณุชุงู ู ุงูุซุงู ู ุญฺฉู ุจุงู ู ฺฉูุฏ... .\n",
            "ุฏุฑ ุชูุตู ุงููุช ุงู ฺฉุชุงุจ ููู ูุฏุฑ ฺฉุงู ุงุณุช ฺฉู ุงุนุฑุงุจ ุจุง ูุฌูุฏ ููุงู ู ุนูุงุฏ ู ูุฌุงุฌ ุฒุงุฏ ฺฉู ุฏุฑ ุณุฑุดุช ุขู ููู ุงุณุช ู ุจุง ูุตู ุงูฺฉู ููุฑ ุจู ุบุฑ ุงุฒ ูุตุงุญุช ู ุจูุงุบุช ู ุณุฎู ุณูุฌ ูุฏุงุดุชูุฏ ุฏุฑ ูพุด ูุฑุขู ุฒุงูู ุจุฑ ุฒูู ุฒุฏูุฏุ ุขู ุฑุง ฺฉูุงู ุงูู ุฏุงูุณุชู ู ุจู ุฐู ููุง ุขู ุฏุณุช ุฒุฏูุฏ.\n",
            "\n",
            "(ุจุงุฑุชูู ุณูุช ููุฑุ ูุญูุฏ ู ูุฑุขูุ ุต188-187)\n",
            "ุนุงุงุงุงููููููณุจุจุจุจุจ\n",
            "ุนุงุงุงุงููููููณุจุจุจุจุจ\n",
            "ฺฉุงุด ุฌุฒูุง ุฑุง ูู ูุดุฎุต ูฺฉุฑุฏ. ููุฏููู ูู ูพุฏุง ููฺฉูู ุง ูุดุฎุต ูุณุช. ฺฉุณ ูุชููู ุฑุงูููุงู ฺฉููุุ\n",
            "ฺฉุงุด ุฌุฒูุง ุฑุง ูู ูุดุฎุต ูฺฉุฑุฏ. ููุฏููู ูู ูพุฏุง ููฺฉูู ุง ูุดุฎุต ูุณุช. ฺฉุณ ูุชููู ุฑุงูููุงู ฺฉููุุ\n",
            "ุนุงู\n",
            "\n",
            "ุนุงู\n",
            "\n",
            "ฺฉูุงู ุฎุฏุงุงุฑุงูุจุฎุด ุฏู ูุฌุงู\n",
            "ฺฉูุงู ุฎุฏุงุงุฑุงูุจุฎุด ุฏู ูุฌุงู\n",
            "ุชุฑุฌูู ูุฑุญูู ูููุงุฏููุฏุงุฒูุฑุขู ฺฉุฑู ุจูุชุฑู ุชุฑุฌูู ุฏุฑุฒุจุงู ูุงุฑุณ ุงุณุช.ุงูุฏูุงุฑู ูุทุงูุนู ฺฉูู ูุจูุฑู ุจุจุฑู.ุงูุดุงุงููู.\n",
            "ุชุฑุฌูู ูุฑุญูู ูููุงุฏููุฏุงุฒูุฑุขู ฺฉุฑู ุจูุชุฑู ุชุฑุฌูู ุฏุฑุฒุจุงู ูุงุฑุณ ุงุณุช.ุงูุฏูุงุฑู ูุทุงูุนู ฺฉูู ูุจูุฑู ุจุจุฑู.ุงูุดุงุงููู.\n",
            "ฺฉูุงู ุฎุฏุง ู ุนุงู ุงุณุช\n",
            "ฺฉูุงู ุฎุฏุง ู ุนุงู ุงุณุช\n",
            "ุฎูุฏุช ฺฏูุช ุจุฎูุงู \n",
            "ูุฎูุงููุช \n",
            "ุงูฺฉ ูุฑุง ุฏุฑุงุจ \n",
            "ุจู ฺุดูุงู ฺฉ ูุฌูุฏ ุชูุฑุง\n",
            "ููุฑ ุนูุงุช ฺฉู ....\n",
            "ู ุฎุฏุง ููู ูุฒุฏฺฉุณุช \n",
            "ฺฉูุงุฑ ูู ู ุชู ู ูุง.......\n",
            "ุบุงูู ุงุฒ ุงูุูุดุบููู...650\n",
            "ุฎูุฏุช ฺฏูุช ุจุฎูุงู \n",
            "ูุฎูุงููุช \n",
            "ุงูฺฉ ูุฑุง ุฏุฑุงุจ \n",
            "ุจู ฺุดูุงู ฺฉ ูุฌูุฏ ุชูุฑุง\n",
            "ููุฑ ุนูุงุช ฺฉู ....\n",
            "ู ุฎุฏุง ููู ูุฒุฏฺฉุณุช \n",
            "ฺฉูุงุฑ ูู ู ุชู ู ูุง.......\n",
            "ุบุงูู ุงุฒ ุงูุูุดุบููู...650\n",
            "ุจู ูุงู ุฎุฏุง ฺฉู ูุฑฺฏุฒ ุฏุบุฏุบู ุงุฒ ุฏุณุช ุฏุงุฏูุด ุฑุง ูุฏุงุฑู..\n",
            "ุฎุฏุงููุฏ ุจููุฏ ูุฑุชุจู ุฏุฑ ุขู 103 ุณูุฑู ุงูุนุงู ููุฑูุงุฏ:\n",
            "ฺุดู ูุง ุงู ุฑุง ูู ุจููุฏ\n",
            "ูู ุงู ููู ฺุดู ูุง ุฑุง ู ุจูุฏ...\n",
            "\n",
            "ุณูพุงุณ ุทุงูฺู\n",
            "ุจู ูุงู ุฎุฏุง ฺฉู ูุฑฺฏุฒ ุฏุบุฏุบู ุงุฒ ุฏุณุช ุฏุงุฏูุด ุฑุง ูุฏุงุฑู..\n",
            "ุฎุฏุงููุฏ ุจููุฏ ูุฑุชุจู ุฏุฑ ุขู 103 ุณูุฑู ุงูุนุงู ููุฑูุงุฏ:\n",
            "ฺุดู ูุง ุงู ุฑุง ูู ุจููุฏ\n",
            "ูู ุงู ููู ฺุดู ูุง ุฑุง ู ุจูุฏ...\n",
            "\n",
            "ุณูพุงุณ ุทุงูฺู\n",
            "ุฎูุจู ููุท ุขู ูุง ุณุฌุฏู ุฏุงุฑ ุฑู ูฺฏูุชู ฺฉุฏูู ุณุฌุฏู ุฏุงุฑู ูุซ ุณูุฑู ุงูุดูุงู ฺฉู ุณุฌุฏู ูุณุชุญุจ ุฏุงุฑู ูฺ ุนูุงูุช ุจุงูุง ุขู ุด ูุฐุงุดุชู\n",
            "ุฎูุจู ููุท ุขู ูุง ุณุฌุฏู ุฏุงุฑ ุฑู ูฺฏูุชู ฺฉุฏูู ุณุฌุฏู ุฏุงุฑู ูุซ ุณูุฑู ุงูุดูุงู ฺฉู ุณุฌุฏู ูุณุชุญุจ ุฏุงุฑู ูฺ ุนูุงูุช ุจุงูุง ุขู ุด ูุฐุงุดุชู\n",
            "ฺ ุงุฒ ูุฑุขู ฺฉุฑู ุจูุชุฑ ุุุุ\n",
            "ฺ ุงุฒ ูุฑุขู ฺฉุฑู ุจูุชุฑ ุุุุ\n",
            "ุชุฑุฌูู ุงูู ููุดู ุง ุฑู ูู ูุฑุงุฑ ุจุฏุฏ ูุทูุง ุจุง ุชุดฺฉุฑ\n",
            "ุชุฑุฌูู ุงูู ููุดู ุง ุฑู ูู ูุฑุงุฑ ุจุฏุฏ ูุทูุง ุจุง ุชุดฺฉุฑ\n",
            "ุนุงุงุงุงู \n",
            "ุฏุฑูพูุงู ูุฑุงู\n",
            "ุนุงุงุงุงู \n",
            "ุฏุฑูพูุงู ูุฑุงู\n",
            "ุนุงู(very good)\n",
            "ุนุงู(very good)\n",
            "ุณูพุงุณ\n",
            "ุณูพุงุณ\n",
            "ูุฑุงู ููุดู ุนุงูุณุช\n",
            "ูุฑุงู ููุดู ุนุงูุณุช\n",
            "ููููู ฺฉู ุฑุงฺฏุงูู\n",
            "ููููู ฺฉู ุฑุงฺฏุงูู\n",
            "ุฎู ููููู ุจุงุจุช ุฑุงฺฏุงู ฺฏุฐุงุดุชู ูุฑุขู\n",
            "ุฎู ููููู ุจุงุจุช ุฑุงฺฏุงู ฺฏุฐุงุดุชู ูุฑุขู\n",
            "ุนุงู ุจูุฏ\n",
            "ู ุฑุงฺฏุงู ุจูุฏูุด ููู ุงูุนุงุฏุด ูฺฉูู\n",
            "ุนุงู ุจูุฏ\n",
            "ู ุฑุงฺฏุงู ุจูุฏูุด ููู ุงูุนุงุฏุด ูฺฉูู\n",
            "ุฎู ุฒุจุง ุชุดฺฉุฑ\n",
            "ุฎู ุฒุจุง ุชุดฺฉุฑ\n",
            "ุฎู ุนุงูู ุฎู ุฎู ุนุงูู\n",
            "ุฎู ุนุงูู ุฎู ุฎู ุนุงูู\n",
            "ุจุง ุณูุงู ู ุชุดฺฉุฑ . ุชุฑุฌูู  ุขูุง ุงูู ููุดู ุง ุฑุง ูู ุจุฐุงุฑุฏ.\n",
            "ุจุง ุณูุงู ู ุชุดฺฉุฑ . ุชุฑุฌูู  ุขูุง ุงูู ููุดู ุง ุฑุง ูู ุจุฐุงุฑุฏ.\n",
            "ููููู ุงุฒ ุจุฑูุงูู ุฎูุจุชูู\n",
            "ููููู ุงุฒ ุจุฑูุงูู ุฎูุจุชูู\n",
            "ุจูุงู ูุงู ุญุถุฑุช ุฏูุณุช \n",
            "\n",
            "ูุญู  ูุฒููุง  ุงูุฐฺฉุฑ \n",
            "\n",
            "ุงุณุชุงุฏ  ูุญูุฏ ููุฏ ูููุงุฏููุฏ  ( ุฑู )  ุงุฒ  ุงุณุงุชุฏ  ุนููู ุงููุงุช  ู  ูุฑุขู  ู ุงุฒ  ูุชุฑุฌูุงู  ฺฉุชุงุจ ุฎุฏุง  ู  ฺฉุชุจ ููุฏุณ  ุฏู ุงุณุช. \n",
            "ุงุณุชุงุฏ ูููุงุฏููุฏ  ุบุฑ ุงุฒ ุชุฑุฌูู  ูุฑุขู  ูุฌุฏ  ุ \n",
            "ฺฉุชุงุจ  ููุฌ ุงูุจูุงุบู \n",
            "ุตุญูู  ุณุฌุงุฏู \n",
            "ุฏุนุง ฺฉูู   ุฑุง  ุจู ูุงุฑุณ  ุชุฑุฌูู ฺฉุฑุฏู  ู ุชุฑุฌูู  ุงุดุงู  ุงุฒ \n",
            "ฺฉุชุงุจ ุงููู  ููุฑุฏ  ุชูุฌู  ูุฑุขู  ูพฺููุงู   ู  ูุชุฑุฌูุงู  ุงู  ฺฉุชุงุจ \n",
            "ุขุณูุงู ูุฑุงุฑ ฺฏุฑูุชู ุงุณุช. \n",
            "ุงุณุชุงุฏ  ุจูุงุกุงูุฏู  ุฎุฑูุดุงู ฺฉู ุงุฒ  ุงุณุงุชุฏ ูุณูู  ุฒุจุงู ู ุงุฏุจุงุช ูุงุฑุณ  ู  ุงุฏุจุงุช  ุนุฑุจ  ู  ุงุฒ  ุจุฒุฑฺฏุงู  ุญุงูุธ  ูพฺูู  ู  ูุฑุขู  ูพฺูู ุงุณุช  ู  ุฏุฑ  ุฒููู   ุนููู  ูุฑุงู ุฏุงุฑุง ฺูุฏู ุงุซุฑ   \n",
            "ูุงุฎุฑ  ู  ุงุฑุฒุดููุฏ  ุงุณุช  ู ูุฑูุงุฏ ๏ผ\n",
            "\n",
            "\"  ุจุฏูู   ุงุบุฑุงู ุชุฑุฌูู  ุงุณุชุงุฏ  ูุญูุฏ ููุฏ ูููุงุฏููุฏ  ุงุฒ  ูุฑุขู ูุฌุฏ  ุงุฒ  ุจูุชุฑู  ุชุฑุฌูู  ูุง  ุฒุจุงู  ูุงุฑุณ  ุงุณุช. \"\n",
            "ุงุดุงู  ูุนุชูุฏ ูุฏ  ฺฉู ุชุณูุท ุงุณุชุงุฏ ูููุงุฏููุฏ ุจุฑ  ุฒุจุงู  ุนุฑุจ ู ูุงุฑุณ  ุจุงุนุซ ุดุฏู  ฺฉู  ฺฉ  ูุซุฑ ูุงุฎุฑ ุฑุง ูุจูุง  ุชุฑุฌูู ุฎูุด ูุฑุงุฑ ุฏููุฏ. \n",
            "ุชุฑุฌูู ุง ฺฉู   ูุจูุง ุขู  ุฒุจุงู ูุงุฑุณ ุงูุฑูุฒ ุงุณุช. \n",
            "ุจุทูุฑฺฉู  ุงุดุงู ุงู ุชุฑุฌูู  ุฑุง   ุจุณุงุฑ ุฎูุจ  ุฏุงูุณุชู  ุจู  ฺฏููู ุง ฺฉู  ูู  ุฏุฑ ุขู  ุงูุฑุงุท ฺฏุฑุง  ุฒุจุงู  ูุงุฑุณ  ูุดุงูุฏู  ู ุดูุฏ \n",
            "ู ูู  ูฺฺฏ ูุง  ููุฑุท ุฒุจุงู ุนุฑุจ!! \n",
            "ุงุณุชุงุฏ ุฎุฑูุดุงู  ุงู ุชุฑุฌูู ุฑุง ุงุฒ ุขู  ุฌูุช  ฺฉู ูุธุฑ  ู ุฏุงููุฏ ฺฉู ุฏุฑ  ุขู   ุณูุฑู  ูุง ูฺฉ  ุจุตูุฑุช  ุขููฺฏู  ุชุฑุฌูู ุดุฏู ุงูุฏ. \n",
            "\n",
            "ุงุณุชุงุฏ ฺฉูุดุง ฺฉู ุงุฒ  ุงุณุงุชุฏ   ุจูุงู   ุนููู ูุฑุงู  ู ุงุฒ  ููุชูุฏู  ุชุฑุฌูู ูุง  ูุงุฑุณ  ฺฉุชุงุจ  ูุฑุขู ุงุณุช  ุ ุชุฑุฌูู ุงุณุชุงุฏ ูููุงุฏููุฏ \n",
            "ุงุฒ ูุฑุขู  ุฑุง  ุฌุฒุก ุชุฑุฌูู ูุง ู ุฏุงูุฏ ฺฉู  ุฏุฑุงู  \n",
            "ูุญุชูุงฺฏุฑุง  ูุฏุง  ุชุฑุฌูู   ุชุญุช ุงููุธ ูุดุฏู ุงุณุช!! \n",
            "\n",
            "ูฺฉุชู  ูพุงุงู  ุดฺฉุฑ ู ุณูพุงุณ ุจฺฉุฑุงู  ุงุฒ ุฎุงูู  ูุงุฒุงู  ุงู \n",
            "ูุนุฌุฒู  ุฎุงูุฏู  ู ูพุงูุจุฑ  ุฑุญูุช ุงุณุช  ฺฉู  ุฏุฑ ุฏูุฑุงู ุฑุณุงูุช \n",
            "ุฎูุฏ  ุขู ุฑุง ุจุฑ ุงูุช  ุฎูุงูุฏ  ู ุจุฑุง ุฌูุงูุงู ุจู ุงุฏฺฏุงุฑ ฺฏุฐุงุดุช. \n",
            "\n",
            "ู ุณูพุงุณ ุจฺฉุฑุงู ุงุฒ ูพุงฺฏุงู  ูุฑููฺฏ ุทุงูฺู  ฺฉู ุขูุฑุง  ุจู  ฺฉุงุฑุจุฑุงู \n",
            "ููู ุฎูุด ุงูุฏุง ูููุฏ. \n",
            "\n",
            "ูู ุงููู  ุงูุชููู\n",
            "ุจูุงู ูุงู ุญุถุฑุช ุฏูุณุช \n",
            "\n",
            "ูุญู  ูุฒููุง  ุงูุฐฺฉุฑ \n",
            "\n",
            "ุงุณุชุงุฏ  ูุญูุฏ ููุฏ ูููุงุฏููุฏ  ( ุฑู )  ุงุฒ  ุงุณุงุชุฏ  ุนููู ุงููุงุช  ู  ูุฑุขู  ู ุงุฒ  ูุชุฑุฌูุงู  ฺฉุชุงุจ ุฎุฏุง  ู  ฺฉุชุจ ููุฏุณ  ุฏู ุงุณุช. \n",
            "ุงุณุชุงุฏ ูููุงุฏููุฏ  ุบุฑ ุงุฒ ุชุฑุฌูู  ูุฑุขู  ูุฌุฏ  ุ \n",
            "ฺฉุชุงุจ  ููุฌ ุงูุจูุงุบู \n",
            "ุตุญูู  ุณุฌุงุฏู \n",
            "ุฏุนุง ฺฉูู   ุฑุง  ุจู ูุงุฑุณ  ุชุฑุฌูู ฺฉุฑุฏู  ู ุชุฑุฌูู  ุงุดุงู  ุงุฒ \n",
            "ฺฉุชุงุจ ุงููู  ููุฑุฏ  ุชูุฌู  ูุฑุขู  ูพฺููุงู   ู  ูุชุฑุฌูุงู  ุงู  ฺฉุชุงุจ \n",
            "ุขุณูุงู ูุฑุงุฑ ฺฏุฑูุชู ุงุณุช. \n",
            "ุงุณุชุงุฏ  ุจูุงุกุงูุฏู  ุฎุฑูุดุงู ฺฉู ุงุฒ  ุงุณุงุชุฏ ูุณูู  ุฒุจุงู ู ุงุฏุจุงุช ูุงุฑุณ  ู  ุงุฏุจุงุช  ุนุฑุจ  ู  ุงุฒ  ุจุฒุฑฺฏุงู  ุญุงูุธ  ูพฺูู  ู  ูุฑุขู  ูพฺูู ุงุณุช  ู  ุฏุฑ  ุฒููู   ุนููู  ูุฑุงู ุฏุงุฑุง ฺูุฏู ุงุซุฑ   \n",
            "ูุงุฎุฑ  ู  ุงุฑุฒุดููุฏ  ุงุณุช  ู ูุฑูุงุฏ \n",
            "\n",
            "\"  ุจุฏูู   ุงุบุฑุงู ุชุฑุฌูู  ุงุณุชุงุฏ  ูุญูุฏ ููุฏ ูููุงุฏููุฏ  ุงุฒ  ูุฑุขู ูุฌุฏ  ุงุฒ  ุจูุชุฑู  ุชุฑุฌูู  ูุง  ุฒุจุงู  ูุงุฑุณ  ุงุณุช. \"\n",
            "ุงุดุงู  ูุนุชูุฏ ูุฏ  ฺฉู ุชุณูุท ุงุณุชุงุฏ ูููุงุฏููุฏ ุจุฑ  ุฒุจุงู  ุนุฑุจ ู ูุงุฑุณ  ุจุงุนุซ ุดุฏู  ฺฉู  ฺฉ  ูุซุฑ ูุงุฎุฑ ุฑุง ูุจูุง  ุชุฑุฌูู ุฎูุด ูุฑุงุฑ ุฏููุฏ. \n",
            "ุชุฑุฌูู ุง ฺฉู   ูุจูุง ุขู  ุฒุจุงู ูุงุฑุณ ุงูุฑูุฒ ุงุณุช. \n",
            "ุจุทูุฑฺฉู  ุงุดุงู ุงู ุชุฑุฌูู  ุฑุง   ุจุณุงุฑ ุฎูุจ  ุฏุงูุณุชู  ุจู  ฺฏููู ุง ฺฉู  ูู  ุฏุฑ ุขู  ุงูุฑุงุท ฺฏุฑุง  ุฒุจุงู  ูุงุฑุณ  ูุดุงูุฏู  ู ุดูุฏ \n",
            "ู ูู  ูฺฺฏ ูุง  ููุฑุท ุฒุจุงู ุนุฑุจ!! \n",
            "ุงุณุชุงุฏ ุฎุฑูุดุงู  ุงู ุชุฑุฌูู ุฑุง ุงุฒ ุขู  ุฌูุช  ฺฉู ูุธุฑ  ู ุฏุงููุฏ ฺฉู ุฏุฑ  ุขู   ุณูุฑู  ูุง ูฺฉ  ุจุตูุฑุช  ุขููฺฏู  ุชุฑุฌูู ุดุฏู ุงูุฏ. \n",
            "\n",
            "ุงุณุชุงุฏ ฺฉูุดุง ฺฉู ุงุฒ  ุงุณุงุชุฏ   ุจูุงู   ุนููู ูุฑุงู  ู ุงุฒ  ููุชูุฏู  ุชุฑุฌูู ูุง  ูุงุฑุณ  ฺฉุชุงุจ  ูุฑุขู ุงุณุช  ุ ุชุฑุฌูู ุงุณุชุงุฏ ูููุงุฏููุฏ \n",
            "ุงุฒ ูุฑุขู  ุฑุง  ุฌุฒุก ุชุฑุฌูู ูุง ู ุฏุงูุฏ ฺฉู  ุฏุฑุงู  \n",
            "ูุญุชูุงฺฏุฑุง  ูุฏุง  ุชุฑุฌูู   ุชุญุช ุงููุธ ูุดุฏู ุงุณุช!! \n",
            "\n",
            "ูฺฉุชู  ูพุงุงู  ุดฺฉุฑ ู ุณูพุงุณ ุจฺฉุฑุงู  ุงุฒ ุฎุงูู  ูุงุฒุงู  ุงู \n",
            "ูุนุฌุฒู  ุฎุงูุฏู  ู ูพุงูุจุฑ  ุฑุญูุช ุงุณุช  ฺฉู  ุฏุฑ ุฏูุฑุงู ุฑุณุงูุช \n",
            "ุฎูุฏ  ุขู ุฑุง ุจุฑ ุงูุช  ุฎูุงูุฏ  ู ุจุฑุง ุฌูุงูุงู ุจู ุงุฏฺฏุงุฑ ฺฏุฐุงุดุช. \n",
            "\n",
            "ู ุณูพุงุณ ุจฺฉุฑุงู ุงุฒ ูพุงฺฏุงู  ูุฑููฺฏ ุทุงูฺู  ฺฉู ุขูุฑุง  ุจู  ฺฉุงุฑุจุฑุงู \n",
            "ููู ุฎูุด ุงูุฏุง ูููุฏ. \n",
            "\n",
            "ูู ุงููู  ุงูุชููู\n",
            "mamnon ๐๐\n",
            "mamnon \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCQfM5DmRGG-"
      },
      "source": [
        "**<font color=red> Cleaning is the final step in this section. Your cleaned method should be included these steps:</font>**\n",
        "\n",
        "**<font color=red>- fixing unicodes</font>**\n",
        "\n",
        "**<font color=red>- removing specials like a phone number, email, url, new lines, ...</font>**\n",
        "\n",
        "**<font color=red>- cleaning HTMLs</font>**\n",
        "\n",
        "**<font color=red>- normalizing</font>**\n",
        "\n",
        "**<font color=red>- removing emojis</font>**\n",
        "\n",
        "**<font color=red>- removing extra spaces, hashtags</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CRX3CZT6REFh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7107792-c8b7-4037-e37c-d665fd2f1687"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting hazm\n",
            "  Downloading hazm-0.7.0-py3-none-any.whl (316 kB)\n",
            "\u001b[K     |โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ| 316 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting libwapiti>=0.2.1\n",
            "  Downloading libwapiti-0.2.1.tar.gz (233 kB)\n",
            "\u001b[K     |โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ| 233 kB 46.4 MB/s \n",
            "\u001b[?25hCollecting nltk==3.3\n",
            "  Downloading nltk-3.3.0.zip (1.4 MB)\n",
            "\u001b[K     |โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ| 1.4 MB 39.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.3->hazm) (1.15.0)\n",
            "Building wheels for collected packages: nltk, libwapiti\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.3-py3-none-any.whl size=1394489 sha256=129df1e822745e01ca10f82cd3bc071a1cacc8977fba53e4d5207830e9a87b18\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/fd/0c/d92302c876e5de87ebd7fc0979d82edb93e2d8d768bf71fac4\n",
            "  Building wheel for libwapiti (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libwapiti: filename=libwapiti-0.2.1-cp37-cp37m-linux_x86_64.whl size=154994 sha256=bcbc8399d5c96a95134805fda773a62dfd4530adf8f8df22026141964bdf8dcc\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/b2/5b/0fe4b8f5c0e65341e8ea7bb3f4a6ebabfe8b1ac31322392dbf\n",
            "Successfully built nltk libwapiti\n",
            "Installing collected packages: nltk, libwapiti, hazm\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.7\n",
            "    Uninstalling nltk-3.7:\n",
            "      Successfully uninstalled nltk-3.7\n",
            "Successfully installed hazm-0.7.0 libwapiti-0.2.1 nltk-3.3\n",
            "\u001b[K     |โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ| 4.2 MB 5.3 MB/s \n",
            "\u001b[K     |โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ| 86 kB 6.2 MB/s \n",
            "\u001b[K     |โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ| 596 kB 48.8 MB/s \n",
            "\u001b[K     |โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ| 6.6 MB 48.1 MB/s \n",
            "\u001b[K     |โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ| 53 kB 1.6 MB/s \n",
            "\u001b[K     |โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ| 175 kB 10.4 MB/s \n",
            "\u001b[K     |โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ| 235 kB 56.0 MB/s \n",
            "\u001b[?25h  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install hazm\n",
        "!pip install -q transformers\n",
        "!pip install -q hazm\n",
        "!pip install -q clean-text[gpl]\n",
        "\n",
        "import hazm\n",
        "from cleantext import clean\n",
        "\n",
        "def cleaning(text):\n",
        "    text = text.strip()\n",
        "\n",
        "    ##############################################################################################\n",
        "    #                                       Your Code                                            #\n",
        "    ##############################################################################################\n",
        "    # regular cleaning\n",
        "    text = clean(text,\n",
        "        fix_unicode=True,\n",
        "        to_ascii=False,\n",
        "        lower=True,\n",
        "        no_line_breaks=True,\n",
        "        no_urls=True,\n",
        "        no_emails=True,\n",
        "        no_phone_numbers=True,\n",
        "        no_numbers=False,\n",
        "        no_digits=False,\n",
        "        no_currency_symbols=True,\n",
        "        no_punct=False,\n",
        "        replace_with_url=\"\",\n",
        "        replace_with_email=\"\",\n",
        "        replace_with_phone_number=\"\",\n",
        "        replace_with_number=\"\",\n",
        "        replace_with_digit=\"0\",\n",
        "        replace_with_currency_symbol=\"\",\n",
        "    )\n",
        "\n",
        "    # cleaning htmls\n",
        "\n",
        "    cleanr = re.compile('<.*?>')\n",
        "    text = re.sub(cleanr, '', text)\n",
        "    \n",
        "    # normalizing\n",
        "\n",
        "\n",
        "    normalizer = hazm.Normalizer()\n",
        "    text = normalizer.normalize(text)\n",
        "    \n",
        "    # removing wierd patterns\n",
        "    wierd_pattern = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "        u\"\\U0001f926-\\U0001f937\"\n",
        "        u'\\U00010000-\\U0010ffff'\n",
        "        u\"\\u200d\"\n",
        "        u\"\\u2640-\\u2642\"\n",
        "        u\"\\u2600-\\u2B55\"\n",
        "        u\"\\u23cf\"\n",
        "        u\"\\u23e9\"\n",
        "        u\"\\u231a\"\n",
        "        u\"\\u3030\"\n",
        "        u\"\\ufe0f\"\n",
        "        u\"\\u2069\"\n",
        "        u\"\\u2066\"\n",
        "        # u\"\\u200c\"\n",
        "        u\"\\u2068\"\n",
        "        u\"\\u2067\"\n",
        "        \"]+\", flags=re.UNICODE)\n",
        "    \n",
        "    text = wierd_pattern.sub(r'', text)\n",
        "    \n",
        "    # removing extra spaces, hashtags\n",
        "    text = re.sub(\"#\", \"\", text)\n",
        "    text = re.sub(\"\\s+\", \" \", text)\n",
        "    \n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "681o2WMERHbJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# cleaning comments\n",
        "data['cleaned_comment'] = data['comment'].apply(cleaning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asSwiNKxPaAz"
      },
      "source": [
        "**<font color=red> Calculate the Length of Comments based on their Words</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ioFL5_1MQzIb"
      },
      "outputs": [],
      "source": [
        "##############################################################################################\n",
        "#                                       Your Code                                            #\n",
        "##############################################################################################\n",
        "data['cleaned_comment_len_by_words'] = data['cleaned_comment'].apply(lambda t: len(hazm.word_tokenize(t)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDwxjxkJPpyY"
      },
      "source": [
        "**<font color=red> Remove Comments with the Length of Fewer than 3 Words & More than 256 Words</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "kliWRX7-3U1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "0ae193c5-566b-45cb-8669-a1a3fdae8c68"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             comment  rate  \\\n",
              "0  ุงุณู ฺฉุชุงุจ   No one writes to the Colonel\\nุชุฑุฌูุด...     0   \n",
              "1  ุทุงูฺู ุนุฒุฒุูุงู ฺฉุชุงุจ\"ฺฉุณ ุจู ุณุฑููฺฏ ูุงูู ููููุณุฏ...     5   \n",
              "2  ุจูุธุฑู ุงู ุงุซุฑ ูุงุฑฺฉุฒ ุฎู ุงุฒ ุตุฏ ุณุงู ุชููุง ฺฉู ุจ...     5   \n",
              "3  ุจู ูุธุฑ ฺฉุชุงุจ ุฎูุจ ูููุฏ ุงูุง ูู ุงุฒ ุชุฑุฌูุด ุฎูุดู ู...     2   \n",
              "4                                      ฺฉุชุงุจ ุฎูุจ ุงุณุช     3   \n",
              "\n",
              "                                     cleaned_comment  \\\n",
              "0  ุงุณู ฺฉุชุงุจ no one writes to the colonel ุชุฑุฌูุด ู...   \n",
              "1  ุทุงูฺู ุนุฒุฒุ ูุงู ฺฉุชุงุจ ยซฺฉุณ ุจู ุณุฑููฺฏ ูุงูู ูููู...   \n",
              "2  ุจูุธุฑู ุงู ุงุซุฑ ูุงุฑฺฉุฒ ุฎู ุงุฒ ุตุฏ ุณุงู ุชููุง ฺฉู ุจ...   \n",
              "3  ุจู ูุธุฑ ฺฉุชุงุจ ุฎูุจ ูููุฏ ุงูุง ูู ุงุฒ ุชุฑุฌูุด ุฎูุดู ู...   \n",
              "4                                      ฺฉุชุงุจ ุฎูุจ ุงุณุช   \n",
              "\n",
              "   cleaned_comment_len_by_words  \n",
              "0                            47  \n",
              "1                            20  \n",
              "2                            45  \n",
              "3                            20  \n",
              "4                             3  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2cc5e470-cc20-4e4d-ab4e-acb6f46198f8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>rate</th>\n",
              "      <th>cleaned_comment</th>\n",
              "      <th>cleaned_comment_len_by_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ุงุณู ฺฉุชุงุจ   No one writes to the Colonel\\nุชุฑุฌูุด...</td>\n",
              "      <td>0</td>\n",
              "      <td>ุงุณู ฺฉุชุงุจ no one writes to the colonel ุชุฑุฌูุด ู...</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ุทุงูฺู ุนุฒุฒุูุงู ฺฉุชุงุจ\"ฺฉุณ ุจู ุณุฑููฺฏ ูุงูู ููููุณุฏ...</td>\n",
              "      <td>5</td>\n",
              "      <td>ุทุงูฺู ุนุฒุฒุ ูุงู ฺฉุชุงุจ ยซฺฉุณ ุจู ุณุฑููฺฏ ูุงูู ูููู...</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ุจูุธุฑู ุงู ุงุซุฑ ูุงุฑฺฉุฒ ุฎู ุงุฒ ุตุฏ ุณุงู ุชููุง ฺฉู ุจ...</td>\n",
              "      <td>5</td>\n",
              "      <td>ุจูุธุฑู ุงู ุงุซุฑ ูุงุฑฺฉุฒ ุฎู ุงุฒ ุตุฏ ุณุงู ุชููุง ฺฉู ุจ...</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ุจู ูุธุฑ ฺฉุชุงุจ ุฎูุจ ูููุฏ ุงูุง ูู ุงุฒ ุชุฑุฌูุด ุฎูุดู ู...</td>\n",
              "      <td>2</td>\n",
              "      <td>ุจู ูุธุฑ ฺฉุชุงุจ ุฎูุจ ูููุฏ ุงูุง ูู ุงุฒ ุชุฑุฌูุด ุฎูุดู ู...</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ฺฉุชุงุจ ุฎูุจ ุงุณุช</td>\n",
              "      <td>3</td>\n",
              "      <td>ฺฉุชุงุจ ุฎูุจ ุงุณุช</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2cc5e470-cc20-4e4d-ab4e-acb6f46198f8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2cc5e470-cc20-4e4d-ab4e-acb6f46198f8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2cc5e470-cc20-4e4d-ab4e-acb6f46198f8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "##############################################################################################\n",
        "#                                       Your Code                                            #\n",
        "##############################################################################################\n",
        "minlim = 3\n",
        "maxlim = 256\n",
        "# remove comments with the length of fewer than three words\n",
        "data['cleaned_comment_len_by_words'] = data['cleaned_comment_len_by_words'].apply(lambda len_t: len_t if minlim < len_t <= maxlim else len_t)\n",
        "data = data.dropna(subset=['cleaned_comment_len_by_words'])\n",
        "data = data.reset_index(drop=True)\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rate_to_label(rate, threshold=3.0):\n",
        "    if rate <= threshold:\n",
        "        return \"0\"\n",
        "    else:\n",
        "        return \"1\"\n",
        "\n",
        "\n",
        "data['label'] = data['rate'].apply(lambda t: rate_to_label(t, 3.0))\n",
        "labels = list(sorted(data['label'].unique()))\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "xHjWUqk_GKGS",
        "outputId": "7a26c892-3a5e-4a7c-fa35-41a91e2306c1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             comment  rate  \\\n",
              "0  ุงุณู ฺฉุชุงุจ   No one writes to the Colonel\\nุชุฑุฌูุด...     0   \n",
              "1  ุทุงูฺู ุนุฒุฒุูุงู ฺฉุชุงุจ\"ฺฉุณ ุจู ุณุฑููฺฏ ูุงูู ููููุณุฏ...     5   \n",
              "2  ุจูุธุฑู ุงู ุงุซุฑ ูุงุฑฺฉุฒ ุฎู ุงุฒ ุตุฏ ุณุงู ุชููุง ฺฉู ุจ...     5   \n",
              "3  ุจู ูุธุฑ ฺฉุชุงุจ ุฎูุจ ูููุฏ ุงูุง ูู ุงุฒ ุชุฑุฌูุด ุฎูุดู ู...     2   \n",
              "4                                      ฺฉุชุงุจ ุฎูุจ ุงุณุช     3   \n",
              "\n",
              "                                     cleaned_comment  \\\n",
              "0  ุงุณู ฺฉุชุงุจ no one writes to the colonel ุชุฑุฌูุด ู...   \n",
              "1  ุทุงูฺู ุนุฒุฒุ ูุงู ฺฉุชุงุจ ยซฺฉุณ ุจู ุณุฑููฺฏ ูุงูู ูููู...   \n",
              "2  ุจูุธุฑู ุงู ุงุซุฑ ูุงุฑฺฉุฒ ุฎู ุงุฒ ุตุฏ ุณุงู ุชููุง ฺฉู ุจ...   \n",
              "3  ุจู ูุธุฑ ฺฉุชุงุจ ุฎูุจ ูููุฏ ุงูุง ูู ุงุฒ ุชุฑุฌูุด ุฎูุดู ู...   \n",
              "4                                      ฺฉุชุงุจ ุฎูุจ ุงุณุช   \n",
              "\n",
              "   cleaned_comment_len_by_words label  \n",
              "0                            47     0  \n",
              "1                            20     1  \n",
              "2                            45     1  \n",
              "3                            20     0  \n",
              "4                             3     0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6aba810a-1c83-4196-9c4f-668ee6e69c48\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>rate</th>\n",
              "      <th>cleaned_comment</th>\n",
              "      <th>cleaned_comment_len_by_words</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ุงุณู ฺฉุชุงุจ   No one writes to the Colonel\\nุชุฑุฌูุด...</td>\n",
              "      <td>0</td>\n",
              "      <td>ุงุณู ฺฉุชุงุจ no one writes to the colonel ุชุฑุฌูุด ู...</td>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ุทุงูฺู ุนุฒุฒุูุงู ฺฉุชุงุจ\"ฺฉุณ ุจู ุณุฑููฺฏ ูุงูู ููููุณุฏ...</td>\n",
              "      <td>5</td>\n",
              "      <td>ุทุงูฺู ุนุฒุฒุ ูุงู ฺฉุชุงุจ ยซฺฉุณ ุจู ุณุฑููฺฏ ูุงูู ูููู...</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ุจูุธุฑู ุงู ุงุซุฑ ูุงุฑฺฉุฒ ุฎู ุงุฒ ุตุฏ ุณุงู ุชููุง ฺฉู ุจ...</td>\n",
              "      <td>5</td>\n",
              "      <td>ุจูุธุฑู ุงู ุงุซุฑ ูุงุฑฺฉุฒ ุฎู ุงุฒ ุตุฏ ุณุงู ุชููุง ฺฉู ุจ...</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ุจู ูุธุฑ ฺฉุชุงุจ ุฎูุจ ูููุฏ ุงูุง ูู ุงุฒ ุชุฑุฌูุด ุฎูุดู ู...</td>\n",
              "      <td>2</td>\n",
              "      <td>ุจู ูุธุฑ ฺฉุชุงุจ ุฎูุจ ูููุฏ ุงูุง ูู ุงุฒ ุชุฑุฌูุด ุฎูุดู ู...</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ฺฉุชุงุจ ุฎูุจ ุงุณุช</td>\n",
              "      <td>3</td>\n",
              "      <td>ฺฉุชุงุจ ุฎูุจ ุงุณุช</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6aba810a-1c83-4196-9c4f-668ee6e69c48')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6aba810a-1c83-4196-9c4f-668ee6e69c48 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6aba810a-1c83-4196-9c4f-668ee6e69c48');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "GlBnHyl0RIzx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "463facf6-4f63-4d4c-83e9-568945bb39a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             comment label\n",
              "0  ุงุณู ฺฉุชุงุจ no one writes to the colonel ุชุฑุฌูุด ู...     0\n",
              "1  ุทุงูฺู ุนุฒุฒุ ูุงู ฺฉุชุงุจ ยซฺฉุณ ุจู ุณุฑููฺฏ ูุงูู ูููู...     1\n",
              "2  ุจูุธุฑู ุงู ุงุซุฑ ูุงุฑฺฉุฒ ุฎู ุงุฒ ุตุฏ ุณุงู ุชููุง ฺฉู ุจ...     1\n",
              "3  ุจู ูุธุฑ ฺฉุชุงุจ ุฎูุจ ูููุฏ ุงูุง ูู ุงุฒ ุชุฑุฌูุด ุฎูุดู ู...     0\n",
              "4                                      ฺฉุชุงุจ ุฎูุจ ุงุณุช     0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ab8c5224-0346-4be1-be4c-bf1b92ec17d8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ุงุณู ฺฉุชุงุจ no one writes to the colonel ุชุฑุฌูุด ู...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ุทุงูฺู ุนุฒุฒุ ูุงู ฺฉุชุงุจ ยซฺฉุณ ุจู ุณุฑููฺฏ ูุงูู ูููู...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ุจูุธุฑู ุงู ุงุซุฑ ูุงุฑฺฉุฒ ุฎู ุงุฒ ุตุฏ ุณุงู ุชููุง ฺฉู ุจ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ุจู ูุธุฑ ฺฉุชุงุจ ุฎูุจ ูููุฏ ุงูุง ูู ุงุฒ ุชุฑุฌูุด ุฎูุดู ู...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ฺฉุชุงุจ ุฎูุจ ุงุณุช</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab8c5224-0346-4be1-be4c-bf1b92ec17d8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ab8c5224-0346-4be1-be4c-bf1b92ec17d8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ab8c5224-0346-4be1-be4c-bf1b92ec17d8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "data = data[['cleaned_comment', 'label']]\n",
        "data.columns = ['comment', 'label']\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ny0D77atzqWT"
      },
      "source": [
        "### Handling Unbalanced Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Q0yEPxd-tb-"
      },
      "source": [
        "**<font color=red> Because the Data is Unbalanced, You should Balance it. Before & After Balancing Data, You should Plot a Bar Chart of Distribution of label within comments [DATA]</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "8rhzPbMURPyK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "48803821-7eca-44f7-c8a6-d20e0e7d7368"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"397ebdae-3283-4836-91f6-e0fbafda3f3a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"397ebdae-3283-4836-91f6-e0fbafda3f3a\")) {                    Plotly.newPlot(                        \"397ebdae-3283-4836-91f6-e0fbafda3f3a\",                        [{\"text\":[\"1246\",\"3419\"],\"textposition\":\"auto\",\"x\":[\"0\",\"1\"],\"y\":[1246,3419],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Distribution of label within comments [DATA]\"},\"xaxis\":{\"title\":{\"text\":\"Label\"}},\"yaxis\":{\"title\":{\"text\":\"Frequency\"}},\"bargap\":0.2,\"bargroupgap\":0.2},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('397ebdae-3283-4836-91f6-e0fbafda3f3a');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "##############################################################################################\n",
        "#                                       Your Code                                            #\n",
        "##############################################################################################\n",
        "fig = go.Figure()\n",
        "\n",
        "groupby_label = data.groupby('label')['label'].count()\n",
        "\n",
        "fig.add_trace(go.Bar(\n",
        "    x=list(sorted(groupby_label.index)),\n",
        "    y=groupby_label.tolist(),\n",
        "    text=groupby_label.tolist(),\n",
        "    textposition='auto'\n",
        "))\n",
        "\n",
        "fig.update_layout(\n",
        "    title_text='Distribution of label within comments [DATA]',\n",
        "    xaxis_title_text='Label',\n",
        "    yaxis_title_text='Frequency',\n",
        "    bargap=0.2,\n",
        "    bargroupgap=0.2)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "negative_data = data[data['label'] == \"0\"]\n",
        "positive_data = data[data['label'] == \"1\"]\n",
        "\n",
        "cutting_point = min(len(negative_data), len(positive_data))\n",
        "\n",
        "if cutting_point <= len(negative_data):\n",
        "    negative_data = negative_data.sample(n=cutting_point).reset_index(drop=True)\n",
        "\n",
        "if cutting_point <= len(positive_data):\n",
        "    positive_data = positive_data.sample(n=cutting_point).reset_index(drop=True)\n",
        "\n",
        "new_data = pd.concat([negative_data, positive_data])\n",
        "new_data = new_data.sample(frac=1).reset_index(drop=True)\n",
        "new_data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwtZY3lHHoYm",
        "outputId": "674db289-00da-42c6-d4f2-d7e12b25ffaf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2492 entries, 0 to 2491\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   comment  2492 non-null   object\n",
            " 1   label    2492 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 39.1+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure()\n",
        "\n",
        "groupby_label = new_data.groupby('label')['label'].count()\n",
        "\n",
        "fig.add_trace(go.Bar(\n",
        "    x=list(sorted(groupby_label.index)),\n",
        "    y=groupby_label.tolist(),\n",
        "    text=groupby_label.tolist(),\n",
        "    textposition='auto'\n",
        "))\n",
        "\n",
        "fig.update_layout(\n",
        "    title_text='Distribution of label within comments [NEW DATA]',\n",
        "    xaxis_title_text='Label',\n",
        "    yaxis_title_text='Frequency',\n",
        "    bargap=0.2,\n",
        "    bargroupgap=0.2)\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "7N2l1DiRH6zm",
        "outputId": "76bc005d-1d14-4889-bf57-1dca8e1099ce"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"fe1c622d-d404-497e-9cda-1647361619f8\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"fe1c622d-d404-497e-9cda-1647361619f8\")) {                    Plotly.newPlot(                        \"fe1c622d-d404-497e-9cda-1647361619f8\",                        [{\"text\":[\"1246\",\"1246\"],\"textposition\":\"auto\",\"x\":[\"0\",\"1\"],\"y\":[1246,1246],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Distribution of label within comments [NEW DATA]\"},\"xaxis\":{\"title\":{\"text\":\"Label\"}},\"yaxis\":{\"title\":{\"text\":\"Frequency\"}},\"bargap\":0.2,\"bargroupgap\":0.2},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('fe1c622d-d404-497e-9cda-1647361619f8');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpLObddZROJm"
      },
      "source": [
        "## Train,Validation,Test split\n",
        "\n",
        "To achieve a globalized model, we need to split the cleaned dataset into train, valid, test sets due to size of the data. In this tutorial, I have considered a rate of **0.1** for both *valid*, *test* sets. For splitting, I use `train_test_split` provided by Sklearn package with stratifying on the label for preserving the distribution balance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "DR_4CTGERLyw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "561201c7-b2e9-45c8-e4c2-0947890438dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2017, 3)\n",
            "(225, 3)\n",
            "(250, 3)\n"
          ]
        }
      ],
      "source": [
        "new_data['label_id'] = new_data['label'].apply(lambda t: labels.index(t))\n",
        "\n",
        "train, test = train_test_split(new_data, test_size=0.1, random_state=1, stratify=new_data['label'])\n",
        "train, valid = train_test_split(train, test_size=0.1, random_state=1, stratify=train['label'])\n",
        "\n",
        "train = train.reset_index(drop=True)\n",
        "valid = valid.reset_index(drop=True)\n",
        "test = test.reset_index(drop=True)\n",
        "\n",
        "x_train, y_train = train['comment'].values.tolist(), train['label_id'].values.tolist()\n",
        "x_valid, y_valid = valid['comment'].values.tolist(), valid['label_id'].values.tolist()\n",
        "x_test, y_test = test['comment'].values.tolist(), test['label_id'].values.tolist()\n",
        "\n",
        "print(train.shape)\n",
        "print(valid.shape)\n",
        "print(test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17sghNPPRaOz"
      },
      "source": [
        "![BERT INPUTS](https://res.cloudinary.com/m3hrdadfi/image/upload/v1595158991/kaggle/bert_inputs_w8rith.png)\n",
        "\n",
        "As you may know, the BERT model input is a combination of 3 embeddings.\n",
        "- Token embeddings: WordPiece token vocabulary (WordPiece is another word segmentation algorithm, similar to BPE)\n",
        "- Segment embeddings: for pair sentences [A-B] marked as $E_A$ or $E_B$ mean that it belongs to the first sentence or the second one.\n",
        "- Position embeddings: specify the position of words in a sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mk-T5EvIRc6t"
      },
      "source": [
        "## PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "LjfRss-DR3fu"
      },
      "outputs": [],
      "source": [
        "# Import required packages (If You Need Any More Packages, You Can Add them HERE.)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SperdZDDWKxT"
      },
      "source": [
        "### Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "WFpUoggdpU3x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75f946fb-1b3c-4289-8005-6c3df4ea8cda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda:0\n",
            "CUDA is available!  Training on GPU ...\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'device: {device}')\n",
        "\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "mH38OJU0X7rd"
      },
      "outputs": [],
      "source": [
        "# general config\n",
        "MAX_LEN = 128\n",
        "TRAIN_BATCH_SIZE = 16\n",
        "VALID_BATCH_SIZE = 16\n",
        "TEST_BATCH_SIZE = 16\n",
        "\n",
        "EPOCHS = 10\n",
        "EEVERY_EPOCH = 1000\n",
        "LEARNING_RATE = 2e-5\n",
        "CLIP = 0.0\n",
        "\n",
        "OUTPUT_PATH = '/content/bert-fa-base-uncased-sentiment-taaghceh/pytorch_model.bin'\n",
        "\n",
        "os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "qK02AC0pYIPj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1b24033-8639-496d-e167-52a82567a438"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label2id: {'0': 0, '1': 1}\n",
            "id2label: {0: '0', 1: '1'}\n"
          ]
        }
      ],
      "source": [
        "# create a key finder based on label 2 id and id to label\n",
        "\n",
        "label2id = {label: i for i, label in enumerate(labels)}\n",
        "id2label = {v: k for k, v in label2id.items()}\n",
        "\n",
        "print(f'label2id: {label2id}')\n",
        "print(f'id2label: {id2label}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBjLAydrU8jN"
      },
      "source": [
        "**<font color=red> Setup the Tokenizer and Configuration</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "qGJRNBXFYOcx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637,
          "referenced_widgets": [
            "499f74de07764d43a4164df19b1a0ccf",
            "f125474f707f48a589eb3d21da4a95f2",
            "43eff8ce43dd4056b7898a22179aa812",
            "e6bc9ed89a274f88bdbf192d3e2eaddb",
            "04e5a3fce56b4ca09f3e2b3af8067623",
            "5a5bb13585944ef69718c9f3b7fad322",
            "c942290c8bd14ec6b8644a83504b2aa2",
            "12a3210bbb864414ae7cb9d3361351e3",
            "42cc91115efa47e6bf6121e1e1550731",
            "8a4d0d26defe40f5b06ee4f901289647",
            "bd891371cd304c81a62be55c2f388a6c",
            "3ff4ae5966814bc89dc823fdda0f7ce6",
            "1d8080f487384783a2aec63391331610",
            "09f8f12214bb4675800dbfee6cd2038c",
            "33ec7bccf44d40e195b90861f561bd4b",
            "b6da6ffdece54ea69fff9929fdf467ad",
            "bf2995046fad4709ac48cbcc42d1c394",
            "7d87c212aa1c48c3b666af39e794547c",
            "2939d19010ba4caeb56e973373bfc80f",
            "a61c30e0a3a64185939b9fa537355712",
            "36bc92e1736a48faa3174c5ba6994c10",
            "a44e0a294e7648fa995c326f66950342"
          ]
        },
        "outputId": "c4338e08-3f01-4471-8213-466307f68f89"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.14M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "499f74de07764d43a4164df19b1a0ccf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/440 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ff4ae5966814bc89dc823fdda0f7ce6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"0\",\n",
            "    \"1\": \"1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"0\": 0,\n",
            "    \"1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.19.4\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 100000\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "##############################################################################################\n",
        "#                                       Your Code                                            #\n",
        "##############################################################################################\n",
        "MODEL_NAME_OR_PATH = 'HooshvareLab/bert-fa-base-uncased'\n",
        "from transformers import BertConfig, BertTokenizer\n",
        "from transformers import BertModel\n",
        "\n",
        "from transformers import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME_OR_PATH)\n",
        "config = BertConfig.from_pretrained(\n",
        "    MODEL_NAME_OR_PATH, **{\n",
        "        'label2id': label2id,\n",
        "        'id2label': id2label,\n",
        "    })\n",
        "\n",
        "print(config.to_json_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr9L9N91gSpm"
      },
      "source": [
        "### Input Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pr8cRm9xiyKh"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "TaJBSSuMizgr"
      },
      "outputs": [],
      "source": [
        "class TaaghcheDataset(torch.utils.data.Dataset):\n",
        "    \"\"\" Create a PyTorch dataset for Taaghche. \"\"\"\n",
        "\n",
        "    def __init__(self, tokenizer, comments, targets=None, label_list=None, max_len=128):\n",
        "        self.comments = comments\n",
        "        self.targets = targets\n",
        "        self.has_target = isinstance(targets, list) or isinstance(targets, np.ndarray)\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "        \n",
        "        self.label_map = {label: i for i, label in enumerate(label_list)} if isinstance(label_list, list) else {}\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.comments)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        comment = str(self.comments[item])\n",
        "\n",
        "        if self.has_target:\n",
        "            target = self.label_map.get(str(self.targets[item]), str(self.targets[item]))\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            comment,\n",
        "            add_special_tokens=True,\n",
        "            truncation=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=True,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt')\n",
        "        \n",
        "        inputs = {\n",
        "            'comment': comment,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'token_type_ids': encoding['token_type_ids'].flatten(),\n",
        "        }\n",
        "\n",
        "        if self.has_target:\n",
        "            inputs['targets'] = torch.tensor(target, dtype=torch.long)\n",
        "        \n",
        "        return inputs\n",
        "\n",
        "\n",
        "def create_data_loader(x, y, tokenizer, max_len, batch_size, label_list):\n",
        "    dataset = TaaghcheDataset(\n",
        "        comments=x,\n",
        "        targets=y,\n",
        "        tokenizer=tokenizer,\n",
        "        max_len=max_len, \n",
        "        label_list=label_list)\n",
        "    \n",
        "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "JEcefj6fkZFl"
      },
      "outputs": [],
      "source": [
        "label_list = ['0', '1']\n",
        "train_data_loader = create_data_loader(train['comment'].to_numpy(), train['label'].to_numpy(), tokenizer, MAX_LEN, TRAIN_BATCH_SIZE, label_list)\n",
        "valid_data_loader = create_data_loader(valid['comment'].to_numpy(), valid['label'].to_numpy(), tokenizer, MAX_LEN, VALID_BATCH_SIZE, label_list)\n",
        "test_data_loader = create_data_loader(test['comment'].to_numpy(), None, tokenizer, MAX_LEN, TEST_BATCH_SIZE, label_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doP5OE1OWP38"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqhHjIUQYq3Y"
      },
      "source": [
        "**<font color=red> Complete forward function</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Mv75ARn_R_Dt"
      },
      "outputs": [],
      "source": [
        "class SentimentModel(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super(SentimentModel, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained(MODEL_NAME_OR_PATH)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
        "    \n",
        "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "        ##############################################################################################\n",
        "        #                                       Your Code                                            #\n",
        "        ##############################################################################################\n",
        "        # print(input_ids)\n",
        "        _, pooled_output = self.bert(\n",
        "            input_ids=input_ids, \n",
        "            attention_mask=attention_mask, \n",
        "            token_type_ids=token_type_ids, return_dict=False)\n",
        "        \n",
        "        print(type(pooled_output))\n",
        "        # pooled_output = torch.as_tensor(pooled_output)\n",
        "        # pooled_output = self.dropout(pooled_output)\n",
        "        print(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "VrObbZAdNTNl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a63f1666-3684-42ac-fd14-dc2c639d2956"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jun 14 18:33:23 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P8    11W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "import torch, gc\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "pt_model = None\n",
        "\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "7vzQGZGUmw3-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "1b37ce85d0ba4f74a75d65deb066614a",
            "999dd428264d447093b79a430cf006a9",
            "fa84b3deee9a449499955067e565cf48",
            "376d97cf555949e2847ba49c741aff5d",
            "1ee8ce0c6edd402f8b0d4a96fe8466e9",
            "d894ebbcafd14e2a957365a250eb6a54",
            "73f690b312e142a9ba59fff9adefc5b7",
            "1258cddfc7244ad8b472519a1518ed5c",
            "09839934638340d09ffaa0e1876b7656",
            "67b127d30cc843bf9274617c948e3d3f",
            "ad4641dc3143436cbdd6f64bfe65626a"
          ]
        },
        "outputId": "b603a1ce-c0bb-42e1-c5a8-4dd8ba974150"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/624M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b37ce85d0ba4f74a75d65deb066614a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at HooshvareLab/bert-fa-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pt_model <class '__main__.SentimentModel'>\n"
          ]
        }
      ],
      "source": [
        "pt_model = SentimentModel(config=config)\n",
        "pt_model = pt_model.to(device)\n",
        "\n",
        "print('pt_model', type(pt_model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFZQDfLlp0Sf"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f8_XjYbcdUv"
      },
      "source": [
        "**<font color=red> Complete functions</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "e044fZSfBoKe"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "def acc_and_f1(y_true, y_pred, average='weighted'):\n",
        "    # Define Accuracy and F1-score\n",
        "    ##############################################################################################\n",
        "    #                                       Your Code                                            #\n",
        "    ##############################################################################################\n",
        "    acc = (y_true == y_pred).mean()\n",
        "    f1 = f1_score(y_true=y_true, y_pred=y_pred, average=average)\n",
        "    return {\n",
        "        \"acc\": acc,\n",
        "        \"f1\": f1,\n",
        "    }\n",
        "\n",
        "def y_loss(y_true, y_pred, losses):\n",
        "    y_true = torch.stack(y_true).cpu().detach().numpy()\n",
        "    y_pred = torch.stack(y_pred).cpu().detach().numpy()\n",
        "    y = [y_true, y_pred]\n",
        "    loss = np.mean(losses)\n",
        "\n",
        "    return y, loss\n",
        "\n",
        "\n",
        "def eval_op(model, data_loader, loss_fn):\n",
        "    model.eval()\n",
        "\n",
        "    losses = []\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for dl in tqdm(data_loader, total=len(data_loader), desc=\"Evaluation... \"):\n",
        "\n",
        "            # Define input_ids, attention_mask, token_type_ids, targets\n",
        "            ##############################################################################################\n",
        "            #                                       Your Code                                            #\n",
        "            ##############################################################################################\n",
        "            input_ids = dl['input_ids']\n",
        "            attention_mask = dl['attention_mask']\n",
        "            token_type_ids = dl['token_type_ids']\n",
        "            targets = dl['targets']\n",
        "\n",
        "            # move tensors to GPU if CUDA is available\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            token_type_ids = token_type_ids.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            # compute predicted outputs by passing inputs to the model\n",
        "            ##############################################################################################\n",
        "            #                                       Your Code                                            #\n",
        "            ##############################################################################################\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                token_type_ids=token_type_ids)\n",
        "            \n",
        "            # convert output probabilities to predicted class\n",
        "            ##############################################################################################\n",
        "            #                                       Your Code                                            #\n",
        "            ##############################################################################################\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "            # calculate the batch loss\n",
        "            ##############################################################################################\n",
        "            #                                       Your Code                                            #\n",
        "            ##############################################################################################\n",
        "            loss = loss_fn(outputs, targets)\n",
        "\n",
        "            # accumulate all the losses\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            y_pred.extend(preds)\n",
        "            y_true.extend(targets)\n",
        "    \n",
        "    eval_y, eval_loss = y_loss(y_true, y_pred, losses)\n",
        "    return eval_y, eval_loss\n",
        "\n",
        "\n",
        "def train_op(model, \n",
        "             data_loader, \n",
        "             loss_fn, \n",
        "             optimizer, \n",
        "             scheduler, \n",
        "             step=0, \n",
        "             print_every_step=100, \n",
        "             eval=False,\n",
        "             eval_cb=None,\n",
        "             eval_loss_min=np.Inf,\n",
        "             eval_data_loader=None, \n",
        "             clip=0.0):\n",
        "    \n",
        "    model.train()\n",
        "\n",
        "    losses = []\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "\n",
        "    for dl in tqdm(data_loader, total=len(data_loader), desc=\"Training... \"):\n",
        "        step += 1\n",
        "\n",
        "        # Define input_ids, attention_mask, token_type_ids, targets\n",
        "        ##############################################################################################\n",
        "        #                                       Your Code                                            #\n",
        "        ##############################################################################################\n",
        "        input_ids = dl['input_ids']\n",
        "        attention_mask = dl['attention_mask']\n",
        "        token_type_ids = dl['token_type_ids']\n",
        "        targets = dl['targets']\n",
        "\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "        token_type_ids = token_type_ids.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        # clear the gradients of all optimized variables\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # compute predicted outputs by passing inputs to the model\n",
        "        ##############################################################################################\n",
        "        #                                       Your Code                                            #\n",
        "        ##############################################################################################\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids)\n",
        "        \n",
        "        # convert output probabilities to predicted class\n",
        "        ##############################################################################################\n",
        "        #                                       Your Code                                            #\n",
        "        ##############################################################################################\n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "        # calculate the batch loss\n",
        "        ##############################################################################################\n",
        "        #                                       Your Code                                            #\n",
        "        ##############################################################################################\n",
        "        loss = loss_fn(outputs, targets)\n",
        "\n",
        "        # accumulate all the losses\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        # compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        if clip > 0.0:\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip)\n",
        "\n",
        "        # perform optimization step\n",
        "        optimizer.step()\n",
        "\n",
        "        # perform scheduler step\n",
        "        scheduler.step()\n",
        "\n",
        "        y_pred.extend(preds)\n",
        "        y_true.extend(targets)\n",
        "\n",
        "        if eval:\n",
        "            train_y, train_loss = y_loss(y_true, y_pred, losses)\n",
        "            train_score = acc_and_f1(train_y[0], train_y[1], average='weighted')\n",
        "\n",
        "            if step % print_every_step == 0:\n",
        "                eval_y, eval_loss = eval_op(model, eval_data_loader, loss_fn)\n",
        "                eval_score = acc_and_f1(eval_y[0], eval_y[1], average='weighted')\n",
        "\n",
        "                if hasattr(eval_cb, '__call__'):\n",
        "                    eval_loss_min = eval_cb(model, step, train_score, train_loss, eval_score, eval_loss, eval_loss_min)\n",
        "\n",
        "    train_y, train_loss = y_loss(y_true, y_pred, losses)\n",
        "\n",
        "    return train_y, train_loss, step, eval_loss_min"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1vqogQgbCiH"
      },
      "source": [
        "**<font color=red> Define Optimizer, Scheduler & Loss Function</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTWrdialDAtN",
        "outputId": "9742cb36-ce32-4efe-df67-1e164bcb0c19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning:\n",
            "\n",
            "This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#######################################Your Code#############################################                                   \n",
        "optimizer = AdamW(pt_model.parameters(), lr=LEARNING_RATE, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()                                        \n",
        "##############################################################################################\n",
        "\n",
        "step = 0\n",
        "eval_loss_min = np.Inf\n",
        "history = collections.defaultdict(list)\n",
        "\n",
        "\n",
        "def eval_callback(epoch, epochs, output_path):\n",
        "    def eval_cb(model, step, train_score, train_loss, eval_score, eval_loss, eval_loss_min):\n",
        "        statement = ''\n",
        "        statement += 'Epoch: {}/{}...'.format(epoch, epochs)\n",
        "        statement += 'Step: {}...'.format(step)\n",
        "        \n",
        "        statement += 'Train Loss: {:.6f}...'.format(train_loss)\n",
        "        statement += 'Train Acc: {:.3f}...'.format(train_score['acc'])\n",
        "\n",
        "        statement += 'Valid Loss: {:.6f}...'.format(eval_loss)\n",
        "        statement += 'Valid Acc: {:.3f}...'.format(eval_score['acc'])\n",
        "\n",
        "        print(statement)\n",
        "\n",
        "        if eval_loss <= eval_loss_min:\n",
        "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "                eval_loss_min,\n",
        "                eval_loss))\n",
        "            \n",
        "            torch.save(model.state_dict(), output_path)\n",
        "            eval_loss_min = eval_loss\n",
        "        \n",
        "        return eval_loss_min\n",
        "\n",
        "    return eval_cb\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ph_-AxZkcvQ"
      },
      "source": [
        "**<font color=red> Complete Training & Plot Loss and Accuracy Diagram</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "7i42uhBMkbEy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "849a0c5397714e728f4a0feb8abcaf18",
            "a47c8af7a843479c8abd62902ab6ff1f",
            "9ba1f0d92cfb4520aebd5c2fb02c575d",
            "162d8d89f37e48b9ad775a6e88e66cca",
            "a456d87324ed4acd9f5c70f27719fa88",
            "a1c14ec7f1f74963a3d766611d3a615d",
            "a130a78d20434c2898297db8835ae3f0",
            "74e68e302692433eb0f3735b78adfeb4",
            "ed05b03884a942ccb7800218093cce49",
            "2b9c9c3bb07a4ca692149936f3c688ea",
            "51b0ffdbd4484d6db43405b57b042c50",
            "a5c90b77d0b442f380d7c3d183a5300c",
            "c2926082540d4dfc90cf557cf6db1144",
            "109267bf737e431884382b7d31fd7852",
            "8601eb8ad82545abaf747999a1a8f657",
            "ba841ab64e6f4c66ac56ea5a715a679d",
            "ff2338148b274857bc23c13145e0c906",
            "9a8013942fe24daf9b0e4df1f1f33981",
            "b1ca07b00b0446e2a553925a7950fe32",
            "bf09c769b2254724a902808b07eed392",
            "32ac88fd5ad942b19740d67d74915362",
            "2aadadb679b64dc7b951a63de7e0466f",
            "1f4f054c4ceb4eb4b22900a1439698fa",
            "a99a0c08e9db47d7990e7bcc00d83df6",
            "b53c5194051c4ff981d924ab0a3a8efc",
            "57bb996901ef458e94496afa5f16bbbb",
            "0c6081ba8ca6434d858b85fb6efd325a",
            "24a1ca4632b7490097060ed08b08cc99",
            "19bf4ef60dce4fbe93dffcb6bdc9a929",
            "659f3f0df94d46f6ac775ff04d21f84c",
            "f7fb1d381cff47ae8eee16df8d1208dd",
            "8f207df9a1384cf1ad4b36645946aa6e",
            "e96d3c3ed39d4897ad3a9d617a7bbe6a",
            "82592d0ddb6f4667848b15d4ddf63edb",
            "02ce970aebf74b179f170ff8c20b2bc1",
            "a5266057ae3342a0a9b3ac78a4f9c236",
            "c5061ba32c754d82a42c9fffaeef3b1a",
            "cc82c3ab83a34da3a89a672757bfb3d2",
            "edefb16f58bf44bfbd549e9696798074",
            "f47e3e38804e4555811860c0293e956a",
            "67840bd1888941f891211ea901ad00f5",
            "06955744027840e8bce23fea9c1c26ff",
            "dcbdc9cc99e14477ad7463d13a594a44",
            "1a002b68a0fc42e49f86d517175b421b",
            "893286436692404194cfef6c856cdc67",
            "eda97d34774b432d9204c3729f7e1d9a",
            "825a285ac309419f97b9a2bcef4f7751",
            "ce3fe39bef414eafab7d1a89280b0c86",
            "40ba3eb4005f4f80ab0529d13d2aeb2a",
            "17ac8f3fe5524703be485d2524772a14",
            "004e35587f8747acbaa4719545a49d5a",
            "5a4e3283bbf2426cb9ae5ea0db7a1f3a",
            "adc152c76b2841b185988d26eb7fd58b",
            "8eafef2060da49cbad827c9f1b072f5e",
            "6ef7e897435642dda7bc0ad1b71d9e12",
            "6d4d8827789e41f8be80a443f1a15bdf",
            "8fd982099f054498b548e70ba915952d",
            "6442cf2047d14730b6679df5acb66860",
            "a04497d7247b402f926ab46dedec7b45",
            "66f6ebb3a25143bcb40bc3ee9fa10c09",
            "580b60de18404ed3a6cb53bce4f8f710",
            "df24d290e37b41a4bb02a774cbd86697",
            "e2a50148d417445e859d6f184af3d560",
            "d54d3d1c36cb4d058d90f29fde59eced",
            "b91117a0c541458cbf5eb53c646f3a8b",
            "c7034328b49b4211a0f02a2211cbbda9",
            "270a2e26ad054a649f5169562e1326a5",
            "2a6b2cd2d54a4bc59a0da8a5bc629eea",
            "bb949fc263ff406cbfe018fcfdd37085",
            "89323f4b0f014299a98393ab07512664",
            "b2dc9a16147b4a28a5c90557119f7962",
            "b518b3e487db4191aac7a08f533cec28",
            "df334dc9cb7041388b1450d44e0618a2",
            "7f3a1158935745a8a9483afe4726546b",
            "905b216e2e584e1cb904ba72aa8a3477",
            "de357ed73f024a6a8971b0f3e266f9d0",
            "ed863aedc9f94162a64653b76f15450f",
            "9210640196204e76b9afb46e09bc612e",
            "7c64014fae4041ebbc3220d8f14e19c1",
            "5db0bae4bd0e4b49a6d492cdac896ebe",
            "689889ea9ee744bbade7c64ce451e1b6",
            "b350843193504592a810440cddd04c22",
            "871ab8105fd247a1ab25eda16976b5b1",
            "d4bb601e87d54588b920a1d6ada019af",
            "7ed7b6c303824311b481ae3d6b47f252",
            "4c786b8ae89a4cfdb949a77339d8048a",
            "73c8bb0f9b474300b6caf8db7627b3df",
            "008fcaf16170441db8d07fcad4f8f039",
            "0811f59155e945598ab2daf8db337ea5",
            "4bde0af3b5f2479f80374035ef7e945e",
            "17d4a00ab6934a35aa628aa059eea6e5",
            "68ece3a48eb84cfba024bdc49760582c",
            "7c137e0929d0476585ac3f2af2f3180b",
            "f4c799a68343416cbfbc57be1de6f8a4",
            "baee5ef17b8540cb9b67bd7adb737d5c",
            "f5a300352c7a44f0bcd173fe4b507862",
            "f7803fadc58e486a8457d2f238f16f98",
            "ba1f8ed4c2d748ad80233229b45d768e",
            "d22725e0be734a57af5fe276c88a4945",
            "9aed995118b443409667bc495b4e25df",
            "292ef6272db9499696072df7e307ea90",
            "07a0d2af5bff44f486dd2e3621184b67",
            "7a220e989fb64beca2d5abdecbb30c07",
            "132edba0bbdd49a686439c5c42668973",
            "9db67726b5054c0fa4bfeb168ad8cebf",
            "12477f9b808f44ae807ba8e35921b14f",
            "cd6e2f37e195447a9af47be38f9bd3d4",
            "16727ff7d8f649b59503d5b314cf84e8",
            "a8ee4f6383eb400197d522480a82c033",
            "5d28acfb8458487c986b4c9dc4d511d2",
            "02f80e5f64814c3082ae935a9072716c",
            "e693d92fe71742d09397264c4d99001b",
            "b8ec11b81aaa4247b30d6250a83ccc94",
            "d2d03889b7aa46888abdac0edc526ad4",
            "596bd130a9cf4693b6977d7bc4839af6",
            "96c5531de4764a05873f69da3847b853",
            "1c137234cdea4bd5a34b2cff9c5e1f47",
            "748c02a6382743e88f79ddea63b34c16",
            "17494a17b06547ddaa03d72ef8782044",
            "270f3ad8f39e4c1583546cbedd4644f1",
            "d887b730ae944f3bbaf310183d2bc40b",
            "86e0e04f92c34c38b98de2716e28e376",
            "1450abf5cd1549709badb72b0bac9728",
            "e2946ebcb3244438a391aba94cb44e21",
            "0adbf2ac679e45a0bda05b679d0e830c",
            "177cee6c3eda4b4eab4a2529cfdc7b7c",
            "5ff4520a721445cfaf5cc20fe279468d",
            "19bb820d169a4de1936e49e7f08df1a1",
            "79637fbcc5444cfd825373e0ee4780d5",
            "c9a8966752c94e1e909f77aa4425aeef",
            "5cc5c9813d80411fa37dff15005ecb6d",
            "a4c9df2b59f445cf8a4e5809c2b3a431",
            "d7f309d5689f49c39dbc1e9cd8f6d6a2",
            "bc12ea29b25646ef8a580244d08bddee",
            "70c8ae9dd3064c2098f0e60f8777f147",
            "ce3460e415dc4e64ab47124646438448",
            "f93eae4aed3b4761b65ad6e82512b5cf",
            "4bd127bfc7f04f0a8f5f22eaed5eb1fe",
            "b420d0c66c1b492a85b11cc48c655dcb",
            "47504834cd7f40fa95815e7db77c595a",
            "62d34ee221184081ba83758c7cf83168",
            "90a14ef808df4a6980416bdc0a061137",
            "efd6d60eb98b47d2a81a0599a316035d",
            "eb70fdbcdc9d4d36a8aa15a5047d5374",
            "097eb548449d407480c1d6a2bee7b729",
            "da0faebd99384bb19ac94167f625a43b",
            "5a3dc56a790a4768a1d4e106a1f7c230",
            "ccd0898d21c147dca8b93213f288ecbb",
            "b80fa8fa8b264cd09b72597bf9d40963",
            "657ca5ecd14d4b8c984c8ac1d628e827",
            "cea64c8c4b2f44919e653bb78d637478",
            "39ae8603d3a6414a987a669bf1e71d5d",
            "7a07341aa17841a7884cc2f77a229c73",
            "7fc9045d679d4187b005ba5e9f47c564",
            "c1b622bcbf364de69c9096d57f84dda8",
            "e06275da28e04b73a5b2a4d65f6ced24",
            "8eb45b00a6634c69ae88d3d5cf727ecf",
            "8a47a54439c64ef5bf8a1b32265ffde5",
            "670f02ea804446d984e0b1b060104cf2",
            "24cf6bdc462d43ed8cd930fec703c5ad",
            "23f5f89e1db0434e95c4e41643e5117c",
            "084d2597c7524dc786dfb87b858c4b82",
            "bcb1bb491e40493380fd038a9ef77401",
            "7a82aae66f2b4303a8a7405cbc96bdf5",
            "2ef6fdeeb916463b930433fda0f70ccc",
            "b701b766409f420f9e4ac66415582b78",
            "046f059594864439b2178641641e51e5",
            "0e605e2232bd4dd9b97367e2da30e923",
            "02631f3903bf4ece8764b84baf7ce838",
            "44cad2dff63543c88ee1d8e6ee8f4073",
            "4d95c58e9fd84a7c8c0bdbf91e5784b8",
            "ac77bddf75d44950b932c408535dc2a6",
            "28b51df6499d4bde8cecaa88d223c980",
            "bc33e0ded05d42978be7facb9a67d482",
            "907a5e1e362c4731857e10ee22b52c35",
            "cd1d10c42bb9446191e247c271fc9c17",
            "9f267748ea5d4da1917de0ceb1af462f",
            "82f505c824364c7c997c5bc5cf174183",
            "9c0363e2117245c9a22fb4de2f35e6db",
            "2616c8c2e7b24d6abe73144f07575842",
            "ac6c266425a24051a80c1a6a112a83da",
            "5e4b9c15d1dc44cf9290527e69983ae5",
            "e3f46ed90b4942759a68a499c18b6b97",
            "eb12f34dca574a1da206cf71d055785e",
            "e72082b305dc4ad7a794fb439cbd7fcd",
            "4e95fb3fd5c04c4f975be892a81b238f",
            "f6a07473f1e8475a8fae818c29f4ba08",
            "33403fd8abae4e149f34929ea89b70b0",
            "5a202287e0714bc49148cbf81739bb6f",
            "f08f3bc8fc234b809b02978b477f54cd",
            "091f3c7c1ce7486aacdef75f3c414725",
            "71ed124f595d482eb95d9ee172a29e39",
            "3d41d51bf67c46ffb50b443821473a1b",
            "e30d4bd707234b8b8ca501989e358b16",
            "d95a46f733264b428619021b72614002",
            "74b60563e7c742f7adb8487a409cb6d3",
            "7b2835053b7842cfa5e2dca6a8bf9726",
            "0bb9ff8bf78b4c89b371bf45ebf83753",
            "967af0dfa87e4eac911e6f0ab7415312",
            "f9dbc51c012f4708bfc4ba68621e2505",
            "b95e26d3560f433db8c77db9e1d27616",
            "40d5010dbed2473dbe7e0429b41b5461",
            "029183ecdc644903996e50d665ce198f",
            "1ad6d9c69a0b46e6b8e5876df0b26f81",
            "aa16ace50b74488d9559b0dba579ca4a",
            "96a851951e7c4e6e96dc9e10f99b6f22",
            "6ceb86f21f864739a0fa111259e41b7e",
            "7e6b0bd439894917b0d56c4b61733766",
            "5baf55b049bb4725aaced06f75e30136",
            "699381678de5446392cd7d2b13d3c83e",
            "c5b18a0216274ec3a8df4273d47d732f",
            "7f6f7e2499b84b8ca5456e2827a3e807",
            "af2bdf284b4c4a8aa950f64867445823",
            "b9a37eaa91984bb9ad78cda52cab0557",
            "2b136c6ff6204661a50531262017e0e4",
            "fef5fee962c64e358ec02dc84ad9e690",
            "1f5d9efbf78a495d8fd20a879bf344c5",
            "fb777dbe75334091a0477971da471c04",
            "19ac036ed63643509d0c2f337468860d",
            "9b471f92f09f4ee69b900ee0ba59170f",
            "f3243dfd90014c449a91e5e3826c00a0",
            "555bcd7ed31f4aa7951e6f6c4d987a30",
            "3e90e7ec33c34861837d8be88aebadd1",
            "6981b6c5ecee4c5fbae1bafe68d6ae45",
            "dbf683a521624767830719b3b9422220",
            "86edd78334fb44e69dd9028957d6b856",
            "5a9f098974fb494da092cc4e99e7fd63",
            "0bbdd0af72984ed285a3250ed217f558",
            "e1f76220efd04b2c81bd385b404c0752",
            "8e88156e2b0e460a84448b21a691e65a",
            "17d796277d014aca97f7b5ffcddbc01b",
            "aeebdb00c47c4e588897f4853757d9e5",
            "7bbe10ca6ad44295bcc215443725d29d",
            "320f2ab606874d3782b9e247049ec017",
            "dbe505d579f34f5f8cc1b1b6fb35562e",
            "c84ed20948244c48b74bba18edd4a7f4",
            "b21338a7b4544cd3a01e2ab686fc5ee4",
            "b852f703a61845efbe2df771a49eca88",
            "7598a304ccb94c42b623936c8f28769b",
            "2acd1337f8904501afda98640be3ffc5",
            "29d3f41ab12544efb7088dff79d3a732",
            "1210392c1a894b1ea96e22ab6339926a"
          ]
        },
        "outputId": "5604ec72-917f-4a10-9909-ef1487830354"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epochs... :   0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "849a0c5397714e728f4a0feb8abcaf18"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training... :   0%|          | 0/127 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5c90b77d0b442f380d7c3d183a5300c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0378,  1.0000,  0.0224,  ..., -0.3120, -0.1096, -0.4630],\n",
            "        [ 0.4726,  1.0000,  0.5462,  ..., -0.1145,  0.0859, -0.7667],\n",
            "        [ 0.7134,  1.0000,  0.6169,  ...,  0.3221,  0.0327, -0.6537],\n",
            "        ...,\n",
            "        [ 0.4668,  1.0000, -0.0116,  ..., -0.1864, -0.0823, -0.8706],\n",
            "        [ 0.6155,  1.0000,  0.1617,  ..., -0.0576, -0.0072, -0.6538],\n",
            "        [-0.0339,  0.9999, -0.5607,  ..., -0.7499, -0.1673, -0.3371]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 6.0703e-02,  9.9977e-01, -2.0738e-01,  ..., -7.6526e-01,\n",
            "          1.1743e-01,  6.8751e-02],\n",
            "        [ 2.2653e-01,  9.9998e-01,  1.5204e-01,  ...,  6.6082e-01,\n",
            "          5.6819e-02, -6.6635e-01],\n",
            "        [ 3.4060e-01,  9.9989e-01, -8.1676e-03,  ..., -6.3868e-01,\n",
            "          6.0675e-02, -7.6396e-01],\n",
            "        ...,\n",
            "        [ 4.6589e-01,  9.9783e-01,  1.9846e-01,  ...,  5.4770e-03,\n",
            "         -5.4221e-02, -3.9233e-01],\n",
            "        [ 3.8158e-01,  9.9990e-01, -3.7087e-01,  ..., -2.1707e-01,\n",
            "          1.7733e-01, -6.8158e-01],\n",
            "        [ 2.2851e-01,  9.9410e-01, -1.2848e-01,  ..., -9.5194e-04,\n",
            "         -1.3468e-01, -6.2531e-01]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4959,  0.9999, -0.3204,  ...,  0.1681,  0.5433, -0.4527],\n",
            "        [ 0.4814,  1.0000,  0.3843,  ...,  0.0489,  0.3095, -0.7338],\n",
            "        [ 0.6295,  1.0000,  0.3529,  ..., -0.0019,  0.8029, -0.7378],\n",
            "        ...,\n",
            "        [ 0.8114,  1.0000,  0.2029,  ...,  0.2179,  0.5092, -0.8935],\n",
            "        [-0.0582,  1.0000, -0.3519,  ..., -0.4924,  0.3296, -0.7391],\n",
            "        [ 0.2207,  1.0000,  0.6070,  ..., -0.1460,  0.6554, -0.6216]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7303,  1.0000, -0.0484,  ..., -0.2626,  0.7501, -0.8493],\n",
            "        [ 0.5513,  0.9966, -0.1923,  ..., -0.3049,  0.2445, -0.5728],\n",
            "        [ 0.6265,  1.0000,  0.0267,  ..., -0.6430,  0.6185, -0.7174],\n",
            "        ...,\n",
            "        [ 0.5173,  1.0000, -0.5009,  ..., -0.1048,  0.4627, -0.6883],\n",
            "        [ 0.5674,  1.0000,  0.0742,  ..., -0.4852,  0.4357, -0.4734],\n",
            "        [ 0.5789,  1.0000, -0.3646,  ..., -0.4650,  0.7704, -0.8670]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6494,  1.0000,  0.1329,  ...,  0.2531,  0.5672, -0.7917],\n",
            "        [ 0.8162,  1.0000, -0.1082,  ...,  0.6004,  0.8757, -0.8133],\n",
            "        [ 0.4427,  1.0000, -0.0236,  ..., -0.0053,  0.7127, -0.9304],\n",
            "        ...,\n",
            "        [ 0.4782,  1.0000, -0.0987,  ...,  0.3281,  0.4273, -0.6635],\n",
            "        [ 0.2708,  1.0000, -0.1802,  ..., -0.4829,  0.7275, -0.8943],\n",
            "        [ 0.2287,  1.0000, -0.1579,  ..., -0.5649,  0.8559, -0.8871]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0890,  0.9984,  0.7957,  ...,  0.0429, -0.5620, -0.5594],\n",
            "        [-0.4283,  1.0000,  0.6345,  ..., -0.1258, -0.0930, -0.4614],\n",
            "        [-0.1776,  1.0000,  0.3827,  ..., -0.1326,  0.0373, -0.6797],\n",
            "        ...,\n",
            "        [ 0.1811,  1.0000,  0.8557,  ..., -0.5862,  0.5157, -0.8395],\n",
            "        [-0.4784,  0.9999,  0.0739,  ...,  0.1794, -0.3136, -0.6908],\n",
            "        [ 0.0647,  1.0000,  0.5088,  ...,  0.3727,  0.5865, -0.9123]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1740,  1.0000,  0.7233,  ...,  0.1552, -0.0209, -0.5633],\n",
            "        [ 0.0296,  1.0000,  0.6138,  ...,  0.2327,  0.4792, -0.9435],\n",
            "        [ 0.1157,  1.0000,  0.5836,  ..., -0.3706,  0.1008, -0.9307],\n",
            "        ...,\n",
            "        [-0.4060,  1.0000,  0.3876,  ..., -0.1387, -0.0549, -0.7508],\n",
            "        [ 0.5901,  1.0000,  0.7908,  ...,  0.1279,  0.5974, -0.9052],\n",
            "        [ 0.2947,  1.0000,  0.3942,  ..., -0.1786,  0.0496, -0.7530]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3939,  1.0000, -0.0357,  ...,  0.2073, -0.4730, -0.6435],\n",
            "        [ 0.2837,  1.0000,  0.6471,  ..., -0.6779,  0.6256, -0.9632],\n",
            "        [ 0.4577,  1.0000,  0.6710,  ..., -0.4011,  0.1963, -0.8839],\n",
            "        ...,\n",
            "        [ 0.2771,  1.0000,  0.6185,  ..., -0.0158,  0.4666, -0.9177],\n",
            "        [ 0.3808,  1.0000,  0.8019,  ..., -0.1706,  0.5228, -0.9749],\n",
            "        [ 0.2640,  1.0000,  0.5848,  ..., -0.4338,  0.7203, -0.9374]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3895,  1.0000,  0.3455,  ..., -0.5425,  0.3255, -0.9512],\n",
            "        [-0.2479,  1.0000,  0.5296,  ..., -0.3897,  0.1635, -0.9335],\n",
            "        [ 0.3505,  1.0000,  0.2233,  ..., -0.6076,  0.1118, -0.9434],\n",
            "        ...,\n",
            "        [ 0.3049,  1.0000,  0.2010,  ..., -0.6318,  0.7311, -0.9405],\n",
            "        [ 0.5117,  1.0000,  0.3753,  ..., -0.7297,  0.6080, -0.9361],\n",
            "        [-0.1669,  1.0000, -0.5114,  ..., -0.3469, -0.0283, -0.7057]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5149,  1.0000,  0.3172,  ..., -0.8342,  0.3986, -0.9690],\n",
            "        [ 0.4866,  1.0000,  0.5321,  ..., -0.7143,  0.2085, -0.8727],\n",
            "        [ 0.6744,  1.0000,  0.5174,  ..., -0.2691,  0.7568, -0.9691],\n",
            "        ...,\n",
            "        [-0.5519,  1.0000,  0.6266,  ..., -0.8868, -0.1866, -0.8138],\n",
            "        [-0.1639,  1.0000,  0.1105,  ..., -0.9186,  0.2221, -0.9141],\n",
            "        [ 0.2173,  1.0000,  0.1339,  ..., -0.8108,  0.5010, -0.9527]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0644,  1.0000,  0.4457,  ..., -0.8752,  0.5837, -0.8620],\n",
            "        [ 0.3180,  1.0000,  0.6809,  ..., -0.8712,  0.5013, -0.9194],\n",
            "        [-0.0421,  1.0000,  0.6051,  ..., -0.8496,  0.1503, -0.9274],\n",
            "        ...,\n",
            "        [-0.2427,  1.0000,  0.7267,  ..., -0.8589, -0.1545, -0.8666],\n",
            "        [-0.1667,  1.0000,  0.4883,  ..., -0.9259, -0.1805, -0.8825],\n",
            "        [ 0.1668,  1.0000,  0.5607,  ..., -0.7594,  0.6640, -0.9646]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2366,  1.0000,  0.5454,  ..., -0.9488,  0.8181, -0.9127],\n",
            "        [-0.1426,  1.0000,  0.4186,  ..., -0.9416,  0.3411, -0.9310],\n",
            "        [ 0.4416,  1.0000,  0.7128,  ..., -0.8590,  0.4676, -0.9101],\n",
            "        ...,\n",
            "        [ 0.0123,  1.0000,  0.4595,  ..., -0.9061,  0.4147, -0.8883],\n",
            "        [-0.0679,  1.0000,  0.4529,  ..., -0.9353,  0.7008, -0.8964],\n",
            "        [ 0.3489,  1.0000,  0.6439,  ..., -0.9100,  0.7841, -0.9772]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6751,  1.0000,  0.7836,  ..., -0.9055,  0.8252, -0.9812],\n",
            "        [ 0.2573,  1.0000,  0.4390,  ..., -0.8899,  0.7642, -0.9739],\n",
            "        [ 0.3401,  1.0000,  0.6896,  ..., -0.9051,  0.6451, -0.9422],\n",
            "        ...,\n",
            "        [ 0.2910,  1.0000,  0.7666,  ..., -0.9159,  0.7216, -0.8926],\n",
            "        [ 0.1930,  1.0000,  0.2987,  ..., -0.9545,  0.5355, -0.9489],\n",
            "        [ 0.0611,  1.0000,  0.6432,  ..., -0.8396,  0.6341, -0.9724]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3084,  1.0000,  0.6559,  ..., -0.9437,  0.7859, -0.9602],\n",
            "        [-0.3023,  1.0000,  0.8232,  ..., -0.7433,  0.2849, -0.9140],\n",
            "        [ 0.3301,  1.0000,  0.6520,  ..., -0.9134,  0.8042, -0.9698],\n",
            "        ...,\n",
            "        [ 0.5854,  1.0000,  0.7125,  ..., -0.9251,  0.7895, -0.9632],\n",
            "        [ 0.3466,  1.0000,  0.6750,  ..., -0.9170,  0.8837, -0.9767],\n",
            "        [ 0.4331,  1.0000,  0.7651,  ..., -0.8786,  0.6188, -0.9887]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0980,  1.0000,  0.7805,  ..., -0.9224,  0.8168, -0.9788],\n",
            "        [ 0.1127,  1.0000,  0.7810,  ..., -0.9590,  0.8083, -0.9851],\n",
            "        [ 0.1658,  1.0000,  0.7951,  ..., -0.9286,  0.8125, -0.9770],\n",
            "        ...,\n",
            "        [ 0.6563,  1.0000,  0.8150,  ..., -0.8969,  0.8791, -0.9835],\n",
            "        [-0.4504,  1.0000,  0.7457,  ..., -0.9214,  0.5180, -0.8917],\n",
            "        [ 0.1671,  1.0000,  0.4884,  ..., -0.8313,  0.7684, -0.9738]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3784,  1.0000,  0.6702,  ..., -0.8969,  0.8385, -0.9848],\n",
            "        [ 0.5288,  1.0000,  0.8904,  ..., -0.8754,  0.8119, -0.9863],\n",
            "        [ 0.1020,  1.0000,  0.8656,  ..., -0.9031,  0.7217, -0.9564],\n",
            "        ...,\n",
            "        [ 0.5103,  1.0000,  0.6598,  ..., -0.9087,  0.8881, -0.9606],\n",
            "        [ 0.3383,  1.0000,  0.7387,  ..., -0.9524,  0.8477, -0.9792],\n",
            "        [-0.2842,  1.0000,  0.8162,  ..., -0.9231,  0.8515, -0.9710]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6956,  1.0000,  0.6545,  ..., -0.9161,  0.8595, -0.9732],\n",
            "        [-0.0476,  1.0000,  0.7962,  ..., -0.7716,  0.5234, -0.9347],\n",
            "        [ 0.3685,  1.0000,  0.9264,  ..., -0.9251,  0.8158, -0.9882],\n",
            "        ...,\n",
            "        [ 0.2908,  1.0000,  0.7348,  ..., -0.9104,  0.8425, -0.9605],\n",
            "        [ 0.0012,  1.0000,  0.7910,  ..., -0.9299,  0.8056, -0.9720],\n",
            "        [ 0.1754,  1.0000,  0.8682,  ..., -0.6726,  0.6700, -0.9382]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5011,  1.0000,  0.7191,  ..., -0.8783,  0.8796, -0.9868],\n",
            "        [ 0.2759,  1.0000,  0.9148,  ..., -0.9453,  0.6574, -0.9844],\n",
            "        [-0.0894,  1.0000,  0.9036,  ..., -0.8961,  0.7356, -0.9577],\n",
            "        ...,\n",
            "        [ 0.1974,  1.0000,  0.7199,  ..., -0.7732,  0.7519, -0.9736],\n",
            "        [ 0.3027,  1.0000,  0.8276,  ..., -0.8130,  0.7301, -0.9609],\n",
            "        [ 0.6142,  1.0000,  0.7664,  ..., -0.8908,  0.8637, -0.9918]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6615,  1.0000,  0.8103,  ..., -0.8517,  0.8635, -0.9873],\n",
            "        [ 0.5419,  1.0000,  0.8144,  ..., -0.9116,  0.9108, -0.9884],\n",
            "        [ 0.5831,  1.0000,  0.8816,  ..., -0.8553,  0.8652, -0.9831],\n",
            "        ...,\n",
            "        [ 0.2142,  1.0000,  0.8932,  ..., -0.8388,  0.8142, -0.9669],\n",
            "        [ 0.6202,  1.0000,  0.8543,  ..., -0.8124,  0.8824, -0.9873],\n",
            "        [ 0.3549,  1.0000,  0.8668,  ..., -0.9092,  0.8211, -0.9541]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7740,  1.0000,  0.7469,  ..., -0.8132,  0.9331, -0.9864],\n",
            "        [ 0.5953,  1.0000,  0.8259,  ..., -0.8819,  0.9165, -0.9878],\n",
            "        [ 0.4997,  1.0000,  0.8779,  ..., -0.8053,  0.8431, -0.9715],\n",
            "        ...,\n",
            "        [ 0.7010,  1.0000,  0.8181,  ..., -0.8834,  0.9288, -0.9954],\n",
            "        [ 0.5144,  1.0000,  0.8434,  ..., -0.8903,  0.9224, -0.9941],\n",
            "        [ 0.5134,  1.0000,  0.7047,  ..., -0.7924,  0.9384, -0.9852]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6262,  1.0000,  0.5760,  ..., -0.8596,  0.9240, -0.9866],\n",
            "        [ 0.5769,  1.0000,  0.8739,  ..., -0.9029,  0.9047, -0.9826],\n",
            "        [ 0.6525,  1.0000,  0.7769,  ..., -0.8826,  0.8628, -0.9878],\n",
            "        ...,\n",
            "        [ 0.5689,  1.0000,  0.8380,  ..., -0.9018,  0.9222, -0.9898],\n",
            "        [ 0.6573,  1.0000,  0.5025,  ..., -0.9384,  0.9251, -0.9850],\n",
            "        [ 0.0217,  1.0000,  0.9014,  ..., -0.6151,  0.8140, -0.9345]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7346,  1.0000,  0.8020,  ..., -0.8659,  0.9197, -0.9820],\n",
            "        [ 0.6691,  1.0000,  0.7230,  ..., -0.9074,  0.8710, -0.9923],\n",
            "        [ 0.6387,  1.0000,  0.8119,  ..., -0.9032,  0.8836, -0.9874],\n",
            "        ...,\n",
            "        [ 0.5316,  1.0000,  0.8193,  ..., -0.9485,  0.8356, -0.9852],\n",
            "        [ 0.6672,  1.0000,  0.8630,  ..., -0.8522,  0.8800, -0.9890],\n",
            "        [ 0.3984,  1.0000,  0.8084,  ..., -0.8827,  0.8225, -0.9829]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6131,  1.0000,  0.7692,  ..., -0.9455,  0.9042, -0.9859],\n",
            "        [ 0.4561,  1.0000,  0.8863,  ..., -0.9305,  0.8774, -0.9763],\n",
            "        [ 0.1153,  1.0000,  0.8286,  ..., -0.8428,  0.8115, -0.9616],\n",
            "        ...,\n",
            "        [ 0.4812,  1.0000,  0.6188,  ..., -0.8638,  0.9029, -0.9785],\n",
            "        [ 0.5269,  1.0000,  0.7298,  ..., -0.8193,  0.8904, -0.9839],\n",
            "        [ 0.4970,  1.0000,  0.8319,  ..., -0.9138,  0.8490, -0.9838]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4205,  1.0000,  0.8747,  ..., -0.9115,  0.8581, -0.9915],\n",
            "        [ 0.5577,  1.0000,  0.6775,  ..., -0.8918,  0.8682, -0.9867],\n",
            "        [ 0.1535,  1.0000,  0.9033,  ..., -0.6886,  0.6664, -0.9434],\n",
            "        ...,\n",
            "        [ 0.4603,  1.0000,  0.8538,  ..., -0.9006,  0.8051, -0.9873],\n",
            "        [ 0.4518,  1.0000,  0.8974,  ..., -0.9292,  0.8916, -0.9856],\n",
            "        [ 0.4088,  1.0000,  0.9254,  ..., -0.8872,  0.7655, -0.9839]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1686,  1.0000,  0.9166,  ..., -0.8836,  0.8104, -0.9422],\n",
            "        [ 0.4627,  1.0000,  0.8412,  ..., -0.9368,  0.8220, -0.9862],\n",
            "        [ 0.5248,  1.0000,  0.8308,  ..., -0.9473,  0.9082, -0.9832],\n",
            "        ...,\n",
            "        [ 0.3564,  1.0000,  0.9196,  ..., -0.9359,  0.8475, -0.9779],\n",
            "        [ 0.3760,  1.0000,  0.9142,  ..., -0.8949,  0.8930, -0.9800],\n",
            "        [ 0.1100,  1.0000,  0.9337,  ..., -0.9122,  0.6996, -0.9571]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2069,  1.0000,  0.9228,  ..., -0.9353,  0.7155, -0.9697],\n",
            "        [ 0.4139,  1.0000,  0.8963,  ..., -0.9503,  0.8617, -0.9853],\n",
            "        [ 0.1843,  1.0000,  0.8568,  ..., -0.9314,  0.8322, -0.9689],\n",
            "        ...,\n",
            "        [ 0.3260,  1.0000,  0.8334,  ..., -0.9546,  0.8406, -0.9874],\n",
            "        [ 0.1918,  1.0000,  0.8712,  ..., -0.9328,  0.8362, -0.9807],\n",
            "        [ 0.5824,  1.0000,  0.8818,  ..., -0.9177,  0.8008, -0.9899]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7680,  1.0000,  0.8022,  ..., -0.9184,  0.8985, -0.9820],\n",
            "        [ 0.3060,  1.0000,  0.9240,  ..., -0.9503,  0.7745, -0.9725],\n",
            "        [ 0.1549,  1.0000,  0.8726,  ..., -0.9308,  0.7662, -0.9700],\n",
            "        ...,\n",
            "        [ 0.1316,  1.0000,  0.9296,  ..., -0.9182,  0.7864, -0.9719],\n",
            "        [ 0.3394,  1.0000,  0.8515,  ..., -0.7891,  0.8781, -0.9830],\n",
            "        [ 0.2647,  1.0000,  0.8567,  ..., -0.8943,  0.8826, -0.9810]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2871,  1.0000,  0.8357,  ..., -0.9060,  0.9022, -0.9821],\n",
            "        [ 0.5470,  1.0000,  0.7960,  ..., -0.8562,  0.8413, -0.9894],\n",
            "        [-0.0990,  1.0000,  0.8923,  ..., -0.8936,  0.6083, -0.9622],\n",
            "        ...,\n",
            "        [ 0.4182,  1.0000,  0.8255,  ..., -0.9195,  0.8637, -0.9782],\n",
            "        [ 0.6089,  1.0000,  0.8484,  ..., -0.8721,  0.9086, -0.9804],\n",
            "        [ 0.7081,  1.0000,  0.7875,  ..., -0.8642,  0.9288, -0.9890]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5599,  1.0000,  0.8190,  ..., -0.8706,  0.8971, -0.9899],\n",
            "        [ 0.6414,  1.0000,  0.9118,  ..., -0.9169,  0.8298, -0.9785],\n",
            "        [ 0.5727,  1.0000,  0.8301,  ..., -0.8602,  0.9245, -0.9672],\n",
            "        ...,\n",
            "        [ 0.4993,  1.0000,  0.7309,  ..., -0.8676,  0.9081, -0.9894],\n",
            "        [ 0.3428,  1.0000,  0.9297,  ..., -0.8977,  0.7752, -0.9779],\n",
            "        [ 0.2663,  1.0000,  0.9074,  ..., -0.9297,  0.7809, -0.9899]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0427,  1.0000,  0.8935,  ..., -0.9260,  0.6378, -0.9741],\n",
            "        [-0.0038,  1.0000,  0.8626,  ..., -0.9138,  0.8440, -0.9674],\n",
            "        [ 0.3393,  1.0000,  0.8049,  ..., -0.8496,  0.8436, -0.9808],\n",
            "        ...,\n",
            "        [ 0.6445,  1.0000,  0.8359,  ..., -0.9215,  0.8591, -0.9833],\n",
            "        [ 0.6632,  1.0000,  0.8592,  ..., -0.8852,  0.9357, -0.9798],\n",
            "        [ 0.0266,  1.0000,  0.9147,  ..., -0.8804,  0.7228, -0.9701]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6382,  1.0000,  0.6697,  ..., -0.8444,  0.9221, -0.9761],\n",
            "        [ 0.4805,  1.0000,  0.6511,  ..., -0.8843,  0.9418, -0.9859],\n",
            "        [ 0.5397,  1.0000,  0.7120,  ..., -0.8560,  0.8974, -0.9847],\n",
            "        ...,\n",
            "        [ 0.7217,  1.0000,  0.5260,  ..., -0.8201,  0.9277, -0.9682],\n",
            "        [ 0.7196,  1.0000,  0.7781,  ..., -0.8160,  0.8897, -0.9833],\n",
            "        [ 0.6158,  1.0000,  0.5894,  ..., -0.8065,  0.9219, -0.9848]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5334,  1.0000,  0.7737,  ..., -0.9104,  0.8713, -0.9792],\n",
            "        [ 0.3090,  1.0000,  0.9005,  ..., -0.8930,  0.8670, -0.9835],\n",
            "        [ 0.4091,  1.0000,  0.7131,  ..., -0.8311,  0.8971, -0.9684],\n",
            "        ...,\n",
            "        [ 0.5541,  1.0000,  0.8176,  ..., -0.9075,  0.8633, -0.9771],\n",
            "        [ 0.1793,  1.0000,  0.8953,  ..., -0.9024,  0.8857, -0.9771],\n",
            "        [ 0.3658,  1.0000,  0.7284,  ..., -0.9240,  0.8662, -0.9824]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4293,  1.0000,  0.8402,  ..., -0.9334,  0.8961, -0.9690],\n",
            "        [ 0.3886,  1.0000,  0.8605,  ..., -0.7141,  0.7519, -0.9674],\n",
            "        [ 0.3068,  1.0000,  0.8396,  ..., -0.9423,  0.9112, -0.9575],\n",
            "        ...,\n",
            "        [ 0.7272,  1.0000,  0.7580,  ..., -0.7928,  0.9380, -0.9908],\n",
            "        [ 0.5593,  1.0000,  0.6977,  ..., -0.8999,  0.9376, -0.9796],\n",
            "        [ 0.8044,  1.0000,  0.6132,  ..., -0.7955,  0.9171, -0.9841]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6208,  1.0000,  0.7924,  ..., -0.6911,  0.9421, -0.9818],\n",
            "        [ 0.2069,  1.0000,  0.9064,  ..., -0.9252,  0.8693, -0.9915],\n",
            "        [ 0.6678,  1.0000,  0.7227,  ..., -0.8052,  0.8713, -0.9825],\n",
            "        ...,\n",
            "        [ 0.6987,  1.0000,  0.6733,  ..., -0.8301,  0.8932, -0.9875],\n",
            "        [ 0.0898,  1.0000,  0.8360,  ..., -0.7156,  0.8176, -0.9452],\n",
            "        [ 0.4555,  1.0000,  0.7984,  ..., -0.7683,  0.8800, -0.9889]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3846,  1.0000,  0.9456,  ..., -0.9042,  0.8102, -0.9715],\n",
            "        [ 0.5127,  1.0000,  0.7736,  ..., -0.8921,  0.8436, -0.9810],\n",
            "        [ 0.4740,  1.0000,  0.8297,  ..., -0.8507,  0.7924, -0.9750],\n",
            "        ...,\n",
            "        [ 0.5226,  1.0000,  0.7350,  ..., -0.8164,  0.8684, -0.9814],\n",
            "        [ 0.4460,  1.0000,  0.9075,  ..., -0.9139,  0.8078, -0.9901],\n",
            "        [ 0.4323,  1.0000,  0.9190,  ..., -0.8990,  0.9068, -0.9845]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4575,  1.0000,  0.8623,  ..., -0.9411,  0.8654, -0.9638],\n",
            "        [ 0.5536,  1.0000,  0.8134,  ..., -0.8836,  0.8480, -0.9852],\n",
            "        [ 0.3892,  1.0000,  0.4095,  ..., -0.7227,  0.9221, -0.9757],\n",
            "        ...,\n",
            "        [ 0.4476,  1.0000,  0.9289,  ..., -0.9407,  0.8098, -0.9943],\n",
            "        [ 0.2623,  1.0000,  0.9323,  ..., -0.9418,  0.6893, -0.9772],\n",
            "        [ 0.3016,  1.0000,  0.8099,  ..., -0.9071,  0.8333, -0.9801]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2751,  1.0000,  0.9542,  ..., -0.8644,  0.7558, -0.9767],\n",
            "        [ 0.3589,  1.0000,  0.9127,  ..., -0.9362,  0.7893, -0.9858],\n",
            "        [-0.2302,  1.0000,  0.8583,  ..., -0.8484,  0.6609, -0.9415],\n",
            "        ...,\n",
            "        [ 0.4038,  1.0000,  0.8245,  ..., -0.7622,  0.9276, -0.9906],\n",
            "        [ 0.4581,  1.0000,  0.7559,  ..., -0.8805,  0.9050, -0.9908],\n",
            "        [ 0.3321,  1.0000,  0.8475,  ..., -0.8966,  0.6957, -0.9850]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3251,  1.0000,  0.9316,  ..., -0.9438,  0.7982, -0.9845],\n",
            "        [ 0.0244,  1.0000,  0.9285,  ..., -0.9483,  0.6481, -0.9784],\n",
            "        [ 0.6429,  1.0000,  0.8767,  ..., -0.7223,  0.9116, -0.9945],\n",
            "        ...,\n",
            "        [ 0.2310,  1.0000,  0.9200,  ..., -0.9089,  0.5990, -0.9744],\n",
            "        [ 0.4632,  1.0000,  0.5596,  ..., -0.8310,  0.7858, -0.9309],\n",
            "        [ 0.2651,  1.0000,  0.6307,  ..., -0.7787,  0.8348, -0.9464]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6055,  1.0000,  0.9229,  ..., -0.9091,  0.8258, -0.9811],\n",
            "        [ 0.1916,  1.0000,  0.9522,  ..., -0.7617,  0.1796, -0.9534],\n",
            "        [ 0.3544,  1.0000,  0.9576,  ..., -0.8926,  0.6804, -0.9825],\n",
            "        ...,\n",
            "        [-0.0376,  1.0000,  0.9594,  ..., -0.8950,  0.2961, -0.9527],\n",
            "        [ 0.0834,  1.0000,  0.9332,  ..., -0.9058,  0.8307, -0.9781],\n",
            "        [-0.0387,  1.0000,  0.8977,  ..., -0.9220,  0.5348, -0.9579]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0648,  1.0000,  0.9549,  ..., -0.4766,  0.5703, -0.9220],\n",
            "        [ 0.5070,  1.0000,  0.9321,  ..., -0.8906,  0.7394, -0.9713],\n",
            "        [ 0.5716,  1.0000,  0.8465,  ..., -0.9101,  0.7481, -0.9824],\n",
            "        ...,\n",
            "        [ 0.5855,  1.0000,  0.8423,  ..., -0.8329,  0.8263, -0.9940],\n",
            "        [ 0.7310,  1.0000,  0.7870,  ..., -0.6564,  0.8808, -0.9886],\n",
            "        [ 0.6147,  1.0000,  0.8466,  ..., -0.8847,  0.9127, -0.9858]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5337,  1.0000,  0.9105,  ..., -0.9376,  0.7849, -0.9849],\n",
            "        [ 0.4636,  1.0000,  0.7514,  ..., -0.6954,  0.8644, -0.9801],\n",
            "        [ 0.5252,  1.0000,  0.5248,  ..., -0.4278,  0.9073, -0.9443],\n",
            "        ...,\n",
            "        [-0.2029,  1.0000,  0.9508,  ..., -0.6941,  0.4605, -0.9308],\n",
            "        [ 0.2955,  1.0000,  0.9525,  ..., -0.8520,  0.8169, -0.9868],\n",
            "        [ 0.5674,  1.0000,  0.9248,  ..., -0.9163,  0.8725, -0.9782]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2913,  1.0000,  0.9182,  ..., -0.7961,  0.2230, -0.8918],\n",
            "        [ 0.4588,  1.0000,  0.9505,  ..., -0.9379,  0.4765, -0.9797],\n",
            "        [ 0.4071,  1.0000,  0.7923,  ..., -0.8521,  0.8092, -0.9431],\n",
            "        ...,\n",
            "        [ 0.5335,  1.0000,  0.8791,  ..., -0.9102,  0.7737, -0.9905],\n",
            "        [ 0.2689,  1.0000,  0.8650,  ..., -0.9223,  0.7383, -0.9894],\n",
            "        [ 0.2456,  1.0000,  0.8408,  ..., -0.7919,  0.6330, -0.9744]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5148,  1.0000,  0.9086,  ..., -0.8910,  0.8121, -0.9921],\n",
            "        [ 0.5388,  1.0000,  0.8426,  ..., -0.9142,  0.7923, -0.9933],\n",
            "        [ 0.5920,  1.0000,  0.8385,  ..., -0.7016,  0.8580, -0.9680],\n",
            "        ...,\n",
            "        [-0.0234,  1.0000,  0.9340,  ..., -0.8946,  0.6671, -0.9617],\n",
            "        [ 0.6343,  1.0000,  0.6608,  ..., -0.7597,  0.8508, -0.9868],\n",
            "        [ 0.4964,  1.0000,  0.9106,  ..., -0.8659,  0.8651, -0.9801]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5929,  1.0000,  0.8369,  ..., -0.7822,  0.8526, -0.9844],\n",
            "        [ 0.0398,  1.0000,  0.5876,  ..., -0.8881,  0.5949, -0.9409],\n",
            "        [ 0.2862,  1.0000,  0.4646,  ..., -0.8537,  0.7968, -0.9652],\n",
            "        ...,\n",
            "        [ 0.5656,  1.0000,  0.6509,  ..., -0.8091,  0.8609, -0.9815],\n",
            "        [ 0.2196,  1.0000,  0.9495,  ..., -0.9006,  0.6664, -0.9757],\n",
            "        [ 0.6601,  1.0000,  0.7037,  ..., -0.8128,  0.9459, -0.9772]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3320,  1.0000,  0.9432,  ..., -0.8817,  0.7544, -0.9810],\n",
            "        [-0.0999,  1.0000,  0.9590,  ..., -0.8240,  0.4705, -0.9417],\n",
            "        [ 0.4127,  1.0000,  0.9033,  ..., -0.8484,  0.8409, -0.9915],\n",
            "        ...,\n",
            "        [ 0.5236,  1.0000,  0.9442,  ..., -0.8775,  0.8200, -0.9856],\n",
            "        [ 0.7020,  1.0000,  0.5638,  ..., -0.4097,  0.8453, -0.9521],\n",
            "        [-0.1502,  1.0000,  0.9253,  ..., -0.8900,  0.6629, -0.9464]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5940,  1.0000,  0.8730,  ..., -0.8346,  0.8807, -0.9850],\n",
            "        [ 0.6489,  1.0000,  0.6229,  ..., -0.5804,  0.9381, -0.9685],\n",
            "        [-0.0151,  1.0000,  0.6161,  ..., -0.8568,  0.5777, -0.9727],\n",
            "        ...,\n",
            "        [ 0.6245,  1.0000,  0.6082,  ..., -0.7263,  0.9068, -0.9774],\n",
            "        [ 0.0523,  1.0000,  0.8772,  ..., -0.9324,  0.5354, -0.9697],\n",
            "        [ 0.2131,  1.0000,  0.9487,  ..., -0.7779,  0.7972, -0.9868]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5318,  1.0000,  0.8124,  ..., -0.8468,  0.8601, -0.9700],\n",
            "        [ 0.1132,  1.0000,  0.9368,  ..., -0.9038,  0.5038, -0.9723],\n",
            "        [ 0.3871,  1.0000,  0.6118,  ..., -0.8624,  0.9000, -0.9571],\n",
            "        ...,\n",
            "        [ 0.3379,  1.0000,  0.9466,  ..., -0.8128,  0.7917, -0.9899],\n",
            "        [ 0.4477,  1.0000,  0.9082,  ..., -0.8234,  0.7834, -0.9809],\n",
            "        [ 0.5419,  1.0000,  0.4837,  ..., -0.6226,  0.8835, -0.9566]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6110,  1.0000,  0.7787,  ..., -0.8285,  0.9113, -0.9626],\n",
            "        [ 0.5884,  1.0000,  0.9456,  ..., -0.8642,  0.7169, -0.9909],\n",
            "        [ 0.5254,  1.0000,  0.8285,  ..., -0.8220,  0.9215, -0.9649],\n",
            "        ...,\n",
            "        [-0.2748,  1.0000,  0.9673,  ..., -0.7791,  0.2757, -0.9563],\n",
            "        [ 0.6906,  1.0000,  0.7644,  ..., -0.7154,  0.9268, -0.9813],\n",
            "        [ 0.0200,  1.0000,  0.9114,  ..., -0.7766,  0.6189, -0.9559]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4654,  1.0000,  0.7609,  ..., -0.6397,  0.6929, -0.9756],\n",
            "        [ 0.3406,  1.0000,  0.9094,  ..., -0.9014,  0.6754, -0.9900],\n",
            "        [ 0.4902,  1.0000,  0.9052,  ..., -0.7886,  0.7727, -0.9852],\n",
            "        ...,\n",
            "        [ 0.3655,  1.0000,  0.9281,  ..., -0.8525,  0.7127, -0.9838],\n",
            "        [ 0.7088,  1.0000,  0.7759,  ..., -0.7845,  0.8475, -0.9767],\n",
            "        [ 0.6743,  1.0000,  0.8163,  ..., -0.7979,  0.9352, -0.9811]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3966,  1.0000,  0.9563,  ..., -0.8688,  0.7816, -0.9880],\n",
            "        [ 0.4118,  1.0000,  0.9151,  ..., -0.7770,  0.7744, -0.9901],\n",
            "        [ 0.6895,  1.0000,  0.7925,  ..., -0.6605,  0.9035, -0.9915],\n",
            "        ...,\n",
            "        [ 0.5770,  1.0000,  0.9164,  ..., -0.8407,  0.8356, -0.9914],\n",
            "        [ 0.4103,  1.0000,  0.9271,  ..., -0.8902,  0.5235, -0.9870],\n",
            "        [ 0.0655,  1.0000,  0.9318,  ..., -0.6329,  0.6707, -0.9670]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0079,  1.0000,  0.9327,  ..., -0.8234,  0.4053, -0.9676],\n",
            "        [ 0.4551,  1.0000,  0.8934,  ..., -0.8526,  0.8996, -0.9874],\n",
            "        [ 0.4184,  1.0000,  0.9328,  ..., -0.9135,  0.7021, -0.9859],\n",
            "        ...,\n",
            "        [ 0.6303,  1.0000,  0.7521,  ..., -0.8498,  0.8937, -0.9925],\n",
            "        [ 0.8222,  1.0000,  0.6334,  ..., -0.6786,  0.8506, -0.9846],\n",
            "        [ 0.3429,  1.0000,  0.8052,  ..., -0.5766,  0.5682, -0.9583]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4215,  1.0000,  0.9518,  ..., -0.8785,  0.7280, -0.9880],\n",
            "        [ 0.5657,  1.0000,  0.8753,  ..., -0.9526,  0.7604, -0.9821],\n",
            "        [ 0.2888,  1.0000,  0.6776,  ..., -0.8250,  0.8481, -0.9773],\n",
            "        ...,\n",
            "        [ 0.7782,  1.0000,  0.7909,  ..., -0.8008,  0.8102, -0.9762],\n",
            "        [ 0.3257,  1.0000,  0.9585,  ..., -0.8115,  0.7073, -0.9883],\n",
            "        [ 0.3279,  1.0000,  0.9482,  ..., -0.8739,  0.5601, -0.9755]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5165,  1.0000,  0.9748,  ..., -0.8865,  0.8115, -0.9895],\n",
            "        [ 0.5347,  1.0000,  0.9490,  ..., -0.8255,  0.6577, -0.9938],\n",
            "        [ 0.6573,  1.0000,  0.9040,  ..., -0.8699,  0.8830, -0.9908],\n",
            "        ...,\n",
            "        [ 0.6267,  1.0000,  0.8728,  ..., -0.7565,  0.7975, -0.9880],\n",
            "        [ 0.7344,  1.0000,  0.6838,  ..., -0.5396,  0.9095, -0.9683],\n",
            "        [ 0.8323,  1.0000,  0.8395,  ..., -0.5908,  0.7460, -0.9676]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.8080,  1.0000,  0.6476,  ..., -0.7195,  0.9150, -0.9725],\n",
            "        [ 0.5847,  1.0000,  0.9621,  ..., -0.8314,  0.6530, -0.9858],\n",
            "        [ 0.6277,  1.0000,  0.9372,  ..., -0.8749,  0.8843, -0.9888],\n",
            "        ...,\n",
            "        [ 0.6161,  1.0000,  0.7585,  ..., -0.7742,  0.7932, -0.9756],\n",
            "        [ 0.7485,  1.0000,  0.6603,  ..., -0.6996,  0.8715, -0.9667],\n",
            "        [ 0.7657,  1.0000,  0.7720,  ..., -0.6015,  0.8245, -0.9691]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5646,  1.0000,  0.9542,  ..., -0.6849,  0.6519, -0.9751],\n",
            "        [ 0.2065,  1.0000,  0.9135,  ..., -0.5680,  0.4475, -0.9725],\n",
            "        [ 0.8787,  1.0000,  0.7829,  ..., -0.7461,  0.8787, -0.9826],\n",
            "        ...,\n",
            "        [ 0.8308,  1.0000,  0.6105,  ..., -0.6263,  0.8955, -0.9527],\n",
            "        [ 0.4211,  1.0000,  0.7465,  ..., -0.6984,  0.6532, -0.9689],\n",
            "        [ 0.6040,  1.0000,  0.8976,  ..., -0.8387,  0.7984, -0.9848]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3129,  1.0000,  0.9320,  ..., -0.6456,  0.2264, -0.8953],\n",
            "        [ 0.6887,  1.0000,  0.7309,  ..., -0.7816,  0.7523, -0.9884],\n",
            "        [ 0.4629,  1.0000,  0.9098,  ..., -0.8262,  0.4133, -0.9825],\n",
            "        ...,\n",
            "        [ 0.2144,  1.0000,  0.9465,  ..., -0.8987,  0.4717, -0.9656],\n",
            "        [ 0.5475,  1.0000,  0.9033,  ..., -0.8118,  0.8922, -0.9761],\n",
            "        [ 0.2756,  1.0000,  0.8767,  ..., -0.8217,  0.4274, -0.9751]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7501,  1.0000,  0.9386,  ..., -0.7899,  0.4825, -0.9816],\n",
            "        [ 0.5760,  1.0000,  0.6707,  ..., -0.7958,  0.8547, -0.9596],\n",
            "        [ 0.4896,  1.0000,  0.9430,  ..., -0.8487,  0.4355, -0.9561],\n",
            "        ...,\n",
            "        [ 0.6447,  1.0000,  0.9393,  ..., -0.8449,  0.6263, -0.9714],\n",
            "        [ 0.7845,  1.0000,  0.8320,  ..., -0.7592,  0.8230, -0.9778],\n",
            "        [ 0.5145,  1.0000,  0.9392,  ..., -0.8422,  0.6200, -0.9707]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5603,  1.0000,  0.9522,  ..., -0.7662,  0.3845, -0.9504],\n",
            "        [ 0.4434,  1.0000,  0.9605,  ..., -0.4308,  0.2723, -0.9378],\n",
            "        [ 0.5386,  1.0000,  0.9577,  ..., -0.8718,  0.5638, -0.9846],\n",
            "        ...,\n",
            "        [ 0.4177,  1.0000,  0.8995,  ..., -0.8864,  0.7048, -0.9854],\n",
            "        [ 0.3899,  1.0000,  0.9601,  ..., -0.7882,  0.1344, -0.9702],\n",
            "        [ 0.1878,  1.0000,  0.9141,  ..., -0.6247,  0.0211, -0.9270]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6490,  1.0000,  0.9642,  ..., -0.6985,  0.4780, -0.9681],\n",
            "        [ 0.5630,  1.0000,  0.8279,  ..., -0.8634,  0.8075, -0.9841],\n",
            "        [ 0.2989,  1.0000,  0.9378,  ..., -0.5768, -0.1819, -0.9051],\n",
            "        ...,\n",
            "        [ 0.7808,  1.0000,  0.6967,  ..., -0.6591,  0.7464, -0.9635],\n",
            "        [ 0.3772,  1.0000,  0.9372,  ..., -0.8303,  0.6211, -0.9700],\n",
            "        [ 0.6063,  1.0000,  0.8561,  ..., -0.7704,  0.8002, -0.9924]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5252,  1.0000,  0.9503,  ..., -0.1341,  0.2586, -0.9696],\n",
            "        [ 0.5914,  1.0000,  0.5319,  ..., -0.5870,  0.7127, -0.9480],\n",
            "        [ 0.6957,  1.0000,  0.9546,  ..., -0.7139,  0.6489, -0.9807],\n",
            "        ...,\n",
            "        [ 0.6653,  1.0000,  0.9173,  ..., -0.7687,  0.4538, -0.9742],\n",
            "        [ 0.5255,  1.0000,  0.9497,  ..., -0.5753,  0.3578, -0.9758],\n",
            "        [ 0.2334,  1.0000,  0.9315,  ..., -0.7649,  0.5880, -0.9734]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7084,  1.0000,  0.7782,  ..., -0.8705,  0.7245, -0.9918],\n",
            "        [ 0.7162,  1.0000,  0.5461,  ..., -0.6987,  0.6437, -0.9691],\n",
            "        [ 0.6482,  1.0000,  0.3109,  ..., -0.7014,  0.6668, -0.9470],\n",
            "        ...,\n",
            "        [ 0.5300,  1.0000,  0.0862,  ..., -0.7333,  0.6872, -0.9011],\n",
            "        [ 0.6911,  1.0000,  0.5975,  ..., -0.4527,  0.8605, -0.9587],\n",
            "        [ 0.6918,  1.0000,  0.4773,  ..., -0.8396,  0.7104, -0.9630]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2645,  1.0000,  0.9341,  ..., -0.7733,  0.5886, -0.9444],\n",
            "        [ 0.4393,  1.0000,  0.6572,  ..., -0.8861,  0.7660, -0.9729],\n",
            "        [ 0.1842,  1.0000,  0.8091,  ..., -0.7549,  0.3797, -0.9259],\n",
            "        ...,\n",
            "        [ 0.2925,  1.0000,  0.9453,  ..., -0.7125,  0.6562, -0.9686],\n",
            "        [ 0.5228,  1.0000,  0.8748,  ..., -0.8504,  0.5479, -0.9855],\n",
            "        [ 0.7051,  1.0000,  0.3200,  ..., -0.4967,  0.6231, -0.9363]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4946,  1.0000,  0.9512,  ..., -0.7344,  0.6074, -0.9725],\n",
            "        [ 0.5164,  1.0000,  0.5501,  ..., -0.7134,  0.6751, -0.9745],\n",
            "        [ 0.4818,  1.0000,  0.9131,  ..., -0.6952,  0.7769, -0.9930],\n",
            "        ...,\n",
            "        [ 0.6636,  1.0000,  0.7604,  ..., -0.8478,  0.8840, -0.9877],\n",
            "        [ 0.7901,  1.0000,  0.6127,  ..., -0.5420,  0.8313, -0.9762],\n",
            "        [ 0.7569,  1.0000,  0.9060,  ..., -0.1890,  0.9060, -0.9944]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5360,  1.0000,  0.9375,  ..., -0.7694,  0.7950, -0.9851],\n",
            "        [ 0.5893,  1.0000,  0.7459,  ..., -0.6493,  0.8287, -0.9935],\n",
            "        [ 0.5658,  1.0000,  0.8812,  ..., -0.8391,  0.7826, -0.9936],\n",
            "        ...,\n",
            "        [ 0.6866,  1.0000,  0.9167,  ..., -0.8472,  0.6880, -0.9872],\n",
            "        [ 0.4499,  1.0000,  0.9226,  ..., -0.8260,  0.4488, -0.9660],\n",
            "        [ 0.5496,  1.0000,  0.9489,  ..., -0.8528,  0.6459, -0.9893]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5542,  1.0000,  0.6584,  ..., -0.7777,  0.7650, -0.9825],\n",
            "        [ 0.6721,  1.0000,  0.5948,  ..., -0.7863,  0.6241, -0.9746],\n",
            "        [ 0.4580,  1.0000,  0.2546,  ..., -0.8445,  0.5898, -0.9092],\n",
            "        ...,\n",
            "        [ 0.5810,  1.0000,  0.6658,  ..., -0.8217,  0.7515, -0.9552],\n",
            "        [ 0.4604,  1.0000,  0.8449,  ..., -0.8652,  0.8565, -0.9922],\n",
            "        [ 0.5743,  1.0000,  0.6875,  ..., -0.7597,  0.7892, -0.9863]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4131,  1.0000,  0.9415,  ..., -0.7765,  0.6094, -0.9757],\n",
            "        [ 0.1696,  1.0000,  0.6586,  ..., -0.8656,  0.5662, -0.9680],\n",
            "        [ 0.5202,  1.0000,  0.6137,  ..., -0.8830,  0.5716, -0.9200],\n",
            "        ...,\n",
            "        [ 0.4387,  1.0000,  0.5783,  ..., -0.9148,  0.6601, -0.9793],\n",
            "        [ 0.7152,  1.0000,  0.9159,  ..., -0.5605,  0.8237, -0.9798],\n",
            "        [ 0.6376,  1.0000,  0.8990,  ..., -0.8207,  0.7219, -0.9947]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6656,  1.0000,  0.8258,  ..., -0.7909,  0.7213, -0.9883],\n",
            "        [ 0.2982,  1.0000,  0.6809,  ..., -0.8918,  0.8363, -0.9818],\n",
            "        [ 0.4550,  1.0000,  0.6227,  ..., -0.8311,  0.5944, -0.9783],\n",
            "        ...,\n",
            "        [ 0.4784,  1.0000,  0.6852,  ..., -0.9217,  0.6520, -0.9767],\n",
            "        [ 0.5657,  1.0000,  0.8925,  ..., -0.8720,  0.8283, -0.9931],\n",
            "        [ 0.4571,  1.0000,  0.8854,  ..., -0.7879,  0.6323, -0.9698]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4254,  1.0000,  0.8032,  ..., -0.8681,  0.6911, -0.9915],\n",
            "        [ 0.6386,  1.0000,  0.9399,  ..., -0.8039,  0.8126, -0.9939],\n",
            "        [ 0.6025,  1.0000,  0.6459,  ..., -0.8365,  0.7028, -0.9802],\n",
            "        ...,\n",
            "        [ 0.2335,  1.0000,  0.8037,  ..., -0.8649,  0.6964, -0.9803],\n",
            "        [ 0.4185,  1.0000,  0.8902,  ..., -0.9011,  0.6286, -0.9883],\n",
            "        [ 0.5847,  1.0000,  0.7825,  ..., -0.8909,  0.7338, -0.9935]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5033,  1.0000,  0.9522,  ..., -0.8293,  0.5971, -0.9892],\n",
            "        [ 0.4301,  1.0000,  0.9387,  ..., -0.7717,  0.3546, -0.9790],\n",
            "        [ 0.4816,  1.0000,  0.8081,  ..., -0.8605,  0.7312, -0.9828],\n",
            "        ...,\n",
            "        [ 0.6589,  1.0000,  0.9491,  ..., -0.7137,  0.6433, -0.9834],\n",
            "        [ 0.3257,  1.0000,  0.9559,  ..., -0.6956,  0.0622, -0.9543],\n",
            "        [ 0.0510,  1.0000,  0.8389,  ..., -0.8578,  0.6660, -0.9922]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5730,  1.0000,  0.9267,  ..., -0.7533,  0.5283, -0.9711],\n",
            "        [ 0.3344,  1.0000,  0.9047,  ..., -0.7811,  0.5420, -0.9656],\n",
            "        [ 0.4898,  1.0000,  0.9577,  ..., -0.8016,  0.8474, -0.9908],\n",
            "        ...,\n",
            "        [ 0.5198,  1.0000,  0.6222,  ..., -0.8815,  0.5726, -0.9708],\n",
            "        [ 0.3823,  1.0000,  0.9338,  ..., -0.8875,  0.4132, -0.9800],\n",
            "        [ 0.3800,  1.0000,  0.4306,  ..., -0.8138,  0.7030, -0.9765]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5064,  1.0000,  0.8551,  ..., -0.8202,  0.5375, -0.9862],\n",
            "        [ 0.4785,  1.0000,  0.9353,  ..., -0.8972,  0.4861, -0.9855],\n",
            "        [ 0.1849,  1.0000,  0.6735,  ..., -0.8061,  0.7086, -0.9888],\n",
            "        ...,\n",
            "        [ 0.4963,  1.0000,  0.8803,  ..., -0.8345,  0.7541, -0.9906],\n",
            "        [ 0.3046,  1.0000,  0.7727,  ..., -0.9051,  0.5442, -0.9470],\n",
            "        [ 0.3697,  1.0000,  0.8888,  ..., -0.8758,  0.7289, -0.9870]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3540,  1.0000,  0.9235,  ..., -0.8498,  0.4475, -0.9710],\n",
            "        [ 0.3580,  1.0000,  0.8866,  ..., -0.9146,  0.3838, -0.9750],\n",
            "        [ 0.4325,  1.0000,  0.9514,  ..., -0.7056,  0.3856, -0.9671],\n",
            "        ...,\n",
            "        [ 0.2597,  1.0000,  0.3810,  ..., -0.9073,  0.6512, -0.9152],\n",
            "        [ 0.4809,  1.0000,  0.7511,  ..., -0.8048,  0.6564, -0.9897],\n",
            "        [-0.0261,  1.0000,  0.9362,  ..., -0.6955, -0.1201, -0.9016]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2559,  1.0000,  0.9416,  ..., -0.8419,  0.7522, -0.9773],\n",
            "        [ 0.3544,  1.0000,  0.6079,  ..., -0.9050,  0.6714, -0.9644],\n",
            "        [ 0.3390,  1.0000,  0.8140,  ..., -0.8823,  0.6951, -0.9876],\n",
            "        ...,\n",
            "        [ 0.6397,  1.0000,  0.9270,  ..., -0.7901,  0.3787, -0.9619],\n",
            "        [ 0.5873,  1.0000,  0.9272,  ..., -0.6494,  0.1752, -0.9848],\n",
            "        [ 0.0588,  1.0000,  0.9087,  ..., -0.8589,  0.3518, -0.9857]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5795,  1.0000,  0.9369,  ..., -0.8774,  0.6221, -0.9871],\n",
            "        [ 0.3273,  1.0000,  0.9633,  ..., -0.8295,  0.4797, -0.9633],\n",
            "        [ 0.5903,  1.0000,  0.4249,  ..., -0.8325,  0.6861, -0.9283],\n",
            "        ...,\n",
            "        [ 0.0466,  1.0000,  0.9372,  ..., -0.7458,  0.5132, -0.9647],\n",
            "        [ 0.3659,  1.0000,  0.7103,  ..., -0.8729,  0.6429, -0.9615],\n",
            "        [ 0.3498,  1.0000,  0.9222,  ..., -0.8516,  0.5766, -0.9682]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4275,  1.0000,  0.5738,  ..., -0.9514,  0.7193, -0.9570],\n",
            "        [ 0.2301,  1.0000,  0.8843,  ..., -0.8903,  0.6286, -0.9616],\n",
            "        [ 0.1005,  1.0000,  0.9511,  ..., -0.8849,  0.5322, -0.9426],\n",
            "        ...,\n",
            "        [ 0.1880,  1.0000,  0.9239,  ..., -0.8444,  0.7295, -0.9855],\n",
            "        [ 0.0469,  1.0000,  0.9532,  ..., -0.7202,  0.1303, -0.9036],\n",
            "        [-0.3327,  1.0000,  0.9469,  ..., -0.5999, -0.0696, -0.8511]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0425,  1.0000,  0.5639,  ..., -0.9035,  0.4786, -0.9507],\n",
            "        [ 0.2689,  1.0000,  0.8533,  ..., -0.9307,  0.4043, -0.9735],\n",
            "        [ 0.1794,  1.0000,  0.7939,  ..., -0.9141,  0.5908, -0.9758],\n",
            "        ...,\n",
            "        [ 0.0561,  1.0000,  0.8125,  ..., -0.8477,  0.8017, -0.9677],\n",
            "        [ 0.2621,  1.0000,  0.9326,  ..., -0.6698,  0.7702, -0.9751],\n",
            "        [ 0.3982,  1.0000,  0.9546,  ..., -0.8167,  0.6759, -0.9440]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2109,  1.0000,  0.9246,  ..., -0.8528,  0.4636, -0.9750],\n",
            "        [ 0.4581,  1.0000,  0.8439,  ..., -0.8721,  0.5893, -0.9765],\n",
            "        [ 0.3181,  1.0000,  0.8957,  ..., -0.8906,  0.7056, -0.9738],\n",
            "        ...,\n",
            "        [ 0.1515,  1.0000,  0.9189,  ..., -0.7303,  0.0040, -0.9713],\n",
            "        [-0.2919,  1.0000,  0.1647,  ..., -0.8753,  0.4127, -0.9512],\n",
            "        [ 0.3874,  1.0000,  0.8699,  ..., -0.7078,  0.3473, -0.9805]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1879,  1.0000,  0.9176,  ..., -0.8802,  0.4248, -0.9618],\n",
            "        [-0.0454,  1.0000,  0.9173,  ..., -0.8763,  0.4577, -0.9571],\n",
            "        [ 0.2668,  1.0000,  0.8113,  ..., -0.8566,  0.7081, -0.9680],\n",
            "        ...,\n",
            "        [-0.4140,  1.0000,  0.4120,  ..., -0.8988,  0.5870, -0.8977],\n",
            "        [ 0.2074,  1.0000,  0.5606,  ..., -0.8755,  0.5185, -0.9317],\n",
            "        [-0.0967,  1.0000,  0.3456,  ..., -0.8604,  0.2200, -0.6997]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3058,  1.0000,  0.9503,  ..., -0.6629,  0.5557, -0.9764],\n",
            "        [ 0.2688,  1.0000,  0.8486,  ..., -0.8615,  0.4577, -0.9462],\n",
            "        [ 0.2704,  1.0000,  0.7080,  ..., -0.7795,  0.6355, -0.9574],\n",
            "        ...,\n",
            "        [ 0.0509,  1.0000,  0.9539,  ..., -0.7384,  0.6736, -0.9689],\n",
            "        [ 0.2301,  1.0000,  0.7706,  ..., -0.8828,  0.5816, -0.9757],\n",
            "        [ 0.3589,  1.0000,  0.9278,  ..., -0.7933,  0.5953, -0.9626]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0767,  1.0000,  0.6039,  ..., -0.8593,  0.7398, -0.9685],\n",
            "        [ 0.1631,  1.0000,  0.3759,  ..., -0.8013,  0.7324, -0.9378],\n",
            "        [ 0.0106,  1.0000,  0.6691,  ..., -0.9000,  0.8900, -0.9586],\n",
            "        ...,\n",
            "        [-0.0321,  1.0000,  0.8636,  ..., -0.8688,  0.7473, -0.9793],\n",
            "        [-0.2133,  1.0000,  0.1375,  ..., -0.8438,  0.1657, -0.7841],\n",
            "        [ 0.4603,  1.0000,  0.3936,  ..., -0.8520,  0.7943, -0.9619]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3179,  1.0000,  0.9494,  ..., -0.7963,  0.6079, -0.9863],\n",
            "        [ 0.4573,  1.0000,  0.8890,  ..., -0.7717,  0.7935, -0.9883],\n",
            "        [-0.1983,  1.0000,  0.2745,  ..., -0.8987,  0.7338, -0.8966],\n",
            "        ...,\n",
            "        [ 0.3102,  1.0000,  0.8849,  ..., -0.8415,  0.6281, -0.9918],\n",
            "        [ 0.3281,  1.0000,  0.9544,  ..., -0.5683,  0.6254, -0.9302],\n",
            "        [-0.0332,  1.0000,  0.6204,  ..., -0.8706,  0.7038, -0.9088]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2307,  1.0000,  0.5655,  ..., -0.8142,  0.6465, -0.9630],\n",
            "        [ 0.0395,  1.0000,  0.5316,  ..., -0.8918,  0.6223, -0.9604],\n",
            "        [ 0.3410,  1.0000,  0.9141,  ..., -0.8180,  0.6779, -0.9763],\n",
            "        ...,\n",
            "        [ 0.4200,  1.0000,  0.8486,  ..., -0.8768,  0.3380, -0.9496],\n",
            "        [ 0.1452,  1.0000,  0.9407,  ..., -0.8193,  0.6475, -0.9631],\n",
            "        [ 0.5436,  1.0000,  0.9287,  ..., -0.7937,  0.6641, -0.9891]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1209,  1.0000,  0.1478,  ..., -0.8898,  0.7745, -0.9067],\n",
            "        [ 0.2528,  1.0000,  0.5780,  ..., -0.7644,  0.6288, -0.9399],\n",
            "        [-0.1843,  1.0000,  0.8904,  ..., -0.7496, -0.0742, -0.8685],\n",
            "        ...,\n",
            "        [ 0.1884,  1.0000,  0.8909,  ..., -0.8928,  0.8180, -0.9803],\n",
            "        [ 0.1406,  1.0000,  0.6786,  ..., -0.7703,  0.6891, -0.9521],\n",
            "        [ 0.3320,  1.0000,  0.9467,  ..., -0.8062,  0.6141, -0.9738]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2686,  1.0000,  0.9249,  ..., -0.8465,  0.6333, -0.9757],\n",
            "        [ 0.3308,  1.0000,  0.8941,  ..., -0.9040,  0.8129, -0.9714],\n",
            "        [ 0.0757,  1.0000,  0.5081,  ..., -0.9109,  0.6175, -0.9037],\n",
            "        ...,\n",
            "        [ 0.4218,  1.0000,  0.9464,  ..., -0.8020,  0.5833, -0.9736],\n",
            "        [ 0.3528,  1.0000,  0.6668,  ..., -0.7840,  0.7004, -0.9357],\n",
            "        [ 0.1469,  1.0000,  0.1279,  ..., -0.8698,  0.6407, -0.8801]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0678,  1.0000,  0.9504,  ..., -0.7360, -0.1144, -0.8756],\n",
            "        [ 0.3127,  1.0000,  0.8633,  ..., -0.8902,  0.4823, -0.9868],\n",
            "        [ 0.0733,  1.0000,  0.9584,  ..., -0.8293,  0.3725, -0.9523],\n",
            "        ...,\n",
            "        [ 0.0256,  1.0000,  0.9266,  ..., -0.8312,  0.3742, -0.8628],\n",
            "        [ 0.1649,  1.0000,  0.9404,  ..., -0.8009,  0.7785, -0.9799],\n",
            "        [-0.2129,  1.0000,  0.9608,  ..., -0.4984, -0.4346, -0.7249]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3131,  1.0000,  0.8743,  ..., -0.8417,  0.8447, -0.9838],\n",
            "        [ 0.0214,  1.0000, -0.3359,  ..., -0.8936,  0.4858, -0.6383],\n",
            "        [-0.0357,  1.0000,  0.5321,  ..., -0.8810,  0.6858, -0.9447],\n",
            "        ...,\n",
            "        [-0.1776,  1.0000,  0.9392,  ..., -0.8406,  0.4820, -0.9113],\n",
            "        [ 0.2337,  1.0000,  0.8928,  ..., -0.8649,  0.7946, -0.9657],\n",
            "        [ 0.1448,  1.0000,  0.9554,  ..., -0.6260,  0.1492, -0.8856]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2460,  1.0000,  0.8531,  ..., -0.8727,  0.7151, -0.9804],\n",
            "        [ 0.2642,  1.0000,  0.8541,  ..., -0.7402,  0.7223, -0.9862],\n",
            "        [ 0.2490,  1.0000,  0.3455,  ..., -0.8292,  0.6739, -0.8826],\n",
            "        ...,\n",
            "        [-0.1947,  1.0000,  0.9663,  ..., -0.6995, -0.0461, -0.8513],\n",
            "        [ 0.0578,  1.0000,  0.9708,  ..., -0.7228,  0.4722, -0.9423],\n",
            "        [ 0.4087,  1.0000,  0.9127,  ..., -0.8033,  0.6264, -0.9502]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0143,  1.0000,  0.9182,  ..., -0.7066,  0.8039, -0.9554],\n",
            "        [ 0.4634,  1.0000,  0.8873,  ..., -0.7368,  0.6901, -0.9690],\n",
            "        [ 0.2027,  1.0000,  0.6871,  ..., -0.8299,  0.4826, -0.9651],\n",
            "        ...,\n",
            "        [ 0.2183,  1.0000,  0.6068,  ..., -0.8921,  0.7630, -0.9512],\n",
            "        [ 0.0818,  1.0000,  0.7876,  ..., -0.8629,  0.8531, -0.9781],\n",
            "        [-0.3682,  1.0000,  0.9024,  ..., -0.8228, -0.0383, -0.8245]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0399,  1.0000,  0.3816,  ..., -0.8499,  0.8109, -0.9520],\n",
            "        [ 0.2835,  1.0000,  0.7722,  ..., -0.8610,  0.6180, -0.9673],\n",
            "        [-0.1202,  1.0000,  0.2900,  ..., -0.9111,  0.6655, -0.8774],\n",
            "        ...,\n",
            "        [-0.3131,  1.0000,  0.9303,  ..., -0.8069,  0.1604, -0.9374],\n",
            "        [ 0.3346,  1.0000,  0.9433,  ..., -0.8785,  0.4776, -0.9255],\n",
            "        [ 0.1101,  1.0000,  0.9207,  ..., -0.9000,  0.7002, -0.9682]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0824,  1.0000,  0.9570,  ..., -0.7089, -0.0621, -0.9200],\n",
            "        [-0.2233,  1.0000,  0.9462,  ..., -0.8199,  0.2627, -0.9206],\n",
            "        [ 0.3905,  1.0000,  0.4553,  ..., -0.8901,  0.7464, -0.9269],\n",
            "        ...,\n",
            "        [-0.4723,  1.0000,  0.9484,  ..., -0.6897, -0.0379, -0.8538],\n",
            "        [ 0.3638,  1.0000,  0.6126,  ..., -0.9067,  0.6158, -0.9775],\n",
            "        [-0.4364,  1.0000,  0.8716,  ..., -0.8011, -0.3260, -0.7625]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1522,  1.0000, -0.1906,  ..., -0.8578,  0.4193, -0.7120],\n",
            "        [ 0.0817,  1.0000,  0.8936,  ..., -0.8590,  0.3464, -0.9062],\n",
            "        [-0.0469,  1.0000,  0.2848,  ..., -0.8760,  0.6111, -0.8592],\n",
            "        ...,\n",
            "        [ 0.2211,  1.0000,  0.9482,  ..., -0.6950,  0.6679, -0.9680],\n",
            "        [ 0.1101,  1.0000,  0.0338,  ..., -0.8337,  0.5499, -0.9665],\n",
            "        [ 0.1174,  1.0000,  0.7924,  ..., -0.8500,  0.7996, -0.9831]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2101,  1.0000,  0.6160,  ..., -0.8433,  0.7473, -0.9153],\n",
            "        [ 0.0986,  1.0000,  0.7580,  ..., -0.7656,  0.8227, -0.9702],\n",
            "        [-0.1327,  1.0000, -0.0394,  ..., -0.8562,  0.3788, -0.7983],\n",
            "        ...,\n",
            "        [-0.1359,  1.0000,  0.8990,  ..., -0.8332,  0.6247, -0.9235],\n",
            "        [ 0.2891,  1.0000,  0.9069,  ..., -0.8215,  0.6720, -0.9699],\n",
            "        [ 0.1268,  1.0000,  0.3421,  ..., -0.7988,  0.7415, -0.9062]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0472,  1.0000, -0.5205,  ..., -0.7937,  0.5041, -0.8600],\n",
            "        [ 0.3256,  1.0000,  0.6122,  ..., -0.8997,  0.7490, -0.9801],\n",
            "        [ 0.0350,  0.9999,  0.5992,  ..., -0.8368,  0.5421, -0.9479],\n",
            "        ...,\n",
            "        [ 0.2359,  1.0000,  0.0103,  ..., -0.7875,  0.6973, -0.9214],\n",
            "        [ 0.0162,  1.0000,  0.9080,  ..., -0.8537,  0.2426, -0.8886],\n",
            "        [-0.1613,  1.0000, -0.0300,  ..., -0.8457,  0.4027, -0.7109]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1098,  1.0000,  0.2474,  ..., -0.8335,  0.7525, -0.9405],\n",
            "        [ 0.1937,  1.0000,  0.7333,  ..., -0.6844,  0.6295, -0.9659],\n",
            "        [ 0.1057,  1.0000,  0.0263,  ..., -0.8519,  0.5794, -0.8463],\n",
            "        ...,\n",
            "        [ 0.3872,  1.0000,  0.6804,  ..., -0.7693,  0.8269, -0.9714],\n",
            "        [ 0.2006,  1.0000,  0.9146,  ..., -0.8758,  0.5940, -0.9593],\n",
            "        [-0.0148,  1.0000,  0.1471,  ..., -0.8234,  0.6308, -0.8072]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2884,  1.0000,  0.3175,  ..., -0.8703,  0.8089, -0.9207],\n",
            "        [ 0.1558,  1.0000,  0.8553,  ..., -0.7804,  0.6755, -0.9839],\n",
            "        [-0.2364,  0.9998, -0.2850,  ..., -0.8283,  0.6071, -0.8902],\n",
            "        ...,\n",
            "        [ 0.0519,  1.0000,  0.8915,  ..., -0.3275,  0.2739, -0.9660],\n",
            "        [ 0.2050,  1.0000,  0.0387,  ..., -0.8817,  0.5385, -0.9019],\n",
            "        [ 0.1365,  1.0000,  0.8306,  ..., -0.5571,  0.3483, -0.9593]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4622,  1.0000,  0.1926,  ..., -0.8419,  0.8447, -0.9308],\n",
            "        [ 0.3647,  1.0000,  0.8477,  ..., -0.8484,  0.7660, -0.9643],\n",
            "        [ 0.0359,  1.0000,  0.4689,  ..., -0.8702,  0.7856, -0.9158],\n",
            "        ...,\n",
            "        [ 0.1246,  1.0000,  0.7921,  ..., -0.7079,  0.7494, -0.9852],\n",
            "        [ 0.4537,  1.0000,  0.6906,  ..., -0.7873,  0.8430, -0.9724],\n",
            "        [ 0.2346,  1.0000,  0.6228,  ..., -0.8627,  0.8769, -0.9668]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2874,  1.0000,  0.6691,  ..., -0.8762,  0.7262, -0.9706],\n",
            "        [ 0.0316,  1.0000,  0.9264,  ..., -0.6162,  0.1025, -0.9262],\n",
            "        [ 0.1506,  1.0000,  0.6287,  ..., -0.7602,  0.7237, -0.9715],\n",
            "        ...,\n",
            "        [ 0.3518,  1.0000,  0.8409,  ..., -0.9082,  0.8275, -0.9630],\n",
            "        [-0.0389,  1.0000,  0.0371,  ..., -0.7862,  0.7877, -0.9472],\n",
            "        [ 0.0515,  1.0000,  0.8814,  ..., -0.8206,  0.5784, -0.9609]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1592,  1.0000,  0.4528,  ..., -0.8135,  0.8371, -0.9456],\n",
            "        [ 0.2543,  1.0000,  0.9536,  ..., -0.6726,  0.5546, -0.9741],\n",
            "        [ 0.1783,  1.0000,  0.5531,  ..., -0.7908,  0.6971, -0.9679],\n",
            "        ...,\n",
            "        [ 0.3815,  1.0000,  0.9345,  ..., -0.6401,  0.4864, -0.9718],\n",
            "        [ 0.0530,  1.0000,  0.6283,  ..., -0.8041,  0.7671, -0.9561],\n",
            "        [ 0.3041,  1.0000,  0.9442,  ..., -0.7881,  0.8721, -0.9831]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1954,  1.0000,  0.9622,  ..., -0.6782,  0.1141, -0.9192],\n",
            "        [ 0.3453,  1.0000,  0.1559,  ..., -0.7264,  0.8188, -0.9581],\n",
            "        [ 0.2985,  1.0000,  0.5601,  ..., -0.7502,  0.7820, -0.9540],\n",
            "        ...,\n",
            "        [ 0.0756,  1.0000,  0.7340,  ..., -0.7953,  0.6516, -0.9313],\n",
            "        [ 0.1053,  1.0000,  0.8956,  ..., -0.8000,  0.4815, -0.9585],\n",
            "        [ 0.4484,  1.0000,  0.7315,  ..., -0.8344,  0.6893, -0.9586]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3362,  1.0000,  0.8877,  ..., -0.8312,  0.7079, -0.9745],\n",
            "        [-0.5641,  1.0000,  0.8772,  ..., -0.8013,  0.3404, -0.8885],\n",
            "        [-0.0195,  1.0000,  0.9304,  ..., -0.7390,  0.0667, -0.9114],\n",
            "        ...,\n",
            "        [-0.3653,  1.0000,  0.9339,  ..., -0.3605,  0.0401, -0.8411],\n",
            "        [-0.3998,  1.0000,  0.8787,  ..., -0.7927, -0.2070, -0.8576],\n",
            "        [ 0.2024,  1.0000,  0.8052,  ..., -0.6570,  0.8081, -0.9725]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3806,  1.0000,  0.7511,  ..., -0.7752,  0.7873, -0.9703],\n",
            "        [-0.1774,  1.0000,  0.9482,  ..., -0.7585,  0.0164, -0.8981],\n",
            "        [ 0.3895,  1.0000,  0.5693,  ..., -0.7061,  0.8420, -0.9643],\n",
            "        ...,\n",
            "        [-0.2291,  1.0000,  0.9368,  ..., -0.6971,  0.2563, -0.8880],\n",
            "        [-0.5668,  1.0000,  0.9253,  ..., -0.3713,  0.0876, -0.8042],\n",
            "        [ 0.2001,  1.0000,  0.7188,  ..., -0.8628,  0.7727, -0.9635]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3567,  1.0000,  0.6281,  ..., -0.7565,  0.8605, -0.9688],\n",
            "        [ 0.3079,  1.0000,  0.9008,  ..., -0.7610,  0.7130, -0.9834],\n",
            "        [ 0.5786,  1.0000,  0.7189,  ..., -0.7747,  0.8705, -0.9779],\n",
            "        ...,\n",
            "        [ 0.0132,  1.0000,  0.9240,  ..., -0.6794,  0.5545, -0.9787],\n",
            "        [-0.4113,  1.0000,  0.9022,  ..., -0.6818,  0.1188, -0.9325],\n",
            "        [ 0.3993,  1.0000,  0.7877,  ..., -0.7967,  0.8132, -0.9787]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2291,  1.0000,  0.3755,  ..., -0.8460,  0.8425, -0.9748],\n",
            "        [ 0.2981,  1.0000,  0.7560,  ..., -0.8897,  0.7328, -0.9634],\n",
            "        [ 0.3583,  1.0000,  0.8340,  ..., -0.7390,  0.8011, -0.9918],\n",
            "        ...,\n",
            "        [ 0.5332,  1.0000,  0.7437,  ..., -0.7238,  0.8356, -0.9803],\n",
            "        [ 0.0821,  1.0000,  0.9247,  ..., -0.7580,  0.5482, -0.9887],\n",
            "        [ 0.3427,  1.0000,  0.7227,  ..., -0.8031,  0.8004, -0.9728]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1288,  1.0000,  0.9203,  ..., -0.7657,  0.3226, -0.9674],\n",
            "        [ 0.4921,  1.0000,  0.8528,  ..., -0.7184,  0.6491, -0.9563],\n",
            "        [ 0.4519,  1.0000,  0.5549,  ..., -0.7193,  0.8751, -0.9861],\n",
            "        ...,\n",
            "        [ 0.3789,  1.0000,  0.7971,  ..., -0.7976,  0.8532, -0.9874],\n",
            "        [ 0.5554,  1.0000,  0.8472,  ..., -0.8064,  0.7895, -0.9878],\n",
            "        [-0.2985,  1.0000,  0.9546,  ..., -0.5715,  0.0580, -0.8306]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0890,  1.0000,  0.9277,  ..., -0.8262,  0.6220, -0.9819],\n",
            "        [-0.1276,  1.0000,  0.9528,  ..., -0.6292,  0.3319, -0.9170],\n",
            "        [ 0.2538,  1.0000,  0.5826,  ..., -0.8362,  0.7929, -0.9592],\n",
            "        ...,\n",
            "        [ 0.3668,  1.0000,  0.9123,  ..., -0.8165,  0.6600, -0.9895],\n",
            "        [ 0.0838,  1.0000,  0.7714,  ..., -0.7421,  0.8265, -0.9902],\n",
            "        [ 0.2493,  1.0000,  0.6092,  ..., -0.8310,  0.8204, -0.9729]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2768,  1.0000,  0.7586,  ..., -0.7955,  0.8881, -0.9724],\n",
            "        [ 0.0722,  1.0000,  0.9450,  ..., -0.7110,  0.1800, -0.9647],\n",
            "        [-0.1562,  1.0000,  0.9218,  ..., -0.8575,  0.1529, -0.9423],\n",
            "        ...,\n",
            "        [-0.0047,  1.0000,  0.8965,  ..., -0.5498,  0.5679, -0.9733],\n",
            "        [ 0.3221,  1.0000,  0.9119,  ..., -0.8800,  0.6987, -0.9771],\n",
            "        [ 0.4040,  1.0000,  0.6090,  ..., -0.8311,  0.8439, -0.9694]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1051,  1.0000,  0.9404,  ..., -0.8269,  0.5914, -0.9825],\n",
            "        [ 0.2484,  1.0000,  0.8267,  ..., -0.6058,  0.8423, -0.9736],\n",
            "        [-0.0713,  1.0000,  0.9325,  ..., -0.5819, -0.1660, -0.9158],\n",
            "        ...,\n",
            "        [ 0.2655,  1.0000,  0.9394,  ..., -0.8398,  0.5832, -0.9854],\n",
            "        [ 0.0833,  1.0000,  0.6041,  ..., -0.8064,  0.6309, -0.9619],\n",
            "        [ 0.3773,  1.0000,  0.8987,  ..., -0.7080,  0.6145, -0.9792]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3613,  1.0000,  0.9459,  ..., -0.7004, -0.1677, -0.9137],\n",
            "        [ 0.4398,  1.0000,  0.8489,  ..., -0.7838,  0.6259, -0.9892],\n",
            "        [ 0.0578,  0.9999,  0.9325,  ..., -0.5047,  0.0270, -0.9118],\n",
            "        ...,\n",
            "        [ 0.2333,  1.0000,  0.7099,  ..., -0.8757,  0.7648, -0.9833],\n",
            "        [ 0.5769,  1.0000,  0.5930,  ..., -0.8497,  0.9018, -0.9768],\n",
            "        [-0.2778,  1.0000,  0.8799,  ..., -0.7956,  0.1071, -0.8913]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 5.3400e-01,  1.0000e+00,  8.8502e-01,  ..., -8.6697e-01,\n",
            "          8.1389e-01, -9.8642e-01],\n",
            "        [ 5.7318e-01,  1.0000e+00,  5.1481e-01,  ..., -7.7514e-01,\n",
            "          8.1017e-01, -9.7828e-01],\n",
            "        [-1.7416e-01,  1.0000e+00,  9.3082e-01,  ..., -8.7659e-01,\n",
            "          4.1988e-01, -9.6722e-01],\n",
            "        ...,\n",
            "        [ 4.1518e-01,  1.0000e+00,  8.0052e-01,  ..., -8.1377e-01,\n",
            "          7.8664e-01, -9.8725e-01],\n",
            "        [ 4.4983e-02,  1.0000e+00,  9.0661e-01,  ..., -8.6743e-01,\n",
            "          3.4517e-01, -9.5395e-01],\n",
            "        [-1.6810e-01,  1.0000e+00,  9.3510e-01,  ..., -6.9109e-01,\n",
            "         -6.7729e-04, -9.4675e-01]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0415,  1.0000,  0.8322,  ..., -0.8502,  0.7116, -0.9781],\n",
            "        [ 0.4066,  1.0000,  0.7350,  ..., -0.8497,  0.6413, -0.9851],\n",
            "        [ 0.1033,  1.0000,  0.8821,  ..., -0.8269,  0.4940, -0.9717],\n",
            "        ...,\n",
            "        [-0.0098,  1.0000,  0.9260,  ..., -0.6878,  0.3915, -0.9146],\n",
            "        [ 0.1754,  1.0000,  0.9316,  ..., -0.5243, -0.0348, -0.9083],\n",
            "        [ 0.1672,  1.0000,  0.7053,  ..., -0.8579,  0.7386, -0.9811]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2253,  1.0000,  0.7729,  ..., -0.9128,  0.8206, -0.9836],\n",
            "        [ 0.1485,  1.0000,  0.9224,  ..., -0.8661,  0.6242, -0.9537],\n",
            "        [ 0.5040,  1.0000,  0.4423,  ..., -0.8514,  0.7698, -0.9640],\n",
            "        ...,\n",
            "        [ 0.2279,  1.0000,  0.6106,  ..., -0.7948,  0.8415, -0.9659],\n",
            "        [ 0.1685,  1.0000,  0.8385,  ..., -0.7192,  0.3474, -0.9626],\n",
            "        [-0.1240,  1.0000,  0.9462,  ..., -0.8597,  0.3828, -0.9845]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4000,  1.0000,  0.9049,  ..., -0.8366,  0.2827, -0.9475],\n",
            "        [ 0.2860,  1.0000,  0.3113,  ..., -0.8278,  0.8171, -0.9712],\n",
            "        [ 0.0434,  1.0000,  0.9081,  ..., -0.6965,  0.1411, -0.9306],\n",
            "        ...,\n",
            "        [ 0.2492,  1.0000,  0.4255,  ..., -0.9404,  0.7729, -0.9840],\n",
            "        [-0.1005,  1.0000,  0.8664,  ..., -0.7767,  0.2205, -0.9494],\n",
            "        [ 0.2899,  1.0000,  0.8732,  ..., -0.8015,  0.6580, -0.9730]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4332,  1.0000,  0.7641,  ..., -0.7746,  0.8125, -0.9613],\n",
            "        [-0.0627,  1.0000,  0.8676,  ..., -0.7218,  0.3352, -0.9361],\n",
            "        [-0.2308,  1.0000,  0.8902,  ..., -0.7370, -0.3184, -0.8973],\n",
            "        ...,\n",
            "        [ 0.6514,  1.0000,  0.4732,  ..., -0.8166,  0.8237, -0.9919],\n",
            "        [-0.0346,  1.0000,  0.9209,  ..., -0.8394,  0.6057, -0.9638],\n",
            "        [ 0.4663,  1.0000,  0.3383,  ..., -0.8482,  0.8194, -0.9675]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2169,  1.0000,  0.4745,  ..., -0.8678,  0.7771, -0.9703],\n",
            "        [-0.4175,  0.9999,  0.9089,  ..., -0.3453, -0.1966, -0.7650],\n",
            "        [-0.0464,  1.0000,  0.9416,  ..., -0.1773,  0.2052, -0.8965],\n",
            "        ...,\n",
            "        [ 0.1585,  1.0000,  0.9310,  ..., -0.7460,  0.4399, -0.9748],\n",
            "        [ 0.2097,  1.0000,  0.7213,  ..., -0.8632,  0.8429, -0.9832],\n",
            "        [ 0.3594,  1.0000,  0.4447,  ..., -0.8690,  0.7360, -0.9799]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2808,  1.0000,  0.8097,  ..., -0.8764,  0.8254, -0.9872],\n",
            "        [ 0.5601,  1.0000,  0.5068,  ..., -0.8649,  0.8590, -0.9747],\n",
            "        [ 0.2539,  1.0000,  0.7873,  ..., -0.8590,  0.6760, -0.9884],\n",
            "        ...,\n",
            "        [ 0.1018,  1.0000,  0.7325,  ..., -0.9576,  0.7379, -0.9854],\n",
            "        [-0.2053,  1.0000,  0.8518,  ..., -0.6293, -0.0483, -0.9215],\n",
            "        [ 0.4436,  1.0000,  0.2174,  ..., -0.8677,  0.9220, -0.9855]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0983,  1.0000,  0.9246,  ..., -0.4031,  0.6432, -0.9810],\n",
            "        [ 0.0753,  1.0000,  0.8885,  ..., -0.8337,  0.1496, -0.9634],\n",
            "        [ 0.5888,  1.0000,  0.1535,  ..., -0.9394,  0.8773, -0.9617],\n",
            "        ...,\n",
            "        [ 0.5179,  1.0000,  0.0895,  ..., -0.8921,  0.7958, -0.9637],\n",
            "        [ 0.4449,  1.0000,  0.5427,  ..., -0.9085,  0.8570, -0.9735],\n",
            "        [ 0.4168,  1.0000,  0.0864,  ..., -0.9326,  0.7933, -0.9623]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2936,  1.0000,  0.2268,  ..., -0.8832,  0.8356, -0.9526],\n",
            "        [-0.0526,  1.0000,  0.8992,  ..., -0.6768,  0.4152, -0.9116],\n",
            "        [-0.1503,  1.0000,  0.9113,  ..., -0.8352,  0.2193, -0.9520],\n",
            "        ...,\n",
            "        [ 0.3337,  1.0000,  0.8833,  ..., -0.9258,  0.8404, -0.9871],\n",
            "        [ 0.5012,  1.0000,  0.2260,  ..., -0.8242,  0.8928, -0.9771],\n",
            "        [ 0.0500,  1.0000,  0.5172,  ..., -0.8724,  0.7968, -0.9831]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0531,  1.0000,  0.9407,  ..., -0.6198,  0.1388, -0.9645],\n",
            "        [ 0.4624,  1.0000, -0.1121,  ..., -0.9088,  0.8133, -0.9706],\n",
            "        [ 0.5114,  1.0000,  0.2780,  ..., -0.9076,  0.8093, -0.9709],\n",
            "        ...,\n",
            "        [-0.1799,  1.0000,  0.8570,  ..., -0.7954,  0.1854, -0.8336],\n",
            "        [ 0.5975,  1.0000,  0.5464,  ..., -0.8315,  0.6521, -0.9935],\n",
            "        [ 0.2761,  1.0000,  0.5898,  ..., -0.8507,  0.7860, -0.9837]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3339,  1.0000,  0.4638,  ..., -0.8324,  0.7804, -0.9489],\n",
            "        [-0.2589,  1.0000,  0.9021,  ..., -0.6810, -0.0040, -0.7982],\n",
            "        [-0.2242,  0.9999,  0.9065,  ..., -0.4765, -0.4331, -0.7470],\n",
            "        ...,\n",
            "        [-0.0785,  1.0000,  0.8325,  ..., -0.3948,  0.0177, -0.8207],\n",
            "        [-0.1197,  1.0000,  0.9220,  ..., -0.5125, -0.0896, -0.8670],\n",
            "        [ 0.3291,  1.0000,  0.7209,  ..., -0.8745,  0.7318, -0.9804]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1541,  1.0000,  0.8124,  ..., -0.8367,  0.7011, -0.9773],\n",
            "        [-0.1344,  1.0000,  0.8707,  ..., -0.3721,  0.0342, -0.8282],\n",
            "        [ 0.4295,  1.0000,  0.7773,  ..., -0.9036,  0.7093, -0.9842],\n",
            "        ...,\n",
            "        [ 0.5056,  1.0000,  0.0839,  ..., -0.9005,  0.8543, -0.9656],\n",
            "        [ 0.1720,  1.0000,  0.8845,  ..., -0.2724,  0.0868, -0.8653],\n",
            "        [-0.0043,  1.0000,  0.8208,  ..., -0.8904,  0.3981, -0.9702]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0681,  1.0000,  0.9290,  ..., -0.8162,  0.3700, -0.9167],\n",
            "        [ 0.2600,  1.0000,  0.8777,  ..., -0.7170,  0.4204, -0.9747],\n",
            "        [-0.2601,  0.9998,  0.8486,  ..., -0.6065, -0.2474, -0.6649],\n",
            "        ...,\n",
            "        [ 0.1332,  1.0000,  0.9038,  ..., -0.7422,  0.5380, -0.9673],\n",
            "        [-0.1131,  1.0000,  0.8429,  ..., -0.8824,  0.1100, -0.9613],\n",
            "        [ 0.4311,  1.0000,  0.6671,  ..., -0.8506,  0.6341, -0.9828]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4375,  1.0000,  0.5536,  ..., -0.7863,  0.8456, -0.9831],\n",
            "        [ 0.3710,  1.0000,  0.6168,  ..., -0.8812,  0.7364, -0.9423],\n",
            "        [ 0.2150,  1.0000, -0.1234,  ..., -0.8628,  0.8122, -0.9570],\n",
            "        ...,\n",
            "        [-0.1600,  0.9999,  0.9261,  ..., -0.6288,  0.0685, -0.7635],\n",
            "        [-0.1374,  1.0000,  0.9001,  ..., -0.6884,  0.0790, -0.8645],\n",
            "        [ 0.0257,  1.0000,  0.9221,  ..., -0.6760,  0.4687, -0.9389]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4324,  1.0000,  0.9418,  ...,  0.0183, -0.0191, -0.8556],\n",
            "        [ 0.2283,  1.0000,  0.8595,  ..., -0.8133,  0.8242, -0.9703],\n",
            "        [-0.1350,  0.9999,  0.9381,  ..., -0.3514, -0.1109, -0.7079],\n",
            "        ...,\n",
            "        [ 0.4805,  1.0000,  0.6841,  ..., -0.8898,  0.8489, -0.9903],\n",
            "        [ 0.0738,  1.0000,  0.7961,  ..., -0.7561,  0.8491, -0.9866],\n",
            "        [-0.3485,  0.9997,  0.8468,  ..., -0.6772, -0.1530, -0.7622]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2574,  1.0000,  0.4073,  ..., -0.9052,  0.8437, -0.9592],\n",
            "        [-0.0100,  1.0000,  0.9253,  ..., -0.8701,  0.7193, -0.9525],\n",
            "        [ 0.4063,  1.0000,  0.2446,  ..., -0.9320,  0.8252, -0.9808],\n",
            "        ...,\n",
            "        [ 0.0871,  1.0000,  0.7557,  ..., -0.8094,  0.7718, -0.9902],\n",
            "        [ 0.2811,  0.9999,  0.9317,  ..., -0.1309, -0.0193, -0.8268],\n",
            "        [ 0.2499,  1.0000,  0.2740,  ..., -0.9181,  0.7442, -0.9854]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1976,  0.9998,  0.8848,  ..., -0.2355, -0.1584, -0.7361],\n",
            "        [-0.2009,  1.0000,  0.8961,  ..., -0.7064,  0.1106, -0.8383],\n",
            "        [ 0.4216,  1.0000,  0.2888,  ..., -0.9065,  0.8986, -0.9762],\n",
            "        ...,\n",
            "        [ 0.5186,  1.0000,  0.3697,  ..., -0.8561,  0.8409, -0.9898],\n",
            "        [-0.4378,  1.0000,  0.8652,  ..., -0.7666, -0.1070, -0.9361],\n",
            "        [-0.0557,  1.0000,  0.8276,  ..., -0.7806,  0.0743, -0.9207]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0506,  1.0000,  0.5294,  ..., -0.9494,  0.5937, -0.9756],\n",
            "        [ 0.2736,  1.0000,  0.4992,  ..., -0.8683,  0.8429, -0.9823],\n",
            "        [-0.0186,  1.0000,  0.8102,  ..., -0.9211,  0.7290, -0.9802],\n",
            "        ...,\n",
            "        [ 0.2223,  1.0000,  0.5366,  ..., -0.8526,  0.8126, -0.9802],\n",
            "        [ 0.0953,  1.0000,  0.1555,  ..., -0.9195,  0.7787, -0.9799],\n",
            "        [ 0.0761,  1.0000,  0.5201,  ..., -0.8675,  0.6990, -0.9818]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2938,  1.0000,  0.1444, -0.9990,  0.9098, -0.1368,  0.9256,  0.5034,\n",
            "         -0.9998,  0.5470,  0.6870,  0.4154, -0.5600,  1.0000, -0.1696, -0.9630,\n",
            "          0.0564, -0.9995,  0.9409, -0.9465,  0.7900,  0.2124,  0.9143, -0.8514,\n",
            "         -0.4334, -0.3896, -0.2581,  0.9550, -0.7997,  0.9132, -0.9059, -0.7549,\n",
            "          0.9918,  0.9443,  0.7448, -0.9921, -0.9214, -0.9558, -0.9997, -0.9996,\n",
            "         -0.9486, -0.7878,  1.0000, -0.9499,  0.9990, -0.9983,  0.5043, -0.9472,\n",
            "          0.9505,  0.9409, -0.7730, -0.8919,  0.8910,  0.8979, -0.9045, -0.9998,\n",
            "         -0.6541,  0.9759, -0.9646, -0.4464,  0.8445, -0.8895, -0.6854,  0.7604,\n",
            "         -0.8279,  0.9369,  0.9487,  0.7725,  0.0061, -0.9994,  0.6257, -0.9920,\n",
            "          0.9202, -0.5871,  0.9509,  0.9388, -0.7664, -0.7797, -0.7464,  0.9989,\n",
            "          0.8892,  0.9173,  0.8738, -1.0000,  0.6579, -0.9633,  0.9943, -0.9984,\n",
            "         -0.9940,  0.2020,  0.9473,  0.6759, -0.3848, -0.6957, -0.6189, -0.9788,\n",
            "         -0.1821,  0.0948, -1.0000,  0.9043,  0.9222,  0.9611, -0.2856, -0.8993,\n",
            "         -1.0000, -0.4680, -0.0189, -0.9850, -1.0000, -0.9693, -0.9250, -0.8915,\n",
            "         -0.2888,  0.9962,  0.3477,  1.0000,  0.5991,  0.9859, -1.0000, -0.9918,\n",
            "          0.4846,  0.9824, -0.8835, -0.8666,  0.8815, -0.9980, -0.9979, -1.0000,\n",
            "          0.9279, -0.6367, -0.7878,  0.9839,  0.5107, -0.9902, -0.9616, -0.0398,\n",
            "         -0.9999,  0.4383, -0.5590, -0.9995,  0.9972,  0.9898,  0.1074, -0.8849,\n",
            "         -0.5466,  0.9930,  0.5388,  0.2874, -0.6356, -0.6015, -0.7202,  0.8260,\n",
            "          0.8651,  0.1935, -1.0000,  0.9425,  0.3824,  0.9986, -0.4020,  0.5748,\n",
            "         -0.6317, -1.0000,  0.9763,  0.8235,  0.2464,  0.8011, -0.8623,  0.9623,\n",
            "          0.0984,  0.8564,  0.9416,  0.8242,  0.7801,  0.9692,  0.8491, -0.9813,\n",
            "         -0.9371, -0.9510,  0.9498, -0.9957,  0.9983, -0.9369,  0.9941, -0.9941,\n",
            "         -0.9679,  0.9391,  0.1447, -1.0000,  0.9877,  0.9721,  0.8680, -0.9661,\n",
            "          0.9765, -0.7749,  0.7838, -0.2866, -0.9402,  0.8797, -0.7993,  0.9932,\n",
            "          0.7263, -0.9973,  0.9998,  0.9856,  0.8650, -0.9991,  0.5525,  0.9986,\n",
            "         -0.9990, -0.9828,  0.6544, -0.6203,  0.7956, -0.3525, -0.9545, -0.9445,\n",
            "          0.9942, -0.6408,  0.9887,  0.3544,  0.9173,  0.6740, -0.9587,  0.7178,\n",
            "          0.2443,  0.7746, -0.8004,  0.5810, -0.5611, -1.0000,  0.7109,  0.7062,\n",
            "          0.7337, -0.8697,  1.0000,  0.8833, -0.2968,  0.9959, -0.9995, -0.7041,\n",
            "         -0.6832, -0.9993,  0.8390, -0.5497,  1.0000, -0.9998,  0.9994,  0.2508,\n",
            "          0.9235,  0.8127, -0.9122,  0.8423,  0.9403,  0.8451,  0.4481,  0.9877,\n",
            "         -0.8593, -0.9999,  0.1660,  0.9209, -0.9977, -0.3333, -0.4545, -0.9746,\n",
            "          0.9983,  1.0000, -0.9248,  0.7582,  0.8958,  0.9733,  0.9779, -0.9994,\n",
            "          0.9943,  1.0000, -0.9944, -0.8850,  1.0000,  0.9216, -0.9713,  0.6318,\n",
            "          0.5598, -0.9993, -0.3664, -0.9305,  0.6512,  0.6711,  0.3976, -0.9985,\n",
            "         -0.9996, -0.9993,  0.9996, -0.7281, -0.0814,  0.6395,  0.6086, -0.9034,\n",
            "          0.9029,  0.9921, -0.9978,  1.0000,  0.9940, -0.9836, -0.9982, -0.7380,\n",
            "          0.4158,  0.8296,  0.9975,  0.0376, -0.9871,  0.8500,  0.9912,  0.6822,\n",
            "          0.9992, -0.6769,  0.8792,  0.1675,  0.8817, -0.9989, -0.9459, -0.8418,\n",
            "          0.9586,  0.9985,  0.9384, -0.9305,  0.9994,  0.6500, -1.0000,  1.0000,\n",
            "          0.9974, -0.9990,  0.4229, -0.4933,  0.9588,  0.5694,  0.8570, -0.9499,\n",
            "         -0.6559, -0.9992,  0.9856,  0.6893,  0.4417,  0.8831, -0.3111,  0.9295,\n",
            "          0.7388,  0.9113,  0.4594, -0.9857, -0.9992,  0.3824,  0.8443,  0.8891,\n",
            "         -0.5753,  0.9984,  0.8378,  1.0000, -0.6018,  0.9999, -0.9550,  0.9776,\n",
            "          0.2021,  0.8678,  0.7430, -0.9783, -1.0000,  0.3551, -0.9622,  0.9278,\n",
            "          0.3657, -0.9988, -0.9797,  0.6252, -0.8107,  0.0675, -0.6396, -0.8249,\n",
            "          1.0000,  0.9859,  0.7717, -0.9232, -0.8634,  0.9284,  0.9933,  0.8274,\n",
            "          0.9943, -0.9571,  0.9844, -0.6987,  0.7858, -0.8155,  0.0935,  0.5824,\n",
            "          0.5682,  0.9975,  0.9625,  0.9953, -0.9082,  0.8038, -0.9990,  1.0000,\n",
            "          0.6368,  0.9463,  0.6089, -0.1601,  0.8788, -0.8423,  0.9640, -0.9521,\n",
            "          0.9897, -0.4635,  0.8912,  0.4260,  0.9186, -0.8930,  0.3624,  0.8127,\n",
            "          0.8280, -0.9695, -0.9985,  0.9936, -0.9959, -0.7414, -0.9847, -0.5116,\n",
            "          0.9988, -0.9492, -0.4054, -0.9057, -0.9418, -0.8690, -0.7850, -0.9731,\n",
            "          0.3413, -0.9990,  0.9999, -0.9982,  0.9454, -0.7519, -0.7969,  0.8830,\n",
            "          0.4612, -0.9111, -0.5690,  0.1989, -0.9489,  0.9531, -0.4398,  0.3211,\n",
            "          0.3319, -0.7456,  0.8294,  0.9674,  0.8655,  0.9986, -0.8841, -0.9976,\n",
            "         -0.9488, -0.7425,  0.7616,  0.9994, -0.9985,  0.7326,  1.0000, -0.9993,\n",
            "         -0.9262, -0.6155, -0.9999,  0.9481, -0.9691, -0.9965, -0.5310, -0.9688,\n",
            "          0.9680,  0.9882,  0.9999, -0.3781, -0.9500, -0.9988, -0.8904,  0.9884,\n",
            "         -0.9994,  0.8823, -0.7709, -0.9992,  0.9978,  0.9046, -0.8119,  0.5256,\n",
            "          0.2542,  0.9994, -0.6587, -0.9975,  0.9177,  0.8721, -0.2158,  0.9034,\n",
            "         -0.7814, -0.8634, -0.9995,  0.5296,  1.0000, -0.5361, -0.9188,  0.9717,\n",
            "          0.8640,  0.7907,  1.0000, -0.9984,  0.9837,  1.0000, -0.4271,  0.9656,\n",
            "         -0.6125, -0.8739, -0.2020,  0.7499, -0.8211,  1.0000, -0.9642, -0.9704,\n",
            "         -1.0000,  0.6793, -0.9836,  0.9698,  0.9765, -0.6364,  0.7331,  0.6244,\n",
            "         -0.9994,  0.9859, -0.9290, -1.0000, -0.9999,  0.8077, -0.6730, -0.8752,\n",
            "          0.4402, -0.6580, -0.9595,  0.9999,  0.2190, -1.0000, -0.7922,  0.9824,\n",
            "          0.9995, -0.6368,  0.9557, -0.8539, -0.8330, -0.5491, -1.0000, -0.8094,\n",
            "          0.9908,  0.4304,  0.2927,  0.9999,  0.3122, -0.9632, -0.6494,  0.7436,\n",
            "          0.8101, -1.0000, -0.9339,  1.0000, -0.9486, -0.4449, -0.9896, -0.7602,\n",
            "          0.6123,  0.9632,  0.9986, -0.9982,  1.0000,  0.6976,  0.9706,  0.9912,\n",
            "         -0.0643, -0.9371, -0.9951, -0.1491,  0.8600, -0.3147,  0.1614, -0.9814,\n",
            "          0.9782,  0.4873, -0.9714,  0.4822, -0.7070, -0.7209, -0.7362,  0.9889,\n",
            "          0.8346, -0.7702,  0.9998, -0.5278, -0.9420,  0.7591,  0.6646,  0.6864,\n",
            "         -1.0000,  0.4798,  0.4052, -0.9973, -0.1634,  0.7847, -0.9684, -0.8367,\n",
            "          0.9624, -0.7497,  0.8070,  0.9998,  0.9694,  0.8201, -0.9976, -1.0000,\n",
            "         -0.7366,  0.3029, -0.9956,  0.8273, -0.8070,  0.9998,  0.1769,  0.7561,\n",
            "          0.9516,  1.0000, -0.1668,  0.8944, -0.4860,  0.4629, -0.9830,  0.9891,\n",
            "         -0.1581, -0.9973, -0.9038, -0.0493, -0.7419,  0.3589, -0.1313,  0.7150,\n",
            "          1.0000, -0.0057,  0.9248,  0.9366, -0.7857,  0.2947, -0.9692,  0.9949,\n",
            "         -1.0000,  0.9973,  0.7708, -0.7907,  0.9428, -0.2142, -0.6695, -0.8327,\n",
            "         -0.8238, -0.9091, -0.6524,  0.3234, -0.8647,  0.8337,  0.9909, -0.9710,\n",
            "         -1.0000,  0.2168,  0.1691,  0.8560, -0.4081, -0.8344,  0.9541, -0.2485,\n",
            "          0.9971, -0.8775, -0.8858, -0.9780, -0.9351, -0.1724,  0.9212,  0.9644,\n",
            "          0.8841,  0.5167, -0.5459, -0.7215, -0.5370, -0.7278,  0.6186,  0.4542,\n",
            "          0.9919,  0.8299,  0.9633,  0.9959,  0.6864, -0.7924,  0.8837, -0.8580,\n",
            "         -0.5605, -0.9996,  0.9993,  0.6551, -0.9358, -1.0000,  0.4457,  0.5732,\n",
            "          0.4589,  0.6063, -0.7848, -0.9729, -0.8149,  0.7915, -1.0000,  0.5506,\n",
            "         -0.0656, -0.7909,  0.7748, -0.9996, -0.7739,  0.8408, -0.9331,  0.4476,\n",
            "          0.9999, -0.9787, -0.9967, -0.9912, -0.6555,  0.9200,  0.8067, -0.9976,\n",
            "         -0.7460,  0.9694, -0.9998,  0.7573, -0.5025, -0.6162,  0.8967,  0.7767,\n",
            "          0.9856, -1.0000,  0.8933, -0.6017,  0.8992,  0.1100,  0.2719,  0.9129,\n",
            "          0.7879, -1.0000,  0.7664,  0.6503,  0.9748,  0.9746,  0.6597, -0.8640,\n",
            "         -0.6946, -0.8583,  0.9844,  0.9310, -0.9382,  0.8986,  0.9999, -0.3424,\n",
            "          0.9673, -0.2946, -0.9878, -0.9980, -0.9846, -0.8704,  0.8035, -0.9482]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluation... :   0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f4f054c4ceb4eb4b22900a1439698fa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1810,  1.0000,  0.9081,  ..., -0.5688, -0.0747, -0.8233],\n",
            "        [ 0.0405,  1.0000,  0.9216,  ..., -0.0388, -0.0352, -0.7774],\n",
            "        [ 0.2427,  1.0000, -0.2934,  ..., -0.9360,  0.8165, -0.9471],\n",
            "        ...,\n",
            "        [ 0.1082,  1.0000,  0.8187,  ..., -0.9121,  0.8074, -0.9882],\n",
            "        [ 0.3021,  1.0000,  0.4244,  ..., -0.8816,  0.8733, -0.9791],\n",
            "        [ 0.3027,  1.0000,  0.1232,  ..., -0.8689,  0.7891, -0.9691]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4909,  1.0000,  0.8657,  ..., -0.8036,  0.2647, -0.8630],\n",
            "        [-0.0673,  1.0000,  0.7566,  ..., -0.8656,  0.7524, -0.9801],\n",
            "        [-0.2791,  1.0000,  0.8716,  ..., -0.5000, -0.1698, -0.6432],\n",
            "        ...,\n",
            "        [ 0.0414,  1.0000,  0.7670,  ..., -0.8605,  0.7832, -0.9877],\n",
            "        [ 0.0370,  1.0000,  0.6296,  ..., -0.9021,  0.8000, -0.9832],\n",
            "        [ 0.2883,  1.0000,  0.7363,  ..., -0.8962,  0.7861, -0.9852]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0779,  1.0000,  0.8625,  ..., -0.2978, -0.1618, -0.6751],\n",
            "        [-0.1388,  0.9999,  0.9226,  ..., -0.2205, -0.0010, -0.7858],\n",
            "        [-0.0567,  1.0000,  0.8786,  ..., -0.7361,  0.5919, -0.9694],\n",
            "        ...,\n",
            "        [-0.0978,  1.0000,  0.8753,  ..., -0.8539,  0.6540, -0.9771],\n",
            "        [ 0.1836,  1.0000,  0.3214,  ..., -0.8937,  0.7982, -0.9705],\n",
            "        [-0.1583,  1.0000,  0.8434,  ..., -0.8561,  0.7491, -0.9845]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1729,  1.0000,  0.8799,  ..., -0.8218,  0.3770, -0.9528],\n",
            "        [-0.0186,  1.0000,  0.8183,  ..., -0.9284,  0.7491, -0.9651],\n",
            "        [ 0.1290,  1.0000,  0.8524,  ..., -0.8851,  0.7794, -0.9943],\n",
            "        ...,\n",
            "        [ 0.0433,  1.0000,  0.8750,  ..., -0.6353,  0.1311, -0.8175],\n",
            "        [ 0.1936,  1.0000,  0.4652,  ..., -0.8979,  0.8547, -0.9802],\n",
            "        [-0.1936,  1.0000,  0.9108,  ..., -0.3458, -0.1074, -0.7241]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2269,  1.0000,  0.9199,  ..., -0.7731,  0.1089, -0.9026],\n",
            "        [ 0.0211,  1.0000,  0.7965,  ..., -0.8438,  0.7502, -0.9746],\n",
            "        [ 0.2135,  1.0000,  0.7663,  ..., -0.8980,  0.6058, -0.9872],\n",
            "        ...,\n",
            "        [ 0.1580,  1.0000,  0.7135,  ..., -0.9355,  0.7000, -0.9897],\n",
            "        [-0.2787,  1.0000,  0.9048,  ..., -0.2750, -0.0797, -0.7748],\n",
            "        [-0.0121,  0.9999,  0.8943,  ..., -0.0960, -0.1497, -0.7250]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2222,  1.0000,  0.8780,  ..., -0.4918, -0.1336, -0.6967],\n",
            "        [ 0.0474,  1.0000,  0.8225,  ..., -0.8480,  0.5928, -0.9697],\n",
            "        [ 0.5112,  1.0000, -0.0903,  ..., -0.9155,  0.8845, -0.9420],\n",
            "        ...,\n",
            "        [ 0.3992,  1.0000, -0.0524,  ..., -0.9322,  0.8551, -0.9469],\n",
            "        [-0.1205,  1.0000,  0.8585,  ..., -0.8367,  0.2543, -0.9420],\n",
            "        [-0.0419,  1.0000,  0.9093,  ..., -0.7867,  0.6120, -0.9228]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4973,  1.0000,  0.3498,  ..., -0.9121,  0.8412, -0.9863],\n",
            "        [ 0.3750,  1.0000,  0.1149,  ..., -0.9411,  0.8255, -0.9695],\n",
            "        [ 0.1349,  1.0000,  0.9182,  ..., -0.5092,  0.0579, -0.8445],\n",
            "        ...,\n",
            "        [ 0.2855,  1.0000,  0.6937,  ..., -0.9056,  0.7647, -0.9872],\n",
            "        [-0.0478,  1.0000,  0.8697,  ..., -0.4632,  0.1475, -0.7725],\n",
            "        [ 0.0594,  1.0000,  0.5333,  ..., -0.8900,  0.6994, -0.9824]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-4.1592e-01,  1.0000e+00,  8.5311e-01,  ..., -4.1188e-01,\n",
            "         -4.1897e-04, -8.5831e-01],\n",
            "        [-1.5948e-01,  9.9999e-01,  9.2714e-01,  ..., -3.7625e-01,\n",
            "         -4.2913e-02, -8.0844e-01],\n",
            "        [-7.0281e-02,  9.9999e-01,  9.3701e-01,  ...,  1.3461e-01,\n",
            "          1.5646e-01, -8.3596e-01],\n",
            "        ...,\n",
            "        [-1.0856e-01,  9.9999e-01,  9.2161e-01,  ..., -5.4446e-01,\n",
            "          1.8263e-01, -8.3108e-01],\n",
            "        [-2.4351e-01,  9.9999e-01,  8.8561e-01,  ..., -6.7084e-01,\n",
            "          9.3551e-02, -7.8022e-01],\n",
            "        [ 9.0591e-02,  1.0000e+00,  8.2089e-01,  ..., -8.0607e-01,\n",
            "          7.7671e-01, -9.7486e-01]], device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1658,  1.0000,  0.8982,  ..., -0.6582,  0.1436, -0.8633],\n",
            "        [ 0.0380,  1.0000,  0.7255,  ..., -0.8945,  0.7741, -0.9801],\n",
            "        [-0.1854,  1.0000,  0.8159,  ..., -0.9233,  0.7778, -0.9758],\n",
            "        ...,\n",
            "        [-0.0487,  0.9999,  0.8830,  ..., -0.2755, -0.2313, -0.7175],\n",
            "        [ 0.3096,  1.0000,  0.2474,  ..., -0.9186,  0.8369, -0.9817],\n",
            "        [-0.1228,  0.9999,  0.8882,  ..., -0.0846, -0.0669, -0.7488]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3914,  1.0000, -0.0901,  ..., -0.9003,  0.8024, -0.9581],\n",
            "        [-0.2956,  1.0000,  0.8536,  ..., -0.8679,  0.4350, -0.9084],\n",
            "        [-0.2684,  1.0000,  0.8877,  ..., -0.6668,  0.1777, -0.8814],\n",
            "        ...,\n",
            "        [-0.0650,  1.0000,  0.8797,  ..., -0.5510, -0.0523, -0.7886],\n",
            "        [-0.1928,  1.0000,  0.8758,  ..., -0.5559,  0.0174, -0.8060],\n",
            "        [ 0.0748,  1.0000,  0.9182,  ...,  0.3831,  0.1022, -0.8826]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3473,  1.0000,  0.2029,  ..., -0.9138,  0.8200, -0.9710],\n",
            "        [ 0.0552,  1.0000,  0.3669,  ..., -0.9240,  0.7477, -0.9597],\n",
            "        [-0.2735,  1.0000,  0.7863,  ..., -0.7949,  0.1845, -0.8894],\n",
            "        ...,\n",
            "        [ 0.1433,  1.0000,  0.8971,  ..., -0.7362,  0.4778, -0.9707],\n",
            "        [-0.0250,  1.0000,  0.7056,  ..., -0.9057,  0.5520, -0.9669],\n",
            "        [-0.2661,  1.0000,  0.8913,  ..., -0.4420, -0.1848, -0.7829]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2867,  1.0000,  0.9196,  ..., -0.5640, -0.0010, -0.8072],\n",
            "        [ 0.2773,  1.0000,  0.3568,  ..., -0.9008,  0.8502, -0.9823],\n",
            "        [ 0.0327,  1.0000,  0.8113,  ..., -0.9352,  0.5624, -0.9713],\n",
            "        ...,\n",
            "        [ 0.2466,  1.0000,  0.0526,  ..., -0.9065,  0.8017, -0.9634],\n",
            "        [ 0.2558,  1.0000,  0.5053,  ..., -0.9087,  0.8125, -0.9925],\n",
            "        [ 0.2723,  1.0000,  0.1199,  ..., -0.9294,  0.7370, -0.9726]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4399,  1.0000,  0.6741,  ..., -0.5821,  0.9369, -0.9815],\n",
            "        [-0.0034,  1.0000,  0.7515,  ..., -0.8331,  0.7678, -0.9852],\n",
            "        [ 0.2880,  1.0000,  0.3318,  ..., -0.9331,  0.7494, -0.9682],\n",
            "        ...,\n",
            "        [-0.3433,  1.0000,  0.7382,  ..., -0.8368,  0.6858, -0.9623],\n",
            "        [ 0.4423,  1.0000, -0.1210,  ..., -0.9053,  0.8240, -0.9557],\n",
            "        [ 0.2592,  1.0000,  0.4381,  ..., -0.8738,  0.8161, -0.9832]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3440,  1.0000,  0.4875,  ..., -0.8885,  0.7420, -0.9790],\n",
            "        [ 0.0753,  1.0000,  0.6187,  ..., -0.9063,  0.7152, -0.9739],\n",
            "        [ 0.3729,  1.0000,  0.2057,  ..., -0.8543,  0.7977, -0.9786],\n",
            "        ...,\n",
            "        [ 0.3422,  1.0000,  0.4224,  ..., -0.8803,  0.7262, -0.9698],\n",
            "        [ 0.2666,  1.0000,  0.7683,  ..., -0.8935,  0.9084, -0.9805],\n",
            "        [-0.2657,  1.0000,  0.8354,  ..., -0.5226, -0.2228, -0.7301]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3810,  1.0000,  0.4805, -0.9995,  0.8131,  0.6036,  0.9533,  0.8769,\n",
            "         -0.9999, -0.5816,  0.7709, -0.6308, -0.7795,  1.0000, -0.6943, -0.7798,\n",
            "          0.8931, -0.9999,  0.9633, -0.9797,  0.8914,  0.0208,  0.9691, -0.9428,\n",
            "          0.6414,  0.3124, -0.1651,  0.9419, -0.8341,  0.9227, -0.5992, -0.9046,\n",
            "          0.9708,  0.7034,  0.9521, -0.9989, -0.9231, -0.9861, -0.9998, -0.9999,\n",
            "         -0.9843, -0.9717,  1.0000, -0.9287,  0.9999, -0.9995, -0.2585, -0.8543,\n",
            "          0.9753,  0.9111, -0.9182,  0.0066,  0.8656,  0.9835, -0.7776, -0.9995,\n",
            "         -0.8805,  0.9423, -0.9915, -0.3561,  0.9490, -0.7390, -0.7147,  0.3624,\n",
            "         -0.9602,  0.9318,  0.8216,  0.8745, -0.8397, -0.9993,  0.8882, -0.9917,\n",
            "          0.9303, -0.8114,  0.8241,  0.9863, -0.9494,  0.4352, -0.8243,  0.9978,\n",
            "          0.8984,  0.8875,  0.8761, -1.0000,  0.9023, -0.9649,  0.9989, -0.9994,\n",
            "         -0.9987,  0.8242,  0.9421,  0.9313,  0.4761, -0.9173, -0.8398, -0.8951,\n",
            "         -0.2730,  0.7869, -1.0000,  0.9573,  0.9194,  0.9353, -0.0345, -0.8261,\n",
            "         -1.0000, -0.1582, -0.4115, -0.9769, -1.0000, -0.9480, -0.8689, -0.8913,\n",
            "         -0.6973,  0.9990,  0.3243,  1.0000,  0.8880,  0.9990, -1.0000, -0.9981,\n",
            "          0.7338,  0.9924, -0.9190, -0.8634,  0.8333, -0.9981, -0.9917, -1.0000,\n",
            "          0.9136, -0.9619, -0.9214,  0.9925,  0.8064, -0.9773, -0.9796, -0.0803,\n",
            "         -1.0000,  0.8201, -0.9629, -0.9998,  0.9987,  0.9944,  0.4326, -0.9426,\n",
            "         -0.4471,  0.9949,  0.8539, -0.3476, -0.7421, -0.4136, -0.8501,  0.9185,\n",
            "          0.9548, -0.3686, -1.0000,  0.7586,  0.6453,  0.9958, -0.9833,  0.9918,\n",
            "         -0.9718, -1.0000,  0.9852,  0.8901, -0.8896,  0.9228, -0.7400,  0.9911,\n",
            "         -0.8265,  0.9329,  0.9806,  0.8900,  0.7624,  0.9512,  0.9171, -0.9821,\n",
            "         -0.8705, -0.9511,  0.3613, -0.9994,  0.9984, -0.9454,  0.9965, -0.9916,\n",
            "         -0.9925,  0.9474,  0.0753, -1.0000,  0.9986,  0.9255,  0.9724, -0.9580,\n",
            "          0.9864, -0.9148,  0.9536, -0.6745, -0.9629,  0.9350, -0.9245,  0.9965,\n",
            "          0.7164, -0.9996,  0.9997,  0.9997,  0.9382, -0.9964, -0.1562,  0.9983,\n",
            "         -0.9997, -0.9684,  0.3559, -0.8922,  0.8884,  0.0896, -0.9518, -0.9341,\n",
            "          0.9896,  0.0060,  0.9663, -0.3440,  0.9755,  0.9243, -0.9669,  0.9211,\n",
            "          0.9151,  0.9975, -0.9122,  0.3655,  0.1504, -1.0000,  0.9066,  0.5234,\n",
            "          0.5951, -0.9265,  1.0000,  0.9716,  0.3777,  0.9971, -0.9993, -0.7748,\n",
            "         -0.8334, -0.9554,  0.8417,  0.2674,  1.0000, -1.0000,  0.9994,  0.3660,\n",
            "          0.8798,  0.6651, -0.9002,  0.5226,  0.9365,  0.8999, -0.3604,  0.9974,\n",
            "         -0.9227, -1.0000,  0.3134,  0.9279, -0.9966, -0.4891,  0.4884, -0.9729,\n",
            "          0.9999,  1.0000, -0.6832,  0.7189,  0.9278,  0.9790,  0.9875, -0.9990,\n",
            "          0.9982,  1.0000, -0.9956, -0.6841,  1.0000,  0.9535, -0.9698, -0.3477,\n",
            "          0.9039, -0.9979, -0.7264, -0.8930,  0.4909,  0.1383,  0.7643, -0.9991,\n",
            "         -0.9999, -0.9998,  0.9995, -0.8643, -0.8456,  0.8521,  0.3495, -0.9489,\n",
            "          0.5696,  0.9981, -0.9979,  1.0000,  0.9941, -0.9912, -0.9977, -0.7608,\n",
            "          0.8457,  0.5333,  0.9998,  0.0608, -0.9759,  0.9630,  0.9805,  0.6203,\n",
            "          0.9972, -0.7068,  0.8911, -0.0954,  0.9148, -0.9987, -0.9323, -0.9713,\n",
            "          0.9809,  0.9977,  0.9250, -0.9393,  0.9995,  0.8525, -1.0000,  1.0000,\n",
            "          0.9982, -0.9998,  0.5975, -0.8858,  0.9728,  0.8633,  0.9739, -0.9508,\n",
            "         -0.8094, -0.9999,  0.9780,  0.7660, -0.5848,  0.9112, -0.9183,  0.8935,\n",
            "          0.8065,  0.9425,  0.6656, -0.9648, -0.9999,  0.5846,  0.7452,  0.8605,\n",
            "          0.5164,  0.9983,  0.4027,  1.0000, -0.8951,  0.9969, -0.9150,  0.9616,\n",
            "          0.4196,  0.9517,  0.0345, -0.9268, -1.0000,  0.7461, -0.9327,  0.8859,\n",
            "          0.4916, -0.9995, -0.8887, -0.0228, -0.8944, -0.3524, -0.2111, -0.5249,\n",
            "          1.0000,  0.9764,  0.6169, -0.9219, -0.8233,  0.8952,  0.9941,  0.9725,\n",
            "          0.9993, -0.9799,  0.9665,  0.2576,  0.6269, -0.9248,  0.0765,  0.2309,\n",
            "          0.8203,  0.9990,  0.9853,  0.9820, -0.8561,  0.8894, -0.9994,  1.0000,\n",
            "          0.7473,  0.9210,  0.9791, -0.4855,  0.9586, -0.8916,  0.9685, -0.9756,\n",
            "          0.9951,  0.7320,  0.9186,  0.8431,  0.9727, -0.9666,  0.0559,  0.9579,\n",
            "          0.8873, -0.9592, -0.9960,  0.9979, -0.9981, -0.5139, -0.9801,  0.2844,\n",
            "          0.9984, -0.9776, -0.8823, -0.9311, -0.9618, -0.9753, -0.9608, -0.9988,\n",
            "         -0.1658, -0.9988,  1.0000, -0.9978,  0.9161, -0.9549, -0.9022,  0.9623,\n",
            "          0.4889, -0.9466, -0.8714, -0.0186, -0.9709,  0.9662, -0.0310,  0.6514,\n",
            "          0.4718, -0.7711,  0.9056,  0.8999,  0.7738,  0.9987, -0.9478, -0.9981,\n",
            "         -0.9583, -0.8469,  0.5735,  0.9993, -0.9984,  0.2885,  1.0000, -0.9998,\n",
            "         -0.8894, -0.0236, -0.9999,  0.8712, -0.9806, -0.9987, -0.8479, -0.9600,\n",
            "          0.9856,  0.9959,  1.0000, -0.6125, -0.9522, -0.9947, -0.7849,  0.9958,\n",
            "         -0.9996,  0.7921, -0.5745, -0.9998,  0.9892,  0.9185, -0.8216,  0.8004,\n",
            "         -0.6884,  0.9994, -0.8163, -0.9941,  0.8382,  0.9167,  0.2743,  0.9026,\n",
            "         -0.6842, -0.7268, -0.9991,  0.7954,  1.0000, -0.6547, -0.9873,  0.9724,\n",
            "          0.9858,  0.9374,  1.0000, -0.9978,  0.9827,  1.0000, -0.6633,  0.9431,\n",
            "         -0.8579, -0.9433, -0.0816,  0.9123, -0.9970,  1.0000, -0.9088, -0.9940,\n",
            "         -1.0000,  0.8147, -0.9659,  0.9366,  0.9928,  0.2956,  0.8479,  0.9370,\n",
            "         -0.9998,  0.9857, -0.9886, -1.0000, -1.0000,  0.9502, -0.2083, -0.7999,\n",
            "          0.7658, -0.8132, -0.9272,  1.0000,  0.7438, -1.0000, -0.9412,  0.9823,\n",
            "          0.9968, -0.8817,  0.9639, -0.8797, -0.4746, -0.0286, -1.0000, -0.9400,\n",
            "          0.9987, -0.4847,  0.5960,  1.0000,  0.9319, -0.9558, -0.9537,  0.8309,\n",
            "          0.9585, -1.0000, -0.9731,  1.0000, -0.9785, -0.7034, -0.9874, -0.2467,\n",
            "          0.8926,  0.9681,  0.9913, -0.9998,  0.9999,  0.9284,  0.8136,  0.9970,\n",
            "          0.3792, -0.9027, -0.9945, -0.8456,  0.9452, -0.5308,  0.8122, -0.9886,\n",
            "          0.9963,  0.8155, -0.9757,  0.9408,  0.3790, -0.7740, -0.9186,  0.9968,\n",
            "          0.7925, -0.7898,  0.9988, -0.5178, -0.8663,  0.2891,  0.8891,  0.9506,\n",
            "         -1.0000,  0.9104, -0.8355, -0.9935,  0.6700,  0.6396, -0.9527, -0.7614,\n",
            "          0.9823, -0.9444,  0.8087,  0.9984,  0.9703,  0.9763, -0.9942, -1.0000,\n",
            "         -0.8340, -0.5687, -0.9750,  0.6773, -0.6387,  0.9998,  0.6693,  0.7848,\n",
            "          0.9546,  1.0000, -0.4181,  0.9871, -0.8660,  0.9233, -0.9993,  0.9760,\n",
            "          0.0438, -0.9990, -0.9436,  0.7045, -0.8399,  0.7600, -0.9532,  0.8906,\n",
            "          1.0000, -0.5355,  0.7785,  0.9580, -0.9523,  0.8972, -0.9456,  0.9998,\n",
            "         -1.0000,  0.9965,  0.9001,  0.0346,  0.9353,  0.1531, -0.7498, -0.8914,\n",
            "         -0.9297, -0.9911, -0.8186,  0.8623, -0.8037,  0.9722,  0.9867, -0.9786,\n",
            "         -1.0000, -0.5740,  0.3373,  0.8910, -0.8701, -0.9700,  0.9783, -0.9041,\n",
            "          0.9956, -0.9588, -0.9504, -0.9266, -0.9702, -0.5377,  0.9212,  0.9817,\n",
            "          0.9569,  0.9105, -0.7912, -0.8805, -0.7996, -0.9680,  0.7918,  0.5632,\n",
            "          0.9855,  0.9122,  0.9430,  0.9965,  0.5344, -0.7074,  0.7469, -0.9319,\n",
            "         -0.8447, -0.9999,  0.9999,  0.8368, -0.9659, -1.0000,  0.8880,  0.7516,\n",
            "         -0.5771,  0.7592, -0.9308, -0.9908, -0.8340,  0.9865, -1.0000, -0.4303,\n",
            "          0.8939, -0.6666,  0.7820, -0.9999, -0.3079,  0.9087, -0.8863,  0.7492,\n",
            "          1.0000, -0.9639, -0.9984, -0.9962, -0.3103,  0.9152,  0.8728, -0.9995,\n",
            "         -0.8977,  0.9898, -1.0000,  0.7384, -0.8304, -0.9236,  0.9040,  0.8244,\n",
            "          0.9932, -1.0000,  0.9503, -0.9337,  0.9754, -0.2047,  0.7380,  0.9186,\n",
            "          0.9838, -1.0000,  0.8970,  0.7024,  0.9739,  0.8749,  0.9339, -0.9305,\n",
            "         -0.9637, -0.9664,  0.9968,  0.9953, -0.9522,  0.9777,  1.0000, -0.6731,\n",
            "          0.9835,  0.1345, -0.9439, -0.9998, -0.9869, -0.9134,  0.7161, -0.9715]],\n",
            "       device='cuda:0')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training... :   0%|          | 0/127 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82592d0ddb6f4667848b15d4ddf63edb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2965,  1.0000,  0.7790,  ..., -0.8919,  0.7821, -0.9770],\n",
            "        [-0.1840,  1.0000,  0.9038,  ..., -0.4630,  0.2551, -0.8254],\n",
            "        [ 0.2368,  1.0000,  0.4167,  ..., -0.8145,  0.7180, -0.9716],\n",
            "        ...,\n",
            "        [ 0.0936,  1.0000,  0.8922,  ..., -0.6109,  0.0759, -0.8646],\n",
            "        [ 0.4546,  1.0000, -0.0855,  ..., -0.9144,  0.7833, -0.9599],\n",
            "        [ 0.1061,  1.0000,  0.8873,  ..., -0.8104,  0.1632, -0.9331]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3662,  1.0000, -0.0793,  ..., -0.9038,  0.8304, -0.9581],\n",
            "        [-0.4099,  1.0000,  0.8853,  ..., -0.7035, -0.0697, -0.8600],\n",
            "        [ 0.3520,  1.0000,  0.4817,  ..., -0.8998,  0.8135, -0.9835],\n",
            "        ...,\n",
            "        [ 0.0381,  1.0000,  0.9034,  ..., -0.8109,  0.2876, -0.8999],\n",
            "        [ 0.3216,  1.0000,  0.8777,  ..., -0.7097, -0.1018, -0.8857],\n",
            "        [ 0.4194,  1.0000,  0.7697,  ..., -0.8376,  0.8380, -0.9919]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3312,  1.0000,  0.1649,  ..., -0.8658,  0.8431, -0.9707],\n",
            "        [-0.2882,  1.0000,  0.8639,  ..., -0.6082, -0.1173, -0.8781],\n",
            "        [-0.0822,  1.0000,  0.8891,  ..., -0.1506,  0.3498, -0.8666],\n",
            "        ...,\n",
            "        [ 0.0214,  1.0000,  0.8819,  ..., -0.6523,  0.1961, -0.8098],\n",
            "        [-0.1477,  1.0000,  0.9060,  ..., -0.4371, -0.0199, -0.7649],\n",
            "        [-0.1375,  1.0000,  0.8958,  ..., -0.7624, -0.0191, -0.8629]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0515,  1.0000,  0.7657,  ..., -0.4922,  0.1400, -0.9081],\n",
            "        [-0.2421,  1.0000,  0.8637,  ..., -0.5021, -0.0479, -0.8994],\n",
            "        [ 0.1617,  1.0000,  0.5607,  ..., -0.8915,  0.8128, -0.9737],\n",
            "        ...,\n",
            "        [ 0.5452,  1.0000,  0.0771,  ..., -0.8740,  0.8115, -0.9670],\n",
            "        [-0.0684,  1.0000,  0.8298,  ..., -0.6795,  0.0688, -0.9448],\n",
            "        [-0.1569,  1.0000,  0.8614,  ..., -0.8494,  0.5922, -0.9610]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2309,  1.0000, -0.0013,  ..., -0.8908,  0.6994, -0.9590],\n",
            "        [ 0.1211,  1.0000,  0.8708,  ..., -0.8054,  0.7661, -0.9840],\n",
            "        [-0.0324,  1.0000,  0.7182,  ..., -0.9269,  0.7194, -0.9710],\n",
            "        ...,\n",
            "        [ 0.0604,  1.0000,  0.6263,  ..., -0.8649,  0.9028, -0.9889],\n",
            "        [ 0.1045,  1.0000,  0.5589,  ..., -0.8814,  0.8002, -0.9848],\n",
            "        [-0.4046,  1.0000,  0.8858,  ..., -0.6649,  0.2920, -0.8927]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1692,  1.0000,  0.6017,  ..., -0.7745,  0.5100, -0.9623],\n",
            "        [-0.3368,  1.0000,  0.8491,  ..., -0.7862,  0.6850, -0.9427],\n",
            "        [ 0.0078,  1.0000,  0.6342,  ..., -0.8318,  0.7532, -0.9749],\n",
            "        ...,\n",
            "        [ 0.1602,  1.0000,  0.8270,  ..., -0.8311,  0.3097, -0.9618],\n",
            "        [-0.0829,  1.0000,  0.8968,  ..., -0.5467,  0.2279, -0.8578],\n",
            "        [-0.0663,  1.0000,  0.7965,  ..., -0.8124,  0.7401, -0.9851]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1668,  1.0000,  0.8257,  ..., -0.8652,  0.7540, -0.9581],\n",
            "        [ 0.1574,  1.0000,  0.9298,  ..., -0.7097,  0.8048, -0.9541],\n",
            "        [-0.1764,  1.0000,  0.9144,  ..., -0.2585, -0.1111, -0.8552],\n",
            "        ...,\n",
            "        [-0.1064,  1.0000,  0.9453,  ..., -0.1484, -0.2912, -0.7543],\n",
            "        [ 0.1974,  1.0000,  0.8419,  ..., -0.7843,  0.7823, -0.9651],\n",
            "        [ 0.2971,  1.0000,  0.4084,  ..., -0.9589,  0.8932, -0.9576]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1910,  0.9997,  0.8718,  ..., -0.5594, -0.2229, -0.5748],\n",
            "        [-0.0542,  1.0000,  0.9256,  ..., -0.6363, -0.3101, -0.7976],\n",
            "        [ 0.0717,  1.0000,  0.8819,  ..., -0.3757, -0.1301, -0.7051],\n",
            "        ...,\n",
            "        [ 0.0754,  1.0000,  0.8632,  ..., -0.8120,  0.8320, -0.9702],\n",
            "        [ 0.0150,  1.0000,  0.8058,  ..., -0.8309,  0.6440, -0.9740],\n",
            "        [ 0.1093,  1.0000, -0.0082,  ..., -0.9011,  0.8296, -0.9733]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0494,  1.0000,  0.7837,  ..., -0.8641,  0.6319, -0.9655],\n",
            "        [-0.2122,  1.0000,  0.7190,  ..., -0.4255,  0.0841, -0.8814],\n",
            "        [-0.0582,  1.0000,  0.4181,  ..., -0.9009,  0.5843, -0.9717],\n",
            "        ...,\n",
            "        [ 0.0532,  1.0000,  0.2770,  ..., -0.8994,  0.8678, -0.9566],\n",
            "        [-0.0738,  1.0000,  0.9410,  ..., -0.7495,  0.5722, -0.9334],\n",
            "        [ 0.0258,  1.0000,  0.4920,  ..., -0.9120,  0.7829, -0.9728]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3413,  1.0000,  0.8974,  ..., -0.2613, -0.0823, -0.8441],\n",
            "        [ 0.1520,  1.0000,  0.8012,  ..., -0.7613,  0.3852, -0.9743],\n",
            "        [ 0.4182,  1.0000,  0.9029,  ..., -0.5958,  0.7228, -0.9904],\n",
            "        ...,\n",
            "        [-0.1306,  1.0000,  0.9041,  ..., -0.4617,  0.1421, -0.8338],\n",
            "        [-0.1659,  1.0000,  0.8693,  ..., -0.4873,  0.3366, -0.8873],\n",
            "        [ 0.3280,  1.0000,  0.6576,  ..., -0.8984,  0.8871, -0.9772]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1722,  1.0000,  0.7125,  ..., -0.9144,  0.7463, -0.9478],\n",
            "        [ 0.2717,  1.0000,  0.8465,  ..., -0.8163,  0.7257, -0.9601],\n",
            "        [ 0.2987,  1.0000,  0.7849,  ..., -0.8879,  0.6851, -0.9340],\n",
            "        ...,\n",
            "        [ 0.2772,  0.9999,  0.9227,  ..., -0.1438,  0.3671, -0.7535],\n",
            "        [ 0.0697,  1.0000,  0.8116,  ..., -0.8892,  0.5524, -0.9313],\n",
            "        [-0.0948,  1.0000,  0.9266,  ..., -0.5112,  0.4843, -0.8461]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 5.3283e-02,  1.0000e+00,  1.2794e-01,  ..., -9.3432e-01,\n",
            "          8.1555e-01, -9.4743e-01],\n",
            "        [ 3.3625e-02,  9.9999e-01,  8.8269e-01,  ..., -5.5535e-01,\n",
            "          2.6181e-01, -6.4102e-01],\n",
            "        [ 3.4921e-01,  1.0000e+00,  9.4115e-03,  ..., -9.0032e-01,\n",
            "          8.2826e-01, -9.5089e-01],\n",
            "        ...,\n",
            "        [ 1.3009e-02,  9.9952e-01,  6.9062e-01,  ..., -5.2559e-02,\n",
            "          3.4811e-01, -7.7821e-01],\n",
            "        [ 1.6666e-04,  1.0000e+00,  7.7024e-01,  ..., -9.0594e-01,\n",
            "          6.3970e-01, -9.5863e-01],\n",
            "        [ 2.0143e-01,  1.0000e+00,  8.7267e-01,  ..., -7.2314e-01,\n",
            "          7.2561e-01, -9.6896e-01]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2109,  1.0000,  0.9390,  ..., -0.5011,  0.4257, -0.8351],\n",
            "        [ 0.2184,  1.0000,  0.1945,  ..., -0.9279,  0.6995, -0.9478],\n",
            "        [ 0.6072,  1.0000,  0.7792,  ..., -0.8206,  0.6017, -0.9672],\n",
            "        ...,\n",
            "        [ 0.1963,  1.0000,  0.8986,  ..., -0.6654,  0.0260, -0.8401],\n",
            "        [ 0.0779,  1.0000,  0.9121,  ..., -0.8607,  0.3801, -0.8995],\n",
            "        [ 0.1841,  1.0000,  0.5983,  ..., -0.8407,  0.8447, -0.9883]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0264,  1.0000,  0.9019,  ..., -0.8183,  0.5469, -0.9739],\n",
            "        [ 0.0761,  1.0000,  0.8617,  ..., -0.4465, -0.0079, -0.8754],\n",
            "        [ 0.0965,  1.0000,  0.3475,  ..., -0.9055,  0.8045, -0.9679],\n",
            "        ...,\n",
            "        [ 0.3910,  1.0000,  0.9459,  ..., -0.0713,  0.2637, -0.8066],\n",
            "        [ 0.0270,  1.0000,  0.3314,  ..., -0.8592,  0.7564, -0.9616],\n",
            "        [ 0.0745,  1.0000,  0.9434,  ..., -0.2406, -0.0589, -0.8514]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0129,  1.0000,  0.8923,  ..., -0.7336,  0.5019, -0.9658],\n",
            "        [ 0.0854,  1.0000,  0.3812,  ..., -0.9016,  0.8634, -0.9818],\n",
            "        [ 0.3613,  1.0000,  0.9465,  ..., -0.6380,  0.1589, -0.8785],\n",
            "        ...,\n",
            "        [ 0.1538,  1.0000,  0.3231,  ..., -0.8704,  0.7549, -0.9661],\n",
            "        [ 0.2125,  1.0000,  0.8793,  ..., -0.7301,  0.8165, -0.9656],\n",
            "        [ 0.1630,  1.0000,  0.9248,  ..., -0.3209, -0.1346, -0.8450]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0752,  1.0000,  0.9231,  ..., -0.7466,  0.5315, -0.9558],\n",
            "        [ 0.2334,  1.0000,  0.0359,  ..., -0.8470,  0.8646, -0.9645],\n",
            "        [-0.0859,  1.0000,  0.8918,  ..., -0.6146,  0.2335, -0.7446],\n",
            "        ...,\n",
            "        [ 0.2781,  1.0000,  0.5294,  ..., -0.9087,  0.8884, -0.9678],\n",
            "        [ 0.1650,  1.0000,  0.2978,  ..., -0.9366,  0.8787, -0.9557],\n",
            "        [ 0.0476,  1.0000, -0.0837,  ..., -0.9076,  0.7308, -0.9504]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 3.6460e-01,  1.0000e+00,  4.6516e-03,  ..., -8.8741e-01,\n",
            "          7.2549e-01, -9.7631e-01],\n",
            "        [ 2.9891e-01,  1.0000e+00, -2.9542e-01,  ..., -8.7570e-01,\n",
            "          7.2011e-01, -9.2332e-01],\n",
            "        [ 8.5455e-02,  1.0000e+00,  8.7434e-01,  ..., -4.7859e-01,\n",
            "          1.8045e-01, -8.4013e-01],\n",
            "        ...,\n",
            "        [ 3.3841e-01,  9.9999e-01,  8.6284e-01,  ..., -9.3583e-02,\n",
            "         -5.9030e-02, -6.5510e-01],\n",
            "        [ 4.4627e-01,  1.0000e+00,  8.4691e-01,  ..., -9.1031e-01,\n",
            "          8.7006e-01, -9.7956e-01],\n",
            "        [ 5.4208e-04,  9.9998e-01,  8.7920e-01,  ..., -2.3220e-01,\n",
            "          5.5921e-02, -6.5128e-01]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0978,  1.0000,  0.9347,  ..., -0.6206,  0.5037, -0.9309],\n",
            "        [-0.0103,  1.0000,  0.8079,  ..., -0.7674,  0.6992, -0.9569],\n",
            "        [ 0.2015,  1.0000,  0.9379,  ...,  0.0940, -0.1362, -0.4996],\n",
            "        ...,\n",
            "        [-0.2414,  1.0000,  0.4783,  ..., -0.8916,  0.6166, -0.9494],\n",
            "        [-0.0560,  0.9999,  0.9503,  ..., -0.0902, -0.2222, -0.4283],\n",
            "        [ 0.2539,  1.0000,  0.5704,  ..., -0.9146,  0.7159, -0.9719]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0455,  1.0000,  0.8325,  ..., -0.8815,  0.8433, -0.9640],\n",
            "        [ 0.1741,  1.0000,  0.9427,  ..., -0.3940,  0.0464, -0.8965],\n",
            "        [ 0.1847,  1.0000,  0.6771,  ..., -0.8484,  0.7821, -0.9755],\n",
            "        ...,\n",
            "        [ 0.0449,  1.0000,  0.8800,  ..., -0.5750,  0.5797, -0.9058],\n",
            "        [ 0.2331,  1.0000,  0.7537,  ..., -0.8770,  0.6916, -0.9712],\n",
            "        [-0.0289,  1.0000,  0.8823,  ..., -0.7272,  0.4913, -0.6906]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2492,  1.0000,  0.1156,  ..., -0.8985,  0.8084, -0.9225],\n",
            "        [ 0.2380,  1.0000,  0.9136,  ..., -0.4723,  0.5026, -0.9386],\n",
            "        [ 0.1067,  1.0000,  0.9586,  ..., -0.6769,  0.5040, -0.9050],\n",
            "        ...,\n",
            "        [ 0.0699,  1.0000,  0.8660,  ..., -0.7607,  0.5738, -0.9459],\n",
            "        [ 0.3224,  1.0000,  0.9196,  ..., -0.2525,  0.1976, -0.9317],\n",
            "        [-0.1142,  1.0000,  0.3735,  ..., -0.8676,  0.7972, -0.9432]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1419,  1.0000,  0.6946,  ..., -0.7991,  0.8452, -0.9682],\n",
            "        [ 0.0167,  1.0000,  0.9468,  ...,  0.0265,  0.4653, -0.9302],\n",
            "        [-0.0574,  1.0000,  0.8901,  ..., -0.7622,  0.6566, -0.9159],\n",
            "        ...,\n",
            "        [-0.0461,  1.0000,  0.6089,  ..., -0.8639,  0.8501, -0.9749],\n",
            "        [-0.0039,  1.0000, -0.1742,  ..., -0.9469,  0.8321, -0.9139],\n",
            "        [-0.0462,  0.9999,  0.9229,  ...,  0.0351, -0.0346, -0.7233]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2267,  1.0000, -0.2609,  ..., -0.8881,  0.9055, -0.9457],\n",
            "        [ 0.1653,  1.0000,  0.1223,  ..., -0.8688,  0.8329, -0.9702],\n",
            "        [-0.0080,  1.0000,  0.8726,  ..., -0.7784,  0.5602, -0.9407],\n",
            "        ...,\n",
            "        [-0.1596,  1.0000,  0.6292,  ..., -0.8790,  0.7480, -0.9475],\n",
            "        [ 0.3884,  1.0000,  0.8903,  ..., -0.6068,  0.5476, -0.9655],\n",
            "        [ 0.0573,  1.0000,  0.8334,  ..., -0.7862,  0.7034, -0.9850]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1022,  1.0000,  0.8213,  ..., -0.8734,  0.7651, -0.9682],\n",
            "        [ 0.1698,  1.0000,  0.8485,  ..., -0.9049,  0.8033, -0.9544],\n",
            "        [-0.0107,  1.0000, -0.3432,  ..., -0.8177,  0.7841, -0.9142],\n",
            "        ...,\n",
            "        [ 0.0356,  1.0000,  0.0049,  ..., -0.9362,  0.7993, -0.9194],\n",
            "        [-0.0185,  1.0000, -0.0653,  ..., -0.7818,  0.7886, -0.9452],\n",
            "        [ 0.5365,  1.0000,  0.8948,  ..., -0.4723,  0.0959, -0.8839]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0627,  1.0000,  0.8968,  ..., -0.2326,  0.2031, -0.9388],\n",
            "        [ 0.2078,  1.0000,  0.8105,  ..., -0.0809, -0.3273, -0.7524],\n",
            "        [ 0.7838,  1.0000,  0.9259,  ...,  0.4476,  0.2227, -0.9744],\n",
            "        ...,\n",
            "        [ 0.1014,  1.0000, -0.2807,  ..., -0.9119,  0.7871, -0.9220],\n",
            "        [-0.1422,  1.0000,  0.9179,  ..., -0.1116, -0.1074, -0.7361],\n",
            "        [ 0.0478,  1.0000,  0.9458,  ..., -0.2995,  0.0662, -0.7958]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0655,  0.9990,  0.8621,  ..., -0.1286, -0.3453, -0.6965],\n",
            "        [ 0.0144,  1.0000,  0.8785,  ..., -0.1531, -0.2319, -0.7851],\n",
            "        [ 0.1360,  1.0000,  0.0813,  ..., -0.9023,  0.8190, -0.8634],\n",
            "        ...,\n",
            "        [ 0.1814,  1.0000,  0.8852,  ..., -0.8134,  0.4879, -0.9589],\n",
            "        [-0.0448,  0.9997,  0.8810,  ...,  0.0806, -0.1155, -0.5545],\n",
            "        [ 0.6230,  0.9998,  0.8943,  ...,  0.6948, -0.3258, -0.7712]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2119,  1.0000,  0.9097,  ..., -0.7382,  0.7071, -0.9889],\n",
            "        [ 0.0503,  1.0000,  0.9329,  ..., -0.2167,  0.4836, -0.8812],\n",
            "        [ 0.2690,  1.0000,  0.8995,  ..., -0.5764,  0.4749, -0.8132],\n",
            "        ...,\n",
            "        [ 0.0299,  1.0000,  0.8196,  ..., -0.0232, -0.6089, -0.6738],\n",
            "        [ 0.1559,  1.0000,  0.8271,  ..., -0.8173,  0.7771, -0.9810],\n",
            "        [ 0.3074,  1.0000,  0.2353,  ..., -0.8178,  0.9016, -0.9109]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1120,  1.0000,  0.0307,  ..., -0.9034,  0.8998, -0.9260],\n",
            "        [ 0.1131,  0.9999,  0.9268,  ...,  0.3084, -0.3838, -0.7632],\n",
            "        [ 0.0630,  1.0000,  0.7936,  ..., -0.5791,  0.3505, -0.9204],\n",
            "        ...,\n",
            "        [ 0.1044,  0.9999,  0.9121,  ..., -0.0299, -0.1021, -0.7395],\n",
            "        [-0.3990,  1.0000,  0.2237,  ..., -0.9097,  0.6917, -0.9048],\n",
            "        [-0.3638,  1.0000,  0.7927,  ..., -0.7917,  0.8028, -0.9691]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0177,  1.0000,  0.4924,  ..., -0.8108,  0.6828, -0.9615],\n",
            "        [-0.0857,  1.0000,  0.7263,  ..., -0.8707,  0.7044, -0.9745],\n",
            "        [ 0.0222,  1.0000,  0.7964,  ..., -0.6785,  0.1113, -0.9610],\n",
            "        ...,\n",
            "        [ 0.4880,  1.0000,  0.9156,  ...,  0.0958,  0.3923, -0.8697],\n",
            "        [-0.1837,  1.0000,  0.3271,  ..., -0.8844,  0.7886, -0.9241],\n",
            "        [ 0.2013,  1.0000,  0.1175,  ..., -0.8640,  0.8086, -0.9354]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2458,  1.0000,  0.9273,  ...,  0.0776,  0.0704, -0.9126],\n",
            "        [ 0.0942,  1.0000,  0.9142,  ..., -0.5827,  0.4820, -0.9625],\n",
            "        [-0.3115,  1.0000,  0.8513,  ..., -0.8680,  0.6985, -0.9714],\n",
            "        ...,\n",
            "        [-0.0681,  1.0000,  0.8481,  ..., -0.5144,  0.3411, -0.9373],\n",
            "        [ 0.3708,  1.0000,  0.8990,  ..., -0.5814, -0.0997, -0.9182],\n",
            "        [ 0.6128,  1.0000,  0.9076,  ...,  0.4937, -0.2170, -0.9106]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2752,  1.0000,  0.9536,  ..., -0.1090, -0.0075, -0.8882],\n",
            "        [-0.1127,  1.0000,  0.2643,  ..., -0.8595,  0.5683, -0.9489],\n",
            "        [ 0.0156,  1.0000, -0.4273,  ..., -0.9254,  0.7047, -0.8264],\n",
            "        ...,\n",
            "        [ 0.4280,  1.0000,  0.9089,  ..., -0.1712,  0.1581, -0.9028],\n",
            "        [-0.1815,  1.0000,  0.4833,  ..., -0.9512,  0.8601, -0.9448],\n",
            "        [ 0.4799,  1.0000,  0.9327,  ...,  0.1761, -0.0019, -0.8672]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0039,  1.0000,  0.0311,  ..., -0.9304,  0.8121, -0.8648],\n",
            "        [-0.0476,  1.0000,  0.8819,  ..., -0.7629,  0.6821, -0.9686],\n",
            "        [ 0.3663,  1.0000,  0.9233,  ..., -0.4499,  0.5435, -0.9545],\n",
            "        ...,\n",
            "        [-0.2044,  1.0000,  0.0950,  ..., -0.9043,  0.8308, -0.9055],\n",
            "        [-0.0818,  1.0000,  0.7919,  ..., -0.8708,  0.6496, -0.9635],\n",
            "        [-0.1717,  1.0000,  0.3114,  ..., -0.8841,  0.8901, -0.9605]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0215,  1.0000,  0.8558,  ..., -0.8485,  0.8741, -0.9824],\n",
            "        [ 0.4576,  1.0000,  0.9280,  ..., -0.2682,  0.3211, -0.9330],\n",
            "        [-0.1830,  1.0000,  0.5782,  ..., -0.8659,  0.6620, -0.9360],\n",
            "        ...,\n",
            "        [-0.3964,  1.0000,  0.7811,  ..., -0.8639,  0.6042, -0.9566],\n",
            "        [ 0.4355,  1.0000,  0.8891,  ..., -0.0780,  0.0828, -0.9156],\n",
            "        [ 0.3015,  1.0000,  0.9447,  ..., -0.3684,  0.0723, -0.8630]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3605,  1.0000,  0.9113,  ..., -0.3539,  0.6288, -0.9293],\n",
            "        [-0.2025,  1.0000,  0.6024,  ..., -0.8156,  0.4869, -0.9256],\n",
            "        [-0.0905,  1.0000,  0.9433,  ..., -0.5220,  0.4635, -0.8791],\n",
            "        ...,\n",
            "        [ 0.4520,  1.0000,  0.8269,  ..., -0.6209,  0.8984, -0.9836],\n",
            "        [ 0.1566,  1.0000, -0.3158,  ..., -0.9247,  0.7806, -0.8408],\n",
            "        [-0.0950,  1.0000, -0.3153,  ..., -0.9017,  0.8194, -0.7394]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1266,  1.0000,  0.1947,  ..., -0.9166,  0.8590, -0.9510],\n",
            "        [ 0.2260,  1.0000,  0.8822,  ..., -0.8209,  0.7957, -0.9769],\n",
            "        [ 0.1861,  1.0000,  0.8627,  ..., -0.7409,  0.7039, -0.9675],\n",
            "        ...,\n",
            "        [-0.2850,  1.0000, -0.1191,  ..., -0.9000,  0.8459, -0.9151],\n",
            "        [ 0.0597,  1.0000,  0.9365,  ..., -0.5590,  0.2396, -0.9594],\n",
            "        [ 0.2520,  1.0000,  0.9219,  ..., -0.0375,  0.1776, -0.9092]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3074,  1.0000,  0.8991,  ..., -0.4769,  0.0605, -0.9129],\n",
            "        [ 0.1259,  1.0000,  0.9081,  ..., -0.6233,  0.6709, -0.9352],\n",
            "        [ 0.1822,  1.0000,  0.2300,  ..., -0.8714,  0.7068, -0.9636],\n",
            "        ...,\n",
            "        [-0.0915,  1.0000,  0.1349,  ..., -0.9433,  0.7636, -0.8121],\n",
            "        [-0.0782,  1.0000,  0.8744,  ..., -0.7934,  0.7837, -0.9780],\n",
            "        [ 0.3790,  1.0000,  0.9019,  ..., -0.0054,  0.1445, -0.8748]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2434,  1.0000, -0.5789,  ..., -0.8472,  0.8281, -0.8643],\n",
            "        [ 0.0794,  1.0000, -0.3072,  ..., -0.9202,  0.7581, -0.8036],\n",
            "        [-0.0328,  1.0000, -0.5856,  ..., -0.8951,  0.6037, -0.8365],\n",
            "        ...,\n",
            "        [ 0.1354,  1.0000,  0.8640,  ..., -0.7052,  0.6436, -0.9521],\n",
            "        [-0.2197,  1.0000,  0.2712,  ..., -0.9296,  0.3833, -0.8958],\n",
            "        [-0.0592,  1.0000,  0.0835,  ..., -0.9075,  0.8743, -0.9077]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2776,  1.0000,  0.5733,  ..., -0.8254,  0.6591, -0.9157],\n",
            "        [ 0.1462,  1.0000,  0.7467,  ..., -0.8539,  0.7224, -0.9585],\n",
            "        [ 0.0859,  1.0000,  0.3650,  ..., -0.7839,  0.4867, -0.9527],\n",
            "        ...,\n",
            "        [ 0.3928,  1.0000,  0.8756,  ..., -0.2040,  0.1583, -0.9458],\n",
            "        [-0.3217,  1.0000,  0.5519,  ..., -0.8883,  0.7540, -0.9743],\n",
            "        [ 0.2777,  1.0000,  0.4797,  ..., -0.8352,  0.8316, -0.9720]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5074,  1.0000,  0.9266,  ..., -0.0410,  0.3874, -0.8697],\n",
            "        [ 0.1621,  1.0000,  0.8146,  ..., -0.7875,  0.7546, -0.9416],\n",
            "        [ 0.3133,  1.0000,  0.6168,  ..., -0.7846,  0.8274, -0.9750],\n",
            "        ...,\n",
            "        [ 0.4372,  1.0000,  0.8923,  ..., -0.6255,  0.7678, -0.9389],\n",
            "        [-0.0502,  1.0000, -0.4320,  ..., -0.9322,  0.7432, -0.8355],\n",
            "        [ 0.0479,  1.0000, -0.2457,  ..., -0.9069,  0.5933, -0.8887]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2947,  1.0000, -0.3006,  ..., -0.8998,  0.8482, -0.9268],\n",
            "        [ 0.5117,  1.0000,  0.8643,  ..., -0.7266,  0.3848, -0.9636],\n",
            "        [ 0.5845,  1.0000,  0.8140,  ...,  0.5511,  0.1252, -0.7896],\n",
            "        ...,\n",
            "        [ 0.4484,  1.0000,  0.9053,  ..., -0.1068,  0.5511, -0.7081],\n",
            "        [ 0.4794,  1.0000,  0.8542,  ...,  0.3564,  0.3908, -0.8171],\n",
            "        [ 0.6209,  1.0000,  0.8326,  ...,  0.1195,  0.0870, -0.7387]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5313,  1.0000,  0.9024,  ...,  0.1596, -0.1019, -0.5969],\n",
            "        [ 0.2806,  1.0000,  0.8827,  ..., -0.5892,  0.7193, -0.9087],\n",
            "        [ 0.3160,  1.0000,  0.8284,  ..., -0.7902,  0.6972, -0.9619],\n",
            "        ...,\n",
            "        [-0.1599,  1.0000, -0.3077,  ..., -0.8755,  0.6001, -0.9611],\n",
            "        [ 0.4943,  1.0000,  0.8999,  ..., -0.5216,  0.6748, -0.9698],\n",
            "        [ 0.1565,  1.0000, -0.3729,  ..., -0.9080,  0.7639, -0.8707]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7281,  1.0000,  0.8989,  ...,  0.4393,  0.0909, -0.7088],\n",
            "        [ 0.0558,  1.0000, -0.2011,  ..., -0.8898,  0.8052, -0.8262],\n",
            "        [ 0.1022,  1.0000, -0.4538,  ..., -0.7159,  0.8073, -0.8390],\n",
            "        ...,\n",
            "        [ 0.6654,  1.0000,  0.9345,  ...,  0.4761, -0.1069, -0.8597],\n",
            "        [ 0.6213,  1.0000,  0.9050,  ...,  0.2910,  0.0308, -0.8398],\n",
            "        [ 0.4777,  1.0000,  0.7563,  ...,  0.0179,  0.5274, -0.7845]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 7.4972e-01,  9.9999e-01,  8.9185e-01,  ...,  6.2885e-01,\n",
            "          1.6481e-02, -7.4867e-01],\n",
            "        [ 6.0055e-01,  9.9997e-01,  8.6596e-01,  ...,  4.5747e-01,\n",
            "         -8.9885e-02, -5.7656e-01],\n",
            "        [ 5.4945e-04,  9.9998e-01,  2.5643e-01,  ..., -7.9333e-01,\n",
            "          5.4018e-01, -8.4133e-01],\n",
            "        ...,\n",
            "        [ 4.6896e-01,  1.0000e+00,  9.3223e-01,  ..., -2.1245e-01,\n",
            "          2.4258e-01, -8.9075e-01],\n",
            "        [-5.0192e-02,  9.9993e-01,  7.8402e-01,  ..., -1.2402e-01,\n",
            "          3.3876e-01, -7.5602e-01],\n",
            "        [ 5.5471e-01,  1.0000e+00,  9.4908e-01,  ..., -2.5470e-01,\n",
            "          4.0763e-01, -9.2466e-01]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5470,  1.0000,  0.8794,  ...,  0.5365,  0.3939, -0.8750],\n",
            "        [ 0.4670,  1.0000,  0.8692,  ..., -0.4391,  0.6656, -0.9551],\n",
            "        [ 0.5483,  1.0000,  0.7528,  ..., -0.2364,  0.5342, -0.8260],\n",
            "        ...,\n",
            "        [ 0.3843,  1.0000,  0.5905,  ..., -0.8137,  0.5316, -0.9419],\n",
            "        [ 0.0904,  1.0000, -0.2461,  ..., -0.9243,  0.7770, -0.9247],\n",
            "        [ 0.5418,  1.0000,  0.8659,  ..., -0.7089,  0.8342, -0.9110]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6805,  1.0000,  0.9157,  ...,  0.2138,  0.6855, -0.8853],\n",
            "        [ 0.6186,  1.0000,  0.8921,  ...,  0.7483, -0.1607, -0.7417],\n",
            "        [-0.0968,  1.0000,  0.3765,  ..., -0.8700,  0.6347, -0.9662],\n",
            "        ...,\n",
            "        [ 0.0552,  1.0000, -0.5769,  ..., -0.8666,  0.6716, -0.7942],\n",
            "        [ 0.6486,  1.0000,  0.8413,  ...,  0.4454, -0.0917, -0.7178],\n",
            "        [ 0.0591,  1.0000, -0.3549,  ..., -0.9099,  0.8720, -0.8865]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6153,  1.0000,  0.8775,  ...,  0.7003,  0.1639, -0.6117],\n",
            "        [ 0.6370,  1.0000,  0.9024,  ...,  0.6826, -0.3136, -0.6186],\n",
            "        [ 0.3419,  1.0000,  0.8699,  ..., -0.8133,  0.8111, -0.9757],\n",
            "        ...,\n",
            "        [ 0.6806,  1.0000,  0.8444,  ...,  0.5618, -0.0066, -0.7950],\n",
            "        [-0.1138,  1.0000, -0.4467,  ..., -0.9095,  0.6056, -0.8393],\n",
            "        [ 0.7547,  1.0000,  0.7997,  ...,  0.6518, -0.1234, -0.7705]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0642,  1.0000,  0.0851,  ..., -0.8379,  0.8912, -0.8726],\n",
            "        [ 0.5010,  1.0000,  0.7441,  ..., -0.1420,  0.5233, -0.8760],\n",
            "        [-0.0012,  1.0000,  0.8917,  ...,  0.5266,  0.3364, -0.8640],\n",
            "        ...,\n",
            "        [ 0.3339,  1.0000,  0.3971,  ..., -0.8740,  0.9274, -0.9641],\n",
            "        [-0.0784,  1.0000,  0.6511,  ..., -0.9416,  0.5713, -0.9274],\n",
            "        [ 0.2836,  1.0000, -0.3154,  ..., -0.8533,  0.8442, -0.8785]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2449,  1.0000,  0.6248,  ..., -0.3503,  0.5879, -0.7855],\n",
            "        [ 0.7128,  1.0000,  0.8824,  ...,  0.4634, -0.1603, -0.7006],\n",
            "        [-0.5340,  1.0000, -0.0087,  ..., -0.8298,  0.7883, -0.7885],\n",
            "        ...,\n",
            "        [ 0.6699,  1.0000,  0.5975,  ..., -0.8769,  0.7898, -0.9836],\n",
            "        [ 0.3170,  1.0000,  0.7840,  ..., -0.3366,  0.5345, -0.9531],\n",
            "        [-0.0139,  1.0000, -0.2178,  ..., -0.9047,  0.6323, -0.8387]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1224,  1.0000, -0.4302,  ..., -0.9283,  0.8631, -0.9027],\n",
            "        [ 0.7273,  1.0000,  0.8378,  ...,  0.6830,  0.0476, -0.7789],\n",
            "        [ 0.2522,  1.0000, -0.4316,  ..., -0.8889,  0.9104, -0.8992],\n",
            "        ...,\n",
            "        [ 0.4786,  1.0000,  0.7943,  ...,  0.4573,  0.0722, -0.7424],\n",
            "        [ 0.2019,  1.0000,  0.7417,  ..., -0.7589,  0.6894, -0.9745],\n",
            "        [ 0.2950,  1.0000,  0.8798,  ..., -0.5112,  0.4888, -0.9525]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0738,  1.0000, -0.2797,  ..., -0.8375,  0.5664, -0.4706],\n",
            "        [ 0.4556,  1.0000,  0.8541,  ...,  0.5995,  0.1072, -0.8524],\n",
            "        [ 0.5437,  1.0000,  0.8484,  ...,  0.3580,  0.1493, -0.7075],\n",
            "        ...,\n",
            "        [ 0.4831,  1.0000,  0.9210,  ..., -0.1376,  0.3482, -0.7674],\n",
            "        [-0.0691,  1.0000, -0.3219,  ..., -0.8841,  0.7180, -0.8042],\n",
            "        [ 0.3967,  1.0000, -0.2045,  ..., -0.9081,  0.7791, -0.9420]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0790,  1.0000,  0.8941,  ..., -0.7771,  0.6311, -0.9545],\n",
            "        [ 0.4988,  1.0000,  0.7335,  ..., -0.1396,  0.1028, -0.8513],\n",
            "        [ 0.2432,  1.0000,  0.6541,  ..., -0.7590,  0.7213, -0.9613],\n",
            "        ...,\n",
            "        [ 0.6883,  1.0000,  0.8383,  ...,  0.7596,  0.0179, -0.7674],\n",
            "        [ 0.5674,  1.0000,  0.7227,  ..., -0.7081,  0.4167, -0.9193],\n",
            "        [ 0.7265,  1.0000,  0.8447,  ...,  0.7655, -0.1132, -0.5631]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1523,  1.0000,  0.5882,  ..., -0.6284,  0.6509, -0.9203],\n",
            "        [ 0.3691,  1.0000,  0.6972,  ..., -0.6293,  0.3826, -0.9122],\n",
            "        [ 0.6515,  1.0000,  0.8778,  ..., -0.0082,  0.1594, -0.8555],\n",
            "        ...,\n",
            "        [ 0.0623,  1.0000, -0.2860,  ..., -0.8937,  0.7485, -0.8097],\n",
            "        [ 0.3137,  1.0000, -0.5986,  ..., -0.8384,  0.7981, -0.8641],\n",
            "        [-0.1187,  1.0000, -0.2763,  ..., -0.8288,  0.8554, -0.7004]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4150,  1.0000,  0.8769,  ..., -0.4318,  0.8596, -0.8657],\n",
            "        [ 0.2551,  1.0000,  0.8612,  ..., -0.8823,  0.6776, -0.9078],\n",
            "        [-0.3729,  1.0000, -0.2538,  ..., -0.8125,  0.7328, -0.6742],\n",
            "        ...,\n",
            "        [-0.0396,  1.0000, -0.3393,  ..., -0.8810,  0.8247, -0.8550],\n",
            "        [ 0.5622,  1.0000,  0.8662,  ...,  0.8590, -0.0142, -0.6581],\n",
            "        [ 0.7599,  1.0000,  0.8699,  ...,  0.4719,  0.3006, -0.7961]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7525,  1.0000,  0.9161,  ...,  0.5225,  0.3271, -0.8653],\n",
            "        [ 0.5908,  1.0000,  0.8808,  ...,  0.6098,  0.1465, -0.7668],\n",
            "        [ 0.3901,  1.0000, -0.3750,  ..., -0.8303,  0.8974, -0.9635],\n",
            "        ...,\n",
            "        [ 0.7174,  1.0000,  0.8652,  ...,  0.7152,  0.0418, -0.6743],\n",
            "        [-0.0149,  1.0000, -0.3848,  ..., -0.7933,  0.8416, -0.8542],\n",
            "        [ 0.1839,  1.0000, -0.5143,  ..., -0.8995,  0.7786, -0.9028]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2675,  1.0000, -0.5459,  ..., -0.9159,  0.7296, -0.7556],\n",
            "        [ 0.6227,  0.9999,  0.7815,  ...,  0.7477, -0.0437, -0.5486],\n",
            "        [ 0.6470,  1.0000,  0.7915,  ...,  0.5780,  0.0445, -0.4663],\n",
            "        ...,\n",
            "        [ 0.1161,  1.0000,  0.3485,  ..., -0.8015,  0.6055, -0.9658],\n",
            "        [ 0.7307,  1.0000,  0.7855,  ..., -0.3113,  0.6232, -0.9331],\n",
            "        [ 0.1782,  1.0000, -0.3574,  ..., -0.7702,  0.7785, -0.7013]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7089,  1.0000,  0.8880,  ..., -0.3781,  0.5683, -0.9577],\n",
            "        [ 0.5523,  1.0000,  0.8481,  ...,  0.5877,  0.0954, -0.6747],\n",
            "        [ 0.4413,  1.0000, -0.5119,  ..., -0.7098,  0.8291, -0.9005],\n",
            "        ...,\n",
            "        [ 0.1503,  1.0000, -0.2794,  ..., -0.8933,  0.7431, -0.7601],\n",
            "        [-0.3710,  1.0000, -0.4743,  ..., -0.8381,  0.6859, -0.7231],\n",
            "        [ 0.0619,  1.0000, -0.3756,  ..., -0.9433,  0.7390, -0.8767]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6868,  0.9998,  0.8771,  ...,  0.8646, -0.0890, -0.5382],\n",
            "        [-0.0267,  1.0000, -0.5893,  ..., -0.8944,  0.6515, -0.7938],\n",
            "        [ 0.5320,  1.0000,  0.8724,  ...,  0.5245,  0.3687, -0.6776],\n",
            "        ...,\n",
            "        [ 0.6081,  1.0000,  0.8488,  ...,  0.6407, -0.1549, -0.6278],\n",
            "        [-0.2925,  1.0000, -0.3024,  ..., -0.8740,  0.7025, -0.6337],\n",
            "        [ 0.1798,  1.0000,  0.8516,  ..., -0.2380,  0.1868, -0.9040]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7100,  1.0000,  0.8612,  ...,  0.8124, -0.1870, -0.4761],\n",
            "        [ 0.4887,  1.0000,  0.5160,  ...,  0.0015,  0.6497, -0.7683],\n",
            "        [ 0.5941,  1.0000,  0.8533,  ...,  0.7285, -0.2227, -0.6323],\n",
            "        ...,\n",
            "        [ 0.6112,  0.9999,  0.8031,  ...,  0.7904, -0.0552, -0.4468],\n",
            "        [ 0.1725,  1.0000,  0.1855,  ..., -0.8143,  0.8288, -0.9039],\n",
            "        [-0.0402,  1.0000, -0.6306,  ..., -0.8885,  0.6888, -0.6823]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.8502,  1.0000,  0.8252,  ...,  0.0214,  0.0823, -0.9544],\n",
            "        [ 0.3318,  0.9988,  0.8760,  ...,  0.5949, -0.4514, -0.5349],\n",
            "        [ 0.0283,  1.0000, -0.3427,  ..., -0.8907,  0.8415, -0.9457],\n",
            "        ...,\n",
            "        [-0.2063,  1.0000,  0.0063,  ..., -0.9094,  0.5532, -0.7368],\n",
            "        [ 0.2649,  1.0000,  0.7826,  ..., -0.3828,  0.5091, -0.9726],\n",
            "        [ 0.8031,  1.0000,  0.8429,  ...,  0.7039,  0.1780, -0.6977]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4271,  1.0000,  0.7029,  ..., -0.6319,  0.7467, -0.9316],\n",
            "        [ 0.1876,  1.0000,  0.3733,  ..., -0.8731,  0.7745, -0.8321],\n",
            "        [ 0.7258,  0.9975,  0.8635,  ...,  0.8320, -0.0552, -0.4075],\n",
            "        ...,\n",
            "        [-0.0573,  1.0000, -0.5762,  ..., -0.8551,  0.6618, -0.6983],\n",
            "        [ 0.6409,  1.0000,  0.8643,  ...,  0.3723,  0.1868, -0.7272],\n",
            "        [ 0.1172,  1.0000, -0.4886,  ..., -0.8951,  0.6928, -0.7597]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5211,  0.9999,  0.8072,  ...,  0.5276, -0.1021, -0.5520],\n",
            "        [ 0.0256,  1.0000,  0.6094,  ..., -0.7499,  0.8339, -0.9075],\n",
            "        [ 0.6016,  0.9997,  0.8774,  ...,  0.5979, -0.3606, -0.5736],\n",
            "        ...,\n",
            "        [ 0.6773,  1.0000,  0.8549,  ...,  0.5372, -0.2360, -0.5735],\n",
            "        [ 0.8010,  1.0000,  0.8474,  ...,  0.5560,  0.1111, -0.7648],\n",
            "        [ 0.7622,  1.0000,  0.8765,  ...,  0.8552, -0.1865, -0.6497]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4447,  1.0000,  0.7664,  ..., -0.0827,  0.7329, -0.9153],\n",
            "        [ 0.1557,  1.0000,  0.2284,  ..., -0.6448,  0.7039, -0.9583],\n",
            "        [ 0.1990,  1.0000, -0.4256,  ..., -0.8333,  0.6204, -0.7211],\n",
            "        ...,\n",
            "        [ 0.2434,  1.0000,  0.4535,  ..., -0.8604,  0.7676, -0.9300],\n",
            "        [-0.1370,  1.0000, -0.5589,  ..., -0.8175,  0.7037, -0.5397],\n",
            "        [-0.0651,  1.0000, -0.0992,  ..., -0.9022,  0.6352, -0.9509]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6248,  1.0000,  0.8346,  ...,  0.2404,  0.3189, -0.6104],\n",
            "        [ 0.0771,  1.0000, -0.3610,  ..., -0.7352,  0.6375, -0.7460],\n",
            "        [ 0.2849,  1.0000,  0.7694,  ..., -0.7306,  0.3325, -0.9045],\n",
            "        ...,\n",
            "        [ 0.7437,  1.0000,  0.8968,  ...,  0.5182, -0.1531, -0.6261],\n",
            "        [ 0.5907,  1.0000,  0.8431,  ...,  0.5844, -0.0147, -0.6144],\n",
            "        [-0.1569,  1.0000, -0.5838,  ..., -0.8527,  0.5127, -0.6799]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6415,  1.0000,  0.8840,  ...,  0.7710, -0.2757, -0.4340],\n",
            "        [ 0.0625,  1.0000,  0.5986,  ..., -0.7675,  0.7332, -0.8769],\n",
            "        [ 0.4544,  1.0000,  0.8286,  ...,  0.5804, -0.2959, -0.4867],\n",
            "        ...,\n",
            "        [ 0.6212,  1.0000,  0.8475,  ...,  0.6424, -0.3209, -0.6598],\n",
            "        [ 0.5506,  1.0000,  0.8257,  ...,  0.5079,  0.3590, -0.6441],\n",
            "        [ 0.6728,  0.9997,  0.8431,  ...,  0.6857, -0.4370, -0.4450]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6043,  0.9998,  0.8502,  ...,  0.4787, -0.4461, -0.4397],\n",
            "        [-0.1548,  1.0000,  0.3402,  ..., -0.4279,  0.8243, -0.9497],\n",
            "        [ 0.2618,  1.0000,  0.5411,  ..., -0.8029,  0.8076, -0.9790],\n",
            "        ...,\n",
            "        [ 0.5855,  1.0000,  0.8401,  ...,  0.5674, -0.2886, -0.6105],\n",
            "        [ 0.4945,  1.0000,  0.6633,  ...,  0.5123,  0.0555, -0.5864],\n",
            "        [ 0.6427,  1.0000,  0.7875,  ...,  0.1779,  0.0580, -0.6857]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4798,  1.0000,  0.6145,  ...,  0.2605, -0.1333, -0.8134],\n",
            "        [ 0.2428,  1.0000,  0.3304,  ..., -0.8419,  0.4595, -0.9539],\n",
            "        [-0.3532,  1.0000, -0.6021,  ..., -0.8869,  0.7583, -0.6276],\n",
            "        ...,\n",
            "        [ 0.2387,  1.0000, -0.2254,  ..., -0.6925,  0.7602, -0.6972],\n",
            "        [ 0.5105,  1.0000,  0.7180,  ...,  0.3136,  0.4663, -0.8291],\n",
            "        [ 0.4480,  1.0000,  0.6786,  ..., -0.5202,  0.5871, -0.9610]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5759,  1.0000,  0.9010,  ...,  0.6070, -0.1448, -0.6262],\n",
            "        [-0.4729,  1.0000, -0.5411,  ..., -0.8692,  0.4697, -0.7075],\n",
            "        [-0.1887,  1.0000, -0.5318,  ..., -0.8922,  0.4967, -0.5865],\n",
            "        ...,\n",
            "        [ 0.2583,  1.0000,  0.7516,  ..., -0.4558,  0.0514, -0.8517],\n",
            "        [ 0.6001,  1.0000,  0.8606,  ...,  0.7253,  0.1599, -0.7950],\n",
            "        [ 0.5314,  1.0000,  0.8537,  ...,  0.6196, -0.1314, -0.7101]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5124,  1.0000,  0.8016,  ...,  0.0572, -0.0836, -0.7780],\n",
            "        [ 0.5110,  1.0000,  0.7739,  ...,  0.0047,  0.5319, -0.8437],\n",
            "        [-0.3222,  1.0000, -0.4331,  ..., -0.8557,  0.6400, -0.6124],\n",
            "        ...,\n",
            "        [-0.2667,  1.0000, -0.7459,  ..., -0.8185,  0.4234, -0.4596],\n",
            "        [ 0.5582,  1.0000,  0.6859,  ...,  0.1940, -0.1623, -0.6187],\n",
            "        [ 0.6754,  1.0000,  0.8415,  ...,  0.4762, -0.1810, -0.6146]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2977,  1.0000, -0.2750,  ..., -0.8555,  0.7918, -0.9393],\n",
            "        [ 0.4635,  1.0000,  0.8209,  ..., -0.5463,  0.6987, -0.9825],\n",
            "        [-0.4123,  0.9999, -0.4840,  ..., -0.8512,  0.7336, -0.3752],\n",
            "        ...,\n",
            "        [ 0.4520,  1.0000,  0.7595,  ..., -0.6740,  0.6394, -0.9644],\n",
            "        [-0.1694,  1.0000, -0.2746,  ..., -0.9076,  0.6229, -0.8777],\n",
            "        [ 0.0953,  1.0000,  0.6003,  ..., -0.8911,  0.7202, -0.9175]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6576,  1.0000,  0.8683,  ...,  0.1393,  0.3162, -0.8866],\n",
            "        [ 0.4896,  1.0000,  0.6668,  ..., -0.7090,  0.5482, -0.9079],\n",
            "        [-0.1265,  1.0000, -0.6272,  ..., -0.9348,  0.8161, -0.7349],\n",
            "        ...,\n",
            "        [ 0.4936,  1.0000,  0.7406,  ...,  0.3427, -0.2052, -0.7012],\n",
            "        [ 0.6634,  1.0000,  0.7939,  ..., -0.2558,  0.5289, -0.8604],\n",
            "        [-0.4314,  1.0000, -0.0499,  ..., -0.8385,  0.5539, -0.7676]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6562,  1.0000,  0.6888,  ..., -0.3932,  0.5529, -0.9551],\n",
            "        [ 0.1909,  1.0000,  0.0866,  ..., -0.8986,  0.7861, -0.9174],\n",
            "        [ 0.0834,  1.0000,  0.6611,  ..., -0.7270,  0.8967, -0.9863],\n",
            "        ...,\n",
            "        [-0.3229,  0.9999, -0.5034,  ..., -0.8826,  0.5952, -0.5038],\n",
            "        [ 0.2607,  1.0000,  0.3188,  ..., -0.8700,  0.7546, -0.9270],\n",
            "        [-0.0177,  1.0000, -0.5708,  ..., -0.8342,  0.3975, -0.8266]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4247,  1.0000,  0.7785,  ..., -0.2171,  0.1069, -0.8124],\n",
            "        [ 0.5230,  1.0000,  0.8511,  ..., -0.3338,  0.3478, -0.9023],\n",
            "        [-0.2174,  1.0000,  0.1162,  ..., -0.8874,  0.7520, -0.9498],\n",
            "        ...,\n",
            "        [-0.1074,  1.0000, -0.3842,  ..., -0.8415,  0.8694, -0.9032],\n",
            "        [ 0.0612,  1.0000, -0.2544,  ..., -0.8762,  0.7351, -0.8567],\n",
            "        [ 0.4429,  1.0000,  0.7141,  ..., -0.6275,  0.4255, -0.8713]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1004,  1.0000, -0.4844,  ..., -0.9110,  0.6133, -0.9181],\n",
            "        [ 0.0753,  1.0000, -0.2278,  ..., -0.8422,  0.5316, -0.8135],\n",
            "        [ 0.5242,  1.0000,  0.7559,  ..., -0.3983,  0.5848, -0.9639],\n",
            "        ...,\n",
            "        [ 0.0029,  1.0000, -0.6214,  ..., -0.8856,  0.5835, -0.5555],\n",
            "        [ 0.3016,  1.0000,  0.7630,  ..., -0.8330,  0.6029, -0.9690],\n",
            "        [ 0.5183,  1.0000,  0.3745,  ..., -0.6811,  0.7265, -0.9570]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7229,  1.0000,  0.9036,  ..., -0.1308,  0.1567, -0.9069],\n",
            "        [ 0.6366,  1.0000,  0.8719,  ..., -0.2190,  0.1627, -0.9586],\n",
            "        [-0.0783,  1.0000, -0.5849,  ..., -0.8782,  0.6207, -0.7348],\n",
            "        ...,\n",
            "        [ 0.6181,  1.0000,  0.8501,  ..., -0.1027,  0.4425, -0.9230],\n",
            "        [ 0.5862,  1.0000,  0.8915,  ..., -0.0500, -0.0981, -0.8122],\n",
            "        [ 0.6536,  1.0000,  0.8563,  ..., -0.2278,  0.3452, -0.9378]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6182,  1.0000,  0.8929,  ..., -0.2617,  0.2398, -0.8395],\n",
            "        [ 0.5895,  1.0000,  0.8566,  ..., -0.4240,  0.4516, -0.9195],\n",
            "        [ 0.5732,  1.0000,  0.7912,  ..., -0.3546,  0.5014, -0.9388],\n",
            "        ...,\n",
            "        [ 0.6360,  1.0000,  0.8029,  ..., -0.1487,  0.1188, -0.7608],\n",
            "        [ 0.2470,  1.0000,  0.4014,  ..., -0.8578,  0.7448, -0.9570],\n",
            "        [ 0.1601,  1.0000,  0.0076,  ..., -0.9156,  0.6952, -0.9166]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2690,  1.0000, -0.7322,  ..., -0.8525,  0.2835, -0.6363],\n",
            "        [ 0.2923,  1.0000,  0.7075,  ..., -0.7882,  0.7080, -0.9318],\n",
            "        [ 0.4119,  1.0000,  0.7992,  ..., -0.2481,  0.4921, -0.9335],\n",
            "        ...,\n",
            "        [ 0.2887,  1.0000,  0.8309,  ..., -0.1704,  0.2730, -0.8919],\n",
            "        [ 0.1397,  1.0000,  0.8343,  ...,  0.0111,  0.0070, -0.6674],\n",
            "        [ 0.6147,  1.0000,  0.9189,  ...,  0.4984,  0.2158, -0.9033]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0364,  1.0000, -0.1821,  ..., -0.7855,  0.6387, -0.8518],\n",
            "        [ 0.4940,  1.0000,  0.4765,  ..., -0.8591,  0.6194, -0.9425],\n",
            "        [-0.0346,  1.0000, -0.4395,  ..., -0.9389,  0.5735, -0.8935],\n",
            "        ...,\n",
            "        [ 0.2389,  1.0000,  0.0540,  ..., -0.7915,  0.8098, -0.8778],\n",
            "        [ 0.5544,  1.0000,  0.8567,  ..., -0.4336,  0.7381, -0.9526],\n",
            "        [ 0.5397,  1.0000,  0.9049,  ..., -0.2990,  0.5053, -0.8716]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6272,  1.0000,  0.8511,  ...,  0.1758,  0.1693, -0.8733],\n",
            "        [ 0.4182,  1.0000,  0.6828,  ..., -0.7787,  0.3792, -0.9401],\n",
            "        [ 0.5265,  1.0000,  0.7945,  ..., -0.5726,  0.7348, -0.9647],\n",
            "        ...,\n",
            "        [ 0.6996,  1.0000,  0.8059,  ..., -0.1501,  0.3874, -0.9451],\n",
            "        [-0.0965,  1.0000, -0.4617,  ..., -0.9219,  0.5348, -0.8664],\n",
            "        [ 0.6981,  1.0000,  0.8712,  ...,  0.2379,  0.2556, -0.8932]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6420,  1.0000,  0.8188,  ..., -0.5680,  0.3731, -0.9585],\n",
            "        [ 0.4855,  1.0000,  0.8358,  ..., -0.4113,  0.4956, -0.9146],\n",
            "        [ 0.4532,  1.0000,  0.8296,  ..., -0.2099,  0.2822, -0.9095],\n",
            "        ...,\n",
            "        [-0.2965,  1.0000, -0.0733,  ..., -0.7844,  0.2592, -0.8492],\n",
            "        [ 0.1149,  1.0000, -0.3273,  ..., -0.8771,  0.4411, -0.8265],\n",
            "        [-0.1034,  1.0000, -0.6235,  ..., -0.9062,  0.5347, -0.7661]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5852,  1.0000,  0.8576,  ..., -0.0208,  0.2906, -0.8530],\n",
            "        [ 0.6724,  1.0000,  0.8490,  ..., -0.1290,  0.3747, -0.9355],\n",
            "        [ 0.6661,  1.0000,  0.8240,  ...,  0.1498,  0.3940, -0.9108],\n",
            "        ...,\n",
            "        [ 0.3399,  1.0000,  0.5688,  ..., -0.4848,  0.8315, -0.9414],\n",
            "        [ 0.7212,  1.0000,  0.8812,  ...,  0.1864,  0.5502, -0.9051],\n",
            "        [ 0.6840,  1.0000,  0.8844,  ...,  0.1670, -0.0493, -0.8390]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5714,  1.0000, -0.4052,  ..., -0.8130,  0.6700, -0.8488],\n",
            "        [ 0.5446,  1.0000,  0.6754,  ..., -0.6670,  0.4150, -0.9298],\n",
            "        [-0.1353,  1.0000, -0.3675,  ..., -0.9227,  0.6340, -0.8641],\n",
            "        ...,\n",
            "        [ 0.5150,  1.0000,  0.9046,  ..., -0.6565,  0.5697, -0.9487],\n",
            "        [ 0.7233,  1.0000,  0.8618,  ..., -0.4526,  0.4335, -0.9482],\n",
            "        [ 0.2388,  1.0000, -0.2331,  ..., -0.8479,  0.4838, -0.8544]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7221,  1.0000,  0.8331,  ...,  0.0591,  0.3904, -0.9184],\n",
            "        [ 0.7285,  1.0000,  0.9111,  ..., -0.2447,  0.5459, -0.9575],\n",
            "        [-0.0283,  1.0000, -0.2088,  ..., -0.9007,  0.5018, -0.7815],\n",
            "        ...,\n",
            "        [ 0.5503,  1.0000,  0.8686,  ..., -0.5778,  0.6387, -0.9692],\n",
            "        [ 0.6053,  1.0000,  0.8472,  ..., -0.1354,  0.4848, -0.9413],\n",
            "        [-0.2203,  1.0000, -0.5184,  ..., -0.8496,  0.2976, -0.7075]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2241,  1.0000, -0.3332,  ..., -0.9353,  0.3368, -0.6695],\n",
            "        [ 0.0846,  1.0000,  0.2180,  ..., -0.8366,  0.6125, -0.9200],\n",
            "        [ 0.0736,  1.0000,  0.5741,  ..., -0.5273,  0.5431, -0.9140],\n",
            "        ...,\n",
            "        [ 0.8027,  1.0000,  0.9265,  ...,  0.0104,  0.4561, -0.9259],\n",
            "        [ 0.6736,  1.0000,  0.8387,  ..., -0.3978,  0.5657, -0.9327],\n",
            "        [ 0.3547,  1.0000,  0.5316,  ..., -0.8210,  0.6465, -0.8596]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3934,  0.9999, -0.7950,  ..., -0.9123,  0.5311, -0.1209],\n",
            "        [-0.3341,  1.0000, -0.4572,  ..., -0.8727,  0.3449, -0.7623],\n",
            "        [ 0.4506,  1.0000,  0.8606,  ..., -0.1289,  0.4279, -0.8601],\n",
            "        ...,\n",
            "        [ 0.4607,  1.0000,  0.9224,  ..., -0.4151,  0.6107, -0.9538],\n",
            "        [-0.0716,  1.0000, -0.3578,  ..., -0.8201,  0.3026, -0.8039],\n",
            "        [ 0.4900,  1.0000,  0.8065,  ..., -0.6940,  0.6921, -0.9550]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7792,  1.0000,  0.8474,  ..., -0.0425,  0.3644, -0.9578],\n",
            "        [ 0.5956,  1.0000,  0.8316,  ...,  0.0596,  0.7098, -0.9415],\n",
            "        [ 0.5543,  1.0000,  0.8114,  ..., -0.7860,  0.7078, -0.9621],\n",
            "        ...,\n",
            "        [ 0.3721,  1.0000,  0.3896,  ..., -0.8512,  0.7157, -0.9174],\n",
            "        [ 0.2678,  1.0000,  0.2400,  ..., -0.7492,  0.7742, -0.9703],\n",
            "        [-0.0862,  0.9999, -0.6881,  ..., -0.9297,  0.2750, -0.4175]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7589,  1.0000,  0.8616,  ...,  0.2851,  0.4037, -0.9597],\n",
            "        [ 0.5395,  1.0000,  0.8470,  ..., -0.0438,  0.4914, -0.9142],\n",
            "        [ 0.7618,  1.0000,  0.8171,  ...,  0.0598,  0.7804, -0.9679],\n",
            "        ...,\n",
            "        [ 0.6886,  1.0000,  0.8156,  ..., -0.3882,  0.2262, -0.8969],\n",
            "        [-0.0290,  1.0000,  0.0818,  ..., -0.7656,  0.4015, -0.9272],\n",
            "        [ 0.8206,  1.0000,  0.8705,  ...,  0.2819,  0.0212, -0.8391]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0727,  1.0000, -0.3151,  ..., -0.9075,  0.3729, -0.8340],\n",
            "        [-0.1848,  0.9998, -0.7208,  ..., -0.8974,  0.6092, -0.4090],\n",
            "        [-0.1431,  1.0000, -0.5045,  ..., -0.9291,  0.2739, -0.5720],\n",
            "        ...,\n",
            "        [ 0.6670,  1.0000,  0.9199,  ...,  0.4859,  0.0355, -0.8547],\n",
            "        [ 0.7279,  1.0000,  0.8363,  ..., -0.2550,  0.4111, -0.9616],\n",
            "        [ 0.7257,  1.0000,  0.9240,  ...,  0.4970, -0.1430, -0.8053]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4885,  1.0000,  0.1602,  ..., -0.7784,  0.6186, -0.8753],\n",
            "        [ 0.7656,  1.0000,  0.8397,  ...,  0.3328,  0.1051, -0.8943],\n",
            "        [-0.1503,  1.0000, -0.4637,  ..., -0.8690,  0.4010, -0.6638],\n",
            "        ...,\n",
            "        [ 0.7493,  1.0000,  0.8643,  ...,  0.2965,  0.2340, -0.8954],\n",
            "        [ 0.7905,  1.0000,  0.9519,  ...,  0.2913,  0.5645, -0.9787],\n",
            "        [ 0.6435,  1.0000,  0.9053,  ...,  0.4280,  0.3876, -0.8769]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5653,  1.0000,  0.9147,  ..., -0.3139,  0.6979, -0.9828],\n",
            "        [ 0.3660,  1.0000,  0.7817,  ..., -0.3643,  0.4796, -0.9539],\n",
            "        [ 0.5641,  1.0000,  0.6721,  ..., -0.7263,  0.5923, -0.9508],\n",
            "        ...,\n",
            "        [ 0.1042,  1.0000, -0.3068,  ..., -0.8527,  0.3212, -0.9056],\n",
            "        [ 0.7159,  1.0000,  0.8949,  ...,  0.2461,  0.2676, -0.9076],\n",
            "        [ 0.7553,  1.0000,  0.8848,  ...,  0.1650,  0.1015, -0.9125]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5175,  0.9998, -0.8182,  ..., -0.8443,  0.3943, -0.1842],\n",
            "        [ 0.3931,  1.0000,  0.4077,  ..., -0.7525,  0.4591, -0.9685],\n",
            "        [ 0.2955,  1.0000, -0.2180,  ..., -0.7461,  0.7275, -0.8842],\n",
            "        ...,\n",
            "        [ 0.6435,  1.0000,  0.8404,  ..., -0.3243,  0.6773, -0.9634],\n",
            "        [ 0.6178,  1.0000,  0.9067,  ..., -0.0087,  0.2130, -0.9196],\n",
            "        [-0.0136,  1.0000, -0.4480,  ..., -0.8640,  0.2463, -0.6546]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7276,  1.0000,  0.9253,  ...,  0.4786,  0.3796, -0.8544],\n",
            "        [ 0.7653,  1.0000,  0.9042,  ...,  0.5769,  0.2399, -0.7592],\n",
            "        [-0.1981,  1.0000, -0.7471,  ..., -0.8888,  0.1201, -0.2222],\n",
            "        ...,\n",
            "        [ 0.6746,  1.0000,  0.9077,  ...,  0.5829, -0.0060, -0.7171],\n",
            "        [-0.3499,  0.9999, -0.7081,  ..., -0.6664,  0.0080, -0.1831],\n",
            "        [ 0.6604,  1.0000,  0.8872,  ...,  0.4255,  0.1596, -0.8492]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1526,  0.9999, -0.3492,  ..., -0.7342,  0.5064, -0.6351],\n",
            "        [ 0.8145,  1.0000,  0.8688,  ...,  0.5387,  0.3618, -0.8809],\n",
            "        [-0.3139,  1.0000, -0.4188,  ..., -0.8398,  0.6519, -0.8421],\n",
            "        ...,\n",
            "        [ 0.7745,  1.0000,  0.9119,  ...,  0.5482,  0.3064, -0.8993],\n",
            "        [ 0.5568,  1.0000,  0.7674,  ..., -0.5985,  0.5049, -0.9703],\n",
            "        [ 0.6696,  1.0000,  0.8953,  ...,  0.3406,  0.4195, -0.9539]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7556,  1.0000,  0.9326,  ...,  0.3654,  0.3008, -0.9291],\n",
            "        [ 0.7419,  1.0000,  0.9460,  ...,  0.3118,  0.2199, -0.9090],\n",
            "        [-0.1329,  0.9996, -0.5554,  ..., -0.8727,  0.1952, -0.4282],\n",
            "        ...,\n",
            "        [ 0.3333,  1.0000,  0.8975,  ...,  0.3907,  0.3351, -0.7563],\n",
            "        [ 0.5807,  1.0000,  0.8590,  ...,  0.4997,  0.1233, -0.8909],\n",
            "        [-0.3458,  1.0000, -0.3422,  ..., -0.8262,  0.4673, -0.4858]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0351,  0.9987, -0.5888,  ..., -0.7442,  0.6252,  0.1235],\n",
            "        [ 0.5964,  1.0000,  0.8271,  ...,  0.2869,  0.2587, -0.9603],\n",
            "        [ 0.4557,  1.0000,  0.9223,  ...,  0.2532,  0.2888, -0.8908],\n",
            "        ...,\n",
            "        [ 0.6307,  1.0000,  0.9203,  ..., -0.5923,  0.4379, -0.9637],\n",
            "        [ 0.5285,  1.0000,  0.8095,  ...,  0.1142,  0.1509, -0.8081],\n",
            "        [ 0.0573,  1.0000, -0.0927,  ..., -0.9081,  0.5411, -0.8619]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2647,  1.0000,  0.4126,  ..., -0.7695,  0.8593, -0.9228],\n",
            "        [-0.3026,  1.0000, -0.3547,  ..., -0.2909,  0.5658, -0.7318],\n",
            "        [-0.2087,  0.9999, -0.6253,  ..., -0.8515,  0.4441, -0.6030],\n",
            "        ...,\n",
            "        [ 0.0924,  0.9999, -0.4917,  ..., -0.2449,  0.6707, -0.3549],\n",
            "        [-0.2224,  0.9999, -0.3346,  ..., -0.8304,  0.5296, -0.5027],\n",
            "        [-0.0469,  0.9998, -0.7183,  ..., -0.8398,  0.2612, -0.3369]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0389,  1.0000, -0.4576,  ..., -0.8356,  0.4187, -0.6922],\n",
            "        [-0.1523,  1.0000,  0.0558,  ..., -0.6984,  0.5955, -0.9570],\n",
            "        [ 0.5939,  0.9999, -0.1614,  ..., -0.5130,  0.8128, -0.4924],\n",
            "        ...,\n",
            "        [ 0.6855,  1.0000,  0.9380,  ...,  0.4313,  0.1747, -0.8898],\n",
            "        [-0.0552,  0.9998, -0.6559,  ..., -0.8072,  0.4201, -0.4820],\n",
            "        [ 0.7757,  1.0000,  0.9248,  ...,  0.7226,  0.1977, -0.9124]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3090,  0.9997, -0.5660,  ..., -0.8019,  0.5049, -0.3671],\n",
            "        [ 0.8481,  1.0000,  0.9171,  ...,  0.3123,  0.4633, -0.8550],\n",
            "        [-0.1172,  1.0000, -0.5761,  ..., -0.8267,  0.5394, -0.5753],\n",
            "        ...,\n",
            "        [ 0.2388,  1.0000, -0.2121,  ..., -0.7640,  0.7747, -0.9249],\n",
            "        [ 0.6031,  1.0000,  0.8963,  ..., -0.0277,  0.6351, -0.9463],\n",
            "        [-0.1267,  0.9999, -0.6918,  ..., -0.7463,  0.5560, -0.4313]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 1.9661e-01,  1.0000e+00, -2.1724e-01,  ..., -6.7600e-01,\n",
            "          6.0604e-01, -6.0292e-01],\n",
            "        [ 4.6648e-01,  1.0000e+00,  9.0692e-01,  ...,  3.2409e-01,\n",
            "          1.2583e-01, -7.1715e-01],\n",
            "        [ 3.7075e-01,  1.0000e+00,  7.7576e-01,  ..., -5.4857e-01,\n",
            "          6.7057e-01, -9.6985e-01],\n",
            "        ...,\n",
            "        [ 1.5669e-01,  9.9999e-01, -4.8033e-01,  ..., -7.7382e-01,\n",
            "          3.7972e-01, -6.3142e-04],\n",
            "        [ 2.3027e-01,  9.9998e-01, -2.4025e-01,  ..., -5.9738e-01,\n",
            "          6.3547e-01, -2.0586e-01],\n",
            "        [ 7.1881e-01,  1.0000e+00,  9.3568e-01,  ...,  3.0536e-01,\n",
            "          2.4883e-01, -9.5115e-01]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4534,  1.0000, -0.4929,  ..., -0.6163,  0.5872, -0.6118],\n",
            "        [ 0.2325,  1.0000,  0.6739,  ..., -0.6915,  0.5740, -0.8914],\n",
            "        [ 0.2509,  1.0000, -0.2455,  ..., -0.4107,  0.6337, -0.5056],\n",
            "        ...,\n",
            "        [ 0.7303,  1.0000,  0.8600,  ..., -0.2622,  0.5865, -0.9769],\n",
            "        [-0.1778,  1.0000,  0.2716,  ..., -0.7511,  0.8534, -0.7295],\n",
            "        [ 0.7442,  1.0000,  0.9371,  ...,  0.0535,  0.5711, -0.9683]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7287,  1.0000,  0.9040,  ...,  0.3053,  0.1817, -0.8995],\n",
            "        [ 0.8607,  1.0000,  0.5122,  ..., -0.1052,  0.8309, -0.6880],\n",
            "        [ 0.4987,  1.0000, -0.3844,  ..., -0.5739,  0.6940, -0.7615],\n",
            "        ...,\n",
            "        [ 0.0292,  0.9999, -0.5368,  ..., -0.7385,  0.4569, -0.5362],\n",
            "        [-0.0206,  1.0000, -0.3976,  ..., -0.7192,  0.7223, -0.7754],\n",
            "        [ 0.3903,  1.0000, -0.1494,  ..., -0.4140,  0.6478, -0.6304]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0561,  1.0000,  0.3782,  ..., -0.8827,  0.6650, -0.8925],\n",
            "        [ 0.5106,  1.0000,  0.9105,  ...,  0.0033,  0.4485, -0.9235],\n",
            "        [ 0.7121,  1.0000,  0.9295,  ...,  0.4505,  0.0863, -0.7761],\n",
            "        ...,\n",
            "        [-0.0930,  0.9995,  0.5137,  ..., -0.1647,  0.0976, -0.6902],\n",
            "        [ 0.7735,  1.0000,  0.9330,  ...,  0.3237,  0.3346, -0.9294],\n",
            "        [ 0.2442,  1.0000,  0.3144,  ..., -0.5713,  0.7296, -0.8157]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5724,  1.0000, -0.1292,  ..., -0.4308,  0.8554, -0.8714],\n",
            "        [ 0.3079,  1.0000,  0.8053,  ..., -0.3492,  0.1285, -0.7574],\n",
            "        [ 0.5841,  1.0000,  0.3861,  ...,  0.0468,  0.6553, -0.8600],\n",
            "        ...,\n",
            "        [-0.2168,  0.9995,  0.7499,  ..., -0.0683,  0.0130, -0.6777],\n",
            "        [-0.0130,  0.9999,  0.7751,  ...,  0.0459,  0.3192, -0.7432],\n",
            "        [ 0.4499,  1.0000, -0.0635,  ..., -0.4195,  0.7158, -0.6473]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1113,  1.0000, -0.1363,  ..., -0.6586,  0.8964, -0.9333],\n",
            "        [ 0.5733,  1.0000,  0.9501,  ...,  0.0600,  0.6974, -0.9793],\n",
            "        [ 0.7561,  1.0000,  0.1011,  ..., -0.1935,  0.7985, -0.8466],\n",
            "        ...,\n",
            "        [ 0.7799,  1.0000,  0.7518,  ..., -0.2089,  0.4312, -0.9773],\n",
            "        [ 0.7611,  1.0000,  0.9488,  ...,  0.5085,  0.0198, -0.8836],\n",
            "        [ 0.4632,  1.0000,  0.9070,  ..., -0.6142,  0.6734, -0.9786]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.8818,  1.0000,  0.7397,  ...,  0.0414,  0.8652, -0.9614],\n",
            "        [ 0.4022,  1.0000,  0.5459,  ..., -0.3753,  0.6857, -0.9060],\n",
            "        [ 0.5059,  1.0000,  0.8408,  ..., -0.5928,  0.6504, -0.9818],\n",
            "        ...,\n",
            "        [ 0.6706,  1.0000,  0.8252,  ..., -0.4035,  0.7952, -0.9558],\n",
            "        [ 0.3514,  1.0000,  0.6645,  ..., -0.7731,  0.7266, -0.9628],\n",
            "        [ 0.5677,  1.0000,  0.5370,  ..., -0.4351,  0.8530, -0.9619]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6568,  1.0000,  0.8766,  ...,  0.3219,  0.4246, -0.9446],\n",
            "        [ 0.6626,  1.0000,  0.9166,  ..., -0.2901,  0.3393, -0.9740],\n",
            "        [ 0.3788,  1.0000, -0.2829,  ..., -0.4888,  0.7377, -0.9348],\n",
            "        ...,\n",
            "        [ 0.7604,  1.0000,  0.9251,  ..., -0.5873,  0.6766, -0.9718],\n",
            "        [ 0.5122,  1.0000,  0.6916,  ..., -0.6591,  0.8250, -0.9664],\n",
            "        [ 0.7740,  1.0000,  0.8910,  ...,  0.5987, -0.0749, -0.7602]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5764,  1.0000,  0.9491,  ...,  0.4354,  0.3903, -0.9291],\n",
            "        [ 0.2760,  1.0000,  0.9123,  ...,  0.3431,  0.3700, -0.7936],\n",
            "        [ 0.3617,  1.0000,  0.5017,  ..., -0.6145,  0.6412, -0.9563],\n",
            "        ...,\n",
            "        [ 0.5386,  1.0000,  0.9208,  ..., -0.1143,  0.4497, -0.9810],\n",
            "        [ 0.3425,  1.0000,  0.3446,  ..., -0.5834,  0.7985, -0.9690],\n",
            "        [ 0.7919,  1.0000,  0.7014,  ..., -0.6301,  0.8280, -0.9780]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3852,  1.0000,  0.7516,  ..., -0.3251,  0.6509, -0.9176],\n",
            "        [ 0.7930,  1.0000,  0.9114,  ...,  0.3888, -0.0679, -0.8339],\n",
            "        [ 0.6569,  1.0000,  0.8982,  ...,  0.4232, -0.0754, -0.8619],\n",
            "        ...,\n",
            "        [ 0.7528,  1.0000,  0.8628,  ...,  0.4082,  0.3189, -0.9048],\n",
            "        [ 0.7907,  1.0000,  0.9580,  ...,  0.0206,  0.6976, -0.9718],\n",
            "        [ 0.6507,  1.0000,  0.0955,  ..., -0.5362,  0.7095, -0.9076]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7692,  1.0000,  0.9332,  ...,  0.3311,  0.4611, -0.9348],\n",
            "        [ 0.7245,  1.0000,  0.9553,  ..., -0.0561,  0.5629, -0.9432],\n",
            "        [ 0.2817,  1.0000,  0.8433,  ...,  0.2826,  0.2554, -0.7535],\n",
            "        ...,\n",
            "        [ 0.6635,  1.0000,  0.9374,  ...,  0.4075,  0.0959, -0.8755],\n",
            "        [ 0.7824,  1.0000,  0.6978,  ..., -0.3937,  0.8966, -0.9873],\n",
            "        [ 0.7902,  1.0000,  0.9331,  ...,  0.3778,  0.2980, -0.8604]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7921,  1.0000,  0.9705,  ...,  0.2075,  0.4977, -0.9208],\n",
            "        [ 0.7318,  1.0000,  0.9413,  ...,  0.3803,  0.2419, -0.9693],\n",
            "        [ 0.7175,  1.0000,  0.9192,  ...,  0.5216,  0.0492, -0.7851],\n",
            "        ...,\n",
            "        [ 0.5144,  1.0000,  0.7350,  ..., -0.5763,  0.7927, -0.9506],\n",
            "        [ 0.6741,  1.0000, -0.0792,  ..., -0.1130,  0.8648, -0.9226],\n",
            "        [ 0.8291,  1.0000,  0.9070,  ...,  0.1483,  0.5102, -0.9351]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7032,  1.0000,  0.9614,  ..., -0.4731,  0.7617, -0.9707],\n",
            "        [ 0.8376,  1.0000,  0.4633,  ..., -0.6259,  0.8374, -0.9414],\n",
            "        [ 0.6724,  1.0000,  0.9383,  ...,  0.2676,  0.3780, -0.9666],\n",
            "        ...,\n",
            "        [ 0.6041,  1.0000,  0.3888,  ..., -0.4122,  0.6612, -0.8705],\n",
            "        [ 0.6638,  1.0000,  0.8802,  ..., -0.3614,  0.3314, -0.9259],\n",
            "        [ 0.7259,  1.0000,  0.9423,  ...,  0.3663,  0.3457, -0.9208]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4248,  1.0000,  0.6933,  ..., -0.2448,  0.5160, -0.8796],\n",
            "        [ 0.6487,  1.0000,  0.8204,  ..., -0.3880,  0.6606, -0.9871],\n",
            "        [ 0.7328,  1.0000,  0.9242,  ...,  0.5275,  0.1199, -0.9287],\n",
            "        ...,\n",
            "        [ 0.8671,  1.0000,  0.8415,  ...,  0.1388,  0.0887, -0.9156],\n",
            "        [ 0.7018,  1.0000,  0.9391,  ...,  0.5082, -0.0073, -0.8071],\n",
            "        [ 0.6782,  1.0000,  0.9499,  ..., -0.2199,  0.6368, -0.9863]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6509,  1.0000,  0.5176,  ..., -0.6723,  0.8017, -0.9170],\n",
            "        [ 0.6813,  1.0000,  0.9093,  ...,  0.2206,  0.5067, -0.9554],\n",
            "        [ 0.7673,  1.0000,  0.4675,  ..., -0.3438,  0.7994, -0.9474],\n",
            "        ...,\n",
            "        [ 0.6659,  1.0000,  0.9330,  ...,  0.4047,  0.3670, -0.8871],\n",
            "        [ 0.5859,  1.0000,  0.9379,  ..., -0.1398,  0.6046, -0.9383],\n",
            "        [ 0.6643,  1.0000,  0.9613,  ..., -0.1057,  0.3235, -0.9865]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3528,  1.0000,  0.8712,  ..., -0.2716,  0.3889, -0.9782],\n",
            "        [ 0.5800,  1.0000,  0.1436,  ..., -0.7148,  0.7644, -0.9510],\n",
            "        [ 0.6940,  1.0000,  0.9012,  ...,  0.6293,  0.2596, -0.8781],\n",
            "        ...,\n",
            "        [ 0.1726,  1.0000,  0.2390,  ..., -0.7918,  0.7732, -0.9714],\n",
            "        [ 0.7391,  1.0000,  0.9173,  ...,  0.3443,  0.3632, -0.9191],\n",
            "        [ 0.7232,  1.0000,  0.2457,  ..., -0.6930,  0.7707, -0.8988]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5543,  1.0000,  0.8229,  ..., -0.6708,  0.2962, -0.9400],\n",
            "        [ 0.8367,  1.0000,  0.9170,  ..., -0.1007,  0.5023, -0.9600],\n",
            "        [ 0.6696,  1.0000,  0.9376,  ...,  0.3975,  0.1667, -0.8851],\n",
            "        ...,\n",
            "        [ 0.6796,  1.0000,  0.8890,  ..., -0.3478,  0.7413, -0.9949],\n",
            "        [ 0.3071,  1.0000,  0.0439,  ..., -0.7878,  0.6293, -0.6859],\n",
            "        [ 0.7087,  1.0000, -0.1043,  ..., -0.5807,  0.7593, -0.8769]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0172,  1.0000,  0.5089,  ..., -0.6861,  0.8244, -0.9225],\n",
            "        [ 0.7083,  1.0000,  0.9698,  ...,  0.5018,  0.1849, -0.8540],\n",
            "        [ 0.2165,  1.0000,  0.8651,  ...,  0.1843,  0.1995, -0.7857],\n",
            "        ...,\n",
            "        [ 0.4757,  1.0000,  0.9372,  ...,  0.1095,  0.3399, -0.9668],\n",
            "        [ 0.8214,  1.0000,  0.8748,  ...,  0.0239,  0.6579, -0.9701],\n",
            "        [ 0.2280,  1.0000,  0.3185,  ..., -0.8694,  0.6329, -0.9555]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5102,  1.0000, -0.1354,  ..., -0.6594,  0.8002, -0.9009],\n",
            "        [ 0.7235,  1.0000,  0.7670,  ..., -0.7704,  0.6831, -0.9720],\n",
            "        [ 0.8336,  1.0000,  0.9694,  ...,  0.3900,  0.5930, -0.9703],\n",
            "        ...,\n",
            "        [ 0.8560,  1.0000,  0.9420,  ..., -0.5355,  0.4317, -0.9784],\n",
            "        [ 0.1974,  0.9999,  0.8783,  ...,  0.1033,  0.0289, -0.7562],\n",
            "        [ 0.6535,  1.0000,  0.9206,  ..., -0.4769,  0.9000, -0.9836]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7372,  1.0000,  0.9263,  ...,  0.3450,  0.2881, -0.9699],\n",
            "        [ 0.6522,  1.0000,  0.9086,  ...,  0.1268,  0.3757, -0.9223],\n",
            "        [ 0.5113,  1.0000, -0.2854,  ..., -0.7747,  0.7336, -0.8437],\n",
            "        ...,\n",
            "        [ 0.6020,  1.0000, -0.2322,  ..., -0.7541,  0.7607, -0.8502],\n",
            "        [ 0.6141,  1.0000,  0.1907,  ..., -0.7755,  0.7154, -0.8935],\n",
            "        [ 0.7757,  1.0000, -0.0277,  ..., -0.5915,  0.7829, -0.9012]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4645,  1.0000, -0.4214,  ..., -0.6098,  0.6629, -0.8359],\n",
            "        [ 0.7208,  1.0000,  0.9612,  ..., -0.3054,  0.7191, -0.9665],\n",
            "        [ 0.7115,  1.0000,  0.9164,  ..., -0.0389,  0.3419, -0.9595],\n",
            "        ...,\n",
            "        [ 0.4337,  1.0000, -0.2234,  ..., -0.8142,  0.8017, -0.8244],\n",
            "        [ 0.1458,  1.0000,  0.1991,  ..., -0.7778,  0.6582, -0.9256],\n",
            "        [ 0.5620,  1.0000,  0.4164,  ..., -0.8197,  0.7719, -0.9623]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7647,  1.0000,  0.9437,  ...,  0.5297,  0.1081, -0.9660],\n",
            "        [ 0.7717,  1.0000, -0.0951,  ..., -0.6522,  0.8899, -0.9260],\n",
            "        [ 0.3046,  1.0000, -0.0460,  ..., -0.7868,  0.7080, -0.8945],\n",
            "        ...,\n",
            "        [ 0.5762,  1.0000,  0.9149,  ..., -0.0115,  0.2010, -0.9729],\n",
            "        [ 0.4887,  1.0000,  0.7242,  ..., -0.6541,  0.6985, -0.9532],\n",
            "        [ 0.3192,  1.0000,  0.2488,  ..., -0.6835,  0.7045, -0.9397]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7241,  1.0000, -0.1064,  ..., -0.7122,  0.7762, -0.7458],\n",
            "        [ 0.4763,  1.0000,  0.9466,  ..., -0.5991,  0.4231, -0.9600],\n",
            "        [ 0.7091,  1.0000,  0.8146,  ...,  0.2962,  0.3000, -0.9040],\n",
            "        ...,\n",
            "        [ 0.4197,  1.0000,  0.9191,  ..., -0.0239,  0.3292, -0.9187],\n",
            "        [ 0.6754,  1.0000,  0.9365,  ..., -0.3410,  0.5795, -0.9648],\n",
            "        [ 0.2833,  1.0000,  0.5812,  ..., -0.7686,  0.7039, -0.9698]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1236,  1.0000,  0.5180,  ..., -0.6211,  0.8496, -0.9470],\n",
            "        [ 0.6834,  1.0000,  0.9438,  ...,  0.0410,  0.2386, -0.9437],\n",
            "        [ 0.7620,  1.0000,  0.9015,  ...,  0.2054,  0.3417, -0.9269],\n",
            "        ...,\n",
            "        [ 0.2872,  1.0000,  0.1737,  ..., -0.7661,  0.7246, -0.9507],\n",
            "        [ 0.5098,  1.0000,  0.9265,  ...,  0.0051,  0.2026, -0.8749],\n",
            "        [ 0.1873,  1.0000,  0.6992,  ..., -0.6319,  0.7073, -0.9787]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4433,  1.0000,  0.4736,  ..., -0.8015,  0.7672, -0.9214],\n",
            "        [ 0.4189,  1.0000,  0.3456,  ..., -0.8264,  0.7461, -0.9469],\n",
            "        [ 0.8115,  1.0000,  0.9550,  ...,  0.4088,  0.2125, -0.9371],\n",
            "        ...,\n",
            "        [ 0.2702,  1.0000,  0.8536,  ..., -0.5540,  0.6767, -0.8936],\n",
            "        [ 0.2760,  1.0000, -0.1727,  ..., -0.8176,  0.8862, -0.9656],\n",
            "        [ 0.3967,  1.0000,  0.4687,  ..., -0.8981,  0.7261, -0.9585]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6607,  1.0000,  0.6349,  ..., -0.6606,  0.8297, -0.9820],\n",
            "        [ 0.5707,  1.0000,  0.0640,  ..., -0.5970,  0.7697, -0.8898],\n",
            "        [ 0.6256,  1.0000,  0.6090,  ..., -0.7428,  0.7584, -0.9743],\n",
            "        ...,\n",
            "        [ 0.1591,  1.0000,  0.8832,  ..., -0.6117,  0.4196, -0.9628],\n",
            "        [ 0.6041,  1.0000,  0.4225,  ..., -0.8659,  0.6782, -0.9760],\n",
            "        [ 0.3698,  1.0000,  0.8469,  ..., -0.7763,  0.8302, -0.9868]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5157,  1.0000,  0.8991,  ..., -0.0498, -0.0029, -0.9251],\n",
            "        [ 0.3047,  1.0000,  0.1862,  ..., -0.6603,  0.7661, -0.9162],\n",
            "        [ 0.6585,  1.0000,  0.9107,  ..., -0.2685,  0.6054, -0.9735],\n",
            "        ...,\n",
            "        [ 0.3555,  1.0000, -0.2797,  ..., -0.8168,  0.6780, -0.8661],\n",
            "        [ 0.6599,  1.0000,  0.8742,  ...,  0.1692, -0.0189, -0.9547],\n",
            "        [ 0.6380,  1.0000,  0.9139,  ...,  0.0363,  0.3824, -0.8878]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1312,  1.0000, -0.5002,  ..., -0.8774,  0.5644, -0.8440],\n",
            "        [ 0.6457,  1.0000,  0.8935,  ..., -0.6548,  0.7899, -0.9891],\n",
            "        [ 0.3524,  1.0000,  0.0854,  ..., -0.8656,  0.8921, -0.9427],\n",
            "        ...,\n",
            "        [ 0.1613,  1.0000,  0.3889,  ..., -0.7441,  0.8153, -0.9850],\n",
            "        [ 0.6900,  1.0000,  0.8963,  ...,  0.4934, -0.0279, -0.9228],\n",
            "        [ 0.3523,  1.0000,  0.8020,  ..., -0.7912,  0.7930, -0.9733]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6962,  1.0000,  0.8736,  ..., -0.5171,  0.6048, -0.9732],\n",
            "        [ 0.2295,  1.0000,  0.5985,  ..., -0.5958,  0.4068, -0.9662],\n",
            "        [ 0.2369,  1.0000, -0.0055,  ..., -0.7605,  0.5810, -0.8165],\n",
            "        ...,\n",
            "        [ 0.2641,  1.0000, -0.2045,  ..., -0.8673,  0.6927, -0.8597],\n",
            "        [ 0.6111,  1.0000,  0.8324,  ...,  0.1794,  0.0525, -0.9474],\n",
            "        [ 0.7786,  1.0000,  0.8835,  ..., -0.1472,  0.2631, -0.9406]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3250,  1.0000,  0.7089,  ..., -0.8110,  0.4955, -0.9599],\n",
            "        [ 0.3273,  1.0000, -0.0926,  ..., -0.7283,  0.6782, -0.8953],\n",
            "        [ 0.2172,  1.0000,  0.4092,  ..., -0.8932,  0.8052, -0.9361],\n",
            "        ...,\n",
            "        [ 0.2063,  1.0000,  0.7161,  ..., -0.4687,  0.4378, -0.9846],\n",
            "        [ 0.1368,  1.0000, -0.0718,  ..., -0.7940,  0.5586, -0.9336],\n",
            "        [ 0.5458,  1.0000,  0.5514,  ..., -0.4960,  0.6389, -0.8859]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1849,  1.0000,  0.1119, -0.9997,  0.8220,  0.0545,  0.8863, -0.2756,\n",
            "         -1.0000,  0.5348,  0.4432,  0.7129, -0.7024,  1.0000,  0.0700, -0.9220,\n",
            "         -0.2450, -0.9999,  0.9492, -0.8563,  0.4379,  0.3252,  0.8540, -0.7299,\n",
            "         -0.5307, -0.6269,  0.1386,  0.9171, -0.6434,  0.8450, -0.8633, -0.3653,\n",
            "          0.9966,  0.9161,  0.6042, -0.9978, -0.7254, -0.9867, -0.9999, -0.9999,\n",
            "         -0.1863, -0.6006,  1.0000, -0.9221,  0.9994, -0.9994,  0.5091, -0.9003,\n",
            "          0.9269,  0.9153, -0.6894, -0.7970,  0.7994,  0.8582, -0.8800, -0.9996,\n",
            "         -0.5260,  0.9371, -0.8530, -0.1832,  0.4086, -0.8516,  0.0343,  0.7895,\n",
            "         -0.0663,  0.9087,  0.9238,  0.4060,  0.5534, -0.9984, -0.1468, -0.9920,\n",
            "          0.9357, -0.4021,  0.9355,  0.8933, -0.5130, -0.9236, -0.6028,  0.9995,\n",
            "          0.9053,  0.8110,  0.7163, -1.0000, -0.0579, -0.9844,  0.9985, -0.9990,\n",
            "         -0.9976,  0.2644,  0.8013, -0.2151, -0.6821, -0.6031,  0.0226, -0.9812,\n",
            "          0.0824, -0.1837, -1.0000,  0.9169,  0.9401,  0.8910, -0.2955, -0.6759,\n",
            "         -1.0000, -0.4982,  0.4205, -0.9507, -1.0000, -0.9417, -0.9306, -0.7670,\n",
            "          0.4654,  0.9958,  0.1023,  1.0000, -0.2207,  0.9992, -1.0000, -0.9988,\n",
            "          0.1429,  0.9782, -0.7335, -0.7893,  0.8047, -0.9996, -0.9984, -1.0000,\n",
            "          0.8893, -0.5142, -0.5087,  0.9919, -0.2157, -0.9706, -0.9061, -0.3453,\n",
            "         -1.0000,  0.3198, -0.4929, -0.9999,  0.9997,  0.9941, -0.3171, -0.7903,\n",
            "         -0.6831,  0.9945,  0.1245,  0.0731, -0.5386, -0.8420, -0.3069,  0.7066,\n",
            "          0.7569,  0.0750, -1.0000,  0.8520,  0.1069,  0.9920, -0.4040,  0.7336,\n",
            "         -0.9066, -1.0000,  0.9520,  0.8145,  0.7471,  0.5407, -0.8431,  0.9739,\n",
            "          0.4422,  0.7020,  0.9283,  0.8731,  0.7359,  0.9526,  0.8681, -0.9774,\n",
            "         -0.9565, -0.7658,  0.8926, -0.9972,  0.9991, -0.8366,  0.9961, -0.9862,\n",
            "         -0.8983,  0.9061,  0.3136, -1.0000,  0.9907,  0.9302,  0.4682, -0.9475,\n",
            "          0.9022, -0.7919,  0.3955,  0.0539, -0.8911,  0.7651, -0.2542,  0.9974,\n",
            "          0.7191, -0.9995,  0.9997,  0.9884,  0.8603, -0.9937,  0.2750,  0.9987,\n",
            "         -0.9998, -0.9869,  0.4205,  0.0133,  0.5668, -0.8335, -0.9080, -0.9020,\n",
            "          0.9884, -0.9372,  0.9640,  0.4717,  0.7955,  0.0283, -0.9247,  0.1215,\n",
            "          0.3165,  0.9046, -0.3547,  0.5447, -0.8378, -1.0000,  0.3650,  0.5148,\n",
            "          0.7058, -0.5551,  0.9999,  0.5967, -0.5534,  0.9987, -0.9998, -0.4740,\n",
            "          0.0850, -0.9962,  0.9177, -0.3707,  1.0000, -0.9999,  0.9997, -0.2808,\n",
            "          0.8097,  0.8109, -0.8717,  0.6594,  0.9548,  0.8875,  0.7544,  0.9786,\n",
            "         -0.1674, -0.9999,  0.1284,  0.9023, -0.9988,  0.1146, -0.7841, -0.9762,\n",
            "          0.9992,  1.0000, -0.9429,  0.7569,  0.8731,  0.9654,  0.9608, -0.9996,\n",
            "          0.9979,  1.0000, -0.9972, -0.9193,  1.0000,  0.8655, -0.9694,  0.5183,\n",
            "         -0.4125, -0.9998, -0.2576, -0.7636,  0.6791,  0.5600, -0.0952, -0.9995,\n",
            "         -0.9999, -0.9997,  0.9997, -0.1760,  0.6163,  0.2367,  0.5833, -0.8727,\n",
            "          0.8885,  0.9975, -0.9961,  1.0000,  0.9899, -0.9911, -0.9982, -0.7009,\n",
            "          0.4786,  0.8795,  0.9994,  0.0167, -0.9810,  0.6647,  0.9757,  0.2042,\n",
            "          0.9996, -0.4573,  0.6660,  0.1442,  0.8544, -0.9994, -0.9757, -0.3251,\n",
            "          0.8802,  0.9998,  0.7730, -0.7951,  0.9999,  0.3456, -1.0000,  1.0000,\n",
            "          0.9996, -0.9990,  0.1835,  0.4081,  0.8695,  0.5495,  0.6889, -0.8945,\n",
            "         -0.2890, -0.9987,  0.8815,  0.6870,  0.6515,  0.9020,  0.1892,  0.9309,\n",
            "          0.4363,  0.6352,  0.4858, -0.9628, -0.9999, -0.1779,  0.7074,  0.7104,\n",
            "         -0.6798,  0.9987,  0.8576,  1.0000, -0.3730,  0.9991, -0.9307,  0.9031,\n",
            "         -0.3410,  0.8864,  0.7627, -0.9450, -1.0000, -0.4023, -0.8977,  0.9401,\n",
            "          0.4021, -0.9998, -0.9214,  0.7404, -0.8264,  0.3331, -0.5552, -0.8788,\n",
            "          1.0000,  0.9777,  0.6350, -0.7489, -0.7097,  0.8955,  0.9938,  0.7175,\n",
            "          0.9987, -0.8710,  0.9700, -0.8163,  0.8244, -0.3227,  0.0515,  0.3638,\n",
            "          0.1630,  0.9984,  0.9444,  0.9814, -0.8370,  0.6375, -0.9998,  1.0000,\n",
            "          0.3015,  0.8824,  0.9347,  0.6784,  0.7194, -0.7879,  0.9694, -0.9437,\n",
            "          0.9890, -0.8368,  0.8979,  0.1992,  0.8271, -0.8568, -0.5488,  0.6256,\n",
            "          0.4047, -0.9690, -0.9975,  0.9970, -0.9979, -0.6364, -0.9487, -0.7449,\n",
            "          0.9976, -0.8980,  0.4256, -0.7412, -0.9464, -0.8920, -0.6638, -0.9914,\n",
            "          0.2975, -0.9982,  1.0000, -0.9986,  0.9084, -0.8767, -0.4939,  0.8986,\n",
            "          0.4703, -0.6947, -0.2122,  0.4031, -0.7858,  0.9378, -0.4394, -0.4752,\n",
            "          0.5856, -0.4893,  0.4510,  0.9745,  0.6083,  0.9996, -0.4617, -0.9975,\n",
            "         -0.8355, -0.1405,  0.7193,  0.9999, -0.9973,  0.8788,  1.0000, -0.9996,\n",
            "         -0.8688, -0.5013, -1.0000,  0.9331, -0.9130, -0.9989, -0.1621, -0.9368,\n",
            "          0.9158,  0.9986,  1.0000, -0.7425, -0.8653, -0.9991, -0.9237,  0.9866,\n",
            "         -0.9997,  0.8390, -0.9362, -0.9998,  0.9980,  0.8127, -0.4797,  0.5042,\n",
            "          0.4190,  0.9997, -0.3755, -0.9962,  0.8448,  0.8462,  0.1125,  0.8762,\n",
            "         -0.6658, -0.6179, -0.9991,  0.3612,  1.0000, -0.4889, -0.8526,  0.9335,\n",
            "          0.4746,  0.9246,  1.0000, -0.9991,  0.9602,  1.0000, -0.4825,  0.8924,\n",
            "         -0.2065, -0.6418,  0.5381,  0.5928, -0.8384,  1.0000, -0.9347, -0.9934,\n",
            "         -1.0000,  0.3357, -0.9837,  0.8951,  0.9880, -0.8321,  0.6027,  0.1343,\n",
            "         -0.9997,  0.9857, -0.7732, -1.0000, -1.0000,  0.3902, -0.7954, -0.8563,\n",
            "         -0.1099, -0.4765, -0.9822,  1.0000, -0.1431, -1.0000, -0.6654,  0.9824,\n",
            "          0.9990, -0.1594,  0.3767, -0.8995, -0.8741, -0.2507, -1.0000, -0.7031,\n",
            "          0.9896,  0.5846, -0.1024,  1.0000, -0.1870, -0.9358, -0.4536,  0.4201,\n",
            "          0.5606, -1.0000, -0.8749,  1.0000, -0.8370, -0.2461, -0.9168, -0.9024,\n",
            "          0.2979,  0.9374,  0.9945, -0.9988,  1.0000,  0.0618,  0.8821,  0.9883,\n",
            "         -0.5258, -0.9796, -0.9884,  0.4760,  0.7918,  0.3715,  0.3292, -0.9162,\n",
            "          0.9843, -0.1396, -0.9638,  0.7029, -0.7016, -0.7616, -0.6929,  0.9596,\n",
            "          0.7359, -0.7801,  0.9999, -0.5037, -0.9416,  0.6831, -0.1681, -0.5017,\n",
            "         -1.0000, -0.1104,  0.6673, -0.9947, -0.6681,  0.6589, -0.7930, -0.6311,\n",
            "          0.9240, -0.6253,  0.3872,  0.9997,  0.9661,  0.9352, -0.9966, -1.0000,\n",
            "         -0.4218,  0.7706, -0.9882,  0.7482, -0.8103,  1.0000, -0.2628,  0.7999,\n",
            "          0.9077,  1.0000, -0.1373,  0.9627,  0.0554,  0.3973, -0.9948,  0.9749,\n",
            "         -0.5071, -0.9988, -0.8724, -0.4552, -0.6739, -0.5951, -0.7653,  0.5126,\n",
            "          1.0000,  0.0863,  0.8841,  0.8036, -0.7911, -0.2192, -0.9519,  0.9985,\n",
            "         -1.0000,  0.9932,  0.5310, -0.6772,  0.8300, -0.5935, -0.8756, -0.8074,\n",
            "         -0.6396, -0.9744, -0.5775, -0.2875, -0.9167,  0.4683,  0.9634, -0.9374,\n",
            "         -1.0000,  0.7403, -0.0450,  0.9857,  0.2879, -0.8372,  0.9637,  0.5441,\n",
            "          0.9935, -0.8741, -0.6159, -0.9535, -0.7674, -0.0044,  0.8557,  0.9434,\n",
            "          0.3933,  0.1003,  0.1784, -0.6200,  0.0956,  0.0014,  0.5000,  0.0970,\n",
            "          0.9716,  0.8743,  0.9370,  0.9989,  0.4609, -0.8755,  0.7613, -0.7019,\n",
            "          0.3811, -1.0000,  1.0000,  0.4069, -0.8787, -1.0000,  0.1109,  0.4990,\n",
            "          0.4338,  0.6232, -0.4407, -0.9199, -0.5636,  0.7697, -1.0000,  0.1182,\n",
            "         -0.5855, -0.8160,  0.4646, -1.0000, -0.7169,  0.6586, -0.8981,  0.0136,\n",
            "          1.0000, -0.9860, -0.9989, -0.9990, -0.6221,  0.5686,  0.8546, -0.9942,\n",
            "         -0.1875,  0.9118, -0.9999,  0.5354, -0.0196,  0.3696,  0.5435, -0.1893,\n",
            "          0.9979, -1.0000,  0.8431, -0.6019,  0.8124,  0.6962, -0.0610,  0.7651,\n",
            "          0.6219, -1.0000,  0.5259,  0.7467,  0.9648,  0.9312, -0.2117, -0.5361,\n",
            "         -0.0914, -0.6544,  0.9981,  0.9561, -0.8070,  0.9035,  1.0000,  0.7154,\n",
            "          0.9726, -0.4896, -0.9575, -0.9995, -0.9528, -0.7763,  0.6558, -0.8065]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluation... :   0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "893286436692404194cfef6c856cdc67"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7535,  1.0000,  0.9027,  ...,  0.3799, -0.0028, -0.9045],\n",
            "        [ 0.7451,  1.0000,  0.8999,  ...,  0.6153, -0.0569, -0.8505],\n",
            "        [ 0.5534,  1.0000, -0.1749,  ..., -0.8932,  0.8573, -0.8818],\n",
            "        ...,\n",
            "        [ 0.3857,  1.0000,  0.9295,  ..., -0.0559,  0.4312, -0.9507],\n",
            "        [ 0.0306,  1.0000,  0.4702,  ..., -0.6725,  0.6784, -0.9419],\n",
            "        [ 0.1539,  1.0000, -0.4176,  ..., -0.7466,  0.6199, -0.8022]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5458,  1.0000,  0.8626,  ..., -0.1663,  0.2316, -0.9418],\n",
            "        [ 0.5214,  1.0000,  0.8134,  ..., -0.5471,  0.5271, -0.9709],\n",
            "        [ 0.5808,  1.0000,  0.9219,  ...,  0.0530,  0.3006, -0.8166],\n",
            "        ...,\n",
            "        [ 0.3230,  1.0000,  0.8509,  ..., -0.6297,  0.6067, -0.9825],\n",
            "        [ 0.5342,  1.0000,  0.8699,  ..., -0.8041,  0.7346, -0.9819],\n",
            "        [ 0.6822,  1.0000,  0.9257,  ..., -0.4167,  0.7277, -0.9929]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6366,  1.0000,  0.9145,  ...,  0.4538,  0.0254, -0.8645],\n",
            "        [ 0.5433,  1.0000,  0.9112,  ...,  0.3901,  0.1418, -0.7429],\n",
            "        [ 0.7239,  1.0000,  0.9226,  ...,  0.4146,  0.3656, -0.9450],\n",
            "        ...,\n",
            "        [ 0.5430,  1.0000,  0.8990,  ..., -0.2324,  0.6111, -0.9680],\n",
            "        [ 0.0827,  1.0000,  0.4902,  ..., -0.7945,  0.6784, -0.8509],\n",
            "        [ 0.5582,  1.0000,  0.9246,  ..., -0.3448,  0.6433, -0.9805]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3910,  1.0000,  0.8374,  ..., -0.3077,  0.2656, -0.9643],\n",
            "        [ 0.5328,  1.0000,  0.8816,  ..., -0.5003,  0.7421, -0.9867],\n",
            "        [ 0.5835,  1.0000,  0.9090,  ..., -0.6707,  0.7758, -0.9944],\n",
            "        ...,\n",
            "        [ 0.7353,  1.0000,  0.9034,  ...,  0.6579, -0.0293, -0.8032],\n",
            "        [ 0.0214,  1.0000,  0.2638,  ..., -0.8589,  0.7935, -0.9504],\n",
            "        [ 0.6917,  1.0000,  0.9145,  ...,  0.6522,  0.0334, -0.7626]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6981,  1.0000,  0.9328,  ..., -0.1437,  0.3708, -0.9613],\n",
            "        [ 0.5141,  1.0000,  0.9187,  ..., -0.0227,  0.7545, -0.9630],\n",
            "        [ 0.6568,  1.0000,  0.7064,  ..., -0.5510,  0.6358, -0.9749],\n",
            "        ...,\n",
            "        [ 0.4258,  1.0000,  0.8590,  ..., -0.6489,  0.7016, -0.9857],\n",
            "        [ 0.6630,  1.0000,  0.9268,  ...,  0.3960,  0.1460, -0.8985],\n",
            "        [ 0.4005,  1.0000,  0.8982,  ...,  0.3958,  0.2734, -0.7692]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6529,  1.0000,  0.8817,  ...,  0.5808,  0.1279, -0.7319],\n",
            "        [ 0.6527,  1.0000,  0.8265,  ..., -0.4031,  0.6127, -0.9815],\n",
            "        [ 0.4949,  1.0000, -0.4134,  ..., -0.7713,  0.8229, -0.8837],\n",
            "        ...,\n",
            "        [ 0.6560,  1.0000, -0.3077,  ..., -0.8955,  0.8812, -0.8590],\n",
            "        [ 0.5647,  1.0000,  0.6975,  ..., -0.4655,  0.4813, -0.9632],\n",
            "        [ 0.5915,  1.0000,  0.9291,  ...,  0.3574,  0.1211, -0.9190]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5087,  1.0000,  0.6925,  ..., -0.8203,  0.6436, -0.9765],\n",
            "        [ 0.1344,  1.0000,  0.2540,  ..., -0.9156,  0.7639, -0.9621],\n",
            "        [ 0.8017,  1.0000,  0.9015,  ...,  0.4848,  0.0254, -0.8770],\n",
            "        ...,\n",
            "        [ 0.4492,  1.0000,  0.8486,  ..., -0.6952,  0.5565, -0.9551],\n",
            "        [ 0.7202,  1.0000,  0.9211,  ...,  0.6701,  0.0471, -0.8092],\n",
            "        [ 0.3716,  1.0000,  0.7354,  ..., -0.6286,  0.6895, -0.9798]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7551,  1.0000,  0.9301,  ...,  0.6157,  0.1676, -0.9067],\n",
            "        [ 0.6937,  1.0000,  0.9352,  ...,  0.6613, -0.0059, -0.8295],\n",
            "        [ 0.7796,  1.0000,  0.9171,  ...,  0.6059, -0.1611, -0.7793],\n",
            "        ...,\n",
            "        [ 0.6562,  1.0000,  0.9268,  ...,  0.4201,  0.0384, -0.8725],\n",
            "        [ 0.5598,  1.0000,  0.9095,  ...,  0.2708,  0.4273, -0.8884],\n",
            "        [ 0.6355,  1.0000,  0.8708,  ..., -0.4688,  0.7333, -0.9776]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7343,  1.0000,  0.9136,  ...,  0.6472, -0.0988, -0.7838],\n",
            "        [ 0.3581,  1.0000, -0.0231,  ..., -0.7753,  0.6815, -0.9008],\n",
            "        [ 0.1455,  1.0000,  0.8290,  ..., -0.7992,  0.7031, -0.9469],\n",
            "        ...,\n",
            "        [ 0.5643,  1.0000,  0.9001,  ...,  0.4088,  0.3533, -0.7610],\n",
            "        [ 0.0702,  1.0000, -0.2754,  ..., -0.8640,  0.7384, -0.8967],\n",
            "        [ 0.6366,  1.0000,  0.9016,  ...,  0.6101, -0.0309, -0.7963]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3851,  1.0000, -0.4761,  ..., -0.8359,  0.6403, -0.8010],\n",
            "        [ 0.6003,  1.0000,  0.8392,  ..., -0.1683,  0.4686, -0.9559],\n",
            "        [ 0.6926,  1.0000,  0.9122,  ...,  0.3800,  0.1236, -0.8373],\n",
            "        ...,\n",
            "        [ 0.6664,  1.0000,  0.8763,  ...,  0.4734, -0.0649, -0.8385],\n",
            "        [ 0.6356,  1.0000,  0.8555,  ...,  0.4803,  0.0263, -0.7428],\n",
            "        [ 0.7463,  1.0000,  0.9297,  ...,  0.7089, -0.0934, -0.7584]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4041,  1.0000,  0.3244,  ..., -0.7965,  0.7916, -0.9525],\n",
            "        [ 0.1214,  1.0000, -0.1691,  ..., -0.8844,  0.6037, -0.7848],\n",
            "        [ 0.7656,  1.0000,  0.8583,  ..., -0.2144,  0.5398, -0.9741],\n",
            "        ...,\n",
            "        [ 0.7152,  1.0000,  0.9249,  ...,  0.1549,  0.4155, -0.9617],\n",
            "        [ 0.5003,  1.0000,  0.0482,  ..., -0.7975,  0.6076, -0.9426],\n",
            "        [ 0.7513,  1.0000,  0.9284,  ...,  0.4995, -0.0224, -0.8515]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5322,  1.0000,  0.9025,  ...,  0.2669,  0.3263, -0.8031],\n",
            "        [ 0.3175,  1.0000, -0.0487,  ..., -0.8141,  0.7970, -0.9511],\n",
            "        [ 0.0916,  1.0000,  0.5516,  ..., -0.8776,  0.4812, -0.9396],\n",
            "        ...,\n",
            "        [ 0.2025,  1.0000, -0.0562,  ..., -0.8730,  0.7320, -0.9211],\n",
            "        [ 0.6853,  1.0000,  0.9051,  ..., -0.5606,  0.7322, -0.9855],\n",
            "        [ 0.2142,  1.0000,  0.5040,  ..., -0.7849,  0.8187, -0.9326]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6171,  1.0000,  0.2613,  ..., -0.3196,  0.8638, -0.9096],\n",
            "        [ 0.4151,  1.0000,  0.8480,  ..., -0.2499,  0.7262, -0.9645],\n",
            "        [ 0.1588,  1.0000, -0.3463,  ..., -0.8882,  0.5355, -0.6825],\n",
            "        ...,\n",
            "        [ 0.0553,  1.0000,  0.8050,  ..., -0.5580,  0.5837, -0.9731],\n",
            "        [ 0.6153,  1.0000, -0.1549,  ..., -0.8149,  0.7616, -0.8844],\n",
            "        [ 0.1249,  1.0000,  0.1912,  ..., -0.6887,  0.6062, -0.9390]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6022,  1.0000,  0.9056,  ..., -0.6214,  0.2406, -0.9635],\n",
            "        [ 0.6555,  1.0000,  0.8605,  ..., -0.7035,  0.7848, -0.9801],\n",
            "        [ 0.0897,  1.0000, -0.3987,  ..., -0.7581,  0.4147, -0.8718],\n",
            "        ...,\n",
            "        [ 0.5378,  1.0000,  0.8847,  ..., -0.3716,  0.1842, -0.9610],\n",
            "        [ 0.5662,  1.0000,  0.8661,  ...,  0.1114,  0.8157, -0.9519],\n",
            "        [ 0.6312,  1.0000,  0.8688,  ...,  0.4600,  0.0977, -0.8658]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4214,  1.0000,  0.8607, -0.9967,  0.3887,  0.8983,  0.9608,  0.9159,\n",
            "         -0.9999, -0.8881,  0.9317, -0.8187, -0.6111,  1.0000, -0.6430, -0.7980,\n",
            "          0.9640, -0.9997,  0.9689, -0.9749,  0.8162, -0.2800,  0.9898, -0.8958,\n",
            "          0.8517,  0.8630, -0.5018,  0.9375, -0.8260,  0.8808, -0.7331, -0.9390,\n",
            "          0.9856,  0.8964,  0.9903, -0.9985, -0.8538, -0.9962, -0.9993, -0.9999,\n",
            "         -0.9899, -0.8489,  1.0000, -0.9081,  0.9999, -0.9995, -0.2915, -0.6793,\n",
            "          0.9731,  0.8322, -0.9801,  0.9688,  0.9369,  0.9905, -0.5767, -0.9987,\n",
            "         -0.9387,  0.9422, -0.9890, -0.2601,  0.9666, -0.0824, -0.8939,  0.1684,\n",
            "         -0.9773,  0.4972,  0.8180,  0.8795, -0.9483, -0.9923,  0.9645, -0.9801,\n",
            "          0.9697, -0.7921,  0.2544,  0.9854, -0.9194,  0.4347, -0.9264,  0.9982,\n",
            "          0.8637,  0.8383,  0.9082, -1.0000,  0.9531, -0.9735,  0.9992, -0.9995,\n",
            "         -0.9997,  0.9468,  0.9253,  0.9701,  0.8993, -0.8091, -0.8956, -0.9519,\n",
            "         -0.5019,  0.8086, -1.0000,  0.9489,  0.9463,  0.9631, -0.4777, -0.9106,\n",
            "         -1.0000,  0.3969, -0.7897, -0.9439, -1.0000, -0.9529, -0.8040, -0.9622,\n",
            "         -0.8578,  0.9984,  0.5920,  1.0000,  0.9653,  0.9997, -1.0000, -0.9967,\n",
            "          0.8640,  0.9907, -0.8980, -0.8335,  0.7727, -0.9983, -0.9139, -1.0000,\n",
            "          0.9549, -0.9936, -0.9695,  0.9916,  0.9712, -0.8951, -0.9505,  0.5246,\n",
            "         -1.0000,  0.6005, -0.9903, -0.9998,  0.9981,  0.9918,  0.8215, -0.9706,\n",
            "         -0.7637,  0.9948,  0.9594, -0.8312, -0.7593,  0.4621, -0.8918,  0.9554,\n",
            "          0.9346, -0.7334, -1.0000,  0.7916,  0.6217,  0.9789, -0.9864,  0.9978,\n",
            "         -0.9959, -1.0000,  0.9529,  0.8686, -0.9850,  0.9596, -0.9126,  0.9898,\n",
            "         -0.9191,  0.9133,  0.9909,  0.9236,  0.6436,  0.5770, -0.3885, -0.9641,\n",
            "         -0.1084, -0.9362, -0.6628, -0.9994,  0.9987, -0.9651,  0.9956, -0.9730,\n",
            "         -0.9520,  0.9474,  0.3849, -1.0000,  0.9983,  0.7340,  0.9387, -0.6416,\n",
            "          0.9741, -0.9034,  0.9614, -0.4824, -0.9176,  0.9777, -0.9002,  0.9958,\n",
            "          0.7739, -0.9999,  0.9988,  0.9997,  0.8725, -0.9928, -0.0384,  0.9992,\n",
            "         -0.9999, -0.9223, -0.0774, -0.9444,  0.8651,  0.6771, -0.9242, -0.9119,\n",
            "          0.9832,  0.6766,  0.8701, -0.7560,  0.9560,  0.8812, -0.9524,  0.9358,\n",
            "          0.9818,  0.9998, -0.9501, -0.1991,  0.5910, -1.0000,  0.9677,  0.1653,\n",
            "          0.5197, -0.9144,  0.9996,  0.9800,  0.9228,  0.9875, -0.9987, -0.8207,\n",
            "         -0.8378, -0.5386,  0.3997,  0.0099,  1.0000, -0.9999,  0.9989,  0.8120,\n",
            "          0.8736,  0.2460, -0.6898,  0.3522,  0.8216,  0.8101, -0.7366,  0.9979,\n",
            "         -0.9793, -0.9990,  0.7525,  0.8965, -0.9952, -0.9156,  0.9093, -0.9197,\n",
            "          0.9999,  1.0000,  0.1878,  0.7555,  0.9500,  0.9691,  0.9717, -0.9989,\n",
            "          0.9965,  1.0000, -0.9894, -0.3923,  1.0000,  0.9669, -0.9045, -0.4734,\n",
            "          0.9479, -0.9979, -0.8043, -0.8590, -0.2451, -0.2925,  0.6021, -0.9970,\n",
            "         -1.0000, -0.9999,  0.9986, -0.9470, -0.9745,  0.9388,  0.6912, -0.9301,\n",
            "         -0.2422,  0.9987, -0.9968,  1.0000,  0.9788, -0.9829, -0.9986, -0.8297,\n",
            "          0.9346,  0.5306,  0.9999,  0.4390, -0.9630,  0.9759,  0.9366,  0.5208,\n",
            "          0.9964, -0.8749,  0.9355,  0.0923,  0.8378, -0.9986, -0.7827, -0.9726,\n",
            "          0.9867,  0.9986,  0.9410, -0.9352,  0.9987,  0.9396, -1.0000,  1.0000,\n",
            "          0.9975, -0.9999,  0.9021, -0.8278,  0.9826,  0.7034,  0.9820, -0.9707,\n",
            "         -0.9622, -0.9999,  0.9887,  0.7311, -0.8174,  0.8885, -0.9782,  0.9215,\n",
            "          0.6971,  0.9078,  0.6894, -0.8890, -1.0000,  0.8351,  0.8867,  0.7616,\n",
            "          0.8974,  0.9978, -0.0950,  1.0000, -0.9747,  0.9748, -0.7756,  0.9255,\n",
            "          0.7866,  0.8950, -0.2202, -0.7211, -1.0000,  0.8181, -0.9047,  0.8503,\n",
            "          0.9142, -0.9995, -0.7295, -0.2027, -0.7696, -0.5561,  0.5683,  0.5791,\n",
            "          1.0000,  0.8851,  0.1051, -0.9155, -0.6034,  0.8746,  0.9901,  0.9889,\n",
            "          0.9995, -0.9727,  0.8831,  0.8488,  0.5381, -0.9249,  0.3516,  0.0825,\n",
            "          0.8391,  0.9991,  0.9683,  0.7719, -0.8876,  0.9059, -0.9994,  1.0000,\n",
            "          0.8444,  0.8612,  0.9960, -0.6073,  0.9805, -0.8400,  0.9561, -0.9594,\n",
            "          0.9972,  0.9258,  0.9547,  0.8078,  0.9323, -0.9326, -0.3371,  0.9652,\n",
            "          0.9010, -0.9513, -0.9952,  0.9986, -0.9953,  0.0016, -0.9133,  0.9166,\n",
            "          0.9837, -0.9436, -0.9764, -0.9575, -0.9075, -0.9868, -0.9823, -0.9998,\n",
            "         -0.5894, -0.9983,  1.0000, -0.9964,  0.9258, -0.9813, -0.9025,  0.9260,\n",
            "          0.0698, -0.9069, -0.9077,  0.1133, -0.9165,  0.9824,  0.3912,  0.9358,\n",
            "         -0.3290, -0.2027,  0.9044,  0.5128,  0.7216,  0.9854, -0.9352, -0.9993,\n",
            "         -0.9772, -0.9231, -0.5393,  0.9980, -0.9945, -0.1631,  1.0000, -0.9996,\n",
            "         -0.6601,  0.0099, -0.9999,  0.8130, -0.9708, -0.9971, -0.9458, -0.9086,\n",
            "          0.9706,  0.9975,  1.0000,  0.3038, -0.9504, -0.9974, -0.7508,  0.9983,\n",
            "         -0.9997,  0.3064,  0.3556, -0.9999,  0.9615,  0.9003, -0.7215,  0.9448,\n",
            "         -0.9489,  0.9990, -0.6669, -0.9980,  0.8731,  0.9144,  0.4548,  0.9712,\n",
            "         -0.3255, -0.5802, -0.9954,  0.8477,  1.0000, -0.1720, -0.9757,  0.9374,\n",
            "          0.9868,  0.9380,  1.0000, -0.9988,  0.9841,  1.0000, -0.8275,  0.9352,\n",
            "         -0.7891, -0.9556, -0.1628,  0.9116, -0.9988,  1.0000, -0.8507, -0.9983,\n",
            "         -1.0000,  0.9413, -0.9715,  0.9142,  0.9942,  0.6770,  0.8587,  0.9339,\n",
            "         -0.9997,  0.9379, -0.9847, -1.0000, -1.0000,  0.9590,  0.0979,  0.3264,\n",
            "          0.9385, -0.8286, -0.9014,  1.0000,  0.9490, -1.0000, -0.9508,  0.9405,\n",
            "          0.9909, -0.9458,  0.9731, -0.6775, -0.0785, -0.2648, -1.0000, -0.9618,\n",
            "          0.9993, -0.8366,  0.7874,  1.0000,  0.9549, -0.8678, -0.9887,  0.8974,\n",
            "          0.9767, -1.0000, -0.9655,  1.0000, -0.9683, -0.9276, -0.9614,  0.5972,\n",
            "          0.9531,  0.9752,  0.9790, -0.9999,  0.9998,  0.9815, -0.2711,  0.9988,\n",
            "         -0.0237, -0.9496, -0.9911, -0.9356,  0.9473, -0.7806,  0.9382, -0.9697,\n",
            "          0.9987,  0.9495, -0.9404,  0.9629,  0.9018, -0.9605, -0.8750,  0.9938,\n",
            "          0.7768, -0.6518,  0.9979, -0.6209, -0.9438, -0.7579,  0.9800,  0.9788,\n",
            "         -1.0000,  0.9768, -0.9040, -0.9734,  0.9584,  0.1198, -0.9454, -0.7521,\n",
            "          0.9667, -0.9607,  0.6127,  0.9895,  0.9743,  0.9665, -0.9971, -1.0000,\n",
            "         -0.9207, -0.8990, -0.9596, -0.1625, -0.5899,  0.9988,  0.8630,  0.5004,\n",
            "          0.9450,  1.0000, -0.8156,  0.9984, -0.9769,  0.9888, -0.9995,  0.9345,\n",
            "          0.4548, -0.9989, -0.9227,  0.9815, -0.9134,  0.9128, -0.9917,  0.9606,\n",
            "          1.0000, -0.9334,  0.5276,  0.9768, -0.9702,  0.9716, -0.8515,  0.9997,\n",
            "         -1.0000,  0.9971,  0.9287,  0.7295,  0.9117,  0.8258, -0.5499, -0.9281,\n",
            "         -0.9528, -0.9981, -0.3607,  0.9454, -0.7950,  0.9398,  0.9843, -0.9834,\n",
            "         -1.0000, -0.9417,  0.6693,  0.9841, -0.9322, -0.9991,  0.9939, -0.8847,\n",
            "          0.9988, -0.6203, -0.9485, -0.8904, -0.9478, -0.8018,  0.9450,  0.9639,\n",
            "          0.9898,  0.8163, -0.8975, -0.8497, -0.8944, -0.9867,  0.9455,  0.6980,\n",
            "          0.9252,  0.9288,  0.9238,  0.9988,  0.6782, -0.7603,  0.8600, -0.9231,\n",
            "         -0.9567, -1.0000,  1.0000,  0.9716, -0.9672, -1.0000,  0.9813,  0.9144,\n",
            "         -0.7463,  0.8976, -0.9398, -0.9763, -0.5319,  0.9922, -1.0000,  0.2169,\n",
            "          0.9538, -0.7956,  0.5349, -1.0000, -0.1173,  0.8250, -0.8930,  0.8740,\n",
            "          1.0000, -0.8575, -0.9967, -0.9959,  0.2316,  0.9473,  0.8231, -0.9991,\n",
            "         -0.8598,  0.9852, -1.0000,  0.7891, -0.9305, -0.8337,  0.9209,  0.9460,\n",
            "          0.9946, -1.0000,  0.9884, -0.9371,  0.9714, -0.6173,  0.8082,  0.9439,\n",
            "          0.9912, -1.0000,  0.9703,  0.7121,  0.8940,  0.8182,  0.9765, -0.9473,\n",
            "         -0.9856, -0.9471,  0.9956,  0.9981, -0.9174,  0.9760,  1.0000, -0.8009,\n",
            "          0.9438,  0.6208, -0.7222, -0.9999, -0.9739, -0.5591,  0.1136, -0.9647]],\n",
            "       device='cuda:0')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training... :   0%|          | 0/127 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d4d8827789e41f8be80a443f1a15bdf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0078,  1.0000, -0.0410,  ..., -0.9072,  0.7547, -0.9514],\n",
            "        [ 0.4513,  1.0000,  0.8990,  ...,  0.2360,  0.1007, -0.7875],\n",
            "        [ 0.6102,  1.0000,  0.8783,  ..., -0.0119, -0.0514, -0.8504],\n",
            "        ...,\n",
            "        [ 0.5848,  1.0000,  0.8261,  ...,  0.4974,  0.1575, -0.9347],\n",
            "        [ 0.6142,  1.0000,  0.1686,  ..., -0.6835,  0.7970, -0.8241],\n",
            "        [ 0.4498,  1.0000,  0.8714,  ..., -0.3641,  0.3584, -0.8916]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5627,  1.0000, -0.3086,  ..., -0.7799,  0.8073, -0.8758],\n",
            "        [ 0.5945,  1.0000,  0.9131,  ...,  0.0745,  0.0962, -0.8054],\n",
            "        [ 0.2496,  1.0000,  0.5316,  ..., -0.7997,  0.8262, -0.9766],\n",
            "        ...,\n",
            "        [ 0.6921,  1.0000,  0.9285,  ..., -0.5224,  0.7816, -0.9728],\n",
            "        [ 0.6607,  1.0000,  0.8704,  ...,  0.4805,  0.0569, -0.8466],\n",
            "        [ 0.6620,  1.0000,  0.9165,  ..., -0.0541,  0.1781, -0.9543]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3532,  1.0000, -0.1634,  ..., -0.7422,  0.8577, -0.9251],\n",
            "        [ 0.5978,  1.0000,  0.8922,  ...,  0.5312,  0.1200, -0.7945],\n",
            "        [ 0.6273,  1.0000,  0.8852,  ...,  0.5150,  0.1339, -0.7399],\n",
            "        ...,\n",
            "        [ 0.3462,  1.0000,  0.8722,  ...,  0.1750, -0.0693, -0.8654],\n",
            "        [ 0.6087,  1.0000,  0.8979,  ...,  0.7220, -0.2016, -0.8308],\n",
            "        [ 0.6418,  1.0000,  0.8472,  ...,  0.4352,  0.2126, -0.8585]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7150,  1.0000,  0.8714,  ...,  0.5874, -0.3016, -0.8202],\n",
            "        [ 0.2923,  1.0000,  0.8767,  ..., -0.3289,  0.3797, -0.9558],\n",
            "        [ 0.6032,  1.0000,  0.8513,  ...,  0.2959,  0.1548, -0.8989],\n",
            "        ...,\n",
            "        [ 0.4771,  1.0000, -0.3989,  ..., -0.7762,  0.6646, -0.8017],\n",
            "        [ 0.7190,  1.0000,  0.8506,  ...,  0.3073,  0.1460, -0.8553],\n",
            "        [ 0.2460,  1.0000,  0.5229,  ..., -0.8533,  0.7811, -0.9777]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4452,  1.0000, -0.5948,  ..., -0.8596,  0.5030, -0.8206],\n",
            "        [ 0.5889,  1.0000,  0.9408,  ..., -0.1239,  0.5909, -0.9693],\n",
            "        [ 0.6253,  1.0000,  0.6202,  ..., -0.6536,  0.5763, -0.9091],\n",
            "        ...,\n",
            "        [ 0.5570,  1.0000,  0.9174,  ...,  0.4289,  0.2960, -0.9042],\n",
            "        [ 0.7122,  1.0000,  0.8701,  ..., -0.2530,  0.4910, -0.8948],\n",
            "        [ 0.5894,  1.0000,  0.8858,  ...,  0.5758,  0.0227, -0.8659]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5333,  1.0000,  0.9073,  ..., -0.2591,  0.3902, -0.9598],\n",
            "        [ 0.2485,  1.0000,  0.8986,  ..., -0.0486,  0.2703, -0.8702],\n",
            "        [ 0.4430,  1.0000,  0.7950,  ..., -0.7128,  0.6633, -0.9523],\n",
            "        ...,\n",
            "        [ 0.7150,  1.0000,  0.9090,  ...,  0.3627, -0.0210, -0.8238],\n",
            "        [ 0.6918,  1.0000,  0.8495,  ...,  0.6167,  0.3948, -0.9299],\n",
            "        [-0.0928,  1.0000,  0.3981,  ..., -0.6757,  0.6924, -0.9410]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7927,  1.0000,  0.4463,  ..., -0.8199,  0.8711, -0.9105],\n",
            "        [ 0.7633,  1.0000,  0.9392,  ...,  0.6918,  0.2841, -0.8956],\n",
            "        [ 0.7368,  1.0000,  0.9251,  ...,  0.5320, -0.1515, -0.8655],\n",
            "        ...,\n",
            "        [ 0.6553,  1.0000,  0.9080,  ...,  0.5541, -0.2377, -0.7443],\n",
            "        [ 0.6627,  1.0000,  0.8594,  ...,  0.5833,  0.3281, -0.7442],\n",
            "        [ 0.1230,  1.0000,  0.1172,  ..., -0.9248,  0.8880, -0.9570]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3824,  1.0000,  0.8302,  ..., -0.0389, -0.1728, -0.9451],\n",
            "        [ 0.4388,  1.0000,  0.8905,  ...,  0.3758, -0.2209, -0.7998],\n",
            "        [ 0.8123,  1.0000,  0.8570,  ...,  0.5976,  0.1611, -0.8661],\n",
            "        ...,\n",
            "        [ 0.1163,  1.0000,  0.5452,  ..., -0.7096,  0.7134, -0.9740],\n",
            "        [ 0.3017,  1.0000, -0.1790,  ..., -0.7934,  0.6966, -0.8797],\n",
            "        [ 0.2523,  1.0000,  0.3192,  ..., -0.9357,  0.7730, -0.9655]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2284,  1.0000,  0.0843,  ..., -0.6881,  0.6878, -0.9167],\n",
            "        [ 0.4203,  1.0000,  0.8874,  ...,  0.0725,  0.3000, -0.9189],\n",
            "        [ 0.1572,  1.0000, -0.4183,  ..., -0.8928,  0.5826, -0.8839],\n",
            "        ...,\n",
            "        [-0.0260,  1.0000, -0.6054,  ..., -0.7759,  0.6606, -0.8152],\n",
            "        [ 0.6493,  1.0000,  0.9207,  ..., -0.4628,  0.5602, -0.9286],\n",
            "        [-0.2783,  1.0000, -0.4834,  ..., -0.9087,  0.3469, -0.6256]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6583,  1.0000,  0.9079,  ...,  0.4315,  0.1260, -0.7600],\n",
            "        [ 0.0364,  1.0000,  0.3719,  ..., -0.8993,  0.7091, -0.9384],\n",
            "        [ 0.8064,  1.0000,  0.9609,  ...,  0.2008,  0.4032, -0.9797],\n",
            "        ...,\n",
            "        [ 0.5931,  1.0000,  0.7660,  ...,  0.4702,  0.0381, -0.8570],\n",
            "        [ 0.7120,  1.0000,  0.9124,  ...,  0.7526, -0.0713, -0.7446],\n",
            "        [ 0.6538,  1.0000,  0.9450,  ...,  0.0866,  0.6612, -0.9757]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2622,  0.9998, -0.4022,  ..., -0.8883,  0.5338, -0.6887],\n",
            "        [ 0.8356,  1.0000,  0.9113,  ...,  0.2953,  0.4400, -0.8616],\n",
            "        [-0.0208,  1.0000,  0.6756,  ..., -0.6017,  0.4367, -0.9184],\n",
            "        ...,\n",
            "        [ 0.7799,  1.0000,  0.9545,  ...,  0.2778,  0.1997, -0.9395],\n",
            "        [ 0.2601,  1.0000,  0.6749,  ..., -0.7873,  0.7828, -0.9737],\n",
            "        [ 0.7896,  1.0000,  0.8806,  ...,  0.5797,  0.3644, -0.8363]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0737,  1.0000, -0.4845,  ..., -0.9248,  0.5977, -0.6505],\n",
            "        [ 0.7632,  1.0000,  0.9049,  ...,  0.1210,  0.1465, -0.7915],\n",
            "        [ 0.3126,  1.0000, -0.7310,  ..., -0.8574,  0.6436, -0.7553],\n",
            "        ...,\n",
            "        [ 0.7493,  1.0000,  0.8835,  ...,  0.6795,  0.1338, -0.8115],\n",
            "        [ 0.6393,  1.0000,  0.7997,  ..., -0.4706,  0.4481, -0.9630],\n",
            "        [ 0.6797,  1.0000,  0.9337,  ...,  0.3852,  0.1426, -0.9138]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6838,  1.0000,  0.8636,  ...,  0.6242, -0.0065, -0.8158],\n",
            "        [ 0.3125,  1.0000, -0.2022,  ..., -0.8177,  0.7923, -0.8475],\n",
            "        [ 0.0277,  1.0000, -0.5921,  ..., -0.8881,  0.5284, -0.5425],\n",
            "        ...,\n",
            "        [ 0.6611,  1.0000,  0.8962,  ...,  0.5794, -0.0505, -0.8690],\n",
            "        [ 0.6933,  1.0000,  0.8540,  ...,  0.2759, -0.0937, -0.8982],\n",
            "        [ 0.5700,  1.0000,  0.8860,  ..., -0.2687,  0.6078, -0.9517]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4973,  1.0000,  0.6502,  ..., -0.7069,  0.4899, -0.9731],\n",
            "        [ 0.1872,  1.0000,  0.6913,  ..., -0.3198,  0.6751, -0.9325],\n",
            "        [ 0.1075,  1.0000, -0.6110,  ..., -0.8759,  0.5796, -0.6558],\n",
            "        ...,\n",
            "        [ 0.7990,  1.0000,  0.9024,  ...,  0.7319,  0.1493, -0.8490],\n",
            "        [ 0.0178,  1.0000, -0.5421,  ..., -0.8639,  0.5251, -0.7053],\n",
            "        [ 0.7181,  1.0000,  0.7799,  ...,  0.7326,  0.2767, -0.7834]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5856,  1.0000,  0.7763,  ...,  0.5371,  0.1192, -0.8790],\n",
            "        [ 0.0188,  1.0000, -0.6064,  ..., -0.8418,  0.5978, -0.8338],\n",
            "        [ 0.6194,  1.0000,  0.8466,  ...,  0.4036,  0.1057, -0.8247],\n",
            "        ...,\n",
            "        [ 0.1660,  1.0000, -0.5068,  ..., -0.8929,  0.5522, -0.6166],\n",
            "        [ 0.0527,  1.0000,  0.7858,  ..., -0.4979,  0.8791, -0.8933],\n",
            "        [ 0.5306,  1.0000,  0.9076,  ...,  0.6536, -0.0413, -0.7355]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5838,  1.0000,  0.9350,  ...,  0.4412,  0.3342, -0.7758],\n",
            "        [-0.0302,  1.0000, -0.4666,  ..., -0.8463,  0.7341, -0.6859],\n",
            "        [ 0.7980,  1.0000,  0.8312,  ...,  0.7708, -0.4161, -0.7698],\n",
            "        ...,\n",
            "        [ 0.1944,  1.0000, -0.2339,  ..., -0.8631,  0.8655, -0.8691],\n",
            "        [ 0.2649,  1.0000, -0.6833,  ..., -0.8675,  0.6419, -0.6788],\n",
            "        [-0.1504,  1.0000, -0.6516,  ..., -0.7767,  0.7310, -0.6087]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0590,  1.0000, -0.1599,  ..., -0.8695,  0.6496, -0.9055],\n",
            "        [ 0.3318,  1.0000, -0.5042,  ..., -0.8688,  0.5368, -0.6748],\n",
            "        [ 0.6677,  1.0000,  0.8880,  ...,  0.5361, -0.0608, -0.8229],\n",
            "        ...,\n",
            "        [ 0.7013,  1.0000,  0.8746,  ..., -0.2260,  0.4575, -0.9417],\n",
            "        [ 0.4361,  1.0000,  0.8551,  ...,  0.3816,  0.2227, -0.7957],\n",
            "        [ 0.1567,  1.0000,  0.9286,  ...,  0.0998,  0.3628, -0.8587]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6724,  1.0000,  0.9726,  ...,  0.2752,  0.2552, -0.9097],\n",
            "        [ 0.2954,  1.0000,  0.1551,  ..., -0.7966,  0.7432, -0.9267],\n",
            "        [ 0.6247,  1.0000,  0.9021,  ...,  0.5918, -0.2170, -0.6042],\n",
            "        ...,\n",
            "        [ 0.0719,  1.0000,  0.8130,  ..., -0.4500,  0.4592, -0.9455],\n",
            "        [ 0.6548,  1.0000,  0.9190,  ...,  0.6142,  0.2856, -0.8438],\n",
            "        [ 0.5553,  1.0000,  0.9410,  ..., -0.3478,  0.5396, -0.9809]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4950,  1.0000,  0.9582,  ...,  0.1939,  0.1788, -0.9122],\n",
            "        [ 0.6995,  1.0000,  0.8809,  ...,  0.7411,  0.0493, -0.8166],\n",
            "        [-0.1676,  1.0000, -0.0403,  ..., -0.8201,  0.6770, -0.8688],\n",
            "        ...,\n",
            "        [ 0.4315,  1.0000,  0.9406,  ..., -0.2190,  0.3177, -0.8878],\n",
            "        [ 0.5093,  1.0000,  0.8823,  ...,  0.4161,  0.0695, -0.8862],\n",
            "        [ 0.6471,  1.0000,  0.8438,  ...,  0.4701, -0.1582, -0.7294]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1864,  1.0000, -0.2426,  ..., -0.7994,  0.7331, -0.7974],\n",
            "        [ 0.7188,  1.0000,  0.8881,  ...,  0.3362,  0.1327, -0.8969],\n",
            "        [ 0.7474,  1.0000,  0.9280,  ...,  0.5448,  0.0440, -0.6777],\n",
            "        ...,\n",
            "        [ 0.1792,  1.0000,  0.9294,  ..., -0.2293,  0.7862, -0.9846],\n",
            "        [ 0.5928,  1.0000,  0.9079,  ..., -0.2578,  0.7758, -0.9704],\n",
            "        [ 0.6846,  1.0000,  0.8748,  ...,  0.2476,  0.4663, -0.9647]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6059,  1.0000,  0.8418,  ...,  0.6431, -0.1481, -0.7971],\n",
            "        [ 0.4411,  1.0000,  0.8929,  ...,  0.3759, -0.0064, -0.8168],\n",
            "        [-0.0113,  1.0000,  0.9277,  ...,  0.1865, -0.0283, -0.8124],\n",
            "        ...,\n",
            "        [ 0.0227,  1.0000, -0.2874,  ..., -0.9383,  0.6456, -0.8969],\n",
            "        [-0.0544,  1.0000, -0.6906,  ..., -0.9284,  0.2085, -0.5955],\n",
            "        [ 0.3970,  1.0000,  0.9291,  ...,  0.3017,  0.1644, -0.6873]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1106,  1.0000, -0.5762,  ..., -0.8626,  0.6942, -0.6391],\n",
            "        [-0.3734,  1.0000, -0.5851,  ..., -0.8897,  0.2870, -0.7368],\n",
            "        [ 0.6778,  1.0000,  0.9009,  ...,  0.5577, -0.1285, -0.7963],\n",
            "        ...,\n",
            "        [ 0.0878,  1.0000, -0.3156,  ..., -0.7413,  0.7445, -0.7304],\n",
            "        [ 0.2515,  1.0000,  0.9017,  ...,  0.2669,  0.0296, -0.7653],\n",
            "        [ 0.1604,  1.0000, -0.3598,  ..., -0.7600,  0.2760, -0.9064]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4902,  1.0000,  0.8963,  ..., -0.5975,  0.6089, -0.9664],\n",
            "        [ 0.5455,  1.0000,  0.9673,  ..., -0.2801,  0.3801, -0.9092],\n",
            "        [ 0.2565,  1.0000, -0.4606,  ..., -0.8159,  0.7585, -0.6660],\n",
            "        ...,\n",
            "        [ 0.0680,  1.0000, -0.0781,  ..., -0.6825,  0.2805, -0.8714],\n",
            "        [ 0.2315,  1.0000, -0.4270,  ..., -0.7838,  0.7441, -0.7769],\n",
            "        [ 0.7333,  1.0000,  0.8680,  ...,  0.2763,  0.0352, -0.8526]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3401,  1.0000,  0.5934,  ..., -0.7653,  0.5232, -0.9813],\n",
            "        [ 0.6357,  1.0000,  0.8334,  ...,  0.4991, -0.1040, -0.7958],\n",
            "        [ 0.6089,  1.0000,  0.9318,  ...,  0.3606,  0.1750, -0.9572],\n",
            "        ...,\n",
            "        [ 0.3279,  1.0000, -0.6579,  ..., -0.8572,  0.5134, -0.7586],\n",
            "        [ 0.5606,  1.0000,  0.9268,  ...,  0.2779,  0.1127, -0.8894],\n",
            "        [ 0.3005,  1.0000,  0.9252,  ...,  0.7551,  0.0954, -0.7597]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4549,  1.0000,  0.8429,  ...,  0.4893, -0.2721, -0.8535],\n",
            "        [ 0.4434,  1.0000,  0.9184,  ...,  0.0102,  0.2382, -0.8906],\n",
            "        [-0.2298,  0.9999, -0.7020,  ..., -0.9295,  0.2047,  0.1530],\n",
            "        ...,\n",
            "        [ 0.3676,  1.0000,  0.7522,  ..., -0.7202,  0.8632, -0.9621],\n",
            "        [ 0.4367,  1.0000,  0.8971,  ...,  0.4429,  0.1766, -0.8815],\n",
            "        [ 0.4739,  1.0000,  0.9278,  ...,  0.5287, -0.0839, -0.8143]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1151,  1.0000,  0.1897,  ..., -0.8438,  0.6134, -0.8835],\n",
            "        [ 0.4349,  1.0000,  0.9207,  ...,  0.3812,  0.0160, -0.7050],\n",
            "        [ 0.6958,  1.0000,  0.9166,  ...,  0.5816, -0.1580, -0.8146],\n",
            "        ...,\n",
            "        [ 0.1881,  1.0000,  0.9091,  ..., -0.1004,  0.2713, -0.9799],\n",
            "        [ 0.3032,  1.0000,  0.8342,  ..., -0.6044,  0.5093, -0.9774],\n",
            "        [-0.2412,  1.0000, -0.4262,  ..., -0.8372,  0.6021, -0.6328]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0029,  1.0000, -0.7910,  ..., -0.8827,  0.3261, -0.4321],\n",
            "        [ 0.6267,  1.0000,  0.9091,  ...,  0.6377,  0.0047, -0.7608],\n",
            "        [ 0.2085,  1.0000,  0.8012,  ..., -0.5852,  0.7221, -0.9234],\n",
            "        ...,\n",
            "        [-0.1485,  1.0000,  0.8706,  ..., -0.7710,  0.5042, -0.9729],\n",
            "        [-0.4457,  1.0000, -0.7111,  ..., -0.7398,  0.4371, -0.6151],\n",
            "        [-0.3129,  1.0000, -0.3851,  ..., -0.8632,  0.5469, -0.7791]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2886,  1.0000, -0.1137,  ..., -0.8326,  0.5879, -0.8597],\n",
            "        [-0.1740,  1.0000, -0.7327,  ..., -0.9048,  0.5147, -0.5369],\n",
            "        [ 0.1020,  1.0000,  0.6316,  ..., -0.0616,  0.0449, -0.9090],\n",
            "        ...,\n",
            "        [ 0.7748,  1.0000,  0.9621,  ...,  0.5227,  0.2504, -0.8451],\n",
            "        [-0.1759,  1.0000, -0.6035,  ..., -0.8127,  0.5772, -0.6850],\n",
            "        [-0.2364,  1.0000, -0.7135,  ..., -0.8878,  0.3873, -0.5436]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5711,  1.0000,  0.9430,  ...,  0.6572, -0.1934, -0.7424],\n",
            "        [ 0.5567,  1.0000,  0.8105,  ..., -0.4602,  0.3096, -0.9099],\n",
            "        [ 0.5122,  1.0000,  0.9398,  ...,  0.4614, -0.2009, -0.8721],\n",
            "        ...,\n",
            "        [-0.3024,  1.0000, -0.5377,  ..., -0.6767,  0.5852, -0.7482],\n",
            "        [ 0.4544,  1.0000,  0.8586,  ...,  0.1028, -0.0798, -0.8927],\n",
            "        [ 0.1253,  1.0000,  0.9031,  ...,  0.2286,  0.2188, -0.7647]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0609,  1.0000,  0.7978,  ..., -0.4233,  0.0973, -0.7863],\n",
            "        [ 0.6604,  1.0000,  0.8491,  ...,  0.5669,  0.1919, -0.8999],\n",
            "        [ 0.1287,  1.0000, -0.6883,  ..., -0.8434,  0.4810, -0.6763],\n",
            "        ...,\n",
            "        [ 0.7105,  1.0000,  0.9060,  ...,  0.6681, -0.0788, -0.8183],\n",
            "        [-0.0718,  1.0000, -0.5088,  ..., -0.9034,  0.6774, -0.5221],\n",
            "        [ 0.5669,  1.0000,  0.8938,  ...,  0.7647, -0.3229, -0.5675]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4579,  1.0000, -0.4897,  ..., -0.8867,  0.6322, -0.4469],\n",
            "        [-0.3086,  1.0000,  0.5127,  ..., -0.7491,  0.5573, -0.9462],\n",
            "        [ 0.6427,  1.0000,  0.9039,  ...,  0.6344, -0.0374, -0.8283],\n",
            "        ...,\n",
            "        [-0.2280,  1.0000, -0.4252,  ..., -0.7566,  0.7202, -0.6524],\n",
            "        [ 0.6288,  1.0000,  0.9587,  ...,  0.6046, -0.0903, -0.8087],\n",
            "        [-0.4720,  1.0000, -0.8096,  ..., -0.9088,  0.4117, -0.4805]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2972,  0.9999,  0.7414,  ..., -0.1913, -0.0455, -0.3693],\n",
            "        [ 0.6879,  1.0000,  0.9256,  ...,  0.6773, -0.2220, -0.5893],\n",
            "        [-0.1319,  1.0000, -0.5835,  ..., -0.8415,  0.4034, -0.6265],\n",
            "        ...,\n",
            "        [-0.0722,  1.0000, -0.1142,  ..., -0.8248,  0.6559, -0.9166],\n",
            "        [ 0.7817,  1.0000,  0.9165,  ...,  0.8277, -0.1214, -0.7172],\n",
            "        [ 0.7269,  1.0000,  0.9089,  ...,  0.8714, -0.1798, -0.6568]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6044,  1.0000,  0.9275,  ...,  0.6956, -0.4662, -0.6775],\n",
            "        [ 0.1019,  1.0000,  0.0857,  ..., -0.5617,  0.1626, -0.7086],\n",
            "        [ 0.5009,  1.0000,  0.9393,  ...,  0.5388, -0.1632, -0.5568],\n",
            "        ...,\n",
            "        [ 0.6038,  1.0000,  0.9261,  ...,  0.4450,  0.3853, -0.9766],\n",
            "        [ 0.1574,  1.0000, -0.5999,  ..., -0.9342,  0.6105, -0.6255],\n",
            "        [-0.1677,  1.0000, -0.7793,  ..., -0.8077,  0.3871, -0.0921]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4664,  1.0000, -0.2865,  ..., -0.9372,  0.5046, -0.7598],\n",
            "        [ 0.6241,  1.0000, -0.1432,  ..., -0.6844,  0.6734, -0.8480],\n",
            "        [ 0.6917,  1.0000,  0.8985,  ...,  0.6540, -0.1946, -0.7546],\n",
            "        ...,\n",
            "        [ 0.0949,  1.0000, -0.4862,  ..., -0.8106,  0.6640, -0.7372],\n",
            "        [ 0.8806,  1.0000,  0.9653,  ...,  0.8338, -0.1304, -0.8544],\n",
            "        [ 0.6069,  1.0000,  0.9625,  ...,  0.6458, -0.1597, -0.6627]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6130,  1.0000,  0.9030,  ...,  0.7469, -0.1438, -0.8063],\n",
            "        [ 0.6060,  1.0000,  0.8785,  ...,  0.6924, -0.1691, -0.6594],\n",
            "        [ 0.0083,  1.0000,  0.9054,  ..., -0.2004,  0.1788, -0.9808],\n",
            "        ...,\n",
            "        [-0.3631,  1.0000, -0.7203,  ..., -0.8502,  0.3967, -0.6153],\n",
            "        [-0.1612,  1.0000, -0.6957,  ..., -0.7553,  0.7589, -0.6161],\n",
            "        [ 0.6563,  1.0000,  0.8896,  ...,  0.8700, -0.3306, -0.7093]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2586,  1.0000, -0.8474,  ..., -0.9167,  0.4215, -0.3343],\n",
            "        [-0.3377,  1.0000, -0.7318,  ..., -0.8845,  0.6170, -0.3268],\n",
            "        [ 0.5010,  1.0000, -0.1624,  ..., -0.7017,  0.6288, -0.7070],\n",
            "        ...,\n",
            "        [ 0.6152,  1.0000,  0.9021,  ...,  0.5420,  0.2479, -0.8667],\n",
            "        [-0.3584,  1.0000, -0.4990,  ..., -0.9217,  0.0883, -0.5741],\n",
            "        [-0.0722,  1.0000, -0.4529,  ..., -0.8989,  0.7478, -0.7674]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2657,  1.0000, -0.3257,  ..., -0.8539,  0.4862, -0.8887],\n",
            "        [ 0.5342,  1.0000,  0.9326,  ...,  0.3643,  0.1000, -0.7482],\n",
            "        [ 0.2846,  0.9998, -0.6283,  ..., -0.8510,  0.7108, -0.4352],\n",
            "        ...,\n",
            "        [ 0.7047,  1.0000,  0.9482,  ...,  0.6234, -0.0297, -0.9125],\n",
            "        [ 0.4593,  1.0000,  0.8935,  ...,  0.6609,  0.1217, -0.9514],\n",
            "        [ 0.4443,  1.0000,  0.7802,  ..., -0.7114,  0.4534, -0.9641]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6229,  1.0000,  0.8962,  ...,  0.7512, -0.2740, -0.7202],\n",
            "        [ 0.4523,  1.0000,  0.9069,  ..., -0.1593,  0.1993, -0.7806],\n",
            "        [ 0.7771,  1.0000,  0.9030,  ...,  0.8167, -0.3420, -0.7380],\n",
            "        ...,\n",
            "        [-0.3360,  1.0000, -0.7254,  ..., -0.9118,  0.5220, -0.3793],\n",
            "        [-0.3778,  1.0000, -0.8390,  ..., -0.9117,  0.4902, -0.1909],\n",
            "        [-0.0511,  1.0000, -0.7721,  ..., -0.9343,  0.7063, -0.7135]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2139,  1.0000, -0.4469,  ..., -0.8228,  0.7050, -0.8864],\n",
            "        [ 0.0326,  1.0000, -0.2833,  ..., -0.8259,  0.6123, -0.9098],\n",
            "        [ 0.7596,  1.0000,  0.8820,  ...,  0.8597, -0.3525, -0.5826],\n",
            "        ...,\n",
            "        [ 0.5896,  0.9998,  0.8881,  ...,  0.7745, -0.1032, -0.6325],\n",
            "        [ 0.7251,  1.0000,  0.9172,  ...,  0.7902, -0.3213, -0.7795],\n",
            "        [ 0.6901,  1.0000,  0.8880,  ...,  0.8119, -0.3521, -0.6283]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4610,  1.0000,  0.9093,  ...,  0.8540, -0.2233, -0.4790],\n",
            "        [ 0.7329,  1.0000,  0.9213,  ...,  0.7004, -0.4138, -0.8433],\n",
            "        [ 0.3070,  1.0000,  0.7871,  ..., -0.7047,  0.3339, -0.9560],\n",
            "        ...,\n",
            "        [-0.2827,  1.0000, -0.4729,  ..., -0.8992,  0.4496, -0.7886],\n",
            "        [ 0.8207,  1.0000,  0.9522,  ...,  0.8255, -0.1493, -0.6804],\n",
            "        [-0.0812,  1.0000, -0.8379,  ..., -0.9225,  0.5506, -0.4696]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6788,  1.0000,  0.9021,  ...,  0.8271, -0.3087, -0.5774],\n",
            "        [-0.2696,  1.0000, -0.7473,  ..., -0.8802,  0.4920, -0.4525],\n",
            "        [ 0.1730,  1.0000, -0.6074,  ..., -0.9015,  0.7773, -0.4972],\n",
            "        ...,\n",
            "        [ 0.7425,  1.0000,  0.9393,  ...,  0.7614, -0.1075, -0.7146],\n",
            "        [ 0.8239,  1.0000,  0.9319,  ...,  0.8723, -0.1774, -0.7779],\n",
            "        [ 0.6022,  1.0000,  0.8916,  ...,  0.5238,  0.0445, -0.7555]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7711,  1.0000,  0.8434,  ...,  0.7783, -0.5970, -0.6340],\n",
            "        [ 0.8238,  0.9999,  0.9440,  ...,  0.6412, -0.0722, -0.7713],\n",
            "        [ 0.2388,  1.0000, -0.7045,  ..., -0.8271,  0.4083, -0.6522],\n",
            "        ...,\n",
            "        [ 0.6672,  1.0000,  0.8916,  ...,  0.6754, -0.3906, -0.7575],\n",
            "        [ 0.6501,  1.0000,  0.8531,  ...,  0.4187, -0.0848, -0.7982],\n",
            "        [ 0.7037,  1.0000,  0.9157,  ...,  0.6641, -0.2933, -0.7508]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 6.8822e-01,  1.0000e+00,  8.5461e-01,  ...,  5.0816e-01,\n",
            "          7.5675e-04, -8.6687e-01],\n",
            "        [ 2.7577e-01,  1.0000e+00,  9.4601e-01,  ..., -1.2908e-03,\n",
            "          6.7362e-02, -9.0631e-01],\n",
            "        [ 7.1493e-01,  9.9999e-01,  9.3751e-01,  ...,  7.0669e-01,\n",
            "         -1.7892e-01, -7.1672e-01],\n",
            "        ...,\n",
            "        [ 2.7641e-01,  9.9999e-01, -5.3340e-01,  ..., -8.7515e-01,\n",
            "          5.7056e-01, -7.5053e-01],\n",
            "        [-1.6153e-01,  1.0000e+00, -7.5981e-01,  ..., -9.2849e-01,\n",
            "          4.0135e-01, -6.0424e-01],\n",
            "        [-6.7406e-02,  9.9999e-01, -4.7212e-01,  ..., -8.1443e-01,\n",
            "          6.3884e-01, -6.2212e-01]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6053,  1.0000,  0.9367,  ...,  0.7184, -0.2021, -0.7929],\n",
            "        [ 0.7815,  1.0000,  0.9515,  ...,  0.9122, -0.2229, -0.6432],\n",
            "        [ 0.5151,  1.0000,  0.8427,  ...,  0.1847, -0.3617, -0.9221],\n",
            "        ...,\n",
            "        [ 0.1507,  1.0000, -0.5692,  ..., -0.9411,  0.3553, -0.3095],\n",
            "        [ 0.7910,  1.0000,  0.9030,  ...,  0.7356,  0.1092, -0.8333],\n",
            "        [-0.1216,  1.0000, -0.2713,  ..., -0.8036,  0.6840, -0.7008]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7139,  1.0000,  0.8676,  ...,  0.8554, -0.2981, -0.5824],\n",
            "        [ 0.7411,  1.0000,  0.8839,  ...,  0.8378, -0.5848, -0.4810],\n",
            "        [ 0.0409,  1.0000,  0.6359,  ..., -0.7991,  0.4790, -0.9616],\n",
            "        ...,\n",
            "        [ 0.6466,  1.0000,  0.8649,  ...,  0.8613, -0.1508, -0.6101],\n",
            "        [-0.2982,  1.0000, -0.7008,  ..., -0.9188,  0.3126, -0.7539],\n",
            "        [ 0.7221,  1.0000,  0.9022,  ...,  0.8490, -0.3057, -0.6774]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0394,  1.0000,  0.5323,  ..., -0.7504,  0.7699, -0.9215],\n",
            "        [ 0.7285,  1.0000,  0.8815,  ...,  0.7511, -0.4214, -0.6777],\n",
            "        [ 0.6308,  1.0000,  0.9338,  ...,  0.5406, -0.4381, -0.7442],\n",
            "        ...,\n",
            "        [ 0.5812,  1.0000,  0.9185,  ...,  0.2640,  0.1844, -0.9782],\n",
            "        [-0.6201,  1.0000,  0.5207,  ..., -0.9124,  0.2367, -0.8462],\n",
            "        [-0.2296,  1.0000, -0.6529,  ..., -0.9236,  0.4564, -0.4403]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 5.8186e-01,  1.0000e+00,  8.2404e-01,  ...,  5.5584e-01,\n",
            "         -1.7333e-01, -6.1580e-01],\n",
            "        [ 7.7903e-01,  1.0000e+00,  8.6495e-01,  ...,  8.6978e-01,\n",
            "         -2.5897e-01, -5.6379e-01],\n",
            "        [-3.8161e-01,  9.9924e-01, -2.4867e-01,  ..., -8.3386e-01,\n",
            "          4.1810e-01, -6.8490e-01],\n",
            "        ...,\n",
            "        [ 3.8495e-01,  1.0000e+00,  6.5658e-01,  ..., -7.8462e-01,\n",
            "          4.9465e-01, -9.7215e-01],\n",
            "        [ 8.4031e-01,  1.0000e+00,  9.0996e-01,  ...,  7.9928e-01,\n",
            "         -1.4549e-01, -7.7254e-01],\n",
            "        [-3.5204e-01,  1.0000e+00, -8.1877e-04,  ..., -7.8592e-01,\n",
            "          4.8351e-01, -8.8584e-01]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1908,  1.0000, -0.8424,  ..., -0.9201,  0.5363, -0.6407],\n",
            "        [ 0.7511,  1.0000,  0.9318,  ...,  0.8166, -0.3835, -0.6148],\n",
            "        [ 0.1410,  1.0000, -0.4890,  ..., -0.9302,  0.8086, -0.7740],\n",
            "        ...,\n",
            "        [ 0.6648,  1.0000,  0.8291,  ...,  0.7388, -0.2326, -0.7970],\n",
            "        [ 0.5685,  1.0000,  0.8637,  ...,  0.6977, -0.2955, -0.7518],\n",
            "        [ 0.6840,  1.0000,  0.8772,  ...,  0.5893, -0.3655, -0.6300]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2027,  1.0000, -0.7700,  ..., -0.8340,  0.3504, -0.2574],\n",
            "        [ 0.7987,  1.0000,  0.9172,  ...,  0.8264, -0.0698, -0.6327],\n",
            "        [ 0.7447,  1.0000,  0.9022,  ...,  0.7782, -0.3046, -0.8038],\n",
            "        ...,\n",
            "        [ 0.7025,  1.0000,  0.8825,  ...,  0.6454, -0.1838, -0.5505],\n",
            "        [ 0.0794,  1.0000, -0.4740,  ..., -0.8329,  0.5526, -0.5341],\n",
            "        [-0.0044,  1.0000, -0.4484,  ..., -0.9377,  0.6423, -0.7237]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0354,  1.0000,  0.2799,  ..., -0.7661,  0.4936, -0.9382],\n",
            "        [ 0.7971,  1.0000,  0.8396,  ...,  0.7698, -0.5123, -0.4508],\n",
            "        [ 0.7636,  1.0000,  0.9291,  ...,  0.8531, -0.3158, -0.8065],\n",
            "        ...,\n",
            "        [ 0.7607,  1.0000,  0.8769,  ...,  0.7418, -0.2090, -0.7064],\n",
            "        [ 0.7942,  1.0000,  0.8866,  ...,  0.6682, -0.1855, -0.8187],\n",
            "        [ 0.7198,  1.0000,  0.9246,  ...,  0.8902, -0.3754, -0.6359]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1069,  1.0000,  0.7380,  ..., -0.7636,  0.6414, -0.9266],\n",
            "        [ 0.6547,  1.0000,  0.9082,  ...,  0.7658, -0.2820, -0.6216],\n",
            "        [ 0.4860,  1.0000,  0.9272,  ...,  0.3121,  0.0268, -0.8568],\n",
            "        ...,\n",
            "        [-0.1680,  1.0000, -0.4958,  ..., -0.8271,  0.5767, -0.6521],\n",
            "        [-0.0749,  1.0000, -0.7612,  ..., -0.8390,  0.1584, -0.5969],\n",
            "        [-0.2060,  1.0000, -0.7492,  ..., -0.8087,  0.3137, -0.2963]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6421,  1.0000,  0.8657,  ...,  0.7422, -0.3166, -0.6048],\n",
            "        [-0.1506,  1.0000, -0.5611,  ..., -0.9018,  0.7517, -0.5188],\n",
            "        [-0.1878,  1.0000, -0.4064,  ..., -0.8437,  0.5736, -0.6165],\n",
            "        ...,\n",
            "        [-0.3738,  1.0000, -0.8572,  ..., -0.8272,  0.4634, -0.2600],\n",
            "        [ 0.6865,  1.0000,  0.9035,  ...,  0.8156, -0.1330, -0.6455],\n",
            "        [ 0.6746,  1.0000,  0.9258,  ...,  0.4143,  0.0741, -0.8875]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7699,  1.0000,  0.8754,  ...,  0.7955, -0.2635, -0.6322],\n",
            "        [ 0.5813,  1.0000,  0.8929,  ..., -0.1045,  0.2238, -0.9477],\n",
            "        [ 0.2193,  1.0000, -0.4051,  ..., -0.8154,  0.7865, -0.8605],\n",
            "        ...,\n",
            "        [ 0.8138,  1.0000,  0.8644,  ...,  0.7831, -0.2725, -0.5272],\n",
            "        [ 0.1244,  1.0000, -0.5429,  ..., -0.8801,  0.6476, -0.6578],\n",
            "        [-0.0886,  1.0000, -0.6021,  ..., -0.9162,  0.6079, -0.6625]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2037,  0.9999, -0.8110,  ..., -0.8355,  0.4998, -0.3796],\n",
            "        [ 0.6870,  1.0000,  0.8802,  ...,  0.8410, -0.3131, -0.6044],\n",
            "        [ 0.6491,  1.0000,  0.8832,  ...,  0.7573, -0.1067, -0.6389],\n",
            "        ...,\n",
            "        [ 0.6755,  1.0000,  0.9199,  ...,  0.7117, -0.4099, -0.8507],\n",
            "        [ 0.8472,  1.0000,  0.9239,  ...,  0.7262, -0.1740, -0.7672],\n",
            "        [ 0.0653,  1.0000, -0.5365,  ..., -0.9275,  0.3594, -0.6023]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4475,  1.0000,  0.9663,  ...,  0.3884, -0.0746, -0.9320],\n",
            "        [ 0.1301,  0.9999,  0.8814,  ...,  0.1727, -0.1250, -0.8196],\n",
            "        [ 0.2753,  1.0000, -0.2078,  ..., -0.8747,  0.5795, -0.7644],\n",
            "        ...,\n",
            "        [-0.3353,  1.0000, -0.7747,  ..., -0.9135,  0.3284, -0.4416],\n",
            "        [-0.4794,  0.9999, -0.6366,  ..., -0.8724,  0.0857, -0.0821],\n",
            "        [ 0.0367,  0.9999, -0.4175,  ..., -0.8826,  0.5700, -0.7948]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7191,  1.0000,  0.8756,  ...,  0.8803, -0.2715, -0.4632],\n",
            "        [-0.0018,  1.0000, -0.6983,  ..., -0.9255,  0.5901, -0.6855],\n",
            "        [ 0.4083,  1.0000,  0.9280,  ...,  0.0344,  0.1469, -0.9300],\n",
            "        ...,\n",
            "        [ 0.6706,  1.0000,  0.9271,  ...,  0.8535, -0.3475, -0.5682],\n",
            "        [-0.3499,  1.0000, -0.0104,  ..., -0.9013,  0.4630, -0.4087],\n",
            "        [ 0.7221,  1.0000,  0.9009,  ...,  0.2115,  0.0534, -0.7627]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6740,  1.0000,  0.9003,  ...,  0.8574, -0.4445, -0.7134],\n",
            "        [ 0.7721,  1.0000,  0.8148,  ...,  0.8469, -0.3480, -0.7218],\n",
            "        [ 0.7555,  1.0000,  0.9435,  ...,  0.8964, -0.2139, -0.7404],\n",
            "        ...,\n",
            "        [ 0.7807,  1.0000,  0.8696,  ...,  0.7823, -0.3348, -0.6611],\n",
            "        [ 0.6836,  1.0000,  0.8528,  ...,  0.7996, -0.3845, -0.5307],\n",
            "        [-0.1086,  1.0000, -0.7743,  ..., -0.8893,  0.1724, -0.3092]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3772,  1.0000,  0.3410,  ..., -0.4333,  0.4599, -0.8445],\n",
            "        [ 0.7875,  1.0000,  0.9193,  ...,  0.8451, -0.3069, -0.6481],\n",
            "        [ 0.0251,  1.0000, -0.7818,  ..., -0.8774,  0.5537, -0.4301],\n",
            "        ...,\n",
            "        [-0.4168,  1.0000, -0.4691,  ..., -0.9240,  0.4863, -0.5374],\n",
            "        [ 0.6680,  0.9999,  0.9097,  ...,  0.6838, -0.2540, -0.6655],\n",
            "        [ 0.6255,  1.0000,  0.8982,  ...,  0.7790, -0.1931, -0.6335]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1027,  1.0000, -0.6573,  ..., -0.9035,  0.4430, -0.8194],\n",
            "        [ 0.0658,  1.0000, -0.7373,  ..., -0.9193,  0.3253, -0.5520],\n",
            "        [ 0.7800,  1.0000,  0.8799,  ...,  0.8626, -0.1310, -0.6584],\n",
            "        ...,\n",
            "        [ 0.2347,  1.0000, -0.8257,  ..., -0.8575,  0.6252, -0.5083],\n",
            "        [ 0.6218,  1.0000,  0.9250,  ...,  0.6500, -0.0293, -0.5534],\n",
            "        [-0.0875,  1.0000, -0.7194,  ..., -0.9143,  0.3488, -0.3189]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7471,  1.0000,  0.9214,  ...,  0.8688, -0.3050, -0.6628],\n",
            "        [-0.3787,  1.0000, -0.4323,  ..., -0.9016,  0.7146, -0.4868],\n",
            "        [ 0.6322,  1.0000,  0.9298,  ...,  0.8106, -0.3063, -0.5391],\n",
            "        ...,\n",
            "        [ 0.6602,  1.0000,  0.8415,  ...,  0.6874, -0.0675, -0.7486],\n",
            "        [ 0.8680,  1.0000,  0.9019,  ...,  0.6082, -0.3125, -0.5182],\n",
            "        [ 0.7475,  1.0000,  0.8641,  ...,  0.8576, -0.3587, -0.5824]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7117,  1.0000,  0.7805,  ..., -0.3346,  0.1848, -0.9811],\n",
            "        [-0.3198,  1.0000, -0.7025,  ..., -0.9251,  0.3290, -0.3984],\n",
            "        [-0.2032,  1.0000, -0.7089,  ..., -0.8934,  0.3183, -0.3751],\n",
            "        ...,\n",
            "        [-0.3270,  1.0000, -0.2597,  ..., -0.9017,  0.6953, -0.7273],\n",
            "        [-0.1137,  0.9998, -0.7667,  ..., -0.8120,  0.2697, -0.2342],\n",
            "        [ 0.0326,  1.0000, -0.6672,  ..., -0.8694,  0.5515, -0.7847]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5779,  1.0000,  0.9022,  ...,  0.1069,  0.2178, -0.9303],\n",
            "        [-0.3053,  0.9998, -0.8066,  ..., -0.8824,  0.4001, -0.2382],\n",
            "        [-0.4999,  1.0000, -0.6044,  ..., -0.9184,  0.2470, -0.7710],\n",
            "        ...,\n",
            "        [ 0.8487,  1.0000,  0.9033,  ...,  0.8156, -0.2031, -0.7550],\n",
            "        [ 0.7267,  1.0000,  0.8518,  ...,  0.8222, -0.2461, -0.6207],\n",
            "        [-0.2162,  1.0000, -0.6259,  ..., -0.8410,  0.2043, -0.2846]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.8370,  1.0000,  0.8895,  ...,  0.8663, -0.1981, -0.7308],\n",
            "        [-0.4810,  1.0000, -0.7920,  ..., -0.8620,  0.1459, -0.3145],\n",
            "        [ 0.7918,  1.0000,  0.9015,  ...,  0.6026, -0.4289, -0.8123],\n",
            "        ...,\n",
            "        [ 0.6876,  1.0000,  0.8617,  ...,  0.8314, -0.3598, -0.6560],\n",
            "        [-0.1681,  1.0000, -0.4822,  ..., -0.8687,  0.7389, -0.8985],\n",
            "        [ 0.7039,  1.0000,  0.8702,  ...,  0.8484, -0.3049, -0.4858]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.8085,  1.0000,  0.8954,  ...,  0.8761, -0.2042, -0.5943],\n",
            "        [-0.4090,  1.0000, -0.5276,  ..., -0.6871,  0.6415, -0.5638],\n",
            "        [ 0.6187,  1.0000,  0.8761,  ...,  0.1209, -0.2765, -0.9715],\n",
            "        ...,\n",
            "        [ 0.7695,  1.0000,  0.8878,  ...,  0.8398, -0.3840, -0.5684],\n",
            "        [-0.1152,  1.0000,  0.0661,  ..., -0.7941, -0.1201, -0.9240],\n",
            "        [ 0.1658,  0.9999,  0.8783,  ..., -0.2405, -0.1679, -0.7964]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7828,  1.0000,  0.8725,  ...,  0.8259, -0.1566, -0.6601],\n",
            "        [ 0.3078,  1.0000,  0.3412,  ..., -0.6419,  0.1307, -0.9579],\n",
            "        [-0.4579,  1.0000, -0.8237,  ..., -0.8876,  0.5941, -0.5955],\n",
            "        ...,\n",
            "        [ 0.0037,  1.0000, -0.3977,  ..., -0.8566,  0.3743, -0.7073],\n",
            "        [-0.0432,  1.0000,  0.3866,  ..., -0.7402,  0.5466, -0.9467],\n",
            "        [ 0.5004,  1.0000,  0.8175,  ...,  0.4972,  0.0433, -0.8745]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6272,  1.0000,  0.8740,  ...,  0.8881, -0.3619, -0.4405],\n",
            "        [-0.0865,  1.0000, -0.6891,  ..., -0.8641,  0.4796, -0.5788],\n",
            "        [-0.2466,  1.0000, -0.6427,  ..., -0.8553,  0.3905, -0.4380],\n",
            "        ...,\n",
            "        [-0.1354,  1.0000,  0.8428,  ..., -0.4504,  0.1661, -0.9473],\n",
            "        [ 0.6691,  1.0000,  0.8784,  ...,  0.8425, -0.6001, -0.5125],\n",
            "        [ 0.7847,  1.0000,  0.8929,  ...,  0.8523, -0.2034, -0.6605]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7282,  1.0000,  0.9341,  ...,  0.8590, -0.3389, -0.5840],\n",
            "        [ 0.7017,  1.0000,  0.8923,  ...,  0.8160,  0.0214, -0.7881],\n",
            "        [-0.3131,  1.0000, -0.5148,  ..., -0.8867,  0.4379, -0.4979],\n",
            "        ...,\n",
            "        [-0.0076,  1.0000, -0.5701,  ..., -0.8809,  0.4419, -0.6261],\n",
            "        [ 0.6786,  1.0000,  0.8945,  ...,  0.7954, -0.5500, -0.6106],\n",
            "        [ 0.7919,  1.0000,  0.8591,  ...,  0.9061,  0.0274, -0.5954]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2805,  1.0000,  0.6429,  ..., -0.1539,  0.2095, -0.9599],\n",
            "        [ 0.7760,  1.0000,  0.9107,  ...,  0.7867,  0.2693, -0.7375],\n",
            "        [-0.4485,  1.0000, -0.7265,  ..., -0.8953,  0.3406, -0.4098],\n",
            "        ...,\n",
            "        [ 0.7025,  1.0000,  0.8844,  ...,  0.8584, -0.2100, -0.6593],\n",
            "        [-0.4048,  1.0000,  0.4502,  ..., -0.7771,  0.1391, -0.9370],\n",
            "        [ 0.6985,  1.0000,  0.9097,  ...,  0.5576, -0.0077, -0.6696]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6410,  1.0000,  0.9368,  ...,  0.7841, -0.1667, -0.7884],\n",
            "        [ 0.7213,  1.0000,  0.8267,  ...,  0.6603, -0.2731, -0.6906],\n",
            "        [-0.1639,  0.9998, -0.7441,  ..., -0.8668,  0.6724, -0.5383],\n",
            "        ...,\n",
            "        [ 0.8689,  1.0000,  0.9273,  ...,  0.8469, -0.0272, -0.7274],\n",
            "        [ 0.7186,  1.0000,  0.8693,  ...,  0.7297, -0.1599, -0.6396],\n",
            "        [-0.0929,  1.0000,  0.6716,  ..., -0.0703,  0.3802, -0.8898]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7852,  1.0000,  0.8864,  ...,  0.8490, -0.3001, -0.7895],\n",
            "        [ 0.7229,  1.0000,  0.9088,  ...,  0.8002, -0.0877, -0.6178],\n",
            "        [ 0.6616,  1.0000,  0.8020,  ...,  0.3432, -0.2460, -0.8788],\n",
            "        ...,\n",
            "        [-0.0369,  1.0000, -0.7113,  ..., -0.7994,  0.4460, -0.3171],\n",
            "        [ 0.6718,  1.0000,  0.8736,  ...,  0.7218, -0.5080, -0.6138],\n",
            "        [-0.3958,  1.0000, -0.7965,  ..., -0.8401,  0.4583, -0.3698]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7407,  1.0000,  0.9161,  ...,  0.8083, -0.4027, -0.6087],\n",
            "        [ 0.7116,  1.0000,  0.8382,  ...,  0.7374, -0.4268, -0.5008],\n",
            "        [ 0.0224,  1.0000,  0.6398,  ..., -0.6897,  0.7024, -0.9604],\n",
            "        ...,\n",
            "        [-0.2959,  1.0000, -0.6464,  ..., -0.8405,  0.6693, -0.7835],\n",
            "        [-0.2398,  1.0000, -0.5549,  ..., -0.8653,  0.4915, -0.6179],\n",
            "        [ 0.7112,  1.0000,  0.9077,  ...,  0.6214, -0.1254, -0.7419]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1772,  1.0000, -0.7140,  ..., -0.9117,  0.4938, -0.5904],\n",
            "        [-0.2094,  1.0000, -0.7031,  ..., -0.9453,  0.2576, -0.1450],\n",
            "        [ 0.3668,  1.0000,  0.8104,  ..., -0.1567, -0.3269, -0.9351],\n",
            "        ...,\n",
            "        [-0.2177,  0.9999, -0.8471,  ..., -0.9238,  0.4480, -0.2413],\n",
            "        [ 0.4239,  1.0000,  0.8186,  ..., -0.5874,  0.2535, -0.9762],\n",
            "        [-0.2138,  1.0000, -0.6239,  ..., -0.7928,  0.5179, -0.4211]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6870,  1.0000,  0.9037,  ...,  0.6750, -0.2270, -0.7449],\n",
            "        [ 0.7585,  1.0000,  0.8865,  ...,  0.0487,  0.0417, -0.9615],\n",
            "        [ 0.0254,  1.0000, -0.4436,  ..., -0.8930,  0.5734, -0.7971],\n",
            "        ...,\n",
            "        [ 0.7578,  1.0000,  0.8877,  ...,  0.8122, -0.2139, -0.7832],\n",
            "        [ 0.5465,  1.0000,  0.8846,  ...,  0.8060, -0.3868, -0.5600],\n",
            "        [ 0.5734,  1.0000,  0.8964,  ...,  0.3898, -0.3819, -0.8359]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7527,  1.0000,  0.9188,  ...,  0.7164, -0.2932, -0.7167],\n",
            "        [ 0.2236,  1.0000,  0.0528,  ..., -0.8388,  0.7020, -0.9598],\n",
            "        [ 0.4971,  1.0000,  0.8348,  ..., -0.4000,  0.4206, -0.9039],\n",
            "        ...,\n",
            "        [ 0.6887,  1.0000,  0.8671,  ...,  0.7344, -0.2215, -0.6117],\n",
            "        [ 0.1998,  1.0000, -0.1181,  ..., -0.8796,  0.6881, -0.8832],\n",
            "        [-0.3690,  1.0000, -0.7025,  ..., -0.8976,  0.5119, -0.4734]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2975,  1.0000, -0.8656,  ..., -0.9121,  0.3110, -0.0676],\n",
            "        [ 0.4318,  1.0000,  0.8544,  ..., -0.7684,  0.2944, -0.9191],\n",
            "        [ 0.6525,  1.0000,  0.8853,  ...,  0.7456, -0.4359, -0.7943],\n",
            "        ...,\n",
            "        [ 0.3894,  1.0000,  0.8805,  ...,  0.4952, -0.0095, -0.7501],\n",
            "        [ 0.7216,  1.0000,  0.8386,  ...,  0.6780, -0.2298, -0.4012],\n",
            "        [ 0.4810,  1.0000,  0.9330,  ...,  0.7016, -0.1923, -0.7251]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0681,  0.9998, -0.6137,  ..., -0.8342,  0.2675, -0.3456],\n",
            "        [-0.1602,  1.0000, -0.4950,  ..., -0.9114,  0.5456, -0.5843],\n",
            "        [ 0.0637,  0.9999, -0.7820,  ..., -0.9064,  0.5142, -0.0677],\n",
            "        ...,\n",
            "        [ 0.0121,  1.0000, -0.3923,  ..., -0.8178,  0.5647, -0.2036],\n",
            "        [ 0.0617,  1.0000, -0.5821,  ..., -0.8064,  0.7403, -0.7129],\n",
            "        [ 0.1474,  1.0000,  0.1168,  ..., -0.7805,  0.7925, -0.8719]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4688,  1.0000,  0.8800,  ...,  0.0736, -0.2037, -0.9413],\n",
            "        [-0.1891,  1.0000, -0.6352,  ..., -0.8977,  0.3609, -0.4110],\n",
            "        [-0.1061,  1.0000, -0.5925,  ..., -0.8098,  0.7414, -0.8288],\n",
            "        ...,\n",
            "        [-0.0419,  0.9991,  0.6162,  ..., -0.1182,  0.1831, -0.8930],\n",
            "        [-0.4563,  0.9999, -0.7532,  ..., -0.8857,  0.2487, -0.4047],\n",
            "        [-0.0921,  0.9997,  0.5818,  ..., -0.5697,  0.1110, -0.9225]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1579,  1.0000,  0.0441,  ..., -0.8825,  0.5495, -0.8634],\n",
            "        [ 0.6399,  1.0000,  0.8870,  ...,  0.6550, -0.3901, -0.7129],\n",
            "        [ 0.6719,  1.0000,  0.8479,  ...,  0.6533, -0.2654, -0.7448],\n",
            "        ...,\n",
            "        [-0.3372,  1.0000, -0.7040,  ..., -0.9056,  0.1026, -0.5278],\n",
            "        [-0.3029,  1.0000, -0.4120,  ..., -0.8622,  0.4088, -0.6121],\n",
            "        [-0.2386,  0.9999, -0.6930,  ..., -0.9162,  0.1835, -0.3330]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6776,  1.0000,  0.8964,  ...,  0.7869, -0.3893, -0.6632],\n",
            "        [ 0.5571,  1.0000,  0.8555,  ...,  0.5090, -0.0724, -0.8249],\n",
            "        [ 0.7479,  1.0000,  0.8947,  ...,  0.5720, -0.0874, -0.8251],\n",
            "        ...,\n",
            "        [-0.1944,  1.0000,  0.2402,  ..., -0.5716,  0.2717, -0.9285],\n",
            "        [ 0.5133,  1.0000,  0.8819,  ...,  0.5113, -0.3711, -0.5137],\n",
            "        [ 0.6352,  1.0000,  0.8831,  ...,  0.7885, -0.4813, -0.4945]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0631,  1.0000, -0.6798,  ..., -0.8247,  0.5398, -0.8314],\n",
            "        [ 0.7337,  1.0000,  0.9007,  ...,  0.4586, -0.4982, -0.8454],\n",
            "        [-0.3645,  1.0000, -0.3236,  ..., -0.9433,  0.5865, -0.8613],\n",
            "        ...,\n",
            "        [ 0.5688,  1.0000,  0.8612,  ...,  0.6268, -0.3771, -0.6502],\n",
            "        [ 0.5979,  1.0000,  0.8534,  ..., -0.6135,  0.1521, -0.9695],\n",
            "        [-0.1740,  0.9999, -0.7370,  ..., -0.8380,  0.2582, -0.1344]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5175,  0.9999,  0.8144,  ...,  0.4444, -0.3621, -0.6013],\n",
            "        [ 0.4380,  1.0000,  0.7281,  ..., -0.4933,  0.3630, -0.9791],\n",
            "        [-0.2247,  1.0000, -0.2857,  ..., -0.8632,  0.4362, -0.6976],\n",
            "        ...,\n",
            "        [-0.0707,  1.0000,  0.4444,  ..., -0.8584,  0.4261, -0.9556],\n",
            "        [ 0.6689,  1.0000,  0.8988,  ...,  0.8213, -0.4213, -0.5211],\n",
            "        [-0.0381,  1.0000, -0.4171,  ..., -0.8118,  0.6044, -0.6181]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2596,  1.0000, -0.6780,  ..., -0.8983,  0.3142, -0.3378],\n",
            "        [ 0.0698,  1.0000, -0.1935,  ..., -0.8923,  0.4442, -0.6760],\n",
            "        [-0.1792,  1.0000,  0.3372,  ..., -0.7331,  0.4591, -0.7642],\n",
            "        ...,\n",
            "        [ 0.4814,  1.0000,  0.9184,  ...,  0.4133, -0.2911, -0.7131],\n",
            "        [ 0.6157,  1.0000,  0.8679,  ...,  0.6549, -0.2619, -0.4945],\n",
            "        [ 0.7433,  1.0000,  0.8333,  ...,  0.8450, -0.4458, -0.7297]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4032,  1.0000, -0.6813,  ..., -0.8984,  0.1008, -0.4249],\n",
            "        [-0.3874,  1.0000, -0.7659,  ..., -0.8747,  0.1101, -0.0946],\n",
            "        [ 0.3390,  0.9995,  0.8918,  ...,  0.1973, -0.2599, -0.6963],\n",
            "        ...,\n",
            "        [ 0.4232,  1.0000,  0.8005,  ...,  0.4201, -0.4035, -0.5476],\n",
            "        [-0.2263,  1.0000, -0.5253,  ..., -0.8684,  0.4243, -0.4772],\n",
            "        [ 0.5923,  1.0000,  0.4600,  ..., -0.3019,  0.4395, -0.9710]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7534,  1.0000,  0.8091,  ...,  0.6200, -0.2669, -0.7219],\n",
            "        [ 0.5948,  1.0000,  0.8481,  ...,  0.3419, -0.1602, -0.7603],\n",
            "        [-0.1000,  1.0000,  0.8765,  ..., -0.2912, -0.1106, -0.9039],\n",
            "        ...,\n",
            "        [-0.4346,  1.0000, -0.2430,  ..., -0.7483,  0.4150, -0.5018],\n",
            "        [ 0.5754,  1.0000,  0.8998,  ...,  0.2881, -0.3553, -0.6882],\n",
            "        [-0.1758,  1.0000, -0.5099,  ..., -0.8833,  0.0031, -0.6229]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7022,  1.0000,  0.8979,  ...,  0.6978, -0.3397, -0.5856],\n",
            "        [ 0.4735,  1.0000,  0.7662,  ...,  0.6209, -0.1007, -0.7273],\n",
            "        [ 0.5466,  1.0000,  0.8248,  ...,  0.4596, -0.4570, -0.6203],\n",
            "        ...,\n",
            "        [ 0.6794,  0.9999,  0.7930,  ...,  0.6347, -0.5759, -0.5536],\n",
            "        [-0.2166,  1.0000, -0.3686,  ..., -0.8406,  0.0311, -0.4560],\n",
            "        [ 0.5285,  1.0000,  0.9011,  ...,  0.1663, -0.0871, -0.7500]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2185,  1.0000, -0.2800,  ..., -0.8356,  0.2639, -0.8713],\n",
            "        [-0.4512,  1.0000, -0.6808,  ..., -0.8759,  0.2070, -0.4137],\n",
            "        [-0.3299,  1.0000, -0.6909,  ..., -0.8837,  0.0275, -0.4138],\n",
            "        ...,\n",
            "        [ 0.6359,  1.0000,  0.8829,  ...,  0.6548, -0.4496, -0.4250],\n",
            "        [ 0.6313,  1.0000,  0.8896,  ...,  0.3547, -0.2734, -0.7879],\n",
            "        [ 0.8042,  1.0000,  0.8977,  ...,  0.7195, -0.1494, -0.7426]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2227,  1.0000, -0.6118,  ..., -0.7814,  0.0135, -0.3540],\n",
            "        [ 0.5962,  1.0000,  0.7553,  ...,  0.5717, -0.1339, -0.7662],\n",
            "        [-0.2918,  1.0000, -0.6836,  ..., -0.9107,  0.4703, -0.2968],\n",
            "        ...,\n",
            "        [ 0.5839,  1.0000,  0.7727,  ...,  0.4300, -0.3118, -0.4765],\n",
            "        [ 0.6541,  1.0000,  0.9540,  ..., -0.2222,  0.4151, -0.9701],\n",
            "        [ 0.6488,  1.0000,  0.8621,  ...,  0.6243, -0.2372, -0.4556]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6338,  1.0000,  0.8740,  ...,  0.4998, -0.2149, -0.4751],\n",
            "        [ 0.7914,  1.0000,  0.8480,  ...,  0.7401, -0.1396, -0.6881],\n",
            "        [ 0.4895,  1.0000,  0.8995,  ..., -0.0510, -0.5017, -0.7036],\n",
            "        ...,\n",
            "        [-0.2290,  1.0000, -0.6804,  ..., -0.9138,  0.1790, -0.2708],\n",
            "        [ 0.5388,  1.0000,  0.8006,  ..., -0.1345,  0.3685, -0.9377],\n",
            "        [ 0.6262,  0.9999,  0.8365,  ...,  0.6183, -0.4678, -0.6187]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1923,  1.0000, -0.8304,  ..., -0.8969,  0.3069, -0.2445],\n",
            "        [ 0.2583,  1.0000, -0.1804,  ..., -0.8681,  0.1340, -0.4368],\n",
            "        [-0.0434,  1.0000, -0.1144,  ..., -0.8763,  0.4082, -0.9205],\n",
            "        ...,\n",
            "        [-0.3772,  1.0000, -0.6443,  ..., -0.8313,  0.1056, -0.5594],\n",
            "        [ 0.4477,  1.0000,  0.7538,  ...,  0.5426, -0.5378, -0.5631],\n",
            "        [-0.3840,  0.9999, -0.5978,  ..., -0.8628,  0.4360, -0.0078]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6519,  1.0000,  0.8695,  ...,  0.2653, -0.0489, -0.7780],\n",
            "        [ 0.5391,  1.0000,  0.8644,  ...,  0.7069, -0.4869, -0.5858],\n",
            "        [-0.1097,  1.0000, -0.8770,  ..., -0.8992,  0.3800, -0.3612],\n",
            "        ...,\n",
            "        [ 0.6450,  0.9998,  0.9258,  ...,  0.6949, -0.4409, -0.4078],\n",
            "        [-0.0201,  1.0000, -0.5203,  ..., -0.7661, -0.1215, -0.3685],\n",
            "        [ 0.6967,  1.0000,  0.8620,  ...,  0.7247, -0.4446, -0.5601]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2717,  1.0000, -0.4776,  ..., -0.8592,  0.5066, -0.7642],\n",
            "        [ 0.5705,  1.0000,  0.8662,  ...,  0.3692, -0.2248, -0.6641],\n",
            "        [-0.4479,  1.0000, -0.7039,  ..., -0.8854,  0.0715, -0.6982],\n",
            "        ...,\n",
            "        [ 0.2045,  1.0000,  0.7792,  ...,  0.2375,  0.5810, -0.9491],\n",
            "        [-0.4444,  1.0000, -0.6112,  ..., -0.9059,  0.1635, -0.7102],\n",
            "        [ 0.6383,  1.0000,  0.8770,  ...,  0.5323, -0.1840, -0.8588]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6067,  1.0000,  0.7742,  ...,  0.0400, -0.1782, -0.7693],\n",
            "        [ 0.4486,  1.0000,  0.9221,  ...,  0.3729, -0.3857, -0.6301],\n",
            "        [-0.3582,  0.9995, -0.6979,  ..., -0.9103,  0.1050,  0.0200],\n",
            "        ...,\n",
            "        [-0.1536,  0.9980,  0.7517,  ..., -0.1851, -0.1214, -0.6068],\n",
            "        [ 0.7209,  1.0000,  0.8668,  ...,  0.7024, -0.4212, -0.6002],\n",
            "        [-0.5823,  0.9999, -0.7985,  ..., -0.8882,  0.4336, -0.3590]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0093,  1.0000, -0.6126,  ..., -0.8505,  0.1998, -0.3186],\n",
            "        [ 0.4798,  1.0000,  0.7784,  ...,  0.4111, -0.3474, -0.7365],\n",
            "        [-0.2694,  0.9999,  0.6001,  ..., -0.4656,  0.4050, -0.6451],\n",
            "        ...,\n",
            "        [ 0.3551,  0.9999,  0.8936,  ..., -0.2881, -0.6007, -0.8589],\n",
            "        [ 0.4726,  1.0000,  0.7706,  ..., -0.6676,  0.2062, -0.9565],\n",
            "        [-0.0815,  1.0000, -0.2020,  ..., -0.8651,  0.2674, -0.8834]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3095,  0.9999, -0.8319,  ..., -0.8591,  0.3005, -0.3001],\n",
            "        [-0.4119,  0.9997, -0.8398,  ..., -0.9309,  0.2278, -0.3553],\n",
            "        [-0.3413,  0.9999, -0.7668,  ..., -0.9215,  0.3715, -0.0902],\n",
            "        ...,\n",
            "        [-0.1554,  1.0000,  0.2737,  ..., -0.8343,  0.5182, -0.9487],\n",
            "        [-0.1421,  0.9999, -0.5271,  ..., -0.9423,  0.3286, -0.6057],\n",
            "        [-0.3602,  0.9999, -0.5949,  ..., -0.8553,  0.4006, -0.1938]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2809,  1.0000, -0.5001,  ..., -0.8826,  0.2722, -0.6781],\n",
            "        [-0.1861,  1.0000, -0.5042,  ..., -0.8680,  0.2908, -0.8258],\n",
            "        [-0.3294,  0.9991, -0.7099,  ..., -0.9169,  0.0760, -0.0752],\n",
            "        ...,\n",
            "        [ 0.4350,  1.0000,  0.8801,  ...,  0.5459, -0.0719, -0.9349],\n",
            "        [-0.5071,  0.9997, -0.7704,  ..., -0.9576,  0.0268, -0.3943],\n",
            "        [ 0.7129,  1.0000,  0.9022,  ...,  0.4604,  0.0897, -0.9084]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1003,  0.9997, -0.7107,  ..., -0.9022, -0.1663, -0.2581],\n",
            "        [ 0.5299,  0.9999,  0.8567,  ...,  0.2979, -0.2226, -0.5664],\n",
            "        [-0.2061,  1.0000, -0.5658,  ..., -0.8334,  0.3950, -0.8306],\n",
            "        ...,\n",
            "        [ 0.2907,  1.0000,  0.6536,  ..., -0.8880,  0.4261, -0.9879],\n",
            "        [ 0.4412,  0.9999,  0.8441,  ...,  0.6084, -0.4137, -0.4894],\n",
            "        [-0.4305,  1.0000, -0.5523,  ..., -0.8904,  0.3354, -0.5080]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1960,  1.0000,  0.6312,  ..., -0.7264,  0.2673, -0.9025],\n",
            "        [ 0.5630,  0.9999,  0.8956,  ...,  0.4467, -0.4806, -0.3670],\n",
            "        [ 0.4392,  0.9999,  0.9014,  ...,  0.3759, -0.3748, -0.6293],\n",
            "        ...,\n",
            "        [-0.2117,  1.0000, -0.6644,  ..., -0.9295,  0.4032, -0.5039],\n",
            "        [-0.2266,  0.9999, -0.6640,  ..., -0.9004,  0.0903, -0.3757],\n",
            "        [ 0.5257,  1.0000,  0.8250,  ...,  0.5599, -0.2162, -0.5345]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2649,  1.0000, -0.6202,  ..., -0.8615,  0.2886, -0.6802],\n",
            "        [-0.2161,  1.0000, -0.4871,  ..., -0.9335,  0.3101, -0.5859],\n",
            "        [-0.0147,  1.0000, -0.1165,  ..., -0.8629,  0.3165, -0.6493],\n",
            "        ...,\n",
            "        [ 0.0596,  1.0000,  0.2135,  ..., -0.7659,  0.3028, -0.9566],\n",
            "        [-0.0963,  1.0000,  0.9237,  ..., -0.4953,  0.0051, -0.8581],\n",
            "        [ 0.5627,  1.0000,  0.8724,  ...,  0.5462, -0.4101, -0.5379]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3563,  0.9999,  0.8811,  ...,  0.2936, -0.4279, -0.6414],\n",
            "        [ 0.0908,  1.0000, -0.6773,  ..., -0.9448,  0.0414, -0.6743],\n",
            "        [-0.5027,  1.0000, -0.5802,  ..., -0.8694,  0.1272, -0.4934],\n",
            "        ...,\n",
            "        [-0.2379,  0.9999, -0.7226,  ..., -0.8920,  0.0425, -0.1164],\n",
            "        [-0.1817,  1.0000,  0.3278,  ..., -0.8585,  0.1886, -0.9375],\n",
            "        [ 0.5822,  1.0000,  0.7064,  ..., -0.7290,  0.4530, -0.9301]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5359,  1.0000,  0.8334,  ...,  0.2494, -0.4959, -0.4479],\n",
            "        [ 0.1430,  1.0000,  0.8221,  ..., -0.6302, -0.0987, -0.9269],\n",
            "        [ 0.5081,  1.0000,  0.8943,  ...,  0.5090, -0.3730, -0.4106],\n",
            "        ...,\n",
            "        [ 0.5881,  0.9999,  0.8076,  ...,  0.6319, -0.6312, -0.3226],\n",
            "        [ 0.5379,  1.0000,  0.8491,  ...,  0.5208, -0.3077, -0.6657],\n",
            "        [ 0.0375,  1.0000,  0.8213,  ..., -0.8541,  0.4509, -0.9229]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1516,  1.0000, -0.4464,  ..., -0.9029,  0.2741, -0.8209],\n",
            "        [ 0.3795,  0.9998,  0.8456,  ...,  0.3428, -0.6259, -0.3787],\n",
            "        [ 0.0421,  1.0000, -0.4343,  ..., -0.8941,  0.3025, -0.7694],\n",
            "        ...,\n",
            "        [ 0.2059,  0.9999,  0.7919,  ..., -0.3290, -0.4196, -0.8145],\n",
            "        [ 0.5579,  0.9999,  0.8766,  ...,  0.6392, -0.2820, -0.4751],\n",
            "        [ 0.2928,  1.0000, -0.4022,  ..., -0.9486,  0.2057, -0.6917]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2651,  1.0000, -0.3945,  ..., -0.8781,  0.4362, -0.8567],\n",
            "        [ 0.4829,  1.0000,  0.9159,  ..., -0.5031,  0.0688, -0.8991],\n",
            "        [-0.1877,  1.0000, -0.6773,  ..., -0.9159,  0.1647, -0.4763],\n",
            "        ...,\n",
            "        [ 0.3625,  1.0000, -0.1262,  ..., -0.8648, -0.0155, -0.8771],\n",
            "        [ 0.1542,  0.9992,  0.8408,  ...,  0.4542, -0.6489, -0.2593],\n",
            "        [ 0.4112,  1.0000,  0.8957,  ..., -0.6259,  0.2053, -0.9631]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1638,  1.0000,  0.4940,  ..., -0.6080,  0.6675, -0.8023],\n",
            "        [ 0.3213,  1.0000,  0.8239,  ..., -0.7921,  0.1852, -0.8854],\n",
            "        [ 0.1769,  1.0000,  0.9002,  ..., -0.4376,  0.3591, -0.9246],\n",
            "        ...,\n",
            "        [ 0.0505,  1.0000,  0.7995,  ..., -0.7712,  0.3991, -0.9656],\n",
            "        [-0.0178,  1.0000, -0.6415,  ..., -0.9268,  0.1906, -0.7563],\n",
            "        [ 0.2600,  1.0000,  0.4722,  ..., -0.8731,  0.6642, -0.9265]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3518,  1.0000,  0.4848,  ..., -0.8454,  0.4482, -0.9605],\n",
            "        [ 0.2963,  1.0000,  0.7385,  ..., -0.5638, -0.1683, -0.9304],\n",
            "        [-0.3566,  1.0000, -0.3995,  ..., -0.9318,  0.1797, -0.7734],\n",
            "        ...,\n",
            "        [ 0.0935,  1.0000,  0.5661,  ..., -0.6876,  0.6039, -0.9674],\n",
            "        [-0.0466,  1.0000,  0.1916,  ..., -0.8153,  0.4006, -0.9427],\n",
            "        [ 0.7112,  1.0000,  0.7917,  ...,  0.4791, -0.3941, -0.6396]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6274,  1.0000,  0.8870,  ...,  0.3965, -0.2449, -0.7305],\n",
            "        [ 0.4977,  1.0000,  0.8763,  ...,  0.5167, -0.4494, -0.5999],\n",
            "        [-0.3684,  1.0000, -0.4522,  ..., -0.8640,  0.1727, -0.5728],\n",
            "        ...,\n",
            "        [-0.4387,  1.0000,  0.0545,  ..., -0.8236,  0.2826, -0.9635],\n",
            "        [-0.0067,  1.0000, -0.5370,  ..., -0.8704,  0.3896, -0.6891],\n",
            "        [-0.1091,  1.0000, -0.4880,  ..., -0.8597,  0.5400, -0.8174]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3628,  1.0000, -0.6115,  ..., -0.8991,  0.2853, -0.3237],\n",
            "        [ 0.5858,  1.0000,  0.7823,  ...,  0.5710, -0.2400, -0.7847],\n",
            "        [ 0.3719,  1.0000,  0.8448,  ...,  0.2438, -0.4081, -0.5524],\n",
            "        ...,\n",
            "        [ 0.5034,  1.0000,  0.8295,  ...,  0.5897, -0.2349, -0.6157],\n",
            "        [ 0.1308,  1.0000,  0.9099,  ..., -0.2333, -0.0163, -0.9469],\n",
            "        [-0.2565,  1.0000, -0.5745,  ..., -0.9371,  0.0951, -0.7331]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5273,  1.0000,  0.8474,  ...,  0.2731, -0.3206, -0.6667],\n",
            "        [-0.1254,  1.0000,  0.8277,  ..., -0.3029, -0.2852, -0.9400],\n",
            "        [ 0.4774,  1.0000,  0.8695,  ...,  0.5121, -0.2366, -0.4254],\n",
            "        ...,\n",
            "        [ 0.5778,  1.0000,  0.9124,  ...,  0.5418, -0.2877, -0.6724],\n",
            "        [ 0.1479,  1.0000, -0.1686,  ..., -0.8625,  0.1947, -0.9342],\n",
            "        [ 0.4283,  1.0000,  0.4568,  ..., -0.4708, -0.0754, -0.9572]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2829,  1.0000,  0.5256,  ..., -0.7922,  0.6975, -0.8981],\n",
            "        [ 0.1427,  1.0000,  0.8261,  ..., -0.5977, -0.4011, -0.9740],\n",
            "        [ 0.5187,  0.9996,  0.8843,  ...,  0.5765, -0.0462, -0.5012],\n",
            "        ...,\n",
            "        [-0.0330,  1.0000,  0.2395,  ..., -0.9158,  0.1240, -0.8721],\n",
            "        [-0.1159,  1.0000, -0.4851,  ..., -0.9456,  0.3604, -0.7752],\n",
            "        [-0.2016,  1.0000, -0.1725,  ..., -0.8100, -0.0722, -0.8525]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1899,  1.0000,  0.6011,  ..., -0.8141,  0.2144, -0.9523],\n",
            "        [ 0.0453,  1.0000, -0.4139,  ..., -0.9317, -0.2502, -0.7740],\n",
            "        [ 0.2982,  1.0000,  0.8298,  ..., -0.1444, -0.0086, -0.9533],\n",
            "        ...,\n",
            "        [-0.1604,  1.0000, -0.3605,  ..., -0.9054,  0.2573, -0.5634],\n",
            "        [ 0.4331,  1.0000,  0.6837,  ..., -0.7172,  0.2959, -0.9475],\n",
            "        [ 0.6820,  1.0000,  0.9142,  ...,  0.6269, -0.1940, -0.5857]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2951,  1.0000, -0.1005,  ..., -0.8997,  0.1901, -0.8650],\n",
            "        [ 0.0972,  1.0000, -0.2232,  ..., -0.9223,  0.0355, -0.9021],\n",
            "        [ 0.5932,  1.0000,  0.8124,  ...,  0.5764, -0.2897, -0.6023],\n",
            "        ...,\n",
            "        [ 0.7452,  1.0000,  0.7503,  ..., -0.2443, -0.0406, -0.9005],\n",
            "        [ 0.7401,  1.0000,  0.8737,  ...,  0.6787, -0.4431, -0.4942],\n",
            "        [-0.0031,  1.0000,  0.6107,  ..., -0.6177, -0.3210, -0.9380]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0874,  1.0000,  0.6048,  ..., -0.4928,  0.2777, -0.9361],\n",
            "        [ 0.0363,  1.0000,  0.7701,  ..., -0.7351,  0.2493, -0.9684],\n",
            "        [ 0.0264,  1.0000,  0.0617,  ..., -0.8556,  0.2575, -0.9457],\n",
            "        ...,\n",
            "        [ 0.6787,  1.0000,  0.8024,  ...,  0.4942, -0.2596, -0.6692],\n",
            "        [ 0.1916,  1.0000, -0.5231,  ..., -0.8343,  0.4455, -0.6794],\n",
            "        [ 0.4913,  1.0000,  0.8869,  ...,  0.1077, -0.1972, -0.9157]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0052,  1.0000,  0.7484,  ..., -0.1590,  0.0628, -0.9125],\n",
            "        [ 0.6854,  1.0000,  0.8634,  ...,  0.4927, -0.2227, -0.6467],\n",
            "        [ 0.5929,  1.0000,  0.9338,  ...,  0.1848, -0.4135, -0.7823],\n",
            "        ...,\n",
            "        [ 0.0508,  1.0000, -0.4991,  ..., -0.9308,  0.1870, -0.7634],\n",
            "        [ 0.7133,  1.0000,  0.8754,  ...,  0.4797, -0.2570, -0.8531],\n",
            "        [ 0.3308,  1.0000, -0.3228,  ..., -0.8433,  0.3320, -0.9071]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3843,  1.0000,  0.3276,  ..., -0.8656,  0.3659, -0.9212],\n",
            "        [ 0.6284,  1.0000,  0.8957,  ...,  0.6292, -0.0810, -0.7457],\n",
            "        [ 0.6823,  1.0000,  0.9022,  ...,  0.6102, -0.5336, -0.4631],\n",
            "        ...,\n",
            "        [ 0.2235,  1.0000,  0.8172,  ..., -0.3989, -0.1172, -0.8847],\n",
            "        [-0.3263,  1.0000, -0.3266,  ..., -0.9042,  0.0859, -0.6895],\n",
            "        [-0.0353,  1.0000, -0.3356,  ..., -0.7414,  0.1167, -0.8649]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6518,  1.0000,  0.8541,  ..., -0.0015,  0.1607, -0.8931],\n",
            "        [ 0.6424,  1.0000,  0.9401,  ...,  0.8012, -0.1220, -0.5507],\n",
            "        [ 0.5099,  0.9999,  0.8950,  ...,  0.4193, -0.3935, -0.3788],\n",
            "        ...,\n",
            "        [ 0.6007,  1.0000,  0.8694,  ...,  0.7251, -0.2586, -0.6758],\n",
            "        [ 0.6309,  1.0000,  0.8436,  ...,  0.5694, -0.0979, -0.6123],\n",
            "        [ 0.7421,  1.0000,  0.7550,  ...,  0.4110,  0.2530, -0.8182]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3462,  1.0000, -0.2832,  ..., -0.8433,  0.2924, -0.9560],\n",
            "        [ 0.6394,  1.0000,  0.8540,  ...,  0.2371, -0.2478, -0.8425],\n",
            "        [ 0.7371,  1.0000,  0.8705,  ...,  0.3014, -0.2690, -0.9046],\n",
            "        ...,\n",
            "        [ 0.6390,  1.0000,  0.8694,  ...,  0.3844, -0.2806, -0.6145],\n",
            "        [ 0.4445,  0.9991,  0.8951,  ...,  0.1871, -0.0151, -0.6565],\n",
            "        [ 0.6782,  1.0000,  0.8954,  ...,  0.5646,  0.1322, -0.8477]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7242,  1.0000,  0.9198,  ...,  0.2560,  0.1143, -0.9566],\n",
            "        [ 0.7077,  1.0000,  0.8814,  ...,  0.5622, -0.3423, -0.6631],\n",
            "        [-0.0306,  1.0000, -0.3145,  ..., -0.8876,  0.2579, -0.8337],\n",
            "        ...,\n",
            "        [ 0.0548,  1.0000, -0.2030,  ..., -0.9084,  0.3170, -0.8930],\n",
            "        [-0.0572,  1.0000, -0.3042,  ..., -0.8873,  0.1735, -0.8446],\n",
            "        [-0.1776,  1.0000, -0.6860,  ..., -0.8868,  0.0616, -0.6227]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0496,  1.0000, -0.3697,  ..., -0.9302,  0.5751, -0.8328],\n",
            "        [ 0.4976,  1.0000,  0.9233,  ..., -0.4153,  0.1264, -0.9748],\n",
            "        [ 0.5978,  1.0000,  0.9015,  ...,  0.6177, -0.2876, -0.5530],\n",
            "        ...,\n",
            "        [-0.1512,  1.0000, -0.7304,  ..., -0.8946,  0.4121, -0.6024],\n",
            "        [-0.4329,  1.0000, -0.3070,  ..., -0.8776,  0.3992, -0.8263],\n",
            "        [-0.3212,  1.0000, -0.7022,  ..., -0.8998,  0.5231, -0.6505]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5936,  1.0000,  0.8970,  ...,  0.6729, -0.3389, -0.6811],\n",
            "        [ 0.1689,  1.0000, -0.0947,  ..., -0.8311,  0.6648, -0.7817],\n",
            "        [-0.0290,  1.0000, -0.4782,  ..., -0.9141,  0.5637, -0.8543],\n",
            "        ...,\n",
            "        [ 0.6439,  1.0000,  0.7999,  ...,  0.5100, -0.5091, -0.6417],\n",
            "        [-0.0219,  1.0000,  0.6441,  ..., -0.5091,  0.3260, -0.9684],\n",
            "        [ 0.1931,  1.0000,  0.3707,  ..., -0.8391,  0.4324, -0.9157]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0976,  1.0000, -0.5567,  ..., -0.7981,  0.6573, -0.6017],\n",
            "        [ 0.6319,  1.0000,  0.9149,  ...,  0.1853, -0.2384, -0.5628],\n",
            "        [ 0.5993,  0.9998,  0.8086,  ...,  0.5857, -0.3637, -0.5291],\n",
            "        ...,\n",
            "        [ 0.6148,  1.0000,  0.9175,  ...,  0.5835, -0.2331, -0.7873],\n",
            "        [ 0.6589,  1.0000,  0.8597,  ..., -0.0495,  0.2901, -0.9180],\n",
            "        [ 0.1641,  1.0000, -0.3454,  ..., -0.9097,  0.4819, -0.8998]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4124,  0.9999, -0.3259,  ..., -0.9507,  0.4726, -0.8993],\n",
            "        [ 0.5075,  1.0000,  0.9142,  ...,  0.0030,  0.0153, -0.8569],\n",
            "        [ 0.7623,  1.0000,  0.8794,  ...,  0.6519, -0.1388, -0.7042],\n",
            "        ...,\n",
            "        [ 0.6221,  1.0000,  0.8126,  ..., -0.1203, -0.1179, -0.9353],\n",
            "        [ 0.5676,  1.0000,  0.9119,  ...,  0.2843, -0.0858, -0.7933],\n",
            "        [ 0.4436,  1.0000,  0.8521,  ...,  0.0207, -0.2937, -0.8768]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1477,  1.0000,  0.3548,  ..., -0.6367,  0.6268, -0.8934],\n",
            "        [-0.1505,  1.0000,  0.4806,  ..., -0.8179,  0.5366, -0.9533],\n",
            "        [ 0.6149,  1.0000,  0.8841,  ...,  0.0223, -0.2071, -0.9086],\n",
            "        ...,\n",
            "        [-0.1580,  1.0000, -0.1685,  ..., -0.8374,  0.5674, -0.7809],\n",
            "        [-0.1694,  1.0000, -0.5445,  ..., -0.8904,  0.5216, -0.9171],\n",
            "        [ 0.0157,  1.0000, -0.4191,  ..., -0.8891,  0.3579, -0.9363]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2460,  1.0000, -0.2114,  ..., -0.8069,  0.3867, -0.8981],\n",
            "        [ 0.5482,  1.0000,  0.1734,  ..., -0.7879,  0.6353, -0.9583],\n",
            "        [ 0.7933,  1.0000,  0.8592,  ...,  0.1075, -0.0710, -0.7881],\n",
            "        ...,\n",
            "        [-0.1539,  1.0000,  0.3960,  ..., -0.6791,  0.2539, -0.8472],\n",
            "        [ 0.2424,  1.0000, -0.2025,  ..., -0.7862,  0.4678, -0.8981],\n",
            "        [ 0.6560,  1.0000,  0.7587,  ...,  0.5383, -0.1355, -0.9011]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0422,  0.9766,  0.4626,  ..., -0.2704,  0.1839, -0.6865],\n",
            "        [ 0.4283,  1.0000,  0.4123,  ..., -0.6288,  0.7191, -0.9711],\n",
            "        [ 0.3663,  1.0000,  0.4304,  ..., -0.6478,  0.5334, -0.9549],\n",
            "        ...,\n",
            "        [-0.5282,  1.0000, -0.6183,  ..., -0.8908,  0.0789, -0.4890],\n",
            "        [ 0.6819,  1.0000,  0.8175,  ...,  0.5152, -0.2057, -0.7924],\n",
            "        [ 0.6939,  1.0000,  0.8937,  ...,  0.7094, -0.3086, -0.7356]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3560,  1.0000, -0.7255,  ..., -0.9059,  0.4934, -0.4161],\n",
            "        [-0.3768,  1.0000, -0.2172,  ..., -0.8402,  0.6234, -0.8313],\n",
            "        [-0.1955,  1.0000, -0.6664,  ..., -0.9111,  0.5639, -0.8483],\n",
            "        ...,\n",
            "        [-0.3765,  1.0000, -0.7549,  ..., -0.8352,  0.4279, -0.6893],\n",
            "        [ 0.4378,  1.0000,  0.6196,  ..., -0.4254,  0.4028, -0.9816],\n",
            "        [-0.3484,  1.0000, -0.4975,  ..., -0.8655,  0.1875, -0.6425]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7641,  1.0000,  0.9360,  ...,  0.7526, -0.1036, -0.8511],\n",
            "        [ 0.8088,  1.0000,  0.8737,  ...,  0.6941, -0.2592, -0.8452],\n",
            "        [-0.2783,  1.0000, -0.2021,  ..., -0.9422,  0.5377, -0.8517],\n",
            "        ...,\n",
            "        [-0.2842,  1.0000, -0.7928,  ..., -0.8911,  0.3736, -0.6263],\n",
            "        [ 0.6941,  1.0000,  0.8759,  ...,  0.3748, -0.2255, -0.8331],\n",
            "        [ 0.6520,  1.0000,  0.8570,  ...,  0.1381, -0.3538, -0.9299]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0918,  1.0000,  0.0339,  ..., -0.7808,  0.7085, -0.8236],\n",
            "        [ 0.1395,  1.0000, -0.6591,  ..., -0.8605,  0.6505, -0.6974],\n",
            "        [-0.1784,  1.0000, -0.7932,  ..., -0.8883,  0.4305, -0.1609],\n",
            "        ...,\n",
            "        [ 0.6732,  1.0000,  0.8100,  ...,  0.1870, -0.1432, -0.8664],\n",
            "        [-0.0897,  1.0000, -0.6777,  ..., -0.9028,  0.5313, -0.7613],\n",
            "        [ 0.2836,  1.0000, -0.1335,  ..., -0.8719,  0.6186, -0.8640]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2765,  1.0000, -0.6644, -0.9978,  0.7498, -0.7421,  0.7347, -0.4295,\n",
            "         -0.9988,  0.4110, -0.3297,  0.8847, -0.6540,  1.0000, -0.2325, -0.5867,\n",
            "         -0.6373, -0.9989,  0.8038, -0.6867,  0.6103,  0.7313,  0.8607, -0.8060,\n",
            "         -0.6694, -0.4259,  0.4401,  0.8262, -0.5416,  0.3849, -0.8307, -0.0292,\n",
            "          0.9821,  0.7637,  0.4784, -0.9481, -0.4208, -0.8898, -0.9973, -0.9981,\n",
            "         -0.0562, -0.4048,  0.9999, -0.9642,  0.9955, -0.9777,  0.3752, -0.8383,\n",
            "          0.9346,  0.7701,  0.1312, -0.8982,  0.7602,  0.4541, -0.9091, -0.9969,\n",
            "         -0.6340,  0.8404, -0.8718,  0.6743,  0.2503, -0.8917,  0.6639,  0.6687,\n",
            "          0.7762,  0.7913,  0.8852,  0.2028,  0.8742, -0.9979, -0.4117, -0.9651,\n",
            "          0.5235, -0.5902,  0.8250,  0.5020,  0.1758, -0.8287, -0.4530,  0.9832,\n",
            "          0.2478,  0.7800,  0.8249, -1.0000,  0.1283, -0.8611,  0.9783, -0.9860,\n",
            "         -0.9757,  0.2828,  0.7003, -0.6890, -0.7399, -0.0988,  0.0248, -0.9074,\n",
            "         -0.1137, -0.7164, -0.9998,  0.7581,  0.9205,  0.8847,  0.3950, -0.5578,\n",
            "         -1.0000, -0.7122,  0.4041, -0.9599, -1.0000, -0.7268, -0.8476, -0.6449,\n",
            "          0.4414,  0.9472, -0.2590,  1.0000, -0.8166,  0.9305, -1.0000, -0.9723,\n",
            "          0.3900,  0.6276, -0.2777, -0.7574,  0.5404, -0.9912, -0.9918, -0.9997,\n",
            "          0.7369,  0.3354, -0.6039,  0.9200, -0.5368, -0.9139, -0.6349, -0.3577,\n",
            "         -0.9994,  0.5719,  0.3737, -0.9982,  0.9952,  0.9630, -0.2309, -0.7499,\n",
            "         -0.4395,  0.9701, -0.0443,  0.2811, -0.5113, -0.6783, -0.1478,  0.2225,\n",
            "         -0.0073,  0.5139, -1.0000,  0.8259,  0.6742,  0.9965,  0.6101,  0.5673,\n",
            "         -0.6941, -1.0000,  0.9051,  0.5787,  0.9741, -0.1061, -0.3861,  0.9301,\n",
            "          0.7123,  0.5213,  0.7608,  0.8431,  0.5174,  0.8718,  0.9852, -0.9622,\n",
            "         -0.8962, -0.8147,  0.8670, -0.9784,  0.9877, -0.7241,  0.9676, -0.9763,\n",
            "         -0.8521,  0.4265, -0.2419, -1.0000,  0.8983,  0.9239,  0.4279, -0.9686,\n",
            "          0.7454,  0.2383,  0.6494, -0.3276, -0.7807,  0.7811, -0.0429,  0.9755,\n",
            "          0.6030, -0.9840,  0.9984,  0.8549,  0.2317, -0.9940,  0.2106,  0.9955,\n",
            "         -0.9935, -0.9503,  0.5091, -0.2017,  0.6843, -0.7163, -0.6216, -0.6467,\n",
            "          0.9518, -0.9534,  0.9109,  0.5903,  0.5329, -0.1806, -0.6327, -0.2604,\n",
            "         -0.1496,  0.8664, -0.6455,  0.3857, -0.7109, -1.0000,  0.2618,  0.3240,\n",
            "          0.7625, -0.0904,  0.9993,  0.6710, -0.8392,  0.9802, -0.9973, -0.5375,\n",
            "          0.8385, -0.9968,  0.8703, -0.0817,  1.0000, -0.9987,  0.9953, -0.7628,\n",
            "          0.8443,  0.7155, -0.8145,  0.1584,  0.9132,  0.6635,  0.7817,  0.9488,\n",
            "          0.0588, -0.9988, -0.2821,  0.6717, -0.9907,  0.1075, -0.9508, -0.9615,\n",
            "          0.9902,  1.0000, -0.7841,  0.5056,  0.7384,  0.8020,  0.7480, -0.9978,\n",
            "          0.9054,  1.0000, -0.9794, -0.8910,  1.0000,  0.6829, -0.9528,  0.6150,\n",
            "         -0.6769, -0.9965,  0.6159, -0.6276,  0.5409,  0.6537, -0.0720, -0.9941,\n",
            "         -0.9989, -0.9934,  0.9982,  0.3409,  0.8296,  0.5306, -0.4089, -0.9224,\n",
            "          0.9232,  0.8971, -0.9875,  1.0000,  0.9482, -0.9615, -0.9918, -0.3201,\n",
            "          0.2527,  0.7946,  0.9876,  0.4232, -0.9195,  0.6917,  0.9071, -0.1410,\n",
            "          0.9941, -0.0471,  0.0844, -0.1796,  0.2458, -0.9950, -0.8881, -0.6603,\n",
            "          0.7937,  0.9955,  0.5817, -0.8734,  0.9959,  0.5026, -1.0000,  0.9999,\n",
            "          0.9923, -0.9870, -0.1334,  0.3178,  0.7865,  0.1105,  0.7903, -0.8300,\n",
            "         -0.1366, -0.9954,  0.9007,  0.7889,  0.6022,  0.7093,  0.5429,  0.8227,\n",
            "          0.6293,  0.1049,  0.6755, -0.8877, -0.9971, -0.3494,  0.5263,  0.7691,\n",
            "         -0.8452,  0.9909,  0.8447,  1.0000,  0.5976,  0.9987, -0.8897,  0.8019,\n",
            "         -0.4049,  0.5964,  0.7569, -0.9684, -1.0000, -0.4905, -0.7645,  0.7993,\n",
            "         -0.5699, -0.9927, -0.9552,  0.6651, -0.7416,  0.8282, -0.3811, -0.9450,\n",
            "          0.9996,  0.9007,  0.7185, -0.5937, -0.5225,  0.8555,  0.9612,  0.5161,\n",
            "          0.9756, -0.7277,  0.9513, -0.8402,  0.8582, -0.4016,  0.1754,  0.3043,\n",
            "          0.3177,  0.9872,  0.9109,  0.9762, -0.7510,  0.2036, -0.9993,  1.0000,\n",
            "         -0.3215,  0.7865,  0.6280,  0.3550,  0.8181, -0.8347,  0.9181, -0.7709,\n",
            "          0.9832, -0.8347,  0.8556,  0.6583,  0.8491, -0.6994, -0.3572,  0.5951,\n",
            "          0.2294, -0.8912, -0.9812,  0.9446, -0.9917, -0.7539, -0.9785, -0.9116,\n",
            "          0.9956, -0.8848,  0.5943, -0.7454, -0.8580, -0.8206, -0.5142, -0.9521,\n",
            "          0.5188, -0.9922,  0.9994, -0.9946,  0.8871, -0.8491, -0.0085,  0.8723,\n",
            "          0.6460,  0.0722,  0.0712, -0.0250, -0.4673,  0.8467, -0.5203, -0.6419,\n",
            "          0.5240, -0.0381,  0.4384,  0.9527, -0.2639,  0.9908,  0.0636, -0.9577,\n",
            "         -0.5922, -0.6279,  0.8824,  0.9982, -0.9835,  0.9157,  1.0000, -0.9937,\n",
            "         -0.7619, -0.4421, -0.9992,  0.9296, -0.9159, -0.9941, -0.1675, -0.7432,\n",
            "          0.9074,  0.9677,  0.9985, -0.4965, -0.7674, -0.9923, -0.8343,  0.4804,\n",
            "         -0.9917,  0.8031, -0.9337, -0.9951,  0.9969,  0.6188, -0.3511,  0.3504,\n",
            "          0.4239,  0.9977, -0.4641, -0.9732,  0.6115,  0.6454,  0.1143,  0.6761,\n",
            "         -0.7493, -0.7311, -0.9979,  0.5828,  1.0000, -0.4359, -0.5922,  0.9058,\n",
            "         -0.0969,  0.3416,  1.0000, -0.9838,  0.9216,  1.0000,  0.1688,  0.8840,\n",
            "         -0.5470,  0.0995,  0.0923,  0.6922, -0.6664,  0.9998, -0.9306, -0.9429,\n",
            "         -1.0000,  0.3718, -0.7981,  0.6640,  0.9540, -0.8364,  0.1022,  0.6692,\n",
            "         -0.9971,  0.9508, -0.6104, -1.0000, -0.9991, -0.3415, -0.4482, -0.9586,\n",
            "         -0.2130, -0.7404, -0.9409,  0.9991, -0.8738, -1.0000, -0.3112,  0.9484,\n",
            "          0.9794,  0.1758,  0.5706, -0.7032, -0.7283,  0.1368, -1.0000, -0.4496,\n",
            "          0.9683,  0.3668, -0.4071,  0.9978, -0.7296, -0.9109, -0.3645,  0.5653,\n",
            "          0.3740, -1.0000, -0.5763,  0.9993, -0.6412, -0.3832, -0.9168, -0.7526,\n",
            "         -0.5806,  0.4384,  0.9959, -0.9717,  0.9998, -0.3061,  0.9081,  0.9651,\n",
            "         -0.2738, -0.8371, -0.9036,  0.8300,  0.8388,  0.3137,  0.4536, -0.8646,\n",
            "          0.8330, -0.3562, -0.9277,  0.6587, -0.7141,  0.1055, -0.5532,  0.9584,\n",
            "          0.7653, -0.4858,  0.9983, -0.0774, -0.9374,  0.7950, -0.1761, -0.5266,\n",
            "         -1.0000, -0.7473,  0.6170, -0.9957, -0.5071,  0.6584, -0.7620, -0.7178,\n",
            "          0.9568, -0.2912,  0.6199,  0.9971,  0.8064,  0.7130, -0.9828, -1.0000,\n",
            "         -0.2865,  0.7932, -0.9602,  0.8008, -0.8126,  0.9993,  0.0756,  0.7434,\n",
            "          0.8187,  0.9998,  0.0215,  0.3820,  0.2366,  0.0732, -0.9094,  0.9464,\n",
            "         -0.5211, -0.9875, -0.8966, -0.6040, -0.4810, -0.4808,  0.1867,  0.5072,\n",
            "          1.0000,  0.8011,  0.9482,  0.7850,  0.1038, -0.2496, -0.8374,  0.9773,\n",
            "         -1.0000,  0.9614,  0.4178, -0.6454,  0.7833, -0.8378, -0.4890, -0.6012,\n",
            "         -0.7613, -0.9311, -0.7213, -0.5833, -0.7166, -0.1864,  0.9457, -0.7485,\n",
            "         -0.9993,  0.8931, -0.5737,  0.8778,  0.5495, -0.7673,  0.9077,  0.5483,\n",
            "          0.9787, -0.8197,  0.2306, -0.7893, -0.8789,  0.4460,  0.7358,  0.9075,\n",
            "          0.4317, -0.0337,  0.8269, -0.1748, -0.6798, -0.0088,  0.2165,  0.6025,\n",
            "          0.9495,  0.3812,  0.8787,  0.9744, -0.0979, -0.5890,  0.2041, -0.0409,\n",
            "          0.8434, -0.9982,  0.9987,  0.3125, -0.2567, -0.9999, -0.1801,  0.5525,\n",
            "          0.7452,  0.3584, -0.4789, -0.8438, -0.7855,  0.8788, -1.0000, -0.6971,\n",
            "         -0.3313, -0.2377,  0.7651, -0.9990, -0.6794,  0.7865, -0.6071, -0.2387,\n",
            "          0.9990, -0.8849, -0.9831, -0.9902, -0.8439,  0.3983,  0.8466, -0.9793,\n",
            "          0.1162,  0.9296, -0.9977, -0.4496,  0.1577,  0.6068, -0.0978, -0.0653,\n",
            "          0.9415, -1.0000,  0.7992, -0.6465, -0.0392,  0.6424, -0.7074,  0.7269,\n",
            "          0.5928, -0.9998,  0.3390,  0.1773,  0.9157,  0.8712, -0.3809, -0.5624,\n",
            "          0.2050, -0.6117,  0.9822,  0.9490, -0.3802,  0.2349,  0.9991,  0.6868,\n",
            "          0.8717, -0.1586, -0.9306, -0.9971, -0.7848, -0.7964,  0.5011, -0.3062]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluation... :   0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "270a2e26ad054a649f5169562e1326a5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.8434,  1.0000,  0.9043,  ...,  0.7092, -0.4506, -0.8152],\n",
            "        [ 0.7114,  1.0000,  0.8956,  ...,  0.7312, -0.3570, -0.6826],\n",
            "        [ 0.4102,  1.0000, -0.2909,  ..., -0.8116,  0.6291, -0.6050],\n",
            "        ...,\n",
            "        [ 0.4997,  1.0000,  0.8923,  ...,  0.4378, -0.2297, -0.7500],\n",
            "        [-0.0305,  1.0000, -0.4118,  ..., -0.7975,  0.5347, -0.8044],\n",
            "        [-0.4380,  1.0000, -0.6535,  ..., -0.8021,  0.5121, -0.5950]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2847,  1.0000,  0.3916,  ..., -0.7952,  0.6361, -0.9484],\n",
            "        [ 0.6633,  1.0000,  0.6804,  ..., -0.3640,  0.2014, -0.9458],\n",
            "        [ 0.5029,  1.0000,  0.9532,  ...,  0.2879, -0.1254, -0.8925],\n",
            "        ...,\n",
            "        [-0.0677,  1.0000,  0.5829,  ..., -0.6074,  0.3408, -0.9673],\n",
            "        [-0.1046,  1.0000,  0.6501,  ..., -0.7863,  0.4442, -0.9488],\n",
            "        [ 0.3374,  1.0000,  0.7219,  ..., -0.8479,  0.6698, -0.9811]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7172,  1.0000,  0.9032,  ...,  0.7817, -0.4218, -0.6003],\n",
            "        [ 0.0543,  0.9909,  0.6402,  ...,  0.2193,  0.2970, -0.5760],\n",
            "        [ 0.4680,  1.0000,  0.7581,  ...,  0.1078,  0.0632, -0.9492],\n",
            "        ...,\n",
            "        [ 0.3357,  1.0000,  0.8772,  ..., -0.6388,  0.1870, -0.9706],\n",
            "        [-0.3374,  1.0000, -0.4456,  ..., -0.8828,  0.4310, -0.6242],\n",
            "        [ 0.5141,  1.0000,  0.7925,  ..., -0.6100,  0.4691, -0.9816]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4101,  1.0000,  0.7007,  ..., -0.2596, -0.0407, -0.9190],\n",
            "        [-0.0249,  1.0000,  0.6915,  ..., -0.7711,  0.7139, -0.9828],\n",
            "        [ 0.2430,  1.0000,  0.5769,  ..., -0.7653,  0.3933, -0.9815],\n",
            "        ...,\n",
            "        [ 0.7304,  1.0000,  0.8835,  ...,  0.7879, -0.3173, -0.5615],\n",
            "        [-0.1966,  1.0000, -0.5200,  ..., -0.8781,  0.5980, -0.6790],\n",
            "        [ 0.7075,  1.0000,  0.9076,  ...,  0.8046, -0.3876, -0.6042]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6970,  1.0000,  0.8868,  ...,  0.3624, -0.2098, -0.8240],\n",
            "        [ 0.5132,  1.0000,  0.9087,  ...,  0.4669,  0.2612, -0.9037],\n",
            "        [ 0.2347,  1.0000, -0.5503,  ..., -0.7529,  0.3991, -0.8427],\n",
            "        ...,\n",
            "        [ 0.1337,  1.0000,  0.1569,  ..., -0.6533,  0.1931, -0.9637],\n",
            "        [ 0.6624,  1.0000,  0.9128,  ...,  0.6091, -0.3831, -0.5864],\n",
            "        [-0.0806,  0.8943,  0.3448,  ...,  0.1370,  0.0819, -0.4206]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4809,  0.9999,  0.8932,  ...,  0.6145, -0.2333, -0.5127],\n",
            "        [ 0.7226,  1.0000,  0.7134,  ...,  0.2963, -0.1894, -0.9223],\n",
            "        [ 0.0481,  1.0000, -0.7913,  ..., -0.8725,  0.6262, -0.5508],\n",
            "        ...,\n",
            "        [ 0.4441,  1.0000, -0.4672,  ..., -0.7595,  0.7618, -0.5156],\n",
            "        [ 0.5098,  1.0000,  0.2897,  ..., -0.6320,  0.1874, -0.9287],\n",
            "        [-0.0961,  1.0000, -0.4708,  ..., -0.8554,  0.4783, -0.6941]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3522,  1.0000,  0.0303,  ..., -0.8156,  0.2913, -0.9121],\n",
            "        [-0.1467,  1.0000, -0.7719,  ..., -0.8967,  0.3977, -0.3402],\n",
            "        [ 0.7595,  1.0000,  0.9029,  ...,  0.8081, -0.3911, -0.7041],\n",
            "        ...,\n",
            "        [-0.2798,  1.0000,  0.1501,  ..., -0.8563,  0.1800, -0.8253],\n",
            "        [ 0.6953,  1.0000,  0.9284,  ...,  0.7789, -0.3364, -0.6107],\n",
            "        [ 0.0845,  1.0000, -0.4420,  ..., -0.6928,  0.2602, -0.6017]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7731,  1.0000,  0.9183,  ...,  0.6214, -0.3165, -0.7972],\n",
            "        [ 0.7420,  1.0000,  0.9277,  ...,  0.7917, -0.3447, -0.6730],\n",
            "        [-0.0493,  0.9164,  0.4581,  ...,  0.0722,  0.0586, -0.4424],\n",
            "        ...,\n",
            "        [ 0.7280,  1.0000,  0.9186,  ...,  0.7359, -0.4465, -0.6754],\n",
            "        [ 0.5097,  1.0000,  0.8563,  ...,  0.6079, -0.3271, -0.8393],\n",
            "        [ 0.6562,  1.0000,  0.5939,  ..., -0.2542,  0.3928, -0.9465]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5862,  0.9999,  0.9102,  ...,  0.7124, -0.2772, -0.4260],\n",
            "        [-0.1676,  1.0000, -0.3064,  ..., -0.8326,  0.4488, -0.7669],\n",
            "        [-0.5963,  0.9997, -0.0354,  ..., -0.7723,  0.4970, -0.8377],\n",
            "        ...,\n",
            "        [-0.0582,  0.9533,  0.5378,  ...,  0.1040,  0.1455, -0.4780],\n",
            "        [-0.1751,  1.0000, -0.5583,  ..., -0.8675,  0.6870, -0.6248],\n",
            "        [ 0.5751,  0.9999,  0.8884,  ...,  0.7070, -0.4289, -0.4583]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2134,  1.0000, -0.7266,  ..., -0.8902,  0.4517, -0.5581],\n",
            "        [ 0.6688,  1.0000,  0.8762,  ...,  0.5672, -0.3768, -0.8197],\n",
            "        [ 0.5905,  1.0000,  0.9020,  ...,  0.6215, -0.4238, -0.6172],\n",
            "        ...,\n",
            "        [ 0.6644,  1.0000,  0.8455,  ...,  0.6483, -0.5831, -0.6638],\n",
            "        [ 0.7569,  1.0000,  0.8846,  ...,  0.7101, -0.2766, -0.6413],\n",
            "        [ 0.0470,  0.9613,  0.6452,  ...,  0.1742, -0.0186, -0.4448]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1663,  1.0000, -0.6139,  ..., -0.8735,  0.4678, -0.6975],\n",
            "        [-0.2265,  1.0000, -0.7092,  ..., -0.9230,  0.4497, -0.4961],\n",
            "        [-0.4236,  1.0000, -0.7907,  ..., -0.9265,  0.3313, -0.5498],\n",
            "        ...,\n",
            "        [ 0.7099,  1.0000,  0.8576,  ...,  0.0996,  0.1549, -0.9343],\n",
            "        [ 0.4136,  1.0000, -0.3219,  ..., -0.6849,  0.5707, -0.8447],\n",
            "        [ 0.7034,  1.0000,  0.9245,  ...,  0.7236, -0.4929, -0.5939]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1817,  0.8094,  0.1162,  ..., -0.0683,  0.1376, -0.3780],\n",
            "        [-0.1477,  1.0000, -0.7390,  ..., -0.8978,  0.4765, -0.5761],\n",
            "        [-0.3511,  1.0000, -0.5463,  ..., -0.8771,  0.4254, -0.7631],\n",
            "        ...,\n",
            "        [-0.0221,  1.0000, -0.4597,  ..., -0.8583,  0.4797, -0.8330],\n",
            "        [ 0.6234,  1.0000,  0.8372,  ..., -0.2901,  0.3932, -0.9383],\n",
            "        [-0.1597,  1.0000, -0.1782,  ..., -0.8802,  0.4452, -0.8334]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1218,  1.0000, -0.3847,  ..., -0.3789,  0.7202, -0.5454],\n",
            "        [ 0.7653,  1.0000,  0.9067,  ...,  0.4018, -0.0931, -0.9029],\n",
            "        [-0.2145,  0.9995, -0.6495,  ..., -0.8898,  0.4669, -0.3326],\n",
            "        ...,\n",
            "        [-0.4220,  1.0000, -0.5230,  ..., -0.8467,  0.6830, -0.8421],\n",
            "        [ 0.0717,  1.0000, -0.6849,  ..., -0.8421,  0.5391, -0.6279],\n",
            "        [-0.0448,  1.0000,  0.3693,  ..., -0.6230,  0.5295, -0.9756]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7218,  1.0000,  0.8818,  ..., -0.2584, -0.0601, -0.8525],\n",
            "        [ 0.6459,  1.0000,  0.8177,  ..., -0.0150, -0.1934, -0.9352],\n",
            "        [-0.1691,  1.0000, -0.7615,  ..., -0.8075,  0.2206, -0.4602],\n",
            "        ...,\n",
            "        [ 0.6253,  1.0000,  0.6104,  ..., -0.4736, -0.3063, -0.8833],\n",
            "        [ 0.1548,  1.0000,  0.4702,  ..., -0.6391,  0.5174, -0.8574],\n",
            "        [ 0.1145,  1.0000,  0.4367,  ..., -0.0708, -0.3131, -0.9317]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3431,  1.0000,  0.3513, -0.9956,  0.0806,  0.8890,  0.8538,  0.8080,\n",
            "         -0.9986, -0.7888,  0.7241, -0.4005,  0.1438,  0.9999, -0.3895,  0.1902,\n",
            "          0.9283, -0.9970,  0.9179, -0.9007,  0.7705, -0.5537,  0.9469, -0.7901,\n",
            "          0.8452,  0.6216, -0.3577,  0.8558, -0.7357,  0.5572, -0.6702, -0.8334,\n",
            "          0.9423,  0.7204,  0.9214, -0.9581, -0.5688, -0.9716, -0.9988, -0.9992,\n",
            "         -0.7884, -0.7919,  0.9998, -0.8482,  0.9983, -0.9943, -0.2675, -0.6448,\n",
            "          0.9308,  0.5935, -0.9228,  0.6869,  0.9139,  0.8370, -0.7426, -0.9810,\n",
            "         -0.9239,  0.9016, -0.9886,  0.1176,  0.9669,  0.3801, -0.3510,  0.1537,\n",
            "         -0.9193,  0.3249,  0.7401,  0.7542, -0.8058, -0.9870,  0.9042, -0.9814,\n",
            "          0.9051, -0.5830,  0.3827,  0.9700, -0.8693,  0.8061, -0.8452,  0.9898,\n",
            "          0.4804,  0.7143,  0.9130, -1.0000,  0.8750, -0.9597,  0.9863, -0.9962,\n",
            "         -0.9844,  0.8671,  0.7223,  0.8229,  0.5572, -0.7204, -0.8096, -0.7767,\n",
            "         -0.6303,  0.7913, -0.9998,  0.8987,  0.9350,  0.9661, -0.4992, -0.8474,\n",
            "         -0.9998, -0.3013, -0.8925, -0.8991, -1.0000, -0.8705, -0.8666, -0.8246,\n",
            "         -0.5473,  0.9853,  0.4481,  0.9999,  0.7778,  0.9947, -1.0000, -0.9803,\n",
            "          0.7106,  0.9823, -0.8379, -0.8611,  0.6789, -0.9902, -0.7999, -0.9992,\n",
            "          0.9338, -0.9770, -0.8464,  0.9142,  0.8847, -0.6663, -0.8021,  0.5178,\n",
            "         -0.9999,  0.3607, -0.9084, -0.9978,  0.9961,  0.9753,  0.7304, -0.8429,\n",
            "         -0.6467,  0.9517,  0.9051, -0.5972, -0.3763, -0.5291, -0.7909,  0.8869,\n",
            "          0.6092, -0.7816, -1.0000,  0.8015, -0.0827,  0.9790, -0.9620,  0.9966,\n",
            "         -0.9690, -1.0000,  0.8677,  0.6074, -0.0598,  0.9359, -0.9266,  0.9334,\n",
            "         -0.7380,  0.9095,  0.9368,  0.9305,  0.4372,  0.5871,  0.8748, -0.8916,\n",
            "          0.1781, -0.9067, -0.4993, -0.9943,  0.9795, -0.9402,  0.9828, -0.9314,\n",
            "         -0.6496,  0.6513, -0.0260, -1.0000,  0.9473,  0.7423,  0.8811, -0.5699,\n",
            "          0.7678, -0.6541,  0.7854, -0.3189, -0.8884,  0.9570, -0.6316,  0.9846,\n",
            "          0.8891, -0.9988,  0.9738,  0.9991,  0.6345, -0.9427, -0.0611,  0.9963,\n",
            "         -0.9982, -0.8802,  0.2332, -0.8729,  0.8750,  0.3334, -0.6671, -0.7108,\n",
            "          0.9734, -0.0441,  0.7174, -0.3689,  0.5566,  0.5801, -0.7812,  0.6612,\n",
            "          0.9399,  0.9994, -0.7855, -0.4935,  0.3814, -0.9998,  0.9352,  0.4789,\n",
            "          0.0424, -0.8117,  0.9974,  0.9601,  0.6842,  0.9776, -0.9739, -0.7857,\n",
            "         -0.4234,  0.1109,  0.6153,  0.0369,  1.0000, -0.9986,  0.9849,  0.8027,\n",
            "          0.5241,  0.2326, -0.1298, -0.0596,  0.6842,  0.5632, -0.5809,  0.9972,\n",
            "         -0.8913, -0.9956,  0.2757,  0.6048, -0.9880, -0.7332,  0.4810, -0.9072,\n",
            "          0.9951,  1.0000, -0.0675,  0.6928,  0.8726,  0.8810,  0.9461, -0.9867,\n",
            "          0.9920,  1.0000, -0.9758, -0.1513,  1.0000,  0.8623, -0.8036, -0.4024,\n",
            "          0.6876, -0.9689, -0.0910, -0.5821, -0.1331, -0.2508,  0.5579, -0.9612,\n",
            "         -0.9997, -0.9972,  0.9955, -0.8398, -0.7202,  0.9028, -0.7173, -0.8217,\n",
            "         -0.1561,  0.9927, -0.9209,  1.0000,  0.9131, -0.5976, -0.9774, -0.3847,\n",
            "          0.7637,  0.4177,  0.9987,  0.5439, -0.9207,  0.9337,  0.8916,  0.1076,\n",
            "          0.9367, -0.5451,  0.7624,  0.0160,  0.6934, -0.9823, -0.5517, -0.9401,\n",
            "          0.9784,  0.9855,  0.9185, -0.9066,  0.9631,  0.9009, -1.0000,  0.9997,\n",
            "          0.9732, -0.9963,  0.8819, -0.4916,  0.9405,  0.3188,  0.9388, -0.9216,\n",
            "         -0.9289, -0.9923,  0.9096,  0.5822, -0.6675,  0.8448, -0.9091,  0.8579,\n",
            "          0.5751,  0.6717,  0.3377, -0.7881, -0.9993,  0.7726,  0.8758,  0.5361,\n",
            "          0.8333,  0.9857,  0.4504,  1.0000, -0.9134,  0.9295, -0.5806,  0.9212,\n",
            "          0.4158,  0.8161,  0.2778, -0.3893, -1.0000, -0.0718, -0.3898,  0.6240,\n",
            "          0.3796, -0.9895, -0.6243, -0.3521, -0.7996,  0.3024,  0.0739,  0.2651,\n",
            "          0.9998,  0.8131, -0.1897, -0.7947, -0.5663,  0.5540,  0.9748,  0.9592,\n",
            "          0.9977, -0.8922,  0.7298,  0.7632,  0.1279, -0.8728,  0.2734,  0.5883,\n",
            "          0.5218,  0.9783,  0.9167,  0.5439, -0.7851,  0.8931, -0.9973,  1.0000,\n",
            "          0.5634,  0.8015,  0.9659, -0.1148,  0.9544, -0.7750,  0.6651, -0.8984,\n",
            "          0.9949,  0.8281,  0.7764,  0.5423,  0.8844, -0.4286, -0.8388,  0.9516,\n",
            "          0.3500, -0.8501, -0.9910,  0.9814, -0.9963,  0.0170, -0.8894,  0.7711,\n",
            "          0.9903, -0.8189, -0.7757, -0.8802, -0.6425, -0.9773, -0.9689, -0.9984,\n",
            "         -0.1557, -0.9756,  0.9999, -0.9954,  0.7706, -0.9587, -0.8562,  0.8816,\n",
            "          0.1911, -0.8154, -0.6855,  0.2085, -0.7675,  0.9480, -0.2079,  0.8085,\n",
            "         -0.0931,  0.1400,  0.8199,  0.7483,  0.5171,  0.8604, -0.8780, -0.9957,\n",
            "         -0.8781, -0.6707, -0.4327,  0.9610, -0.9863, -0.3168,  1.0000, -0.9929,\n",
            "         -0.1043, -0.3576, -0.9987,  0.8027, -0.9682, -0.9901, -0.7827, -0.8370,\n",
            "          0.9475,  0.9401,  0.9997, -0.1010, -0.6732, -0.9804, -0.7507,  0.9809,\n",
            "         -0.9901,  0.3640, -0.1479, -0.9987,  0.9680,  0.7544, -0.5197,  0.9304,\n",
            "         -0.8447,  0.9757, -0.1711, -0.9960,  0.9081,  0.9097,  0.2513,  0.9333,\n",
            "         -0.6647, -0.2994, -0.9584,  0.7125,  0.9999, -0.3868, -0.9506,  0.9060,\n",
            "          0.9217,  0.7929,  1.0000, -0.9410,  0.8142,  0.9999, -0.3137,  0.6988,\n",
            "         -0.4078, -0.8618, -0.3431,  0.8320, -0.9946,  0.9999, -0.5487, -0.9950,\n",
            "         -1.0000,  0.7187, -0.8702,  0.7426,  0.9736,  0.0857,  0.8974,  0.8005,\n",
            "         -0.9971,  0.9004, -0.9043, -1.0000, -0.9998,  0.8669, -0.0982, -0.4320,\n",
            "          0.7748, -0.5970, -0.8565,  0.9998,  0.8189, -1.0000, -0.8425,  0.4878,\n",
            "          0.9803, -0.8888,  0.8702,  0.0168, -0.0212, -0.3356, -1.0000, -0.9231,\n",
            "          0.9943, -0.4913,  0.2217,  0.9998,  0.8449, -0.5556, -0.9803,  0.7264,\n",
            "          0.9575, -1.0000, -0.9260,  0.9999, -0.8707, -0.7083, -0.9497, -0.2229,\n",
            "          0.7288,  0.8934,  0.9249, -0.9986,  0.9991,  0.8750, -0.6592,  0.9971,\n",
            "         -0.0484, -0.8677, -0.9666, -0.7440,  0.9470, -0.7542,  0.8925, -0.9095,\n",
            "          0.9946,  0.9344, -0.9387,  0.9344,  0.8704, -0.8295, -0.8263,  0.9830,\n",
            "          0.8763, -0.1523,  0.9848, -0.1698, -0.8618, -0.2191,  0.9195,  0.9126,\n",
            "         -1.0000,  0.9416, -0.6891, -0.9476,  0.6683, -0.2239, -0.9370, -0.5260,\n",
            "          0.7108, -0.8736,  0.7259,  0.9701,  0.9551,  0.9494, -0.9894, -1.0000,\n",
            "         -0.8032, -0.6088, -0.8711,  0.2709, -0.3100,  0.9905,  0.6557,  0.7728,\n",
            "          0.7381,  0.9999, -0.7205,  0.9648, -0.9118,  0.9664, -0.9966,  0.9214,\n",
            "          0.3360, -0.9932, -0.9081,  0.9022, -0.8517,  0.8862, -0.9724,  0.8042,\n",
            "          1.0000, -0.6921,  0.1453,  0.8847, -0.9472,  0.8670, -0.6897,  0.9986,\n",
            "         -1.0000,  0.9873,  0.7792,  0.6020,  0.8194,  0.5678,  0.2280, -0.8170,\n",
            "         -0.8899, -0.9944, -0.3798,  0.5858, -0.8291,  0.4802,  0.9856, -0.9636,\n",
            "         -0.9998, -0.7589,  0.2038,  0.9504, -0.5905, -0.9970,  0.9693, -0.6005,\n",
            "          0.9951, -0.5272, -0.7563, -0.8234, -0.8285, -0.6068,  0.8451,  0.8912,\n",
            "          0.9624,  0.7067, -0.5914, -0.5991, -0.6060, -0.8782,  0.8853,  0.4547,\n",
            "          0.8540,  0.8330,  0.9137,  0.9892,  0.5947, -0.5422,  0.8360, -0.6854,\n",
            "         -0.5114, -0.9998,  0.9993,  0.9259, -0.9154, -0.9999,  0.9406,  0.8737,\n",
            "         -0.5797,  0.9024, -0.7778, -0.9657, -0.4685,  0.9696, -1.0000, -0.7065,\n",
            "          0.6238, -0.5674, -0.0981, -0.9998, -0.5129,  0.7064, -0.6252,  0.4877,\n",
            "          0.9996, -0.5577, -0.9959, -0.9751, -0.3267,  0.7391,  0.5139, -0.9979,\n",
            "         -0.7215,  0.9492, -0.9993,  0.0270, -0.8986, -0.7851,  0.5765,  0.7721,\n",
            "          0.8794, -1.0000,  0.9333, -0.8544,  0.9527, -0.4901,  0.4817,  0.9150,\n",
            "          0.9436, -0.9997,  0.9442,  0.2877,  0.8694,  0.8688,  0.9366, -0.3892,\n",
            "         -0.9632, -0.9294,  0.9975,  0.9943, -0.5914,  0.9308,  0.9996, -0.4686,\n",
            "          0.7390,  0.5997, -0.7133, -0.9993, -0.8136, -0.7131, -0.3043, -0.9483]],\n",
            "       device='cuda:0')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training... :   0%|          | 0/127 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9210640196204e76b9afb46e09bc612e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6187,  0.9999, -0.6998,  ..., -0.8843,  0.3987, -0.5194],\n",
            "        [ 0.3747,  0.9976,  0.8169,  ...,  0.3480,  0.3077, -0.7166],\n",
            "        [ 0.5110,  1.0000,  0.8913,  ...,  0.6182, -0.2657, -0.6560],\n",
            "        ...,\n",
            "        [ 0.7855,  1.0000,  0.8947,  ...,  0.8018,  0.0064, -0.8699],\n",
            "        [ 0.4763,  1.0000, -0.0352,  ..., -0.7087,  0.7929, -0.7070],\n",
            "        [ 0.7126,  1.0000,  0.8682,  ...,  0.7074, -0.4911, -0.6098]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1859,  0.9999, -0.4787,  ..., -0.8567,  0.2970, -0.1542],\n",
            "        [ 0.7305,  1.0000,  0.8464,  ...,  0.7824, -0.4752, -0.6219],\n",
            "        [ 0.0883,  1.0000, -0.5692,  ..., -0.9090,  0.5604, -0.7680],\n",
            "        ...,\n",
            "        [ 0.5960,  1.0000,  0.6741,  ..., -0.5138,  0.3843, -0.9431],\n",
            "        [ 0.7909,  1.0000,  0.9072,  ...,  0.6575, -0.3589, -0.7586],\n",
            "        [ 0.7071,  1.0000,  0.9255,  ...,  0.4452, -0.4950, -0.9206]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2203,  1.0000, -0.5217,  ..., -0.7703,  0.6238, -0.7352],\n",
            "        [ 0.6769,  1.0000,  0.9271,  ...,  0.7085, -0.3441, -0.6614],\n",
            "        [ 0.5677,  1.0000,  0.9171,  ...,  0.5995, -0.2809, -0.6795],\n",
            "        ...,\n",
            "        [ 0.4523,  1.0000,  0.9244,  ...,  0.6575, -0.2929, -0.8641],\n",
            "        [ 0.5769,  1.0000,  0.9080,  ...,  0.7715, -0.4691, -0.6396],\n",
            "        [ 0.7254,  1.0000,  0.8582,  ...,  0.7598, -0.3011, -0.6420]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7914,  1.0000,  0.8763,  ...,  0.7937, -0.3628, -0.7276],\n",
            "        [-0.1751,  0.9991,  0.8058,  ..., -0.2013, -0.0929, -0.8003],\n",
            "        [ 0.5821,  1.0000,  0.7836,  ...,  0.3779, -0.1319, -0.6107],\n",
            "        ...,\n",
            "        [-0.0742,  1.0000, -0.6465,  ..., -0.7675,  0.4645, -0.7553],\n",
            "        [ 0.6961,  1.0000,  0.9242,  ...,  0.6790, -0.3056, -0.7912],\n",
            "        [-0.1076,  1.0000, -0.7839,  ..., -0.9119,  0.5023, -0.5705]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1104,  0.9999, -0.8480,  ..., -0.9096,  0.3175, -0.6275],\n",
            "        [ 0.2773,  1.0000,  0.3184,  ..., -0.5583,  0.6326, -0.9480],\n",
            "        [-0.3060,  1.0000, -0.6269,  ..., -0.8792,  0.4712, -0.6806],\n",
            "        ...,\n",
            "        [ 0.4590,  1.0000,  0.8370,  ..., -0.4486,  0.4492, -0.9721],\n",
            "        [ 0.6963,  1.0000,  0.8378,  ...,  0.7162, -0.2887, -0.6357],\n",
            "        [ 0.5196,  1.0000,  0.9140,  ...,  0.7033, -0.0870, -0.6349]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5853,  1.0000,  0.9192,  ...,  0.6775,  0.0256, -0.6639],\n",
            "        [-0.1430,  1.0000,  0.8811,  ..., -0.3778,  0.1544, -0.7838],\n",
            "        [-0.3148,  0.9996, -0.3225,  ..., -0.7462,  0.5480, -0.2590],\n",
            "        ...,\n",
            "        [ 0.5959,  1.0000,  0.8126,  ...,  0.6388, -0.1954, -0.5542],\n",
            "        [ 0.6354,  1.0000,  0.8355,  ...,  0.2983,  0.0407, -0.9351],\n",
            "        [-0.5367,  1.0000, -0.6411,  ..., -0.8767,  0.6141, -0.5539]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1077,  1.0000, -0.6668,  ..., -0.5587,  0.5129, -0.5523],\n",
            "        [ 0.5402,  1.0000,  0.9200,  ...,  0.7568, -0.2268, -0.6213],\n",
            "        [ 0.7547,  1.0000,  0.9225,  ...,  0.8631, -0.3050, -0.7369],\n",
            "        ...,\n",
            "        [ 0.8057,  1.0000,  0.9135,  ...,  0.8404, -0.5616, -0.6375],\n",
            "        [ 0.7670,  1.0000,  0.8277,  ...,  0.7639,  0.0418, -0.4503],\n",
            "        [-0.4051,  1.0000, -0.5903,  ..., -0.8585,  0.6923, -0.7329]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1463,  1.0000, -0.4161,  ..., -0.7750,  0.2482, -0.7932],\n",
            "        [ 0.7230,  1.0000,  0.9385,  ...,  0.7720, -0.4476, -0.5416],\n",
            "        [ 0.7333,  1.0000,  0.9041,  ...,  0.8306, -0.4834, -0.6247],\n",
            "        ...,\n",
            "        [-0.0524,  1.0000, -0.7156,  ..., -0.8733,  0.5743, -0.6610],\n",
            "        [-0.3630,  1.0000, -0.7989,  ..., -0.7939,  0.3609, -0.4659],\n",
            "        [-0.0207,  1.0000, -0.7433,  ..., -0.8986,  0.6344, -0.8438]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2203,  1.0000, -0.0156,  ..., -0.7920,  0.3134, -0.8556],\n",
            "        [ 0.6765,  1.0000,  0.8547,  ...,  0.4372, -0.3855, -0.7947],\n",
            "        [-0.2730,  1.0000, -0.4060,  ..., -0.9035,  0.5473, -0.9146],\n",
            "        ...,\n",
            "        [-0.0616,  1.0000, -0.6835,  ..., -0.8942,  0.6817, -0.4281],\n",
            "        [ 0.6996,  1.0000,  0.8936,  ...,  0.7739, -0.3882, -0.4345],\n",
            "        [-0.1372,  1.0000, -0.7833,  ..., -0.8659,  0.3619, -0.4313]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7681,  1.0000,  0.8730,  ...,  0.8232, -0.3008, -0.7445],\n",
            "        [ 0.2109,  1.0000,  0.3688,  ..., -0.7702,  0.4177, -0.9534],\n",
            "        [ 0.8047,  1.0000,  0.9366,  ...,  0.6867, -0.2728, -0.9119],\n",
            "        ...,\n",
            "        [ 0.6391,  1.0000,  0.9080,  ...,  0.7754, -0.4484, -0.4487],\n",
            "        [ 0.6047,  1.0000,  0.8976,  ...,  0.8398, -0.2789, -0.4071],\n",
            "        [ 0.7083,  1.0000,  0.8866,  ...,  0.5629, -0.2066, -0.8418]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1462,  0.9988, -0.8193,  ..., -0.8766,  0.2159, -0.2201],\n",
            "        [ 0.6817,  1.0000,  0.8084,  ...,  0.7445, -0.2753, -0.5483],\n",
            "        [-0.1223,  0.9996, -0.1607,  ..., -0.6322, -0.1763, -0.7544],\n",
            "        ...,\n",
            "        [ 0.6445,  1.0000,  0.9135,  ...,  0.8500, -0.4768, -0.7186],\n",
            "        [ 0.7525,  1.0000,  0.9113,  ...,  0.8210, -0.1584, -0.8260],\n",
            "        [ 0.7526,  1.0000,  0.8569,  ...,  0.8067, -0.2902, -0.6060]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2756,  0.9999, -0.6702,  ..., -0.9331,  0.5913, -0.5733],\n",
            "        [ 0.6811,  1.0000,  0.8774,  ...,  0.4709, -0.4814, -0.4580],\n",
            "        [-0.0948,  1.0000, -0.8228,  ..., -0.8259,  0.4958, -0.3634],\n",
            "        ...,\n",
            "        [ 0.1317,  0.9984,  0.7775,  ...,  0.4425, -0.0439, -0.5278],\n",
            "        [ 0.7489,  1.0000,  0.9010,  ...,  0.6795, -0.5106, -0.7297],\n",
            "        [ 0.6652,  1.0000,  0.8908,  ...,  0.8550, -0.3820, -0.5461]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6558,  1.0000,  0.9204,  ...,  0.8627, -0.2717, -0.6912],\n",
            "        [ 0.1313,  1.0000, -0.3451,  ..., -0.8937,  0.5712, -0.5423],\n",
            "        [-0.2888,  0.9998, -0.7553,  ..., -0.8289,  0.4844,  0.1216],\n",
            "        ...,\n",
            "        [ 0.7190,  1.0000,  0.9354,  ...,  0.7826, -0.2861, -0.5932],\n",
            "        [ 0.7284,  1.0000,  0.8480,  ...,  0.7731, -0.3492, -0.7968],\n",
            "        [ 0.7419,  1.0000,  0.9213,  ...,  0.8244, -0.2076, -0.8014]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7351,  1.0000,  0.8140,  ...,  0.3918, -0.3756, -0.9166],\n",
            "        [ 0.4697,  1.0000,  0.6186,  ..., -0.1224,  0.1347, -0.9193],\n",
            "        [-0.4817,  0.9998, -0.9002,  ..., -0.9035,  0.3629, -0.1224],\n",
            "        ...,\n",
            "        [ 0.7918,  1.0000,  0.9124,  ...,  0.8127, -0.2092, -0.7086],\n",
            "        [-0.4096,  1.0000, -0.6467,  ..., -0.8709,  0.6369, -0.7337],\n",
            "        [ 0.7231,  1.0000,  0.8846,  ...,  0.8058, -0.3767, -0.5729]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.8235,  1.0000,  0.8495,  ...,  0.8470, -0.3416, -0.6986],\n",
            "        [-0.1167,  1.0000, -0.8372,  ..., -0.8469,  0.3815, -0.3998],\n",
            "        [ 0.5222,  1.0000,  0.8545,  ...,  0.7866, -0.2910, -0.7023],\n",
            "        ...,\n",
            "        [-0.3855,  0.9999, -0.6647,  ..., -0.7871,  0.7376, -0.1725],\n",
            "        [ 0.3057,  1.0000,  0.4640,  ..., -0.5253,  0.5598, -0.9729],\n",
            "        [ 0.6344,  1.0000,  0.9248,  ...,  0.5990, -0.2119, -0.7688]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6495,  1.0000,  0.9553,  ...,  0.8538, -0.4839, -0.5968],\n",
            "        [-0.2030,  1.0000, -0.8495,  ..., -0.8761,  0.5244, -0.1953],\n",
            "        [ 0.8233,  1.0000,  0.8927,  ...,  0.8014, -0.2989, -0.6060],\n",
            "        ...,\n",
            "        [-0.1570,  1.0000, -0.5260,  ..., -0.8543,  0.6302, -0.4082],\n",
            "        [-0.0668,  0.9999, -0.8284,  ..., -0.8576,  0.3528,  0.0419],\n",
            "        [-0.1337,  1.0000, -0.7511,  ..., -0.7610,  0.3494, -0.2872]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1586,  0.9999, -0.7019,  ..., -0.9044,  0.5365, -0.4958],\n",
            "        [ 0.2157,  1.0000, -0.5649,  ..., -0.7826,  0.6555, -0.3536],\n",
            "        [ 0.6418,  1.0000,  0.9332,  ...,  0.8790, -0.4677, -0.3781],\n",
            "        ...,\n",
            "        [ 0.8030,  1.0000,  0.9333,  ...,  0.4519, -0.3538, -0.7493],\n",
            "        [ 0.5099,  1.0000,  0.8105,  ...,  0.6828, -0.5837, -0.6071],\n",
            "        [ 0.1722,  0.9994,  0.8554,  ...,  0.6657,  0.0257, -0.5936]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6952,  1.0000,  0.9574,  ...,  0.5240,  0.1179, -0.8745],\n",
            "        [-0.2573,  1.0000,  0.1751,  ..., -0.7220,  0.6468, -0.9375],\n",
            "        [ 0.7167,  1.0000,  0.9527,  ...,  0.8677, -0.2294, -0.6405],\n",
            "        ...,\n",
            "        [-0.2479,  1.0000,  0.6743,  ..., -0.5091,  0.2801, -0.9041],\n",
            "        [ 0.5792,  0.9999,  0.9416,  ...,  0.5434,  0.1158, -0.8086],\n",
            "        [ 0.7440,  1.0000,  0.9279,  ...,  0.6605, -0.0260, -0.8390]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6839,  1.0000,  0.8832,  ...,  0.7103, -0.1069, -0.7904],\n",
            "        [ 0.8208,  1.0000,  0.9195,  ...,  0.8040, -0.2819, -0.7787],\n",
            "        [-0.2788,  1.0000, -0.5743,  ..., -0.9118,  0.3872, -0.0731],\n",
            "        ...,\n",
            "        [ 0.7539,  1.0000,  0.9465,  ...,  0.7456, -0.2808, -0.7109],\n",
            "        [ 0.7855,  1.0000,  0.8909,  ...,  0.6387,  0.2718, -0.9006],\n",
            "        [ 0.4514,  1.0000,  0.8641,  ...,  0.6999,  0.3137, -0.4945]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2517,  0.9998, -0.7922,  ..., -0.9023,  0.2472, -0.1919],\n",
            "        [ 0.7048,  1.0000,  0.9078,  ...,  0.8172,  0.0826, -0.7226],\n",
            "        [ 0.6768,  1.0000,  0.9190,  ...,  0.8189, -0.1979, -0.5445],\n",
            "        ...,\n",
            "        [ 0.1629,  1.0000,  0.3779,  ..., -0.5907,  0.5347, -0.8890],\n",
            "        [ 0.3178,  1.0000,  0.5974,  ..., -0.5615,  0.1982, -0.8967],\n",
            "        [ 0.6939,  1.0000,  0.9067,  ...,  0.6693, -0.0981, -0.7942]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7229,  1.0000,  0.9243,  ...,  0.7774,  0.0831, -0.6951],\n",
            "        [ 0.7017,  1.0000,  0.8899,  ...,  0.6176, -0.3371, -0.6531],\n",
            "        [ 0.6792,  0.9999,  0.9036,  ...,  0.7104, -0.2201, -0.3658],\n",
            "        ...,\n",
            "        [-0.3833,  0.9964, -0.8974,  ..., -0.8995,  0.5265,  0.0662],\n",
            "        [-0.4418,  1.0000, -0.8696,  ..., -0.9245,  0.1615, -0.2784],\n",
            "        [-0.3343,  0.8935,  0.3474,  ...,  0.1982,  0.0531, -0.5128]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2800,  1.0000, -0.8032,  ..., -0.8729,  0.5060, -0.3722],\n",
            "        [-0.4686,  1.0000, -0.6753,  ..., -0.6808,  0.4418, -0.4365],\n",
            "        [ 0.6738,  1.0000,  0.9225,  ...,  0.7511, -0.2402, -0.6426],\n",
            "        ...,\n",
            "        [-0.5465,  1.0000, -0.8131,  ..., -0.9082,  0.7095, -0.6948],\n",
            "        [ 0.7368,  1.0000,  0.9436,  ...,  0.8262, -0.4466, -0.4688],\n",
            "        [ 0.0102,  1.0000,  0.8044,  ...,  0.0336,  0.3081, -0.9726]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3587,  1.0000,  0.5084,  ..., -0.3232,  0.2981, -0.9435],\n",
            "        [ 0.7780,  1.0000,  0.8910,  ...,  0.1706, -0.2830, -0.6480],\n",
            "        [ 0.0243,  0.9999, -0.4687,  ..., -0.8119,  0.8020, -0.1838],\n",
            "        ...,\n",
            "        [ 0.6517,  1.0000,  0.8152,  ...,  0.6339, -0.0446, -0.6169],\n",
            "        [-0.1222,  1.0000, -0.6583,  ..., -0.8075,  0.3764, -0.6464],\n",
            "        [ 0.7795,  1.0000,  0.9200,  ...,  0.7730, -0.0248, -0.7896]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2723,  1.0000, -0.8356,  ..., -0.9047,  0.2947, -0.0218],\n",
            "        [ 0.6932,  1.0000,  0.9178,  ...,  0.8178, -0.2599, -0.5615],\n",
            "        [ 0.6278,  1.0000,  0.9236,  ...,  0.2471,  0.2590, -0.9809],\n",
            "        ...,\n",
            "        [-0.3295,  0.9996, -0.8566,  ..., -0.8093,  0.4057, -0.2326],\n",
            "        [ 0.5935,  1.0000,  0.8758,  ...,  0.7778, -0.2917, -0.7132],\n",
            "        [ 0.7113,  1.0000,  0.9286,  ...,  0.9009, -0.1566, -0.7000]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3869,  1.0000,  0.9148,  ...,  0.7154,  0.0217, -0.6152],\n",
            "        [ 0.6551,  1.0000,  0.9273,  ...,  0.7488, -0.1291, -0.6783],\n",
            "        [-0.3003,  0.9990, -0.8964,  ..., -0.9146,  0.2441,  0.0966],\n",
            "        ...,\n",
            "        [-0.2020,  1.0000, -0.6913,  ..., -0.9134,  0.6100, -0.4707],\n",
            "        [ 0.7035,  1.0000,  0.8999,  ...,  0.6573, -0.1109, -0.7677],\n",
            "        [ 0.3400,  1.0000,  0.8811,  ...,  0.5838, -0.0611, -0.7728]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0855,  1.0000, -0.8399,  ..., -0.8773,  0.5908, -0.4520],\n",
            "        [ 0.5456,  1.0000,  0.9041,  ...,  0.5828, -0.1871, -0.6912],\n",
            "        [ 0.7727,  1.0000,  0.8888,  ...,  0.6018, -0.0618, -0.6523],\n",
            "        ...,\n",
            "        [-0.4500,  0.9999, -0.3783,  ..., -0.7916,  0.3186, -0.6958],\n",
            "        [ 0.1750,  1.0000, -0.2948,  ..., -0.7123,  0.4332, -0.9232],\n",
            "        [-0.2157,  1.0000, -0.6996,  ..., -0.8495,  0.7097, -0.3374]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1554,  0.9998, -0.8641,  ..., -0.9198,  0.3147, -0.1523],\n",
            "        [ 0.2921,  1.0000,  0.8699,  ...,  0.6791, -0.4142, -0.5836],\n",
            "        [ 0.5314,  1.0000,  0.9201,  ...,  0.1773,  0.1795, -0.9560],\n",
            "        ...,\n",
            "        [-0.0622,  1.0000,  0.8221,  ..., -0.7022,  0.3684, -0.8778],\n",
            "        [-0.4734,  0.9999, -0.8489,  ..., -0.9171,  0.5949, -0.0891],\n",
            "        [-0.2680,  1.0000, -0.7580,  ..., -0.8931,  0.5456, -0.1172]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5850,  1.0000, -0.5061,  ..., -0.8645,  0.5200, -0.6130],\n",
            "        [-0.5225,  0.9998, -0.8555,  ..., -0.8464,  0.5069,  0.0461],\n",
            "        [ 0.2015,  1.0000, -0.4632,  ..., -0.8207,  0.1791, -0.8474],\n",
            "        ...,\n",
            "        [ 0.7501,  1.0000,  0.8214,  ...,  0.6586,  0.1741, -0.7394],\n",
            "        [-0.1574,  1.0000, -0.7139,  ..., -0.8376,  0.5956, -0.5620],\n",
            "        [-0.1153,  0.9999, -0.7664,  ..., -0.8421,  0.4883, -0.0441]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6160,  1.0000,  0.8764,  ...,  0.6387, -0.0330, -0.7081],\n",
            "        [ 0.6156,  1.0000,  0.9014,  ...,  0.6794, -0.0935, -0.6226],\n",
            "        [ 0.0508,  1.0000,  0.6109,  ..., -0.8682,  0.5409, -0.9312],\n",
            "        ...,\n",
            "        [-0.1791,  0.9992, -0.6253,  ..., -0.8249,  0.4067, -0.0078],\n",
            "        [ 0.3079,  0.9986,  0.8271,  ...,  0.5471,  0.1327, -0.3474],\n",
            "        [ 0.5473,  1.0000,  0.9208,  ...,  0.7795, -0.0487, -0.5562]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1036,  0.9094,  0.3543,  ...,  0.4036,  0.0740, -0.3830],\n",
            "        [ 0.8385,  1.0000,  0.8339,  ...,  0.7469, -0.1203, -0.7495],\n",
            "        [-0.2009,  1.0000, -0.7963,  ..., -0.8844,  0.4101, -0.5114],\n",
            "        ...,\n",
            "        [ 0.8337,  1.0000,  0.9070,  ...,  0.8470, -0.1643, -0.6336],\n",
            "        [-0.2307,  0.9968, -0.8553,  ..., -0.9077,  0.5645,  0.1481],\n",
            "        [ 0.2797,  0.9977,  0.5517,  ...,  0.8107, -0.1586, -0.0380]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4967,  0.9996, -0.8586,  ..., -0.9014,  0.2725,  0.0625],\n",
            "        [-0.2361,  0.9996, -0.8504,  ..., -0.8990,  0.2042, -0.0668],\n",
            "        [ 0.4031,  1.0000,  0.7905,  ...,  0.4323,  0.1393, -0.7293],\n",
            "        ...,\n",
            "        [-0.5337,  0.9973, -0.8837,  ..., -0.8783,  0.3679,  0.5004],\n",
            "        [ 0.6936,  1.0000,  0.8911,  ...,  0.8058, -0.4343, -0.6726],\n",
            "        [-0.2175,  0.9996, -0.8337,  ..., -0.9018,  0.3663, -0.1092]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5726,  1.0000,  0.8169,  ...,  0.7946, -0.2637, -0.5386],\n",
            "        [ 0.6528,  1.0000,  0.9320,  ...,  0.7828, -0.2484, -0.4838],\n",
            "        [-0.1158,  1.0000, -0.7858,  ..., -0.8528,  0.5904, -0.4591],\n",
            "        ...,\n",
            "        [-0.2145,  1.0000, -0.2783,  ..., -0.7604,  0.5513, -0.7105],\n",
            "        [-0.0077,  0.9967,  0.7866,  ...,  0.4792, -0.2118, -0.2519],\n",
            "        [ 0.1217,  0.9976,  0.7446,  ...,  0.4120, -0.3584, -0.3253]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2097,  0.9996,  0.8257,  ...,  0.4616, -0.2703, -0.5335],\n",
            "        [-0.4177,  1.0000, -0.8911,  ..., -0.8455,  0.4292, -0.1133],\n",
            "        [ 0.2963,  1.0000,  0.9331,  ...,  0.7456, -0.2093, -0.1154],\n",
            "        ...,\n",
            "        [ 0.9079,  1.0000,  0.8931,  ...,  0.7855,  0.2153, -0.9238],\n",
            "        [-0.1571,  1.0000, -0.7027,  ..., -0.9314,  0.5416, -0.4950],\n",
            "        [-0.3191,  0.9999, -0.8581,  ..., -0.8307,  0.1944, -0.1925]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3303,  0.9999, -0.6509,  ..., -0.8499,  0.2633, -0.2824],\n",
            "        [-0.2543,  1.0000, -0.8435,  ..., -0.8595,  0.5253, -0.4573],\n",
            "        [ 0.6536,  1.0000,  0.8557,  ...,  0.8565, -0.2580, -0.6062],\n",
            "        ...,\n",
            "        [-0.4346,  1.0000, -0.8495,  ..., -0.8859,  0.7230, -0.4617],\n",
            "        [-0.0907,  0.8432,  0.4683,  ...,  0.3288, -0.1169, -0.2813],\n",
            "        [ 0.7897,  1.0000,  0.9350,  ...,  0.8246, -0.3166, -0.5061]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5279,  1.0000,  0.8793,  ...,  0.5311, -0.1559, -0.8788],\n",
            "        [ 0.7187,  1.0000,  0.8918,  ...,  0.5963, -0.0118, -0.6410],\n",
            "        [-0.0216,  1.0000,  0.3148,  ..., -0.6037, -0.1158, -0.8394],\n",
            "        ...,\n",
            "        [-0.4771,  0.9989, -0.8930,  ..., -0.9029,  0.1620,  0.2800],\n",
            "        [-0.2752,  1.0000, -0.6352,  ..., -0.7375,  0.0664, -0.6896],\n",
            "        [ 0.4816,  1.0000,  0.9472,  ...,  0.7721, -0.3820, -0.4229]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1477,  0.9998, -0.9208,  ..., -0.8937,  0.4473, -0.1121],\n",
            "        [-0.3132,  1.0000, -0.8552,  ..., -0.8902,  0.5309, -0.0128],\n",
            "        [ 0.2886,  1.0000,  0.2725,  ..., -0.7924,  0.7353, -0.9598],\n",
            "        ...,\n",
            "        [ 0.7392,  1.0000,  0.9241,  ...,  0.7338,  0.0233, -0.6762],\n",
            "        [-0.5018,  0.9999, -0.8513,  ..., -0.8986,  0.2437,  0.3453],\n",
            "        [-0.3342,  0.9983, -0.8777,  ..., -0.8695,  0.5900, -0.0995]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1585,  0.9999, -0.8204,  ..., -0.8953,  0.5025, -0.3909],\n",
            "        [ 0.6570,  1.0000,  0.8953,  ...,  0.6861, -0.5637, -0.6195],\n",
            "        [-0.1327,  0.9999, -0.7105,  ..., -0.7673,  0.6232, -0.4576],\n",
            "        ...,\n",
            "        [ 0.5918,  1.0000,  0.9059,  ...,  0.5851,  0.1692, -0.9443],\n",
            "        [ 0.6218,  1.0000,  0.9299,  ...,  0.7290, -0.0765, -0.7677],\n",
            "        [-0.6052,  1.0000, -0.4749,  ..., -0.5528,  0.4937, -0.7224]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7374,  1.0000,  0.8532,  ...,  0.7859, -0.1105, -0.4290],\n",
            "        [ 0.6297,  1.0000,  0.9326,  ...,  0.7837, -0.0523, -0.5087],\n",
            "        [ 0.5136,  1.0000,  0.8399,  ...,  0.7095, -0.2285, -0.2878],\n",
            "        ...,\n",
            "        [-0.3970,  1.0000, -0.7998,  ..., -0.8475,  0.4553, -0.1918],\n",
            "        [-0.4165,  1.0000, -0.7017,  ..., -0.9156,  0.6432, -0.2125],\n",
            "        [ 0.0185,  1.0000, -0.8557,  ..., -0.9165,  0.5215, -0.3986]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0908,  0.9999, -0.7829,  ..., -0.8682,  0.5490, -0.5694],\n",
            "        [-0.1924,  1.0000, -0.3130,  ..., -0.9047,  0.6232, -0.8321],\n",
            "        [ 0.6501,  1.0000,  0.9266,  ...,  0.7950, -0.4359, -0.5376],\n",
            "        ...,\n",
            "        [ 0.5713,  0.9999,  0.8512,  ...,  0.7371, -0.3649, -0.6791],\n",
            "        [ 0.6771,  1.0000,  0.8360,  ...,  0.7431, -0.3614, -0.6519],\n",
            "        [ 0.7002,  1.0000,  0.9322,  ...,  0.8612, -0.4076, -0.5306]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0813,  0.1907,  0.5826,  ...,  0.7001, -0.5136, -0.1576],\n",
            "        [ 0.6060,  1.0000,  0.9216,  ...,  0.8907, -0.3379, -0.4569],\n",
            "        [ 0.7552,  1.0000,  0.7953,  ...,  0.6560, -0.4353, -0.7245],\n",
            "        ...,\n",
            "        [-0.1955,  1.0000, -0.6822,  ..., -0.8598,  0.4892, -0.6478],\n",
            "        [ 0.6954,  1.0000,  0.9015,  ...,  0.9009, -0.3599, -0.4771],\n",
            "        [-0.1377,  0.9999, -0.8843,  ..., -0.8904,  0.4764, -0.2297]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7399,  1.0000,  0.9366,  ...,  0.8491, -0.4373, -0.4183],\n",
            "        [-0.2701,  0.9999, -0.8286,  ..., -0.8303,  0.1868, -0.2472],\n",
            "        [ 0.1285,  0.9999, -0.7762,  ..., -0.8588,  0.7070, -0.3761],\n",
            "        ...,\n",
            "        [-0.0690,  0.8499,  0.3885,  ...,  0.3915, -0.1688, -0.2572],\n",
            "        [ 0.3569,  0.9960,  0.9100,  ...,  0.7366, -0.4788, -0.3589],\n",
            "        [ 0.7104,  1.0000,  0.8972,  ...,  0.6398, -0.1104, -0.6560]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0688,  0.8905,  0.7494,  ...,  0.5651, -0.7669,  0.0065],\n",
            "        [ 0.5930,  1.0000,  0.9017,  ...,  0.6691, -0.4235, -0.4941],\n",
            "        [ 0.0310,  0.9999, -0.8597,  ..., -0.8902,  0.4955, -0.5289],\n",
            "        ...,\n",
            "        [ 0.6801,  0.9998,  0.8523,  ...,  0.8257, -0.6322, -0.5207],\n",
            "        [ 0.5857,  1.0000,  0.8531,  ...,  0.7208, -0.3749, -0.6788],\n",
            "        [ 0.5398,  1.0000,  0.9123,  ...,  0.6499, -0.5174, -0.5746]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5881,  1.0000,  0.8897,  ...,  0.7838, -0.3388, -0.6932],\n",
            "        [ 0.6748,  1.0000,  0.9195,  ...,  0.5828, -0.1647, -0.7914],\n",
            "        [ 0.6078,  1.0000,  0.9023,  ...,  0.8306, -0.2902, -0.6011],\n",
            "        ...,\n",
            "        [ 0.3670,  1.0000, -0.6691,  ..., -0.8576,  0.6170, -0.2534],\n",
            "        [-0.3269,  0.9998, -0.8409,  ..., -0.9379,  0.5363, -0.2466],\n",
            "        [-0.1157,  0.9994, -0.6813,  ..., -0.8095,  0.6309, -0.2293]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3587,  1.0000,  0.8710,  ...,  0.5813, -0.1275, -0.6270],\n",
            "        [ 0.6785,  0.9996,  0.9261,  ...,  0.7645, -0.4771, -0.5151],\n",
            "        [ 0.4107,  0.9997,  0.8733,  ...,  0.6658, -0.2265, -0.5491],\n",
            "        ...,\n",
            "        [-0.2450,  1.0000, -0.7754,  ..., -0.8802,  0.6077, -0.5206],\n",
            "        [ 0.7483,  1.0000,  0.8389,  ...,  0.8574, -0.4830, -0.5466],\n",
            "        [-0.2847,  0.9999, -0.7720,  ..., -0.8409,  0.6043, -0.4997]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3142,  0.9998,  0.9314,  ...,  0.7819, -0.3909, -0.1615],\n",
            "        [-0.0345,  0.9583,  0.5987,  ...,  0.6879, -0.6969, -0.0096],\n",
            "        [-0.4015,  1.0000, -0.7019,  ..., -0.8929,  0.5133, -0.7012],\n",
            "        ...,\n",
            "        [ 0.6485,  1.0000,  0.9295,  ...,  0.8418, -0.2404, -0.6121],\n",
            "        [-0.5420,  1.0000, -0.7688,  ..., -0.8648,  0.3092, -0.2065],\n",
            "        [ 0.5214,  1.0000,  0.9274,  ...,  0.7732, -0.2348, -0.6377]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3369,  1.0000, -0.7328,  ..., -0.8440,  0.4988,  0.3045],\n",
            "        [ 0.4478,  0.9996,  0.9218,  ...,  0.6644, -0.4010, -0.5058],\n",
            "        [-0.3463,  0.4987, -0.0453,  ...,  0.2792, -0.1681, -0.0532],\n",
            "        ...,\n",
            "        [ 0.6574,  1.0000,  0.8651,  ...,  0.7494, -0.4815, -0.8362],\n",
            "        [-0.4733,  1.0000, -0.4846,  ..., -0.8521,  0.5532, -0.7211],\n",
            "        [-0.2216,  1.0000, -0.7593,  ..., -0.8479,  0.6503, -0.2671]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5446,  1.0000,  0.8005,  ...,  0.5929, -0.3512, -0.6559],\n",
            "        [ 0.2340,  0.9989,  0.9135,  ...,  0.6797, -0.3375, -0.4059],\n",
            "        [-0.5458,  0.9996, -0.7515,  ..., -0.8901,  0.4344,  0.1359],\n",
            "        ...,\n",
            "        [ 0.2219,  1.0000,  0.4064,  ..., -0.6499,  0.6106, -0.8826],\n",
            "        [ 0.6734,  1.0000,  0.8494,  ...,  0.8141, -0.5194, -0.5738],\n",
            "        [-0.1964,  0.9994, -0.7713,  ..., -0.8370,  0.5476, -0.1693]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4366,  0.9999, -0.8524,  ..., -0.9410,  0.1506, -0.3941],\n",
            "        [ 0.7469,  1.0000,  0.9234,  ...,  0.8346, -0.4133, -0.5534],\n",
            "        [-0.3024,  1.0000, -0.7200,  ..., -0.8804,  0.8545, -0.3212],\n",
            "        ...,\n",
            "        [-0.2655,  0.9476,  0.1377,  ...,  0.5701, -0.3466,  0.0730],\n",
            "        [ 0.7160,  1.0000,  0.9312,  ...,  0.8500, -0.4241, -0.7361],\n",
            "        [-0.2043,  0.9954,  0.4643,  ...,  0.3295, -0.4335, -0.1602]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1682,  1.0000, -0.8213,  ..., -0.8696,  0.4757, -0.2871],\n",
            "        [ 0.7096,  1.0000,  0.8912,  ...,  0.7906, -0.3538, -0.5381],\n",
            "        [ 0.3804,  1.0000,  0.8278,  ...,  0.4665, -0.3633, -0.3944],\n",
            "        ...,\n",
            "        [-0.1204,  0.9992,  0.5424,  ...,  0.6135, -0.5211, -0.1635],\n",
            "        [-0.0044,  1.0000,  0.2459,  ..., -0.5748,  0.7061, -0.9601],\n",
            "        [-0.0768,  1.0000, -0.3951,  ..., -0.9025,  0.7321, -0.7415]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2926,  1.0000, -0.0260,  ..., -0.8212,  0.5544, -0.9293],\n",
            "        [ 0.3042,  1.0000,  0.8914,  ...,  0.0170,  0.3039, -0.8256],\n",
            "        [ 0.6587,  1.0000,  0.9174,  ...,  0.6993, -0.2788, -0.6886],\n",
            "        ...,\n",
            "        [ 0.7037,  1.0000,  0.8856,  ...,  0.7751, -0.5504, -0.5467],\n",
            "        [ 0.6857,  1.0000,  0.8889,  ...,  0.8954, -0.1977, -0.6510],\n",
            "        [ 0.0349,  0.9995,  0.7972,  ...,  0.5655, -0.4432, -0.2508]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2732,  1.0000, -0.3548,  ..., -0.8260,  0.2178, -0.0880],\n",
            "        [ 0.6102,  1.0000,  0.8944,  ...,  0.7961, -0.3255, -0.5401],\n",
            "        [ 0.0912,  1.0000,  0.9238,  ..., -0.1473,  0.5966, -0.8949],\n",
            "        ...,\n",
            "        [-0.2654,  1.0000, -0.6563,  ..., -0.8524,  0.5667, -0.6579],\n",
            "        [-0.2249,  1.0000, -0.3969,  ..., -0.8842,  0.5482, -0.4651],\n",
            "        [-0.0011,  1.0000, -0.7488,  ..., -0.8710,  0.5764, -0.4466]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6120,  1.0000,  0.8597,  ...,  0.8425, -0.2744, -0.5987],\n",
            "        [-0.3129,  1.0000, -0.5940,  ..., -0.9402,  0.8089, -0.7267],\n",
            "        [-0.6044,  1.0000, -0.7049,  ..., -0.8602,  0.1674, -0.3580],\n",
            "        ...,\n",
            "        [-0.6326,  1.0000, -0.8171,  ..., -0.9155,  0.6557, -0.5096],\n",
            "        [ 0.6728,  1.0000,  0.8965,  ...,  0.8152, -0.2357, -0.3490],\n",
            "        [ 0.6792,  1.0000,  0.9254,  ...,  0.8875,  0.0342, -0.6534]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7203,  1.0000,  0.9361,  ...,  0.8248, -0.3434, -0.6196],\n",
            "        [ 0.5069,  1.0000,  0.8492,  ...,  0.8342, -0.3583, -0.4993],\n",
            "        [ 0.4908,  1.0000,  0.0212,  ..., -0.6823,  0.7991, -0.9285],\n",
            "        ...,\n",
            "        [ 0.7975,  1.0000,  0.9408,  ...,  0.8880, -0.3718, -0.4980],\n",
            "        [ 0.1068,  1.0000, -0.6366,  ..., -0.8455,  0.6856, -0.6880],\n",
            "        [-0.3850,  1.0000, -0.4877,  ..., -0.7294,  0.6158, -0.7516]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3113,  0.9999, -0.7804,  ..., -0.8770,  0.5359, -0.6331],\n",
            "        [ 0.7112,  1.0000,  0.9411,  ...,  0.8151, -0.1251, -0.6463],\n",
            "        [ 0.6019,  1.0000,  0.9338,  ...,  0.7740, -0.3675, -0.4316],\n",
            "        ...,\n",
            "        [ 0.7005,  1.0000,  0.9269,  ...,  0.8834, -0.2408, -0.7106],\n",
            "        [ 0.6109,  1.0000,  0.9093,  ...,  0.7236, -0.2034, -0.6771],\n",
            "        [-0.4984,  0.9997, -0.8624,  ..., -0.8760,  0.4362,  0.2005]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6285,  1.0000,  0.8650,  ...,  0.7650, -0.4534, -0.6538],\n",
            "        [-0.2207,  0.9998,  0.5728,  ...,  0.5938, -0.0714, -0.5236],\n",
            "        [-0.0942,  1.0000, -0.5760,  ..., -0.8045,  0.6775, -0.7873],\n",
            "        ...,\n",
            "        [ 0.2655,  1.0000,  0.1960,  ..., -0.7011,  0.5341, -0.8334],\n",
            "        [-0.2737,  0.9997, -0.8435,  ..., -0.8679,  0.3357, -0.3133],\n",
            "        [-0.1112,  1.0000, -0.4274,  ..., -0.8319,  0.5360, -0.8065]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0086,  0.9999,  0.7605,  ...,  0.5320, -0.2098, -0.2843],\n",
            "        [-0.2571,  1.0000, -0.5810,  ..., -0.9431,  0.8162, -0.7307],\n",
            "        [ 0.7304,  1.0000,  0.9400,  ...,  0.9106, -0.2383, -0.6762],\n",
            "        ...,\n",
            "        [ 0.4754,  1.0000,  0.9280,  ...,  0.6918, -0.3001, -0.6140],\n",
            "        [-0.3742,  1.0000, -0.5108,  ..., -0.8404,  0.5119, -0.6757],\n",
            "        [ 0.7125,  1.0000,  0.8778,  ...,  0.8035, -0.1558, -0.7329]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6805,  1.0000,  0.8318,  ...,  0.8806, -0.0520, -0.6398],\n",
            "        [ 0.6721,  1.0000,  0.8746,  ...,  0.8742, -0.4777, -0.5283],\n",
            "        [ 0.6562,  1.0000,  0.9240,  ...,  0.8054, -0.3211, -0.7397],\n",
            "        ...,\n",
            "        [ 0.5196,  1.0000,  0.9341,  ...,  0.8499, -0.2109, -0.5266],\n",
            "        [ 0.6568,  1.0000,  0.9183,  ...,  0.8022, -0.3491, -0.5488],\n",
            "        [-0.4152,  1.0000, -0.8029,  ..., -0.8651,  0.5817, -0.3829]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3738,  1.0000, -0.0862,  ..., -0.4835,  0.2094, -0.7608],\n",
            "        [ 0.7093,  1.0000,  0.9090,  ...,  0.8841, -0.4837, -0.5392],\n",
            "        [-0.2484,  1.0000, -0.7539,  ..., -0.9284,  0.6327, -0.3557],\n",
            "        ...,\n",
            "        [-0.4506,  0.9999, -0.7645,  ..., -0.9152,  0.4936, -0.2640],\n",
            "        [ 0.8088,  1.0000,  0.8598,  ...,  0.8137, -0.3282, -0.7306],\n",
            "        [ 0.3053,  1.0000,  0.8676,  ...,  0.6233, -0.0296, -0.5584]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0391,  1.0000, -0.7694,  ..., -0.8310,  0.5418, -0.5052],\n",
            "        [-0.1941,  1.0000, -0.8257,  ..., -0.9308,  0.5481, -0.4547],\n",
            "        [ 0.5264,  1.0000,  0.9418,  ...,  0.8940, -0.4083, -0.5790],\n",
            "        ...,\n",
            "        [-0.2828,  0.9998, -0.8898,  ..., -0.9078,  0.3001, -0.3477],\n",
            "        [ 0.4592,  1.0000,  0.8781,  ...,  0.6352, -0.3447, -0.5052],\n",
            "        [-0.2652,  1.0000, -0.8485,  ..., -0.9102,  0.4343, -0.4216]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0422,  1.0000,  0.7199,  ...,  0.7005,  0.1075, -0.4760],\n",
            "        [ 0.1664,  1.0000, -0.1431,  ..., -0.8371,  0.7282, -0.9000],\n",
            "        [ 0.6660,  1.0000,  0.9097,  ...,  0.8429, -0.1994, -0.7106],\n",
            "        ...,\n",
            "        [ 0.6375,  1.0000,  0.9331,  ...,  0.8165, -0.0640, -0.5183],\n",
            "        [ 0.1251,  1.0000,  0.6933,  ...,  0.6999,  0.0467, -0.5626],\n",
            "        [ 0.5806,  1.0000,  0.9168,  ...,  0.7747, -0.3130, -0.7016]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6474,  1.0000,  0.8624,  ...,  0.6351, -0.3182, -0.8248],\n",
            "        [-0.6424,  0.9995, -0.8794,  ..., -0.9201,  0.5012, -0.0041],\n",
            "        [-0.3951,  1.0000, -0.8571,  ..., -0.8801,  0.1501, -0.3337],\n",
            "        ...,\n",
            "        [ 0.0896,  1.0000, -0.5331,  ..., -0.9151,  0.5816, -0.7506],\n",
            "        [-0.0927,  0.9984, -0.8797,  ..., -0.8231,  0.4446,  0.0908],\n",
            "        [-0.2347,  1.0000, -0.7502,  ..., -0.8673,  0.7210, -0.4952]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1606,  0.9992, -0.4470,  ..., -0.8244,  0.3496, -0.5196],\n",
            "        [-0.2038,  0.9972, -0.9449,  ..., -0.8834,  0.5480, -0.0953],\n",
            "        [-0.4031,  0.9999, -0.7703,  ..., -0.8890,  0.3632, -0.2145],\n",
            "        ...,\n",
            "        [ 0.7267,  1.0000,  0.9091,  ...,  0.8382, -0.0873, -0.6129],\n",
            "        [ 0.5658,  1.0000,  0.8482,  ...,  0.7450, -0.4891, -0.7590],\n",
            "        [-0.4129,  0.9990, -0.9000,  ..., -0.9043,  0.0877,  0.1683]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7109,  1.0000,  0.9225,  ...,  0.8060, -0.3675, -0.5508],\n",
            "        [-0.6585,  0.9996, -0.7631,  ..., -0.9330,  0.4607, -0.3035],\n",
            "        [ 0.6081,  1.0000,  0.9442,  ...,  0.4034, -0.2625, -0.8448],\n",
            "        ...,\n",
            "        [-0.1824,  1.0000,  0.6655,  ..., -0.7164,  0.2910, -0.9544],\n",
            "        [-0.0735,  1.0000,  0.0256,  ..., -0.8353,  0.6753, -0.8890],\n",
            "        [ 0.4653,  1.0000,  0.8974,  ...,  0.8312, -0.4530, -0.2980]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7549,  1.0000,  0.9368,  ...,  0.8941, -0.1615, -0.6667],\n",
            "        [-0.2020,  1.0000, -0.7660,  ..., -0.8231,  0.7486, -0.8622],\n",
            "        [ 0.6570,  1.0000,  0.9012,  ...,  0.8010, -0.4860, -0.7687],\n",
            "        ...,\n",
            "        [ 0.7293,  1.0000,  0.9338,  ...,  0.7592, -0.2964, -0.5313],\n",
            "        [-0.2927,  1.0000, -0.8634,  ..., -0.8790,  0.6005, -0.3231],\n",
            "        [-0.1927,  0.9999, -0.5447,  ..., -0.8533,  0.5745, -0.5342]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6805,  1.0000,  0.8641,  ...,  0.8366, -0.2082, -0.5269],\n",
            "        [ 0.8108,  1.0000,  0.9388,  ...,  0.8368, -0.2755, -0.8103],\n",
            "        [-0.5416,  0.9996, -0.8513,  ..., -0.9263,  0.4177, -0.3518],\n",
            "        ...,\n",
            "        [-0.2037,  0.9996, -0.8864,  ..., -0.8710,  0.3288, -0.1597],\n",
            "        [-0.4299,  0.9999, -0.8127,  ..., -0.8566,  0.3271, -0.4469],\n",
            "        [ 0.5995,  1.0000,  0.8213,  ..., -0.4240,  0.4432, -0.9602]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4146,  1.0000,  0.9414,  ...,  0.7750,  0.0484, -0.5969],\n",
            "        [-0.1621,  1.0000, -0.8216,  ..., -0.8962,  0.5130, -0.4514],\n",
            "        [-0.3553,  0.9966, -0.8857,  ..., -0.9188,  0.4402, -0.0317],\n",
            "        ...,\n",
            "        [ 0.4112,  1.0000,  0.7547,  ...,  0.7097, -0.5205, -0.7642],\n",
            "        [ 0.7851,  1.0000,  0.8993,  ...,  0.8372, -0.1432, -0.6362],\n",
            "        [ 0.5852,  1.0000,  0.9296,  ...,  0.9052, -0.3066, -0.7854]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7540,  1.0000,  0.9026,  ...,  0.8280, -0.3861, -0.6783],\n",
            "        [ 0.7010,  1.0000,  0.8477,  ...,  0.7883,  0.0547, -0.7941],\n",
            "        [-0.3546,  0.9530, -0.8731,  ..., -0.9429,  0.5128, -0.2386],\n",
            "        ...,\n",
            "        [-0.2802,  1.0000, -0.8348,  ..., -0.9145,  0.6185, -0.1333],\n",
            "        [ 0.7303,  1.0000,  0.8097,  ...,  0.8050, -0.0409, -0.7375],\n",
            "        [ 0.5735,  1.0000,  0.9057,  ...,  0.8110, -0.0240, -0.6761]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3104,  1.0000, -0.7837,  ..., -0.8936,  0.7318, -0.8127],\n",
            "        [ 0.8407,  1.0000,  0.8186,  ...,  0.1179, -0.0332, -0.9472],\n",
            "        [-0.6680,  0.9996, -0.8138,  ..., -0.9174,  0.3506, -0.0999],\n",
            "        ...,\n",
            "        [ 0.1099,  1.0000,  0.6969,  ...,  0.5828,  0.2870, -0.7409],\n",
            "        [ 0.0038,  1.0000,  0.8045,  ..., -0.2605, -0.1553, -0.9118],\n",
            "        [ 0.7311,  1.0000,  0.8432,  ...,  0.7755, -0.5021, -0.4601]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6935,  1.0000,  0.9598,  ...,  0.3689, -0.1832, -0.8567],\n",
            "        [ 0.6028,  1.0000,  0.8667,  ...,  0.6758, -0.0200, -0.8344],\n",
            "        [-0.2561,  1.0000, -0.6391,  ..., -0.9036,  0.7418, -0.4156],\n",
            "        ...,\n",
            "        [ 0.6958,  1.0000,  0.9290,  ...,  0.8695, -0.1026, -0.6477],\n",
            "        [ 0.2328,  0.9982,  0.3045,  ...,  0.6140,  0.0456, -0.4426],\n",
            "        [-0.2404,  1.0000, -0.7260,  ..., -0.9550,  0.5424, -0.6722]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7213,  1.0000,  0.9333,  ...,  0.8368, -0.3387, -0.6029],\n",
            "        [-0.0454,  1.0000,  0.4653,  ...,  0.4166, -0.2224, -0.4599],\n",
            "        [-0.5609,  1.0000, -0.6305,  ..., -0.8451,  0.5786, -0.8054],\n",
            "        ...,\n",
            "        [-0.5603,  0.9999, -0.8329,  ..., -0.8654,  0.5440, -0.1868],\n",
            "        [ 0.7684,  1.0000,  0.8282,  ...,  0.1949, -0.2108, -0.7388],\n",
            "        [-0.5111,  0.9999, -0.9255,  ..., -0.8106,  0.4631, -0.1170]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7675,  1.0000,  0.9296,  ...,  0.8767, -0.0450, -0.7445],\n",
            "        [ 0.7810,  1.0000,  0.8738,  ...,  0.8373, -0.3702, -0.5983],\n",
            "        [ 0.3438,  1.0000,  0.9135,  ...,  0.4031,  0.2830, -0.9692],\n",
            "        ...,\n",
            "        [-0.3141,  0.9997, -0.6828,  ..., -0.8020,  0.7781, -0.5284],\n",
            "        [-0.1917,  0.9999, -0.7330,  ..., -0.9315,  0.7423, -0.3641],\n",
            "        [ 0.7850,  1.0000,  0.8962,  ...,  0.8490, -0.2199, -0.6293]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3131,  1.0000, -0.7052,  ..., -0.8022,  0.6041, -0.7286],\n",
            "        [-0.1876,  0.9999, -0.9131,  ..., -0.9243,  0.2835,  0.0056],\n",
            "        [ 0.2803,  1.0000, -0.0224,  ..., -0.7453,  0.7384, -0.8688],\n",
            "        ...,\n",
            "        [-0.4384,  0.9980, -0.9046,  ..., -0.9290,  0.4375, -0.1900],\n",
            "        [ 0.5164,  1.0000,  0.9063,  ...,  0.7838, -0.5095, -0.7380],\n",
            "        [-0.0956,  0.9999, -0.8473,  ..., -0.8667,  0.3460,  0.1954]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7577,  1.0000,  0.9231,  ...,  0.7396, -0.3224, -0.7034],\n",
            "        [ 0.5942,  1.0000,  0.8821,  ...,  0.7900, -0.3935, -0.7110],\n",
            "        [-0.1639,  1.0000, -0.6604,  ..., -0.8381,  0.7487, -0.4503],\n",
            "        ...,\n",
            "        [ 0.5627,  1.0000,  0.8906,  ...,  0.8349, -0.4835, -0.5953],\n",
            "        [ 0.7627,  1.0000,  0.8662,  ...,  0.8563, -0.1827, -0.5619],\n",
            "        [ 0.6193,  1.0000,  0.8646,  ...,  0.8210, -0.3529, -0.5928]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7171,  1.0000,  0.9208,  ...,  0.8877, -0.4279, -0.5774],\n",
            "        [ 0.1313,  1.0000, -0.4383,  ..., -0.7717,  0.6190, -0.9560],\n",
            "        [ 0.6764,  1.0000,  0.8247,  ...,  0.7823, -0.1840, -0.6803],\n",
            "        ...,\n",
            "        [ 0.7010,  1.0000,  0.9067,  ...,  0.8459,  0.0116, -0.6985],\n",
            "        [ 0.5592,  1.0000,  0.2692,  ..., -0.8508,  0.6671, -0.9142],\n",
            "        [-0.3552,  1.0000, -0.5901,  ..., -0.9367,  0.6585, -0.2417]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2711,  0.9998, -0.8599,  ..., -0.9095,  0.1777,  0.2398],\n",
            "        [ 0.7549,  1.0000,  0.8655,  ...,  0.3858, -0.0636, -0.8380],\n",
            "        [ 0.6593,  1.0000,  0.8785,  ...,  0.7837, -0.5491, -0.7670],\n",
            "        ...,\n",
            "        [ 0.5706,  1.0000,  0.9329,  ...,  0.8728, -0.3573, -0.5478],\n",
            "        [ 0.1199,  1.0000,  0.6287,  ...,  0.6339,  0.3627, -0.2692],\n",
            "        [ 0.7071,  1.0000,  0.9567,  ...,  0.8204, -0.3009, -0.5364]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3206,  0.9942, -0.6171,  ..., -0.8163,  0.4098,  0.0216],\n",
            "        [-0.2264,  0.9995, -0.8682,  ..., -0.9199,  0.4276,  0.1685],\n",
            "        [-0.3192,  0.9924, -0.9161,  ..., -0.9156,  0.2755,  0.1713],\n",
            "        ...,\n",
            "        [-0.2996,  1.0000, -0.3904,  ..., -0.8623,  0.7274, -0.2402],\n",
            "        [ 0.0343,  1.0000, -0.8351,  ..., -0.9109,  0.6516, -0.5414],\n",
            "        [-0.0505,  0.9997, -0.8923,  ..., -0.9212,  0.2327,  0.0263]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5595,  1.0000,  0.9009,  ...,  0.8526, -0.4555, -0.6224],\n",
            "        [-0.3346,  0.9994, -0.8892,  ..., -0.9302,  0.2995, -0.0274],\n",
            "        [-0.2381,  1.0000, -0.8236,  ..., -0.8944,  0.7085, -0.5644],\n",
            "        ...,\n",
            "        [-0.3289,  0.9951,  0.4230,  ..., -0.1555,  0.1330, -0.4670],\n",
            "        [-0.5359,  0.9991, -0.7659,  ..., -0.8561,  0.5256,  0.0505],\n",
            "        [ 0.0916,  1.0000,  0.6967,  ...,  0.3856, -0.2302, -0.4578]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4424,  1.0000, -0.8116,  ..., -0.8983,  0.5040, -0.5543],\n",
            "        [ 0.6030,  1.0000,  0.7894,  ...,  0.7910, -0.3454, -0.4752],\n",
            "        [ 0.8211,  1.0000,  0.8741,  ...,  0.8324, -0.2251, -0.6261],\n",
            "        ...,\n",
            "        [-0.3971,  0.9998, -0.7391,  ..., -0.9331,  0.5884,  0.1279],\n",
            "        [-0.3986,  0.9995, -0.8516,  ..., -0.9006,  0.4132, -0.0519],\n",
            "        [-0.2272,  0.9993, -0.7809,  ..., -0.7722,  0.5935, -0.3612]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6643,  1.0000,  0.9484,  ...,  0.9117, -0.4171, -0.5520],\n",
            "        [ 0.4678,  1.0000,  0.8965,  ...,  0.6430, -0.2685, -0.5253],\n",
            "        [ 0.6875,  1.0000,  0.9207,  ...,  0.8274, -0.1136, -0.7139],\n",
            "        ...,\n",
            "        [-0.3340,  1.0000, -0.6852,  ..., -0.8753,  0.6678, -0.5003],\n",
            "        [ 0.6263,  1.0000,  0.9054,  ...,  0.8057, -0.3144, -0.5516],\n",
            "        [ 0.7157,  1.0000,  0.8930,  ...,  0.8707, -0.4339, -0.5525]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0777,  0.9998, -0.8836,  ..., -0.8897,  0.6576, -0.6770],\n",
            "        [ 0.4379,  1.0000,  0.8772,  ...,  0.4569, -0.4803, -0.6747],\n",
            "        [-0.5137,  0.9998, -0.8498,  ..., -0.9491,  0.6561, -0.2309],\n",
            "        ...,\n",
            "        [ 0.6048,  1.0000,  0.7996,  ...,  0.6310, -0.6115, -0.5622],\n",
            "        [ 0.1417,  1.0000, -0.4778,  ..., -0.8837,  0.5147, -0.9202],\n",
            "        [-0.0801,  0.9985, -0.8200,  ..., -0.9015,  0.1230,  0.0967]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4816,  1.0000,  0.9036,  ...,  0.7982, -0.3422, -0.4529],\n",
            "        [ 0.6712,  1.0000,  0.8169,  ...,  0.2243, -0.0234, -0.8716],\n",
            "        [-0.5251,  0.9994, -0.8725,  ..., -0.8850,  0.2063, -0.2328],\n",
            "        ...,\n",
            "        [-0.4027,  0.9725, -0.8347,  ..., -0.8887,  0.4848,  0.0145],\n",
            "        [ 0.5583,  1.0000,  0.9133,  ...,  0.8797, -0.5259, -0.6319],\n",
            "        [-0.5917,  0.9996, -0.9155,  ..., -0.8631,  0.0911,  0.0441]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1762,  0.9994, -0.7273,  ..., -0.9526,  0.4661, -0.2275],\n",
            "        [-0.4851,  0.9982, -0.9070,  ..., -0.9519,  0.3838, -0.0753],\n",
            "        [-0.2904,  1.0000, -0.8065,  ..., -0.8926,  0.5556, -0.1759],\n",
            "        ...,\n",
            "        [ 0.2518,  1.0000,  0.8180,  ...,  0.6540,  0.1516, -0.6841],\n",
            "        [ 0.6886,  1.0000,  0.9147,  ...,  0.6909, -0.4432, -0.5046],\n",
            "        [ 0.6217,  1.0000,  0.9074,  ...,  0.8850, -0.2305, -0.7380]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5456,  0.9998, -0.9212,  ..., -0.9452,  0.2815,  0.0913],\n",
            "        [-0.3647,  0.9999, -0.8420,  ..., -0.8967,  0.2741, -0.2944],\n",
            "        [ 0.2311,  1.0000,  0.5381,  ...,  0.5478,  0.3749, -0.6075],\n",
            "        ...,\n",
            "        [ 0.2638,  1.0000,  0.8294,  ...,  0.4909, -0.3973, -0.3963],\n",
            "        [-0.2330,  0.9983, -0.8219,  ..., -0.8764,  0.5472, -0.4792],\n",
            "        [ 0.6991,  1.0000,  0.8387,  ...,  0.5885, -0.0537, -0.7173]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6284,  1.0000,  0.9138,  ...,  0.8267, -0.3772, -0.5990],\n",
            "        [ 0.7196,  1.0000,  0.8794,  ...,  0.5654, -0.5073, -0.6219],\n",
            "        [ 0.5984,  1.0000,  0.9337,  ...,  0.7565, -0.4093, -0.6076],\n",
            "        ...,\n",
            "        [-0.3408,  0.9998, -0.7241,  ..., -0.8878,  0.2774, -0.4467],\n",
            "        [ 0.6092,  1.0000,  0.9527,  ...,  0.8133, -0.3838, -0.7002],\n",
            "        [-0.4095,  0.9992, -0.8359,  ..., -0.8908,  0.1281,  0.1312]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7229,  1.0000,  0.8874,  ...,  0.8222, -0.5419, -0.4951],\n",
            "        [ 0.3956,  1.0000,  0.8394,  ...,  0.5419, -0.4166, -0.7423],\n",
            "        [ 0.6424,  1.0000,  0.9262,  ...,  0.7412, -0.4230, -0.5898],\n",
            "        ...,\n",
            "        [ 0.4429,  0.9999,  0.8878,  ...,  0.7871, -0.3531, -0.2482],\n",
            "        [-0.0290,  0.9998,  0.2790,  ..., -0.4054,  0.1481, -0.8295],\n",
            "        [-0.0310,  1.0000,  0.4099,  ...,  0.4594,  0.2580, -0.5976]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4852,  0.9996, -0.7077,  ..., -0.8573,  0.6351, -0.2458],\n",
            "        [-0.1177,  0.9997, -0.8878,  ..., -0.9238,  0.3511, -0.3300],\n",
            "        [-0.2940,  0.9951, -0.8572,  ..., -0.8360,  0.3504,  0.0569],\n",
            "        ...,\n",
            "        [ 0.6679,  1.0000,  0.8962,  ...,  0.7907, -0.3531, -0.5811],\n",
            "        [ 0.4887,  1.0000,  0.9040,  ...,  0.6266, -0.3736, -0.7684],\n",
            "        [ 0.7174,  1.0000,  0.9049,  ...,  0.8068, -0.2593, -0.5281]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2423,  0.9968, -0.7836,  ..., -0.7173,  0.0589,  0.3540],\n",
            "        [ 0.7597,  1.0000,  0.9065,  ...,  0.8720, -0.2722, -0.5968],\n",
            "        [-0.5179,  0.9994, -0.8182,  ..., -0.9106,  0.3922, -0.1576],\n",
            "        ...,\n",
            "        [ 0.3169,  0.9999,  0.8551,  ...,  0.1196, -0.1973, -0.8055],\n",
            "        [ 0.6822,  1.0000,  0.9224,  ..., -0.1563,  0.3681, -0.9468],\n",
            "        [ 0.4881,  0.9999,  0.8272,  ...,  0.6766, -0.5623, -0.4026]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2085,  1.0000,  0.8684,  ...,  0.1439, -0.3473, -0.8424],\n",
            "        [ 0.6569,  1.0000,  0.8447,  ...,  0.6869, -0.4841, -0.5699],\n",
            "        [ 0.6338,  1.0000,  0.8520,  ..., -0.1230, -0.0034, -0.7268],\n",
            "        ...,\n",
            "        [-0.1185,  0.9992, -0.8718,  ..., -0.9407,  0.4285, -0.2044],\n",
            "        [ 0.5912,  1.0000,  0.8036,  ...,  0.4277, -0.2408, -0.7450],\n",
            "        [ 0.7136,  1.0000,  0.8964,  ...,  0.7921, -0.5504, -0.5834]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4119,  0.9980, -0.9375,  ..., -0.9090,  0.3179,  0.0850],\n",
            "        [-0.2456,  0.9983, -0.8884,  ..., -0.8564,  0.2408, -0.1335],\n",
            "        [-0.2226,  1.0000, -0.6278,  ..., -0.8670,  0.7203, -0.7903],\n",
            "        ...,\n",
            "        [-0.4413,  0.8865, -0.8836,  ..., -0.9027,  0.2763, -0.2210],\n",
            "        [ 0.4568,  1.0000,  0.7772,  ...,  0.6971, -0.6973, -0.6306],\n",
            "        [-0.4265,  0.9461, -0.8463,  ..., -0.9027,  0.4155,  0.2281]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6853,  1.0000,  0.8685,  ...,  0.4919, -0.1343, -0.8756],\n",
            "        [ 0.5722,  1.0000,  0.9125,  ...,  0.8972, -0.3332, -0.6277],\n",
            "        [-0.2008,  0.9980, -0.9213,  ..., -0.8766,  0.1856, -0.0016],\n",
            "        ...,\n",
            "        [ 0.6361,  0.9999,  0.8984,  ...,  0.8172, -0.6251, -0.4774],\n",
            "        [-0.2955,  0.9999, -0.7901,  ..., -0.8573,  0.1402, -0.2743],\n",
            "        [ 0.4506,  0.9999,  0.8838,  ...,  0.7094, -0.6107, -0.3659]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0981,  1.0000, -0.3477,  ..., -0.8549,  0.6305, -0.8718],\n",
            "        [ 0.2903,  1.0000,  0.8899,  ...,  0.2751, -0.5172, -0.6270],\n",
            "        [-0.4406,  0.9926, -0.9336,  ..., -0.8784,  0.4566,  0.0022],\n",
            "        ...,\n",
            "        [ 0.5567,  1.0000,  0.9223,  ...,  0.8750, -0.4565, -0.4162],\n",
            "        [-0.3150,  0.9985, -0.7672,  ..., -0.8470,  0.2576,  0.1795],\n",
            "        [ 0.6088,  1.0000,  0.9107,  ...,  0.7324, -0.3928, -0.7660]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7371,  1.0000,  0.8016,  ...,  0.3694, -0.3629, -0.7731],\n",
            "        [ 0.4830,  1.0000,  0.9475,  ...,  0.6436, -0.5217, -0.6275],\n",
            "        [-0.4151,  0.9946, -0.8313,  ..., -0.9247,  0.3173,  0.3490],\n",
            "        ...,\n",
            "        [ 0.1265,  1.0000,  0.7904,  ...,  0.2780,  0.2888, -0.6840],\n",
            "        [ 0.5578,  1.0000,  0.8726,  ...,  0.8176, -0.5111, -0.7196],\n",
            "        [-0.6571,  0.9961, -0.8599,  ..., -0.9058,  0.3365,  0.2552]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5337,  0.9998, -0.8781,  ..., -0.9439,  0.1963,  0.0595],\n",
            "        [ 0.7586,  1.0000,  0.8429,  ...,  0.7968, -0.5000, -0.6474],\n",
            "        [ 0.1473,  0.9992,  0.7352,  ..., -0.4893,  0.2015, -0.6747],\n",
            "        ...,\n",
            "        [-0.0122,  0.9999,  0.5845,  ..., -0.3751,  0.1306, -0.9421],\n",
            "        [ 0.3871,  1.0000,  0.4708,  ..., -0.4682,  0.4207, -0.9058],\n",
            "        [-0.4144,  0.9989, -0.8059,  ..., -0.9210, -0.0657, -0.1060]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4802, -0.7643, -0.9262,  ..., -0.9134,  0.5470,  0.2145],\n",
            "        [-0.4889,  0.8811, -0.9610,  ..., -0.9262,  0.4285,  0.1289],\n",
            "        [-0.5769,  0.9995, -0.8565,  ..., -0.9211,  0.2942,  0.1067],\n",
            "        ...,\n",
            "        [-0.4748,  0.9998, -0.8431,  ..., -0.9083,  0.5596, -0.1395],\n",
            "        [-0.2907,  0.9924, -0.7686,  ..., -0.9235,  0.1666, -0.0962],\n",
            "        [-0.3108,  0.9737, -0.9019,  ..., -0.8991,  0.3054,  0.0342]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3716,  0.9964, -0.7649,  ..., -0.8959,  0.5508, -0.5824],\n",
            "        [-0.2493,  1.0000, -0.2547,  ..., -0.9149,  0.3602, -0.8797],\n",
            "        [-0.4553,  0.9966, -0.8726,  ..., -0.9124,  0.1146,  0.0811],\n",
            "        ...,\n",
            "        [ 0.7578,  1.0000,  0.9282,  ...,  0.8085,  0.3850, -0.9410],\n",
            "        [-0.3688,  0.9936, -0.8758,  ..., -0.9291,  0.2807,  0.0521],\n",
            "        [ 0.7773,  1.0000,  0.9431,  ...,  0.6788, -0.0276, -0.9463]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0362,  0.9998, -0.8652,  ..., -0.9150,  0.4652, -0.4101],\n",
            "        [ 0.6784,  1.0000,  0.8819,  ...,  0.6973, -0.4558, -0.5038],\n",
            "        [-0.1054,  0.9789, -0.8477,  ..., -0.8433,  0.4352, -0.2263],\n",
            "        ...,\n",
            "        [-0.4298,  1.0000, -0.7819,  ..., -0.9275,  0.6916, -0.5934],\n",
            "        [ 0.7061,  1.0000,  0.9150,  ...,  0.8402, -0.3718, -0.6049],\n",
            "        [-0.4496,  0.9969, -0.8682,  ..., -0.8713,  0.4931, -0.4118]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4023,  0.9999, -0.5140,  ..., -0.8649,  0.0513, -0.1172],\n",
            "        [ 0.7279,  1.0000,  0.9114,  ...,  0.6914, -0.3858, -0.7234],\n",
            "        [ 0.6677,  1.0000,  0.8947,  ...,  0.7385, -0.3569, -0.5775],\n",
            "        ...,\n",
            "        [-0.3231,  1.0000, -0.7571,  ..., -0.9557,  0.4160, -0.1895],\n",
            "        [-0.4327,  0.9984, -0.9076,  ..., -0.8939,  0.0129, -0.1656],\n",
            "        [ 0.7641,  1.0000,  0.8167,  ...,  0.7459, -0.4668, -0.7263]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0356,  1.0000, -0.8399,  ..., -0.9028,  0.3561, -0.5231],\n",
            "        [-0.3646,  0.9560, -0.9156,  ..., -0.9348,  0.4287, -0.1148],\n",
            "        [ 0.3475,  1.0000, -0.1575,  ..., -0.7417,  0.5366, -0.8865],\n",
            "        ...,\n",
            "        [-0.2484,  1.0000, -0.5212,  ..., -0.8428,  0.5917, -0.9007],\n",
            "        [ 0.3420,  1.0000,  0.8581,  ...,  0.0268, -0.0528, -0.8953],\n",
            "        [ 0.6915,  1.0000,  0.9200,  ...,  0.6708, -0.3920, -0.6913]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6568,  1.0000,  0.9266,  ...,  0.5868, -0.2240, -0.5837],\n",
            "        [ 0.6122,  1.0000, -0.3941,  ..., -0.6666,  0.5828, -0.6221],\n",
            "        [-0.3643,  0.9999, -0.7485,  ..., -0.8822,  0.3665, -0.2844],\n",
            "        ...,\n",
            "        [-0.2539,  0.9994, -0.8849,  ..., -0.9162,  0.3231, -0.0639],\n",
            "        [-0.1742,  0.9999, -0.7207,  ..., -0.8179,  0.6281, -0.4975],\n",
            "        [ 0.7202,  1.0000,  0.9198,  ...,  0.4978, -0.4142, -0.8059]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5144,  1.0000,  0.8707,  ...,  0.5539, -0.5458, -0.4687],\n",
            "        [ 0.3278,  1.0000,  0.8517,  ...,  0.1188, -0.1597, -0.8932],\n",
            "        [ 0.7233,  1.0000,  0.9234,  ...,  0.8326, -0.3906, -0.6256],\n",
            "        ...,\n",
            "        [ 0.7134,  0.9999,  0.9321,  ...,  0.8195, -0.1030, -0.7631],\n",
            "        [ 0.5422,  1.0000,  0.8859,  ...,  0.7030, -0.7021, -0.6357],\n",
            "        [-0.3883,  1.0000,  0.5452,  ..., -0.7537,  0.6793, -0.6706]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3327,  1.0000, -0.6329,  ..., -0.8208,  0.6200, -0.6809],\n",
            "        [ 0.4356,  1.0000,  0.9167,  ...,  0.6799, -0.1656, -0.6830],\n",
            "        [ 0.5175,  1.0000,  0.0939,  ..., -0.8793,  0.6752, -0.9526],\n",
            "        ...,\n",
            "        [ 0.3178,  1.0000,  0.8876,  ...,  0.4767,  0.3495, -0.7497],\n",
            "        [ 0.7904,  1.0000,  0.9301,  ...,  0.7636, -0.2021, -0.4632],\n",
            "        [-0.0387,  1.0000, -0.1203,  ..., -0.8290,  0.3645, -0.7781]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0560,  1.0000, -0.4899,  ..., -0.9150,  0.5645, -0.9260],\n",
            "        [ 0.3485,  1.0000,  0.8965,  ...,  0.5860, -0.5577, -0.5868],\n",
            "        [-0.2191,  0.9993, -0.8879,  ..., -0.9228,  0.3215, -0.0614],\n",
            "        ...,\n",
            "        [ 0.1779,  1.0000, -0.7015,  ..., -0.8878,  0.2146, -0.4592],\n",
            "        [ 0.4698,  0.9997,  0.9164,  ...,  0.7093, -0.4945, -0.4491],\n",
            "        [ 0.6988,  1.0000,  0.9425,  ...,  0.3427, -0.3896, -0.8424]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1374,  1.0000, -0.6131,  ..., -0.8948,  0.5605, -0.5621],\n",
            "        [ 0.5408,  1.0000,  0.0358,  ..., -0.6808,  0.5555, -0.8575],\n",
            "        [ 0.6850,  1.0000,  0.9311,  ...,  0.1834, -0.1235, -0.9373],\n",
            "        ...,\n",
            "        [ 0.3295,  1.0000,  0.8290,  ..., -0.5154,  0.6896, -0.9581],\n",
            "        [-0.3827,  1.0000, -0.8496,  ..., -0.9669,  0.2885, -0.5750],\n",
            "        [ 0.1304,  1.0000, -0.6239,  ..., -0.8109,  0.5325, -0.4968]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1789,  0.9997, -0.9226,  ..., -0.9398,  0.4872, -0.4588],\n",
            "        [ 0.6591,  1.0000,  0.9228,  ...,  0.6421, -0.3632, -0.6524],\n",
            "        [ 0.4531,  1.0000, -0.1535,  ..., -0.8845,  0.4895, -0.9171],\n",
            "        ...,\n",
            "        [ 0.4240,  1.0000,  0.8699,  ...,  0.6067, -0.4651, -0.7874],\n",
            "        [-0.2984,  0.9995, -0.7385,  ..., -0.9112,  0.4254, -0.3757],\n",
            "        [ 0.6393,  1.0000,  0.9277,  ...,  0.8010, -0.5652, -0.5354]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6923,  1.0000,  0.9479,  ...,  0.7998, -0.4011, -0.7934],\n",
            "        [ 0.4212,  1.0000,  0.9054,  ...,  0.6843, -0.3605, -0.5790],\n",
            "        [-0.3107,  1.0000, -0.8473,  ..., -0.8647,  0.3460,  0.0143],\n",
            "        ...,\n",
            "        [-0.6360,  0.9973, -0.7928,  ..., -0.9097,  0.2286, -0.4198],\n",
            "        [-0.4027,  0.9999, -0.7727,  ..., -0.9138,  0.3487,  0.0209],\n",
            "        [-0.0570,  0.9999, -0.8296,  ..., -0.8985,  0.3640, -0.5748]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5141,  0.9990, -0.8746,  ..., -0.8708,  0.2290, -0.0874],\n",
            "        [ 0.7677,  1.0000,  0.8913,  ...,  0.6756, -0.4221, -0.4228],\n",
            "        [ 0.5917,  1.0000,  0.8700,  ...,  0.7663, -0.3774, -0.5949],\n",
            "        ...,\n",
            "        [ 0.5408,  1.0000,  0.8770,  ...,  0.7526, -0.3049, -0.7270],\n",
            "        [ 0.6806,  1.0000,  0.8918,  ...,  0.4626, -0.1664, -0.8110],\n",
            "        [-0.2189,  0.9998, -0.8159,  ..., -0.8846,  0.3476, -0.0069]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7048,  1.0000,  0.9198,  ...,  0.6643, -0.4537, -0.7204],\n",
            "        [ 0.3877,  1.0000,  0.8767,  ...,  0.5691, -0.2702, -0.5065],\n",
            "        [ 0.5073,  1.0000,  0.8958,  ...,  0.6251, -0.1828, -0.5234],\n",
            "        ...,\n",
            "        [ 0.6738,  1.0000,  0.9458,  ...,  0.6845, -0.2885, -0.7758],\n",
            "        [ 0.4622,  1.0000, -0.6734,  ..., -0.8554,  0.4742, -0.6735],\n",
            "        [ 0.6148,  1.0000,  0.8962,  ...,  0.7941, -0.5055, -0.6887]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5523,  1.0000,  0.7830,  ...,  0.0684, -0.2034, -0.9278],\n",
            "        [ 0.5815,  1.0000,  0.9059,  ...,  0.6010, -0.5316, -0.8247],\n",
            "        [ 0.3604,  1.0000,  0.7701,  ...,  0.4943,  0.4580, -0.7909],\n",
            "        ...,\n",
            "        [ 0.3070,  1.0000, -0.4046,  ..., -0.9157,  0.5978, -0.6744],\n",
            "        [-0.2304,  0.9999, -0.9352,  ..., -0.9064,  0.4341, -0.0921],\n",
            "        [-0.1406,  1.0000, -0.2751,  ..., -0.8719,  0.3885, -0.8317]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2230,  0.9993, -0.4228,  ..., -0.8856,  0.3961, -0.3542],\n",
            "        [ 0.2133,  0.9999, -0.8273,  ..., -0.9137,  0.3312, -0.4772],\n",
            "        [ 0.7424,  1.0000,  0.8678,  ...,  0.4275, -0.1684, -0.8918],\n",
            "        ...,\n",
            "        [ 0.1462,  0.9997, -0.6150,  ..., -0.7785,  0.3448, -0.3781],\n",
            "        [-0.2632,  1.0000, -0.5660,  ..., -0.9347,  0.5626, -0.2836],\n",
            "        [ 0.6176,  1.0000,  0.9137,  ...,  0.7563, -0.3651, -0.7292]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4339,  1.0000, -0.5789,  ..., -0.8744,  0.6725, -0.7321],\n",
            "        [ 0.2763,  1.0000, -0.7175,  ..., -0.9103,  0.3092, -0.8708],\n",
            "        [ 0.6455,  1.0000,  0.8945,  ...,  0.4771, -0.3544, -0.7141],\n",
            "        ...,\n",
            "        [-0.1104,  0.9998, -0.6894,  ..., -0.9206,  0.5743, -0.2188],\n",
            "        [ 0.6513,  1.0000,  0.9030,  ...,  0.7155, -0.4097, -0.6274],\n",
            "        [-0.1345,  1.0000,  0.2614,  ..., -0.6466,  0.5385, -0.9491]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1322,  0.9999, -0.6597,  ..., -0.8629,  0.3716, -0.3998],\n",
            "        [-0.2366,  1.0000, -0.0606,  ..., -0.8783,  0.7448, -0.9117],\n",
            "        [ 0.2064,  1.0000, -0.2387,  ..., -0.8889,  0.6608, -0.9523],\n",
            "        ...,\n",
            "        [ 0.6138,  1.0000,  0.8776,  ...,  0.6545, -0.4352, -0.7042],\n",
            "        [ 0.4338,  1.0000, -0.6626,  ..., -0.7771,  0.6614, -0.8158],\n",
            "        [ 0.6206,  1.0000,  0.6981,  ..., -0.5306,  0.4229, -0.9650]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2804,  0.9936,  0.3466,  ..., -0.5774,  0.4714, -0.4969],\n",
            "        [ 0.6860,  1.0000,  0.8962,  ...,  0.7220, -0.1302, -0.5942],\n",
            "        [ 0.4936,  1.0000,  0.9317,  ...,  0.5722, -0.3785, -0.7558],\n",
            "        ...,\n",
            "        [-0.2033,  1.0000, -0.6043,  ..., -0.8621,  0.4454, -0.7835],\n",
            "        [ 0.5389,  1.0000,  0.9132,  ...,  0.6930, -0.3205, -0.6306],\n",
            "        [ 0.2045,  1.0000, -0.5818,  ..., -0.8448,  0.5754, -0.7187]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2330,  1.0000,  0.2599,  ..., -0.8803,  0.8568, -0.8394],\n",
            "        [ 0.7593,  1.0000,  0.8507,  ...,  0.7078, -0.4162, -0.7660],\n",
            "        [ 0.4336,  1.0000,  0.9024,  ...,  0.6958, -0.3308, -0.6481],\n",
            "        ...,\n",
            "        [ 0.6645,  1.0000,  0.8572,  ..., -0.4845,  0.0202, -0.9496],\n",
            "        [-0.1172,  0.9998, -0.8636,  ..., -0.8885,  0.1448, -0.1225],\n",
            "        [-0.0305,  1.0000, -0.7396,  ..., -0.8757, -0.0854, -0.3839]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7823,  1.0000,  0.8379,  ...,  0.4488,  0.0361, -0.8651],\n",
            "        [ 0.6099,  1.0000,  0.9506,  ...,  0.7898, -0.5282, -0.5019],\n",
            "        [ 0.4755,  0.9999,  0.9254,  ...,  0.6574, -0.4210, -0.6075],\n",
            "        ...,\n",
            "        [ 0.5009,  1.0000,  0.9032,  ...,  0.7401, -0.6520, -0.7293],\n",
            "        [ 0.4104,  1.0000,  0.7970,  ...,  0.7393, -0.3021, -0.6521],\n",
            "        [ 0.5882,  1.0000,  0.7506,  ...,  0.4480, -0.2105, -0.7626]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0396,  0.9995, -0.8329,  ..., -0.9066,  0.3200, -0.5460],\n",
            "        [ 0.7254,  1.0000,  0.8256,  ...,  0.6925, -0.2316, -0.7806],\n",
            "        [ 0.8400,  1.0000,  0.9241,  ...,  0.7176, -0.3159, -0.7772],\n",
            "        ...,\n",
            "        [ 0.6574,  1.0000,  0.8511,  ...,  0.6133, -0.3101, -0.6109],\n",
            "        [ 0.4658,  1.0000,  0.9065,  ...,  0.3305,  0.4463, -0.8124],\n",
            "        [ 0.7030,  1.0000,  0.9201,  ...,  0.6618, -0.4645, -0.7731]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6344,  1.0000,  0.9223,  ...,  0.2630,  0.1465, -0.9799],\n",
            "        [ 0.5744,  0.9999,  0.9116,  ...,  0.7230, -0.4812, -0.5903],\n",
            "        [-0.0439,  1.0000, -0.7684,  ..., -0.9530,  0.6219, -0.4975],\n",
            "        ...,\n",
            "        [ 0.0958,  1.0000, -0.8090,  ..., -0.9032,  0.5306, -0.5391],\n",
            "        [ 0.0476,  0.9997, -0.6624,  ..., -0.8947,  0.4829, -0.5587],\n",
            "        [-0.2484,  0.9984, -0.9022,  ..., -0.8901,  0.2486, -0.0084]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0474,  1.0000, -0.4207,  ..., -0.8503,  0.7837, -0.8981],\n",
            "        [ 0.4371,  1.0000,  0.1686,  ..., -0.4194,  0.4830, -0.8124],\n",
            "        [ 0.5703,  0.9999,  0.8883,  ...,  0.7609, -0.5389, -0.5307],\n",
            "        ...,\n",
            "        [-0.0243,  0.9992, -0.8842,  ..., -0.9271,  0.5943, -0.1665],\n",
            "        [-0.5248,  0.9997, -0.7732,  ..., -0.8394,  0.5938,  0.0740],\n",
            "        [-0.5428,  0.9999, -0.8973,  ..., -0.9164,  0.3701, -0.2573]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.8158,  1.0000,  0.8777,  ...,  0.7858, -0.3027, -0.7645],\n",
            "        [ 0.7258,  1.0000, -0.0071,  ..., -0.6397,  0.5542, -0.9513],\n",
            "        [-0.1652,  1.0000, -0.8266,  ..., -0.9303,  0.5563, -0.4129],\n",
            "        ...,\n",
            "        [ 0.4919,  1.0000,  0.8238,  ...,  0.7724, -0.6573, -0.6731],\n",
            "        [-0.4037,  1.0000,  0.2421,  ..., -0.2512,  0.5878, -0.8613],\n",
            "        [-0.2196,  1.0000, -0.4576,  ..., -0.7510,  0.3765, -0.5048]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3074,  1.0000, -0.8405,  ..., -0.8806,  0.0104, -0.0132],\n",
            "        [ 0.3666,  1.0000,  0.8998,  ...,  0.5542, -0.4078, -0.4438],\n",
            "        [ 0.5847,  1.0000,  0.8922,  ...,  0.7735, -0.4653, -0.7994],\n",
            "        ...,\n",
            "        [ 0.5862,  1.0000,  0.9082,  ...,  0.4309, -0.6514, -0.7919],\n",
            "        [ 0.3224,  1.0000,  0.8755,  ..., -0.6051,  0.8498, -0.9351],\n",
            "        [ 0.2874,  1.0000, -0.3019,  ..., -0.8084,  0.7409, -0.8958]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2686,  1.0000, -0.6208,  ..., -0.8680,  0.5921, -0.3986],\n",
            "        [ 0.4561,  1.0000,  0.9124,  ...,  0.6177, -0.2948, -0.7033],\n",
            "        [ 0.3145,  1.0000,  0.8597,  ...,  0.5471, -0.4239, -0.6408],\n",
            "        ...,\n",
            "        [ 0.3636,  1.0000,  0.7862,  ...,  0.3366, -0.2992, -0.7006],\n",
            "        [ 0.2940,  0.9999,  0.8444,  ...,  0.6375, -0.6429, -0.3894],\n",
            "        [ 0.5295,  1.0000,  0.9115,  ...,  0.0779, -0.1514, -0.9225]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1191,  1.0000, -0.4421,  ..., -0.7420,  0.3521, -0.3690],\n",
            "        [-0.5185,  1.0000, -0.2234,  ..., -0.8894,  0.6103, -0.8069],\n",
            "        [ 0.7473,  1.0000,  0.8849,  ...,  0.6544, -0.3335, -0.8425],\n",
            "        ...,\n",
            "        [ 0.1784,  1.0000, -0.2567,  ..., -0.8922,  0.6454, -0.8209],\n",
            "        [ 0.1101,  1.0000, -0.7274,  ..., -0.9036,  0.6137, -0.9253],\n",
            "        [ 0.1220,  1.0000, -0.5279,  ..., -0.9440,  0.5248, -0.8686]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0222,  1.0000, -0.5304,  ..., -0.8803,  0.3408, -0.6957],\n",
            "        [ 0.5447,  1.0000,  0.8228,  ..., -0.3815,  0.4311, -0.9414],\n",
            "        [ 0.4046,  1.0000,  0.9294,  ...,  0.4622, -0.3895, -0.5398],\n",
            "        ...,\n",
            "        [ 0.0648,  1.0000,  0.8518,  ...,  0.0442,  0.4402, -0.9609],\n",
            "        [ 0.3519,  1.0000, -0.0244,  ..., -0.9002,  0.4366, -0.9452],\n",
            "        [ 0.4116,  1.0000,  0.8063,  ...,  0.5547, -0.1834, -0.9212]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4551,  1.0000,  0.9377,  ...,  0.2215,  0.1321, -0.9061],\n",
            "        [-0.1453,  1.0000, -0.2812,  ..., -0.7205,  0.6519, -0.8297],\n",
            "        [-0.1271,  0.9996, -0.8260,  ..., -0.8348,  0.3818, -0.6029],\n",
            "        ...,\n",
            "        [-0.4304,  0.9995, -0.8790,  ..., -0.9363,  0.2637,  0.0561],\n",
            "        [ 0.3961,  1.0000,  0.8748,  ...,  0.8198, -0.5555, -0.5954],\n",
            "        [ 0.2013,  1.0000,  0.8534,  ...,  0.3091, -0.5997, -0.7422]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2913,  0.9999, -0.8918,  ..., -0.9550,  0.3770, -0.0550],\n",
            "        [-0.4418,  1.0000, -0.6273,  ..., -0.8731,  0.6788, -0.1922],\n",
            "        [-0.0242,  1.0000, -0.8119,  ..., -0.9162,  0.6395, -0.8064],\n",
            "        ...,\n",
            "        [-0.4710,  0.9994, -0.9026,  ..., -0.8718,  0.3471, -0.0520],\n",
            "        [ 0.4204,  1.0000,  0.7971,  ...,  0.2100, -0.3822, -0.8325],\n",
            "        [-0.4764,  1.0000, -0.8806,  ..., -0.9443,  0.4695, -0.4018]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5414,  1.0000,  0.9007,  ...,  0.2748,  0.2226, -0.9315],\n",
            "        [ 0.8215,  1.0000,  0.8473,  ...,  0.7040, -0.4937, -0.8664],\n",
            "        [-0.3485,  0.9999, -0.5444,  ..., -0.9410,  0.6648, -0.6721],\n",
            "        ...,\n",
            "        [-0.4903,  0.9951, -0.8591,  ..., -0.9349,  0.4201,  0.0231],\n",
            "        [ 0.4254,  1.0000,  0.8085,  ...,  0.4801, -0.3764, -0.7976],\n",
            "        [ 0.5794,  1.0000,  0.8306,  ...,  0.5267, -0.6700, -0.5951]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1930,  1.0000, -0.5532,  ..., -0.8601,  0.4206, -0.9014],\n",
            "        [-0.0898,  0.9996, -0.7760,  ..., -0.8554,  0.1438, -0.2454],\n",
            "        [-0.3218,  0.9958, -0.8812,  ..., -0.9087,  0.2253,  0.3661],\n",
            "        ...,\n",
            "        [ 0.4395,  1.0000,  0.8468,  ...,  0.5236, -0.2760, -0.7293],\n",
            "        [-0.3896,  1.0000, -0.8427,  ..., -0.9309,  0.4613, -0.6333],\n",
            "        [-0.2831,  0.9998, -0.7818,  ..., -0.9164,  0.2773, -0.5562]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-4.0639e-01,  9.9965e-01, -8.1005e-01, -9.8433e-01,  5.7341e-01,\n",
            "         -8.6376e-01, -1.9955e-01, -3.5049e-01, -9.5846e-01,  3.1689e-01,\n",
            "         -6.2846e-01,  8.6906e-01, -3.1281e-01,  9.9760e-01, -1.3999e-01,\n",
            "          6.7112e-01, -6.1768e-01, -9.6758e-01,  6.8836e-01, -6.6800e-01,\n",
            "          4.7752e-01,  8.4910e-01,  6.1624e-01, -6.9991e-01, -8.2732e-01,\n",
            "         -7.0940e-01,  5.5020e-01,  6.0156e-01, -5.2931e-01,  2.6498e-01,\n",
            "         -5.8655e-01,  2.0402e-01,  8.9822e-01,  6.0217e-01,  2.5833e-01,\n",
            "         -8.3921e-01, -1.1140e-01, -3.7816e-01, -9.8272e-01, -9.7259e-01,\n",
            "          4.5901e-01, -2.8362e-01,  9.9219e-01, -9.0230e-01,  9.6010e-01,\n",
            "         -9.5185e-01,  2.3547e-01, -7.6226e-01,  8.0431e-01,  5.3807e-01,\n",
            "         -8.3764e-02, -9.8393e-01,  7.5787e-01, -4.3346e-01, -7.2335e-01,\n",
            "         -9.9280e-01, -6.3593e-01,  7.5133e-01, -6.3789e-01,  6.4218e-01,\n",
            "         -3.8323e-02, -7.8648e-01,  8.1497e-01,  5.4455e-01,  7.8916e-01,\n",
            "          6.4202e-01,  8.3612e-01,  5.3497e-01,  9.1079e-01, -9.8852e-01,\n",
            "         -5.1631e-01, -7.9127e-01,  2.8252e-01, -5.5420e-01,  6.7444e-01,\n",
            "         -2.4510e-01,  3.7713e-01, -6.7613e-01, -4.2377e-01,  7.7818e-01,\n",
            "         -1.7827e-01,  7.5033e-01,  7.7542e-01, -9.9933e-01, -2.5167e-01,\n",
            "         -8.2536e-01,  9.4514e-01, -8.7600e-01, -8.0188e-01,  1.5387e-01,\n",
            "          2.8263e-01, -6.3611e-01, -6.1160e-01,  3.6369e-02, -2.0941e-02,\n",
            "         -8.5101e-01,  3.8245e-02, -5.8315e-01, -9.9351e-01,  4.6895e-01,\n",
            "          8.2592e-01,  8.2344e-01,  6.1076e-01, -2.9677e-01, -9.9817e-01,\n",
            "         -8.4126e-01,  2.2188e-01, -8.8592e-01, -9.9938e-01, -1.9667e-01,\n",
            "         -8.0234e-01, -1.7366e-01,  3.8084e-01,  8.2436e-01, -2.6949e-01,\n",
            "          9.9845e-01, -8.8928e-01,  6.1095e-01, -9.9855e-01, -8.8671e-01,\n",
            "          1.2641e-01,  4.1857e-01,  1.7137e-02, -6.0646e-01,  1.8665e-01,\n",
            "         -9.6409e-01, -9.2495e-01, -9.9185e-01,  3.2405e-01, -3.0801e-03,\n",
            "         -4.5729e-01,  5.0954e-01, -6.5448e-01, -8.3159e-01, -1.6175e-01,\n",
            "         -4.1494e-01, -9.9056e-01,  6.3145e-01,  5.1338e-01, -9.6586e-01,\n",
            "          9.6699e-01,  9.5164e-01, -2.3812e-01, -5.9690e-01, -2.0016e-01,\n",
            "          9.0530e-01, -5.0701e-02,  2.1096e-01, -6.8319e-02, -8.4710e-01,\n",
            "          3.3591e-02,  1.1071e-01, -1.3100e-01,  4.5726e-01, -9.9953e-01,\n",
            "          7.5484e-01,  7.1884e-01,  9.6638e-01,  9.2810e-01,  1.6621e-01,\n",
            "         -6.1275e-01, -9.9934e-01,  8.4422e-01,  4.6534e-01,  9.7100e-01,\n",
            "          9.1170e-03, -3.6043e-02,  8.9106e-01,  5.7406e-01,  1.6128e-01,\n",
            "          5.1695e-01,  6.5252e-01,  5.1370e-01,  7.6237e-01,  9.7722e-01,\n",
            "         -8.9196e-01, -8.7859e-01, -7.3514e-01,  8.8225e-01, -7.4655e-01,\n",
            "          9.4074e-01, -6.0715e-01,  7.0298e-01, -9.3988e-01, -5.4921e-01,\n",
            "          5.7683e-04, -2.8500e-01, -9.9955e-01, -2.4648e-02,  8.3080e-01,\n",
            "         -1.8873e-01, -9.0164e-01,  4.4352e-01,  2.1500e-01,  6.3639e-01,\n",
            "         -3.0766e-01, -6.7045e-01,  5.7709e-01, -2.8762e-02,  8.8463e-01,\n",
            "          6.7244e-01, -8.8972e-01,  9.8781e-01,  3.3673e-01, -2.1955e-01,\n",
            "         -9.7955e-01,  5.0789e-01,  9.6146e-01, -9.3273e-01, -8.1990e-01,\n",
            "          1.4964e-01,  1.1384e-01,  5.6276e-01, -7.3850e-01, -1.0254e-01,\n",
            "         -5.1053e-01,  8.8894e-01, -8.6917e-01,  7.8868e-01,  6.9052e-01,\n",
            "         -8.8139e-02, -5.2246e-01, -4.4853e-01, -5.7258e-01,  2.8390e-01,\n",
            "         -1.6098e-02, -5.1418e-01,  2.1558e-01, -8.9783e-01, -9.9832e-01,\n",
            "          2.1767e-01,  6.0277e-01,  6.0323e-01,  5.4692e-02,  9.9792e-01,\n",
            "          4.1272e-01, -7.3747e-01,  9.2781e-01, -9.6325e-01, -4.5861e-01,\n",
            "          7.1070e-01, -9.8811e-01,  7.8582e-01, -3.1330e-01,  9.9938e-01,\n",
            "         -9.8337e-01,  9.0983e-01, -8.0264e-01,  5.7869e-01,  7.8740e-01,\n",
            "         -5.8261e-01,  1.4479e-01,  8.7976e-01,  7.7450e-01,  8.4030e-01,\n",
            "          8.5393e-01,  9.1589e-02, -9.8848e-01, -3.6293e-02,  6.0848e-01,\n",
            "         -9.7233e-01,  3.4446e-01, -9.6770e-01, -9.0223e-01,  9.1527e-01,\n",
            "          9.9877e-01, -8.2501e-01,  2.5888e-01,  5.5961e-01,  6.4503e-01,\n",
            "          6.8737e-01, -9.5129e-01,  5.0642e-01,  9.9966e-01, -9.1956e-01,\n",
            "         -8.4516e-01,  9.9929e-01,  3.6175e-01, -9.2691e-01,  5.0809e-01,\n",
            "         -7.2520e-01, -9.3160e-01,  5.5034e-01, -3.1253e-01,  4.6601e-01,\n",
            "          6.7274e-01,  2.8099e-01, -9.4056e-01, -9.8988e-01, -8.9953e-01,\n",
            "          9.8348e-01,  4.5743e-01,  6.7467e-01,  3.1643e-01, -7.9220e-01,\n",
            "         -9.2857e-01,  9.1609e-01,  4.2818e-01, -9.1679e-01,  9.9959e-01,\n",
            "          6.8651e-01, -6.2042e-01, -9.6036e-01,  2.2862e-01,  2.2601e-01,\n",
            "          7.1761e-01,  8.5582e-01,  5.7347e-01, -8.0415e-01,  2.8793e-01,\n",
            "          7.6691e-01, -3.9375e-01,  9.4714e-01,  6.9190e-02, -2.5000e-01,\n",
            "         -2.3879e-01, -2.7083e-01, -9.5330e-01, -6.9639e-01, -5.7443e-01,\n",
            "          5.4175e-01,  9.5619e-01,  6.0082e-01, -8.6824e-01,  9.3141e-01,\n",
            "          3.5383e-01, -9.9936e-01,  9.9545e-01,  9.2160e-01, -8.5004e-01,\n",
            "         -1.4782e-01,  6.7195e-01,  6.3454e-01, -3.1184e-01,  6.6616e-01,\n",
            "         -7.0945e-01, -3.2276e-01, -8.5604e-01,  3.8634e-01,  7.4766e-01,\n",
            "          7.2264e-01,  5.4471e-01,  4.1223e-01,  5.2063e-01,  1.0046e-01,\n",
            "         -5.2024e-01,  7.1909e-01, -6.6163e-01, -9.2947e-01, -5.2946e-01,\n",
            "          1.9377e-01,  6.9824e-01, -8.0704e-01,  8.5788e-01,  8.4616e-01,\n",
            "          9.9967e-01,  5.4073e-01,  9.9782e-01, -8.0963e-01,  6.5985e-01,\n",
            "         -4.7889e-01,  3.7807e-01,  8.3478e-01, -9.0991e-01, -9.9926e-01,\n",
            "         -2.1048e-01, -4.7048e-01,  6.0622e-01, -7.5341e-01, -9.3169e-01,\n",
            "         -8.9986e-01,  4.7290e-01, -4.8172e-01,  8.9293e-01, -5.0319e-01,\n",
            "         -8.3368e-01,  9.8317e-01,  5.2768e-01,  7.0265e-01,  1.9380e-01,\n",
            "         -5.7567e-01,  8.0991e-01,  8.4421e-01,  4.0838e-01,  8.6141e-01,\n",
            "         -3.9209e-01,  8.7451e-01, -8.0488e-01,  7.4661e-01, -1.9430e-01,\n",
            "          2.6819e-01, -7.2587e-04,  2.3523e-01,  7.8294e-01,  7.4872e-01,\n",
            "          9.5446e-01, -3.9150e-01,  2.9251e-02, -9.9310e-01,  9.9968e-01,\n",
            "         -1.8459e-01,  5.2615e-01,  6.0113e-02,  4.7285e-01,  7.8815e-01,\n",
            "         -8.3797e-01,  6.1744e-01, -4.0279e-01,  9.3580e-01, -7.8565e-01,\n",
            "          8.7016e-01,  6.3547e-01,  8.2601e-01, -3.3511e-01, -8.2113e-01,\n",
            "          3.1043e-01, -1.7728e-01, -7.2953e-01, -9.5274e-01,  8.8619e-01,\n",
            "         -9.2625e-01, -6.6633e-01, -8.5519e-01, -9.3242e-01,  9.8522e-01,\n",
            "         -8.5442e-01,  7.1225e-01, -7.8402e-01, -8.1559e-01, -8.1879e-01,\n",
            "         -4.8432e-01, -6.7924e-01,  5.0248e-01, -9.3004e-01,  9.9419e-01,\n",
            "         -9.6690e-01,  7.0279e-01, -7.2079e-01,  2.9588e-01,  7.6847e-01,\n",
            "          6.1824e-01,  1.6164e-01,  5.0051e-01, -3.7744e-02,  5.7689e-02,\n",
            "          7.2422e-01, -7.1938e-01, -7.2604e-01,  1.9563e-01,  4.1362e-01,\n",
            "          3.9666e-01,  9.3768e-01, -2.6510e-01,  9.6777e-01,  3.8176e-01,\n",
            "         -7.9374e-01, -5.0052e-01, -5.3666e-01,  8.9895e-01,  9.8965e-01,\n",
            "         -9.3867e-01,  8.5972e-01,  9.9924e-01, -9.1771e-01, -2.4856e-01,\n",
            "         -2.2347e-01, -9.7813e-01,  6.6792e-01, -8.7198e-01, -9.6238e-01,\n",
            "          2.0913e-01, -5.4817e-01,  7.3594e-01,  6.6845e-01,  9.7387e-01,\n",
            "         -6.9191e-01, -7.4423e-01, -9.6102e-01, -5.1850e-01, -6.9441e-01,\n",
            "         -8.7661e-01,  8.3289e-01, -9.3447e-01, -9.2818e-01,  9.6092e-01,\n",
            "          3.8634e-01, -1.3951e-01,  2.5962e-01,  5.8829e-01,  9.4874e-01,\n",
            "         -6.3777e-01, -9.4670e-01,  3.0210e-01,  5.9598e-01,  1.8929e-01,\n",
            "          4.5668e-01, -8.3315e-01, -5.4007e-01, -9.6418e-01,  7.5409e-01,\n",
            "          9.9749e-01, -4.5586e-01, -5.3961e-01,  7.4016e-01,  1.0205e-01,\n",
            "         -2.3162e-01,  9.9952e-01, -6.4938e-01,  7.8533e-01,  9.9794e-01,\n",
            "          4.8768e-02,  7.2054e-01, -5.7903e-01,  5.9433e-02,  5.1716e-02,\n",
            "          8.2507e-01, -6.3078e-02,  9.8407e-01, -8.0342e-01, -8.7639e-01,\n",
            "         -9.9957e-01,  2.4395e-01, -6.0817e-01, -2.4118e-02,  7.3504e-01,\n",
            "         -8.0425e-01, -4.5007e-01,  4.6213e-01, -9.9071e-01,  8.6688e-01,\n",
            "         -9.3950e-02, -9.9851e-01, -9.7094e-01, -6.3903e-01, -4.2873e-01,\n",
            "         -9.5903e-01, -1.6652e-02, -7.1250e-01, -8.6330e-01,  9.5080e-01,\n",
            "         -7.5282e-01, -9.9938e-01, -3.3575e-01,  7.8343e-01,  9.8844e-01,\n",
            "          3.2558e-01,  2.6902e-01, -6.3832e-01, -6.9245e-01,  4.0215e-01,\n",
            "         -9.9976e-01, -8.4088e-02,  8.2319e-01,  5.2680e-01, -5.3386e-01,\n",
            "          9.6871e-01, -6.1851e-01, -8.3778e-01, -4.2031e-01,  4.4394e-01,\n",
            "          5.1969e-01, -9.9978e-01, -1.6499e-01,  9.8483e-01, -1.7164e-01,\n",
            "         -3.7598e-01, -8.1858e-01, -8.1153e-01, -6.4089e-01, -1.8782e-02,\n",
            "          9.8396e-01, -7.1956e-01,  9.9568e-01, -2.6989e-01,  6.0855e-01,\n",
            "          8.6853e-01,  1.1785e-02, -8.5900e-01, -5.7967e-01,  7.7039e-01,\n",
            "          7.5271e-01,  4.1580e-01,  5.0672e-01, -5.8310e-01,  1.7742e-01,\n",
            "         -2.0529e-01, -7.9219e-01,  5.4454e-01, -6.7051e-01,  4.4701e-01,\n",
            "         -2.8594e-01,  7.2655e-01,  7.0004e-01, -4.6444e-01,  9.9638e-01,\n",
            "          2.5029e-01, -8.2361e-01,  7.1091e-01, -1.8952e-01, -2.6660e-01,\n",
            "         -9.9940e-01, -6.9309e-01,  7.1655e-01, -9.6339e-01, -7.4654e-01,\n",
            "          4.9252e-01, -4.4696e-01, -4.4660e-01,  7.3888e-01, -2.9280e-01,\n",
            "          7.5687e-01,  9.9012e-01,  7.5347e-01,  6.1421e-01, -9.0751e-01,\n",
            "         -9.9763e-01,  1.3784e-01,  7.3623e-01, -8.5996e-01,  8.2727e-01,\n",
            "         -7.6452e-01,  9.9505e-01,  1.1545e-02,  6.4761e-01,  5.3029e-01,\n",
            "          9.8533e-01,  1.9131e-02, -4.8221e-01,  5.6838e-01,  2.6214e-01,\n",
            "         -5.5468e-01,  9.1477e-01, -5.2939e-01, -9.5166e-01, -6.9937e-01,\n",
            "         -7.0315e-01, -1.8179e-01, -4.1318e-01,  5.8864e-01, -3.0509e-02,\n",
            "          9.9965e-01,  8.1792e-01,  8.9388e-01,  4.1194e-01,  6.2721e-01,\n",
            "         -5.2738e-01, -6.5800e-01,  8.9823e-01, -9.9952e-01,  9.1753e-01,\n",
            "          2.5066e-01, -7.3453e-01,  3.9182e-01, -8.4992e-01, -5.5421e-01,\n",
            "         -4.2288e-01, -6.4837e-01, -6.8429e-01, -7.5866e-01, -7.5304e-01,\n",
            "         -4.1257e-01, -3.5759e-01,  8.4836e-01, -6.8979e-01, -9.8347e-01,\n",
            "          9.1925e-01, -5.9900e-01,  6.0408e-01,  5.3492e-01, -3.1982e-01,\n",
            "          4.9420e-01,  6.7401e-01,  8.4500e-01, -6.9726e-01,  2.2155e-01,\n",
            "         -4.6619e-01, -7.4501e-01,  3.7981e-01,  2.8474e-01,  8.5713e-01,\n",
            "          4.3753e-01,  1.6282e-01,  8.2668e-01, -1.7870e-01, -6.5230e-01,\n",
            "          3.0507e-01,  2.5565e-01,  5.0373e-01,  8.3776e-01, -2.8857e-01,\n",
            "          7.6380e-01,  7.8285e-01, -2.1305e-01, -5.0970e-01,  3.8653e-01,\n",
            "          1.9833e-01,  8.9807e-01, -9.9105e-01,  9.9252e-01,  3.3748e-01,\n",
            "         -2.7122e-01, -9.9442e-01, -2.5083e-01,  3.0744e-01,  4.9719e-01,\n",
            "          5.7731e-01,  9.8363e-02, -6.0001e-01, -7.3233e-01,  7.9692e-01,\n",
            "         -9.9977e-01, -8.1831e-01, -6.5114e-01, -1.5156e-02,  7.1752e-01,\n",
            "         -9.8780e-01, -5.9482e-01,  4.3819e-01, -2.5227e-01, -1.1797e-01,\n",
            "          9.8209e-01, -6.9081e-01, -8.7398e-01, -9.2894e-01, -9.2647e-01,\n",
            "          3.6349e-01,  7.0957e-01, -9.3459e-01,  4.3586e-01,  6.8466e-01,\n",
            "         -9.5150e-01, -2.6987e-01,  1.4141e-01,  6.8423e-01, -4.7412e-01,\n",
            "         -3.2882e-01,  8.5047e-01, -9.9967e-01,  7.9959e-01, -2.1477e-01,\n",
            "         -3.3816e-01,  6.4885e-01, -8.1542e-01,  7.1917e-01,  6.2313e-01,\n",
            "         -9.9442e-01,  5.1990e-01, -2.5047e-02,  7.9378e-01,  6.8674e-01,\n",
            "         -5.1726e-01,  3.3135e-01,  4.7524e-01, -3.4831e-01,  9.2373e-01,\n",
            "          4.1474e-01, -6.6364e-02,  1.2924e-01,  9.8347e-01,  6.3329e-01,\n",
            "          7.8843e-01, -2.6954e-02, -9.0257e-01, -9.6492e-01, -3.7069e-01,\n",
            "         -9.2453e-01,  1.7633e-01, -2.2066e-02]], device='cuda:0',\n",
            "       grad_fn=<TanhBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluation... :   0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0811f59155e945598ab2daf8db337ea5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7521,  1.0000,  0.8886,  ...,  0.7293, -0.5455, -0.7694],\n",
            "        [ 0.5936,  1.0000,  0.8982,  ...,  0.7500, -0.5754, -0.6286],\n",
            "        [ 0.8039,  1.0000,  0.3753,  ..., -0.6686,  0.6417, -0.8835],\n",
            "        ...,\n",
            "        [ 0.3786,  1.0000,  0.8748,  ...,  0.3163, -0.3833, -0.7855],\n",
            "        [ 0.0052,  0.9981, -0.7497,  ..., -0.8520,  0.5159, -0.4746],\n",
            "        [-0.4800,  0.9996, -0.8316,  ..., -0.8219,  0.3624, -0.2190]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0806,  1.0000, -0.2766,  ..., -0.9071,  0.6906, -0.8543],\n",
            "        [ 0.5501,  1.0000,  0.7013,  ..., -0.4551, -0.1568, -0.8791],\n",
            "        [ 0.4914,  1.0000,  0.9657,  ..., -0.1020,  0.2034, -0.9684],\n",
            "        ...,\n",
            "        [ 0.2262,  1.0000,  0.7607,  ..., -0.6086,  0.3445, -0.9719],\n",
            "        [-0.3871,  1.0000,  0.2797,  ..., -0.8463,  0.5086, -0.8658],\n",
            "        [ 0.3552,  1.0000,  0.6232,  ..., -0.8585,  0.6676, -0.9812]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5138,  1.0000,  0.9007,  ...,  0.7322, -0.4788, -0.5182],\n",
            "        [ 0.4127,  1.0000,  0.7798,  ...,  0.4174,  0.7664, -0.8707],\n",
            "        [ 0.4786,  1.0000,  0.9067,  ...,  0.4166, -0.1036, -0.9129],\n",
            "        ...,\n",
            "        [ 0.2863,  1.0000,  0.6575,  ..., -0.8843,  0.7964, -0.9870],\n",
            "        [-0.4482,  1.0000, -0.6980,  ..., -0.9114,  0.4033, -0.5664],\n",
            "        [ 0.3795,  1.0000,  0.6808,  ..., -0.8337,  0.4673, -0.9870]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3529,  1.0000,  0.4962,  ..., -0.4342, -0.2874, -0.9230],\n",
            "        [ 0.2450,  1.0000,  0.8131,  ..., -0.4512,  0.5471, -0.9703],\n",
            "        [ 0.3164,  1.0000,  0.2595,  ..., -0.8430,  0.3645, -0.9734],\n",
            "        ...,\n",
            "        [ 0.6824,  1.0000,  0.9054,  ...,  0.8119, -0.4381, -0.6367],\n",
            "        [-0.2038,  0.9996, -0.7167,  ..., -0.9191,  0.5913, -0.5789],\n",
            "        [ 0.6448,  1.0000,  0.9167,  ...,  0.7927, -0.5560, -0.7172]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6223,  1.0000,  0.7965,  ...,  0.0772, -0.0553, -0.7724],\n",
            "        [ 0.3188,  1.0000,  0.9106,  ...,  0.4404,  0.1139, -0.9087],\n",
            "        [-0.0350,  0.9996, -0.7162,  ..., -0.7288,  0.3496, -0.4992],\n",
            "        ...,\n",
            "        [ 0.2137,  1.0000,  0.2966,  ..., -0.5935,  0.0093, -0.9603],\n",
            "        [ 0.5802,  1.0000,  0.9123,  ...,  0.5594, -0.4659, -0.6245],\n",
            "        [ 0.4258,  1.0000,  0.8616,  ...,  0.5459,  0.6380, -0.8609]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5489,  1.0000,  0.8852,  ...,  0.7742, -0.4600, -0.6556],\n",
            "        [ 0.7066,  1.0000,  0.7936,  ...,  0.6295, -0.5138, -0.8333],\n",
            "        [ 0.0018,  0.9999, -0.9014,  ..., -0.9051,  0.5165, -0.3928],\n",
            "        ...,\n",
            "        [ 0.7729,  1.0000,  0.0213,  ..., -0.7110,  0.7514, -0.8193],\n",
            "        [ 0.2742,  1.0000,  0.2364,  ..., -0.5704,  0.0202, -0.8894],\n",
            "        [-0.0661,  1.0000,  0.3808,  ..., -0.8257,  0.4091, -0.9509]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2001,  1.0000, -0.4307,  ..., -0.8596,  0.1302, -0.8704],\n",
            "        [-0.2460,  0.9997, -0.9077,  ..., -0.9325,  0.2490,  0.0446],\n",
            "        [ 0.6472,  1.0000,  0.8804,  ...,  0.7657, -0.4786, -0.7224],\n",
            "        ...,\n",
            "        [-0.2300,  1.0000,  0.0615,  ..., -0.8670, -0.1377, -0.8476],\n",
            "        [ 0.5767,  1.0000,  0.9138,  ...,  0.7485, -0.6053, -0.6339],\n",
            "        [-0.1679,  0.9999, -0.6853,  ..., -0.8202,  0.0993, -0.1559]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6557,  1.0000,  0.9081,  ...,  0.4847, -0.3060, -0.8021],\n",
            "        [ 0.6637,  1.0000,  0.9187,  ...,  0.7836, -0.4919, -0.7002],\n",
            "        [ 0.5972,  1.0000,  0.9266,  ...,  0.7475, -0.3259, -0.6566],\n",
            "        ...,\n",
            "        [ 0.5851,  1.0000,  0.9140,  ...,  0.6733, -0.5826, -0.6306],\n",
            "        [ 0.3467,  1.0000,  0.9013,  ...,  0.5920, -0.0823, -0.9274],\n",
            "        [ 0.6585,  1.0000,  0.7310,  ..., -0.3276,  0.3421, -0.9387]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6364,  1.0000,  0.9135,  ...,  0.8316, -0.5743, -0.6617],\n",
            "        [-0.0953,  1.0000, -0.7242,  ..., -0.8592,  0.2909, -0.4110],\n",
            "        [-0.5924,  0.9990, -0.1143,  ..., -0.8324,  0.2900, -0.7738],\n",
            "        ...,\n",
            "        [ 0.4701,  1.0000,  0.9349,  ...,  0.6034,  0.3529, -0.7930],\n",
            "        [-0.3701,  0.9999, -0.7216,  ..., -0.9075,  0.6584, -0.3866],\n",
            "        [ 0.5615,  1.0000,  0.9047,  ...,  0.7156, -0.5348, -0.6202]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1139,  0.9998, -0.8639,  ..., -0.9010,  0.3132, -0.3461],\n",
            "        [ 0.5841,  1.0000,  0.8307,  ..., -0.4075,  0.0155, -0.9614],\n",
            "        [ 0.4835,  1.0000,  0.8999,  ...,  0.6479, -0.5423, -0.6558],\n",
            "        ...,\n",
            "        [ 0.6390,  1.0000,  0.8471,  ...,  0.6631, -0.6110, -0.7099],\n",
            "        [ 0.5564,  1.0000,  0.8589,  ...,  0.5729, -0.3529, -0.6454],\n",
            "        [ 0.7315,  1.0000,  0.9487,  ...,  0.8465, -0.0697, -0.8817]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1359,  1.0000, -0.7730,  ..., -0.8949,  0.4816, -0.4444],\n",
            "        [-0.1431,  0.9999, -0.8259,  ..., -0.9470,  0.4369, -0.4012],\n",
            "        [-0.4736,  0.9998, -0.9209,  ..., -0.9583,  0.1360, -0.2417],\n",
            "        ...,\n",
            "        [ 0.6950,  1.0000,  0.8943,  ...,  0.3899,  0.0758, -0.9260],\n",
            "        [ 0.6750,  1.0000, -0.1314,  ..., -0.6661,  0.4623, -0.9300],\n",
            "        [ 0.6357,  1.0000,  0.9308,  ...,  0.7560, -0.5049, -0.6884]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3818,  1.0000,  0.7239,  ...,  0.4306,  0.7484, -0.8537],\n",
            "        [-0.1113,  1.0000, -0.8820,  ..., -0.9198,  0.3732, -0.3461],\n",
            "        [-0.2030,  1.0000,  0.0669,  ..., -0.8733,  0.4728, -0.9098],\n",
            "        ...,\n",
            "        [ 0.1535,  1.0000, -0.3954,  ..., -0.8731,  0.5329, -0.8746],\n",
            "        [ 0.5695,  1.0000,  0.7889,  ..., -0.3685,  0.1508, -0.9226],\n",
            "        [-0.0116,  1.0000, -0.3821,  ..., -0.9318,  0.5531, -0.8143]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0038,  0.9999, -0.7199,  ..., -0.6069,  0.6414, -0.0228],\n",
            "        [ 0.5373,  1.0000,  0.8683,  ...,  0.2536, -0.2714, -0.9064],\n",
            "        [-0.3229,  0.8708, -0.7806,  ..., -0.9240,  0.4702, -0.0115],\n",
            "        ...,\n",
            "        [-0.6463,  1.0000, -0.8817,  ..., -0.8331,  0.5812, -0.3952],\n",
            "        [ 0.0882,  1.0000, -0.8009,  ..., -0.8812,  0.4944, -0.5821],\n",
            "        [-0.4475,  1.0000, -0.4128,  ..., -0.7808,  0.4747, -0.8624]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7161,  1.0000,  0.8865,  ...,  0.0270, -0.3719, -0.8331],\n",
            "        [ 0.6442,  1.0000,  0.8568,  ...,  0.0626, -0.2420, -0.9206],\n",
            "        [-0.2760,  0.9982, -0.8961,  ..., -0.8617,  0.1060,  0.0785],\n",
            "        ...,\n",
            "        [ 0.4964,  1.0000,  0.5220,  ..., -0.5396, -0.2951, -0.9118],\n",
            "        [-0.0221,  1.0000,  0.3542,  ..., -0.5975,  0.6395, -0.8348],\n",
            "        [ 0.0863,  1.0000,  0.2551,  ..., -0.0618, -0.2925, -0.9228]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3841,  1.0000,  0.4836, -0.9875, -0.0282,  0.9234,  0.8226,  0.8255,\n",
            "         -0.9986, -0.7708,  0.7922, -0.6373,  0.2191,  0.9998, -0.1371,  0.0812,\n",
            "          0.9148, -0.9916,  0.9062, -0.8211,  0.6097, -0.5501,  0.9247, -0.6406,\n",
            "          0.8345,  0.6856, -0.2291,  0.8642, -0.5094,  0.3662, -0.6822, -0.6364,\n",
            "          0.9715,  0.7745,  0.9185, -0.9728, -0.4853, -0.9749, -0.9976, -0.9993,\n",
            "         -0.6437, -0.6269,  0.9998, -0.8676,  0.9982, -0.9954,  0.1839, -0.3986,\n",
            "          0.8524,  0.5590, -0.9157,  0.8246,  0.8802,  0.8720, -0.6957, -0.9590,\n",
            "         -0.9073,  0.7814, -0.9756, -0.2928,  0.9244,  0.4921, -0.5547, -0.1243,\n",
            "         -0.8723, -0.0626,  0.6686,  0.7401, -0.8222, -0.9816,  0.9041, -0.9544,\n",
            "          0.8825, -0.3513, -0.1876,  0.9357, -0.9013,  0.7921, -0.8663,  0.9946,\n",
            "          0.5530,  0.7219,  0.8394, -1.0000,  0.7874, -0.9281,  0.9937, -0.9947,\n",
            "         -0.9892,  0.8610,  0.7591,  0.7818,  0.7398, -0.4415, -0.7471, -0.8192,\n",
            "         -0.7308,  0.7332, -0.9997,  0.8894,  0.8756,  0.9330, -0.5945, -0.7890,\n",
            "         -0.9999,  0.3288, -0.7540, -0.7672, -1.0000, -0.8316, -0.8402, -0.9002,\n",
            "         -0.6168,  0.9685,  0.5244,  0.9999,  0.8460,  0.9988, -1.0000, -0.9931,\n",
            "          0.6332,  0.9620, -0.7816, -0.5992,  0.5947, -0.9919, -0.2818, -0.9992,\n",
            "          0.9162, -0.9785, -0.7147,  0.8074,  0.9152, -0.2796, -0.7864,  0.6156,\n",
            "         -0.9999,  0.4035, -0.8862, -0.9980,  0.9970,  0.9603,  0.8384, -0.7608,\n",
            "         -0.4876,  0.9520,  0.9294, -0.7262, -0.1972, -0.3693, -0.8499,  0.8931,\n",
            "          0.4063, -0.6865, -1.0000,  0.6724, -0.1443,  0.9721, -0.9810,  0.9895,\n",
            "         -0.9794, -1.0000,  0.7989,  0.5054, -0.6781,  0.9037, -0.8994,  0.9181,\n",
            "         -0.7405,  0.8635,  0.8879,  0.8609,  0.3551,  0.0069,  0.7398, -0.8597,\n",
            "          0.6466, -0.8395, -0.5763, -0.9865,  0.9876, -0.7951,  0.9758, -0.9422,\n",
            "         -0.6574,  0.6079,  0.0557, -1.0000,  0.9335,  0.4346,  0.7025,  0.0544,\n",
            "          0.5931, -0.5923,  0.5500, -0.2406, -0.8133,  0.9233, -0.3794,  0.9660,\n",
            "          0.7936, -0.9996,  0.9529,  0.9984,  0.3548, -0.8571, -0.1123,  0.9950,\n",
            "         -0.9990, -0.8093,  0.3627, -0.7447,  0.7988,  0.3599, -0.6714, -0.7765,\n",
            "          0.9116,  0.2977,  0.5104, -0.3230,  0.3887,  0.6868, -0.6718,  0.7005,\n",
            "          0.9345,  0.9994, -0.7843, -0.5563,  0.5228, -0.9998,  0.9265,  0.4790,\n",
            "         -0.0789, -0.8008,  0.9969,  0.9285,  0.7778,  0.9820, -0.9693, -0.5587,\n",
            "         -0.5352,  0.7258,  0.2109,  0.0343,  1.0000, -0.9985,  0.9888,  0.8463,\n",
            "          0.2130, -0.2330,  0.3685,  0.1713,  0.2387,  0.3022, -0.5904,  0.9958,\n",
            "         -0.8832, -0.9948,  0.4756,  0.4242, -0.9681, -0.8749,  0.6108, -0.8158,\n",
            "          0.9935,  1.0000,  0.5623,  0.5791,  0.8140,  0.8751,  0.9016, -0.9882,\n",
            "          0.9842,  1.0000, -0.9646,  0.1461,  1.0000,  0.8172, -0.6621, -0.4722,\n",
            "          0.5801, -0.9833, -0.2363, -0.4335, -0.0697, -0.2349,  0.1846, -0.9749,\n",
            "         -0.9998, -0.9970,  0.9911, -0.7839, -0.6202,  0.8285, -0.6738, -0.6554,\n",
            "         -0.4418,  0.9959, -0.9154,  1.0000,  0.8320, -0.7855, -0.9785, -0.4196,\n",
            "          0.8197,  0.2779,  0.9995,  0.3583, -0.8724,  0.8901,  0.7164,  0.3322,\n",
            "          0.9254, -0.5780,  0.6789,  0.1297,  0.5145, -0.9826, -0.3540, -0.9277,\n",
            "          0.9578,  0.9889,  0.8017, -0.6499,  0.9799,  0.9017, -1.0000,  0.9997,\n",
            "          0.9865, -0.9969,  0.8780, -0.2312,  0.9301,  0.0703,  0.8490, -0.9319,\n",
            "         -0.9195, -0.9928,  0.9074,  0.5164, -0.6524,  0.7129, -0.9356,  0.8987,\n",
            "          0.2420,  0.7295,  0.1376, -0.5549, -0.9992,  0.7938,  0.8834,  0.3091,\n",
            "          0.8114,  0.9901,  0.3464,  1.0000, -0.8234,  0.7623, -0.3221,  0.8424,\n",
            "          0.4807,  0.7779, -0.1461, -0.0942, -1.0000,  0.0972, -0.6123,  0.3971,\n",
            "          0.5304, -0.9915,  0.0523, -0.3971, -0.4579, -0.0552,  0.3792,  0.6268,\n",
            "          0.9998,  0.6230, -0.2221, -0.7118, -0.4756,  0.3434,  0.9596,  0.9436,\n",
            "          0.9967, -0.8859,  0.3396,  0.8225,  0.1622, -0.7824,  0.1816,  0.6129,\n",
            "          0.4585,  0.9676,  0.8941,  0.1127, -0.6814,  0.8807, -0.9986,  1.0000,\n",
            "          0.5643,  0.6305,  0.9735, -0.1731,  0.9290, -0.2643,  0.6418, -0.8354,\n",
            "          0.9923,  0.7047,  0.7367,  0.3892,  0.6259, -0.4480, -0.8335,  0.9003,\n",
            "          0.3040, -0.7683, -0.9781,  0.9861, -0.9914,  0.2985, -0.6909,  0.7819,\n",
            "          0.9877, -0.6995, -0.8574, -0.8135, -0.3218, -0.9546, -0.9626, -0.9978,\n",
            "         -0.0906, -0.9747,  1.0000, -0.9952,  0.7377, -0.9295, -0.8732,  0.8335,\n",
            "          0.0938, -0.6346, -0.7982, -0.0484, -0.6656,  0.9196, -0.0492,  0.8032,\n",
            "         -0.3244,  0.3280,  0.6630,  0.4929,  0.4531,  0.9078, -0.7853, -0.9922,\n",
            "         -0.8849, -0.8015, -0.6183,  0.9772, -0.9820, -0.6165,  1.0000, -0.9945,\n",
            "          0.2026, -0.2550, -0.9988,  0.5780, -0.8962, -0.9854, -0.8400, -0.7844,\n",
            "          0.8999,  0.9513,  0.9997,  0.0973, -0.3021, -0.9859, -0.7667,  0.9962,\n",
            "         -0.9903, -0.0415,  0.0238, -0.9987,  0.9271,  0.7324, -0.5406,  0.9139,\n",
            "         -0.8220,  0.9846,  0.1104, -0.9979,  0.8319,  0.8822,  0.1446,  0.8927,\n",
            "         -0.3925, -0.1191, -0.9783,  0.6271,  0.9999,  0.1050, -0.9578,  0.7007,\n",
            "          0.9143,  0.8191,  1.0000, -0.9725,  0.8372,  0.9999, -0.5092,  0.6970,\n",
            "         -0.1044, -0.7939, -0.0726,  0.7622, -0.9907,  0.9999, -0.4956, -0.9881,\n",
            "         -1.0000,  0.6488, -0.8555,  0.8060,  0.9693,  0.2114,  0.9146,  0.6538,\n",
            "         -0.9977,  0.7232, -0.8709, -1.0000, -0.9999,  0.8774, -0.0532, -0.0266,\n",
            "          0.8109, -0.5046, -0.8527,  0.9999,  0.9179, -1.0000, -0.7226,  0.4968,\n",
            "          0.9721, -0.8394,  0.8222,  0.1287,  0.2016, -0.3475, -1.0000, -0.8391,\n",
            "          0.9955, -0.4100,  0.2235,  0.9998,  0.8060, -0.0540, -0.9771,  0.6090,\n",
            "          0.9048, -1.0000, -0.8020,  0.9999, -0.7654, -0.5351, -0.8790,  0.2587,\n",
            "          0.7033,  0.7973,  0.6910, -0.9989,  0.9983,  0.9323, -0.6760,  0.9982,\n",
            "         -0.2582, -0.8223, -0.9026, -0.7687,  0.9109, -0.7137,  0.8290, -0.7141,\n",
            "          0.9934,  0.9334, -0.7139,  0.9161,  0.9129, -0.8340, -0.6360,  0.9565,\n",
            "          0.8243,  0.1289,  0.9896, -0.2157, -0.8213, -0.1875,  0.7985,  0.9566,\n",
            "         -1.0000,  0.9383, -0.6371, -0.9482,  0.7749, -0.4941, -0.8953, -0.2333,\n",
            "          0.2844, -0.8290,  0.4867,  0.9634,  0.9286,  0.9218, -0.9920, -1.0000,\n",
            "         -0.7176, -0.6360, -0.8684, -0.2828, -0.0993,  0.9897,  0.6230,  0.5871,\n",
            "          0.6693,  1.0000, -0.5694,  0.9886, -0.9197,  0.9669, -0.9938,  0.8180,\n",
            "          0.4367, -0.9925, -0.8816,  0.9501, -0.7835,  0.8686, -0.9626,  0.8972,\n",
            "          1.0000, -0.7759, -0.2484,  0.8584, -0.9109,  0.8690, -0.2967,  0.9979,\n",
            "         -1.0000,  0.9898,  0.5814,  0.5837,  0.7021,  0.6943,  0.4445, -0.6952,\n",
            "         -0.8365, -0.9920, -0.0119,  0.5730, -0.7597,  0.5373,  0.9832, -0.9332,\n",
            "         -0.9997, -0.6747,  0.2982,  0.9280, -0.5470, -0.9928,  0.9656, -0.4676,\n",
            "          0.9900, -0.1273, -0.8397, -0.6849, -0.6916, -0.7184,  0.8024,  0.8823,\n",
            "          0.9485,  0.4982, -0.7579, -0.6734, -0.5508, -0.8938,  0.9002,  0.2875,\n",
            "          0.5509,  0.7518,  0.8801,  0.9894,  0.4594, -0.1400,  0.7941, -0.7331,\n",
            "         -0.6817, -0.9999,  0.9997,  0.9260, -0.9028, -0.9999,  0.9541,  0.7096,\n",
            "         -0.5996,  0.8778, -0.5529, -0.9457, -0.2231,  0.9595, -1.0000, -0.6251,\n",
            "          0.6076, -0.4997, -0.3096, -0.9999, -0.4425,  0.4642, -0.4075,  0.4348,\n",
            "          0.9995, -0.3632, -0.9932, -0.9755, -0.3341,  0.7944,  0.4474, -0.9939,\n",
            "         -0.6574,  0.9505, -0.9992,  0.4281, -0.8545, -0.6309,  0.4824,  0.6860,\n",
            "          0.9493, -1.0000,  0.9509, -0.8740,  0.9310, -0.5092,  0.4411,  0.8526,\n",
            "          0.8226, -0.9996,  0.9502,  0.3150,  0.8856,  0.8149,  0.9135, -0.1774,\n",
            "         -0.9476, -0.8100,  0.9888,  0.9892, -0.6604,  0.9197,  0.9997, -0.6981,\n",
            "          0.7699,  0.5809, -0.3428, -0.9995, -0.8282, -0.5722, -0.4276, -0.9261]],\n",
            "       device='cuda:0')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training... :   0%|          | 0/127 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9aed995118b443409667bc495b4e25df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4234,  1.0000, -0.8079,  ..., -0.8953,  0.4403, -0.5166],\n",
            "        [ 0.6646,  0.9998,  0.9233,  ...,  0.6683, -0.6931, -0.5730],\n",
            "        [ 0.6604,  0.9997,  0.8965,  ...,  0.6125, -0.6687, -0.6399],\n",
            "        ...,\n",
            "        [ 0.3550,  1.0000,  0.7044,  ...,  0.3481, -0.3726, -0.8455],\n",
            "        [ 0.7545,  1.0000,  0.2608,  ..., -0.7127,  0.6819, -0.9128],\n",
            "        [ 0.4838,  1.0000,  0.8839,  ...,  0.6986, -0.5635, -0.6675]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3568,  0.9973, -0.8341,  ..., -0.9324,  0.3338, -0.0544],\n",
            "        [ 0.5135,  1.0000,  0.9249,  ...,  0.6463,  0.0649, -0.8398],\n",
            "        [-0.1101,  0.9996, -0.8127,  ..., -0.9435,  0.4677, -0.5314],\n",
            "        ...,\n",
            "        [ 0.7438,  1.0000,  0.1121,  ..., -0.8969,  0.7412, -0.9388],\n",
            "        [ 0.7045,  1.0000,  0.8691,  ...,  0.6785, -0.4458, -0.6999],\n",
            "        [ 0.5403,  1.0000,  0.7609,  ...,  0.4566, -0.2978, -0.8289]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0077,  1.0000, -0.7461,  ..., -0.9212,  0.5579, -0.5040],\n",
            "        [ 0.4612,  0.9998,  0.8588,  ...,  0.4336,  0.0837, -0.7498],\n",
            "        [ 0.3115,  0.9998,  0.9156,  ...,  0.6664, -0.7150, -0.4736],\n",
            "        ...,\n",
            "        [ 0.1711,  1.0000,  0.8335,  ..., -0.3573,  0.2429, -0.6982],\n",
            "        [ 0.6912,  1.0000,  0.8933,  ...,  0.8059, -0.6189, -0.6399],\n",
            "        [ 0.7283,  1.0000,  0.8429,  ...,  0.7762, -0.6287, -0.5761]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5105,  1.0000,  0.8627,  ...,  0.6854, -0.5080, -0.7079],\n",
            "        [ 0.0886,  1.0000,  0.7209,  ...,  0.0478,  0.3919, -0.7415],\n",
            "        [ 0.5985,  1.0000,  0.8526,  ...,  0.7558,  0.2293, -0.7160],\n",
            "        ...,\n",
            "        [-0.2906,  1.0000, -0.8031,  ..., -0.8854,  0.1629, -0.4821],\n",
            "        [ 0.5704,  1.0000,  0.8696,  ...,  0.6505, -0.5531, -0.6818],\n",
            "        [-0.3475,  0.9967, -0.9014,  ..., -0.9615,  0.2171, -0.1284]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1688,  0.9989, -0.8802,  ..., -0.9008,  0.1470, -0.1577],\n",
            "        [ 0.5987,  1.0000,  0.9340,  ...,  0.5947, -0.2362, -0.7848],\n",
            "        [-0.2895,  0.9987, -0.8558,  ..., -0.9236,  0.1269,  0.0014],\n",
            "        ...,\n",
            "        [ 0.3687,  1.0000,  0.8820,  ...,  0.1180, -0.0304, -0.9228],\n",
            "        [ 0.6891,  1.0000,  0.8935,  ...,  0.6420, -0.3346, -0.6974],\n",
            "        [ 0.5352,  1.0000,  0.8881,  ...,  0.6126, -0.4255, -0.7736]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5002,  0.9999,  0.8605,  ...,  0.4433, -0.2914, -0.7441],\n",
            "        [ 0.5577,  1.0000,  0.8942,  ...,  0.5155, -0.3089, -0.7961],\n",
            "        [-0.0589,  0.9993, -0.2853,  ..., -0.6366,  0.1346, -0.7572],\n",
            "        ...,\n",
            "        [ 0.7091,  1.0000,  0.8352,  ...,  0.3589, -0.4860, -0.6335],\n",
            "        [-0.3649,  1.0000, -0.2733,  ..., -0.8412,  0.5410, -0.7099],\n",
            "        [-0.3243,  0.9994, -0.8716,  ..., -0.9256,  0.5940, -0.2346]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4965,  0.9998, -0.7320,  ..., -0.8429,  0.1953, -0.0885],\n",
            "        [ 0.3892,  1.0000,  0.8699,  ...,  0.3095,  0.1358, -0.7261],\n",
            "        [ 0.4904,  1.0000,  0.8820,  ...,  0.5556, -0.4276, -0.7064],\n",
            "        ...,\n",
            "        [ 0.5996,  1.0000,  0.8990,  ...,  0.6956, -0.5953, -0.4861],\n",
            "        [ 0.6719,  1.0000,  0.8275,  ...,  0.7581, -0.1953, -0.6637],\n",
            "        [-0.1460,  0.9996, -0.8688,  ..., -0.9321,  0.5075, -0.4009]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2464,  1.0000, -0.6234,  ..., -0.9186,  0.6376, -0.7141],\n",
            "        [ 0.6659,  1.0000,  0.9328,  ...,  0.7613, -0.6259, -0.7414],\n",
            "        [ 0.6113,  1.0000,  0.8863,  ...,  0.7669, -0.5679, -0.5730],\n",
            "        ...,\n",
            "        [-0.5147,  0.9998, -0.8658,  ..., -0.9095,  0.4338, -0.3376],\n",
            "        [-0.3519,  0.9990, -0.9037,  ..., -0.8949,  0.1134, -0.3265],\n",
            "        [-0.1304,  0.9997, -0.8173,  ..., -0.9243,  0.5525, -0.6859]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6438,  1.0000, -0.4982,  ..., -0.7301, -0.2481,  0.3031],\n",
            "        [ 0.4802,  1.0000,  0.7497,  ...,  0.0828,  0.1006, -0.9263],\n",
            "        [ 0.0835,  0.9999, -0.8312,  ..., -0.9512,  0.3629, -0.5935],\n",
            "        ...,\n",
            "        [-0.2228,  0.9990, -0.9322,  ..., -0.9299,  0.5106, -0.1810],\n",
            "        [ 0.4148,  1.0000,  0.8510,  ...,  0.3680, -0.4053, -0.5781],\n",
            "        [-0.1823,  0.9997, -0.8825,  ..., -0.9106,  0.2060, -0.1468]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5808,  0.9998,  0.8875,  ...,  0.4571, -0.5817, -0.4438],\n",
            "        [-0.1430,  0.9999, -0.6953,  ..., -0.8935,  0.7274, -0.4227],\n",
            "        [ 0.8468,  1.0000,  0.9528,  ...,  0.1874,  0.3627, -0.9574],\n",
            "        ...,\n",
            "        [ 0.2075,  1.0000,  0.5389,  ..., -0.7209,  0.7314, -0.9499],\n",
            "        [ 0.3680,  0.9999,  0.8512,  ...,  0.7704, -0.4360, -0.5024],\n",
            "        [ 0.7706,  1.0000,  0.9182,  ...,  0.7368, -0.4480, -0.7604]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3690,  0.6895, -0.8962,  ..., -0.9331,  0.2919,  0.2287],\n",
            "        [ 0.7511,  1.0000,  0.8242,  ...,  0.4943, -0.3516, -0.4225],\n",
            "        [-0.2626,  0.9995, -0.6266,  ..., -0.6034, -0.1011, -0.9089],\n",
            "        ...,\n",
            "        [ 0.3202,  0.9996,  0.6131,  ..., -0.3749,  0.3159, -0.9445],\n",
            "        [ 0.7280,  1.0000,  0.8891,  ...,  0.4022, -0.3200, -0.8679],\n",
            "        [ 0.1083,  1.0000,  0.7919,  ...,  0.1928, -0.1635, -0.9058]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0477,  0.9986, -0.8797,  ..., -0.9410,  0.4192, -0.2694],\n",
            "        [ 0.2982,  1.0000,  0.8174,  ..., -0.2139,  0.2382, -0.7069],\n",
            "        [-0.1517,  0.9997, -0.8088,  ..., -0.8631,  0.6149, -0.2909],\n",
            "        ...,\n",
            "        [ 0.5054,  0.9999,  0.8616,  ...,  0.5841, -0.0207, -0.6046],\n",
            "        [ 0.6937,  1.0000,  0.8406,  ...,  0.5338, -0.5060, -0.7515],\n",
            "        [ 0.7204,  1.0000,  0.8310,  ...,  0.7744, -0.2613, -0.6066]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5590,  1.0000,  0.8431,  ...,  0.7060, -0.5824, -0.5415],\n",
            "        [ 0.4048,  1.0000, -0.7845,  ..., -0.9199,  0.2064, -0.2455],\n",
            "        [-0.4620,  0.9987, -0.8464,  ..., -0.8788,  0.3501,  0.2206],\n",
            "        ...,\n",
            "        [ 0.5946,  1.0000,  0.8823,  ...,  0.6322, -0.7188, -0.5961],\n",
            "        [ 0.7058,  1.0000,  0.8382,  ..., -0.0753, -0.2134, -0.8781],\n",
            "        [ 0.5792,  1.0000,  0.8573,  ...,  0.7274, -0.3613, -0.7098]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4004,  1.0000,  0.6913,  ..., -0.0624, -0.1581, -0.9422],\n",
            "        [ 0.0800,  1.0000,  0.4413,  ..., -0.6081,  0.3913, -0.8372],\n",
            "        [-0.2754,  0.9634, -0.9299,  ..., -0.9423,  0.2380, -0.0495],\n",
            "        ...,\n",
            "        [ 0.6742,  1.0000,  0.9041,  ...,  0.7661, -0.5357, -0.6640],\n",
            "        [-0.2583,  0.9999, -0.7116,  ..., -0.9273,  0.5014, -0.4496],\n",
            "        [ 0.5840,  1.0000,  0.8560,  ...,  0.6367, -0.4999, -0.6693]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5379,  1.0000,  0.7907,  ...,  0.6452, -0.4147, -0.7002],\n",
            "        [-0.1968,  0.9996, -0.8403,  ..., -0.8976,  0.2645, -0.4247],\n",
            "        [ 0.5172,  1.0000,  0.8022,  ...,  0.7212, -0.5939, -0.5212],\n",
            "        ...,\n",
            "        [-0.2050,  0.9969, -0.8640,  ..., -0.9087,  0.4223,  0.3454],\n",
            "        [ 0.1097,  1.0000, -0.3566,  ..., -0.7791,  0.8520, -0.9422],\n",
            "        [ 0.3103,  0.9998,  0.8845,  ...,  0.7056, -0.5148, -0.6537]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5415,  1.0000,  0.7314,  ...,  0.7922, -0.1316, -0.6841],\n",
            "        [-0.4593,  0.9996, -0.8874,  ..., -0.9300,  0.0875, -0.1430],\n",
            "        [ 0.5362,  0.9999,  0.9113,  ...,  0.5084, -0.5773, -0.4708],\n",
            "        ...,\n",
            "        [-0.2871,  0.9982, -0.8085,  ..., -0.9085,  0.7718, -0.3492],\n",
            "        [-0.1330,  0.9888, -0.9229,  ..., -0.8775,  0.3252,  0.2599],\n",
            "        [-0.3232,  0.9979, -0.8113,  ..., -0.8574,  0.2930,  0.0436]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4244,  1.0000, -0.7618,  ..., -0.8275,  0.5852, -0.6351],\n",
            "        [ 0.0654,  0.9999, -0.8064,  ..., -0.8876,  0.5321, -0.5159],\n",
            "        [ 0.5303,  1.0000,  0.8686,  ...,  0.7397, -0.7372, -0.5012],\n",
            "        ...,\n",
            "        [ 0.7981,  0.9999,  0.9150,  ..., -0.3249,  0.1698, -0.8879],\n",
            "        [ 0.5456,  1.0000,  0.9032,  ...,  0.8321, -0.7065, -0.7287],\n",
            "        [ 0.0932,  1.0000,  0.7081,  ...,  0.1798,  0.4596, -0.8318]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2665,  1.0000, -0.3176,  ..., -0.7603,  0.7156, -0.8795],\n",
            "        [-0.1765,  1.0000, -0.6389,  ..., -0.7886,  0.5204, -0.8381],\n",
            "        [ 0.2545,  0.9983,  0.8798,  ...,  0.5452, -0.6594, -0.2830],\n",
            "        ...,\n",
            "        [ 0.1560,  1.0000,  0.4783,  ..., -0.7456,  0.4591, -0.9659],\n",
            "        [ 0.2336,  0.9991,  0.9292,  ...,  0.5760, -0.5974, -0.5592],\n",
            "        [ 0.5475,  1.0000,  0.9449,  ...,  0.6229, -0.5201, -0.7556]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4839,  1.0000,  0.8863,  ...,  0.7202, -0.3487, -0.6411],\n",
            "        [ 0.4829,  1.0000,  0.8463,  ...,  0.7353, -0.6777, -0.5019],\n",
            "        [-0.5086,  0.9922, -0.7997,  ..., -0.8952,  0.1299,  0.1889],\n",
            "        ...,\n",
            "        [ 0.5999,  1.0000,  0.8844,  ...,  0.1707, -0.2813, -0.7459],\n",
            "        [ 0.6532,  1.0000,  0.7619,  ...,  0.0377, -0.2568, -0.8856],\n",
            "        [ 0.6756,  1.0000,  0.8278,  ...,  0.3833, -0.3624, -0.3846]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2070,  0.9993, -0.8412,  ..., -0.8649,  0.1731, -0.1765],\n",
            "        [ 0.6162,  1.0000,  0.8913,  ...,  0.8246, -0.3411, -0.5793],\n",
            "        [ 0.5313,  0.9999,  0.9380,  ...,  0.7160, -0.4510, -0.4278],\n",
            "        ...,\n",
            "        [ 0.1092,  0.9997, -0.2394,  ..., -0.7429,  0.2413, -0.8012],\n",
            "        [ 0.0340,  1.0000, -0.3231,  ..., -0.5809,  0.5064, -0.8381],\n",
            "        [ 0.5054,  1.0000,  0.9001,  ...,  0.5895, -0.3537, -0.8194]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5711,  1.0000,  0.8296,  ...,  0.8153, -0.6183, -0.5157],\n",
            "        [ 0.3968,  0.9999,  0.8244,  ...,  0.7021, -0.5287, -0.5336],\n",
            "        [ 0.5360,  1.0000,  0.8538,  ...,  0.7362, -0.3692, -0.6501],\n",
            "        ...,\n",
            "        [-0.2622,  0.9827, -0.8752,  ..., -0.9103,  0.3751, -0.1843],\n",
            "        [-0.3292,  0.9977, -0.8414,  ..., -0.9532,  0.0041,  0.1124],\n",
            "        [ 0.3839,  0.9999,  0.8815,  ...,  0.8143, -0.5846, -0.3704]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5736,  0.9997, -0.8505,  ..., -0.9067,  0.6543, -0.3942],\n",
            "        [-0.5932,  0.9987, -0.8602,  ..., -0.9196,  0.0467, -0.2195],\n",
            "        [ 0.4687,  1.0000,  0.8282,  ...,  0.7020, -0.6198, -0.5832],\n",
            "        ...,\n",
            "        [-0.0455,  0.9997, -0.7295,  ..., -0.8488,  0.7813, -0.7567],\n",
            "        [ 0.5042,  0.9999,  0.8641,  ...,  0.7409, -0.5852, -0.3474],\n",
            "        [-0.0707,  1.0000, -0.5392,  ..., -0.6752,  0.4590, -0.8309]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 6.4350e-01,  9.9997e-01,  8.5918e-01,  ...,  5.7305e-01,\n",
            "         -7.1036e-01, -7.2397e-01],\n",
            "        [ 7.0910e-01,  9.9995e-01,  8.9063e-01,  ...,  6.0550e-01,\n",
            "         -6.1276e-01, -6.0259e-01],\n",
            "        [ 6.4473e-01,  1.0000e+00,  8.0236e-04,  ..., -6.9516e-01,\n",
            "          6.8015e-01, -7.9721e-01],\n",
            "        ...,\n",
            "        [ 5.5853e-01,  9.9999e-01,  7.1072e-01,  ...,  7.2790e-01,\n",
            "         -1.5615e-01, -4.4284e-01],\n",
            "        [-2.4050e-01,  9.9998e-01, -6.7803e-01,  ..., -8.4884e-01,\n",
            "          3.0855e-01, -8.4231e-01],\n",
            "        [ 7.1844e-01,  9.9999e-01,  9.0908e-01,  ...,  6.8042e-01,\n",
            "         -3.3183e-01, -7.9567e-01]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1141,  0.9998, -0.7089,  ..., -0.8877,  0.2760,  0.2775],\n",
            "        [ 0.3638,  0.9999,  0.7913,  ...,  0.7333, -0.6644, -0.4628],\n",
            "        [ 0.3788,  1.0000,  0.9336,  ...,  0.4064,  0.1920, -0.9700],\n",
            "        ...,\n",
            "        [-0.2521,  0.9998, -0.5439,  ..., -0.8161,  0.0156, -0.5618],\n",
            "        [ 0.2374,  1.0000,  0.8843,  ...,  0.6557, -0.5632, -0.4098],\n",
            "        [ 0.5300,  1.0000,  0.9316,  ...,  0.7472, -0.5158, -0.5387]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0660,  0.9985,  0.9279,  ...,  0.4106, -0.4853, -0.3653],\n",
            "        [ 0.7015,  1.0000,  0.8296,  ...,  0.8432, -0.6251, -0.6905],\n",
            "        [-0.4442,  0.9769, -0.9360,  ..., -0.9209,  0.0713,  0.4187],\n",
            "        ...,\n",
            "        [-0.2832,  0.9982, -0.7202,  ..., -0.7614,  0.3541, -0.1018],\n",
            "        [ 0.5966,  1.0000,  0.7926,  ...,  0.6108, -0.2660, -0.5170],\n",
            "        [ 0.4630,  0.9998,  0.8655,  ...,  0.7105, -0.4297, -0.4915]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3523,  0.9999, -0.8141,  ..., -0.8901,  0.2596, -0.4393],\n",
            "        [ 0.5527,  1.0000,  0.9001,  ...,  0.7571, -0.6143, -0.5577],\n",
            "        [ 0.5731,  1.0000,  0.8552,  ...,  0.6013, -0.6563, -0.5744],\n",
            "        ...,\n",
            "        [-0.3074,  1.0000, -0.3097,  ..., -0.6895, -0.0555, -0.8572],\n",
            "        [ 0.6286,  1.0000,  0.8600,  ...,  0.5666, -0.4408, -0.8259],\n",
            "        [ 0.0667,  0.9999, -0.6498,  ..., -0.8811,  0.5105, -0.4139]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4650,  0.9981, -0.9001,  ..., -0.8706,  0.3711,  0.1717],\n",
            "        [ 0.6604,  1.0000,  0.8915,  ...,  0.8771, -0.5454, -0.7433],\n",
            "        [ 0.5222,  1.0000,  0.8723,  ...,  0.5987, -0.2352, -0.8930],\n",
            "        ...,\n",
            "        [ 0.4855,  1.0000,  0.8356,  ..., -0.5040, -0.2086, -0.8981],\n",
            "        [-0.4673,  0.9993, -0.8759,  ..., -0.9364,  0.0320,  0.0716],\n",
            "        [-0.2890,  1.0000, -0.6660,  ..., -0.8557,  0.2181, -0.3843]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4283,  0.9999, -0.1232,  ..., -0.6301, -0.1714, -0.7821],\n",
            "        [-0.3658,  0.9999, -0.7456,  ..., -0.8820,  0.2684, -0.1261],\n",
            "        [-0.1156,  1.0000, -0.2447,  ..., -0.6877, -0.0157, -0.7284],\n",
            "        ...,\n",
            "        [ 0.5868,  0.9999,  0.8828,  ...,  0.8929, -0.5984, -0.1959],\n",
            "        [-0.2856,  1.0000, -0.7447,  ..., -0.7308,  0.3282, -0.5299],\n",
            "        [-0.3443,  0.9964, -0.8619,  ..., -0.8201,  0.0916,  0.2148]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3208,  0.9975,  0.8464,  ...,  0.6918, -0.6311, -0.4711],\n",
            "        [ 0.4816,  1.0000,  0.7818,  ...,  0.6937, -0.0794, -0.7425],\n",
            "        [ 0.5681,  1.0000,  0.8689,  ...,  0.7616, -0.5405, -0.7043],\n",
            "        ...,\n",
            "        [-0.4092,  0.9683, -0.7461,  ..., -0.7965,  0.1992,  0.4317],\n",
            "        [ 0.4689,  0.9999,  0.9350,  ...,  0.7756, -0.5057, -0.6654],\n",
            "        [ 0.5560,  0.9998,  0.8662,  ...,  0.7085, -0.3860, -0.5932]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3647,  0.9998,  0.7823,  ...,  0.3181, -0.5601, -0.6712],\n",
            "        [ 0.6239,  1.0000,  0.8188,  ...,  0.3661, -0.2970, -0.6864],\n",
            "        [-0.0852,  0.9997, -0.8045,  ..., -0.8746,  0.6144, -0.3403],\n",
            "        ...,\n",
            "        [ 0.6468,  1.0000,  0.8427,  ...,  0.8650, -0.5941, -0.5884],\n",
            "        [-0.1030,  0.9979, -0.8639,  ..., -0.9348,  0.5163, -0.0702],\n",
            "        [ 0.6811,  1.0000,  0.9545,  ...,  0.8474, -0.4035, -0.6470]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5371,  0.9939, -0.8615,  ..., -0.9577,  0.1888,  0.3777],\n",
            "        [-0.2905,  0.9999, -0.7369,  ..., -0.9296,  0.3314, -0.3875],\n",
            "        [ 0.8288,  1.0000,  0.8562,  ...,  0.7259, -0.2524, -0.7138],\n",
            "        ...,\n",
            "        [-0.5479,  0.5197, -0.8355,  ..., -0.8985,  0.5492,  0.6578],\n",
            "        [ 0.6829,  1.0000,  0.8837,  ...,  0.8160, -0.6471, -0.5136],\n",
            "        [-0.6424,  0.9931, -0.8439,  ..., -0.8451,  0.2714,  0.0138]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4480,  0.9999,  0.8651,  ...,  0.7769, -0.5237, -0.3804],\n",
            "        [ 0.6084,  1.0000,  0.9044,  ...,  0.8110, -0.6384, -0.4300],\n",
            "        [ 0.1359,  0.9998, -0.3750,  ..., -0.8950,  0.5902, -0.2626],\n",
            "        ...,\n",
            "        [ 0.0756,  1.0000, -0.0949,  ..., -0.6438,  0.6436, -0.9318],\n",
            "        [ 0.4610,  0.9997,  0.9128,  ...,  0.7529, -0.6669, -0.6327],\n",
            "        [ 0.5851,  1.0000,  0.9511,  ...,  0.8140, -0.4181, -0.7333]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2583,  1.0000,  0.8265,  ...,  0.6896, -0.5473, -0.6159],\n",
            "        [ 0.0289,  1.0000, -0.7900,  ..., -0.8378,  0.2857, -0.5690],\n",
            "        [ 0.3143,  1.0000,  0.8984,  ...,  0.6775, -0.4307, -0.6615],\n",
            "        ...,\n",
            "        [ 0.7983,  1.0000,  0.9019,  ...,  0.5136, -0.2116, -0.8511],\n",
            "        [-0.1255,  0.9999, -0.8608,  ..., -0.9085,  0.4202, -0.1193],\n",
            "        [-0.3812,  0.9930, -0.8698,  ..., -0.8978,  0.2536, -0.0106]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1798,  0.9913,  0.2560,  ..., -0.7503, -0.2941, -0.6922],\n",
            "        [ 0.0163,  1.0000, -0.7140,  ..., -0.8829,  0.2152, -0.4911],\n",
            "        [ 0.4551,  1.0000,  0.8483,  ...,  0.7797, -0.4755, -0.7802],\n",
            "        ...,\n",
            "        [-0.5112,  0.9669, -0.8493,  ..., -0.8941,  0.0758, -0.2242],\n",
            "        [ 0.6949,  1.0000,  0.9482,  ...,  0.5891, -0.2911, -0.8797],\n",
            "        [ 0.4310,  0.9999,  0.8781,  ...,  0.8752, -0.5451, -0.5253]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7281,  1.0000,  0.9052,  ...,  0.7499, -0.3914, -0.6657],\n",
            "        [ 0.6978,  1.0000,  0.8294,  ...,  0.7022, -0.5989, -0.6779],\n",
            "        [ 0.5912,  1.0000,  0.8578,  ...,  0.7755, -0.6163, -0.6797],\n",
            "        ...,\n",
            "        [-0.5519,  0.9996, -0.8822,  ..., -0.8851,  0.2008,  0.3240],\n",
            "        [-0.1805,  0.9999, -0.6021,  ..., -0.8089,  0.4363, -0.1634],\n",
            "        [ 0.4326,  1.0000,  0.8998,  ...,  0.8160, -0.5440, -0.5470]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3594,  0.9981, -0.9059,  ..., -0.8869,  0.2388,  0.0141],\n",
            "        [-0.3903,  0.9982, -0.8880,  ..., -0.9123,  0.3900,  0.4842],\n",
            "        [ 0.3948,  1.0000,  0.9049,  ...,  0.3488, -0.1993, -0.8061],\n",
            "        ...,\n",
            "        [ 0.5431,  1.0000,  0.8627,  ...,  0.5526, -0.3638, -0.5228],\n",
            "        [-0.2554,  0.9996, -0.8401,  ..., -0.8727, -0.1433,  0.1866],\n",
            "        [-0.4622,  0.9759, -0.8487,  ..., -0.7911,  0.5584,  0.3080]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2797,  0.9998, -0.6740,  ..., -0.7076,  0.2893, -0.1781],\n",
            "        [ 0.5372,  0.9999,  0.8128,  ...,  0.5392, -0.7774, -0.3751],\n",
            "        [-0.3304,  1.0000, -0.4857,  ..., -0.5947,  0.5496, -0.7777],\n",
            "        ...,\n",
            "        [ 0.4291,  1.0000,  0.9104,  ...,  0.3939, -0.3970, -0.6988],\n",
            "        [ 0.5310,  1.0000,  0.8769,  ...,  0.4436, -0.0947, -0.8629],\n",
            "        [ 0.6008,  1.0000,  0.9357,  ...,  0.3106,  0.0894, -0.7759]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4471,  0.9994,  0.7637,  ...,  0.5755, -0.7552, -0.4926],\n",
            "        [ 0.6255,  1.0000,  0.7863,  ...,  0.6756, -0.4600, -0.3201],\n",
            "        [ 0.5448,  0.9997,  0.9131,  ...,  0.7629, -0.7470, -0.4549],\n",
            "        ...,\n",
            "        [-0.7664,  0.9967, -0.8598,  ..., -0.9019,  0.2108,  0.3099],\n",
            "        [-0.3347,  0.9999, -0.7975,  ..., -0.9205,  0.4521, -0.0765],\n",
            "        [-0.1334,  1.0000, -0.8286,  ..., -0.9102,  0.6088, -0.2541]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2933,  0.9993, -0.8017,  ..., -0.9176,  0.3289, -0.1100],\n",
            "        [-0.5657,  1.0000, -0.8286,  ..., -0.8805,  0.2414, -0.6645],\n",
            "        [ 0.4643,  0.9995,  0.8381,  ...,  0.7816, -0.6322, -0.3073],\n",
            "        ...,\n",
            "        [-0.1958,  0.9995,  0.8397,  ..., -0.5123,  0.1362, -0.8698],\n",
            "        [ 0.5617,  1.0000,  0.7989,  ...,  0.8295, -0.5531, -0.5943],\n",
            "        [ 0.2627,  1.0000,  0.9006,  ...,  0.3247, -0.5855, -0.8003]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3534,  0.9998,  0.9199,  ...,  0.6439, -0.4437, -0.5162],\n",
            "        [ 0.5348,  1.0000,  0.8196,  ...,  0.7162, -0.7109, -0.2755],\n",
            "        [ 0.5200,  1.0000,  0.9608,  ...,  0.4304,  0.0892, -0.9150],\n",
            "        ...,\n",
            "        [-0.5053,  0.9935, -0.8678,  ..., -0.9020,  0.2675,  0.1432],\n",
            "        [ 0.4079,  0.9999,  0.7815,  ...,  0.6982, -0.7163, -0.4572],\n",
            "        [-0.2539,  0.9905, -0.9304,  ..., -0.9394,  0.3600,  0.2534]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5771,  1.0000,  0.9232,  ...,  0.8814, -0.5015, -0.5710],\n",
            "        [-0.4813,  0.9918, -0.8961,  ..., -0.8412,  0.0813,  0.2876],\n",
            "        [ 0.2733,  1.0000, -0.7647,  ..., -0.9097,  0.6905, -0.6129],\n",
            "        ...,\n",
            "        [ 0.3560,  1.0000,  0.9000,  ...,  0.3886, -0.4456, -0.7679],\n",
            "        [ 0.5586,  1.0000,  0.9281,  ...,  0.8293, -0.4434, -0.8041],\n",
            "        [ 0.2331,  1.0000,  0.8740,  ...,  0.5819, -0.4320, -0.4833]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6155,  1.0000,  0.9271,  ...,  0.8794, -0.4711, -0.5452],\n",
            "        [ 0.6864,  1.0000,  0.8835,  ...,  0.6781, -0.2332, -0.8039],\n",
            "        [-0.0118,  0.9624, -0.8711,  ..., -0.8683,  0.1996, -0.1496],\n",
            "        ...,\n",
            "        [ 0.4522,  0.9999, -0.1405,  ..., -0.6331,  0.0532, -0.6579],\n",
            "        [ 0.6481,  0.9996,  0.8490,  ...,  0.5313, -0.4968, -0.6558],\n",
            "        [ 0.5975,  1.0000,  0.9098,  ...,  0.7797, -0.5680, -0.6434]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7140,  1.0000,  0.7859,  ...,  0.7866, -0.5974, -0.5290],\n",
            "        [-0.4455,  1.0000, -0.5292,  ..., -0.9196,  0.2676, -0.7990],\n",
            "        [ 0.2691,  1.0000,  0.9025,  ...,  0.1457, -0.0292, -0.9162],\n",
            "        ...,\n",
            "        [ 0.2567,  0.9997, -0.8815,  ..., -0.9319,  0.6554,  0.1428],\n",
            "        [-0.3584,  0.9984, -0.8875,  ..., -0.8951,  0.3007,  0.1152],\n",
            "        [-0.6060,  0.6972, -0.9399,  ..., -0.8491,  0.3204,  0.5809]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5710,  1.0000,  0.8883,  ...,  0.5879, -0.5699, -0.7188],\n",
            "        [ 0.5092,  1.0000,  0.9370,  ...,  0.7106, -0.2726, -0.9243],\n",
            "        [ 0.4392,  1.0000,  0.8558,  ...,  0.1402, -0.4083, -0.8627],\n",
            "        ...,\n",
            "        [-0.4617,  0.9962, -0.8777,  ..., -0.9308, -0.1734, -0.1068],\n",
            "        [ 0.7188,  1.0000,  0.7035,  ...,  0.7554, -0.2023, -0.8363],\n",
            "        [-0.3882,  0.9805, -0.7565,  ..., -0.8795,  0.5460, -0.4356]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5789,  1.0000,  0.9666,  ...,  0.9057, -0.3011, -0.6338],\n",
            "        [ 0.7147,  1.0000,  0.9118,  ...,  0.7936, -0.5842, -0.4825],\n",
            "        [-0.5821,  0.9997, -0.8140,  ..., -0.9105,  0.7492, -0.3735],\n",
            "        ...,\n",
            "        [ 0.5196,  1.0000,  0.8885,  ...,  0.8981, -0.5351, -0.5362],\n",
            "        [-0.5123,  0.9993, -0.8279,  ..., -0.9115,  0.0010,  0.2357],\n",
            "        [ 0.5421,  1.0000,  0.8821,  ...,  0.7981, -0.2351, -0.5406]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5388,  0.9977, -0.8058,  ..., -0.8353,  0.1188,  0.3899],\n",
            "        [ 0.5795,  0.9999,  0.8465,  ...,  0.8242, -0.7703, -0.5652],\n",
            "        [ 0.3205,  1.0000,  0.9571,  ...,  0.4425, -0.0619, -0.7725],\n",
            "        ...,\n",
            "        [ 0.6604,  1.0000,  0.8619,  ...,  0.8404, -0.4523, -0.6648],\n",
            "        [-0.7068,  0.9997, -0.4558,  ..., -0.9095,  0.1769, -0.3040],\n",
            "        [-0.3783,  0.9999, -0.9178,  ..., -0.8945,  0.3625, -0.2849]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5980,  1.0000,  0.7140,  ...,  0.8033, -0.6378, -0.4313],\n",
            "        [ 0.6655,  0.9999,  0.9036,  ...,  0.8892, -0.6478, -0.5062],\n",
            "        [-0.4440,  0.9967, -0.7587,  ..., -0.8098,  0.5136,  0.0774],\n",
            "        ...,\n",
            "        [-0.5064,  0.9999, -0.8255,  ..., -0.8686,  0.4464, -0.3272],\n",
            "        [ 0.4772,  1.0000,  0.8719,  ...,  0.8477, -0.7319, -0.6000],\n",
            "        [-0.3188,  0.9995, -0.7830,  ..., -0.8851, -0.0099,  0.0755]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0470,  0.9991, -0.8130,  ..., -0.9246, -0.1409, -0.3499],\n",
            "        [ 0.6436,  1.0000,  0.9181,  ...,  0.9159, -0.6385, -0.5174],\n",
            "        [-0.3486,  0.9999, -0.8331,  ..., -0.9012,  0.6917, -0.2591],\n",
            "        ...,\n",
            "        [ 0.5478,  1.0000,  0.8890,  ...,  0.7440, -0.5256, -0.6203],\n",
            "        [ 0.7472,  1.0000,  0.9360,  ...,  0.9030, -0.5879, -0.6629],\n",
            "        [ 0.4360,  0.9999,  0.9336,  ..., -0.1141,  0.0668, -0.7701]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4598,  0.9967, -0.7631,  ..., -0.7773,  0.0952,  0.4711],\n",
            "        [ 0.6267,  1.0000,  0.8677,  ...,  0.8489, -0.5257, -0.5714],\n",
            "        [ 0.4564,  1.0000,  0.8154,  ...,  0.7706, -0.5702, -0.7603],\n",
            "        ...,\n",
            "        [ 0.6933,  0.9999,  0.9247,  ...,  0.7707, -0.5212, -0.7707],\n",
            "        [-0.3934,  0.9969, -0.8014,  ..., -0.7724,  0.3583,  0.4093],\n",
            "        [ 0.1880,  1.0000,  0.1047,  ..., -0.8823,  0.4383, -0.9195]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0542,  1.0000, -0.0627,  ..., -0.9276,  0.1498, -0.7556],\n",
            "        [ 0.4411,  1.0000,  0.9062,  ...,  0.8023, -0.3395, -0.7138],\n",
            "        [ 0.8164,  1.0000,  0.9175,  ...,  0.7538, -0.6076, -0.6216],\n",
            "        ...,\n",
            "        [ 0.6135,  0.9999,  0.8683,  ...,  0.8586, -0.5320, -0.6996],\n",
            "        [ 0.7441,  1.0000,  0.8523,  ...,  0.8088, -0.5581, -0.6583],\n",
            "        [ 0.5305,  1.0000,  0.8993,  ...,  0.8109, -0.2942, -0.6848]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5728,  1.0000, -0.5312,  ..., -0.7320,  0.2490,  0.0711],\n",
            "        [ 0.6125,  1.0000,  0.8533,  ...,  0.8421, -0.4958, -0.4709],\n",
            "        [-0.4158,  1.0000, -0.7455,  ..., -0.8768,  0.5568, -0.6949],\n",
            "        ...,\n",
            "        [-0.2115,  1.0000, -0.7275,  ..., -0.8784,  0.3756, -0.5002],\n",
            "        [ 0.1240,  1.0000, -0.4829,  ..., -0.8491, -0.0041, -0.7387],\n",
            "        [-0.2583,  0.9998, -0.7927,  ..., -0.7808,  0.3040, -0.2037]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3286,  1.0000,  0.8946,  ...,  0.7839, -0.6317, -0.6736],\n",
            "        [ 0.0334,  0.9999, -0.3963,  ..., -0.9201,  0.5792, -0.5267],\n",
            "        [-0.5722,  1.0000, -0.8283,  ..., -0.7537,  0.3961, -0.2032],\n",
            "        ...,\n",
            "        [-0.5573,  1.0000, -0.8382,  ..., -0.8842,  0.5177, -0.2676],\n",
            "        [ 0.5553,  1.0000,  0.8961,  ...,  0.8349, -0.5498, -0.4702],\n",
            "        [ 0.7491,  1.0000,  0.6973,  ...,  0.3258,  0.3334, -0.9095]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6351,  1.0000,  0.9214,  ...,  0.7755, -0.5840, -0.5487],\n",
            "        [ 0.6279,  1.0000,  0.9213,  ...,  0.8130, -0.5371, -0.7185],\n",
            "        [ 0.2876,  0.9999, -0.5767,  ..., -0.7172,  0.6355, -0.5975],\n",
            "        ...,\n",
            "        [ 0.7680,  0.9999,  0.9104,  ...,  0.8323, -0.4559, -0.5420],\n",
            "        [-0.2884,  0.9999, -0.7490,  ..., -0.9404,  0.5650, -0.0799],\n",
            "        [ 0.1685,  1.0000,  0.2567,  ..., -0.7455,  0.2505, -0.8862]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1833,  1.0000, -0.7709,  ..., -0.9055,  0.5407, -0.2202],\n",
            "        [ 0.7513,  1.0000,  0.9363,  ...,  0.8643, -0.4023, -0.7238],\n",
            "        [ 0.6076,  1.0000,  0.8968,  ...,  0.8699, -0.5200, -0.7035],\n",
            "        ...,\n",
            "        [ 0.5601,  1.0000,  0.8926,  ...,  0.8611, -0.4010, -0.7044],\n",
            "        [ 0.5854,  1.0000,  0.9213,  ...,  0.7510, -0.3268, -0.6713],\n",
            "        [-0.0373,  1.0000, -0.5566,  ..., -0.8508,  0.4552, -0.5509]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4172,  1.0000,  0.9313,  ...,  0.8300, -0.4686, -0.6138],\n",
            "        [ 0.4121,  1.0000,  0.9387,  ...,  0.5350, -0.0617, -0.8892],\n",
            "        [ 0.2586,  1.0000,  0.2038,  ..., -0.8403,  0.6871, -0.9652],\n",
            "        ...,\n",
            "        [ 0.2333,  1.0000, -0.0379,  ..., -0.7332,  0.3316, -0.8947],\n",
            "        [-0.6277,  0.9803, -0.8726,  ..., -0.8624, -0.2577,  0.4179],\n",
            "        [ 0.1069,  1.0000, -0.0144,  ..., -0.7021, -0.0373, -0.7849]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7416,  1.0000,  0.9426,  ...,  0.8428, -0.1380, -0.9168],\n",
            "        [-0.2093,  1.0000, -0.8565,  ..., -0.9523,  0.3261, -0.7170],\n",
            "        [ 0.6694,  1.0000,  0.9366,  ...,  0.8110, -0.4838, -0.5527],\n",
            "        ...,\n",
            "        [ 0.7351,  1.0000,  0.9168,  ...,  0.8211, -0.2621, -0.6400],\n",
            "        [-0.0295,  1.0000,  0.0296,  ..., -0.8588,  0.5146, -0.8952],\n",
            "        [ 0.5509,  1.0000,  0.9192,  ...,  0.8161, -0.5849, -0.6131]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6946,  1.0000,  0.9524,  ...,  0.9322, -0.3499, -0.7580],\n",
            "        [ 0.7048,  1.0000,  0.8212,  ...,  0.8652, -0.5883, -0.5122],\n",
            "        [ 0.6486,  1.0000,  0.8808,  ...,  0.8752, -0.4031, -0.6506],\n",
            "        ...,\n",
            "        [ 0.6250,  1.0000,  0.9207,  ...,  0.9063, -0.2164, -0.7629],\n",
            "        [ 0.5562,  0.9999,  0.8835,  ...,  0.8761, -0.3804, -0.3944],\n",
            "        [-0.4888,  0.9979, -0.9043,  ..., -0.9063, -0.1687,  0.0552]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 4.4234e-01,  1.0000e+00,  9.6671e-02,  ..., -5.7824e-01,\n",
            "         -9.4932e-02, -7.6152e-01],\n",
            "        [ 7.4691e-01,  9.9998e-01,  9.0967e-01,  ...,  8.7292e-01,\n",
            "         -4.4068e-01, -7.5452e-01],\n",
            "        [-2.7722e-01,  9.9719e-01, -8.0684e-01,  ..., -9.1625e-01,\n",
            "          5.9068e-01, -5.5512e-01],\n",
            "        ...,\n",
            "        [-7.4191e-02,  1.0000e+00, -1.1593e-02,  ..., -9.3067e-01,\n",
            "         -3.1354e-04, -7.3395e-01],\n",
            "        [ 4.5343e-01,  9.9999e-01,  9.5046e-01,  ...,  6.7145e-01,\n",
            "         -1.7580e-01, -7.2213e-01],\n",
            "        [ 6.3562e-01,  1.0000e+00,  9.4278e-01,  ...,  9.0398e-01,\n",
            "          1.2420e-01, -9.0949e-01]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1760,  0.9988, -0.6141,  ..., -0.8239,  0.2921, -0.5596],\n",
            "        [-0.4227,  1.0000, -0.4548,  ..., -0.8414,  0.6180, -0.4533],\n",
            "        [ 0.5810,  1.0000,  0.9505,  ...,  0.7968, -0.0937, -0.8658],\n",
            "        ...,\n",
            "        [-0.2707,  0.9998, -0.8776,  ..., -0.9345,  0.3393,  0.0046],\n",
            "        [ 0.5939,  1.0000,  0.9439,  ...,  0.8035, -0.2873, -0.7349],\n",
            "        [-0.2152,  0.9996, -0.8824,  ..., -0.9228,  0.1703, -0.2203]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5738,  1.0000,  0.8957,  ...,  0.4689, -0.1894, -0.7085],\n",
            "        [-0.1233,  1.0000, -0.6936,  ..., -0.8575,  0.5395, -0.6397],\n",
            "        [ 0.6446,  1.0000,  0.9437,  ...,  0.8600, -0.5131, -0.7733],\n",
            "        ...,\n",
            "        [ 0.4146,  1.0000,  0.8929,  ...,  0.6926, -0.3458, -0.5399],\n",
            "        [ 0.6621,  1.0000,  0.9415,  ...,  0.6828, -0.2968, -0.7798],\n",
            "        [ 0.6436,  1.0000,  0.9575,  ...,  0.8789,  0.2449, -0.8883]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.8046,  1.0000,  0.8710,  ...,  0.7983, -0.3214, -0.7757],\n",
            "        [-0.6418,  0.9990, -0.8941,  ..., -0.8902,  0.3382,  0.3275],\n",
            "        [-0.4079,  0.9988, -0.8944,  ..., -0.9182,  0.0071,  0.0912],\n",
            "        ...,\n",
            "        [-0.3558,  1.0000, -0.4767,  ..., -0.9281,  0.3970, -0.0874],\n",
            "        [-0.0072,  0.9908, -0.8220,  ..., -0.6617,  0.3410,  0.1848],\n",
            "        [-0.1837,  1.0000, -0.3652,  ..., -0.9488,  0.5281, -0.7692]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5178,  1.0000, -0.4690,  ..., -0.9217, -0.1192, -0.8466],\n",
            "        [-0.4377,  0.9861, -0.8700,  ..., -0.8659,  0.2321,  0.3259],\n",
            "        [-0.2867,  1.0000, -0.6590,  ..., -0.8443,  0.2024, -0.2228],\n",
            "        ...,\n",
            "        [ 0.6774,  1.0000,  0.9506,  ...,  0.8154, -0.4255, -0.4742],\n",
            "        [ 0.5898,  1.0000,  0.9426,  ...,  0.8229, -0.0361, -0.9232],\n",
            "        [-0.0973,  0.9996, -0.8325,  ..., -0.8480,  0.2523,  0.0444]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6846,  1.0000,  0.9354,  ...,  0.8648, -0.3109, -0.6645],\n",
            "        [-0.4657,  1.0000, -0.7492,  ..., -0.8580,  0.2601, -0.5389],\n",
            "        [ 0.4668,  1.0000,  0.9174,  ...,  0.8464, -0.4227, -0.6859],\n",
            "        ...,\n",
            "        [ 0.2716,  1.0000,  0.9396,  ...,  0.8150, -0.3971, -0.7430],\n",
            "        [ 0.3730,  1.0000,  0.3890,  ..., -0.7216,  0.2054, -0.9765],\n",
            "        [ 0.5313,  1.0000,  0.9548,  ...,  0.8749, -0.2551, -0.8209]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6161,  1.0000,  0.9210,  ...,  0.8940,  0.0643, -0.8972],\n",
            "        [ 0.2696,  1.0000, -0.1927,  ..., -0.5597,  0.6589, -0.8735],\n",
            "        [ 0.6185,  1.0000,  0.9092,  ...,  0.8820, -0.4220, -0.8256],\n",
            "        ...,\n",
            "        [ 0.7014,  1.0000,  0.9445,  ...,  0.8030, -0.0652, -0.7651],\n",
            "        [-0.3909,  0.9996, -0.8937,  ..., -0.9172,  0.3828, -0.0081],\n",
            "        [-0.4605,  0.9950, -0.6159,  ..., -0.9011,  0.1833, -0.1142]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5241,  1.0000,  0.8615,  ...,  0.8319,  0.0114, -0.6601],\n",
            "        [ 0.6901,  1.0000,  0.9416,  ...,  0.8542, -0.5167, -0.8400],\n",
            "        [-0.6049,  0.9999, -0.8743,  ..., -0.9154,  0.5071, -0.1668],\n",
            "        ...,\n",
            "        [-0.4856,  0.9988, -0.9100,  ..., -0.9143,  0.3243,  0.3600],\n",
            "        [-0.3993,  1.0000, -0.7200,  ..., -0.8563,  0.4297, -0.6141],\n",
            "        [ 0.7419,  1.0000,  0.8795,  ...,  0.8166,  0.1255, -0.8359]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6720,  1.0000,  0.9518,  ...,  0.8989,  0.2006, -0.9157],\n",
            "        [-0.4385,  0.9984, -0.8083,  ..., -0.9048,  0.0614, -0.0072],\n",
            "        [-0.1015,  0.9977, -0.7125,  ..., -0.8866,  0.1993,  0.3798],\n",
            "        ...,\n",
            "        [ 0.3879,  1.0000,  0.8884,  ...,  0.8078, -0.5468, -0.6690],\n",
            "        [ 0.7366,  1.0000,  0.9669,  ...,  0.8238,  0.1124, -0.9217],\n",
            "        [ 0.7378,  1.0000,  0.9280,  ...,  0.8639, -0.1798, -0.7715]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6710,  1.0000,  0.9104,  ...,  0.8591, -0.4369, -0.7966],\n",
            "        [ 0.3743,  1.0000,  0.9156,  ...,  0.7254, -0.0516, -0.6377],\n",
            "        [-0.5298,  0.9940, -0.8178,  ..., -0.8785,  0.4784, -0.0702],\n",
            "        ...,\n",
            "        [-0.1213,  0.9999, -0.8847,  ..., -0.8602,  0.3785, -0.1247],\n",
            "        [ 0.7367,  1.0000,  0.9187,  ...,  0.8331, -0.4190, -0.7309],\n",
            "        [ 0.6852,  1.0000,  0.9373,  ...,  0.8485,  0.3073, -0.9235]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3030,  1.0000, -0.7545,  ..., -0.9159,  0.4725, -0.6597],\n",
            "        [ 0.7197,  1.0000,  0.9164,  ...,  0.8782, -0.3046, -0.8474],\n",
            "        [-0.6437,  0.9987, -0.8922,  ..., -0.8528,  0.1949,  0.2490],\n",
            "        ...,\n",
            "        [ 0.6070,  1.0000,  0.9594,  ...,  0.8403,  0.0580, -0.9243],\n",
            "        [ 0.5165,  1.0000,  0.8957,  ...,  0.7362, -0.4258, -0.7907],\n",
            "        [ 0.7060,  1.0000,  0.8819,  ...,  0.6208, -0.1276, -0.8149]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4161,  0.9991, -0.4280,  ..., -0.8247,  0.1364, -0.6194],\n",
            "        [ 0.2542,  1.0000,  0.8348,  ...,  0.7775, -0.2533, -0.7300],\n",
            "        [-0.4070,  0.9710, -0.8193,  ..., -0.8846,  0.2656,  0.0994],\n",
            "        ...,\n",
            "        [ 0.5903,  1.0000,  0.9508,  ...,  0.8568,  0.1993, -0.9079],\n",
            "        [ 0.3203,  0.9999,  0.8050,  ...,  0.1869, -0.3996, -0.9165],\n",
            "        [-0.6653,  1.0000, -0.8125,  ..., -0.9150,  0.3217, -0.2279]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 5.4202e-01,  1.0000e+00,  9.4472e-01,  ...,  8.3571e-01,\n",
            "          3.8231e-04, -8.0725e-01],\n",
            "        [ 6.1641e-01,  1.0000e+00,  9.6665e-01,  ...,  6.5694e-01,\n",
            "          2.6848e-01, -9.1307e-01],\n",
            "        [ 3.1424e-01,  1.0000e+00, -3.6563e-01,  ..., -7.9652e-01,\n",
            "          6.3361e-01, -9.3218e-01],\n",
            "        ...,\n",
            "        [-2.3856e-01,  9.9998e-01, -7.0843e-01,  ..., -9.1110e-01,\n",
            "          5.2895e-01, -3.2216e-01],\n",
            "        [ 6.6883e-01,  1.0000e+00,  9.2236e-01,  ...,  8.2572e-01,\n",
            "         -3.2903e-01, -7.6538e-01],\n",
            "        [-5.4309e-01,  9.9991e-01, -7.8493e-01,  ..., -8.5578e-01,\n",
            "          6.0243e-01, -4.5325e-01]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6621,  1.0000,  0.9132,  ...,  0.8585, -0.1063, -0.7373],\n",
            "        [ 0.8375,  1.0000,  0.9134,  ...,  0.7876, -0.4403, -0.6328],\n",
            "        [ 0.5074,  1.0000,  0.9536,  ...,  0.7779, -0.2372, -0.8979],\n",
            "        ...,\n",
            "        [-0.1111,  0.9999, -0.7483,  ..., -0.8692,  0.7153, -0.6981],\n",
            "        [ 0.1360,  1.0000, -0.1869,  ..., -0.8223,  0.5912, -0.9428],\n",
            "        [ 0.3509,  1.0000,  0.9147,  ...,  0.7320, -0.0078, -0.8164]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6185,  0.9999, -0.8320,  ..., -0.8956,  0.5501, -0.7347],\n",
            "        [-0.5483,  0.9998, -0.8283,  ..., -0.9102,  0.2401,  0.2970],\n",
            "        [-0.1066,  0.9994, -0.7419,  ..., -0.8658,  0.5781,  0.0017],\n",
            "        ...,\n",
            "        [-0.5084,  0.6221, -0.9361,  ..., -0.9146,  0.2413,  0.2670],\n",
            "        [ 0.6650,  1.0000,  0.8837,  ...,  0.7972, -0.4995, -0.7836],\n",
            "        [-0.6268,  0.9988, -0.8485,  ..., -0.7184, -0.0504,  0.3467]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5164,  1.0000,  0.9317,  ...,  0.8630, -0.2494, -0.7000],\n",
            "        [ 0.6489,  1.0000,  0.8915,  ...,  0.8764, -0.4434, -0.8037],\n",
            "        [ 0.1321,  1.0000, -0.4375,  ..., -0.8864,  0.5679, -0.8487],\n",
            "        ...,\n",
            "        [ 0.6494,  1.0000,  0.9167,  ...,  0.7678, -0.4848, -0.7851],\n",
            "        [ 0.6933,  1.0000,  0.9098,  ...,  0.8384, -0.2739, -0.7898],\n",
            "        [ 0.6975,  1.0000,  0.8790,  ...,  0.6621, -0.2277, -0.7739]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7274,  1.0000,  0.9330,  ...,  0.8887, -0.0069, -0.6220],\n",
            "        [ 0.5555,  1.0000,  0.6751,  ..., -0.1107,  0.3544, -0.9625],\n",
            "        [ 0.6761,  1.0000,  0.9236,  ...,  0.8298,  0.0064, -0.7047],\n",
            "        ...,\n",
            "        [ 0.6189,  1.0000,  0.9615,  ...,  0.7904, -0.0728, -0.7557],\n",
            "        [ 0.6939,  1.0000,  0.8976,  ..., -0.0546,  0.4094, -0.9402],\n",
            "        [-0.4184,  0.9348, -0.8171,  ..., -0.8344,  0.0282,  0.1114]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4931,  0.9381, -0.9192,  ..., -0.9294,  0.0181,  0.6705],\n",
            "        [ 0.5060,  1.0000,  0.8761,  ...,  0.6151, -0.0446, -0.6970],\n",
            "        [ 0.6860,  1.0000,  0.9368,  ...,  0.8704, -0.4022, -0.7535],\n",
            "        ...,\n",
            "        [ 0.3895,  1.0000,  0.9028,  ...,  0.7692, -0.4108, -0.4698],\n",
            "        [ 0.5909,  1.0000,  0.9397,  ...,  0.8981, -0.2167, -0.7863],\n",
            "        [ 0.6352,  1.0000,  0.9525,  ...,  0.9070,  0.0608, -0.8392]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3908,  0.9997, -0.0709,  ..., -0.6149,  0.3944, -0.6413],\n",
            "        [-0.1391,  0.9996, -0.8911,  ..., -0.9399,  0.5524,  0.2343],\n",
            "        [-0.5228,  0.9772, -0.8971,  ..., -0.9230,  0.4993,  0.1968],\n",
            "        ...,\n",
            "        [-0.4085,  0.9982, -0.5926,  ..., -0.8247,  0.7265, -0.2273],\n",
            "        [-0.1646,  0.9999, -0.8468,  ..., -0.8887,  0.2943,  0.1541],\n",
            "        [-0.2819,  0.9978, -0.9142,  ..., -0.9295,  0.1677,  0.3458]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6896,  1.0000,  0.8904,  ...,  0.6768, -0.4386, -0.6889],\n",
            "        [-0.2879,  0.9693, -0.9064,  ..., -0.8989,  0.1228,  0.2889],\n",
            "        [-0.2692,  0.9975, -0.8465,  ..., -0.8866,  0.4340,  0.0458],\n",
            "        ...,\n",
            "        [ 0.2336,  1.0000,  0.1817,  ..., -0.7892,  0.8037, -0.8821],\n",
            "        [-0.3766,  0.9998, -0.7834,  ..., -0.8907,  0.4178, -0.2440],\n",
            "        [ 0.5702,  1.0000,  0.9493,  ...,  0.6764, -0.0016, -0.7089]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4158,  0.9944, -0.8466,  ..., -0.8887,  0.2475, -0.1799],\n",
            "        [ 0.3968,  1.0000,  0.9067,  ...,  0.8529, -0.2281, -0.7950],\n",
            "        [ 0.7034,  1.0000,  0.7383,  ...,  0.3508, -0.4942, -0.7970],\n",
            "        ...,\n",
            "        [-0.4971,  0.9814, -0.8249,  ..., -0.8332,  0.3435,  0.0170],\n",
            "        [-0.4318,  0.9965, -0.9209,  ..., -0.9463,  0.1345,  0.2336],\n",
            "        [-0.5548,  0.9911, -0.8831,  ..., -0.8834,  0.3342,  0.1308]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5393,  1.0000,  0.9442,  ...,  0.9115,  0.2656, -0.8988],\n",
            "        [ 0.6405,  1.0000,  0.8678,  ...,  0.6927, -0.4942, -0.7806],\n",
            "        [ 0.5773,  1.0000,  0.9214,  ...,  0.7649, -0.1403, -0.8440],\n",
            "        ...,\n",
            "        [-0.4845,  1.0000, -0.5512,  ..., -0.7528,  0.5699, -0.2062],\n",
            "        [ 0.5768,  1.0000,  0.9670,  ...,  0.8836,  0.0825, -0.9068],\n",
            "        [ 0.7211,  1.0000,  0.8648,  ...,  0.8848, -0.4635, -0.6761]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0579,  0.9993, -0.8598,  ..., -0.8962,  0.3791,  0.0316],\n",
            "        [ 0.5969,  1.0000,  0.9097,  ...,  0.6553, -0.3001, -0.5789],\n",
            "        [-0.4757,  0.9979, -0.8247,  ..., -0.9604,  0.4910,  0.1211],\n",
            "        ...,\n",
            "        [ 0.3451,  1.0000,  0.7845,  ...,  0.5311, -0.3484, -0.6173],\n",
            "        [ 0.8609,  1.0000,  0.8710,  ...,  0.3741, -0.1547, -0.9312],\n",
            "        [-0.3800,  0.9974, -0.8561,  ..., -0.8029,  0.2095,  0.1556]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6030,  1.0000,  0.9344,  ...,  0.8085, -0.3149, -0.7563],\n",
            "        [ 0.6547,  1.0000,  0.8208,  ...,  0.1600,  0.6333, -0.9389],\n",
            "        [-0.5095,  0.9973, -0.7588,  ..., -0.8480,  0.2344, -0.0362],\n",
            "        ...,\n",
            "        [-0.5368,  0.9996, -0.8785,  ..., -0.8864,  0.3061,  0.0052],\n",
            "        [ 0.6711,  1.0000,  0.9471,  ...,  0.8792, -0.2975, -0.8985],\n",
            "        [-0.6161,  0.9923, -0.9253,  ..., -0.8896,  0.2951,  0.3548]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5511,  0.9964, -0.9374,  ..., -0.9232,  0.0508, -0.1903],\n",
            "        [-0.4857,  0.8969, -0.9327,  ..., -0.9408,  0.3022,  0.0399],\n",
            "        [-0.3697,  0.9999, -0.8982,  ..., -0.9050,  0.2343,  0.4326],\n",
            "        ...,\n",
            "        [ 0.6794,  1.0000,  0.9524,  ...,  0.9094,  0.1156, -0.8388],\n",
            "        [ 0.5227,  1.0000,  0.8735,  ...,  0.7897, -0.6485, -0.7326],\n",
            "        [ 0.5211,  1.0000,  0.9528,  ...,  0.9047, -0.4544, -0.7930]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5643,  0.9989, -0.9133,  ..., -0.9384,  0.0150,  0.3801],\n",
            "        [-0.2898,  0.9995, -0.8633,  ..., -0.7836,  0.3776, -0.0952],\n",
            "        [ 0.6055,  1.0000,  0.9191,  ...,  0.7748,  0.1495, -0.9550],\n",
            "        ...,\n",
            "        [ 0.4033,  1.0000,  0.8067,  ...,  0.5237, -0.0582, -0.8813],\n",
            "        [-0.3337,  0.9401, -0.8984,  ..., -0.9274,  0.3698,  0.2371],\n",
            "        [ 0.5118,  1.0000,  0.7634,  ...,  0.3855,  0.0342, -0.8941]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7457,  1.0000,  0.7488,  ...,  0.7477, -0.3057, -0.8260],\n",
            "        [ 0.4706,  1.0000,  0.9070,  ...,  0.6501, -0.3006, -0.5836],\n",
            "        [ 0.4759,  1.0000,  0.9368,  ...,  0.7258, -0.3928, -0.8680],\n",
            "        ...,\n",
            "        [-0.3162,  0.9988, -0.8855,  ..., -0.8596, -0.1319,  0.1944],\n",
            "        [ 0.3980,  1.0000,  0.9456,  ...,  0.8010, -0.4910, -0.7061],\n",
            "        [-0.3899,  0.9928, -0.8973,  ..., -0.8752,  0.0867,  0.0199]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7106,  1.0000,  0.9575,  ...,  0.8655, -0.0503, -0.8393],\n",
            "        [ 0.3979,  1.0000,  0.8219,  ...,  0.4776, -0.3647, -0.8253],\n",
            "        [ 0.5857,  1.0000,  0.9102,  ...,  0.6513, -0.4194, -0.7694],\n",
            "        ...,\n",
            "        [ 0.3120,  1.0000,  0.9433,  ...,  0.8987,  0.1124, -0.7287],\n",
            "        [-0.4107,  0.9716, -0.8924,  ..., -0.9060,  0.0716,  0.4740],\n",
            "        [ 0.5637,  1.0000,  0.9367,  ...,  0.7478,  0.1067, -0.8842]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5305,  0.9892, -0.9010,  ..., -0.9287,  0.2754, -0.0881],\n",
            "        [-0.4585,  0.9987, -0.8924,  ..., -0.8757,  0.1471,  0.0423],\n",
            "        [-0.5321,  0.9952, -0.9023,  ..., -0.9151,  0.1339,  0.2640],\n",
            "        ...,\n",
            "        [ 0.6347,  1.0000,  0.9273,  ...,  0.8811, -0.4250, -0.5847],\n",
            "        [ 0.4081,  1.0000,  0.6949,  ...,  0.2052, -0.6406, -0.7820],\n",
            "        [ 0.7148,  1.0000,  0.9111,  ...,  0.6997, -0.3301, -0.7636]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4672,  0.9868, -0.8740,  ..., -0.7557, -0.3358,  0.4794],\n",
            "        [ 0.6165,  1.0000,  0.9314,  ...,  0.7394, -0.1816, -0.7123],\n",
            "        [-0.5809,  0.9970, -0.9138,  ..., -0.8873,  0.0607,  0.3429],\n",
            "        ...,\n",
            "        [-0.0958,  1.0000, -0.1562,  ..., -0.8239,  0.5692, -0.8625],\n",
            "        [-0.4811,  0.8624, -0.8775,  ..., -0.9152,  0.3457,  0.0541],\n",
            "        [ 0.4815,  1.0000,  0.8088,  ...,  0.7036, -0.2552, -0.7006]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6463,  1.0000,  0.9556,  ...,  0.8699, -0.0216, -0.9112],\n",
            "        [ 0.6567,  1.0000,  0.8831,  ...,  0.7742, -0.3534, -0.6081],\n",
            "        [ 0.5607,  1.0000,  0.9395,  ...,  0.7649,  0.3603, -0.9232],\n",
            "        ...,\n",
            "        [-0.5083,  0.9961, -0.8995,  ..., -0.9330,  0.3102,  0.1803],\n",
            "        [ 0.7546,  1.0000,  0.3951,  ..., -0.3127, -0.0344, -0.8705],\n",
            "        [ 0.6442,  1.0000,  0.9146,  ...,  0.8388, -0.5312, -0.7543]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3978,  0.9943, -0.9134,  ..., -0.9158,  0.4914, -0.1039],\n",
            "        [-0.3994,  0.7043, -0.9294,  ..., -0.8915,  0.1140,  0.3223],\n",
            "        [-0.1467,  0.9998, -0.7801,  ..., -0.9581,  0.7393, -0.6399],\n",
            "        ...,\n",
            "        [-0.3769,  0.9107, -0.8050,  ..., -0.9350,  0.3597,  0.0754],\n",
            "        [ 0.2631,  1.0000,  0.8397,  ...,  0.7038, -0.4495, -0.6327],\n",
            "        [-0.4970,  0.9735, -0.8877,  ..., -0.8887,  0.2992,  0.3575]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3708,  1.0000,  0.8405,  ...,  0.1980,  0.1726, -0.8901],\n",
            "        [ 0.4166,  1.0000,  0.9137,  ...,  0.7984, -0.5692, -0.4694],\n",
            "        [-0.4964,  0.6678, -0.9470,  ..., -0.8853,  0.0597,  0.2834],\n",
            "        ...,\n",
            "        [ 0.7071,  1.0000,  0.9373,  ...,  0.8429, -0.2370, -0.8737],\n",
            "        [-0.3245,  0.9986, -0.8102,  ..., -0.8528,  0.5057,  0.0143],\n",
            "        [ 0.7112,  1.0000,  0.9373,  ...,  0.8439, -0.3562, -0.7556]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1462,  1.0000, -0.0438,  ..., -0.8556,  0.7967, -0.8243],\n",
            "        [ 0.5278,  1.0000,  0.8799,  ...,  0.7297,  0.0050, -0.6650],\n",
            "        [-0.5463, -0.0612, -0.9207,  ..., -0.9102, -0.0041,  0.4502],\n",
            "        ...,\n",
            "        [ 0.5479,  1.0000,  0.9491,  ...,  0.9309, -0.2433, -0.7764],\n",
            "        [-0.4057,  0.9987, -0.9289,  ..., -0.8984,  0.0743,  0.1244],\n",
            "        [ 0.5894,  1.0000,  0.8874,  ...,  0.8997, -0.3647, -0.6099]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4567,  1.0000,  0.8455,  ..., -0.1069, -0.1760, -0.8479],\n",
            "        [ 0.6683,  1.0000,  0.9000,  ...,  0.7784, -0.4167, -0.6049],\n",
            "        [-0.5422,  0.9473, -0.9034,  ..., -0.9340,  0.2041,  0.2603],\n",
            "        ...,\n",
            "        [ 0.4660,  1.0000,  0.9489,  ...,  0.7905,  0.0076, -0.8633],\n",
            "        [ 0.6032,  1.0000,  0.8689,  ...,  0.8185, -0.5938, -0.6554],\n",
            "        [-0.6697,  0.7966, -0.8478,  ..., -0.8910,  0.3002,  0.4703]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4550,  0.9991, -0.8502,  ..., -0.8667,  0.2601,  0.1523],\n",
            "        [ 0.4241,  1.0000,  0.9081,  ...,  0.8041, -0.4299, -0.7355],\n",
            "        [ 0.4223,  1.0000,  0.9563,  ...,  0.5281, -0.3482, -0.8863],\n",
            "        ...,\n",
            "        [ 0.7007,  1.0000,  0.8942,  ...,  0.3068, -0.1730, -0.9676],\n",
            "        [ 0.7911,  1.0000,  0.7730,  ...,  0.4590, -0.0245, -0.9494],\n",
            "        [-0.6989,  0.9947, -0.8982,  ..., -0.9270, -0.1279,  0.1505]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4924, -0.4456, -0.9014,  ..., -0.9132,  0.4408,  0.3927],\n",
            "        [-0.6778,  0.9349, -0.9483,  ..., -0.9376,  0.3750,  0.5736],\n",
            "        [-0.5542,  0.9853, -0.8736,  ..., -0.8747,  0.2629,  0.4228],\n",
            "        ...,\n",
            "        [-0.7611,  0.9994, -0.7436,  ..., -0.8285,  0.3472, -0.1717],\n",
            "        [-0.3645,  0.9521, -0.7948,  ..., -0.8936,  0.1672,  0.3990],\n",
            "        [-0.5942,  0.6712, -0.8464,  ..., -0.9028,  0.1378,  0.3818]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5185,  0.9966, -0.8106,  ..., -0.8560,  0.6432,  0.0522],\n",
            "        [-0.5946,  0.7069, -0.8048,  ..., -0.8291,  0.2580, -0.5524],\n",
            "        [-0.0260,  0.9997, -0.8566,  ..., -0.8284,  0.0915, -0.2733],\n",
            "        ...,\n",
            "        [ 0.5829,  1.0000,  0.9536,  ...,  0.4414,  0.2682, -0.9746],\n",
            "        [-0.4380,  0.9505, -0.8321,  ..., -0.9157,  0.3050, -0.1025],\n",
            "        [ 0.6931,  1.0000,  0.8882,  ...,  0.5399,  0.3921, -0.9504]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2981,  0.7806, -0.8974,  ..., -0.8721,  0.1473,  0.3780],\n",
            "        [ 0.6677,  1.0000,  0.9575,  ...,  0.6514,  0.0393, -0.7928],\n",
            "        [-0.3868,  0.9923, -0.9020,  ..., -0.7867,  0.3434,  0.3069],\n",
            "        ...,\n",
            "        [-0.1772,  0.9997, -0.8170,  ..., -0.8388,  0.2016, -0.0773],\n",
            "        [ 0.5830,  1.0000,  0.9440,  ...,  0.8733, -0.0104, -0.8148],\n",
            "        [-0.4474,  0.9950, -0.8503,  ..., -0.8816,  0.4608,  0.0550]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6089,  0.9838, -0.8331,  ..., -0.8246,  0.0389,  0.0897],\n",
            "        [ 0.5906,  1.0000,  0.9232,  ...,  0.8118, -0.3258, -0.8250],\n",
            "        [ 0.6565,  1.0000,  0.9112,  ...,  0.7875, -0.2113, -0.5366],\n",
            "        ...,\n",
            "        [-0.1849,  0.9979, -0.8394,  ..., -0.9288,  0.5474,  0.1105],\n",
            "        [-0.4781,  0.9848, -0.8831,  ..., -0.9322,  0.0498,  0.3874],\n",
            "        [ 0.6309,  1.0000,  0.9187,  ...,  0.8823, -0.4915, -0.7807]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2260,  0.9994, -0.8675,  ..., -0.9232,  0.4063, -0.3034],\n",
            "        [-0.5708, -0.1542, -0.8765,  ..., -0.8963,  0.1293,  0.1421],\n",
            "        [ 0.1186,  1.0000, -0.6460,  ..., -0.7398,  0.4442, -0.6773],\n",
            "        ...,\n",
            "        [-0.2168,  1.0000, -0.7527,  ..., -0.8422,  0.2362, -0.8293],\n",
            "        [-0.4764,  1.0000,  0.8415,  ..., -0.0743,  0.2431, -0.9366],\n",
            "        [ 0.7309,  1.0000,  0.9006,  ...,  0.8277, -0.1062, -0.6265]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0990,  1.0000,  0.8642,  ...,  0.0698, -0.0778, -0.4786],\n",
            "        [ 0.6634,  1.0000, -0.3606,  ..., -0.8055,  0.6204, -0.8323],\n",
            "        [-0.6215,  0.9999, -0.8242,  ..., -0.8904,  0.2698,  0.0197],\n",
            "        ...,\n",
            "        [-0.4307,  0.9207, -0.9414,  ..., -0.9444, -0.2178,  0.3406],\n",
            "        [-0.3605,  1.0000, -0.8296,  ..., -0.8964,  0.7056, -0.3638],\n",
            "        [ 0.6931,  1.0000,  0.9034,  ...,  0.6302, -0.1915, -0.8999]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7174,  1.0000,  0.8454,  ...,  0.7448, -0.4760, -0.6278],\n",
            "        [ 0.5049,  1.0000,  0.8739,  ...,  0.5759, -0.0173, -0.8360],\n",
            "        [ 0.6699,  1.0000,  0.9394,  ...,  0.8864,  0.0685, -0.8976],\n",
            "        ...,\n",
            "        [ 0.5160,  1.0000,  0.9277,  ...,  0.8729,  0.1389, -0.8696],\n",
            "        [ 0.4099,  1.0000,  0.8447,  ...,  0.8591, -0.6414, -0.7205],\n",
            "        [ 0.0088,  1.0000, -0.1941,  ..., -0.8438,  0.3115, -0.3912]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1141,  0.9997, -0.9702,  ..., -0.9065,  0.3652, -0.3882],\n",
            "        [ 0.5327,  1.0000,  0.9373,  ...,  0.8233,  0.2643, -0.9264],\n",
            "        [ 0.1595,  1.0000, -0.4099,  ..., -0.7100,  0.6342, -0.8636],\n",
            "        ...,\n",
            "        [ 0.6308,  1.0000,  0.9639,  ...,  0.8166,  0.0709, -0.8515],\n",
            "        [ 0.5546,  1.0000,  0.9347,  ...,  0.8967, -0.3699, -0.8501],\n",
            "        [-0.2284,  0.9980, -0.8361,  ..., -0.9022,  0.1877, -0.0743]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1683,  1.0000, -0.0090,  ..., -0.7718,  0.6835, -0.9484],\n",
            "        [ 0.4833,  1.0000,  0.9308,  ...,  0.8761, -0.0827, -0.8257],\n",
            "        [-0.1862,  0.9970, -0.9472,  ..., -0.9250,  0.2691,  0.0037],\n",
            "        ...,\n",
            "        [ 0.1425,  1.0000, -0.7771,  ..., -0.8815,  0.2454, -0.2664],\n",
            "        [ 0.6141,  1.0000,  0.9520,  ...,  0.9030,  0.0204, -0.8728],\n",
            "        [ 0.7037,  1.0000,  0.9399,  ...,  0.6747, -0.0683, -0.8399]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5503,  1.0000, -0.7060,  ..., -0.8342,  0.3946, -0.7710],\n",
            "        [ 0.4833,  1.0000, -0.1745,  ..., -0.8682,  0.5987, -0.7131],\n",
            "        [ 0.6200,  1.0000,  0.9289,  ...,  0.1087,  0.0720, -0.9343],\n",
            "        ...,\n",
            "        [ 0.6930,  1.0000,  0.5926,  ..., -0.3558,  0.5476, -0.9060],\n",
            "        [-0.3233,  0.9869, -0.9252,  ..., -0.9347,  0.1954,  0.0415],\n",
            "        [-0.0773,  0.9646, -0.8499,  ..., -0.9043,  0.5401, -0.3830]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1182,  0.9002, -0.9418,  ..., -0.9104,  0.1322,  0.1082],\n",
            "        [ 0.6072,  1.0000,  0.9516,  ...,  0.8142, -0.3503, -0.5583],\n",
            "        [-0.4697,  1.0000, -0.8584,  ..., -0.9254, -0.0820, -0.0592],\n",
            "        ...,\n",
            "        [ 0.5558,  1.0000,  0.9034,  ...,  0.7419, -0.3723, -0.7713],\n",
            "        [-0.2660,  0.9991, -0.8907,  ..., -0.9120,  0.2576, -0.1511],\n",
            "        [ 0.6330,  1.0000,  0.9217,  ...,  0.8672,  0.0593, -0.8667]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5763,  1.0000,  0.9129,  ...,  0.7705, -0.3971, -0.5623],\n",
            "        [ 0.5325,  1.0000,  0.9214,  ...,  0.8806, -0.4660, -0.7123],\n",
            "        [-0.3047,  0.9995, -0.9132,  ..., -0.9330,  0.3767,  0.1797],\n",
            "        ...,\n",
            "        [-0.5119,  0.9883, -0.7537,  ..., -0.8741,  0.3510, -0.0912],\n",
            "        [-0.3679,  1.0000, -0.8854,  ..., -0.8026,  0.2693, -0.4269],\n",
            "        [-0.2175,  0.9894, -0.8705,  ..., -0.8441,  0.3262, -0.0607]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4040,  0.9961, -0.8773,  ..., -0.9164,  0.2267,  0.4794],\n",
            "        [ 0.5953,  1.0000,  0.8721,  ...,  0.7611, -0.5004, -0.6615],\n",
            "        [ 0.4800,  1.0000,  0.8625,  ...,  0.8042, -0.5762, -0.4609],\n",
            "        ...,\n",
            "        [ 0.4460,  1.0000,  0.8546,  ...,  0.8420, -0.3032, -0.7454],\n",
            "        [ 0.6443,  1.0000,  0.9095,  ...,  0.8311,  0.1385, -0.7456],\n",
            "        [-0.3321,  0.9979, -0.8311,  ..., -0.9335, -0.0826,  0.0703]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6563,  1.0000,  0.9358,  ...,  0.7229, -0.6542, -0.4462],\n",
            "        [ 0.2750,  1.0000,  0.9185,  ...,  0.6879,  0.1891, -0.6272],\n",
            "        [ 0.5985,  1.0000,  0.9434,  ...,  0.8333,  0.2548, -0.9033],\n",
            "        ...,\n",
            "        [ 0.4714,  1.0000,  0.9052,  ...,  0.8175, -0.5950, -0.6132],\n",
            "        [ 0.5502,  1.0000, -0.7242,  ..., -0.8482,  0.7502, -0.7144],\n",
            "        [ 0.6466,  1.0000,  0.9557,  ...,  0.8062, -0.1876, -0.7311]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1792,  0.9999, -0.8737,  ..., -0.8778,  0.5046, -0.4053],\n",
            "        [ 0.7076,  1.0000,  0.9364,  ...,  0.8112, -0.2612, -0.7821],\n",
            "        [ 0.6078,  1.0000,  0.9575,  ...,  0.6930,  0.3042, -0.9279],\n",
            "        ...,\n",
            "        [ 0.3086,  1.0000, -0.7559,  ..., -0.8956,  0.3714, -0.5079],\n",
            "        [-0.5048,  0.9982, -0.9061,  ..., -0.8730,  0.2975,  0.0924],\n",
            "        [ 0.3893,  1.0000,  0.7161,  ..., -0.3302, -0.0900, -0.8586]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0651,  0.9987, -0.3300,  ..., -0.7747,  0.3532, -0.0393],\n",
            "        [-0.0815,  0.9978, -0.8789,  ..., -0.9149,  0.2288, -0.0666],\n",
            "        [ 0.5498,  1.0000,  0.8394,  ...,  0.6494, -0.1987, -0.8621],\n",
            "        ...,\n",
            "        [-0.2604,  0.9749, -0.8461,  ..., -0.8343,  0.2459,  0.2059],\n",
            "        [-0.1047,  0.9992, -0.6843,  ..., -0.8969,  0.1718, -0.1335],\n",
            "        [ 0.6970,  1.0000,  0.9587,  ...,  0.8188, -0.1032, -0.8466]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5058,  1.0000, -0.8744,  ..., -0.8916,  0.2889,  0.1610],\n",
            "        [-0.2861,  0.9993, -0.7117,  ..., -0.7851,  0.2839, -0.6469],\n",
            "        [ 0.4544,  1.0000,  0.8891,  ...,  0.8288, -0.5583, -0.6394],\n",
            "        ...,\n",
            "        [-0.4041,  0.9999, -0.7335,  ..., -0.9007,  0.4325, -0.0782],\n",
            "        [ 0.5865,  1.0000,  0.9380,  ...,  0.8621, -0.3388, -0.7338],\n",
            "        [-0.2377,  0.9928, -0.7561,  ..., -0.9124,  0.2978,  0.0170]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1264,  0.9957, -0.6201,  ..., -0.8332,  0.1583, -0.2501],\n",
            "        [-0.1303,  1.0000,  0.0883,  ..., -0.7704,  0.7958, -0.8352],\n",
            "        [ 0.1098,  1.0000, -0.7898,  ..., -0.9082,  0.5029, -0.7114],\n",
            "        ...,\n",
            "        [ 0.5816,  1.0000,  0.8868,  ...,  0.8685, -0.4141, -0.6210],\n",
            "        [ 0.5130,  0.9999, -0.4807,  ..., -0.7473,  0.5586, -0.5695],\n",
            "        [-0.2322,  1.0000, -0.5372,  ..., -0.3911,  0.5124, -0.7513]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2087,  0.9938, -0.0868,  ..., -0.6939,  0.1398, -0.6848],\n",
            "        [ 0.4514,  1.0000,  0.8749,  ...,  0.7565, -0.5147, -0.5515],\n",
            "        [ 0.6948,  1.0000,  0.9295,  ...,  0.8678,  0.0106, -0.8007],\n",
            "        ...,\n",
            "        [-0.2578,  1.0000, -0.6771,  ..., -0.9315,  0.2466, -0.6580],\n",
            "        [ 0.7258,  1.0000,  0.9113,  ...,  0.8439, -0.3730, -0.6626],\n",
            "        [ 0.3872,  1.0000, -0.6096,  ..., -0.6381,  0.4199, -0.6327]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5731,  1.0000,  0.0334,  ..., -0.7163,  0.8689, -0.6535],\n",
            "        [ 0.2986,  1.0000,  0.8800,  ...,  0.8587, -0.4166, -0.6166],\n",
            "        [ 0.5960,  1.0000,  0.9343,  ...,  0.8769, -0.0853, -0.8493],\n",
            "        ...,\n",
            "        [ 0.4575,  1.0000,  0.9654,  ...,  0.9062,  0.1195, -0.8762],\n",
            "        [-0.4631,  0.9995, -0.5933,  ..., -0.8405,  0.3579,  0.3664],\n",
            "        [-0.0917,  1.0000, -0.7536,  ..., -0.7838,  0.1341, -0.4425]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.8174,  1.0000,  0.8217,  ...,  0.5923,  0.0490, -0.7446],\n",
            "        [ 0.6466,  1.0000,  0.9614,  ...,  0.9140, -0.0994, -0.8850],\n",
            "        [ 0.6337,  1.0000,  0.9295,  ...,  0.8535,  0.0911, -0.9008],\n",
            "        ...,\n",
            "        [ 0.3322,  1.0000,  0.9194,  ...,  0.7916, -0.4377, -0.6334],\n",
            "        [ 0.6821,  1.0000,  0.8659,  ...,  0.8513, -0.5487, -0.3613],\n",
            "        [ 0.6415,  1.0000,  0.7713,  ...,  0.6788, -0.3129, -0.7290]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2895,  0.9994, -0.8622,  ..., -0.8839,  0.2501, -0.4855],\n",
            "        [ 0.5083,  1.0000,  0.8265,  ...,  0.7871, -0.7256, -0.4626],\n",
            "        [ 0.6617,  1.0000,  0.9515,  ...,  0.9069, -0.1112, -0.7780],\n",
            "        ...,\n",
            "        [ 0.7346,  1.0000,  0.8647,  ...,  0.7016, -0.5565, -0.5807],\n",
            "        [ 0.6621,  1.0000,  0.9428,  ...,  0.7538,  0.1876, -0.9116],\n",
            "        [ 0.4803,  1.0000,  0.9381,  ...,  0.8843, -0.3641, -0.7023]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6741,  1.0000,  0.9571,  ...,  0.4147,  0.2076, -0.9796],\n",
            "        [ 0.6117,  1.0000,  0.8476,  ...,  0.7132, -0.5101, -0.5160],\n",
            "        [-0.0900,  1.0000, -0.7913,  ..., -0.9020,  0.4707, -0.5332],\n",
            "        ...,\n",
            "        [-0.1574,  0.9999, -0.9328,  ..., -0.9218,  0.5708, -0.1561],\n",
            "        [-0.2221,  0.9893, -0.8993,  ..., -0.8527,  0.2577, -0.0367],\n",
            "        [-0.5421,  0.5030, -0.9288,  ..., -0.8923, -0.0888,  0.2900]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5088,  1.0000,  0.4042,  ..., -0.4226,  0.5114, -0.8820],\n",
            "        [ 0.5695,  1.0000,  0.9399,  ...,  0.5351, -0.2854, -0.8183],\n",
            "        [ 0.4088,  0.9998,  0.8837,  ...,  0.8071, -0.6349, -0.4606],\n",
            "        ...,\n",
            "        [-0.4104,  0.7988, -0.9120,  ..., -0.9292,  0.3387,  0.1151],\n",
            "        [-0.2998,  0.9999, -0.3431,  ..., -0.8594,  0.5240, -0.4198],\n",
            "        [-0.3418,  0.9991, -0.9087,  ..., -0.9371,  0.3313,  0.0027]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5194,  1.0000,  0.9288,  ...,  0.8798, -0.4188, -0.6421],\n",
            "        [ 0.7696,  1.0000,  0.2753,  ..., -0.5660,  0.5079, -0.9306],\n",
            "        [ 0.0159,  1.0000, -0.7514,  ..., -0.9193,  0.6816, -0.6176],\n",
            "        ...,\n",
            "        [ 0.4292,  1.0000,  0.8939,  ...,  0.7720, -0.4929, -0.6794],\n",
            "        [-0.4234,  1.0000,  0.0676,  ..., -0.5962,  0.5932, -0.4801],\n",
            "        [-0.1674,  1.0000, -0.6104,  ..., -0.8360,  0.4396, -0.6654]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1832,  0.9966, -0.9146,  ..., -0.7680, -0.0370,  0.4632],\n",
            "        [ 0.3659,  1.0000,  0.9363,  ...,  0.7015, -0.2083, -0.5714],\n",
            "        [ 0.6706,  1.0000,  0.9521,  ...,  0.8941, -0.2278, -0.8523],\n",
            "        ...,\n",
            "        [ 0.5900,  1.0000,  0.9464,  ...,  0.8322, -0.4603, -0.8471],\n",
            "        [-0.1849,  1.0000, -0.7451,  ..., -0.8465,  0.6032, -0.5819],\n",
            "        [ 0.3529,  1.0000, -0.3111,  ..., -0.9010,  0.6962, -0.7872]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3552,  0.9991, -0.5665,  ..., -0.8503,  0.5098, -0.0906],\n",
            "        [ 0.4293,  1.0000,  0.9157,  ...,  0.6748, -0.6959, -0.7289],\n",
            "        [ 0.4623,  1.0000,  0.7707,  ...,  0.8210, -0.3438, -0.5475],\n",
            "        ...,\n",
            "        [ 0.5512,  1.0000,  0.8514,  ...,  0.6968, -0.3309, -0.5794],\n",
            "        [ 0.5333,  0.9999,  0.8927,  ...,  0.8683, -0.5421, -0.4892],\n",
            "        [ 0.3576,  1.0000,  0.8606,  ...,  0.2057, -0.3031, -0.8529]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1535,  1.0000,  0.2854,  ..., -0.6538,  0.6925, -0.9069],\n",
            "        [-0.6716,  0.9998, -0.6936,  ..., -0.8900,  0.4358, -0.0028],\n",
            "        [ 0.5708,  1.0000,  0.9251,  ...,  0.8239, -0.5730, -0.6156],\n",
            "        ...,\n",
            "        [ 0.0145,  0.9998, -0.7034,  ..., -0.9498,  0.6343, -0.4414],\n",
            "        [ 0.0159,  1.0000, -0.6371,  ..., -0.8633,  0.7341, -0.9211],\n",
            "        [ 0.1631,  0.9986, -0.8399,  ..., -0.9101,  0.4105, -0.3133]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3352,  1.0000, -0.6390,  ..., -0.7580,  0.7969, -0.7789],\n",
            "        [ 0.5472,  1.0000,  0.6928,  ..., -0.2115,  0.0609, -0.9389],\n",
            "        [ 0.4773,  1.0000,  0.9189,  ...,  0.5412, -0.5642, -0.5981],\n",
            "        ...,\n",
            "        [-0.2311,  1.0000,  0.0199,  ..., -0.7014,  0.2766, -0.4504],\n",
            "        [ 0.5526,  1.0000, -0.7313,  ..., -0.8163,  0.6404, -0.7185],\n",
            "        [ 0.4402,  1.0000,  0.8261,  ...,  0.8258, -0.4885, -0.4752]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0041,  1.0000,  0.5051,  ...,  0.0598,  0.6682, -0.7948],\n",
            "        [ 0.2507,  1.0000,  0.2592,  ..., -0.5436,  0.5579, -0.8886],\n",
            "        [-0.2035,  0.0070, -0.8594,  ..., -0.8354,  0.1601, -0.0741],\n",
            "        ...,\n",
            "        [-0.4227,  0.9934, -0.8121,  ..., -0.9172,  0.2062,  0.0644],\n",
            "        [ 0.4461,  1.0000,  0.8561,  ...,  0.8012, -0.6174, -0.6099],\n",
            "        [ 0.5268,  0.9999,  0.9069,  ...,  0.7665, -0.5667, -0.5175]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5670,  0.9908, -0.9343,  ..., -0.8621, -0.0975,  0.4360],\n",
            "        [-0.2454,  0.9993, -0.6343,  ..., -0.8921,  0.6041,  0.1542],\n",
            "        [ 0.3636,  1.0000, -0.7609,  ..., -0.9249,  0.7088, -0.8132],\n",
            "        ...,\n",
            "        [-0.5005,  0.9997, -0.8684,  ..., -0.8873,  0.2474, -0.2064],\n",
            "        [ 0.4758,  1.0000,  0.8106,  ...,  0.1387, -0.3660, -0.8181],\n",
            "        [-0.4258,  0.9998, -0.8615,  ..., -0.9056,  0.1715, -0.0283]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3621,  1.0000,  0.1536,  ...,  0.0039,  0.2304, -0.8869],\n",
            "        [ 0.4828,  1.0000,  0.8406,  ...,  0.7624, -0.6444, -0.8364],\n",
            "        [ 0.1331,  1.0000, -0.6353,  ..., -0.9273,  0.6961, -0.8434],\n",
            "        ...,\n",
            "        [-0.6112,  0.9706, -0.8738,  ..., -0.9275,  0.1653, -0.0060],\n",
            "        [ 0.6592,  1.0000,  0.8857,  ...,  0.7294, -0.3360, -0.7923],\n",
            "        [ 0.6721,  0.9999,  0.8414,  ...,  0.7023, -0.7032, -0.4368]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1113,  1.0000, -0.7223,  ..., -0.7886,  0.5793, -0.8050],\n",
            "        [-0.2280,  0.9752, -0.9055,  ..., -0.8521,  0.0916, -0.0772],\n",
            "        [-0.4445,  0.9487, -0.9334,  ..., -0.9293, -0.0068,  0.2794],\n",
            "        ...,\n",
            "        [ 0.3989,  1.0000,  0.8846,  ...,  0.8652, -0.4223, -0.4195],\n",
            "        [-0.2056,  0.9999, -0.8279,  ..., -0.8816,  0.6620, -0.5137],\n",
            "        [-0.4007,  0.9998, -0.8333,  ..., -0.8953,  0.5344, -0.2904]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5320,  0.9981, -0.8707, -0.9427,  0.3940, -0.8727,  0.3063, -0.5294,\n",
            "         -0.6500,  0.6044, -0.6352,  0.9048, -0.4207,  0.9819, -0.1652, -0.0965,\n",
            "         -0.5986, -0.9478,  0.1087, -0.3715,  0.4257,  0.8510,  0.2763, -0.6074,\n",
            "         -0.6420, -0.7122,  0.4318,  0.5804, -0.0318, -0.1437, -0.4704,  0.4136,\n",
            "          0.8594,  0.4586,  0.5164, -0.4614,  0.1527, -0.1793, -0.9026, -0.9514,\n",
            "          0.7940,  0.0981,  0.9789, -0.9450,  0.6925, -0.9282,  0.2672, -0.5660,\n",
            "          0.7905,  0.3126,  0.4323, -0.9916,  0.5019, -0.8333, -0.6690, -0.9765,\n",
            "         -0.5442,  0.6831, -0.3871,  0.6865, -0.2227, -0.5219,  0.7823,  0.2790,\n",
            "          0.9357,  0.4568,  0.7592, -0.0976,  0.8724, -0.9527, -0.6449, -0.4147,\n",
            "          0.4562, -0.6186,  0.6095, -0.0947,  0.5448, -0.8441, -0.4156,  0.5036,\n",
            "         -0.7015,  0.6400,  0.7441, -0.9974, -0.5493, -0.7213,  0.9351, -0.6612,\n",
            "         -0.6358,  0.2448,  0.2892, -0.6944, -0.6170,  0.1140,  0.1766, -0.6857,\n",
            "          0.0050, -0.5485, -0.9332,  0.3055,  0.7317,  0.7333,  0.6572, -0.0558,\n",
            "         -0.9922, -0.8055,  0.3468, -0.7481, -0.9967, -0.4277, -0.6970, -0.2496,\n",
            "          0.7977,  0.4068, -0.4689,  0.9889, -0.8344, -0.1847, -0.9917, -0.8358,\n",
            "          0.1559, -0.1190,  0.1444, -0.4555, -0.0468, -0.9041, -0.9580, -0.9352,\n",
            "          0.5651,  0.2401, -0.2817, -0.3855, -0.7306, -0.7612,  0.1386, -0.2494,\n",
            "         -0.9898,  0.4984,  0.6053, -0.8874,  0.9282,  0.4600, -0.2456, -0.6044,\n",
            "          0.0214,  0.8824,  0.0648,  0.6112, -0.3781, -0.8124,  0.2899, -0.3206,\n",
            "         -0.2775,  0.3483, -0.9984,  0.6408,  0.6718,  0.9091,  0.9390, -0.5826,\n",
            "          0.4110, -0.9907,  0.7198,  0.5043,  0.9931, -0.4809, -0.1090,  0.4605,\n",
            "          0.8209,  0.0061,  0.0100,  0.6996,  0.6449,  0.6980,  0.9840, -0.7776,\n",
            "         -0.6681, -0.4171,  0.9115, -0.3661,  0.8181, -0.2761, -0.1230, -0.8728,\n",
            "         -0.0667, -0.3390, -0.5406, -0.9970,  0.3288,  0.8131, -0.2411, -0.9090,\n",
            "          0.2558,  0.7431,  0.4407, -0.3603, -0.4668,  0.4937, -0.1892,  0.7918,\n",
            "          0.8210, -0.7393,  0.9595,  0.0935, -0.6166, -0.9456,  0.5900,  0.8694,\n",
            "         -0.8550, -0.3463,  0.4793,  0.2877,  0.4798, -0.7275, -0.3063,  0.1831,\n",
            "          0.7322, -0.9072,  0.7877,  0.7681, -0.3477, -0.6071, -0.3922, -0.7060,\n",
            "          0.0792, -0.6667, -0.1001,  0.4395, -0.7583, -0.9907,  0.3561,  0.5707,\n",
            "          0.5123,  0.7490,  0.9915,  0.3852, -0.8328,  0.8476, -0.8482, -0.4545,\n",
            "          0.8069, -0.9629,  0.6332,  0.1321,  0.9927, -0.9137,  0.5207, -0.6414,\n",
            "          0.2658,  0.7466, -0.6048, -0.1607,  0.6637,  0.6929,  0.6209,  0.5465,\n",
            "          0.4541, -0.9723, -0.4562,  0.4184, -0.7951,  0.3390, -0.9446, -0.8924,\n",
            "          0.6592,  0.9962, -0.6011,  0.0102,  0.4752,  0.3660,  0.5269, -0.8286,\n",
            "          0.1347,  0.9981, -0.6628, -0.7432,  0.9969,  0.2905, -0.8944,  0.5161,\n",
            "         -0.8592, -0.7402,  0.7204,  0.0033,  0.1831,  0.1936,  0.2866, -0.6629,\n",
            "         -0.9825, -0.7063,  0.9727,  0.6915,  0.8427,  0.4092, -0.4456, -0.8439,\n",
            "          0.8336, -0.0331, -0.8721,  0.9985,  0.4394, -0.7569, -0.9063,  0.3211,\n",
            "         -0.1240,  0.6451, -0.0633,  0.5351, -0.8111,  0.4533,  0.6136, -0.3744,\n",
            "          0.6241,  0.2834, -0.0143, -0.6244, -0.1180, -0.7624, -0.2756,  0.0326,\n",
            "          0.4560,  0.9502,  0.2374, -0.6245,  0.6746,  0.4758, -0.9940,  0.9714,\n",
            "          0.6942, -0.7851, -0.1116,  0.7188,  0.3752, -0.5539,  0.7116, -0.3970,\n",
            "         -0.1241, -0.6196,  0.2491,  0.7871,  0.6697,  0.4668,  0.5210,  0.3828,\n",
            "          0.3041, -0.5591,  0.6009, -0.5169, -0.8103, -0.5140,  0.0417,  0.6319,\n",
            "         -0.8224,  0.5187,  0.6001,  0.9985,  0.6104,  0.9872, -0.7340,  0.6530,\n",
            "         -0.3956,  0.3944,  0.8301, -0.8320, -0.9939, -0.5809, -0.3533,  0.2756,\n",
            "         -0.9542, -0.8643, -0.7871,  0.4773, -0.2665,  0.8973, -0.3618, -0.9107,\n",
            "          0.9503,  0.4038,  0.8046,  0.0402, -0.4471,  0.5302,  0.7934,  0.4851,\n",
            "          0.5223, -0.4359,  0.7308, -0.7635,  0.6464, -0.0272, -0.0320,  0.2496,\n",
            "          0.5043,  0.6270,  0.6086,  0.9032, -0.3135, -0.3637, -0.9617,  0.9984,\n",
            "         -0.6002,  0.3010, -0.3296,  0.3684,  0.6595, -0.5274,  0.5040, -0.4445,\n",
            "          0.8536, -0.9099,  0.7351,  0.5763,  0.6579, -0.0223, -0.2387,  0.4885,\n",
            "         -0.7138, -0.4736, -0.8126,  0.7270, -0.8808, -0.7618, -0.8433, -0.8884,\n",
            "          0.9467, -0.6930,  0.7499, -0.7147, -0.7832, -0.6544, -0.3381, -0.4548,\n",
            "          0.6141, -0.9514,  0.9869, -0.9088,  0.3603, -0.0135,  0.5107,  0.5293,\n",
            "          0.8193,  0.5648,  0.6006, -0.3062,  0.4061,  0.4363, -0.6682, -0.8465,\n",
            "         -0.1007,  0.6552,  0.4994,  0.7961, -0.4758,  0.9481,  0.6628, -0.5151,\n",
            "         -0.3190, -0.6286,  0.9078,  0.9916, -0.7685,  0.9112,  0.9970, -0.6234,\n",
            "         -0.2928, -0.0786, -0.9005,  0.7970, -0.8083, -0.8446,  0.4526, -0.2026,\n",
            "          0.5840,  0.4307,  0.8477, -0.3564, -0.3402, -0.8985, -0.1129, -0.8825,\n",
            "         -0.5459,  0.7706, -0.8915, -0.8672,  0.8038,  0.0044,  0.0290,  0.4475,\n",
            "          0.7270,  0.8787, -0.3730, -0.4529,  0.3636,  0.5957,  0.5178,  0.3959,\n",
            "         -0.7539, -0.4325, -0.8165,  0.3746,  0.9903, -0.7702, -0.3634,  0.3902,\n",
            "         -0.1409, -0.8519,  0.9983, -0.1176,  0.5502,  0.9923,  0.3675,  0.6690,\n",
            "         -0.4664,  0.6047, -0.3439,  0.4775,  0.8451,  0.9695, -0.7266, -0.7367,\n",
            "         -0.9982,  0.2527, -0.3415, -0.0069, -0.1793, -0.7993, -0.2616,  0.2559,\n",
            "         -0.9333,  0.4842, -0.3401, -0.9925, -0.9230, -0.4285, -0.6910, -0.8845,\n",
            "          0.1406, -0.6906, -0.8095,  0.9380, -0.8830, -0.9965, -0.3966,  0.5525,\n",
            "          0.9378,  0.5976,  0.2214, -0.3496, -0.6753,  0.5348, -0.9991, -0.0554,\n",
            "          0.5921,  0.7008, -0.6580,  0.9189, -0.7430, -0.6444, -0.4532,  0.6084,\n",
            "          0.7447, -0.9991, -0.1297,  0.9022, -0.1095, -0.3672, -0.7868, -0.4510,\n",
            "         -0.7333, -0.6480,  0.9504, -0.3523,  0.9765, -0.6466,  0.7214,  0.5866,\n",
            "          0.0058, -0.7551, -0.1046,  0.8417,  0.7264,  0.5967,  0.6341, -0.4341,\n",
            "          0.0585, -0.1660, -0.5719,  0.4211, -0.7268,  0.5958, -0.4693,  0.5408,\n",
            "          0.3063, -0.4688,  0.9920,  0.4074, -0.7747,  0.7739, -0.4488, -0.5425,\n",
            "         -0.9973, -0.7596,  0.7566, -0.9310, -0.8004,  0.4601, -0.5349, -0.3588,\n",
            "          0.9171, -0.2756,  0.8338,  0.9700,  0.6238,  0.0647, -0.7773, -0.9929,\n",
            "          0.2333,  0.8292, -0.5084,  0.8082, -0.6704,  0.9926,  0.1505,  0.5175,\n",
            "          0.6172,  0.9755,  0.1185, -0.7327,  0.5667, -0.0179,  0.4042,  0.8360,\n",
            "         -0.2250, -0.9461, -0.4229, -0.6062, -0.2839, -0.4795,  0.8917,  0.2681,\n",
            "          0.9974,  0.6812,  0.7628,  0.4134,  0.7280, -0.5119, -0.2430,  0.6482,\n",
            "         -0.9960,  0.7383, -0.1586, -0.6884,  0.2625, -0.8523, -0.6258, -0.1150,\n",
            "         -0.2533,  0.1513, -0.7794, -0.7013,  0.0112, -0.6645,  0.8189, -0.4984,\n",
            "         -0.9506,  0.8508, -0.6979,  0.4227,  0.8007,  0.1287, -0.3037,  0.8515,\n",
            "         -0.2992, -0.7329,  0.5531, -0.1719, -0.5734,  0.6480,  0.1827,  0.7931,\n",
            "          0.4267, -0.0589,  0.8387,  0.2542, -0.6358,  0.5568, -0.2530,  0.5097,\n",
            "          0.7660, -0.5707,  0.6570,  0.4823, -0.4731, -0.4314,  0.0809,  0.3130,\n",
            "          0.9783, -0.9908,  0.9790,  0.3344, -0.3488, -0.9832, -0.1199,  0.1494,\n",
            "          0.7665, -0.1304,  0.0951, -0.1962, -0.7031,  0.6769, -0.9976, -0.8247,\n",
            "         -0.6334,  0.5883,  0.6127, -0.9894, -0.4234,  0.3577, -0.0276, -0.2768,\n",
            "          0.9572, -0.2996, -0.7687, -0.9191, -0.9232,  0.0867,  0.5217, -0.7024,\n",
            "          0.4841,  0.2670, -0.6912, -0.5649,  0.4203,  0.5962, -0.4946, -0.3211,\n",
            "          0.6779, -0.9976,  0.5665, -0.1211, -0.7219,  0.6928, -0.8282,  0.6801,\n",
            "          0.3889, -0.9680,  0.4821,  0.1587,  0.5735,  0.7287, -0.6813,  0.5673,\n",
            "          0.6600, -0.5220,  0.9099, -0.0187,  0.0558,  0.1145,  0.9499,  0.6413,\n",
            "          0.6746, -0.1296, -0.8425, -0.8262, -0.1050, -0.8025,  0.0520,  0.3954]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluation... :   0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "02f80e5f64814c3082ae935a9072716c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6729,  0.9999,  0.8944,  ...,  0.7976, -0.6764, -0.5604],\n",
            "        [ 0.6210,  1.0000,  0.9214,  ...,  0.8187, -0.4707, -0.7462],\n",
            "        [ 0.8621,  1.0000,  0.6607,  ..., -0.4294,  0.6489, -0.8221],\n",
            "        ...,\n",
            "        [ 0.0939,  1.0000,  0.8549,  ...,  0.4233, -0.5605, -0.7081],\n",
            "        [ 0.2802,  0.9999, -0.3604,  ..., -0.8203,  0.6355, -0.7705],\n",
            "        [-0.5083,  0.9981, -0.8717,  ..., -0.7825,  0.2527,  0.1501]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1057,  1.0000, -0.4271,  ..., -0.8840,  0.7042, -0.7302],\n",
            "        [ 0.3540,  1.0000,  0.7281,  ..., -0.5398, -0.1771, -0.8308],\n",
            "        [ 0.4475,  1.0000,  0.8435,  ..., -0.4109,  0.4867, -0.9777],\n",
            "        ...,\n",
            "        [ 0.0412,  1.0000,  0.2432,  ..., -0.6598,  0.1711, -0.9141],\n",
            "        [-0.2685,  1.0000,  0.4085,  ..., -0.8202,  0.3495, -0.8559],\n",
            "        [ 0.5636,  1.0000,  0.8466,  ..., -0.5354,  0.5686, -0.9845]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4891,  1.0000,  0.9126,  ...,  0.8008, -0.6031, -0.5375],\n",
            "        [ 0.2770,  0.9999,  0.9333,  ...,  0.5481, -0.3183, -0.6933],\n",
            "        [ 0.4827,  1.0000,  0.8678,  ...,  0.6911, -0.4580, -0.7824],\n",
            "        ...,\n",
            "        [-0.1575,  1.0000, -0.0843,  ..., -0.8731,  0.7441, -0.8839],\n",
            "        [-0.5082,  0.9715, -0.8185,  ..., -0.9174,  0.2946, -0.0696],\n",
            "        [ 0.3409,  1.0000,  0.7374,  ..., -0.3224,  0.3059, -0.9742]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1271,  1.0000, -0.2117,  ..., -0.6066, -0.2018, -0.9247],\n",
            "        [ 0.0132,  1.0000,  0.7493,  ..., -0.3856,  0.4326, -0.9735],\n",
            "        [ 0.3150,  1.0000, -0.0321,  ..., -0.8520,  0.5321, -0.9658],\n",
            "        ...,\n",
            "        [ 0.5900,  1.0000,  0.8901,  ...,  0.8222, -0.6215, -0.5196],\n",
            "        [-0.0880,  0.9954, -0.7823,  ..., -0.9283,  0.6783, -0.5411],\n",
            "        [ 0.5708,  1.0000,  0.8876,  ...,  0.8293, -0.7478, -0.4838]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4144,  1.0000,  0.7510,  ...,  0.2471, -0.1084, -0.7220],\n",
            "        [ 0.3800,  1.0000,  0.8747,  ...,  0.7772, -0.2732, -0.7502],\n",
            "        [-0.3097,  0.9992, -0.8255,  ..., -0.8120,  0.3604, -0.0286],\n",
            "        ...,\n",
            "        [ 0.3070,  1.0000,  0.5312,  ...,  0.0061, -0.2825, -0.9392],\n",
            "        [ 0.5210,  0.9998,  0.9174,  ...,  0.7292, -0.6383, -0.4071],\n",
            "        [ 0.6344,  0.9999,  0.9508,  ...,  0.7207, -0.5755, -0.5900]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4786,  1.0000,  0.8915,  ...,  0.8240, -0.6307, -0.4840],\n",
            "        [ 0.6313,  1.0000,  0.7632,  ...,  0.5808, -0.6294, -0.8050],\n",
            "        [ 0.4292,  1.0000, -0.8719,  ..., -0.8806,  0.6545, -0.5943],\n",
            "        ...,\n",
            "        [ 0.8501,  1.0000,  0.2849,  ..., -0.5577,  0.6819, -0.7658],\n",
            "        [ 0.1832,  1.0000,  0.1140,  ..., -0.3105,  0.0645, -0.9089],\n",
            "        [-0.2715,  1.0000,  0.2845,  ..., -0.8039,  0.3701, -0.9027]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0410,  1.0000, -0.5316,  ..., -0.8321,  0.2305, -0.8450],\n",
            "        [-0.3288,  0.9751, -0.9292,  ..., -0.9489,  0.1581,  0.2820],\n",
            "        [ 0.5369,  0.9999,  0.8774,  ...,  0.8588, -0.6953, -0.4367],\n",
            "        ...,\n",
            "        [-0.1537,  1.0000, -0.1280,  ..., -0.8327, -0.1555, -0.7622],\n",
            "        [ 0.5238,  0.9999,  0.9013,  ...,  0.8491, -0.7543, -0.4186],\n",
            "        [-0.1432,  1.0000, -0.6069,  ..., -0.8176,  0.2660, -0.4421]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5883,  1.0000,  0.9042,  ...,  0.8160, -0.5819, -0.6148],\n",
            "        [ 0.6155,  1.0000,  0.9243,  ...,  0.8595, -0.6308, -0.5991],\n",
            "        [ 0.6933,  1.0000,  0.9295,  ...,  0.8096,  0.0849, -0.9439],\n",
            "        ...,\n",
            "        [ 0.4939,  0.9999,  0.9194,  ...,  0.8311, -0.6999, -0.4476],\n",
            "        [ 0.3372,  1.0000,  0.8803,  ...,  0.6138, -0.2011, -0.8892],\n",
            "        [ 0.4985,  1.0000,  0.7845,  ...,  0.2963, -0.2542, -0.7925]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6045,  1.0000,  0.9235,  ...,  0.8524, -0.6379, -0.5853],\n",
            "        [ 0.3066,  1.0000, -0.7705,  ..., -0.8503,  0.4591, -0.7574],\n",
            "        [-0.7758,  0.5053, -0.7589,  ..., -0.9196,  0.3132, -0.3352],\n",
            "        ...,\n",
            "        [ 0.5427,  1.0000,  0.9027,  ...,  0.7995, -0.6017, -0.4623],\n",
            "        [-0.3954,  0.9991, -0.8365,  ..., -0.9234,  0.5905,  0.1785],\n",
            "        [ 0.4352,  0.9998,  0.8913,  ...,  0.7873, -0.6733, -0.4244]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0954,  0.9984, -0.9161,  ..., -0.8965,  0.2823, -0.1643],\n",
            "        [ 0.2744,  1.0000,  0.1626,  ..., -0.8413,  0.6396, -0.9120],\n",
            "        [ 0.4826,  0.9999,  0.8925,  ...,  0.8185, -0.7069, -0.5078],\n",
            "        ...,\n",
            "        [ 0.6049,  1.0000,  0.8433,  ...,  0.7672, -0.6758, -0.6424],\n",
            "        [ 0.5103,  1.0000,  0.8602,  ...,  0.6569, -0.3901, -0.4281],\n",
            "        [ 0.7022,  1.0000,  0.9242,  ...,  0.8056,  0.0520, -0.9434]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0260,  0.9999, -0.8253,  ..., -0.8906,  0.2794, -0.0679],\n",
            "        [-0.2929,  0.9882, -0.8643,  ..., -0.9394,  0.3503, -0.0558],\n",
            "        [-0.6075,  0.9996, -0.9439,  ..., -0.9607,  0.0379, -0.2622],\n",
            "        ...,\n",
            "        [ 0.5764,  1.0000,  0.8792,  ...,  0.4243, -0.2694, -0.9010],\n",
            "        [ 0.8409,  1.0000, -0.2906,  ..., -0.4986,  0.4790, -0.9132],\n",
            "        [ 0.4251,  1.0000,  0.9141,  ...,  0.8115, -0.6660, -0.4163]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5848,  1.0000,  0.9274,  ...,  0.3896, -0.0555, -0.8302],\n",
            "        [-0.2038,  0.9996, -0.8949,  ..., -0.9170,  0.4213, -0.1506],\n",
            "        [-0.5340,  0.9999, -0.7947,  ..., -0.8885,  0.2686, -0.5200],\n",
            "        ...,\n",
            "        [-0.2567,  1.0000, -0.8886,  ..., -0.9089,  0.3853, -0.1548],\n",
            "        [ 0.4219,  1.0000,  0.5064,  ..., -0.6578,  0.2583, -0.9101],\n",
            "        [ 0.0838,  1.0000, -0.4684,  ..., -0.8935,  0.6341, -0.7833]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0804,  0.9998, -0.7579,  ..., -0.5809,  0.6852,  0.1180],\n",
            "        [ 0.4441,  1.0000,  0.8246,  ...,  0.3651, -0.1644, -0.8986],\n",
            "        [-0.4512, -0.3059, -0.8472,  ..., -0.9296,  0.3887,  0.1352],\n",
            "        ...,\n",
            "        [-0.6651,  1.0000, -0.8602,  ..., -0.6849,  0.7316, -0.3308],\n",
            "        [ 0.5808,  1.0000, -0.6549,  ..., -0.8456,  0.6038, -0.8564],\n",
            "        [-0.6196,  0.9999, -0.7650,  ..., -0.8064,  0.4115, -0.5270]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5534,  1.0000,  0.9304,  ...,  0.6072, -0.4677, -0.6883],\n",
            "        [ 0.5513,  1.0000,  0.8096,  ..., -0.0622, -0.0911, -0.9214],\n",
            "        [-0.4180,  0.9691, -0.9226,  ..., -0.8646, -0.0606,  0.2055],\n",
            "        ...,\n",
            "        [ 0.4332,  1.0000,  0.8243,  ...,  0.2755, -0.5818, -0.7230],\n",
            "        [ 0.1210,  1.0000,  0.6957,  ...,  0.3145,  0.5300, -0.8687],\n",
            "        [ 0.2785,  1.0000,  0.4814,  ...,  0.4620, -0.3609, -0.8827]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4019,  1.0000,  0.8444, -0.9477, -0.6113,  0.9320,  0.8151,  0.9127,\n",
            "         -0.9985, -0.7273,  0.9179, -0.7927,  0.4130,  0.9995,  0.2537, -0.4742,\n",
            "          0.8673, -0.9813,  0.8213, -0.5848,  0.5776, -0.7734,  0.9288, -0.3564,\n",
            "          0.8248,  0.8724, -0.6011,  0.6495, -0.0324,  0.5196, -0.6887, -0.5909,\n",
            "          0.9177,  0.8135,  0.9267, -0.9710, -0.4521, -0.9655, -0.9856, -0.9980,\n",
            "         -0.7198, -0.6069,  0.9997, -0.8002,  0.9982, -0.9814,  0.4535, -0.3768,\n",
            "          0.8370,  0.4635, -0.8627,  0.9854,  0.8373,  0.9624, -0.6944, -0.9253,\n",
            "         -0.7795,  0.4918, -0.9011, -0.5088,  0.9097,  0.7892, -0.6945, -0.1489,\n",
            "         -0.9468, -0.7355,  0.6891,  0.6339, -0.8650, -0.9792,  0.9112, -0.9603,\n",
            "          0.7866, -0.2087, -0.6855,  0.9058, -0.8845,  0.8583, -0.8963,  0.9930,\n",
            "          0.7657,  0.7199,  0.7554, -1.0000,  0.8390, -0.9303,  0.9947, -0.9900,\n",
            "         -0.9840,  0.8566,  0.8608,  0.8506,  0.9026, -0.2078, -0.7804, -0.9602,\n",
            "         -0.6895,  0.7569, -0.9990,  0.8420,  0.7056,  0.8096, -0.6966, -0.7408,\n",
            "         -0.9996,  0.6368, -0.5415, -0.6561, -1.0000, -0.8586, -0.8109, -0.9489,\n",
            "         -0.6983,  0.9389,  0.5865,  0.9999,  0.9496,  0.9989, -1.0000, -0.9893,\n",
            "          0.3994,  0.9564, -0.7565, -0.2590,  0.6600, -0.9813,  0.1983, -0.9988,\n",
            "          0.7418, -0.9536, -0.7011,  0.9119,  0.9491,  0.5177, -0.7506,  0.5775,\n",
            "         -0.9998,  0.0206, -0.9094, -0.9917,  0.9944,  0.9311,  0.9039, -0.7922,\n",
            "         -0.4946,  0.9246,  0.9544, -0.8435, -0.2837,  0.3749, -0.8669,  0.7929,\n",
            "          0.6137, -0.6595, -1.0000,  0.4081, -0.5982,  0.9863, -0.9851,  0.9762,\n",
            "         -0.9816, -1.0000,  0.6223,  0.2683, -0.9664,  0.8614, -0.7541,  0.9576,\n",
            "         -0.7501,  0.6627,  0.8172,  0.7838,  0.3791, -0.7864, -0.4367, -0.9038,\n",
            "          0.8542, -0.7396, -0.7901, -0.9823,  0.9868, -0.7575,  0.9790, -0.9707,\n",
            "         -0.8559,  0.7142,  0.4570, -1.0000,  0.9489,  0.4443,  0.6808,  0.8744,\n",
            "          0.5948, -0.5174,  0.5776, -0.1666, -0.6031,  0.7612, -0.5693,  0.9424,\n",
            "          0.4635, -0.9995,  0.9414,  0.9885,  0.4740, -0.5829,  0.1104,  0.9923,\n",
            "         -0.9981, -0.8110,  0.0580, -0.8304,  0.5610,  0.6814, -0.6638, -0.8607,\n",
            "          0.6471,  0.6278, -0.1221, -0.7325,  0.6972,  0.8338, -0.5603,  0.6275,\n",
            "          0.8641,  0.9996, -0.8731, -0.7114,  0.7903, -0.9997,  0.9174,  0.2494,\n",
            "         -0.4140, -0.8035,  0.9869,  0.8968,  0.8390,  0.9739, -0.9770, -0.2979,\n",
            "         -0.8374,  0.4912, -0.5141, -0.2918,  1.0000, -0.9927,  0.9910,  0.9017,\n",
            "          0.4115, -0.2935,  0.5615,  0.3977, -0.5205, -0.2221, -0.8534,  0.9962,\n",
            "         -0.8240, -0.9831,  0.7560, -0.1223, -0.9381, -0.9338,  0.9342, -0.7112,\n",
            "          0.9921,  1.0000,  0.8114,  0.5642,  0.8289,  0.7796,  0.8587, -0.9910,\n",
            "          0.9643,  1.0000, -0.9744,  0.5360,  1.0000,  0.8876, -0.1035, -0.7021,\n",
            "          0.6458, -0.9884, -0.5539, -0.6606, -0.5969, -0.5316,  0.0180, -0.9553,\n",
            "         -0.9995, -0.9932,  0.9828, -0.8081, -0.8848,  0.7725, -0.2674,  0.0115,\n",
            "         -0.8600,  0.9955, -0.8684,  1.0000,  0.6820, -0.7722, -0.9760, -0.5885,\n",
            "          0.7903,  0.3244,  0.9994,  0.0786, -0.6554,  0.7130,  0.7186,  0.5203,\n",
            "          0.9665, -0.7970,  0.7829,  0.3127,  0.3768, -0.9787, -0.5532, -0.9612,\n",
            "          0.8849,  0.9852,  0.7216, -0.1584,  0.9808,  0.9296, -1.0000,  0.9994,\n",
            "          0.9785, -0.9965,  0.8868, -0.4512,  0.9469,  0.1158,  0.7077, -0.9416,\n",
            "         -0.9339, -0.9968,  0.9005,  0.3564, -0.8784,  0.3602, -0.9674,  0.8240,\n",
            "          0.4455,  0.8793, -0.2939, -0.0294, -0.9967,  0.7712,  0.8639, -0.3991,\n",
            "          0.8904,  0.9937, -0.2023,  1.0000, -0.8968, -0.1493,  0.3131,  0.6760,\n",
            "          0.7733,  0.4938, -0.4285,  0.4204, -1.0000,  0.5522, -0.6986,  0.2600,\n",
            "          0.5181, -0.9901,  0.4275, -0.2760,  0.3333, -0.4372,  0.5876,  0.6927,\n",
            "          0.9996,  0.3656, -0.5528, -0.7919,  0.0985,  0.2835,  0.9125,  0.8395,\n",
            "          0.9911, -0.8456, -0.2343,  0.8110,  0.1908, -0.8400,  0.0733,  0.6217,\n",
            "          0.4226,  0.9804,  0.8466, -0.6681, -0.6538,  0.8487, -0.9980,  1.0000,\n",
            "          0.6387,  0.7569,  0.9548, -0.5389,  0.7631,  0.4654,  0.6935, -0.7896,\n",
            "          0.9913,  0.8504,  0.8427,  0.1503,  0.2393, -0.3770, -0.7829,  0.7620,\n",
            "          0.7304, -0.6127, -0.9803,  0.9951, -0.9759,  0.5585, -0.3724,  0.9302,\n",
            "          0.9333, -0.6733, -0.9618, -0.5782,  0.2667, -0.8179, -0.9300, -0.9936,\n",
            "         -0.2622, -0.9425,  0.9999, -0.9933,  0.7515, -0.9677, -0.8683,  0.8370,\n",
            "         -0.4829, -0.6288, -0.8940, -0.2622, -0.6332,  0.8714,  0.2759,  0.9223,\n",
            "         -0.6830,  0.2798,  0.6707, -0.1272,  0.3929,  0.9568, -0.7272, -0.9845,\n",
            "         -0.8358, -0.7752, -0.8104,  0.9693, -0.9503, -0.9012,  1.0000, -0.9925,\n",
            "         -0.3095, -0.3887, -0.9986,  0.5578, -0.6538, -0.9646, -0.8100, -0.7883,\n",
            "          0.8167,  0.9689,  0.9995,  0.5297, -0.0309, -0.9407, -0.5964,  0.9990,\n",
            "         -0.9901, -0.6544,  0.5401, -0.9970,  0.9468,  0.5745, -0.4270,  0.8910,\n",
            "         -0.8950,  0.9726,  0.5954, -0.9983,  0.5508,  0.8230, -0.1066,  0.9199,\n",
            "          0.5162, -0.0885, -0.9724,  0.2747,  0.9997,  0.6272, -0.8645,  0.2831,\n",
            "          0.8956,  0.8871,  1.0000, -0.9867,  0.9079,  0.9997, -0.4577,  0.7200,\n",
            "          0.2805, -0.8642, -0.0564,  0.5419, -0.9785,  0.9999, -0.4591, -0.9875,\n",
            "         -1.0000,  0.7363, -0.9299,  0.8187,  0.9905,  0.7841,  0.8671,  0.6249,\n",
            "         -0.9989,  0.1300, -0.7189, -0.9999, -0.9998,  0.8963,  0.6069,  0.5134,\n",
            "          0.8858, -0.4878, -0.7412,  0.9998,  0.9632, -1.0000, -0.4308,  0.4190,\n",
            "          0.9854, -0.8593,  0.8309,  0.3784,  0.6273, -0.5079, -1.0000, -0.7295,\n",
            "          0.9852, -0.4421,  0.3575,  0.9998,  0.8233,  0.5007, -0.9729,  0.4942,\n",
            "          0.8258, -1.0000, -0.7296,  0.9999, -0.5897, -0.3768, -0.6171,  0.7518,\n",
            "          0.8241,  0.7821,  0.6745, -0.9985,  0.9956,  0.9446, -0.6385,  0.9976,\n",
            "         -0.4195, -0.7586, -0.8797, -0.8756,  0.8821, -0.7284,  0.6979, -0.4775,\n",
            "          0.9864,  0.8925, -0.4059,  0.8467,  0.9530, -0.9101, -0.5467,  0.9209,\n",
            "          0.6767,  0.3747,  0.9532, -0.6313, -0.8119, -0.6939,  0.8535,  0.9491,\n",
            "         -0.9999,  0.9591, -0.7912, -0.9481,  0.8862, -0.6300, -0.6950, -0.4737,\n",
            "         -0.3645, -0.8589,  0.0393,  0.9719,  0.8451,  0.8371, -0.9896, -0.9999,\n",
            "         -0.8312, -0.7782, -0.8988, -0.7552,  0.2861,  0.9413,  0.6049,  0.2429,\n",
            "          0.4070,  0.9998, -0.6011,  0.9931, -0.9522,  0.9538, -0.9936,  0.6272,\n",
            "          0.6306, -0.9644, -0.7489,  0.9867, -0.5746,  0.8529, -0.9828,  0.8049,\n",
            "          1.0000, -0.8995, -0.7422,  0.8743, -0.9352,  0.9181,  0.1620,  0.9948,\n",
            "         -1.0000,  0.9933,  0.3296,  0.6249,  0.6369,  0.7796,  0.5889, -0.7263,\n",
            "         -0.6619, -0.9956,  0.4731,  0.8291, -0.6967,  0.7201,  0.9318, -0.9074,\n",
            "         -0.9993, -0.8759,  0.5585,  0.9373, -0.7630, -0.9982,  0.9829, -0.6669,\n",
            "          0.9866,  0.3392, -0.7928, -0.4573, -0.5764, -0.7639,  0.8328,  0.7710,\n",
            "          0.9465,  0.6561, -0.9014, -0.7361, -0.4557, -0.9165,  0.8964, -0.0703,\n",
            "          0.0439,  0.8758,  0.8995,  0.9841,  0.6969,  0.0467,  0.7717, -0.8177,\n",
            "         -0.8285, -0.9997,  0.9994,  0.9620, -0.8923, -0.9998,  0.9615,  0.5873,\n",
            "         -0.5652,  0.7821, -0.5193, -0.8581,  0.2811,  0.8701, -1.0000, -0.0326,\n",
            "          0.6752, -0.6567, -0.6369, -0.9997, -0.4479,  0.3691, -0.4521,  0.6111,\n",
            "          0.9991, -0.5645, -0.9753, -0.9741,  0.3500,  0.8008,  0.4330, -0.9741,\n",
            "         -0.7888,  0.9424, -0.9990,  0.8403, -0.6204, -0.6408,  0.6149,  0.9010,\n",
            "          0.9376, -1.0000,  0.9177, -0.8015,  0.9423, -0.7221,  0.6912,  0.6179,\n",
            "          0.6778, -0.9990,  0.9188,  0.5224,  0.8129,  0.6918,  0.9326, -0.3539,\n",
            "         -0.9236, -0.7615,  0.9806,  0.9721, -0.7435,  0.7632,  0.9995, -0.7763,\n",
            "          0.6431,  0.6759,  0.2721, -0.9993, -0.9195,  0.0877, -0.5770, -0.8388]],\n",
            "       device='cuda:0')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training... :   0%|          | 0/127 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "86e0e04f92c34c38b98de2716e28e376"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3743,  0.9997, -0.8514,  ..., -0.9266,  0.3656, -0.0620],\n",
            "        [ 0.6860,  1.0000,  0.9364,  ...,  0.8646,  0.3008, -0.9215],\n",
            "        [ 0.5302,  0.9996,  0.9131,  ...,  0.6488, -0.6415, -0.3833],\n",
            "        ...,\n",
            "        [-0.0071,  1.0000, -0.3579,  ..., -0.8273,  0.4428, -0.9133],\n",
            "        [ 0.6895,  1.0000, -0.3419,  ..., -0.7143,  0.6782, -0.7141],\n",
            "        [ 0.6051,  1.0000,  0.7783,  ...,  0.8023, -0.5238, -0.3441]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0712,  0.9969, -0.8153,  ..., -0.9263,  0.3644, -0.3457],\n",
            "        [ 0.5078,  1.0000,  0.9005,  ...,  0.7489, -0.5903, -0.7818],\n",
            "        [-0.2725,  0.9795, -0.9144,  ..., -0.9499,  0.0464, -0.0561],\n",
            "        ...,\n",
            "        [ 0.7319,  1.0000, -0.1083,  ..., -0.7247,  0.8076, -0.8786],\n",
            "        [ 0.6404,  1.0000,  0.9091,  ...,  0.8019, -0.5689, -0.6785],\n",
            "        [ 0.6321,  1.0000,  0.8593,  ...,  0.7821, -0.5826, -0.5587]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7399,  1.0000, -0.4083,  ..., -0.6449,  0.7603, -0.8437],\n",
            "        [ 0.4509,  1.0000,  0.8508,  ...,  0.7419, -0.5001, -0.5548],\n",
            "        [ 0.6315,  1.0000,  0.9510,  ...,  0.8678, -0.3108, -0.8402],\n",
            "        ...,\n",
            "        [ 0.2072,  0.9995,  0.9194,  ...,  0.7495, -0.7003, -0.4977],\n",
            "        [ 0.5825,  1.0000,  0.8502,  ...,  0.8242, -0.7314, -0.4588],\n",
            "        [ 0.6802,  0.9998,  0.8161,  ...,  0.8110, -0.7499, -0.5196]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6165,  0.9999,  0.8366,  ...,  0.8208, -0.6726, -0.5297],\n",
            "        [ 0.5766,  0.9981,  0.9203,  ...,  0.4877, -0.2492, -0.8400],\n",
            "        [ 0.3246,  1.0000,  0.7030,  ...,  0.6704, -0.1785, -0.6264],\n",
            "        ...,\n",
            "        [ 0.3913,  0.9999, -0.8234,  ..., -0.7952,  0.4445, -0.8281],\n",
            "        [ 0.6364,  1.0000,  0.6978,  ...,  0.3263, -0.3060, -0.8981],\n",
            "        [-0.0199,  0.9868, -0.8989,  ..., -0.9199,  0.4929, -0.2980]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2696,  0.9988, -0.8994,  ..., -0.8743,  0.3112, -0.0902],\n",
            "        [ 0.6417,  1.0000,  0.9597,  ...,  0.7142,  0.1375, -0.9126],\n",
            "        [-0.3355,  0.9960, -0.8716,  ..., -0.8988,  0.3792,  0.0373],\n",
            "        ...,\n",
            "        [ 0.2896,  1.0000,  0.9330,  ...,  0.6646, -0.5465, -0.7861],\n",
            "        [ 0.6891,  1.0000,  0.8174,  ...,  0.7790, -0.6909, -0.5083],\n",
            "        [ 0.4583,  1.0000,  0.9503,  ...,  0.8396, -0.3002, -0.6039]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5955,  1.0000,  0.9393,  ...,  0.5552, -0.4672, -0.6319],\n",
            "        [-0.0021,  0.9998,  0.9258,  ...,  0.0705, -0.4575, -0.8127],\n",
            "        [ 0.0188,  0.9697, -0.4380,  ..., -0.8307, -0.1211, -0.2913],\n",
            "        ...,\n",
            "        [ 0.4845,  1.0000,  0.8167,  ...,  0.3926, -0.7182, -0.4059],\n",
            "        [-0.2389,  0.9999, -0.5422,  ..., -0.8051,  0.1416, -0.0539],\n",
            "        [-0.6557,  0.9408, -0.9086,  ..., -0.9228,  0.2600, -0.0475]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1830,  0.9990, -0.8974,  ..., -0.8394,  0.1234,  0.1087],\n",
            "        [ 0.3611,  1.0000,  0.9332,  ...,  0.8460, -0.5802, -0.6887],\n",
            "        [ 0.6341,  1.0000,  0.8839,  ...,  0.8568, -0.6622, -0.5531],\n",
            "        ...,\n",
            "        [ 0.5968,  1.0000,  0.9228,  ...,  0.8940, -0.6142, -0.5672],\n",
            "        [ 0.5917,  1.0000,  0.7388,  ...,  0.8022, -0.4863, -0.4016],\n",
            "        [-0.0824,  0.9999, -0.8364,  ..., -0.8538,  0.4660, -0.4393]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1439,  1.0000, -0.7124,  ..., -0.8051,  0.2180, -0.3067],\n",
            "        [ 0.6691,  1.0000,  0.8592,  ...,  0.9049, -0.5709, -0.3594],\n",
            "        [ 0.4514,  1.0000,  0.8427,  ...,  0.8555, -0.8315, -0.4105],\n",
            "        ...,\n",
            "        [-0.4289,  0.9973, -0.9013,  ..., -0.9006,  0.2980, -0.0566],\n",
            "        [-0.5940,  0.9223, -0.9446,  ..., -0.9328, -0.0878,  0.3620],\n",
            "        [-0.1590,  0.9975, -0.9026,  ..., -0.8756,  0.2968, -0.4175]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5270,  0.9959, -0.5722,  ..., -0.7070,  0.1604, -0.2770],\n",
            "        [ 0.3498,  1.0000,  0.8275,  ...,  0.7753, -0.5477, -0.3757],\n",
            "        [-0.0011,  0.9999, -0.6981,  ..., -0.9456,  0.5991, -0.8042],\n",
            "        ...,\n",
            "        [-0.2327,  0.8889, -0.9606,  ..., -0.9635,  0.3135,  0.2717],\n",
            "        [ 0.5964,  1.0000,  0.7036,  ...,  0.4722, -0.5930, -0.5664],\n",
            "        [-0.0393,  0.9970, -0.9104,  ..., -0.8927,  0.2055, -0.2443]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5620,  1.0000,  0.8281,  ...,  0.6412, -0.7077, -0.3766],\n",
            "        [-0.2702,  0.9768, -0.8889,  ..., -0.9115,  0.1920,  0.0928],\n",
            "        [ 0.5605,  0.9999,  0.9255,  ...,  0.8652, -0.4792, -0.5629],\n",
            "        ...,\n",
            "        [ 0.5447,  1.0000,  0.9033,  ...,  0.7761, -0.0689, -0.7797],\n",
            "        [ 0.5138,  0.9999,  0.9084,  ...,  0.8249, -0.4893, -0.6370],\n",
            "        [ 0.7622,  1.0000,  0.8928,  ...,  0.4754, -0.4221, -0.7121]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4598, -0.9109, -0.8844,  ..., -0.9348,  0.2130,  0.2307],\n",
            "        [ 0.7364,  1.0000,  0.8039,  ...,  0.7621, -0.3966, -0.6247],\n",
            "        [ 0.2753,  0.9986, -0.1156,  ..., -0.8560,  0.0834, -0.8538],\n",
            "        ...,\n",
            "        [ 0.5040,  0.9990,  0.9292,  ...,  0.6331, -0.4815, -0.6524],\n",
            "        [ 0.7401,  1.0000,  0.9003,  ...,  0.6827, -0.7214, -0.5930],\n",
            "        [-0.1069,  0.9996,  0.0280,  ..., -0.8221,  0.5196, -0.7141]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0320,  0.9996, -0.8694,  ..., -0.9306,  0.5090, -0.2040],\n",
            "        [-0.2014,  0.9994, -0.1823,  ..., -0.5280,  0.5630, -0.4811],\n",
            "        [ 0.0839,  1.0000, -0.8340,  ..., -0.8462,  0.3260, -0.2143],\n",
            "        ...,\n",
            "        [ 0.2861,  1.0000,  0.8839,  ...,  0.7550, -0.3619, -0.7749],\n",
            "        [ 0.5997,  1.0000,  0.8431,  ...,  0.7191, -0.7879, -0.3053],\n",
            "        [ 0.5014,  1.0000,  0.7564,  ...,  0.8224, -0.5340, -0.6135]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4975,  0.9999,  0.8825,  ...,  0.8388, -0.7781, -0.3632],\n",
            "        [ 0.1380,  0.9942, -0.8493,  ..., -0.9224,  0.4314, -0.3115],\n",
            "        [-0.4136,  0.8940, -0.9276,  ..., -0.8850,  0.1362,  0.5161],\n",
            "        ...,\n",
            "        [ 0.3589,  0.9997,  0.8175,  ...,  0.7627, -0.7594, -0.3013],\n",
            "        [ 0.3322,  0.9988,  0.6444,  ...,  0.0910, -0.4428, -0.5875],\n",
            "        [ 0.2157,  1.0000,  0.7081,  ...,  0.2446, -0.2234, -0.7908]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2737,  1.0000,  0.7097,  ...,  0.6159, -0.4302, -0.8426],\n",
            "        [ 0.0748,  1.0000, -0.1366,  ..., -0.6824,  0.1069, -0.8001],\n",
            "        [-0.5571,  0.0210, -0.9444,  ..., -0.9123,  0.1618,  0.2850],\n",
            "        ...,\n",
            "        [ 0.5952,  0.9999,  0.8938,  ...,  0.8529, -0.7191, -0.5259],\n",
            "        [-0.2452,  0.9943, -0.9335,  ..., -0.9519,  0.2986, -0.0221],\n",
            "        [ 0.5441,  0.9996,  0.8828,  ...,  0.6948, -0.6884, -0.1876]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6546,  0.9996,  0.7572,  ...,  0.7339, -0.8453, -0.3822],\n",
            "        [-0.0618,  0.9859, -0.9184,  ..., -0.8792,  0.3337,  0.0670],\n",
            "        [ 0.7080,  0.9999,  0.8414,  ...,  0.8061, -0.7847, -0.2452],\n",
            "        ...,\n",
            "        [-0.2267,  0.9950, -0.9293,  ..., -0.8865,  0.2490,  0.1437],\n",
            "        [ 0.1986,  1.0000, -0.6716,  ..., -0.6694,  0.8533, -0.9389],\n",
            "        [ 0.5445,  0.9986,  0.8842,  ...,  0.5887, -0.6561, -0.6196]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5079,  0.9995,  0.8198,  ...,  0.8903, -0.7298, -0.0019],\n",
            "        [-0.2454,  0.9993, -0.9032,  ..., -0.9003,  0.6094,  0.0066],\n",
            "        [ 0.5651,  0.9999,  0.9440,  ...,  0.8591, -0.6297, -0.5986],\n",
            "        ...,\n",
            "        [-0.4400,  0.6511, -0.9263,  ..., -0.7742,  0.5309,  0.4369],\n",
            "        [-0.0751,  0.9865, -0.9080,  ..., -0.8727,  0.3786,  0.2409],\n",
            "        [-0.6980,  0.9215, -0.9053,  ..., -0.8506,  0.1422,  0.1623]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5667,  0.9994, -0.8067,  ..., -0.8387,  0.3928, -0.4488],\n",
            "        [ 0.5954,  1.0000, -0.5432,  ..., -0.5936,  0.6176, -0.5134],\n",
            "        [ 0.4219,  0.9995,  0.8643,  ...,  0.8071, -0.8059, -0.3621],\n",
            "        ...,\n",
            "        [ 0.6132,  0.9999,  0.8484,  ...,  0.6111, -0.6320, -0.5957],\n",
            "        [ 0.5133,  0.9998,  0.7704,  ...,  0.8802, -0.7116, -0.5037],\n",
            "        [ 0.5266,  1.0000,  0.9611,  ...,  0.3573,  0.2983, -0.9214]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1291,  1.0000, -0.0502,  ..., -0.8165,  0.8445, -0.8286],\n",
            "        [-0.2629,  0.9999, -0.7852,  ..., -0.8111,  0.4189, -0.7825],\n",
            "        [ 0.5703,  0.9999,  0.9235,  ...,  0.8624, -0.7430, -0.4076],\n",
            "        ...,\n",
            "        [ 0.0168,  1.0000, -0.4915,  ..., -0.7144,  0.6217, -0.7778],\n",
            "        [ 0.4716,  0.9999,  0.9370,  ...,  0.8850, -0.6053, -0.3798],\n",
            "        [ 0.2072,  1.0000,  0.8462,  ...,  0.1470, -0.4044, -0.7580]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5334,  0.9999,  0.8685,  ...,  0.8379, -0.6240, -0.6399],\n",
            "        [ 0.4741,  0.9998,  0.8306,  ...,  0.7830, -0.7607, -0.1586],\n",
            "        [-0.3594,  0.9990, -0.7461,  ..., -0.9273,  0.1361,  0.3230],\n",
            "        ...,\n",
            "        [ 0.2627,  1.0000,  0.8125,  ..., -0.1936, -0.3666, -0.8360],\n",
            "        [ 0.4472,  0.9999,  0.8828,  ...,  0.7843, -0.6888, -0.3946],\n",
            "        [ 0.8022,  1.0000,  0.7463,  ...,  0.3608, -0.3205, -0.5152]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3114,  0.9891, -0.8988,  ..., -0.8954,  0.2513,  0.3043],\n",
            "        [ 0.5119,  0.9999,  0.8243,  ...,  0.8347, -0.6883, -0.3712],\n",
            "        [ 0.5373,  0.9996,  0.9210,  ...,  0.8238, -0.6317, -0.2049],\n",
            "        ...,\n",
            "        [-0.1448,  1.0000, -0.4386,  ..., -0.7774,  0.3964, -0.5218],\n",
            "        [-0.1421,  1.0000, -0.3731,  ..., -0.7926,  0.7142, -0.4667],\n",
            "        [ 0.5601,  0.9999,  0.8842,  ...,  0.7245, -0.5833, -0.6637]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7025,  1.0000,  0.7859,  ...,  0.7780, -0.6763, -0.4832],\n",
            "        [ 0.5015,  0.9998,  0.8427,  ...,  0.8619, -0.6583, -0.5547],\n",
            "        [ 0.4514,  1.0000,  0.8583,  ...,  0.7440, -0.4102, -0.3293],\n",
            "        ...,\n",
            "        [-0.5947,  0.8335, -0.9438,  ..., -0.9045,  0.2768,  0.2508],\n",
            "        [-0.5031,  0.9825, -0.9094,  ..., -0.9431,  0.0039,  0.1811],\n",
            "        [ 0.2605,  0.9997,  0.8468,  ...,  0.7498, -0.7346, -0.1267]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.8110,  0.9904, -0.9029,  ..., -0.8805,  0.4398,  0.5297],\n",
            "        [-0.3908,  1.0000, -0.6996,  ..., -0.8682,  0.2704, -0.6057],\n",
            "        [ 0.6086,  0.9994,  0.8947,  ...,  0.8244, -0.7371, -0.4613],\n",
            "        ...,\n",
            "        [-0.4315,  0.9602, -0.8950,  ..., -0.8658,  0.3433,  0.0132],\n",
            "        [ 0.4455,  0.9997,  0.8597,  ...,  0.8628, -0.7961, -0.4020],\n",
            "        [-0.5273,  0.9982, -0.5067,  ..., -0.7363, -0.0590, -0.3989]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5186,  1.0000,  0.8593,  ...,  0.8284, -0.6806, -0.3704],\n",
            "        [ 0.7218,  1.0000,  0.8825,  ...,  0.7255, -0.7881, -0.2491],\n",
            "        [ 0.6975,  1.0000, -0.5082,  ..., -0.8297,  0.6448, -0.5447],\n",
            "        ...,\n",
            "        [ 0.5532,  1.0000,  0.6935,  ...,  0.5523, -0.7113, -0.5733],\n",
            "        [ 0.0982,  0.9897, -0.8491,  ..., -0.9074,  0.0920, -0.7335],\n",
            "        [ 0.5795,  0.9999,  0.9158,  ...,  0.7793, -0.8033, -0.5656]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4922,  0.9986, -0.8566,  ..., -0.8915,  0.3474,  0.3362],\n",
            "        [ 0.3706,  0.9997,  0.8825,  ...,  0.8537, -0.7773, -0.2436],\n",
            "        [ 0.4923,  1.0000,  0.9432,  ..., -0.0171,  0.2870, -0.9754],\n",
            "        ...,\n",
            "        [-0.2368,  0.6869, -0.8987,  ..., -0.8548,  0.2309, -0.0521],\n",
            "        [ 0.3923,  0.9999,  0.8496,  ...,  0.8187, -0.7697, -0.0524],\n",
            "        [ 0.6362,  0.9999,  0.8690,  ...,  0.9026, -0.7035, -0.5266]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3315,  0.9996,  0.8605,  ...,  0.8106, -0.7449, -0.2498],\n",
            "        [ 0.6368,  1.0000,  0.9106,  ...,  0.8922, -0.7073, -0.4827],\n",
            "        [-0.5308, -0.6311, -0.9385,  ..., -0.9213, -0.0922,  0.7943],\n",
            "        ...,\n",
            "        [-0.3779,  0.9697, -0.7328,  ..., -0.8426,  0.7084,  0.2417],\n",
            "        [ 0.5441,  0.9999,  0.8695,  ...,  0.7402, -0.8095, -0.5917],\n",
            "        [ 0.3039,  0.9991,  0.8134,  ...,  0.7917, -0.7382, -0.4311]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3055,  0.9995, -0.8961,  ..., -0.9578, -0.0651, -0.2270],\n",
            "        [ 0.6344,  0.9996,  0.8687,  ...,  0.8839, -0.6065, -0.6025],\n",
            "        [ 0.4424,  0.9996,  0.7912,  ...,  0.7618, -0.8517, -0.2819],\n",
            "        ...,\n",
            "        [-0.5508,  0.9579, -0.6652,  ..., -0.8372,  0.1204, -0.4699],\n",
            "        [ 0.6805,  0.9999,  0.8474,  ...,  0.8309, -0.4139, -0.4183],\n",
            "        [-0.2243,  0.9997, -0.7289,  ..., -0.8844,  0.6684, -0.0688]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4350,  0.8510, -0.9217,  ..., -0.9176,  0.1925,  0.3473],\n",
            "        [ 0.6069,  1.0000,  0.8923,  ...,  0.8509, -0.7570, -0.5355],\n",
            "        [ 0.1017,  1.0000,  0.8249,  ...,  0.4207, -0.6684, -0.6634],\n",
            "        ...,\n",
            "        [-0.0833,  1.0000, -0.1554,  ..., -0.7842,  0.3609, -0.6165],\n",
            "        [-0.7749,  0.9849, -0.9218,  ..., -0.9451,  0.3130,  0.4049],\n",
            "        [-0.2709,  0.9577, -0.8958,  ..., -0.9137,  0.1505,  0.4098]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4783,  0.9652, -0.4779,  ..., -0.8110,  0.1181, -0.5039],\n",
            "        [-0.4190,  0.9396, -0.8963,  ..., -0.9306,  0.3179,  0.1915],\n",
            "        [-0.1124,  1.0000, -0.1238,  ..., -0.7223, -0.1181, -0.5847],\n",
            "        ...,\n",
            "        [ 0.5816,  0.9999,  0.8088,  ...,  0.8602, -0.6602, -0.2881],\n",
            "        [-0.4526,  0.6028, -0.7487,  ..., -0.7830,  0.5455, -0.1242],\n",
            "        [-0.4380,  0.9093, -0.8751,  ..., -0.8885,  0.1220,  0.3744]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3772,  0.9997,  0.8620,  ...,  0.8648, -0.7460,  0.0461],\n",
            "        [ 0.6444,  1.0000,  0.8732,  ...,  0.5527, -0.7152, -0.5571],\n",
            "        [ 0.6312,  0.9999,  0.8789,  ...,  0.8160, -0.6981, -0.4664],\n",
            "        ...,\n",
            "        [-0.3362,  0.0117, -0.8265,  ..., -0.8713,  0.3604, -0.0457],\n",
            "        [ 0.4239,  0.9997,  0.8780,  ...,  0.8449, -0.7994, -0.4051],\n",
            "        [ 0.3416,  0.9999,  0.8486,  ...,  0.8048, -0.7905, -0.2132]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4359,  0.9991,  0.7419,  ...,  0.6998, -0.8624, -0.1686],\n",
            "        [ 0.6287,  0.9999,  0.7935,  ...,  0.7543, -0.7895, -0.2290],\n",
            "        [ 0.1561,  0.9991, -0.8178,  ..., -0.8826,  0.5521, -0.4119],\n",
            "        ...,\n",
            "        [ 0.6842,  0.9997,  0.8724,  ...,  0.7933, -0.7850, -0.5575],\n",
            "        [-0.6134, -0.9896, -0.8777,  ..., -0.9376,  0.4535,  0.4840],\n",
            "        [ 0.5069,  1.0000,  0.9127,  ...,  0.8496, -0.6828, -0.5636]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5119,  0.9429, -0.9258,  ..., -0.9203,  0.1756,  0.4256],\n",
            "        [ 0.1556,  1.0000, -0.4237,  ..., -0.8266,  0.3299, -0.7060],\n",
            "        [ 0.6704,  1.0000,  0.8502,  ...,  0.8369, -0.6091, -0.5411],\n",
            "        ...,\n",
            "        [-0.5443, -0.7251, -0.9177,  ..., -0.8994,  0.1185,  0.7983],\n",
            "        [ 0.6807,  0.9999,  0.8966,  ...,  0.8203, -0.7309, -0.4229],\n",
            "        [-0.6319, -0.1497, -0.9372,  ..., -0.9579,  0.0540,  0.2987]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3677,  0.9977,  0.8012,  ...,  0.8017, -0.8215, -0.0705],\n",
            "        [ 0.5465,  0.9998,  0.9039,  ...,  0.8408, -0.7554, -0.3410],\n",
            "        [ 0.0198,  0.9993, -0.7094,  ..., -0.9176,  0.4794,  0.0572],\n",
            "        ...,\n",
            "        [ 0.6929,  1.0000,  0.4074,  ..., -0.4976,  0.4459, -0.9111],\n",
            "        [ 0.4545,  0.9993,  0.9313,  ...,  0.7770, -0.6365, -0.4264],\n",
            "        [ 0.6966,  0.9995,  0.9121,  ...,  0.7668, -0.7455, -0.4689]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2218,  1.0000,  0.8341,  ...,  0.7020, -0.7146, -0.7002],\n",
            "        [ 0.1230,  0.9978, -0.9030,  ..., -0.8243,  0.3548,  0.4649],\n",
            "        [ 0.2034,  0.9998,  0.8903,  ...,  0.7822, -0.7517, -0.1608],\n",
            "        ...,\n",
            "        [ 0.7522,  1.0000,  0.8942,  ...,  0.7684, -0.3276, -0.5652],\n",
            "        [-0.3061,  0.9930, -0.8432,  ..., -0.9029,  0.4399, -0.0551],\n",
            "        [-0.3444,  0.4630, -0.9395,  ..., -0.8875,  0.1031,  0.4328]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5683,  0.9478, -0.9053,  ..., -0.8949,  0.0211,  0.4698],\n",
            "        [-0.2303,  0.9999, -0.7501,  ..., -0.4448,  0.6095, -0.2194],\n",
            "        [ 0.5370,  0.9997,  0.8085,  ...,  0.8684, -0.7226, -0.5245],\n",
            "        ...,\n",
            "        [-0.6225, -0.1250, -0.8441,  ..., -0.9146, -0.0088,  0.1767],\n",
            "        [ 0.8393,  1.0000,  0.9694,  ...,  0.8316, -0.6063, -0.7834],\n",
            "        [ 0.5000,  0.9961,  0.8300,  ...,  0.8280, -0.7017, -0.4085]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3897,  0.9998,  0.7855,  ...,  0.7715, -0.6213, -0.5776],\n",
            "        [ 0.7089,  0.9999,  0.8878,  ...,  0.8731, -0.6007, -0.4678],\n",
            "        [ 0.5668,  0.9997,  0.6702,  ...,  0.6781, -0.5976, -0.6466],\n",
            "        ...,\n",
            "        [-0.5311,  0.8822, -0.9344,  ..., -0.8730,  0.0308,  0.3208],\n",
            "        [-0.2062,  0.9968, -0.7756,  ..., -0.7955,  0.5592, -0.1839],\n",
            "        [ 0.6699,  0.9998,  0.8411,  ...,  0.7777, -0.7004, -0.5039]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6117, -0.9436, -0.9341,  ..., -0.9275,  0.3090,  0.3255],\n",
            "        [-0.3909,  0.0459, -0.9382,  ..., -0.9222,  0.3615,  0.4638],\n",
            "        [ 0.3686,  0.9997,  0.8601,  ...,  0.6669, -0.6888, -0.6237],\n",
            "        ...,\n",
            "        [ 0.6228,  1.0000,  0.8724,  ...,  0.4389, -0.4916, -0.5492],\n",
            "        [-0.7026,  0.9953, -0.8822,  ..., -0.8726, -0.1961,  0.4148],\n",
            "        [-0.3603,  0.9951, -0.8702,  ..., -0.8990,  0.4898,  0.1403]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5784,  0.9947, -0.7977,  ..., -0.8847,  0.3827, -0.2522],\n",
            "        [ 0.8169,  1.0000,  0.7139,  ...,  0.3425, -0.2624, -0.8255],\n",
            "        [-0.4813,  0.9997, -0.7415,  ..., -0.7238,  0.4785, -0.2471],\n",
            "        ...,\n",
            "        [ 0.5660,  0.9999,  0.8895,  ...,  0.7579, -0.7353, -0.3695],\n",
            "        [ 0.2384,  1.0000,  0.9232,  ...,  0.4977, -0.5424, -0.8280],\n",
            "        [ 0.6342,  1.0000,  0.8935,  ...,  0.7302, -0.2636, -0.8021]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5100,  0.9999,  0.9265,  ...,  0.8081, -0.6829, -0.3485],\n",
            "        [ 0.5702,  1.0000,  0.7679,  ...,  0.7562, -0.3483, -0.4810],\n",
            "        [ 0.5283,  0.9998,  0.7912,  ...,  0.7981, -0.7802, -0.2928],\n",
            "        ...,\n",
            "        [-0.7712,  0.8933, -0.9124,  ..., -0.9143,  0.1500,  0.2033],\n",
            "        [ 0.2028,  0.9999, -0.8210,  ..., -0.9103,  0.7538, -0.6306],\n",
            "        [-0.4224,  0.9995, -0.7586,  ..., -0.9076,  0.5324, -0.0607]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2047,  0.6355, -0.9300,  ..., -0.8657,  0.2994,  0.0313],\n",
            "        [-0.1651,  1.0000, -0.7718,  ..., -0.7820,  0.6537, -0.6709],\n",
            "        [ 0.3904,  0.9985,  0.8487,  ...,  0.7739, -0.7179, -0.1438],\n",
            "        ...,\n",
            "        [ 0.4253,  0.9996,  0.8066,  ...,  0.8646, -0.5528, -0.5293],\n",
            "        [ 0.4785,  1.0000,  0.6911,  ...,  0.8145, -0.6383, -0.3598],\n",
            "        [ 0.1643,  1.0000,  0.8649,  ...,  0.6952, -0.4588, -0.4755]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6229,  1.0000,  0.9491,  ...,  0.6671, -0.4560, -0.5468],\n",
            "        [ 0.4455,  0.9999,  0.8829,  ...,  0.8243, -0.6933,  0.1086],\n",
            "        [ 0.6771,  1.0000,  0.8820,  ...,  0.8026,  0.2337, -0.8195],\n",
            "        ...,\n",
            "        [-0.5530,  0.9896, -0.8935,  ..., -0.9528,  0.3553, -0.2380],\n",
            "        [ 0.3951,  0.9991,  0.7809,  ...,  0.7603, -0.6794, -0.2114],\n",
            "        [-0.4113, -0.4849, -0.9631,  ..., -0.9542,  0.2023,  0.4205]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6475,  1.0000,  0.9169,  ...,  0.8109, -0.6516, -0.3626],\n",
            "        [-0.2925,  0.0681, -0.9228,  ..., -0.8890,  0.2621,  0.1359],\n",
            "        [ 0.4065,  0.9997, -0.8612,  ..., -0.8697,  0.7459, -0.4852],\n",
            "        ...,\n",
            "        [ 0.0028,  1.0000,  0.8653,  ..., -0.0789, -0.1139, -0.7975],\n",
            "        [ 0.6012,  0.9999,  0.8876,  ...,  0.8080, -0.4904, -0.5939],\n",
            "        [ 0.4933,  1.0000,  0.8181,  ...,  0.7553, -0.4747, -0.5363]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7616,  1.0000,  0.8772,  ...,  0.8004, -0.7539, -0.6669],\n",
            "        [ 0.1955,  0.9999, -0.5082,  ..., -0.5639,  0.5552, -0.6375],\n",
            "        [-0.1637, -0.8936, -0.9056,  ..., -0.8525,  0.5063,  0.2479],\n",
            "        ...,\n",
            "        [ 0.6758,  0.9998,  0.8379,  ...,  0.7821, -0.7904, -0.5055],\n",
            "        [ 0.6262,  1.0000,  0.4018,  ...,  0.0703,  0.0532, -0.9265],\n",
            "        [ 0.7106,  1.0000,  0.8978,  ...,  0.7280, -0.5210, -0.8216]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7700,  1.0000,  0.7495,  ...,  0.6726, -0.2218, -0.6508],\n",
            "        [ 0.5595,  1.0000,  0.8165,  ...,  0.5590, -0.5585, -0.6560],\n",
            "        [ 0.5675,  1.0000,  0.8895,  ...,  0.1354, -0.5170, -0.8716],\n",
            "        ...,\n",
            "        [ 0.5507,  0.9960, -0.8504,  ..., -0.9257,  0.7170,  0.1053],\n",
            "        [-0.3952, -0.7903, -0.9266,  ..., -0.9130,  0.0383,  0.3078],\n",
            "        [-0.4949, -0.8106, -0.9321,  ..., -0.9073,  0.0654,  0.4518]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4255,  1.0000,  0.8655,  ...,  0.6725, -0.5589, -0.6368],\n",
            "        [ 0.5270,  1.0000,  0.9085,  ...,  0.7384, -0.2961, -0.9139],\n",
            "        [ 0.4892,  1.0000,  0.9119,  ...,  0.3420, -0.5831, -0.8129],\n",
            "        ...,\n",
            "        [-0.3417,  0.1936, -0.9213,  ..., -0.8993, -0.0048,  0.0317],\n",
            "        [ 0.6184,  1.0000,  0.6770,  ...,  0.3988, -0.2064, -0.7480],\n",
            "        [-0.3957, -0.8624, -0.9427,  ..., -0.9524,  0.2440,  0.1675]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4749,  0.9985,  0.8718,  ...,  0.8479, -0.8514, -0.3365],\n",
            "        [ 0.7009,  0.9999,  0.9239,  ...,  0.8539, -0.7069, -0.7465],\n",
            "        [-0.5541,  0.4844, -0.9206,  ..., -0.9004,  0.5697,  0.1140],\n",
            "        ...,\n",
            "        [ 0.4994,  1.0000,  0.6192,  ...,  0.6499, -0.3832, -0.6006],\n",
            "        [-0.3324,  0.6781, -0.9503,  ..., -0.9147, -0.0172,  0.1092],\n",
            "        [ 0.5676,  1.0000,  0.8076,  ...,  0.4626, -0.2945, -0.6783]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5104,  0.5930, -0.9026,  ..., -0.9125,  0.1701,  0.6108],\n",
            "        [ 0.6296,  0.9980,  0.8653,  ...,  0.7826, -0.7907, -0.0849],\n",
            "        [-0.1200,  1.0000,  0.7361,  ..., -0.2424,  0.0497, -0.8262],\n",
            "        ...,\n",
            "        [ 0.5635,  1.0000,  0.8750,  ...,  0.4569, -0.4241, -0.8796],\n",
            "        [-0.6566,  0.9097, -0.8899,  ..., -0.9297,  0.2279, -0.1337],\n",
            "        [-0.6219,  0.9818, -0.9382,  ..., -0.8621,  0.2414,  0.2986]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2387,  0.9998,  0.0708,  ..., -0.3623, -0.2865, -0.6255],\n",
            "        [ 0.4933,  0.9999,  0.8556,  ...,  0.8250, -0.7821, -0.2167],\n",
            "        [-0.4857, -0.9966, -0.9077,  ..., -0.9084,  0.2421,  0.7209],\n",
            "        ...,\n",
            "        [-0.6702, -0.2388, -0.9161,  ..., -0.9420,  0.1994,  0.4521],\n",
            "        [ 0.3166,  1.0000,  0.5765,  ..., -0.0439, -0.5164, -0.7543],\n",
            "        [-0.2107,  0.1511, -0.9319,  ..., -0.9133,  0.1580,  0.2506]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5861, -0.9091, -0.9498,  ..., -0.9232,  0.1648,  0.4196],\n",
            "        [ 0.4538,  0.9997,  0.8558,  ...,  0.8742, -0.8354, -0.4898],\n",
            "        [-0.1876,  0.9562, -0.9041,  ..., -0.9089,  0.5702,  0.2779],\n",
            "        ...,\n",
            "        [ 0.1189,  1.0000,  0.7797,  ...,  0.6603, -0.4401, -0.6085],\n",
            "        [ 0.5690,  1.0000,  0.8501,  ...,  0.8722, -0.6171, -0.5322],\n",
            "        [ 0.7209,  1.0000,  0.9215,  ...,  0.7620, -0.6289, -0.7139]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5005, -0.9657, -0.8955,  ..., -0.8945,  0.0460,  0.5686],\n",
            "        [ 0.6961,  0.9997,  0.7256,  ...,  0.8524, -0.6447, -0.4791],\n",
            "        [ 0.1691,  0.9997,  0.6147,  ...,  0.0933, -0.6940, -0.6496],\n",
            "        ...,\n",
            "        [ 0.5616,  0.9995,  0.8268,  ...,  0.8081, -0.6977, -0.6031],\n",
            "        [-0.5218, -0.6692, -0.9132,  ..., -0.9077,  0.1479,  0.5233],\n",
            "        [-0.5404,  0.9804, -0.8879,  ..., -0.9379, -0.0020,  0.1834]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4185,  0.8746, -0.7679,  ..., -0.8630,  0.3108, -0.1947],\n",
            "        [ 0.2680,  1.0000,  0.8406,  ...,  0.2614, -0.1681, -0.6185],\n",
            "        [ 0.6283,  1.0000,  0.8945,  ...,  0.7572, -0.5281, -0.6474],\n",
            "        ...,\n",
            "        [ 0.6792,  0.9998,  0.6637,  ...,  0.6637, -0.5075, -0.5425],\n",
            "        [ 0.5579,  1.0000,  0.7505,  ...,  0.5461, -0.7078, -0.7467],\n",
            "        [ 0.4540,  0.9999,  0.8711,  ...,  0.7492, -0.7503, -0.4087]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5412,  0.9900, -0.6646,  ..., -0.8584, -0.1809,  0.4025],\n",
            "        [ 0.2156,  1.0000,  0.6841,  ...,  0.6103, -0.5224, -0.3586],\n",
            "        [-0.4852,  0.9875, -0.8767,  ..., -0.8710,  0.3807, -0.3031],\n",
            "        ...,\n",
            "        [-0.7310,  0.8766, -0.8867,  ..., -0.9121,  0.0513,  0.4658],\n",
            "        [-0.4568, -0.9953, -0.9436,  ..., -0.9183,  0.0828,  0.6450],\n",
            "        [ 0.0478,  0.9910, -0.8744,  ..., -0.7967,  0.4005, -0.1800]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5670,  1.0000,  0.8143,  ...,  0.7355, -0.4771, -0.6804],\n",
            "        [-0.4790, -0.9910, -0.9465,  ..., -0.9440,  0.3802,  0.6070],\n",
            "        [-0.6964, -0.2209, -0.8708,  ..., -0.9084, -0.0362,  0.3199],\n",
            "        ...,\n",
            "        [-0.6911,  0.6196, -0.9266,  ..., -0.8957,  0.1425,  0.5616],\n",
            "        [ 0.5467,  1.0000,  0.8652,  ...,  0.8612, -0.7894, -0.1074],\n",
            "        [ 0.5925,  1.0000,  0.8608,  ...,  0.5394, -0.2435, -0.7588]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7242,  0.9997,  0.9067,  ...,  0.8248, -0.6648, -0.5772],\n",
            "        [ 0.6518,  0.9999,  0.7984,  ...,  0.7984, -0.6877, -0.4518],\n",
            "        [-0.1777,  0.9801, -0.9056,  ..., -0.8330,  0.7028,  0.0626],\n",
            "        ...,\n",
            "        [ 0.6513,  0.9996,  0.8074,  ...,  0.7985, -0.7120, -0.2330],\n",
            "        [-0.5235,  0.5610, -0.9208,  ..., -0.9178,  0.3350,  0.4192],\n",
            "        [-0.3541,  0.9246, -0.9153,  ..., -0.9010,  0.1566,  0.2465]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3322, -0.7161, -0.9356,  ..., -0.9355,  0.1893,  0.2746],\n",
            "        [ 0.6438,  0.9999,  0.9331,  ...,  0.8988, -0.7783, -0.5656],\n",
            "        [ 0.3525,  1.0000,  0.8295,  ...,  0.7601, -0.7491, -0.4466],\n",
            "        ...,\n",
            "        [ 0.4829,  1.0000,  0.8879,  ...,  0.7905, -0.5346, -0.8043],\n",
            "        [ 0.5334,  1.0000,  0.8364,  ...,  0.8359, -0.5860, -0.5487],\n",
            "        [-0.4178,  0.7987, -0.9030,  ..., -0.8621, -0.0121,  0.2931]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4348,  0.9999,  0.9117,  ...,  0.7348, -0.8064, -0.4213],\n",
            "        [ 0.0397,  0.9989,  0.5083,  ..., -0.2786, -0.0600, -0.8031],\n",
            "        [-0.5242,  0.9957, -0.9224,  ..., -0.8800,  0.5934,  0.1518],\n",
            "        ...,\n",
            "        [-0.5050,  0.4160, -0.9196,  ..., -0.8642,  0.2005,  0.3931],\n",
            "        [-0.6224, -0.9775, -0.9273,  ..., -0.9241,  0.0646,  0.4478],\n",
            "        [-0.4516, -0.8013, -0.9474,  ..., -0.9073,  0.3332,  0.2346]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4148,  0.9999,  0.9193,  ...,  0.7731, -0.7463, -0.3860],\n",
            "        [-0.1461,  0.9904, -0.8424,  ..., -0.9167,  0.0972,  0.2058],\n",
            "        [ 0.3352,  0.9998,  0.8272,  ...,  0.7854, -0.7109, -0.5114],\n",
            "        ...,\n",
            "        [ 0.6153,  1.0000,  0.8193,  ...,  0.7787, -0.6224, -0.4336],\n",
            "        [-0.8369, -0.9898, -0.9149,  ..., -0.9026,  0.0796,  0.7300],\n",
            "        [ 0.6164,  1.0000,  0.7694,  ...,  0.8825, -0.6888, -0.6721]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4396,  0.9997,  0.7606,  ...,  0.8237, -0.8636, -0.1727],\n",
            "        [ 0.7269,  1.0000,  0.6707,  ...,  0.8255, -0.6853, -0.4261],\n",
            "        [ 0.5403,  1.0000,  0.8396,  ...,  0.8246, -0.7659, -0.2888],\n",
            "        ...,\n",
            "        [ 0.3477,  1.0000,  0.8662,  ...,  0.8456, -0.5419, -0.5253],\n",
            "        [ 0.7236,  1.0000,  0.8991,  ...,  0.7310, -0.5946, -0.3520],\n",
            "        [-0.5515,  0.7971, -0.9582,  ..., -0.9487,  0.1824,  0.5857]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2156,  0.9993, -0.8418,  ..., -0.8035,  0.0799, -0.1723],\n",
            "        [ 0.5535,  1.0000,  0.9450,  ...,  0.9113, -0.5633, -0.6190],\n",
            "        [-0.3420,  0.8923, -0.9341,  ..., -0.9366,  0.3442,  0.1558],\n",
            "        ...,\n",
            "        [-0.5907,  0.9964, -0.8707,  ..., -0.9227, -0.0214,  0.2607],\n",
            "        [ 0.5559,  0.9999,  0.8981,  ...,  0.8073, -0.7267, -0.6375],\n",
            "        [ 0.6504,  1.0000,  0.9506,  ...,  0.7883, -0.5665, -0.7940]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2835,  0.9374, -0.9076,  ..., -0.8734,  0.3986, -0.1498],\n",
            "        [-0.2535,  0.6602, -0.9219,  ..., -0.9261,  0.3739,  0.2769],\n",
            "        [ 0.6859,  0.9999,  0.9223,  ...,  0.8902, -0.6919, -0.4866],\n",
            "        ...,\n",
            "        [-0.4281,  0.2948, -0.9312,  ..., -0.8946,  0.3699,  0.3007],\n",
            "        [-0.0757,  0.9989,  0.7745,  ..., -0.4645, -0.4996, -0.5459],\n",
            "        [-0.4535,  0.9166, -0.9154,  ..., -0.9388,  0.2480,  0.4688]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3717,  1.0000,  0.9235,  ...,  0.5582,  0.1610, -0.7197],\n",
            "        [-0.4622,  0.6837, -0.8414,  ..., -0.9052,  0.1286,  0.4163],\n",
            "        [ 0.7382,  1.0000,  0.8628,  ...,  0.7056, -0.5640, -0.6243],\n",
            "        ...,\n",
            "        [ 0.4476,  1.0000,  0.9264,  ...,  0.8408, -0.7340, -0.5615],\n",
            "        [ 0.5917,  1.0000,  0.9181,  ...,  0.6838, -0.5813, -0.5945],\n",
            "        [ 0.6662,  1.0000,  0.9306,  ...,  0.7505, -0.6598, -0.6144]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7437,  1.0000,  0.8384,  ...,  0.6685, -0.5427, -0.7790],\n",
            "        [-0.6675,  0.9060, -0.9323,  ..., -0.9546,  0.3071,  0.3823],\n",
            "        [-0.7687,  0.0810, -0.9222,  ..., -0.9085,  0.1075,  0.4475],\n",
            "        ...,\n",
            "        [-0.0827,  0.9986, -0.8086,  ..., -0.9375,  0.6914, -0.4205],\n",
            "        [-0.2349, -0.5351, -0.8730,  ..., -0.8214,  0.4031,  0.4936],\n",
            "        [-0.6185,  0.9555, -0.8482,  ..., -0.8654,  0.2162, -0.1182]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1613,  1.0000, -0.2255,  ..., -0.8621,  0.4283, -0.7613],\n",
            "        [-0.4639, -0.9670, -0.8675,  ..., -0.8800,  0.2660,  0.6249],\n",
            "        [-0.1508,  0.9999, -0.8117,  ..., -0.8590,  0.0769, -0.1445],\n",
            "        ...,\n",
            "        [ 0.5863,  1.0000,  0.9133,  ...,  0.7638, -0.7073, -0.2289],\n",
            "        [ 0.6546,  1.0000,  0.9516,  ...,  0.7675, -0.3519, -0.7192],\n",
            "        [-0.2982,  0.9862, -0.9230,  ..., -0.8517, -0.2395,  0.2895]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4590,  1.0000,  0.9263,  ...,  0.6074,  0.0315, -0.7189],\n",
            "        [-0.4815,  0.8429, -0.9092,  ..., -0.8680,  0.0540,  0.2143],\n",
            "        [ 0.5273,  0.9999,  0.8774,  ...,  0.7861, -0.6373, -0.2524],\n",
            "        ...,\n",
            "        [ 0.3456,  0.9999,  0.9322,  ...,  0.8575, -0.7195, -0.4500],\n",
            "        [-0.4359,  0.3695, -0.8550,  ..., -0.8315,  0.4748,  0.5650],\n",
            "        [ 0.4401,  0.9999,  0.9090,  ...,  0.8028, -0.6624, -0.4756]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5988,  1.0000,  0.9283,  ...,  0.8824, -0.3431, -0.6235],\n",
            "        [-0.3351,  0.9915, -0.6792,  ..., -0.6673,  0.4769, -0.4920],\n",
            "        [ 0.7229,  1.0000,  0.8941,  ...,  0.9216, -0.6484, -0.5687],\n",
            "        ...,\n",
            "        [ 0.6235,  1.0000,  0.9357,  ...,  0.8144, -0.5133, -0.5911],\n",
            "        [-0.4754,  0.9143, -0.9037,  ..., -0.9038,  0.1232,  0.4469],\n",
            "        [ 0.1527,  0.6144, -0.6424,  ..., -0.8602,  0.2939, -0.4206]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4194,  1.0000,  0.8631,  ...,  0.8979, -0.5206, -0.6992],\n",
            "        [ 0.6934,  1.0000,  0.9217,  ...,  0.9224, -0.7607, -0.7455],\n",
            "        [-0.5229, -0.6662, -0.8399,  ..., -0.9417,  0.2163,  0.2756],\n",
            "        ...,\n",
            "        [-0.4175,  0.2174, -0.9150,  ..., -0.9022,  0.2685,  0.5661],\n",
            "        [-0.5116,  0.1707, -0.9322,  ..., -0.8492, -0.0920,  0.3131],\n",
            "        [ 0.5685,  1.0000,  0.8575,  ...,  0.7856, -0.2996, -0.7864]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7229,  1.0000,  0.9403,  ...,  0.8162, -0.3076, -0.8252],\n",
            "        [-0.4789,  0.9205, -0.8422,  ..., -0.9139,  0.0872,  0.4643],\n",
            "        [-0.2067, -0.8302, -0.7937,  ..., -0.9505,  0.2386,  0.6871],\n",
            "        ...,\n",
            "        [ 0.5179,  1.0000,  0.8911,  ...,  0.7301, -0.6114, -0.8013],\n",
            "        [ 0.7094,  1.0000,  0.9530,  ...,  0.8869, -0.1761, -0.8354],\n",
            "        [ 0.7426,  1.0000,  0.9615,  ...,  0.9138, -0.2797, -0.7814]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6690,  1.0000,  0.8481,  ...,  0.7695, -0.7011, -0.4222],\n",
            "        [ 0.4481,  1.0000,  0.9449,  ...,  0.7634, -0.6016, -0.5802],\n",
            "        [-0.6595, -0.7614, -0.7654,  ..., -0.8676,  0.4720,  0.3147],\n",
            "        ...,\n",
            "        [-0.6626,  0.9943, -0.8702,  ..., -0.8346,  0.1388,  0.5091],\n",
            "        [ 0.5765,  1.0000,  0.8676,  ...,  0.8604, -0.6826, -0.5264],\n",
            "        [ 0.7202,  1.0000,  0.9531,  ...,  0.8049, -0.0257, -0.8525]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2639,  0.9999, -0.8654,  ..., -0.8983,  0.4297, -0.4302],\n",
            "        [ 0.7465,  1.0000,  0.9481,  ...,  0.8536, -0.4853, -0.8083],\n",
            "        [-0.6732,  0.0730, -0.9177,  ..., -0.8656,  0.1929,  0.4994],\n",
            "        ...,\n",
            "        [ 0.7770,  1.0000,  0.9611,  ...,  0.8359, -0.2793, -0.8258],\n",
            "        [ 0.3561,  1.0000,  0.8086,  ...,  0.7309, -0.5649, -0.4574],\n",
            "        [ 0.6854,  1.0000,  0.8662,  ...,  0.7890, -0.7489, -0.6659]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2987,  0.2860, -0.6065,  ..., -0.6756,  0.3287, -0.0495],\n",
            "        [ 0.6385,  1.0000,  0.9357,  ...,  0.9193, -0.4909, -0.7179],\n",
            "        [-0.5754,  0.9966, -0.9203,  ..., -0.7679,  0.5427,  0.4766],\n",
            "        ...,\n",
            "        [ 0.6108,  1.0000,  0.9480,  ...,  0.8501, -0.3135, -0.7534],\n",
            "        [ 0.5456,  1.0000,  0.9113,  ...,  0.7315, -0.3571, -0.7168],\n",
            "        [-0.8165,  0.9947, -0.9181,  ..., -0.8487,  0.0187,  0.2098]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6333,  1.0000,  0.9477,  ...,  0.9237, -0.6286, -0.4278],\n",
            "        [ 0.5912,  1.0000,  0.9691,  ...,  0.7824, -0.3319, -0.8892],\n",
            "        [-0.3259,  1.0000, -0.4638,  ..., -0.9029,  0.1846, -0.8862],\n",
            "        ...,\n",
            "        [-0.7901,  0.7535, -0.8763,  ..., -0.7911, -0.0312,  0.5670],\n",
            "        [ 0.7177,  1.0000,  0.9054,  ...,  0.8065, -0.6889, -0.3639],\n",
            "        [-0.4919,  0.9977, -0.8394,  ..., -0.8316,  0.5105, -0.2024]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6242,  1.0000,  0.8631,  ...,  0.8044, -0.5470, -0.4462],\n",
            "        [ 0.7411,  1.0000,  0.9093,  ...,  0.9235, -0.6682, -0.4973],\n",
            "        [ 0.3619,  1.0000,  0.9526,  ...,  0.8456, -0.5488, -0.7755],\n",
            "        ...,\n",
            "        [-0.3027,  0.2487, -0.8559,  ..., -0.8278,  0.8810, -0.2489],\n",
            "        [-0.5178,  0.9045, -0.8381,  ..., -0.9247,  0.5016,  0.3045],\n",
            "        [ 0.5491,  1.0000,  0.9352,  ...,  0.8496, -0.3458, -0.7379]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4018,  0.9999, -0.8534,  ..., -0.9143,  0.7695, -0.7728],\n",
            "        [-0.3237,  0.9554, -0.8735,  ..., -0.8289, -0.2427,  0.5750],\n",
            "        [-0.2524,  0.9997, -0.7529,  ..., -0.7386,  0.7947, -0.5044],\n",
            "        ...,\n",
            "        [-0.5214, -0.7809, -0.9417,  ..., -0.9182,  0.4173,  0.3933],\n",
            "        [ 0.5526,  1.0000,  0.8918,  ...,  0.9141, -0.8145, -0.6743],\n",
            "        [-0.7058,  0.8017, -0.9325,  ..., -0.8573,  0.2054,  0.6089]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7912,  1.0000,  0.9395,  ...,  0.9217, -0.5539, -0.7042],\n",
            "        [ 0.5358,  0.9999,  0.9182,  ...,  0.9152, -0.7392, -0.5516],\n",
            "        [ 0.5701,  1.0000,  0.5377,  ...,  0.3270,  0.3937, -0.9416],\n",
            "        ...,\n",
            "        [ 0.6943,  1.0000,  0.9531,  ...,  0.8331, -0.5246, -0.7761],\n",
            "        [ 0.6878,  1.0000,  0.9347,  ...,  0.8323, -0.6769, -0.7480],\n",
            "        [ 0.6605,  1.0000,  0.8628,  ...,  0.8717, -0.7268, -0.5820]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7832,  1.0000,  0.9499,  ...,  0.8983, -0.5492, -0.7377],\n",
            "        [ 0.0710,  0.9998, -0.4691,  ..., -0.7856,  0.3911, -0.6262],\n",
            "        [ 0.7534,  1.0000,  0.9403,  ...,  0.9037, -0.6528, -0.5416],\n",
            "        ...,\n",
            "        [ 0.7015,  1.0000,  0.9705,  ...,  0.6673, -0.3650, -0.8666],\n",
            "        [ 0.6780,  1.0000,  0.8627,  ...,  0.5869, -0.2778, -0.7981],\n",
            "        [-0.2055,  0.9993, -0.4956,  ..., -0.8235,  0.2231, -0.3213]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6043,  0.4101, -0.9358,  ..., -0.9092,  0.0098,  0.6947],\n",
            "        [ 0.7652,  1.0000,  0.9218,  ...,  0.8523, -0.4503, -0.5640],\n",
            "        [ 0.6764,  1.0000,  0.8998,  ...,  0.6632, -0.5562, -0.7383],\n",
            "        ...,\n",
            "        [ 0.5315,  1.0000,  0.9231,  ...,  0.8775, -0.6577, -0.6317],\n",
            "        [ 0.5982,  1.0000,  0.9487,  ...,  0.7734, -0.3027, -0.8091],\n",
            "        [ 0.5884,  1.0000,  0.9535,  ...,  0.7633, -0.3693, -0.7580]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5632,  0.9990, -0.3666,  ..., -0.4882,  0.7372, -0.6391],\n",
            "        [-0.4316,  0.9105, -0.9234,  ..., -0.9637,  0.1358,  0.5598],\n",
            "        [-0.3644, -0.9365, -0.9173,  ..., -0.9186,  0.4226,  0.4442],\n",
            "        ...,\n",
            "        [-0.4634,  0.9979, -0.3762,  ..., -0.4288,  0.6536,  0.5734],\n",
            "        [-0.3292,  0.9978, -0.8638,  ..., -0.8615,  0.3430,  0.3552],\n",
            "        [-0.3842,  0.9982, -0.8797,  ..., -0.9023,  0.4990,  0.1998]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4712,  1.0000,  0.8998,  ...,  0.8168, -0.7326, -0.3214],\n",
            "        [-0.3994, -0.2363, -0.9168,  ..., -0.8581,  0.2759,  0.2824],\n",
            "        [-0.3129,  0.9354, -0.8779,  ..., -0.7816,  0.6434,  0.1009],\n",
            "        ...,\n",
            "        [ 0.6457,  0.9999,  0.5083,  ..., -0.1047,  0.5721, -0.8877],\n",
            "        [-0.3701,  0.9921, -0.8718,  ..., -0.8642,  0.3176,  0.2154],\n",
            "        [ 0.5552,  1.0000,  0.9265,  ...,  0.5730,  0.5191, -0.8404]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1594,  0.9969, -0.8311,  ..., -0.9143,  0.4554,  0.2437],\n",
            "        [ 0.4892,  1.0000,  0.9157,  ...,  0.8532, -0.5246, -0.7064],\n",
            "        [ 0.7432,  1.0000,  0.8211,  ...,  0.8322, -0.6857, -0.5687],\n",
            "        ...,\n",
            "        [-0.6117,  0.9041, -0.8927,  ..., -0.8434,  0.2972, -0.1624],\n",
            "        [-0.5629,  0.6046, -0.8670,  ..., -0.8844,  0.3110,  0.2834],\n",
            "        [-0.5221,  0.9015, -0.9045,  ..., -0.8940,  0.1614,  0.3728]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5025,  1.0000,  0.9638,  ...,  0.7679, -0.4554, -0.6959],\n",
            "        [ 0.6740,  1.0000,  0.8922,  ...,  0.8204, -0.5534, -0.6094],\n",
            "        [ 0.6234,  1.0000,  0.9474,  ...,  0.8695, -0.5828, -0.7035],\n",
            "        ...,\n",
            "        [-0.3751,  0.9998, -0.5381,  ..., -0.6797,  0.3953,  0.4749],\n",
            "        [ 0.5481,  1.0000,  0.9050,  ...,  0.8537, -0.5611, -0.7257],\n",
            "        [ 0.7965,  1.0000,  0.9295,  ...,  0.8514, -0.7504, -0.6674]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0721,  0.9997, -0.9026,  ..., -0.8454,  0.7047, -0.1611],\n",
            "        [ 0.6685,  1.0000,  0.8434,  ...,  0.8505, -0.6948, -0.4166],\n",
            "        [-0.6824,  0.9277, -0.8630,  ..., -0.9510,  0.4360,  0.2168],\n",
            "        ...,\n",
            "        [ 0.4614,  1.0000,  0.8274,  ...,  0.7635, -0.6132, -0.4769],\n",
            "        [ 0.4941,  1.0000,  0.8745,  ...,  0.6540, -0.5300, -0.8387],\n",
            "        [-0.5672,  0.5423, -0.9072,  ..., -0.8145,  0.1261,  0.4194]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5874,  1.0000,  0.9239,  ...,  0.8211, -0.6400, -0.7220],\n",
            "        [ 0.7758,  1.0000,  0.8590,  ...,  0.7398, -0.5855, -0.6039],\n",
            "        [-0.7393,  0.5089, -0.9102,  ..., -0.8930, -0.0049,  0.6508],\n",
            "        ...,\n",
            "        [-0.6737,  0.8864, -0.9189,  ..., -0.8406, -0.0337,  0.3536],\n",
            "        [ 0.5815,  1.0000,  0.9468,  ...,  0.8625, -0.3996, -0.8650],\n",
            "        [-0.6535,  0.9745, -0.9158,  ..., -0.8680,  0.2634,  0.4315]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6187,  0.2640, -0.8752,  ..., -0.8493,  0.3014,  0.1860],\n",
            "        [-0.5880,  0.3029, -0.8823,  ..., -0.8931,  0.4609,  0.3492],\n",
            "        [-0.5471,  0.8775, -0.8931,  ..., -0.8705,  0.2822,  0.4424],\n",
            "        ...,\n",
            "        [ 0.6028,  1.0000,  0.9413,  ...,  0.8708, -0.0456, -0.8976],\n",
            "        [ 0.6389,  1.0000,  0.9125,  ...,  0.7933, -0.6430, -0.5653],\n",
            "        [ 0.7504,  1.0000,  0.9727,  ...,  0.8550, -0.2278, -0.8188]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4721,  0.9895, -0.9358,  ..., -0.8651,  0.2359,  0.1456],\n",
            "        [-0.4452,  0.9684, -0.8779,  ..., -0.8457,  0.4451,  0.2328],\n",
            "        [ 0.6833,  1.0000,  0.9593,  ...,  0.3144,  0.2833, -0.9516],\n",
            "        ...,\n",
            "        [ 0.4054,  1.0000,  0.8436,  ...,  0.7576, -0.4610, -0.5311],\n",
            "        [-0.5252,  0.9446, -0.9160,  ..., -0.8487,  0.3411,  0.0048],\n",
            "        [ 0.3999,  1.0000,  0.8299,  ...,  0.8659, -0.7787, -0.4315]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6248,  1.0000,  0.8806,  ...,  0.8421, -0.6962, -0.5040],\n",
            "        [ 0.6433,  1.0000,  0.9006,  ...,  0.8371, -0.7002, -0.4467],\n",
            "        [ 0.5837,  1.0000,  0.9395,  ...,  0.6478, -0.2506, -0.8019],\n",
            "        ...,\n",
            "        [-0.7461,  0.8029, -0.8524,  ..., -0.8633,  0.2109,  0.6405],\n",
            "        [ 0.4567,  1.0000,  0.9281,  ...,  0.8522, -0.7508, -0.4052],\n",
            "        [-0.4381, -0.9314, -0.9303,  ..., -0.8629,  0.1164,  0.4500]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7397,  1.0000,  0.9567,  ...,  0.8261, -0.0448, -0.9145],\n",
            "        [ 0.1086,  1.0000,  0.7629,  ...,  0.3195,  0.1285, -0.8513],\n",
            "        [ 0.5699,  1.0000,  0.9229,  ...,  0.8006, -0.4438, -0.7706],\n",
            "        ...,\n",
            "        [ 0.6868,  1.0000,  0.9141,  ...,  0.8297, -0.5335, -0.6766],\n",
            "        [-0.5704, -0.9761, -0.8782,  ..., -0.8935, -0.1402,  0.6278],\n",
            "        [ 0.6301,  1.0000,  0.9446,  ...,  0.5616, -0.2502, -0.8628]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2349,  0.9984, -0.9263,  ..., -0.7769,  0.1746, -0.2206],\n",
            "        [-0.3110,  0.6488, -0.9486,  ..., -0.8812,  0.1624,  0.6393],\n",
            "        [-0.7272,  0.8680, -0.9164,  ..., -0.8752,  0.3815,  0.4709],\n",
            "        ...,\n",
            "        [ 0.6690,  1.0000,  0.9348,  ...,  0.8947, -0.6436, -0.5364],\n",
            "        [ 0.3897,  0.9999,  0.7355,  ...,  0.7202, -0.7360, -0.3921],\n",
            "        [ 0.6828,  1.0000,  0.9213,  ...,  0.8348, -0.6112, -0.7291]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5840, -0.9442, -0.9085,  ..., -0.7601, -0.0948,  0.6738],\n",
            "        [ 0.7077,  1.0000,  0.9298,  ...,  0.8550, -0.5122, -0.5913],\n",
            "        [-0.4768,  0.9408, -0.8921,  ..., -0.9121,  0.0954,  0.1838],\n",
            "        ...,\n",
            "        [-0.3339,  1.0000, -0.1742,  ..., -0.8868,  0.7552, -0.8907],\n",
            "        [-0.1916,  0.8651, -0.8488,  ..., -0.7703,  0.3282,  0.4388],\n",
            "        [ 0.6707,  1.0000,  0.8737,  ...,  0.8738, -0.6409, -0.4385]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5352,  1.0000,  0.9597,  ...,  0.8327, -0.4277, -0.5878],\n",
            "        [ 0.7033,  1.0000,  0.7895,  ...,  0.8572, -0.6184, -0.4079],\n",
            "        [ 0.7171,  1.0000,  0.8613,  ...,  0.4336, -0.1431, -0.9576],\n",
            "        ...,\n",
            "        [-0.4004,  0.4306, -0.8590,  ..., -0.9032,  0.1320,  0.2774],\n",
            "        [ 0.6867,  1.0000,  0.9150,  ...,  0.8398, -0.7822, -0.4988],\n",
            "        [ 0.8049,  1.0000,  0.8757,  ...,  0.8724, -0.3375, -0.5635]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3239, -0.9893, -0.9391,  ..., -0.8681,  0.2875,  0.1210],\n",
            "        [-0.2960, -0.8299, -0.8678,  ..., -0.8175,  0.5204,  0.4961],\n",
            "        [-0.0345,  0.9994, -0.8487,  ..., -0.9094,  0.3708, -0.2469],\n",
            "        ...,\n",
            "        [-0.7086,  0.3128, -0.8982,  ..., -0.8077, -0.0984,  0.6041],\n",
            "        [ 0.5181,  0.9999,  0.8364,  ...,  0.8578, -0.7338, -0.5017],\n",
            "        [-0.5376, -0.9333, -0.8986,  ..., -0.8776,  0.4576,  0.4171]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4457,  1.0000, -0.0414,  ..., -0.8371,  0.5478, -0.8803],\n",
            "        [ 0.5451,  1.0000,  0.9116,  ...,  0.7693, -0.5121, -0.6155],\n",
            "        [-0.4290, -0.9505, -0.9302,  ..., -0.8963,  0.2769,  0.3783],\n",
            "        ...,\n",
            "        [ 0.7199,  1.0000,  0.9527,  ...,  0.7852, -0.0283, -0.9393],\n",
            "        [-0.7645,  0.4604, -0.8896,  ..., -0.7922,  0.1935,  0.5857],\n",
            "        [ 0.6898,  1.0000,  0.9394,  ...,  0.7394, -0.3668, -0.7785]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6728,  1.0000,  0.4620,  ..., -0.7547,  0.7698, -0.9640],\n",
            "        [ 0.3820,  1.0000,  0.8921,  ...,  0.3403,  0.4037, -0.9094],\n",
            "        [-0.6170, -0.8927, -0.9230,  ..., -0.8873, -0.0815,  0.4920],\n",
            "        ...,\n",
            "        [ 0.5958,  1.0000,  0.8998,  ...,  0.8840, -0.5700, -0.4930],\n",
            "        [-0.4648,  0.9972, -0.8761,  ..., -0.8899,  0.3658,  0.1141],\n",
            "        [ 0.5401,  1.0000,  0.8565,  ...,  0.7305, -0.1682, -0.6637]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5725,  1.0000,  0.8053,  ...,  0.4372, -0.0837, -0.6748],\n",
            "        [ 0.6858,  0.9999,  0.8956,  ...,  0.8908, -0.6761, -0.6050],\n",
            "        [-0.5394, -0.7252, -0.9109,  ..., -0.9213,  0.0851,  0.7728],\n",
            "        ...,\n",
            "        [ 0.1853,  1.0000,  0.8190,  ...,  0.4467,  0.5125, -0.8160],\n",
            "        [ 0.4973,  1.0000,  0.9026,  ...,  0.8315, -0.7222, -0.5079],\n",
            "        [-0.7721, -0.0716, -0.8870,  ..., -0.9176,  0.3894,  0.4386]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6183,  0.5088, -0.9275,  ..., -0.8762,  0.0270,  0.6475],\n",
            "        [ 0.5070,  1.0000,  0.9631,  ...,  0.8238, -0.4637, -0.6550],\n",
            "        [ 0.5405,  1.0000,  0.9712,  ...,  0.5199, -0.1912, -0.7459],\n",
            "        ...,\n",
            "        [ 0.5315,  1.0000,  0.9468,  ...,  0.3991, -0.1169, -0.9449],\n",
            "        [ 0.6186,  1.0000,  0.8329,  ...,  0.8710, -0.7002, -0.7817],\n",
            "        [-0.4992,  0.9936, -0.7995,  ..., -0.9214,  0.2909,  0.4349]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6337, -0.9968, -0.9120,  ..., -0.9218,  0.1338,  0.2878],\n",
            "        [-0.5153,  0.6752, -0.9600,  ..., -0.8869,  0.5346,  0.5108],\n",
            "        [-0.5867,  0.1470, -0.9297,  ..., -0.8753,  0.1065,  0.4750],\n",
            "        ...,\n",
            "        [-0.6685,  0.9987, -0.8891,  ..., -0.9122,  0.2283, -0.1960],\n",
            "        [-0.3808, -0.9187, -0.8892,  ..., -0.9480, -0.0038,  0.5431],\n",
            "        [-0.4849, -0.0503, -0.8923,  ..., -0.8489,  0.4868,  0.3908]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3765,  0.8294, -0.8706,  ..., -0.8479,  0.4958,  0.2470],\n",
            "        [-0.4903, -0.4334, -0.7860,  ..., -0.9189,  0.1353, -0.3334],\n",
            "        [-0.2853,  0.9743, -0.9137,  ..., -0.9233,  0.1976,  0.4034],\n",
            "        ...,\n",
            "        [ 0.6435,  1.0000,  0.9468,  ...,  0.1393,  0.2992, -0.9760],\n",
            "        [-0.5126, -0.7977, -0.9403,  ..., -0.9053,  0.2338,  0.2671],\n",
            "        [ 0.7362,  1.0000,  0.9389,  ...,  0.2770,  0.3172, -0.9743]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3552, -0.6324, -0.9437,  ..., -0.9216,  0.4964,  0.4837],\n",
            "        [ 0.7967,  1.0000,  0.9402,  ...,  0.7670, -0.4733, -0.7684],\n",
            "        [-0.4618, -0.8486, -0.8969,  ..., -0.8432,  0.2317,  0.5063],\n",
            "        ...,\n",
            "        [-0.3428,  0.9831, -0.8830,  ..., -0.9211,  0.3545,  0.0214],\n",
            "        [ 0.6176,  1.0000,  0.9485,  ...,  0.8233, -0.5579, -0.7866],\n",
            "        [-0.6753,  0.3397, -0.8895,  ..., -0.8306, -0.0300,  0.1040]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6146,  0.5541, -0.8709,  ..., -0.8884,  0.2963,  0.7149],\n",
            "        [ 0.4418,  1.0000,  0.8990,  ...,  0.6741, -0.5023, -0.7330],\n",
            "        [ 0.5194,  1.0000,  0.8933,  ...,  0.7019, -0.4088, -0.6737],\n",
            "        ...,\n",
            "        [ 0.5454,  1.0000, -0.0842,  ..., -0.8256,  0.3505, -0.7937],\n",
            "        [-0.4093, -0.2137, -0.9249,  ..., -0.9216, -0.1658,  0.2129],\n",
            "        [ 0.7450,  1.0000,  0.9455,  ...,  0.9445, -0.5681, -0.7117]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1952,  0.9341, -0.8832,  ..., -0.8481,  0.4143,  0.1293],\n",
            "        [-0.3894, -0.9943, -0.9355,  ..., -0.8878,  0.2510,  0.4241],\n",
            "        [ 0.7517,  1.0000, -0.4709,  ..., -0.8291,  0.8011, -0.9184],\n",
            "        ...,\n",
            "        [-0.2189,  1.0000, -0.3459,  ..., -0.5494,  0.4372, -0.6289],\n",
            "        [ 0.4045,  1.0000,  0.8002,  ...,  0.6799, -0.2004, -0.8984],\n",
            "        [ 0.7260,  0.9999,  0.8955,  ...,  0.8127, -0.6949, -0.3965]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6507,  1.0000,  0.8958,  ...,  0.8277, -0.5207, -0.6933],\n",
            "        [ 0.6925,  0.9998, -0.2152,  ..., -0.3748,  0.6725, -0.7287],\n",
            "        [-0.5166,  0.9981, -0.8348,  ..., -0.8785,  0.2733,  0.4165],\n",
            "        ...,\n",
            "        [-0.5371, -0.4914, -0.9039,  ..., -0.9433,  0.1226,  0.4447],\n",
            "        [-0.4712,  0.4334, -0.9009,  ..., -0.7426,  0.6461,  0.0075],\n",
            "        [ 0.7029,  1.0000,  0.9151,  ...,  0.8457, -0.5076, -0.6948]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6469,  1.0000,  0.8750,  ...,  0.8658, -0.5957, -0.3489],\n",
            "        [ 0.6296,  1.0000,  0.7703,  ...,  0.0833, -0.1078, -0.9432],\n",
            "        [ 0.7723,  1.0000,  0.9370,  ...,  0.8630, -0.3044, -0.6828],\n",
            "        ...,\n",
            "        [ 0.6940,  1.0000,  0.9189,  ...,  0.4953,  0.4228, -0.9471],\n",
            "        [ 0.5620,  1.0000,  0.9109,  ...,  0.8654, -0.6973, -0.4407],\n",
            "        [-0.4002,  1.0000, -0.5392,  ..., -0.7584,  0.3572, -0.2095]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0587,  0.9882, -0.8881,  ..., -0.9450,  0.3945,  0.2330],\n",
            "        [ 0.6370,  1.0000,  0.9532,  ...,  0.7235, -0.0876, -0.9187],\n",
            "        [ 0.4297,  1.0000,  0.4730,  ..., -0.7146,  0.6258, -0.8970],\n",
            "        ...,\n",
            "        [ 0.6001,  1.0000,  0.8860,  ...,  0.7224, -0.4627, -0.6456],\n",
            "        [ 0.7157,  0.9999,  0.9533,  ...,  0.8199, -0.3277, -0.8100],\n",
            "        [ 0.1890,  0.9912, -0.8780,  ..., -0.8976,  0.4639,  0.1255]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6042,  1.0000,  0.6768,  ..., -0.5956,  0.7043, -0.9647],\n",
            "        [ 0.6820,  1.0000,  0.9375,  ...,  0.6782, -0.6009, -0.8804],\n",
            "        [-0.3548, -0.6059, -0.9556,  ..., -0.8913,  0.4533,  0.2173],\n",
            "        ...,\n",
            "        [-0.0039,  0.9998, -0.8973,  ..., -0.9060,  0.3901, -0.0898],\n",
            "        [ 0.4234,  1.0000,  0.9494,  ...,  0.7907, -0.6214, -0.5385],\n",
            "        [ 0.6736,  1.0000,  0.9212,  ...,  0.5483, -0.3961, -0.8214]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1992,  0.9997, -0.8007,  ..., -0.8725,  0.6045, -0.3243],\n",
            "        [ 0.4342,  1.0000, -0.6975,  ..., -0.6595,  0.5937, -0.5919],\n",
            "        [ 0.6442,  1.0000,  0.8928,  ...,  0.7698, -0.4043, -0.8230],\n",
            "        ...,\n",
            "        [ 0.5814,  1.0000,  0.9002,  ...,  0.3786,  0.0954, -0.9209],\n",
            "        [-0.5038, -0.7357, -0.8967,  ..., -0.9487,  0.2402,  0.3880],\n",
            "        [-0.1425, -0.1635, -0.8984,  ..., -0.8838,  0.4132, -0.0848]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4414, -0.7836, -0.9446,  ..., -0.8542, -0.0716,  0.4028],\n",
            "        [ 0.7782,  1.0000,  0.9674,  ...,  0.8175, -0.5165, -0.7838],\n",
            "        [-0.6554,  0.9878, -0.9146,  ..., -0.9014, -0.0628,  0.4968],\n",
            "        ...,\n",
            "        [ 0.4660,  1.0000,  0.8790,  ...,  0.8261, -0.6029, -0.7701],\n",
            "        [-0.3033,  0.3102, -0.8824,  ..., -0.8992,  0.1641,  0.1331],\n",
            "        [ 0.6947,  1.0000,  0.8711,  ...,  0.8542, -0.4631, -0.6505]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 3.8280e-01,  9.9999e-01,  8.8198e-01,  ...,  8.1225e-01,\n",
            "         -5.4474e-01, -5.2122e-01],\n",
            "        [ 5.5800e-01,  9.9996e-01,  9.1802e-01,  ...,  8.5093e-01,\n",
            "         -5.1796e-01, -4.7815e-01],\n",
            "        [-2.8362e-01,  6.4752e-01, -9.2337e-01,  ..., -9.0536e-01,\n",
            "          3.0302e-01,  6.0084e-01],\n",
            "        ...,\n",
            "        [-6.3069e-01, -9.9620e-01, -8.9885e-01,  ..., -9.1092e-01,\n",
            "         -2.4422e-04,  4.8473e-01],\n",
            "        [-5.5874e-01,  9.9446e-01, -8.4069e-01,  ..., -8.3666e-01,\n",
            "          1.5304e-01,  6.9840e-02],\n",
            "        [ 2.9244e-01,  1.2007e-01, -9.0624e-01,  ..., -9.1371e-01,\n",
            "          5.3815e-01,  7.3292e-02]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4832,  0.9602, -0.7877,  ..., -0.7578,  0.5625,  0.2106],\n",
            "        [ 0.7266,  1.0000,  0.8485,  ...,  0.7846, -0.4607, -0.5937],\n",
            "        [ 0.4320,  0.9999,  0.8620,  ...,  0.8009, -0.7752, -0.2767],\n",
            "        ...,\n",
            "        [ 0.5295,  1.0000,  0.8845,  ...,  0.8099, -0.6524, -0.6272],\n",
            "        [ 0.6077,  1.0000,  0.9395,  ...,  0.7056, -0.4732, -0.7471],\n",
            "        [-0.3949,  0.2276, -0.9048,  ..., -0.8908,  0.2076,  0.4886]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6102,  1.0000,  0.8284,  ...,  0.6946, -0.7062, -0.3674],\n",
            "        [ 0.4967,  1.0000,  0.9213,  ...,  0.7732, -0.3272, -0.7074],\n",
            "        [ 0.5617,  1.0000,  0.9368,  ...,  0.5899, -0.1806, -0.8641],\n",
            "        ...,\n",
            "        [ 0.3491,  1.0000,  0.7816,  ...,  0.7813, -0.6570, -0.6845],\n",
            "        [ 0.1021,  0.9988, -0.8820,  ..., -0.8158,  0.4816, -0.4405],\n",
            "        [ 0.5509,  1.0000,  0.9312,  ...,  0.8262, -0.5494, -0.3948]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1349, -0.3889, -0.9076,  ..., -0.9155,  0.1570,  0.5950],\n",
            "        [ 0.8465,  1.0000,  0.9304,  ...,  0.5323, -0.5616, -0.9442],\n",
            "        [ 0.7217,  1.0000,  0.9567,  ...,  0.6408, -0.0468, -0.9204],\n",
            "        ...,\n",
            "        [-0.1514,  0.9931, -0.8839,  ..., -0.8993,  0.3975, -0.1418],\n",
            "        [-0.4551,  0.2010, -0.9489,  ..., -0.8046,  0.2001,  0.5587],\n",
            "        [-0.4936,  0.6447, -0.9117,  ..., -0.7802,  0.1650,  0.3904]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4671, -0.8182, -0.3284,  ..., -0.8153,  0.5674,  0.0276],\n",
            "        [ 0.0407, -0.3812, -0.9409,  ..., -0.9295,  0.1139,  0.3080],\n",
            "        [ 0.5237,  1.0000,  0.6694,  ..., -0.3763, -0.4125, -0.9112],\n",
            "        ...,\n",
            "        [-0.6058, -0.2030, -0.8717,  ..., -0.8592,  0.2577,  0.3742],\n",
            "        [-0.5328,  0.7507, -0.9069,  ..., -0.9016,  0.2338,  0.4369],\n",
            "        [ 0.7066,  1.0000,  0.9432,  ...,  0.7891, -0.3901, -0.7842]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6962,  0.7513, -0.8730,  ..., -0.8312, -0.2186,  0.5740],\n",
            "        [-0.4873,  0.9938, -0.8249,  ..., -0.8659,  0.4566, -0.1682],\n",
            "        [ 0.3825,  1.0000,  0.9087,  ...,  0.7159, -0.6162, -0.6548],\n",
            "        ...,\n",
            "        [-0.5361,  0.6656, -0.8237,  ..., -0.9026,  0.3285,  0.5569],\n",
            "        [ 0.6982,  1.0000,  0.9119,  ...,  0.8597, -0.6388, -0.6570],\n",
            "        [-0.3871,  0.9967, -0.7507,  ..., -0.7671,  0.4468,  0.0264]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5127, -0.4548, -0.8716,  ..., -0.7778, -0.1210,  0.5628],\n",
            "        [-0.3621,  0.9998, -0.7007,  ..., -0.8550,  0.7551, -0.3646],\n",
            "        [ 0.1391,  0.9977, -0.8385,  ..., -0.9068,  0.4549, -0.2996],\n",
            "        ...,\n",
            "        [ 0.6590,  1.0000,  0.8313,  ...,  0.8134, -0.6269, -0.6967],\n",
            "        [ 0.2160,  0.9947, -0.8121,  ..., -0.7398,  0.4413,  0.3955],\n",
            "        [-0.3695,  0.9906, -0.8740,  ..., -0.8370,  0.3998, -0.0168]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5231, -0.1692, -0.5582,  ..., -0.7507, -0.0855,  0.4218],\n",
            "        [ 0.7037,  1.0000,  0.7840,  ...,  0.8205, -0.4768, -0.7112],\n",
            "        [ 0.1643,  1.0000,  0.9536,  ...,  0.8067, -0.3843, -0.8376],\n",
            "        ...,\n",
            "        [-0.5134,  0.9976, -0.8914,  ..., -0.9056,  0.5359,  0.0088],\n",
            "        [ 0.3702,  0.9998,  0.9064,  ...,  0.8265, -0.5141, -0.5014],\n",
            "        [-0.1303,  0.2050, -0.9311,  ..., -0.8808,  0.3643,  0.3035]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2429,  0.9999, -0.6414,  ..., -0.7687,  0.6036, -0.0714],\n",
            "        [ 0.6322,  1.0000,  0.8546,  ...,  0.6361, -0.1619, -0.7503],\n",
            "        [ 0.6238,  1.0000,  0.9374,  ...,  0.8861, -0.5761, -0.6554],\n",
            "        ...,\n",
            "        [ 0.5686,  1.0000,  0.9109,  ...,  0.6901, -0.6011, -0.7937],\n",
            "        [-0.6539,  0.9410, -0.7866,  ..., -0.8777,  0.3786,  0.4517],\n",
            "        [-0.2818,  0.9856, -0.8987,  ..., -0.8164,  0.1929,  0.2789]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5282,  1.0000,  0.7280,  ...,  0.6105, -0.3058, -0.3091],\n",
            "        [ 0.7511,  1.0000,  0.9658,  ...,  0.8367, -0.3996, -0.5436],\n",
            "        [ 0.6551,  1.0000,  0.9508,  ...,  0.7093,  0.1025, -0.9200],\n",
            "        ...,\n",
            "        [ 0.3749,  1.0000,  0.9300,  ...,  0.7954, -0.6749, -0.6911],\n",
            "        [ 0.6585,  1.0000,  0.8018,  ...,  0.8148, -0.6704, -0.4451],\n",
            "        [ 0.7824,  1.0000,  0.6862,  ...,  0.5293, -0.2250, -0.8141]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4191, -0.5335, -0.8609,  ..., -0.8383,  0.2817, -0.2365],\n",
            "        [ 0.5983,  1.0000,  0.7414,  ...,  0.8174, -0.7064, -0.5192],\n",
            "        [ 0.6480,  1.0000,  0.9364,  ...,  0.8964, -0.7232, -0.7307],\n",
            "        ...,\n",
            "        [ 0.6422,  1.0000,  0.7767,  ...,  0.6552, -0.4712, -0.3392],\n",
            "        [ 0.6529,  1.0000,  0.9698,  ...,  0.7591,  0.2208, -0.9189],\n",
            "        [ 0.6457,  0.9999,  0.9160,  ...,  0.8163, -0.5266, -0.7253]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 4.0200e-01,  1.0000e+00,  9.3206e-01,  ...,  3.3114e-01,\n",
            "          5.3132e-01, -9.8005e-01],\n",
            "        [ 7.2160e-01,  9.9998e-01,  8.9799e-01,  ...,  7.0325e-01,\n",
            "         -6.7339e-01, -6.0876e-01],\n",
            "        [-3.3165e-02,  9.9545e-01, -8.3037e-01,  ..., -8.9536e-01,\n",
            "          3.8610e-01, -3.7267e-04],\n",
            "        ...,\n",
            "        [-4.4315e-01, -2.3592e-01, -9.0726e-01,  ..., -9.1289e-01,\n",
            "          3.6526e-01,  1.1080e-01],\n",
            "        [-4.6908e-01,  8.1970e-01, -8.9779e-01,  ..., -9.0434e-01,\n",
            "          4.7913e-01,  9.6144e-02],\n",
            "        [-4.9761e-01, -7.7653e-01, -9.4926e-01,  ..., -8.4109e-01,\n",
            "         -4.4654e-02,  4.8015e-01]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5275, -0.9974, -0.9508,  ..., -0.9417,  0.0792,  0.5153],\n",
            "        [ 0.5169,  1.0000,  0.9139,  ...,  0.6287, -0.4167, -0.7220],\n",
            "        [ 0.5615,  0.9999,  0.8632,  ...,  0.8559, -0.7024, -0.2643],\n",
            "        ...,\n",
            "        [-0.2336, -0.3074, -0.9536,  ..., -0.8717,  0.1589,  0.5863],\n",
            "        [-0.8139,  0.9976, -0.7366,  ..., -0.8825,  0.2721,  0.2726],\n",
            "        [-0.5161,  0.5004, -0.9153,  ..., -0.8826,  0.4385,  0.2070]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4015,  1.0000,  0.8948,  ...,  0.8720, -0.7015, -0.3396],\n",
            "        [ 0.8821,  1.0000,  0.3124,  ..., -0.7102,  0.6862, -0.9804],\n",
            "        [-0.3741,  0.9816, -0.8778,  ..., -0.9157,  0.3057, -0.0297],\n",
            "        ...,\n",
            "        [ 0.5493,  1.0000,  0.8857,  ...,  0.8072, -0.6247, -0.8166],\n",
            "        [-0.0769,  1.0000, -0.7550,  ..., -0.7542,  0.5245, -0.7780],\n",
            "        [ 0.0039,  1.0000,  0.0827,  ..., -0.7206,  0.5413, -0.9201]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3399, -0.2772, -0.8825,  ..., -0.7628,  0.0099,  0.5599],\n",
            "        [ 0.2730,  1.0000,  0.9288,  ...,  0.7887, -0.7048, -0.5530],\n",
            "        [ 0.6000,  1.0000,  0.9236,  ...,  0.8917, -0.5122, -0.6491],\n",
            "        ...,\n",
            "        [ 0.7691,  1.0000,  0.9391,  ...,  0.6023, -0.3716, -0.8421],\n",
            "        [-0.1765,  0.9993, -0.7577,  ..., -0.8852,  0.5218, -0.3623],\n",
            "        [-0.3974,  0.9850, -0.9107,  ..., -0.9091,  0.0618,  0.2935]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2308,  0.9868, -0.4972,  ..., -0.7464,  0.4964,  0.0390],\n",
            "        [ 0.2100,  0.9999,  0.9472,  ...,  0.6534, -0.6448, -0.4798],\n",
            "        [ 0.6320,  1.0000,  0.8714,  ...,  0.8865, -0.5747, -0.5873],\n",
            "        ...,\n",
            "        [ 0.5679,  1.0000,  0.8875,  ...,  0.5628, -0.3446, -0.7588],\n",
            "        [ 0.5880,  0.9995,  0.8544,  ...,  0.8372, -0.6190, -0.1993],\n",
            "        [ 0.6368,  1.0000,  0.9227,  ...,  0.3452, -0.3086, -0.8462]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0243,  0.9983, -0.5288,  ..., -0.6968,  0.3763,  0.1206],\n",
            "        [-0.4700,  0.8064, -0.8345,  ..., -0.8810,  0.4820,  0.1275],\n",
            "        [ 0.6995,  1.0000,  0.9011,  ...,  0.7412, -0.7354, -0.5708],\n",
            "        ...,\n",
            "        [-0.2424,  0.9929, -0.1700,  ..., -0.8232,  0.3136, -0.0071],\n",
            "        [-0.1362,  0.9958, -0.8842,  ..., -0.8686,  0.4065, -0.0814],\n",
            "        [-0.2662,  0.8541, -0.7613,  ..., -0.9117,  0.2990, -0.1022]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2539,  0.9999, -0.6151,  ..., -0.8623,  0.6404, -0.1882],\n",
            "        [ 0.6498,  1.0000,  0.8761,  ...,  0.4483, -0.5756, -0.8210],\n",
            "        [ 0.7458,  1.0000,  0.9249,  ...,  0.4675, -0.6596, -0.6182],\n",
            "        ...,\n",
            "        [-0.5488,  1.0000, -0.5327,  ..., -0.7503,  0.1131,  0.1141],\n",
            "        [-0.2665,  0.9999, -0.6711,  ..., -0.8073,  0.3884, -0.6527],\n",
            "        [ 0.5938,  0.9999,  0.9080,  ...,  0.8639, -0.5226, -0.4914]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1505,  1.0000,  0.6182,  ...,  0.1419,  0.4612, -0.7595],\n",
            "        [-0.5130,  1.0000, -0.6816,  ..., -0.7453,  0.5188, -0.2244],\n",
            "        [-0.3618, -0.9723, -0.8026,  ..., -0.7254,  0.0510, -0.1181],\n",
            "        ...,\n",
            "        [-0.6189,  0.9861, -0.9239,  ..., -0.9158,  0.0104,  0.2280],\n",
            "        [ 0.3788,  0.9999,  0.8246,  ...,  0.8666, -0.4411, -0.5229],\n",
            "        [ 0.1742,  0.9986,  0.7577,  ...,  0.6546, -0.5142, -0.3941]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4995,  0.9745, -0.9152,  ..., -0.9219,  0.2023,  0.2425],\n",
            "        [-0.5221,  0.9994, -0.4409,  ..., -0.8727,  0.7273, -0.3568],\n",
            "        [-0.2679,  0.9973, -0.9120,  ..., -0.9346,  0.3036,  0.2608],\n",
            "        ...,\n",
            "        [-0.5579,  0.9988, -0.9159,  ..., -0.8352,  0.1346, -0.1102],\n",
            "        [ 0.6021,  1.0000,  0.8290,  ...,  0.5233, -0.3637, -0.8585],\n",
            "        [-0.5992,  0.9939, -0.7983,  ..., -0.8967, -0.1464,  0.1208]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6708,  1.0000,  0.8860,  ...,  0.8508, -0.5230, -0.6829],\n",
            "        [ 0.7136,  1.0000,  0.8153,  ...,  0.7467, -0.7958, -0.6626],\n",
            "        [-0.6213,  0.9966, -0.7429,  ..., -0.9115,  0.2464, -0.0901],\n",
            "        ...,\n",
            "        [-0.4952,  0.7903, -0.7779,  ..., -0.8940,  0.7036, -0.5473],\n",
            "        [ 0.5961,  1.0000,  0.8522,  ...,  0.7097, -0.6226, -0.8680],\n",
            "        [ 0.6650,  0.9998,  0.8111,  ...,  0.7785, -0.7658, -0.3543]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0880,  0.9912, -0.9060,  ..., -0.9251, -0.0677, -0.3631],\n",
            "        [-0.4658,  0.9998, -0.5985,  ..., -0.6612,  0.2245, -0.1171],\n",
            "        [-0.4893, -0.9895, -0.9175,  ..., -0.9124, -0.0044,  0.6719],\n",
            "        ...,\n",
            "        [ 0.3999,  0.9999,  0.7317,  ...,  0.8848, -0.8442, -0.3662],\n",
            "        [-0.2152,  0.9982, -0.8605,  ..., -0.8541,  0.2859,  0.0232],\n",
            "        [-0.5150,  0.9773, -0.8854,  ..., -0.8621,  0.3465,  0.3627]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.7280,  0.9714, -0.9186, -0.8451,  0.1817, -0.9347,  0.1613, -0.2370,\n",
            "          0.2112,  0.6686, -0.7934,  0.8839, -0.2653,  0.8176, -0.2975,  0.8998,\n",
            "         -0.5826, -0.8625,  0.5012,  0.0564,  0.3319,  0.8809,  0.3825, -0.2665,\n",
            "         -0.7651, -0.9010,  0.6803,  0.1773,  0.0897, -0.4140, -0.1493,  0.5942,\n",
            "          0.5316,  0.3953,  0.2357, -0.3052,  0.4756, -0.4420, -0.8908, -0.8627,\n",
            "          0.8480,  0.4382,  0.9444, -0.8136,  0.6336, -0.9066,  0.0672, -0.7997,\n",
            "          0.6833,  0.3261,  0.2833, -0.9719,  0.3536, -0.7063, -0.8077, -0.7268,\n",
            "         -0.3457,  0.3493, -0.1361,  0.6782,  0.0078, -0.4809,  0.9063,  0.4980,\n",
            "          0.9577,  0.5254,  0.7161,  0.1376,  0.8841, -0.7907, -0.8236, -0.0457,\n",
            "         -0.0268, -0.6374,  0.4150, -0.0553,  0.3907, -0.4130, -0.4609,  0.5795,\n",
            "         -0.6966,  0.5782,  0.8482, -0.9855, -0.7463, -0.4785,  0.7890, -0.6960,\n",
            "         -0.7188,  0.1794,  0.3266, -0.8079, -0.7415,  0.5062,  0.3961, -0.7839,\n",
            "          0.2145, -0.7467, -0.7734,  0.4559,  0.7902,  0.6022,  0.5080,  0.1681,\n",
            "         -0.9737, -0.8783,  0.4381, -0.6812, -0.9243, -0.1201, -0.7613, -0.1090,\n",
            "          0.5038,  0.0493, -0.4780,  0.9647, -0.8494, -0.7124, -0.9369, -0.5394,\n",
            "          0.1288, -0.1457,  0.2799, -0.5875,  0.0774, -0.7070, -0.7468, -0.4682,\n",
            "          0.4669,  0.1672, -0.4412, -0.5930, -0.7865, -0.7763,  0.2203, -0.1172,\n",
            "         -0.9850,  0.5248,  0.6007, -0.6481,  0.9124,  0.7936, -0.2917, -0.3827,\n",
            "          0.1339,  0.7768, -0.1717,  0.6943, -0.3870, -0.7483,  0.1211, -0.4044,\n",
            "         -0.7642,  0.0476, -0.9893,  0.6397,  0.5275,  0.7578,  0.9637, -0.4643,\n",
            "          0.4758, -0.8400,  0.6542,  0.3309,  0.9615, -0.4896, -0.1232,  0.4833,\n",
            "          0.8993, -0.2898, -0.0227,  0.6829,  0.5488,  0.6520,  0.9711, -0.8118,\n",
            "         -0.8716,  0.0249,  0.9104,  0.1663,  0.6656, -0.4022, -0.6676, -0.8700,\n",
            "          0.1358, -0.3582, -0.5188, -0.9326, -0.6011,  0.7354, -0.0758, -0.9074,\n",
            "         -0.2342,  0.8948,  0.0051, -0.1008, -0.5444,  0.6990,  0.2034,  0.4299,\n",
            "          0.5994, -0.1611,  0.5817, -0.5462, -0.6941, -0.8757, -0.0373,  0.5033,\n",
            "         -0.8170,  0.0139,  0.5138,  0.4275,  0.5343, -0.6678,  0.0046,  0.3575,\n",
            "          0.6473, -0.9151,  0.7563,  0.7749, -0.7446, -0.7148, -0.1527, -0.7883,\n",
            "         -0.1389, -0.6449, -0.2856,  0.1153, -0.7729, -0.9372,  0.1844,  0.5187,\n",
            "          0.6005,  0.6279,  0.9891,  0.0939, -0.8755,  0.6957, -0.2546, -0.6428,\n",
            "          0.8342, -0.5183,  0.7857, -0.0486,  0.8760, -0.7702, -0.1862, -0.8771,\n",
            "          0.0316,  0.6599, -0.4124, -0.2083,  0.8377,  0.7248,  0.6082,  0.6627,\n",
            "          0.6170, -0.9089, -0.5216,  0.2526, -0.8402,  0.3207, -0.9550, -0.8692,\n",
            "          0.4395,  0.9847, -0.7109, -0.0195,  0.5346,  0.4136,  0.6499, -0.0445,\n",
            "         -0.4867,  0.9953, -0.1050, -0.7823,  0.9802,  0.2510, -0.8864,  0.7629,\n",
            "         -0.9438,  0.1412,  0.8165,  0.2335,  0.0608,  0.4968,  0.2246,  0.1795,\n",
            "         -0.9831, -0.4146,  0.9300,  0.7202,  0.9010,  0.0623, -0.2090, -0.8917,\n",
            "          0.8683, -0.2460, -0.3624,  0.9922,  0.4836,  0.5478, -0.6632,  0.3798,\n",
            "          0.1006,  0.7880, -0.4452,  0.5576, -0.5577, -0.1954,  0.5179, -0.7171,\n",
            "          0.2062,  0.4824, -0.3998, -0.7164, -0.1694, -0.4737, -0.4470, -0.0482,\n",
            "          0.1899,  0.8845, -0.4760, -0.8081,  0.0079,  0.2312, -0.8491,  0.8024,\n",
            "          0.1808, -0.2322, -0.3157,  0.8793, -0.1016, -0.5860,  0.6811, -0.4971,\n",
            "         -0.1135,  0.5046,  0.0562,  0.8291,  0.7588,  0.5718,  0.6780,  0.2758,\n",
            "          0.4712, -0.7187,  0.5454, -0.4762, -0.6540, -0.5617, -0.3133,  0.1784,\n",
            "         -0.7943,  0.0054,  0.8083,  0.9913,  0.5927,  0.9546, -0.7097,  0.5840,\n",
            "         -0.6637,  0.3337,  0.7589, -0.7674, -0.9022, -0.6318,  0.2624,  0.2532,\n",
            "         -0.7626, -0.3921, -0.5787,  0.4918, -0.0229,  0.9159, -0.4607, -0.8940,\n",
            "          0.8930,  0.3814,  0.8270,  0.0768, -0.6015,  0.3442,  0.8569,  0.5559,\n",
            "          0.2180, -0.1586,  0.7463, -0.7731,  0.7170,  0.0445,  0.2610,  0.2807,\n",
            "          0.0955, -0.2374,  0.3601,  0.8976, -0.3293, -0.5009, -0.9425,  0.9917,\n",
            "         -0.6302,  0.0661, -0.0039,  0.3454,  0.7991, -0.5609,  0.0996, -0.2302,\n",
            "          0.7144, -0.8712,  0.6666,  0.6758,  0.7197,  0.2423, -0.5368,  0.2975,\n",
            "         -0.8282, -0.3928, -0.7556,  0.5642, -0.6021, -0.7118, -0.8304, -0.9251,\n",
            "          0.8786, -0.5414,  0.8688, -0.7812, -0.7444, -0.6243, -0.3545, -0.5285,\n",
            "          0.7445, -0.8197,  0.9754, -0.9315,  0.2819, -0.3691,  0.7453,  0.5120,\n",
            "          0.6918,  0.6296,  0.7890, -0.2293,  0.3411,  0.4208, -0.5868, -0.8302,\n",
            "          0.1780,  0.6453, -0.0787,  0.8362, -0.7116,  0.8810,  0.6644, -0.0859,\n",
            "         -0.0464, -0.4633,  0.9306,  0.9239, -0.6114,  0.8741,  0.9826,  0.2516,\n",
            "         -0.1517, -0.0929, -0.7055,  0.7174, -0.8764, -0.7740,  0.5982,  0.2662,\n",
            "          0.4968, -0.5018,  0.7946, -0.1647, -0.3401, -0.7142, -0.1986, -0.9652,\n",
            "         -0.5367,  0.6558, -0.9013, -0.8064,  0.6692,  0.1890,  0.1619,  0.5970,\n",
            "          0.7940, -0.0560, -0.2150, -0.7155,  0.2151,  0.8576,  0.3627,  0.2348,\n",
            "         -0.7060, -0.4066, -0.6188,  0.0057,  0.9523, -0.8038, -0.3862,  0.6021,\n",
            "         -0.4092, -0.8368,  0.9882,  0.8073,  0.4907,  0.9413,  0.6301,  0.6437,\n",
            "         -0.3006,  0.8197, -0.3432,  0.5744,  0.4747,  0.9496, -0.7156, -0.9022,\n",
            "         -0.9830, -0.2823, -0.2569, -0.3070, -0.2861, -0.8402, -0.3240,  0.1539,\n",
            "         -0.8601,  0.5104,  0.2153, -0.9706, -0.8723, -0.6651, -0.6825, -0.8451,\n",
            "         -0.1523, -0.6116, -0.7836,  0.9361, -0.9311, -0.9847, -0.3867,  0.4527,\n",
            "          0.8255,  0.5226, -0.1814, -0.4090, -0.3736,  0.4958, -0.9949, -0.3796,\n",
            "          0.7857,  0.8395, -0.7306,  0.8522, -0.7740, -0.4621, -0.2176,  0.2932,\n",
            "          0.5657, -0.9912,  0.4190,  0.5531,  0.3926, -0.5131, -0.4522, -0.7916,\n",
            "         -0.7483, -0.7247,  0.9173,  0.5193,  0.8843, -0.6962,  0.1978,  0.9036,\n",
            "          0.1841, -0.6971,  0.4900,  0.8604,  0.7975,  0.7205,  0.4208, -0.6828,\n",
            "          0.0600, -0.3895, -0.5492,  0.2973, -0.6041,  0.6676, -0.1720,  0.3902,\n",
            "          0.6580, -0.4599,  0.9858,  0.5526, -0.6679,  0.9081, -0.4827, -0.8268,\n",
            "         -0.9905, -0.8419,  0.7792, -0.5661, -0.8177,  0.4061, -0.2020, -0.3241,\n",
            "          0.5487, -0.1233,  0.7336,  0.8986,  0.3490,  0.1199, -0.6339, -0.9783,\n",
            "          0.1013,  0.8184, -0.3713,  0.5951, -0.3207,  0.9516,  0.4719,  0.6569,\n",
            "          0.2649,  0.9520,  0.2820, -0.7139,  0.4734, -0.1516,  0.5728,  0.8689,\n",
            "         -0.5314, -0.9355, -0.5931, -0.7777, -0.4142, -0.7745,  0.8414, -0.1101,\n",
            "          0.9377,  0.7429,  0.7279,  0.2685,  0.5299, -0.6301, -0.2630,  0.6582,\n",
            "         -0.9026,  0.7917, -0.1736, -0.7417,  0.0953, -0.8481, -0.4767,  0.2988,\n",
            "         -0.4730, -0.2729, -0.8571, -0.8024,  0.1160, -0.6333,  0.6980, -0.5992,\n",
            "         -0.8725,  0.9168, -0.5132, -0.2161,  0.8658,  0.6250, -0.5393,  0.8603,\n",
            "          0.0873, -0.4525,  0.7472,  0.2570, -0.6353,  0.5631,  0.3112,  0.2500,\n",
            "          0.2308, -0.3566,  0.9259,  0.2544,  0.0076,  0.6476, -0.1738,  0.6242,\n",
            "          0.7174, -0.5792,  0.6183, -0.2027, -0.4116, -0.6046, -0.2364,  0.4509,\n",
            "          0.8357, -0.9825,  0.9656,  0.5952, -0.4931, -0.9545, -0.3175,  0.2760,\n",
            "          0.6471, -0.2142,  0.4224, -0.4689, -0.7988,  0.6455, -0.9654, -0.8663,\n",
            "         -0.7607,  0.4649,  0.5360, -0.9599, -0.7078,  0.5037,  0.2091, -0.3449,\n",
            "          0.8588,  0.1084, -0.5876, -0.6299, -0.9040, -0.2149,  0.3261, -0.6062,\n",
            "          0.5324, -0.1023, -0.2623, -0.6418,  0.6120,  0.5976, -0.5029, -0.7091,\n",
            "          0.4738, -0.9881,  0.4725, -0.3431, -0.8022,  0.6755, -0.7985,  0.5270,\n",
            "          0.3696, -0.9606,  0.4471,  0.0504,  0.4885,  0.5820, -0.7485,  0.4741,\n",
            "          0.7825, -0.1851,  0.8889,  0.1814,  0.5486,  0.3404,  0.9077,  0.8581,\n",
            "          0.6808, -0.4900, -0.8886, -0.3654,  0.6084, -0.8782,  0.1781,  0.5540]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluation... :   0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d7f309d5689f49c39dbc1e9cd8f6d6a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7036,  0.9996,  0.9075,  ...,  0.8599, -0.7657, -0.4450],\n",
            "        [ 0.7355,  1.0000,  0.9530,  ...,  0.8182, -0.2688, -0.8770],\n",
            "        [ 0.8689,  1.0000,  0.4242,  ..., -0.5408,  0.6618, -0.9062],\n",
            "        ...,\n",
            "        [ 0.4024,  0.9999,  0.8371,  ...,  0.8076, -0.7541, -0.3040],\n",
            "        [ 0.1952,  0.9998, -0.2632,  ..., -0.7942,  0.6169, -0.6474],\n",
            "        [-0.6361,  0.9499, -0.8781,  ..., -0.7329,  0.3279,  0.3737]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1230,  1.0000, -0.5221,  ..., -0.8676,  0.6617, -0.6851],\n",
            "        [ 0.7047,  1.0000,  0.8275,  ...,  0.5551, -0.7136, -0.4799],\n",
            "        [ 0.3951,  1.0000,  0.8112,  ..., -0.3639,  0.3936, -0.9609],\n",
            "        ...,\n",
            "        [-0.0179,  0.9999,  0.1991,  ..., -0.6463,  0.2281, -0.8846],\n",
            "        [-0.4474,  1.0000,  0.2815,  ..., -0.7892,  0.3290, -0.7989],\n",
            "        [ 0.6547,  1.0000,  0.9007,  ..., -0.2411,  0.4761, -0.9817]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5756,  1.0000,  0.9342,  ...,  0.8428, -0.7101, -0.5510],\n",
            "        [ 0.3239,  1.0000,  0.7747,  ...,  0.4498,  0.6662, -0.8302],\n",
            "        [ 0.5681,  1.0000,  0.8856,  ...,  0.8530, -0.6791, -0.6135],\n",
            "        ...,\n",
            "        [ 0.0923,  1.0000,  0.5398,  ..., -0.8478,  0.5357, -0.9465],\n",
            "        [-0.6384,  0.9974, -0.7697,  ..., -0.9138,  0.3299, -0.2221],\n",
            "        [ 0.5047,  1.0000,  0.7725,  ...,  0.1994,  0.2167, -0.9514]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3367,  1.0000,  0.6891,  ...,  0.4347, -0.6309, -0.7300],\n",
            "        [ 0.1515,  1.0000,  0.8364,  ..., -0.3584,  0.3536, -0.9660],\n",
            "        [ 0.5135,  1.0000,  0.6425,  ..., -0.6697,  0.2931, -0.9783],\n",
            "        ...,\n",
            "        [ 0.6874,  1.0000,  0.9020,  ...,  0.8632, -0.6357, -0.5126],\n",
            "        [ 0.2544,  0.9925, -0.4926,  ..., -0.8603,  0.6589, -0.6532],\n",
            "        [ 0.6284,  0.9999,  0.8986,  ...,  0.8783, -0.8150, -0.3853]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6904,  1.0000,  0.8306,  ...,  0.7088, -0.4254, -0.4293],\n",
            "        [ 0.4462,  1.0000,  0.8811,  ...,  0.8459, -0.3806, -0.6366],\n",
            "        [ 0.0093,  0.9999, -0.6154,  ..., -0.6426,  0.4120, -0.4575],\n",
            "        ...,\n",
            "        [ 0.5225,  1.0000,  0.7031,  ...,  0.7082, -0.4063, -0.8491],\n",
            "        [ 0.5338,  0.9999,  0.9214,  ...,  0.6515, -0.6371, -0.4647],\n",
            "        [ 0.5023,  1.0000,  0.9443,  ...,  0.5852,  0.4319, -0.7972]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5719,  1.0000,  0.8952,  ...,  0.8772, -0.6776, -0.5771],\n",
            "        [ 0.7800,  1.0000,  0.7395,  ...,  0.5776, -0.5342, -0.8941],\n",
            "        [-0.2280,  0.9350, -0.9519,  ..., -0.8884,  0.5654,  0.0586],\n",
            "        ...,\n",
            "        [ 0.8258,  1.0000, -0.2043,  ..., -0.6485,  0.7509, -0.8027],\n",
            "        [ 0.4791,  1.0000,  0.4405,  ...,  0.4578, -0.3147, -0.7154],\n",
            "        [-0.2117,  1.0000,  0.1589,  ..., -0.7204,  0.3533, -0.9061]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3204,  0.9999, -0.0096,  ..., -0.7007, -0.2611, -0.8829],\n",
            "        [-0.4601,  0.5763, -0.9233,  ..., -0.9376,  0.1071,  0.5702],\n",
            "        [ 0.5826,  0.9998,  0.8735,  ...,  0.8906, -0.7935, -0.3902],\n",
            "        ...,\n",
            "        [-0.0073,  1.0000,  0.2966,  ..., -0.5835, -0.4109, -0.8051],\n",
            "        [ 0.5765,  0.9999,  0.9187,  ...,  0.8935, -0.8261, -0.3794],\n",
            "        [-0.1863,  0.9999, -0.4823,  ..., -0.7506,  0.2291, -0.3750]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6258,  1.0000,  0.9052,  ...,  0.8488, -0.7238, -0.6111],\n",
            "        [ 0.6498,  1.0000,  0.9326,  ...,  0.8972, -0.7145, -0.5562],\n",
            "        [ 0.7156,  1.0000,  0.9462,  ...,  0.8101,  0.0850, -0.9212],\n",
            "        ...,\n",
            "        [ 0.5790,  0.9998,  0.9131,  ...,  0.8457, -0.8418, -0.3164],\n",
            "        [ 0.4566,  1.0000,  0.8555,  ...,  0.8112, -0.6462, -0.6899],\n",
            "        [ 0.5641,  1.0000,  0.7993,  ...,  0.5790, -0.4474, -0.6935]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7149,  1.0000,  0.9423,  ...,  0.8693, -0.6111, -0.6773],\n",
            "        [ 0.0508,  0.9999, -0.8139,  ..., -0.8589,  0.4158, -0.4574],\n",
            "        [-0.7212,  0.9970, -0.4424,  ..., -0.8823,  0.2102, -0.3921],\n",
            "        ...,\n",
            "        [ 0.6433,  1.0000,  0.9065,  ...,  0.8227, -0.6646, -0.4691],\n",
            "        [-0.5226,  0.9483, -0.8788,  ..., -0.9015,  0.3510,  0.5724],\n",
            "        [ 0.5364,  0.9998,  0.9028,  ...,  0.8109, -0.7595, -0.3557]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3937,  0.7513, -0.9334,  ..., -0.8909,  0.1696,  0.2468],\n",
            "        [ 0.1806,  1.0000,  0.4802,  ..., -0.6606,  0.3658, -0.9051],\n",
            "        [ 0.5535,  0.9999,  0.9084,  ...,  0.8625, -0.8021, -0.4327],\n",
            "        ...,\n",
            "        [ 0.6803,  0.9999,  0.8461,  ...,  0.8730, -0.8005, -0.4094],\n",
            "        [ 0.5003,  1.0000,  0.8654,  ...,  0.6822, -0.5275, -0.2979],\n",
            "        [ 0.7129,  1.0000,  0.9322,  ...,  0.7446,  0.2627, -0.9578]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0286,  0.9992, -0.7850,  ..., -0.8231,  0.4329, -0.1214],\n",
            "        [-0.3750,  0.0299, -0.8691,  ..., -0.9361,  0.2137,  0.2284],\n",
            "        [-0.5613,  0.9993, -0.9260,  ..., -0.9373,  0.0016, -0.1977],\n",
            "        ...,\n",
            "        [ 0.6963,  1.0000,  0.8807,  ...,  0.6418, -0.4562, -0.8618],\n",
            "        [ 0.6840,  1.0000, -0.1906,  ..., -0.5452,  0.4778, -0.8796],\n",
            "        [ 0.4905,  0.9999,  0.9305,  ...,  0.8777, -0.7349, -0.4207]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0231,  1.0000,  0.5165,  ...,  0.2415,  0.6947, -0.8014],\n",
            "        [-0.3053,  0.7451, -0.9324,  ..., -0.9185,  0.2846,  0.2658],\n",
            "        [-0.6272,  0.9975, -0.8561,  ..., -0.8890,  0.2669, -0.3111],\n",
            "        ...,\n",
            "        [-0.3651,  0.9997, -0.8808,  ..., -0.9071,  0.4631,  0.0580],\n",
            "        [ 0.5117,  1.0000,  0.6573,  ..., -0.1793, -0.1792, -0.8373],\n",
            "        [-0.1234,  1.0000, -0.2190,  ..., -0.8623,  0.7025, -0.8099]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4368,  1.0000, -0.4654,  ..., -0.3580,  0.7932, -0.3074],\n",
            "        [ 0.4635,  1.0000,  0.8276,  ...,  0.2736, -0.0841, -0.8906],\n",
            "        [-0.4525,  0.7347, -0.6743,  ..., -0.8931,  0.5120, -0.1721],\n",
            "        ...,\n",
            "        [-0.6319,  1.0000, -0.8144,  ..., -0.7059,  0.7154, -0.2775],\n",
            "        [ 0.0040,  1.0000, -0.8708,  ..., -0.8692,  0.5210, -0.5285],\n",
            "        [-0.0347,  1.0000, -0.0897,  ..., -0.6606,  0.4656, -0.9394]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7247,  1.0000,  0.9312,  ...,  0.5327, -0.4981, -0.6955],\n",
            "        [ 0.6962,  1.0000,  0.8871,  ...,  0.4924, -0.2476, -0.8391],\n",
            "        [-0.6112,  0.9581, -0.8969,  ..., -0.8467, -0.1726,  0.2316],\n",
            "        ...,\n",
            "        [ 0.5100,  1.0000,  0.7642,  ...,  0.0300, -0.5468, -0.7425],\n",
            "        [ 0.5213,  1.0000,  0.8167,  ...,  0.7530, -0.0926, -0.6847],\n",
            "        [-0.1810,  1.0000,  0.0875,  ..., -0.0407, -0.3222, -0.8575]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 4.5458e-01,  1.0000e+00,  7.8023e-01, -9.8035e-01, -4.8912e-01,\n",
            "          9.3616e-01,  7.9050e-01,  8.4106e-01, -9.9932e-01, -7.1580e-01,\n",
            "          8.6677e-01, -6.2628e-01,  3.5730e-01,  9.9986e-01,  3.1774e-01,\n",
            "         -2.0337e-01,  7.7649e-01, -9.9153e-01,  7.3561e-01, -4.3259e-01,\n",
            "          4.3628e-01, -8.1343e-01,  8.9706e-01, -4.6217e-01,  8.1653e-01,\n",
            "          7.7855e-01, -5.7696e-01,  6.6791e-01, -9.2416e-02,  4.1477e-01,\n",
            "         -6.9119e-01, -4.4804e-01,  9.5303e-01,  7.5814e-01,  8.7166e-01,\n",
            "         -9.7376e-01, -4.3954e-01, -9.7342e-01, -9.9442e-01, -9.9896e-01,\n",
            "          5.4997e-02, -5.6095e-01,  9.9988e-01, -8.2028e-01,  9.9858e-01,\n",
            "         -9.9205e-01,  5.3561e-01, -4.0946e-01,  7.3537e-01,  5.4670e-01,\n",
            "         -8.1803e-01,  9.6661e-01,  8.1764e-01,  9.0697e-01, -6.5869e-01,\n",
            "         -9.4618e-01, -8.1378e-01,  5.2484e-01, -9.0609e-01, -5.3035e-01,\n",
            "          8.5689e-01,  6.9078e-01, -7.0309e-01, -6.7087e-03, -9.1852e-01,\n",
            "         -5.5842e-01,  6.3939e-01,  5.6665e-01, -7.7152e-01, -9.8084e-01,\n",
            "          8.7300e-01, -9.6802e-01,  7.5224e-01,  7.5624e-03, -4.1815e-01,\n",
            "          8.9345e-01, -9.0252e-01,  8.7266e-01, -8.3305e-01,  9.9679e-01,\n",
            "          7.2268e-01,  5.5440e-01,  7.5211e-01, -9.9999e-01,  7.4879e-01,\n",
            "         -9.3894e-01,  9.9444e-01, -9.9468e-01, -9.8116e-01,  7.6947e-01,\n",
            "          8.4993e-01,  7.5057e-01,  8.2103e-01, -1.8628e-01, -5.3592e-01,\n",
            "         -9.3800e-01, -6.9515e-01,  6.7843e-01, -9.9965e-01,  8.1154e-01,\n",
            "          7.5528e-01,  8.2050e-01, -7.0009e-01, -7.4405e-01, -9.9984e-01,\n",
            "          4.9202e-01, -6.2685e-01, -6.1195e-01, -9.9999e-01, -8.2387e-01,\n",
            "         -8.2838e-01, -8.9586e-01, -4.6314e-01,  9.3803e-01,  5.6286e-01,\n",
            "          9.9995e-01,  9.0568e-01,  9.9948e-01, -9.9999e-01, -9.9620e-01,\n",
            "          2.7066e-01,  9.4725e-01, -6.9842e-01, -1.9104e-01,  6.4716e-01,\n",
            "         -9.8756e-01,  3.9796e-01, -9.9956e-01,  7.9415e-01, -9.5382e-01,\n",
            "         -6.3722e-01,  9.2713e-01,  9.2571e-01,  3.8608e-01, -7.1505e-01,\n",
            "          6.0694e-01, -9.9987e-01,  4.2027e-02, -7.9714e-01, -9.9668e-01,\n",
            "          9.9704e-01,  9.4388e-01,  8.7851e-01, -6.0841e-01, -4.7092e-01,\n",
            "          9.2298e-01,  9.0249e-01, -7.5832e-01, -1.5733e-01, -2.6537e-02,\n",
            "         -8.6390e-01,  8.3121e-01,  5.7020e-01, -5.3443e-01, -9.9999e-01,\n",
            "          5.0209e-01, -6.5197e-01,  9.8321e-01, -9.9188e-01,  9.8703e-01,\n",
            "         -9.8018e-01, -1.0000e+00,  5.1463e-01,  3.4540e-01, -9.2662e-01,\n",
            "          8.3058e-01, -8.2328e-01,  9.3720e-01, -6.4143e-01,  7.1016e-01,\n",
            "          7.7852e-01,  7.4916e-01,  3.5650e-01, -6.2843e-01,  1.4072e-01,\n",
            "         -8.7744e-01,  7.9942e-01, -7.4982e-01, -6.7349e-01, -9.8557e-01,\n",
            "          9.8986e-01, -5.9341e-01,  9.9138e-01, -9.7198e-01, -8.6239e-01,\n",
            "          6.0410e-01,  3.8227e-01, -1.0000e+00,  9.6085e-01,  5.0923e-01,\n",
            "          5.4550e-01,  6.3015e-01,  4.8607e-01, -4.8989e-01,  3.2825e-01,\n",
            "         -1.0003e-01, -5.7643e-01,  7.6696e-01, -3.8279e-01,  9.6021e-01,\n",
            "          3.8144e-01, -9.9979e-01,  9.2878e-01,  9.9600e-01,  3.6607e-01,\n",
            "         -5.6027e-01,  1.3602e-01,  9.9359e-01, -9.9901e-01, -8.4659e-01,\n",
            "          2.3803e-01, -7.1613e-01,  4.6518e-01,  5.4562e-01, -5.9171e-01,\n",
            "         -8.3193e-01,  7.4383e-01,  4.2034e-01, -5.6867e-02, -5.1422e-01,\n",
            "          5.3025e-01,  7.2857e-01, -4.9059e-01,  5.5495e-01,  8.2530e-01,\n",
            "          9.9950e-01, -7.0209e-01, -5.9596e-01,  6.8008e-01, -9.9991e-01,\n",
            "          8.8396e-01,  4.0500e-01, -2.8487e-01, -7.1627e-01,  9.9556e-01,\n",
            "          8.3898e-01,  7.2675e-01,  9.8889e-01, -9.8618e-01, -2.6314e-01,\n",
            "         -6.7250e-01,  7.7294e-01, -4.3192e-01, -1.5257e-01,  9.9999e-01,\n",
            "         -9.9789e-01,  9.9516e-01,  9.1115e-01,  2.2792e-01, -3.4267e-01,\n",
            "          5.5410e-01,  3.4111e-01, -2.3454e-01, -9.1440e-02, -7.5730e-01,\n",
            "          9.9550e-01, -7.7834e-01, -9.9294e-01,  6.0980e-01, -1.2627e-01,\n",
            "         -9.6761e-01, -8.8472e-01,  8.3830e-01, -7.0506e-01,  9.9366e-01,\n",
            "          9.9998e-01,  7.6980e-01,  5.2673e-01,  7.9811e-01,  7.1648e-01,\n",
            "          8.3794e-01, -9.9518e-01,  9.8413e-01,  1.0000e+00, -9.7776e-01,\n",
            "          3.7911e-01,  9.9999e-01,  7.6454e-01, -2.5875e-01, -5.9394e-01,\n",
            "          5.0243e-01, -9.9461e-01, -2.5954e-01, -5.9381e-01, -4.5820e-01,\n",
            "         -4.9124e-01,  4.7153e-03, -9.8084e-01, -9.9975e-01, -9.9481e-01,\n",
            "          9.9034e-01, -7.7023e-01, -7.5883e-01,  7.0098e-01, -7.1116e-01,\n",
            "          2.6881e-01, -7.2335e-01,  9.9654e-01, -8.4019e-01,  9.9999e-01,\n",
            "          7.1800e-01, -7.9316e-01, -9.8374e-01, -4.5642e-01,  6.6584e-01,\n",
            "          2.5007e-01,  9.9969e-01,  7.2928e-02, -7.4385e-01,  7.4543e-01,\n",
            "          7.7119e-01,  3.8055e-01,  9.7649e-01, -6.9922e-01,  7.4602e-01,\n",
            "          3.9447e-01,  1.9021e-01, -9.8787e-01, -5.7052e-01, -9.0351e-01,\n",
            "          8.6194e-01,  9.8575e-01,  7.3862e-01, -2.1016e-03,  9.9078e-01,\n",
            "          8.7874e-01, -1.0000e+00,  9.9977e-01,  9.9146e-01, -9.9708e-01,\n",
            "          8.6209e-01, -3.2238e-01,  9.2469e-01, -6.6765e-04,  5.8934e-01,\n",
            "         -9.1773e-01, -8.8559e-01, -9.9455e-01,  8.8456e-01,  3.3031e-01,\n",
            "         -7.9286e-01,  4.4595e-01, -9.3615e-01,  8.1605e-01,  2.8415e-01,\n",
            "          8.6462e-01, -2.8761e-01, -8.1151e-02, -9.9860e-01,  7.2921e-01,\n",
            "          8.8233e-01, -2.5691e-01,  8.0674e-01,  9.9517e-01, -1.3655e-02,\n",
            "          1.0000e+00, -8.1909e-01, -2.1240e-01,  1.2868e-01,  6.7504e-01,\n",
            "          5.4375e-01,  5.5238e-01, -3.0825e-01,  3.6287e-01, -1.0000e+00,\n",
            "          3.4019e-01, -6.6885e-01,  3.8728e-01,  5.8621e-01, -9.9482e-01,\n",
            "          4.3044e-01, -4.1979e-01,  4.0006e-02, -2.3500e-01,  3.4941e-01,\n",
            "          6.1868e-01,  9.9978e-01,  4.1606e-01, -5.0091e-01, -7.7109e-01,\n",
            "         -5.7510e-02,  2.5136e-01,  9.3104e-01,  7.8666e-01,  9.9584e-01,\n",
            "         -8.6313e-01, -1.5895e-01,  6.9913e-01,  1.5064e-01, -7.6720e-01,\n",
            "         -1.0157e-01,  6.3147e-01,  1.5693e-01,  9.8192e-01,  8.1400e-01,\n",
            "         -4.8013e-01, -6.5729e-01,  8.3445e-01, -9.9917e-01,  9.9999e-01,\n",
            "          4.6005e-01,  6.7598e-01,  9.6657e-01, -4.1131e-01,  7.8040e-01,\n",
            "          3.5250e-01,  5.6024e-01, -7.8806e-01,  9.8850e-01,  7.8509e-01,\n",
            "          7.6351e-01,  2.3440e-01,  1.2523e-01, -3.8418e-01, -9.0674e-01,\n",
            "          6.5195e-01,  5.4858e-01, -6.0276e-01, -9.9146e-01,  9.9629e-01,\n",
            "         -9.8917e-01,  3.3916e-01, -4.3284e-01,  8.6271e-01,  9.7389e-01,\n",
            "         -6.5725e-01, -9.1838e-01, -3.9059e-01,  1.2101e-01, -7.8070e-01,\n",
            "         -8.6757e-01, -9.9501e-01, -1.4334e-01, -9.6609e-01,  9.9995e-01,\n",
            "         -9.9548e-01,  6.7488e-01, -9.6637e-01, -8.9991e-01,  8.2104e-01,\n",
            "         -4.4541e-01, -7.0823e-01, -8.7049e-01, -8.8895e-02, -6.1332e-01,\n",
            "          8.4718e-01,  7.8470e-02,  8.4427e-01, -5.1185e-01,  2.1468e-01,\n",
            "          7.0941e-01,  1.1543e-01,  3.6465e-01,  9.5995e-01, -6.5752e-01,\n",
            "         -9.7901e-01, -7.7456e-01, -6.9756e-01, -7.0916e-01,  9.8138e-01,\n",
            "         -9.6138e-01, -8.2158e-01,  1.0000e+00, -9.9433e-01, -6.5700e-02,\n",
            "         -4.0105e-01, -9.9918e-01,  6.0820e-01, -5.3061e-01, -9.6802e-01,\n",
            "         -7.3155e-01, -8.1021e-01,  7.7983e-01,  9.8086e-01,  9.9977e-01,\n",
            "          3.2884e-01, -7.7404e-02, -9.8189e-01, -6.6824e-01,  9.9916e-01,\n",
            "         -9.9377e-01, -5.5816e-01,  4.2826e-01, -9.9854e-01,  9.6951e-01,\n",
            "          5.3796e-01, -5.4663e-01,  8.7081e-01, -8.2053e-01,  9.9042e-01,\n",
            "          6.5204e-01, -9.9853e-01,  5.8333e-01,  7.7345e-01, -2.5479e-01,\n",
            "          8.9857e-01,  3.4753e-01, -2.0049e-02, -9.8321e-01,  1.4161e-01,\n",
            "          9.9988e-01,  5.4605e-01, -8.7923e-01,  3.3058e-01,  8.2951e-01,\n",
            "          9.0226e-01,  9.9999e-01, -9.9240e-01,  8.0962e-01,  9.9992e-01,\n",
            "         -4.1088e-01,  6.2635e-01,  1.4625e-01, -8.4493e-01,  5.6986e-03,\n",
            "          5.3056e-01, -9.8615e-01,  9.9996e-01, -3.1671e-01, -9.9109e-01,\n",
            "         -9.9999e-01,  5.2974e-01, -8.7185e-01,  7.9831e-01,  9.9034e-01,\n",
            "          6.6672e-01,  8.7087e-01,  4.5248e-01, -9.9943e-01,  1.3810e-01,\n",
            "         -6.9317e-01, -9.9996e-01, -9.9985e-01,  8.7526e-01,  2.2660e-01,\n",
            "          4.4722e-01,  8.1739e-01, -2.7389e-01, -7.8133e-01,  9.9991e-01,\n",
            "          9.2007e-01, -9.9999e-01, -3.7641e-01,  4.7750e-01,  9.8234e-01,\n",
            "         -8.2386e-01,  7.5641e-01,  3.1643e-01,  4.6882e-01, -4.5899e-01,\n",
            "         -9.9999e-01, -6.2573e-01,  9.8887e-01, -2.0767e-01,  8.3299e-02,\n",
            "          9.9988e-01,  7.6711e-01,  3.3840e-01, -9.6659e-01,  2.2126e-01,\n",
            "          7.8314e-01, -9.9999e-01, -7.7700e-01,  9.9994e-01, -5.4832e-01,\n",
            "         -2.8354e-01, -6.4363e-01,  4.7040e-01,  7.1200e-01,  7.8319e-01,\n",
            "          4.5157e-01, -9.9893e-01,  9.9838e-01,  9.0901e-01, -8.0456e-01,\n",
            "          9.9865e-01, -4.9472e-01, -7.8378e-01, -8.5215e-01, -7.4604e-01,\n",
            "          8.2440e-01, -7.2407e-01,  6.1382e-01, -5.0355e-01,  9.9026e-01,\n",
            "          9.0011e-01, -4.4130e-01,  7.9850e-01,  9.2528e-01, -8.6090e-01,\n",
            "         -4.9386e-01,  9.0254e-01,  6.7241e-01,  3.8033e-01,  9.8732e-01,\n",
            "         -5.6069e-01, -8.1014e-01, -5.2685e-01,  7.6681e-01,  9.3729e-01,\n",
            "         -9.9998e-01,  9.3786e-01, -6.6648e-01, -9.5615e-01,  7.8734e-01,\n",
            "         -5.0469e-01, -7.5408e-01, -3.7807e-01, -2.9739e-01, -7.6400e-01,\n",
            "          1.4530e-01,  9.7762e-01,  8.1369e-01,  8.5985e-01, -9.9339e-01,\n",
            "         -9.9998e-01, -7.3552e-01, -7.0536e-01, -9.0831e-01, -6.1194e-01,\n",
            "          2.0329e-01,  9.7407e-01,  4.1802e-01,  3.6730e-01,  4.4390e-01,\n",
            "          9.9995e-01, -4.7762e-01,  9.9534e-01, -8.7512e-01,  9.4058e-01,\n",
            "         -9.9463e-01,  6.8098e-01,  6.0301e-01, -9.7767e-01, -7.0029e-01,\n",
            "          9.7449e-01, -4.5100e-01,  8.3072e-01, -9.8643e-01,  7.4374e-01,\n",
            "          1.0000e+00, -8.1041e-01, -5.8713e-01,  8.1166e-01, -9.1560e-01,\n",
            "          8.5692e-01, -5.2985e-02,  9.9710e-01, -9.9999e-01,  9.9364e-01,\n",
            "          7.6871e-02,  5.0795e-01,  7.2731e-01,  6.4951e-01,  5.7751e-01,\n",
            "         -6.8843e-01, -6.0838e-01, -9.9587e-01,  5.5562e-01,  5.8124e-01,\n",
            "         -6.7890e-01,  5.1538e-01,  9.4695e-01, -8.7807e-01, -9.9972e-01,\n",
            "         -7.2739e-01,  4.6804e-01,  9.7307e-01, -6.0716e-01, -9.9658e-01,\n",
            "          9.8772e-01, -4.0993e-01,  9.8384e-01,  8.2534e-02, -7.7298e-01,\n",
            "         -4.5374e-01, -4.1984e-01, -6.1764e-01,  7.1794e-01,  7.4161e-01,\n",
            "          8.7597e-01,  4.6544e-01, -8.7878e-01, -5.6187e-01, -2.8987e-01,\n",
            "         -8.6107e-01,  8.1894e-01, -1.6875e-01,  8.3776e-02,  7.7805e-01,\n",
            "          8.9412e-01,  9.9269e-01,  5.5614e-01,  6.0096e-02,  7.7655e-01,\n",
            "         -7.8660e-01, -6.4013e-01, -9.9989e-01,  9.9964e-01,  9.1317e-01,\n",
            "         -8.5221e-01, -9.9994e-01,  9.4922e-01,  3.9461e-01, -4.2097e-01,\n",
            "          7.8789e-01, -3.4433e-01, -8.1072e-01,  2.4719e-01,  8.8521e-01,\n",
            "         -1.0000e+00, -3.6319e-01,  4.6737e-01, -5.4267e-01, -5.8317e-01,\n",
            "         -9.9990e-01, -5.0668e-01,  2.7819e-01, -4.3426e-01,  4.1474e-01,\n",
            "          9.9964e-01, -5.9096e-01, -9.9408e-01, -9.8809e-01, -4.7412e-02,\n",
            "          7.7203e-01,  3.6091e-01, -9.8072e-01, -6.5512e-01,  9.2988e-01,\n",
            "         -9.9954e-01,  7.7154e-01, -6.2120e-01, -5.6919e-01,  3.6745e-01,\n",
            "          8.2203e-01,  9.5796e-01, -9.9999e-01,  9.1912e-01, -7.8497e-01,\n",
            "          9.3410e-01, -5.7173e-01,  6.0887e-01,  6.2909e-01,  5.3388e-01,\n",
            "         -9.9951e-01,  8.8796e-01,  4.2138e-01,  8.3675e-01,  7.7018e-01,\n",
            "          8.7838e-01, -2.7444e-01, -8.9910e-01, -7.1627e-01,  9.8989e-01,\n",
            "          9.8796e-01, -7.3399e-01,  7.5868e-01,  9.9971e-01, -7.1092e-01,\n",
            "          6.4531e-01,  6.2375e-01,  5.1813e-03, -9.9973e-01, -9.0389e-01,\n",
            "         -1.0640e-01, -5.4242e-01, -8.5037e-01]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training... :   0%|          | 0/127 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb70fdbcdc9d4d36a8aa15a5047d5374"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4208,  0.9998, -0.6310,  ..., -0.7825,  0.5701, -0.0048],\n",
            "        [ 0.6489,  1.0000,  0.9337,  ...,  0.7724, -0.3197, -0.7889],\n",
            "        [ 0.7058,  0.9999,  0.8978,  ...,  0.7411, -0.8257, -0.1277],\n",
            "        ...,\n",
            "        [-0.0599,  1.0000, -0.4202,  ..., -0.7771,  0.5094, -0.8747],\n",
            "        [ 0.7837,  1.0000, -0.1183,  ..., -0.7467,  0.8523, -0.8404],\n",
            "        [ 0.7486,  0.9998,  0.8096,  ...,  0.8942, -0.7075, -0.2666]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2873,  0.7575, -0.8246,  ..., -0.9095,  0.2883,  0.2058],\n",
            "        [ 0.5563,  1.0000,  0.9521,  ...,  0.7659, -0.7184, -0.6547],\n",
            "        [-0.3739,  0.8292, -0.8807,  ..., -0.9268,  0.4278,  0.2536],\n",
            "        ...,\n",
            "        [ 0.4712,  1.0000, -0.7422,  ..., -0.9455,  0.8006, -0.7228],\n",
            "        [ 0.5832,  0.9999,  0.8615,  ...,  0.8805, -0.6883, -0.4416],\n",
            "        [ 0.5218,  1.0000,  0.7669,  ...,  0.7842, -0.8049, -0.6360]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0698,  0.9958, -0.8743,  ..., -0.9063,  0.5800, -0.3739],\n",
            "        [ 0.1874,  1.0000,  0.9191,  ...,  0.6914, -0.2185, -0.5531],\n",
            "        [ 0.7103,  1.0000,  0.9502,  ...,  0.8843, -0.6574, -0.6803],\n",
            "        ...,\n",
            "        [ 0.6008,  0.9997,  0.9327,  ...,  0.8524, -0.6789, -0.5443],\n",
            "        [ 0.5607,  0.9999,  0.8773,  ...,  0.9035, -0.8387, -0.3018],\n",
            "        [ 0.6356,  0.9999,  0.8595,  ...,  0.8618, -0.8319, -0.2957]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5893,  0.9992,  0.9010,  ...,  0.8265, -0.8471, -0.6030],\n",
            "        [ 0.4840,  0.9999,  0.9457,  ...,  0.7972, -0.6605, -0.6112],\n",
            "        [ 0.3074,  1.0000,  0.4300,  ...,  0.4654, -0.1441, -0.6316],\n",
            "        ...,\n",
            "        [-0.2609,  0.9615, -0.9326,  ..., -0.8630,  0.4052, -0.0512],\n",
            "        [ 0.7041,  0.9997,  0.8571,  ...,  0.8287, -0.7294, -0.3680],\n",
            "        [-0.3611, -0.7389, -0.9543,  ..., -0.9310,  0.2545,  0.0540]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0396, -0.8898, -0.9377,  ..., -0.8757, -0.0283,  0.1015],\n",
            "        [ 0.6116,  1.0000,  0.9327,  ...,  0.7986, -0.0160, -0.8492],\n",
            "        [-0.6142,  0.3771, -0.9589,  ..., -0.9162,  0.1090,  0.3286],\n",
            "        ...,\n",
            "        [ 0.4457,  0.9998,  0.9284,  ...,  0.7610, -0.6382, -0.5993],\n",
            "        [ 0.7169,  0.9999,  0.7888,  ...,  0.8720, -0.6506, -0.3596],\n",
            "        [ 0.5531,  0.9997,  0.8979,  ...,  0.8383, -0.5330, -0.4408]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5204,  0.9998,  0.9519,  ...,  0.7782, -0.5418, -0.8132],\n",
            "        [ 0.6226,  0.9998,  0.9172,  ...,  0.6967, -0.7352, -0.6292],\n",
            "        [-0.1391,  0.9988,  0.2054,  ..., -0.8581,  0.3957, -0.7018],\n",
            "        ...,\n",
            "        [ 0.5889,  1.0000,  0.8304,  ...,  0.7504, -0.7683, -0.2584],\n",
            "        [-0.3119,  0.9997, -0.8110,  ..., -0.6595, -0.0702, -0.0335],\n",
            "        [-0.7224,  0.9855, -0.9205,  ..., -0.9257,  0.4897,  0.1093]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5438,  0.3356, -0.9123,  ..., -0.8794, -0.0148,  0.4335],\n",
            "        [ 0.6803,  1.0000,  0.9299,  ...,  0.8549, -0.7416, -0.2602],\n",
            "        [ 0.6540,  1.0000,  0.8438,  ...,  0.8804, -0.7413, -0.4056],\n",
            "        ...,\n",
            "        [ 0.7714,  1.0000,  0.9564,  ...,  0.8785, -0.6442, -0.7672],\n",
            "        [ 0.7324,  1.0000,  0.8232,  ...,  0.8911, -0.6466, -0.1293],\n",
            "        [-0.3584,  0.9952, -0.8296,  ..., -0.7652,  0.6721, -0.0366]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4728,  0.9999, -0.9264,  ..., -0.8594, -0.2802, -0.2139],\n",
            "        [ 0.6587,  1.0000,  0.8669,  ...,  0.9220, -0.8366, -0.3810],\n",
            "        [ 0.6655,  1.0000,  0.9038,  ...,  0.8546, -0.7021, -0.4887],\n",
            "        ...,\n",
            "        [-0.3228,  0.9250, -0.8890,  ..., -0.8408,  0.2324,  0.0309],\n",
            "        [-0.5675, -0.8336, -0.8936,  ..., -0.8688, -0.0841,  0.4364],\n",
            "        [-0.0440,  0.9585, -0.8503,  ..., -0.8550,  0.7491, -0.5254]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5784,  0.9956, -0.7585,  ..., -0.8650, -0.4090,  0.1006],\n",
            "        [ 0.2745,  0.9996,  0.9172,  ...,  0.4093, -0.2473, -0.4985],\n",
            "        [-0.2657,  0.9944, -0.5804,  ..., -0.9211,  0.2431, -0.5229],\n",
            "        ...,\n",
            "        [-0.4954, -0.0057, -0.9505,  ..., -0.9327,  0.5042,  0.4451],\n",
            "        [ 0.6983,  0.9999,  0.8569,  ...,  0.6950, -0.7272, -0.5069],\n",
            "        [-0.4771,  0.9304, -0.9324,  ..., -0.8768,  0.1213,  0.4533]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3996,  0.9999,  0.8887,  ...,  0.7995, -0.5921, -0.3524],\n",
            "        [-0.3390,  0.8097, -0.9386,  ..., -0.8955,  0.2679,  0.4087],\n",
            "        [ 0.6205,  0.9998,  0.9174,  ...,  0.8385, -0.7010, -0.6604],\n",
            "        ...,\n",
            "        [ 0.6002,  0.9999,  0.8780,  ...,  0.7935, -0.4720, -0.5480],\n",
            "        [ 0.6236,  0.9992,  0.8963,  ...,  0.8633, -0.7293, -0.2286],\n",
            "        [ 0.7045,  1.0000,  0.8521,  ...,  0.7992, -0.8080, -0.3298]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6125, -0.9981, -0.9565,  ..., -0.9525, -0.0331,  0.5019],\n",
            "        [ 0.6275,  0.9998,  0.8608,  ...,  0.8490, -0.7884, -0.2232],\n",
            "        [-0.2762,  0.9999, -0.3745,  ..., -0.5982,  0.3148, -0.6045],\n",
            "        ...,\n",
            "        [ 0.6754,  0.9999,  0.9515,  ...,  0.8111, -0.5889, -0.6677],\n",
            "        [ 0.7769,  1.0000,  0.9186,  ...,  0.6324, -0.7118, -0.6341],\n",
            "        [ 0.3230,  0.9999,  0.3943,  ..., -0.5077, -0.1084, -0.8445]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0823,  0.9998, -0.7141,  ..., -0.9020,  0.5798, -0.5205],\n",
            "        [-0.1836,  0.9991, -0.3790,  ..., -0.5781,  0.0307, -0.2891],\n",
            "        [-0.4387,  0.1731, -0.9093,  ..., -0.8588,  0.3116,  0.3064],\n",
            "        ...,\n",
            "        [ 0.4831,  1.0000,  0.9239,  ...,  0.6684,  0.1883, -0.8103],\n",
            "        [ 0.5029,  0.9999,  0.8009,  ...,  0.8728, -0.8592, -0.2111],\n",
            "        [ 0.4357,  0.9999,  0.8398,  ...,  0.8146, -0.7628, -0.1576]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5977,  1.0000,  0.8991,  ...,  0.8956, -0.6877, -0.0524],\n",
            "        [-0.0269,  0.7157, -0.8741,  ..., -0.8600,  0.3612,  0.1975],\n",
            "        [-0.3987,  0.8285, -0.8842,  ..., -0.8148,  0.5277,  0.7070],\n",
            "        ...,\n",
            "        [ 0.6269,  0.9996,  0.8403,  ...,  0.8560, -0.8585, -0.2533],\n",
            "        [ 0.7423,  0.9999,  0.8276,  ...,  0.6453, -0.2847, -0.7064],\n",
            "        [ 0.5536,  0.9993,  0.8763,  ...,  0.8519, -0.8208, -0.3578]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5901,  1.0000,  0.8098,  ...,  0.8073, -0.7372, -0.3045],\n",
            "        [ 0.2836,  0.9999,  0.2493,  ..., -0.6720,  0.2745, -0.7032],\n",
            "        [-0.4053, -0.9727, -0.9262,  ..., -0.9270, -0.1013,  0.4584],\n",
            "        ...,\n",
            "        [ 0.6165,  0.9994,  0.9024,  ...,  0.8971, -0.7867, -0.4874],\n",
            "        [-0.1623,  0.6854, -0.8539,  ..., -0.9116,  0.6003,  0.0085],\n",
            "        [ 0.6172,  0.9993,  0.8181,  ...,  0.8498, -0.6659, -0.2493]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6048,  0.9997,  0.6877,  ...,  0.8740, -0.8598, -0.3026],\n",
            "        [-0.0647, -0.2321, -0.9358,  ..., -0.9288,  0.1526,  0.1400],\n",
            "        [ 0.6405,  0.9997,  0.7561,  ...,  0.8211, -0.8383, -0.2169],\n",
            "        ...,\n",
            "        [-0.2733,  0.5468, -0.9210,  ..., -0.7893,  0.3139,  0.4878],\n",
            "        [ 0.3212,  1.0000, -0.6382,  ..., -0.7520,  0.8071, -0.7780],\n",
            "        [ 0.4338,  0.9999,  0.9348,  ...,  0.8319, -0.6556, -0.5155]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6978,  0.9999,  0.7491,  ...,  0.9345, -0.7649, -0.3127],\n",
            "        [-0.5665,  0.8526, -0.9271,  ..., -0.8710,  0.2451,  0.6117],\n",
            "        [ 0.5116,  1.0000,  0.9393,  ...,  0.8050, -0.4844, -0.7628],\n",
            "        ...,\n",
            "        [-0.4171,  0.9740, -0.8564,  ..., -0.7969,  0.4120, -0.1875],\n",
            "        [-0.1502, -0.0155, -0.9084,  ..., -0.8812,  0.2494,  0.3480],\n",
            "        [-0.5996,  0.9443, -0.8897,  ..., -0.9154, -0.1906, -0.1902]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6923,  0.9897, -0.8788,  ..., -0.8473,  0.3326, -0.1565],\n",
            "        [ 0.5059,  1.0000, -0.6692,  ..., -0.8455,  0.6411, -0.6276],\n",
            "        [ 0.3427,  0.9995,  0.8804,  ...,  0.8552, -0.7758, -0.4314],\n",
            "        ...,\n",
            "        [ 0.5639,  0.9999,  0.8872,  ...,  0.7106, -0.3422, -0.6109],\n",
            "        [ 0.3672,  0.9996,  0.8290,  ...,  0.8491, -0.8194, -0.3995],\n",
            "        [ 0.0777,  1.0000,  0.5813,  ...,  0.3400,  0.6216, -0.7590]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1522,  1.0000, -0.3750,  ..., -0.5845,  0.7518, -0.6344],\n",
            "        [-0.3247,  0.9992, -0.7890,  ..., -0.8530,  0.7256, -0.4662],\n",
            "        [ 0.4462,  0.9999,  0.8659,  ...,  0.8244, -0.8279, -0.4020],\n",
            "        ...,\n",
            "        [ 0.3344,  1.0000, -0.4164,  ..., -0.4255,  0.5697, -0.7821],\n",
            "        [ 0.5224,  0.9954,  0.8823,  ...,  0.8422, -0.7118, -0.3283],\n",
            "        [ 0.5323,  0.9995,  0.9141,  ...,  0.8469, -0.6713, -0.4795]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3293,  0.9999,  0.8819,  ...,  0.8530, -0.7814, -0.2687],\n",
            "        [ 0.5637,  0.9998,  0.8829,  ...,  0.8802, -0.7635, -0.3927],\n",
            "        [-0.3892, -0.3844, -0.8836,  ..., -0.9149, -0.0289,  0.6172],\n",
            "        ...,\n",
            "        [-0.1288,  1.0000,  0.2503,  ...,  0.0303,  0.6172, -0.6523],\n",
            "        [ 0.7797,  1.0000,  0.8646,  ...,  0.8331, -0.7029, -0.5957],\n",
            "        [ 0.4853,  1.0000,  0.8700,  ...,  0.6167, -0.7363, -0.4483]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4512,  0.9427, -0.8824,  ..., -0.8630,  0.3065,  0.0736],\n",
            "        [ 0.6266,  0.9999,  0.8269,  ...,  0.8717, -0.6509, -0.3667],\n",
            "        [ 0.6647,  0.9999,  0.9210,  ...,  0.8167, -0.7257, -0.4001],\n",
            "        ...,\n",
            "        [-0.3749,  0.9579, -0.6594,  ..., -0.8314,  0.2721, -0.0618],\n",
            "        [ 0.0438,  0.9973, -0.7761,  ..., -0.7922,  0.2190, -0.5783],\n",
            "        [ 0.7277,  0.9997,  0.9211,  ...,  0.8490, -0.4530, -0.6111]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7014,  0.9998,  0.7780,  ...,  0.8666, -0.7734, -0.2648],\n",
            "        [ 0.3532,  0.9996,  0.8486,  ...,  0.8641, -0.6625, -0.2880],\n",
            "        [ 0.4329,  1.0000,  0.8108,  ...,  0.7448, -0.3986, -0.4170],\n",
            "        ...,\n",
            "        [-0.4822, -0.9304, -0.9146,  ..., -0.8786,  0.4759,  0.1809],\n",
            "        [-0.6986, -0.6944, -0.9133,  ..., -0.9444,  0.0484,  0.4229],\n",
            "        [ 0.3200,  1.0000,  0.9359,  ...,  0.6039,  0.0129, -0.7702]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4996,  0.9906, -0.9276,  ..., -0.9166,  0.3624,  0.0972],\n",
            "        [-0.3214,  1.0000, -0.6745,  ..., -0.8223,  0.5618, -0.7851],\n",
            "        [ 0.5550,  0.9998,  0.8744,  ...,  0.8875, -0.8377, -0.2200],\n",
            "        ...,\n",
            "        [-0.3440, -0.3464, -0.8927,  ..., -0.9069,  0.3857, -0.0916],\n",
            "        [ 0.2978,  0.9999,  0.8921,  ...,  0.8465, -0.8170, -0.3751],\n",
            "        [-0.1195,  0.8843, -0.4155,  ..., -0.8413,  0.1238, -0.7026]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5394,  0.9999,  0.7472,  ...,  0.7769, -0.7486, -0.1444],\n",
            "        [ 0.5461,  0.9994,  0.8350,  ...,  0.6847, -0.7692,  0.0899],\n",
            "        [ 0.3463,  1.0000, -0.3206,  ..., -0.8029,  0.8279, -0.7036],\n",
            "        ...,\n",
            "        [ 0.6712,  0.9999,  0.8174,  ...,  0.8317, -0.7239, -0.3121],\n",
            "        [ 0.1056,  0.9354, -0.8251,  ..., -0.8969,  0.2763, -0.5631],\n",
            "        [ 0.6911,  0.9997,  0.8065,  ...,  0.8121, -0.7825, -0.5705]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3648,  0.9088, -0.8504,  ..., -0.8419, -0.2480,  0.4147],\n",
            "        [ 0.4332,  0.9995,  0.8696,  ...,  0.8238, -0.7861, -0.0950],\n",
            "        [ 0.6432,  1.0000,  0.9180,  ...,  0.2146,  0.2886, -0.9718],\n",
            "        ...,\n",
            "        [ 0.1219,  0.9787, -0.7635,  ..., -0.8597,  0.3524, -0.3430],\n",
            "        [ 0.5795,  0.9994,  0.8562,  ...,  0.8292, -0.8134,  0.0096],\n",
            "        [ 0.6892,  0.9999,  0.8975,  ...,  0.8662, -0.7384, -0.4638]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5410,  0.9979,  0.8486,  ...,  0.8277, -0.6905, -0.4721],\n",
            "        [ 0.6715,  0.9999,  0.8672,  ...,  0.8511, -0.5490, -0.4002],\n",
            "        [-0.3740, -0.9058, -0.9195,  ..., -0.8755,  0.1506,  0.5926],\n",
            "        ...,\n",
            "        [-0.4599,  0.4576, -0.8574,  ..., -0.8868,  0.2931,  0.2083],\n",
            "        [ 0.4736,  0.9999,  0.8010,  ...,  0.7754, -0.7455, -0.5699],\n",
            "        [ 0.6097,  0.9993,  0.8999,  ...,  0.8306, -0.7835, -0.1744]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3507,  0.9980, -0.7926,  ..., -0.8866,  0.3395, -0.3489],\n",
            "        [ 0.3040,  0.9992,  0.8611,  ...,  0.7740, -0.7270, -0.4677],\n",
            "        [ 0.4684,  0.9991,  0.6402,  ...,  0.7861, -0.8493, -0.2804],\n",
            "        ...,\n",
            "        [-0.4771,  0.9926, -0.6470,  ..., -0.7774,  0.3021, -0.7133],\n",
            "        [ 0.7176,  0.9999,  0.8761,  ...,  0.8388, -0.7625, -0.4443],\n",
            "        [-0.3336,  0.9849, -0.7624,  ..., -0.9033,  0.4870, -0.1168]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6019, -0.5272, -0.9410,  ..., -0.9063,  0.4285,  0.4867],\n",
            "        [ 0.6174,  0.9991,  0.8802,  ...,  0.8399, -0.8154, -0.2691],\n",
            "        [ 0.4136,  0.9997,  0.8333,  ...,  0.8931, -0.7295, -0.4620],\n",
            "        ...,\n",
            "        [-0.3628,  1.0000, -0.5935,  ..., -0.9028,  0.2295, -0.5320],\n",
            "        [-0.6523,  0.5364, -0.9277,  ..., -0.9266,  0.1679,  0.7081],\n",
            "        [-0.4456,  0.9076, -0.7317,  ..., -0.8893,  0.4094,  0.4432]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2720,  0.9909, -0.7432,  ..., -0.7633,  0.2405, -0.3141],\n",
            "        [-0.4039, -0.2653, -0.9280,  ..., -0.9194,  0.3616,  0.0486],\n",
            "        [-0.3849,  0.9658, -0.6128,  ..., -0.8778,  0.4653, -0.2866],\n",
            "        ...,\n",
            "        [ 0.5921,  0.9997,  0.8820,  ...,  0.8905, -0.8179, -0.2027],\n",
            "        [-0.3641, -0.9480, -0.8122,  ..., -0.8261,  0.4978, -0.3297],\n",
            "        [-0.4231, -0.2090, -0.9309,  ..., -0.8445,  0.1215,  0.3632]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3555,  0.9947,  0.8978,  ...,  0.7593, -0.8419,  0.1716],\n",
            "        [ 0.3608,  0.9998,  0.8311,  ...,  0.7537, -0.7167, -0.3312],\n",
            "        [ 0.5896,  0.9997,  0.8156,  ...,  0.8410, -0.8336, -0.3293],\n",
            "        ...,\n",
            "        [-0.3620,  0.6284, -0.9134,  ..., -0.8665,  0.3214,  0.4018],\n",
            "        [ 0.4966,  0.9997,  0.9355,  ...,  0.7854, -0.8603, -0.4859],\n",
            "        [ 0.4826,  0.9996,  0.8495,  ...,  0.8694, -0.8253, -0.4314]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5891,  1.0000,  0.7935,  ...,  0.7595, -0.6725, -0.6661],\n",
            "        [ 0.6635,  0.9999,  0.7305,  ...,  0.8038, -0.8479, -0.3125],\n",
            "        [-0.1224,  0.9366, -0.8588,  ..., -0.8927,  0.6120, -0.2984],\n",
            "        ...,\n",
            "        [ 0.6635,  0.9999,  0.8631,  ...,  0.8358, -0.7822, -0.2706],\n",
            "        [-0.6278, -0.8690, -0.8999,  ..., -0.9326,  0.2829,  0.4044],\n",
            "        [ 0.5612,  1.0000,  0.9522,  ...,  0.8948, -0.3548, -0.7164]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6631, -0.9432, -0.9175,  ..., -0.9502,  0.1655,  0.6526],\n",
            "        [ 0.0952,  0.9991, -0.4516,  ..., -0.8520, -0.0460, -0.4996],\n",
            "        [ 0.7227,  0.9999,  0.8054,  ...,  0.8743, -0.6781, -0.3615],\n",
            "        ...,\n",
            "        [-0.4848, -1.0000, -0.8947,  ..., -0.9349, -0.1239,  0.8254],\n",
            "        [ 0.8087,  0.9998,  0.8925,  ...,  0.8662, -0.7843, -0.5181],\n",
            "        [-0.6814, -0.9040, -0.9349,  ..., -0.9347,  0.1035,  0.4040]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5284,  0.9998,  0.8016,  ...,  0.8903, -0.8059, -0.3463],\n",
            "        [ 0.4999,  0.9997,  0.8807,  ...,  0.8860, -0.8333, -0.2660],\n",
            "        [-0.2432,  0.9967, -0.8755,  ..., -0.9136,  0.2169, -0.1371],\n",
            "        ...,\n",
            "        [-0.0892,  0.9999, -0.4755,  ..., -0.5636,  0.5645, -0.7061],\n",
            "        [ 0.6053,  0.9995,  0.9270,  ...,  0.9022, -0.7976, -0.3560],\n",
            "        [ 0.5111,  0.9999,  0.9324,  ...,  0.8905, -0.5516, -0.4855]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5610,  0.9998,  0.8579,  ...,  0.7596, -0.6498, -0.4695],\n",
            "        [-0.3598,  0.9497, -0.9389,  ..., -0.7781,  0.5167,  0.5341],\n",
            "        [ 0.5801,  0.9997,  0.9315,  ...,  0.8031, -0.7684, -0.1580],\n",
            "        ...,\n",
            "        [ 0.7506,  1.0000,  0.7207,  ...,  0.7625, -0.6060, -0.7045],\n",
            "        [-0.1453,  0.9953, -0.9133,  ..., -0.9337,  0.3104,  0.0231],\n",
            "        [-0.3793, -0.9459, -0.9030,  ..., -0.8980,  0.0664,  0.6568]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4324,  0.1324, -0.8086,  ..., -0.8408, -0.2901,  0.5021],\n",
            "        [-0.6078,  0.9482, -0.8140,  ..., -0.9060,  0.0257,  0.4441],\n",
            "        [ 0.6379,  0.9998,  0.8505,  ...,  0.8991, -0.8186, -0.6439],\n",
            "        ...,\n",
            "        [-0.6971, -0.2485, -0.8795,  ..., -0.9354,  0.2354,  0.4688],\n",
            "        [ 0.6927,  0.9999,  0.9239,  ...,  0.7091, -0.6852, -0.6039],\n",
            "        [ 0.2841,  0.9959,  0.8448,  ...,  0.8403, -0.9090, -0.0060]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6000,  1.0000,  0.9358,  ...,  0.8883, -0.8199, -0.6872],\n",
            "        [ 0.5269,  0.9999,  0.8736,  ...,  0.7545, -0.7867, -0.3569],\n",
            "        [ 0.5402,  0.9999,  0.7947,  ...,  0.8115, -0.7623, -0.3234],\n",
            "        ...,\n",
            "        [-0.6425, -0.0638, -0.9075,  ..., -0.8639,  0.1518,  0.5786],\n",
            "        [-0.3877,  0.9552, -0.7962,  ..., -0.8344,  0.6688, -0.5015],\n",
            "        [ 0.5781,  0.9998,  0.8924,  ...,  0.8956, -0.7222, -0.4993]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4084, -0.9888, -0.9660,  ..., -0.9079,  0.0548,  0.6869],\n",
            "        [-0.3816, -0.9451, -0.9069,  ..., -0.9071,  0.2794,  0.5660],\n",
            "        [ 0.5724,  0.9989,  0.9101,  ...,  0.8293, -0.7707, -0.3830],\n",
            "        ...,\n",
            "        [ 0.7928,  0.9992,  0.7484,  ...,  0.8898, -0.7582, -0.3012],\n",
            "        [-0.7114,  0.9742, -0.8536,  ..., -0.9091,  0.0210,  0.5525],\n",
            "        [-0.5171, -0.9462, -0.8971,  ..., -0.8935,  0.2790,  0.6206]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6193, -0.2941, -0.9344,  ..., -0.8192,  0.4552,  0.2532],\n",
            "        [ 0.6244,  0.9997,  0.7618,  ...,  0.7916, -0.7039, -0.2056],\n",
            "        [ 0.3869,  1.0000,  0.0717,  ..., -0.6170,  0.2597, -0.8219],\n",
            "        ...,\n",
            "        [ 0.4276,  0.9990,  0.8933,  ...,  0.8083, -0.8510, -0.5019],\n",
            "        [ 0.4658,  0.9994,  0.9300,  ...,  0.7822, -0.5581, -0.6122],\n",
            "        [ 0.6064,  0.9998,  0.8742,  ...,  0.7254, -0.4014, -0.6739]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5683,  0.9966,  0.8595,  ...,  0.8659, -0.7984,  0.0386],\n",
            "        [ 0.4716,  1.0000,  0.8309,  ...,  0.6171, -0.6242, -0.3863],\n",
            "        [ 0.5422,  0.9998,  0.8050,  ...,  0.7775, -0.8892, -0.1386],\n",
            "        ...,\n",
            "        [-0.9034,  0.3998, -0.8822,  ..., -0.8306,  0.2420,  0.6882],\n",
            "        [ 0.2192,  0.9998, -0.8415,  ..., -0.9009,  0.5998, -0.3918],\n",
            "        [-0.1075,  0.9996, -0.8245,  ..., -0.9172,  0.4288,  0.0673]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1436,  0.4044, -0.9530,  ..., -0.8732,  0.4991,  0.2370],\n",
            "        [-0.1878,  0.9999, -0.4958,  ..., -0.7371,  0.0532, -0.6897],\n",
            "        [ 0.4593,  0.9997,  0.8927,  ...,  0.9379, -0.6755, -0.3805],\n",
            "        ...,\n",
            "        [ 0.6094,  0.9999,  0.9170,  ...,  0.8712, -0.5511, -0.5407],\n",
            "        [ 0.5537,  0.9996,  0.8079,  ...,  0.9105, -0.7658, -0.3515],\n",
            "        [ 0.0227,  1.0000,  0.8829,  ...,  0.4080, -0.4915, -0.8728]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3139,  1.0000,  0.9319,  ...,  0.2758, -0.3348, -0.8742],\n",
            "        [ 0.6467,  0.9993,  0.8348,  ...,  0.8874, -0.7330, -0.2178],\n",
            "        [ 0.6913,  0.9995,  0.8461,  ...,  0.8961, -0.6674, -0.5259],\n",
            "        ...,\n",
            "        [-0.5167,  0.9734, -0.8321,  ..., -0.8970,  0.3705,  0.2120],\n",
            "        [ 0.3362,  0.9993,  0.8825,  ...,  0.8864, -0.8030, -0.0466],\n",
            "        [-0.2241, -0.7491, -0.9457,  ..., -0.9056,  0.2710,  0.5285]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6867,  0.9999,  0.9268,  ...,  0.9264, -0.8679, -0.5972],\n",
            "        [-0.2440, -0.6139, -0.9206,  ..., -0.8862,  0.3235,  0.0958],\n",
            "        [ 0.3986,  1.0000, -0.4049,  ..., -0.8591,  0.7375, -0.7542],\n",
            "        ...,\n",
            "        [ 0.2534,  1.0000,  0.9146,  ...,  0.5662, -0.3091, -0.8938],\n",
            "        [ 0.6227,  0.9993,  0.9247,  ...,  0.8425, -0.7614, -0.5880],\n",
            "        [ 0.5781,  0.9999,  0.8099,  ...,  0.8121, -0.8157, -0.1564]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6042,  0.9999,  0.9548,  ...,  0.7503, -0.6162, -0.4328],\n",
            "        [-0.0123,  1.0000, -0.5278,  ..., -0.3039,  0.6988, -0.7134],\n",
            "        [-0.3155, -0.9003, -0.9308,  ..., -0.8069,  0.3218,  0.1103],\n",
            "        ...,\n",
            "        [ 0.6777,  0.9940,  0.8032,  ...,  0.9098, -0.8078, -0.0999],\n",
            "        [ 0.6593,  0.9995,  0.8010,  ...,  0.8043, -0.8040, -0.3073],\n",
            "        [ 0.4880,  0.9998,  0.9218,  ...,  0.7051, -0.8458, -0.3179]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5092,  0.9992,  0.8645,  ...,  0.8388, -0.6507, -0.0521],\n",
            "        [ 0.6292,  1.0000,  0.7977,  ...,  0.7916, -0.6475, -0.6370],\n",
            "        [ 0.4010,  1.0000,  0.8799,  ...,  0.8193, -0.8355, -0.5491],\n",
            "        ...,\n",
            "        [ 0.5547,  1.0000, -0.5822,  ..., -0.8740,  0.8428, -0.6373],\n",
            "        [-0.5596, -0.9928, -0.9000,  ..., -0.9200,  0.1321,  0.6685],\n",
            "        [-0.6399, -0.9726, -0.9409,  ..., -0.8547,  0.2772,  0.6639]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5924,  1.0000,  0.7882,  ...,  0.7779, -0.7024, -0.4237],\n",
            "        [ 0.7700,  1.0000,  0.9616,  ...,  0.7540, -0.6806, -0.6385],\n",
            "        [ 0.4368,  0.9999,  0.8493,  ...,  0.4805, -0.6879, -0.8434],\n",
            "        ...,\n",
            "        [-0.5426, -0.2312, -0.8933,  ..., -0.9412, -0.1840,  0.1794],\n",
            "        [ 0.6624,  1.0000,  0.7831,  ...,  0.8294, -0.5705, -0.6388],\n",
            "        [-0.6819, -0.9904, -0.9488,  ..., -0.9304,  0.1399,  0.3615]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7264,  0.9999,  0.9226,  ...,  0.8992, -0.7658, -0.6097],\n",
            "        [ 0.8332,  1.0000,  0.9593,  ...,  0.8496, -0.3592, -0.7993],\n",
            "        [-0.6142, -0.9937, -0.9437,  ..., -0.9004,  0.2448,  0.5916],\n",
            "        ...,\n",
            "        [ 0.5139,  0.9991,  0.8195,  ...,  0.8143, -0.8541, -0.1385],\n",
            "        [-0.6011,  0.6809, -0.9489,  ..., -0.8853,  0.0031,  0.2601],\n",
            "        [ 0.3470,  0.9998,  0.7968,  ...,  0.8547, -0.6337, -0.1987]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-6.4272e-01, -9.9945e-01, -9.1701e-01,  ..., -9.1431e-01,\n",
            "         -9.5171e-05,  6.6076e-01],\n",
            "        [ 5.7404e-01,  9.9859e-01,  7.7638e-01,  ...,  8.3336e-01,\n",
            "         -7.6449e-01, -1.1863e-01],\n",
            "        [ 6.4592e-01,  9.9995e-01,  9.5652e-01,  ...,  4.3635e-01,\n",
            "         -4.8073e-01, -5.0494e-01],\n",
            "        ...,\n",
            "        [ 5.3654e-01,  9.9998e-01,  7.4417e-01,  ...,  8.7016e-01,\n",
            "         -7.4346e-01, -7.7988e-01],\n",
            "        [-7.2893e-01, -4.4739e-01, -7.8722e-01,  ..., -9.2737e-01,\n",
            "         -8.0032e-02,  2.9502e-01],\n",
            "        [-7.0917e-01,  1.4797e-01, -9.5905e-01,  ..., -8.3285e-01,\n",
            "          1.6844e-02,  5.6408e-01]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6054,  0.9991,  0.8106,  ...,  0.8573, -0.8444, -0.2776],\n",
            "        [ 0.4554,  0.9997,  0.8883,  ...,  0.8622, -0.8619, -0.3666],\n",
            "        [-0.5950, -0.9974, -0.9477,  ..., -0.9161,  0.2724,  0.5600],\n",
            "        ...,\n",
            "        [-0.5941, -0.1413, -0.9398,  ..., -0.9109,  0.0389,  0.4888],\n",
            "        [ 0.7034,  1.0000,  0.7955,  ...,  0.4641, -0.7359, -0.5551],\n",
            "        [-0.2686, -0.9855, -0.9169,  ..., -0.8852,  0.1259,  0.3871]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4500, -0.9916, -0.9546,  ..., -0.9323,  0.0527,  0.3512],\n",
            "        [ 0.4639,  0.9994,  0.8444,  ...,  0.8637, -0.9010, -0.3153],\n",
            "        [-0.3448, -0.6136, -0.9550,  ..., -0.9139,  0.2845,  0.5418],\n",
            "        ...,\n",
            "        [ 0.4270,  0.9999,  0.7637,  ...,  0.9057, -0.7030, -0.2809],\n",
            "        [ 0.6661,  1.0000,  0.8205,  ...,  0.9291, -0.7054, -0.6955],\n",
            "        [ 0.4958,  1.0000,  0.8984,  ...,  0.6415, -0.2763, -0.8785]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5376, -0.9985, -0.8636,  ..., -0.8568,  0.0751,  0.7093],\n",
            "        [ 0.5323,  0.9992,  0.7931,  ...,  0.8426, -0.7878, -0.3603],\n",
            "        [ 0.3373,  1.0000,  0.7593,  ...,  0.3313, -0.2677, -0.6430],\n",
            "        ...,\n",
            "        [ 0.5793,  0.9994,  0.9171,  ...,  0.8159, -0.7739, -0.3800],\n",
            "        [-0.7123, -0.9916, -0.9353,  ..., -0.8995,  0.1539,  0.6447],\n",
            "        [-0.4509,  0.6330, -0.9242,  ..., -0.9289,  0.3437,  0.2942]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6746,  0.1686, -0.8979,  ..., -0.9464, -0.0055,  0.2110],\n",
            "        [ 0.4941,  0.9995,  0.7166,  ...,  0.7719, -0.6922, -0.6619],\n",
            "        [ 0.6064,  1.0000,  0.8103,  ...,  0.3033,  0.0335, -0.7614],\n",
            "        ...,\n",
            "        [ 0.3870,  1.0000,  0.7001,  ...,  0.3728, -0.2922, -0.7360],\n",
            "        [ 0.6473,  0.9999,  0.7901,  ...,  0.7139, -0.7902, -0.4431],\n",
            "        [ 0.3970,  0.9996,  0.9282,  ...,  0.8774, -0.6758, -0.5774]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.7486,  0.0381, -0.6827,  ..., -0.7614, -0.2100,  0.7546],\n",
            "        [ 0.4304,  0.9993,  0.7307,  ...,  0.7100, -0.6930, -0.0267],\n",
            "        [ 0.0068,  0.9993, -0.8521,  ..., -0.8004,  0.6238, -0.5358],\n",
            "        ...,\n",
            "        [-0.7074, -0.6910, -0.9107,  ..., -0.8928,  0.0157,  0.4924],\n",
            "        [-0.5587, -0.9724, -0.9694,  ..., -0.8904, -0.0304,  0.5354],\n",
            "        [-0.1846,  0.6632, -0.9203,  ..., -0.8110,  0.3810,  0.0551]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5987,  0.9990,  0.7744,  ...,  0.8069, -0.7975, -0.3409],\n",
            "        [-0.6055, -0.9999, -0.9245,  ..., -0.9301,  0.2868,  0.8136],\n",
            "        [-0.6296, -0.5834, -0.9642,  ..., -0.8857,  0.0709,  0.4996],\n",
            "        ...,\n",
            "        [-0.6655, -0.9428, -0.9542,  ..., -0.8405,  0.3515,  0.3335],\n",
            "        [ 0.6421,  0.9998,  0.8587,  ...,  0.8256, -0.8703, -0.1156],\n",
            "        [ 0.5829,  1.0000,  0.7133,  ..., -0.2155,  0.0877, -0.8768]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6266,  0.9997,  0.8923,  ...,  0.7952, -0.7212, -0.4762],\n",
            "        [ 0.6932,  0.9997,  0.8497,  ...,  0.8785, -0.8153, -0.4388],\n",
            "        [-0.3460,  0.8456, -0.9251,  ..., -0.7374,  0.4434,  0.5510],\n",
            "        ...,\n",
            "        [ 0.7832,  0.9997,  0.8448,  ...,  0.8827, -0.7699, -0.3096],\n",
            "        [-0.5962, -0.9455, -0.9524,  ..., -0.8876, -0.0362,  0.6161],\n",
            "        [-0.5021, -0.8134, -0.9006,  ..., -0.9221, -0.1302,  0.4432]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5525, -0.9900, -0.9596,  ..., -0.9293,  0.3066,  0.5437],\n",
            "        [ 0.6128,  0.9996,  0.8696,  ...,  0.8965, -0.8818, -0.2314],\n",
            "        [ 0.4065,  0.9994,  0.7266,  ...,  0.8293, -0.8541, -0.3890],\n",
            "        ...,\n",
            "        [ 0.5716,  1.0000,  0.7391,  ...,  0.7228, -0.6701, -0.4863],\n",
            "        [ 0.5731,  1.0000,  0.8177,  ...,  0.7115, -0.6578, -0.5596],\n",
            "        [-0.6091, -0.9598, -0.9463,  ..., -0.8334,  0.2784,  0.5442]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6379,  0.9997,  0.8771,  ...,  0.8117, -0.7683, -0.5670],\n",
            "        [ 0.7904,  1.0000,  0.9311,  ...,  0.8462, -0.6035, -0.7140],\n",
            "        [-0.4844, -0.1927, -0.9383,  ..., -0.8277,  0.3357,  0.2876],\n",
            "        ...,\n",
            "        [-0.4177, -0.9723, -0.9421,  ..., -0.9113, -0.0700,  0.7765],\n",
            "        [-0.5705, -0.9920, -0.9317,  ..., -0.9033, -0.0368,  0.7384],\n",
            "        [-0.6506, -0.9995, -0.9421,  ..., -0.9187,  0.1939,  0.7436]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5926,  0.9999,  0.9357,  ...,  0.8849, -0.6709, -0.3004],\n",
            "        [-0.4798,  0.6229, -0.9200,  ..., -0.9325,  0.1921,  0.1879],\n",
            "        [ 0.4062,  0.9995,  0.7946,  ...,  0.8207, -0.8021, -0.4733],\n",
            "        ...,\n",
            "        [ 0.6729,  1.0000,  0.8559,  ...,  0.7378, -0.7630, -0.6685],\n",
            "        [-0.7196, -0.8395, -0.8153,  ..., -0.8871,  0.2024,  0.7319],\n",
            "        [ 0.6254,  1.0000,  0.7212,  ..., -0.0327, -0.4685, -0.9389]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5255,  0.9997,  0.7980,  ...,  0.9022, -0.8312, -0.1989],\n",
            "        [ 0.6118,  0.9999,  0.7666,  ...,  0.8942, -0.8165, -0.1444],\n",
            "        [ 0.5011,  1.0000,  0.7072,  ...,  0.5305, -0.7282, -0.3475],\n",
            "        ...,\n",
            "        [ 0.4940,  1.0000,  0.8704,  ...,  0.8000, -0.6848, -0.3742],\n",
            "        [ 0.6036,  0.9986,  0.7358,  ...,  0.7868, -0.8597, -0.1500],\n",
            "        [-0.6219, -0.7819, -0.9533,  ..., -0.8970,  0.1019,  0.6087]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1862,  0.9997, -0.7737,  ..., -0.7282, -0.1487, -0.2377],\n",
            "        [ 0.6484,  0.9997,  0.8559,  ...,  0.8607, -0.6982, -0.3084],\n",
            "        [-0.3723,  0.4654, -0.9360,  ..., -0.9176,  0.2714,  0.3820],\n",
            "        ...,\n",
            "        [-0.7314,  0.5184, -0.8977,  ..., -0.9373, -0.1565,  0.4736],\n",
            "        [ 0.5804,  1.0000,  0.9165,  ...,  0.5678, -0.6063, -0.7865],\n",
            "        [ 0.6908,  1.0000,  0.9385,  ...,  0.6437, -0.0354, -0.9662]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2520,  0.9909, -0.7500,  ..., -0.8008,  0.4440, -0.0852],\n",
            "        [-0.2428,  0.6364, -0.9410,  ..., -0.9208,  0.3052,  0.4481],\n",
            "        [ 0.6692,  0.9995,  0.9104,  ...,  0.8977, -0.8225, -0.2744],\n",
            "        ...,\n",
            "        [-0.4010, -0.7815, -0.9447,  ..., -0.8793,  0.1221,  0.3426],\n",
            "        [ 0.7211,  1.0000,  0.8770,  ...,  0.7439, -0.5333, -0.3700],\n",
            "        [-0.5946, -0.1825, -0.8998,  ..., -0.9066,  0.0240,  0.4924]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3051,  1.0000,  0.7123,  ...,  0.2184,  0.2621, -0.6722],\n",
            "        [-0.4891, -0.6198, -0.9195,  ..., -0.9202,  0.0260,  0.3343],\n",
            "        [ 0.5886,  1.0000,  0.8689,  ...,  0.7292, -0.5745, -0.5839],\n",
            "        ...,\n",
            "        [ 0.4931,  1.0000,  0.8554,  ...,  0.8058, -0.7089, -0.5768],\n",
            "        [ 0.4521,  1.0000,  0.9365,  ...,  0.2080, -0.4716, -0.7383],\n",
            "        [ 0.5760,  1.0000,  0.9018,  ...,  0.6803, -0.3661, -0.8293]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6957,  0.9999,  0.8443,  ...,  0.7991, -0.6692, -0.5150],\n",
            "        [-0.3953, -0.0036, -0.9284,  ..., -0.8920,  0.0834,  0.4293],\n",
            "        [-0.5883, -0.9461, -0.9316,  ..., -0.9396, -0.1688,  0.5704],\n",
            "        ...,\n",
            "        [-0.2859,  0.9798, -0.8925,  ..., -0.8963,  0.6845,  0.1264],\n",
            "        [-0.2758, -0.8692, -0.9241,  ..., -0.8232,  0.2485,  0.6044],\n",
            "        [-0.6807, -0.9776, -0.9336,  ..., -0.9273,  0.4941,  0.0819]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.7045,  0.9997, -0.5014,  ..., -0.8511, -0.1504, -0.6341],\n",
            "        [-0.6399, -0.9993, -0.9527,  ..., -0.9125,  0.2760,  0.6812],\n",
            "        [-0.2931,  0.9006, -0.9105,  ..., -0.8729, -0.0989,  0.4527],\n",
            "        ...,\n",
            "        [ 0.5780,  0.9999,  0.9316,  ...,  0.5477, -0.5617,  0.0219],\n",
            "        [ 0.7285,  1.0000,  0.9031,  ...,  0.8544, -0.4941, -0.7469],\n",
            "        [-0.3460, -0.5542, -0.9263,  ..., -0.9175,  0.1367,  0.6194]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5850,  1.0000,  0.9406,  ...,  0.8897, -0.7484, -0.6189],\n",
            "        [-0.6022, -0.9615, -0.9411,  ..., -0.9059,  0.0902,  0.6836],\n",
            "        [ 0.5799,  1.0000,  0.8607,  ...,  0.7653, -0.6502, -0.4115],\n",
            "        ...,\n",
            "        [ 0.5036,  0.9999,  0.8164,  ...,  0.9046, -0.7644, -0.6540],\n",
            "        [-0.3599, -0.3845, -0.9046,  ..., -0.8008,  0.2795,  0.2217],\n",
            "        [ 0.4284,  0.9998,  0.8837,  ...,  0.7823, -0.6860, -0.6523]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6628,  1.0000,  0.8799,  ...,  0.9140, -0.6522, -0.6032],\n",
            "        [-0.5285,  0.3158, -0.9176,  ..., -0.7945,  0.4346, -0.1762],\n",
            "        [ 0.7301,  0.9998,  0.8801,  ...,  0.9014, -0.7832, -0.3430],\n",
            "        ...,\n",
            "        [ 0.7879,  1.0000,  0.9294,  ...,  0.8167, -0.4531, -0.6772],\n",
            "        [-0.5594, -0.4115, -0.9380,  ..., -0.9176,  0.1904,  0.6354],\n",
            "        [-0.1210, -0.8416, -0.7367,  ..., -0.8702,  0.3275,  0.1622]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4920,  1.0000,  0.8997,  ...,  0.8927, -0.2831, -0.7262],\n",
            "        [ 0.6491,  1.0000,  0.8506,  ...,  0.9433, -0.7538, -0.6296],\n",
            "        [-0.6032, -0.5558, -0.9327,  ..., -0.8866,  0.4612,  0.5456],\n",
            "        ...,\n",
            "        [-0.5240, -0.9601, -0.9289,  ..., -0.9093, -0.0186,  0.3552],\n",
            "        [-0.4537, -0.9137, -0.9325,  ..., -0.8823,  0.0614,  0.4359],\n",
            "        [ 0.7007,  1.0000,  0.8515,  ...,  0.6715, -0.4257, -0.7379]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5800,  1.0000,  0.9567,  ...,  0.9044, -0.5977, -0.7328],\n",
            "        [-0.2202, -0.0471, -0.8868,  ..., -0.8413,  0.2655,  0.4752],\n",
            "        [-0.4721, -0.9934, -0.8810,  ..., -0.9121, -0.0010,  0.5637],\n",
            "        ...,\n",
            "        [ 0.4105,  0.9999,  0.8297,  ...,  0.7662, -0.8147, -0.3097],\n",
            "        [ 0.4499,  1.0000,  0.8801,  ...,  0.6739, -0.4950, -0.7615],\n",
            "        [ 0.6903,  0.9999,  0.8621,  ...,  0.8691, -0.7406, -0.5677]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6886,  0.9998,  0.8562,  ...,  0.8954, -0.6771, -0.3875],\n",
            "        [ 0.5364,  1.0000,  0.8841,  ...,  0.7615, -0.4850, -0.6984],\n",
            "        [-0.6967, -0.9263, -0.8847,  ..., -0.9167,  0.4129,  0.3115],\n",
            "        ...,\n",
            "        [-0.2243,  0.9760, -0.8953,  ..., -0.8867,  0.2763,  0.1253],\n",
            "        [ 0.6199,  1.0000,  0.8858,  ...,  0.8666, -0.6048, -0.4031],\n",
            "        [ 0.6317,  1.0000,  0.9279,  ...,  0.8594, -0.3483, -0.8071]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6771,  0.6994, -0.9392,  ..., -0.9364,  0.1201,  0.4110],\n",
            "        [ 0.7965,  1.0000,  0.7891,  ...,  0.7940, -0.6477, -0.6597],\n",
            "        [-0.7035, -0.9399, -0.9448,  ..., -0.8833, -0.3506,  0.7831],\n",
            "        ...,\n",
            "        [ 0.7817,  1.0000,  0.9559,  ...,  0.6869, -0.3621, -0.9135],\n",
            "        [ 0.6074,  1.0000,  0.8115,  ...,  0.8539, -0.6677, -0.7358],\n",
            "        [ 0.7340,  0.9999,  0.8558,  ...,  0.8716, -0.7882, -0.5276]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0287, -0.8264, -0.6897,  ..., -0.8503,  0.1366, -0.5636],\n",
            "        [ 0.5223,  1.0000,  0.7346,  ...,  0.6903, -0.5978, -0.8864],\n",
            "        [-0.7704, -0.9221, -0.9093,  ..., -0.8587,  0.5382,  0.4461],\n",
            "        ...,\n",
            "        [ 0.6738,  1.0000,  0.9231,  ...,  0.8932, -0.4893, -0.6836],\n",
            "        [ 0.3151,  0.9999,  0.9004,  ...,  0.5650, -0.1663, -0.7731],\n",
            "        [-0.6520, -0.9082, -0.9558,  ..., -0.9062,  0.3278,  0.3740]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6265,  0.9999,  0.9438,  ...,  0.8403, -0.6476, -0.5917],\n",
            "        [ 0.4782,  1.0000,  0.9460,  ...,  0.3751,  0.4339, -0.9374],\n",
            "        [-0.7423,  0.9991, -0.8680,  ..., -0.9392,  0.1002,  0.0281],\n",
            "        ...,\n",
            "        [-0.6625, -0.9836, -0.9230,  ..., -0.8413,  0.0097,  0.6664],\n",
            "        [ 0.7157,  1.0000,  0.8839,  ...,  0.8407, -0.8465, -0.2360],\n",
            "        [-0.5984,  0.2810, -0.9053,  ..., -0.8620,  0.1956,  0.3125]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7841,  0.9999,  0.8927,  ...,  0.8738, -0.6743, -0.5191],\n",
            "        [ 0.7163,  0.9999,  0.8955,  ...,  0.8433, -0.5490, -0.4859],\n",
            "        [ 0.6283,  1.0000,  0.8948,  ...,  0.6434, -0.6670, -0.7819],\n",
            "        ...,\n",
            "        [-0.4775, -0.8788, -0.9054,  ..., -0.8632,  0.3982,  0.2949],\n",
            "        [-0.4412, -0.6844, -0.9187,  ..., -0.8538,  0.2838,  0.3739],\n",
            "        [ 0.7403,  1.0000,  0.8739,  ...,  0.7717, -0.6558, -0.6885]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1546,  0.9986, -0.9364,  ..., -0.8344,  0.5628, -0.5514],\n",
            "        [-0.6489,  0.8256, -0.8683,  ..., -0.9180,  0.1542,  0.6586],\n",
            "        [-0.2092,  1.0000, -0.5846,  ..., -0.8129,  0.6947, -0.3419],\n",
            "        ...,\n",
            "        [-0.4419, -0.9780, -0.9450,  ..., -0.9474,  0.0465,  0.5626],\n",
            "        [ 0.6001,  0.9999,  0.8153,  ...,  0.8337, -0.7887, -0.5225],\n",
            "        [-0.6205,  0.9212, -0.8331,  ..., -0.7844,  0.4248,  0.6383]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7434,  1.0000,  0.8768,  ...,  0.8882, -0.7966, -0.4991],\n",
            "        [ 0.6484,  1.0000,  0.8311,  ...,  0.8869, -0.6873, -0.6160],\n",
            "        [-0.4466,  0.4938, -0.8982,  ..., -0.8890,  0.0147,  0.5778],\n",
            "        ...,\n",
            "        [ 0.6204,  1.0000,  0.9262,  ...,  0.8648, -0.6023, -0.5667],\n",
            "        [ 0.6889,  1.0000,  0.9300,  ...,  0.7885, -0.7676, -0.4705],\n",
            "        [ 0.7155,  1.0000,  0.8573,  ...,  0.8760, -0.7450, -0.5887]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.8298,  1.0000,  0.9245,  ...,  0.8499, -0.4909, -0.6603],\n",
            "        [-0.1683,  0.9989, -0.6880,  ..., -0.8497,  0.4594, -0.7433],\n",
            "        [ 0.6887,  0.9999,  0.8383,  ...,  0.8552, -0.6007, -0.3508],\n",
            "        ...,\n",
            "        [ 0.5400,  1.0000,  0.9433,  ...,  0.5698, -0.0157, -0.8840],\n",
            "        [ 0.6087,  1.0000,  0.9333,  ..., -0.1547, -0.1804, -0.9004],\n",
            "        [-0.6341, -0.7314, -0.9098,  ..., -0.8390,  0.2563,  0.4563]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5858, -0.7631, -0.9533,  ..., -0.8310, -0.2638,  0.7101],\n",
            "        [ 0.6374,  1.0000,  0.8433,  ...,  0.7667, -0.7053, -0.4874],\n",
            "        [ 0.6488,  1.0000,  0.9060,  ...,  0.7353, -0.6059, -0.7916],\n",
            "        ...,\n",
            "        [ 0.4245,  0.9994,  0.7969,  ...,  0.8205, -0.7942, -0.1919],\n",
            "        [ 0.5008,  1.0000,  0.9659,  ...,  0.4936,  0.2320, -0.9153],\n",
            "        [ 0.4327,  0.9996,  0.9303,  ...,  0.7889, -0.6629, -0.6092]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3817, -0.8344, -0.5521,  ..., -0.7371,  0.3680, -0.5489],\n",
            "        [-0.4226,  0.3995, -0.9495,  ..., -0.9488,  0.2319,  0.5708],\n",
            "        [-0.4142, -0.9945, -0.9651,  ..., -0.8966,  0.0154,  0.5502],\n",
            "        ...,\n",
            "        [-0.3953,  0.9867, -0.7889,  ..., -0.7944,  0.5804,  0.2696],\n",
            "        [-0.7259, -0.8741, -0.9170,  ..., -0.9367,  0.4609,  0.6988],\n",
            "        [-0.2579, -0.7282, -0.9317,  ..., -0.8718,  0.4044,  0.5806]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6775,  0.9994,  0.9276,  ...,  0.8312, -0.6045, -0.5426],\n",
            "        [-0.3573,  0.4397, -0.9194,  ..., -0.9156,  0.1666,  0.5730],\n",
            "        [-0.3258, -0.9581, -0.8558,  ..., -0.8815,  0.5557,  0.5262],\n",
            "        ...,\n",
            "        [ 0.1232,  0.9930,  0.3493,  ..., -0.4380,  0.5185, -0.8572],\n",
            "        [-0.6097,  0.4574, -0.8731,  ..., -0.8546,  0.2601,  0.3362],\n",
            "        [ 0.4646,  1.0000,  0.8841,  ...,  0.6021,  0.5207, -0.8742]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4096,  0.9709, -0.9248,  ..., -0.9215,  0.0590, -0.0653],\n",
            "        [ 0.6066,  1.0000,  0.9116,  ...,  0.8714, -0.6225, -0.7648],\n",
            "        [ 0.3665,  0.9998,  0.8872,  ...,  0.8210, -0.6910, -0.2807],\n",
            "        ...,\n",
            "        [-0.6757, -0.5671, -0.8986,  ..., -0.8687, -0.0493,  0.5478],\n",
            "        [-0.6087, -0.9522, -0.9031,  ..., -0.9183,  0.1395,  0.5420],\n",
            "        [-0.4387, -0.7460, -0.9347,  ..., -0.9097,  0.1858,  0.3345]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7364,  1.0000,  0.9635,  ...,  0.7888, -0.0713, -0.8752],\n",
            "        [ 0.4530,  0.9992,  0.9105,  ...,  0.8537, -0.7287, -0.3586],\n",
            "        [ 0.5222,  1.0000,  0.8750,  ...,  0.8324, -0.7444, -0.5986],\n",
            "        ...,\n",
            "        [-0.5517,  0.9928, -0.5213,  ..., -0.7647, -0.0488,  0.5170],\n",
            "        [ 0.5767,  1.0000,  0.9271,  ...,  0.7971, -0.7126, -0.6781],\n",
            "        [ 0.7730,  0.9997,  0.9048,  ...,  0.9135, -0.7568, -0.5278]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4657,  0.9343, -0.8895,  ..., -0.8151,  0.4971,  0.4219],\n",
            "        [ 0.6178,  0.9999,  0.8708,  ...,  0.8946, -0.7933, -0.3289],\n",
            "        [-0.7804,  0.3684, -0.8943,  ..., -0.9369,  0.4343,  0.4593],\n",
            "        ...,\n",
            "        [ 0.6059,  0.9998,  0.8600,  ...,  0.7639, -0.8155, -0.4490],\n",
            "        [ 0.7721,  0.9999,  0.8350,  ...,  0.8118, -0.8180, -0.7512],\n",
            "        [-0.5299, -0.9768, -0.9154,  ..., -0.8164,  0.0446,  0.6392]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5899,  1.0000,  0.8999,  ...,  0.8974, -0.6655, -0.5023],\n",
            "        [ 0.7202,  1.0000,  0.8434,  ...,  0.8060, -0.6248, -0.5336],\n",
            "        [-0.5756, -0.6012, -0.8806,  ..., -0.8806, -0.2556,  0.6337],\n",
            "        ...,\n",
            "        [-0.6128, -0.6103, -0.8016,  ..., -0.8366,  0.0786,  0.0731],\n",
            "        [ 0.6782,  1.0000,  0.9428,  ...,  0.8209, -0.5362, -0.7682],\n",
            "        [-0.7956, -0.8648, -0.9252,  ..., -0.8938,  0.0405,  0.5633]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.7656, -0.6246, -0.8928,  ..., -0.8966,  0.3020,  0.3479],\n",
            "        [-0.5306, -0.9861, -0.9380,  ..., -0.9201,  0.1148,  0.6312],\n",
            "        [-0.7316,  0.7614, -0.9545,  ..., -0.9215,  0.2460,  0.6829],\n",
            "        ...,\n",
            "        [ 0.7727,  1.0000,  0.9503,  ...,  0.8142, -0.4874, -0.8405],\n",
            "        [ 0.4800,  0.9999,  0.7108,  ...,  0.7637, -0.7062, -0.1295],\n",
            "        [ 0.7728,  1.0000,  0.9296,  ...,  0.8142, -0.4421, -0.7447]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.7244,  0.8650, -0.9332,  ..., -0.9078,  0.1888,  0.7165],\n",
            "        [-0.6440,  0.9904, -0.9196,  ..., -0.8329, -0.0705,  0.5859],\n",
            "        [ 0.7066,  1.0000,  0.9300,  ...,  0.1947,  0.5299, -0.9686],\n",
            "        ...,\n",
            "        [ 0.6776,  0.9999,  0.8440,  ...,  0.8418, -0.6992, -0.5990],\n",
            "        [-0.4572,  0.0332, -0.9395,  ..., -0.8625,  0.2080,  0.2615],\n",
            "        [ 0.7755,  1.0000,  0.8793,  ...,  0.8558, -0.5883, -0.6510]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6589,  1.0000,  0.8590,  ...,  0.8755, -0.7673, -0.6565],\n",
            "        [ 0.5419,  0.9997,  0.8691,  ...,  0.8074, -0.6753, -0.2180],\n",
            "        [ 0.4976,  1.0000,  0.9378,  ...,  0.8363, -0.5062, -0.6687],\n",
            "        ...,\n",
            "        [-0.4829,  0.7172, -0.6183,  ..., -0.8686,  0.3721,  0.3931],\n",
            "        [ 0.5940,  0.9999,  0.8833,  ...,  0.8327, -0.8082, -0.4819],\n",
            "        [-0.3923, -0.9107, -0.9325,  ..., -0.9081,  0.0721,  0.2928]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7468,  1.0000,  0.9549,  ...,  0.8754, -0.2184, -0.8798],\n",
            "        [ 0.3603,  1.0000,  0.7896,  ...,  0.1692, -0.3751, -0.7179],\n",
            "        [ 0.7064,  1.0000,  0.9567,  ...,  0.6967, -0.3141, -0.7872],\n",
            "        ...,\n",
            "        [ 0.6617,  1.0000,  0.8732,  ...,  0.9326, -0.5178, -0.7187],\n",
            "        [-0.6009, -0.5256, -0.9375,  ..., -0.8870,  0.1526,  0.6853],\n",
            "        [ 0.5442,  1.0000,  0.6771,  ...,  0.5103,  0.7279, -0.7615]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2140,  0.9040, -0.8159,  ..., -0.6966,  0.4620, -0.1741],\n",
            "        [-0.4736,  0.7840, -0.8878,  ..., -0.8943,  0.2247,  0.5977],\n",
            "        [-0.5634, -0.2031, -0.9119,  ..., -0.9189,  0.3131,  0.4831],\n",
            "        ...,\n",
            "        [ 0.8117,  0.9999,  0.9360,  ...,  0.9120, -0.8051, -0.4789],\n",
            "        [ 0.5807,  0.9999,  0.8834,  ...,  0.8262, -0.8661, -0.4508],\n",
            "        [ 0.7125,  0.9999,  0.8769,  ...,  0.8534, -0.7595, -0.5221]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4278, -0.9462, -0.9216,  ..., -0.8790, -0.2879,  0.4261],\n",
            "        [ 0.6932,  1.0000,  0.9076,  ...,  0.7625, -0.3992, -0.7452],\n",
            "        [-0.6438, -0.1357, -0.9311,  ..., -0.8668,  0.3403,  0.5461],\n",
            "        ...,\n",
            "        [-0.0988,  0.9999,  0.3950,  ..., -0.6697,  0.2432, -0.8762],\n",
            "        [-0.3944, -0.9578, -0.8122,  ..., -0.7098,  0.2496,  0.6784],\n",
            "        [ 0.7079,  0.9999,  0.8889,  ...,  0.9106, -0.6539, -0.4253]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5282,  0.9999,  0.8993,  ...,  0.6632, -0.3976, -0.8076],\n",
            "        [ 0.6358,  0.9999,  0.9244,  ...,  0.8900, -0.5909, -0.4630],\n",
            "        [ 0.5517,  1.0000,  0.8946,  ...,  0.7993, -0.4791, -0.7522],\n",
            "        ...,\n",
            "        [-0.4107,  0.2548, -0.8906,  ..., -0.9048,  0.4137,  0.3759],\n",
            "        [ 0.6641,  1.0000,  0.8747,  ...,  0.8951, -0.6764, -0.5611],\n",
            "        [ 0.6408,  0.9993,  0.8815,  ...,  0.8742, -0.6751, -0.5785]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5134, -0.5985, -0.9327,  ..., -0.8472,  0.0880,  0.5530],\n",
            "        [-0.2975, -0.9051, -0.9000,  ..., -0.9047,  0.0490,  0.4583],\n",
            "        [ 0.2200,  0.9993, -0.8194,  ..., -0.8226,  0.4678, -0.6449],\n",
            "        ...,\n",
            "        [-0.5841, -0.8791, -0.9551,  ..., -0.8625,  0.2134,  0.5305],\n",
            "        [ 0.6577,  0.9999,  0.8402,  ...,  0.8409, -0.6554, -0.4191],\n",
            "        [-0.3276, -0.9992, -0.9101,  ..., -0.8980,  0.2048,  0.4710]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5640,  1.0000,  0.0622,  ..., -0.8297,  0.5908, -0.8790],\n",
            "        [ 0.5118,  1.0000,  0.9319,  ...,  0.8342, -0.6117, -0.5273],\n",
            "        [-0.5286, -0.9825, -0.9625,  ..., -0.8857,  0.0382,  0.4460],\n",
            "        ...,\n",
            "        [ 0.7270,  1.0000,  0.9448,  ...,  0.8372, -0.2328, -0.8289],\n",
            "        [-0.8317,  0.5121, -0.9179,  ..., -0.7814, -0.0092,  0.6913],\n",
            "        [ 0.7067,  1.0000,  0.9145,  ...,  0.8307, -0.5350, -0.6404]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6404,  1.0000,  0.8508,  ...,  0.0827, -0.1092, -0.9527],\n",
            "        [-0.0766,  0.9998,  0.4223,  ..., -0.5476,  0.3946, -0.8379],\n",
            "        [-0.5743, -0.9841, -0.9144,  ..., -0.9086,  0.0569,  0.4086],\n",
            "        ...,\n",
            "        [ 0.5119,  0.9999,  0.9174,  ...,  0.9203, -0.7570, -0.4772],\n",
            "        [-0.3707, -0.3400, -0.9604,  ..., -0.8416, -0.1153,  0.2872],\n",
            "        [ 0.5931,  0.9999,  0.7505,  ...,  0.8159, -0.3142, -0.6517]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6428,  1.0000,  0.7250,  ...,  0.7059, -0.5845, -0.1836],\n",
            "        [ 0.6649,  0.9999,  0.8814,  ...,  0.8656, -0.8397, -0.4796],\n",
            "        [-0.4951, -0.9206, -0.9446,  ..., -0.9107,  0.0242,  0.7680],\n",
            "        ...,\n",
            "        [ 0.4227,  1.0000,  0.8418,  ...,  0.4435,  0.3924, -0.8169],\n",
            "        [ 0.7548,  0.9999,  0.8756,  ...,  0.9228, -0.7165, -0.6771],\n",
            "        [-0.6875,  0.3152, -0.9085,  ..., -0.8789,  0.3573,  0.5053]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4748,  0.9115, -0.9398,  ..., -0.8528,  0.1197,  0.5242],\n",
            "        [ 0.6815,  1.0000,  0.8931,  ...,  0.8309, -0.6909, -0.7497],\n",
            "        [ 0.4356,  1.0000,  0.8254,  ...,  0.1504,  0.5014, -0.9191],\n",
            "        ...,\n",
            "        [ 0.5245,  1.0000,  0.9149,  ...,  0.6981, -0.7638, -0.9070],\n",
            "        [ 0.7488,  1.0000,  0.8035,  ...,  0.8197, -0.7466, -0.8264],\n",
            "        [-0.5876,  0.9220, -0.9168,  ..., -0.9476,  0.0438,  0.5502]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5066, -0.9998, -0.9454,  ..., -0.8760,  0.1806,  0.6129],\n",
            "        [-0.4403, -0.9842, -0.9555,  ..., -0.9214,  0.5363,  0.5362],\n",
            "        [-0.5364, -0.4387, -0.9288,  ..., -0.9294, -0.1565,  0.4786],\n",
            "        ...,\n",
            "        [-0.7951,  0.9930, -0.7728,  ..., -0.9018,  0.2207,  0.1103],\n",
            "        [-0.5847, -0.5570, -0.7482,  ..., -0.9477,  0.2786,  0.3803],\n",
            "        [-0.6337, -0.9580, -0.9333,  ..., -0.8796,  0.5279,  0.6332]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4759, -0.9999, -0.9460,  ..., -0.8848,  0.1781,  0.5853],\n",
            "        [-0.6840, -0.8698, -0.9240,  ..., -0.8991,  0.2926,  0.0315],\n",
            "        [-0.6982, -0.9136, -0.9541,  ..., -0.9091,  0.0536,  0.6939],\n",
            "        ...,\n",
            "        [ 0.7159,  1.0000,  0.9232,  ...,  0.3280,  0.2562, -0.9800],\n",
            "        [-0.6355, -0.9755, -0.9537,  ..., -0.9330, -0.0338,  0.6467],\n",
            "        [ 0.5073,  1.0000,  0.9170,  ...,  0.4882,  0.5086, -0.9704]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6052, -0.9729, -0.9639,  ..., -0.8856, -0.0285,  0.4930],\n",
            "        [ 0.8128,  1.0000,  0.9303,  ...,  0.8702, -0.6331, -0.6707],\n",
            "        [-0.4431, -0.8675, -0.8852,  ..., -0.8226,  0.3495,  0.5163],\n",
            "        ...,\n",
            "        [-0.7716,  0.1954, -0.8887,  ..., -0.9219,  0.3715,  0.3075],\n",
            "        [ 0.3982,  0.9999,  0.8882,  ...,  0.8483, -0.7478, -0.6854],\n",
            "        [-0.5795, -0.7765, -0.8074,  ..., -0.8567,  0.1303,  0.5383]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4692,  0.8910, -0.7964,  ..., -0.9328,  0.2280,  0.5705],\n",
            "        [ 0.6278,  1.0000,  0.8379,  ...,  0.7023, -0.6590, -0.6834],\n",
            "        [ 0.7139,  1.0000,  0.8498,  ...,  0.9338, -0.7286, -0.5778],\n",
            "        ...,\n",
            "        [-0.6978,  0.3841, -0.9176,  ..., -0.9046,  0.4124,  0.6219],\n",
            "        [-0.7354, -0.9934, -0.9279,  ..., -0.9259, -0.2976,  0.7756],\n",
            "        [ 0.6054,  0.9995,  0.8875,  ...,  0.9250, -0.7420, -0.3509]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3363,  0.4532, -0.9127,  ..., -0.9090,  0.4479,  0.0776],\n",
            "        [-0.5372, -0.9999, -0.9265,  ..., -0.9290,  0.1122,  0.5890],\n",
            "        [ 0.7833,  1.0000,  0.3446,  ..., -0.6144,  0.7140, -0.9719],\n",
            "        ...,\n",
            "        [-0.3704,  1.0000, -0.1379,  ..., -0.6880,  0.0930, -0.5035],\n",
            "        [ 0.1447,  0.9999,  0.6246,  ...,  0.7120, -0.3501, -0.6071],\n",
            "        [ 0.6939,  0.9996,  0.8084,  ...,  0.8764, -0.7674, -0.3819]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7067,  0.9999,  0.8504,  ...,  0.8432, -0.7414, -0.3374],\n",
            "        [ 0.2184,  1.0000, -0.2677,  ..., -0.5599,  0.7302, -0.7527],\n",
            "        [-0.5275,  0.3443, -0.8984,  ..., -0.8876,  0.4253,  0.6074],\n",
            "        ...,\n",
            "        [-0.6897, -0.8454, -0.9266,  ..., -0.8893, -0.0715,  0.7083],\n",
            "        [-0.2830,  0.9990, -0.7879,  ..., -0.6497,  0.6519,  0.4569],\n",
            "        [ 0.7437,  1.0000,  0.8917,  ...,  0.9003, -0.7983, -0.5571]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6663,  0.9998,  0.8449,  ...,  0.7862, -0.8155, -0.2065],\n",
            "        [ 0.6738,  0.9999,  0.8785,  ...,  0.8559, -0.5924, -0.6741],\n",
            "        [ 0.7323,  1.0000,  0.9480,  ...,  0.7919, -0.4816, -0.8054],\n",
            "        ...,\n",
            "        [ 0.5926,  1.0000,  0.8990,  ...,  0.6988,  0.4058, -0.9582],\n",
            "        [ 0.6145,  0.9998,  0.9123,  ...,  0.8905, -0.7161, -0.5133],\n",
            "        [-0.7700,  0.9533, -0.8280,  ..., -0.7702,  0.4311,  0.6749]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4087,  0.9924, -0.9297,  ..., -0.9218,  0.2285,  0.4482],\n",
            "        [ 0.5619,  1.0000,  0.9486,  ...,  0.5500,  0.1168, -0.9452],\n",
            "        [ 0.6272,  1.0000,  0.8079,  ..., -0.0489, -0.4465, -0.8399],\n",
            "        ...,\n",
            "        [ 0.5581,  0.9996,  0.9196,  ...,  0.7842, -0.5560, -0.0406],\n",
            "        [ 0.7264,  1.0000,  0.9441,  ...,  0.8637, -0.4603, -0.7722],\n",
            "        [-0.3571, -0.7097, -0.8673,  ..., -0.8818, -0.0403,  0.6018]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5598,  1.0000,  0.8007,  ..., -0.2893,  0.3210, -0.9391],\n",
            "        [ 0.7368,  0.9996,  0.8751,  ...,  0.6447, -0.5667, -0.6576],\n",
            "        [-0.5382, -0.9810, -0.9468,  ..., -0.8939,  0.3088,  0.4889],\n",
            "        ...,\n",
            "        [-0.4093,  0.9607, -0.8995,  ..., -0.8801,  0.1769,  0.4377],\n",
            "        [ 0.4459,  0.9999,  0.9302,  ...,  0.8530, -0.7049, -0.5507],\n",
            "        [ 0.6093,  0.9999,  0.9311,  ...,  0.8475, -0.7177, -0.7267]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-3.1108e-04,  9.9179e-01, -8.5142e-01,  ..., -8.9393e-01,\n",
            "          5.9748e-01, -3.9398e-01],\n",
            "        [-6.2477e-01,  9.3147e-01, -8.8830e-01,  ..., -8.3551e-01,\n",
            "          2.8515e-01,  5.3397e-01],\n",
            "        [ 5.2904e-01,  9.9999e-01,  8.4352e-01,  ...,  5.1282e-01,\n",
            "         -1.3918e-02, -8.6646e-01],\n",
            "        ...,\n",
            "        [ 3.2102e-01,  9.9993e-01,  9.0678e-01,  ...,  7.1804e-01,\n",
            "         -6.6435e-01, -4.9929e-01],\n",
            "        [-6.8239e-01, -9.3395e-01, -9.2381e-01,  ..., -9.2741e-01,\n",
            "          1.1062e-01,  4.6808e-01],\n",
            "        [-2.7980e-01,  4.9388e-01, -8.6179e-01,  ..., -8.5409e-01,\n",
            "          2.6776e-01,  1.7965e-01]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3679, -0.9959, -0.9578,  ..., -0.8812,  0.0766,  0.3539],\n",
            "        [ 0.7396,  1.0000,  0.9199,  ...,  0.8801, -0.5704, -0.7069],\n",
            "        [-0.5811,  0.7200, -0.9600,  ..., -0.8821, -0.1079,  0.5431],\n",
            "        ...,\n",
            "        [ 0.5975,  0.9999,  0.9019,  ...,  0.8952, -0.7444, -0.5855],\n",
            "        [-0.3973, -0.8753, -0.9051,  ..., -0.8787,  0.2593,  0.4587],\n",
            "        [ 0.7585,  1.0000,  0.9011,  ...,  0.9417, -0.6387, -0.6585]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7125,  1.0000,  0.8506,  ...,  0.8803, -0.6247, -0.5720],\n",
            "        [ 0.4950,  0.9999,  0.9359,  ...,  0.9223, -0.6245, -0.5169],\n",
            "        [-0.6855, -0.8589, -0.9558,  ..., -0.9263,  0.1867,  0.7662],\n",
            "        ...,\n",
            "        [-0.7444, -0.9269, -0.7800,  ..., -0.8767, -0.1235,  0.4626],\n",
            "        [-0.6540,  0.2891, -0.9069,  ..., -0.7920,  0.1023,  0.6132],\n",
            "        [-0.2377, -0.8653, -0.9315,  ..., -0.8847,  0.4085,  0.4280]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5824, -0.9721, -0.9283,  ..., -0.8400,  0.5193,  0.6767],\n",
            "        [ 0.8136,  0.9995,  0.8388,  ...,  0.7898, -0.5224, -0.4758],\n",
            "        [ 0.6462,  0.9998,  0.8602,  ...,  0.9069, -0.7502, -0.2767],\n",
            "        ...,\n",
            "        [ 0.4689,  0.9999,  0.8377,  ...,  0.9184, -0.6931, -0.5695],\n",
            "        [ 0.4602,  0.9988,  0.9011,  ...,  0.8435, -0.8206, -0.5376],\n",
            "        [-0.6153,  0.4313, -0.9224,  ..., -0.8679,  0.0873,  0.4452]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7703,  0.9999,  0.8835,  ...,  0.8356, -0.7820, -0.3999],\n",
            "        [ 0.6118,  1.0000,  0.8446,  ...,  0.7140, -0.4605, -0.7148],\n",
            "        [ 0.5520,  1.0000,  0.9684,  ...,  0.6467,  0.0504, -0.9547],\n",
            "        ...,\n",
            "        [ 0.6198,  1.0000,  0.8655,  ...,  0.8335, -0.7763, -0.5250],\n",
            "        [ 0.2228,  0.9257, -0.9207,  ..., -0.7654,  0.4748, -0.1836],\n",
            "        [ 0.7296,  0.9999,  0.9240,  ...,  0.9138, -0.7552, -0.3688]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4677,  0.9660, -0.9113,  ..., -0.8951,  0.4828,  0.6773],\n",
            "        [ 0.5946,  0.9999,  0.8823,  ...,  0.9093, -0.6857, -0.4531],\n",
            "        [ 0.4735,  1.0000,  0.9501,  ...,  0.3985,  0.0559, -0.9431],\n",
            "        ...,\n",
            "        [-0.4933,  0.9236, -0.8896,  ..., -0.8988,  0.1313,  0.4797],\n",
            "        [-0.4333, -0.9718, -0.9631,  ..., -0.8708,  0.0847,  0.6494],\n",
            "        [-0.4978, -0.7793, -0.9321,  ..., -0.9247, -0.0986,  0.6306]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6190,  0.7082, -0.5694,  ..., -0.7170,  0.5019,  0.3172],\n",
            "        [-0.3236, -0.9945, -0.9505,  ..., -0.9009,  0.0105,  0.5616],\n",
            "        [ 0.6619,  0.9994,  0.7678,  ...,  0.8220, -0.6927, -0.6620],\n",
            "        ...,\n",
            "        [-0.4516, -0.8299, -0.9041,  ..., -0.8375,  0.2099,  0.6745],\n",
            "        [-0.5192,  0.9424, -0.9377,  ..., -0.8469,  0.2362,  0.6760],\n",
            "        [ 0.7777,  1.0000,  0.8871,  ...,  0.7996, -0.6222, -0.7771]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.7456,  0.6191, -0.8534,  ..., -0.7976,  0.2587,  0.5700],\n",
            "        [-0.6556, -0.9577, -0.8679,  ..., -0.9149, -0.0073,  0.5014],\n",
            "        [ 0.5973,  1.0000,  0.8445,  ...,  0.8255, -0.6718, -0.2917],\n",
            "        ...,\n",
            "        [-0.3338,  0.8258, -0.8404,  ..., -0.8748,  0.2103,  0.6548],\n",
            "        [ 0.7531,  1.0000,  0.9218,  ...,  0.8839, -0.7984, -0.5619],\n",
            "        [-0.2762,  0.9722, -0.8091,  ..., -0.7946,  0.4398, -0.2021]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5668, -0.9527, -0.8962,  ..., -0.8630,  0.3420,  0.6612],\n",
            "        [ 0.0101,  0.9992, -0.5452,  ..., -0.8844,  0.7817, -0.2989],\n",
            "        [ 0.3406,  0.9881, -0.7127,  ..., -0.8499,  0.4028, -0.4312],\n",
            "        ...,\n",
            "        [ 0.5755,  1.0000,  0.7652,  ...,  0.9210, -0.6695, -0.5450],\n",
            "        [ 0.1765,  0.8619, -0.9418,  ..., -0.6686,  0.7069,  0.2806],\n",
            "        [-0.5029, -0.8743, -0.9215,  ..., -0.8603,  0.2020,  0.5817]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6326, -0.4420, -0.5746,  ..., -0.8614,  0.2337,  0.1047],\n",
            "        [ 0.6938,  0.9991,  0.8789,  ...,  0.8703, -0.7513, -0.4539],\n",
            "        [ 0.5945,  1.0000,  0.9714,  ...,  0.8059, -0.1966, -0.8194],\n",
            "        ...,\n",
            "        [-0.4944,  0.6645, -0.9429,  ..., -0.9361,  0.2714,  0.4960],\n",
            "        [ 0.4981,  0.9995,  0.8804,  ...,  0.8952, -0.5366, -0.1580],\n",
            "        [-0.0640, -0.7538, -0.9290,  ..., -0.8400,  0.1693,  0.3338]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3998,  1.0000,  0.7676,  ..., -0.6862,  0.8327, -0.9168],\n",
            "        [ 0.7091,  1.0000,  0.7773,  ...,  0.8448, -0.5482, -0.5796],\n",
            "        [ 0.7648,  1.0000,  0.8229,  ...,  0.8577, -0.5437, -0.8098],\n",
            "        ...,\n",
            "        [ 0.6550,  1.0000,  0.9214,  ...,  0.8457, -0.5670, -0.6448],\n",
            "        [-0.4833,  0.9434, -0.9092,  ..., -0.8548,  0.0534,  0.6075],\n",
            "        [-0.4398,  0.9690, -0.9438,  ..., -0.8772,  0.0269,  0.4751]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7850,  1.0000,  0.8630,  ...,  0.7957, -0.6187, -0.5497],\n",
            "        [ 0.6409,  1.0000,  0.9691,  ...,  0.8652, -0.2456, -0.5948],\n",
            "        [ 0.6636,  1.0000,  0.9476,  ...,  0.8522,  0.0814, -0.9512],\n",
            "        ...,\n",
            "        [ 0.6801,  0.9998,  0.9246,  ...,  0.7579, -0.7218, -0.5225],\n",
            "        [ 0.6961,  0.9998,  0.6853,  ...,  0.8628, -0.7062, -0.3364],\n",
            "        [ 0.5267,  1.0000,  0.7314,  ...,  0.6838, -0.3605, -0.5796]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5786, -0.2989, -0.9434,  ..., -0.9264,  0.4354,  0.4155],\n",
            "        [ 0.5420,  0.9999,  0.8526,  ...,  0.9055, -0.6225, -0.2839],\n",
            "        [ 0.7037,  0.9999,  0.9613,  ...,  0.8753, -0.4537, -0.5812],\n",
            "        ...,\n",
            "        [ 0.5503,  0.9999,  0.7953,  ...,  0.7311, -0.7601,  0.1855],\n",
            "        [ 0.7513,  1.0000,  0.9360,  ...,  0.8658,  0.2286, -0.9354],\n",
            "        [ 0.4988,  0.9999,  0.9054,  ...,  0.9201, -0.5376, -0.5758]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7280,  1.0000,  0.9560,  ...,  0.5428,  0.5041, -0.9814],\n",
            "        [ 0.6566,  0.9997,  0.9172,  ...,  0.9092, -0.7443, -0.4785],\n",
            "        [-0.5033, -0.6793, -0.9324,  ..., -0.9462,  0.2124,  0.4479],\n",
            "        ...,\n",
            "        [-0.4667,  0.9592, -0.8847,  ..., -0.9246,  0.1884,  0.5933],\n",
            "        [-0.5190, -0.9979, -0.9505,  ..., -0.8777,  0.2265,  0.4942],\n",
            "        [-0.7191, -0.9908, -0.9346,  ..., -0.8769, -0.1632,  0.6222]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5532, -0.9952, -0.9670,  ..., -0.8888, -0.0125,  0.7172],\n",
            "        [ 0.6086,  1.0000,  0.8632,  ...,  0.6316, -0.4540, -0.7448],\n",
            "        [ 0.4159,  0.9976,  0.8206,  ...,  0.8521, -0.8510, -0.0733],\n",
            "        ...,\n",
            "        [-0.3619, -1.0000, -0.9275,  ..., -0.8728,  0.1065,  0.7461],\n",
            "        [-0.6855,  0.9945, -0.8138,  ..., -0.8097,  0.3976,  0.6761],\n",
            "        [-0.4020, -0.5303, -0.9455,  ..., -0.9286,  0.2328,  0.6495]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6880,  0.9998,  0.8922,  ...,  0.9032, -0.8306, -0.5218],\n",
            "        [ 0.8595,  1.0000,  0.5528,  ..., -0.3929,  0.5688, -0.9523],\n",
            "        [-0.2898,  0.8335, -0.9388,  ..., -0.9006,  0.1726,  0.2360],\n",
            "        ...,\n",
            "        [ 0.6971,  0.9999,  0.8354,  ...,  0.8480, -0.5094, -0.7092],\n",
            "        [-0.5220,  0.8960, -0.6551,  ..., -0.8208,  0.2441, -0.1908],\n",
            "        [-0.3949,  0.9996, -0.8486,  ..., -0.8717,  0.4097, -0.1330]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4205, -0.9701, -0.9358,  ..., -0.7685,  0.1372,  0.6968],\n",
            "        [ 0.5089,  0.9999,  0.9125,  ...,  0.8411, -0.5324, -0.5674],\n",
            "        [ 0.5537,  0.9999,  0.9136,  ...,  0.8831, -0.6120, -0.6411],\n",
            "        ...,\n",
            "        [ 0.8032,  1.0000,  0.9421,  ...,  0.6249, -0.4396, -0.9390],\n",
            "        [-0.5877, -0.4894, -0.8523,  ..., -0.8782,  0.2568,  0.0651],\n",
            "        [-0.4269, -0.2706, -0.9348,  ..., -0.9098, -0.2833,  0.8110]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5072, -0.9989, -0.8063,  ..., -0.8635, -0.0303,  0.3791],\n",
            "        [ 0.5863,  0.9981,  0.8021,  ...,  0.7508, -0.8195, -0.2692],\n",
            "        [ 0.5377,  0.9998,  0.8174,  ...,  0.9107, -0.7239, -0.2145],\n",
            "        ...,\n",
            "        [ 0.5447,  0.9988,  0.8407,  ...,  0.7252, -0.7843, -0.3181],\n",
            "        [ 0.6773,  0.9993,  0.7763,  ...,  0.9077, -0.7751, -0.2557],\n",
            "        [ 0.3253,  1.0000,  0.8824,  ...,  0.3599, -0.5840, -0.7434]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2458,  0.9348, -0.8592,  ..., -0.7479,  0.6228,  0.4416],\n",
            "        [-0.4113,  0.4224, -0.8944,  ..., -0.8005,  0.5801,  0.1051],\n",
            "        [ 0.5942,  0.9999,  0.9018,  ...,  0.8311, -0.7856, -0.5116],\n",
            "        ...,\n",
            "        [-0.0176,  0.9971, -0.6130,  ..., -0.8932,  0.3957,  0.2049],\n",
            "        [-0.2534,  0.4372, -0.9380,  ..., -0.8698,  0.5938,  0.2754],\n",
            "        [-0.2713,  0.5044, -0.8669,  ..., -0.8664,  0.3368,  0.2828]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3693,  0.9709, -0.9213,  ..., -0.9153,  0.4661,  0.2785],\n",
            "        [ 0.7715,  1.0000,  0.5831,  ..., -0.0015, -0.1651, -0.9101],\n",
            "        [ 0.7523,  1.0000,  0.4640,  ..., -0.3143, -0.4025, -0.5008],\n",
            "        ...,\n",
            "        [-0.7774,  0.9994, -0.7594,  ..., -0.6756,  0.1613,  0.6507],\n",
            "        [-0.0696,  0.9893, -0.8720,  ..., -0.8775,  0.1426,  0.0303],\n",
            "        [ 0.6309,  0.9998,  0.8524,  ...,  0.8967, -0.8238, -0.5974]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1525,  1.0000,  0.9121,  ...,  0.2636,  0.3137, -0.9147],\n",
            "        [-0.3991,  0.9999, -0.7212,  ..., -0.7525,  0.7185,  0.0195],\n",
            "        [-0.3630, -0.9908, -0.8770,  ..., -0.6561,  0.0226,  0.2779],\n",
            "        ...,\n",
            "        [-0.7296,  0.7627, -0.9393,  ..., -0.8169, -0.0648,  0.5985],\n",
            "        [ 0.7223,  0.9990,  0.8019,  ...,  0.9194, -0.8567, -0.5020],\n",
            "        [ 0.4873,  0.9953,  0.8200,  ...,  0.8033, -0.7083, -0.2522]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.7427, -0.9968, -0.9477,  ..., -0.9386,  0.0164,  0.6935],\n",
            "        [-0.6186,  0.9861, -0.7336,  ..., -0.9161,  0.3891,  0.0956],\n",
            "        [-0.5167, -0.8973, -0.9277,  ..., -0.9200,  0.3520,  0.6337],\n",
            "        ...,\n",
            "        [-0.7258, -0.5889, -0.9096,  ..., -0.8978,  0.2089,  0.4175],\n",
            "        [ 0.4464,  1.0000,  0.6887,  ..., -0.4049,  0.0184, -0.8558],\n",
            "        [-0.8152, -0.0511, -0.9056,  ..., -0.8857,  0.2006,  0.6546]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5096,  0.9999,  0.8678,  ...,  0.8829, -0.7183, -0.3154],\n",
            "        [ 0.7466,  1.0000,  0.8535,  ...,  0.8517, -0.8578, -0.6393],\n",
            "        [-0.2361,  0.9999, -0.7816,  ..., -0.9222,  0.6557, -0.2187],\n",
            "        ...,\n",
            "        [-0.6989, -0.9265, -0.9487,  ..., -0.9269,  0.1736,  0.3040],\n",
            "        [ 0.6535,  1.0000,  0.6992,  ...,  0.7773, -0.5323, -0.8127],\n",
            "        [ 0.6731,  0.9991,  0.7110,  ...,  0.8976, -0.8235, -0.2184]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5142,  0.6659, -0.9053,  ..., -0.8613,  0.0693,  0.0506],\n",
            "        [-0.4683,  0.6204, -0.9129,  ..., -0.8717,  0.2302,  0.2341],\n",
            "        [-0.5876, -0.9920, -0.9313,  ..., -0.9347,  0.0982,  0.5589],\n",
            "        ...,\n",
            "        [ 0.4235,  0.9998,  0.8855,  ...,  0.8527, -0.8076, -0.5352],\n",
            "        [-0.4072,  0.6607, -0.8579,  ..., -0.8936,  0.2427,  0.3979],\n",
            "        [-0.5067,  0.5422, -0.9349,  ..., -0.8616,  0.2405,  0.2517]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-5.9277e-01, -7.9537e-01, -9.3536e-01,  1.4922e-01,  2.9872e-01,\n",
            "         -8.9335e-01, -3.9670e-01, -7.3165e-01,  9.2385e-01,  6.7753e-01,\n",
            "         -8.0773e-01,  9.1434e-01, -5.2594e-01, -8.9654e-01, -3.2044e-02,\n",
            "          9.1100e-01, -6.5164e-01,  5.3898e-01,  2.6754e-01,  3.3743e-01,\n",
            "          2.2587e-01,  8.8572e-01,  3.0057e-01, -1.2332e-01, -7.4410e-01,\n",
            "         -8.1538e-01,  3.7223e-01,  2.5439e-01, -2.8182e-01, -5.8027e-01,\n",
            "          6.9930e-03,  6.9169e-01,  6.5329e-01,  4.5982e-01,  2.8240e-01,\n",
            "          4.5175e-01,  6.1503e-01,  7.4504e-01,  1.8390e-01,  4.9233e-01,\n",
            "          3.3090e-01,  4.9317e-01, -8.0083e-01, -7.2159e-01, -9.1473e-01,\n",
            "         -4.5294e-01,  1.0944e-01, -4.0467e-01,  4.2162e-01,  1.5208e-01,\n",
            "          4.4113e-01, -9.9478e-01,  3.2663e-01, -9.7086e-01, -2.3269e-01,\n",
            "         -9.0619e-01, -2.7142e-01,  4.9731e-01,  5.6600e-02,  7.5730e-01,\n",
            "         -1.7394e-01, -4.2385e-01,  9.1787e-01,  5.8938e-01,  9.3080e-01,\n",
            "          1.5221e-01,  4.2926e-01, -4.1105e-01,  8.5030e-01, -6.4695e-01,\n",
            "         -9.1043e-01,  4.1387e-01, -3.6019e-01, -5.3319e-01,  5.9509e-01,\n",
            "         -3.1225e-01,  6.2508e-01,  1.6608e-01, -2.7485e-01, -8.0179e-01,\n",
            "         -8.6707e-01,  3.6403e-01,  7.9662e-01,  6.1686e-01, -6.3917e-01,\n",
            "         -4.7370e-01, -3.1581e-01,  4.7428e-01,  7.0863e-01, -4.1056e-02,\n",
            "          7.3498e-02, -8.7276e-01, -7.9442e-01,  4.8853e-01,  2.3056e-01,\n",
            "         -5.7683e-01,  2.2531e-01, -7.9622e-01,  8.4129e-01,  4.0188e-01,\n",
            "          6.6629e-01,  5.1830e-01,  6.4435e-01,  2.4741e-01,  6.0438e-01,\n",
            "         -9.0014e-01,  4.2651e-01, -5.5987e-01,  9.1015e-01,  9.3883e-02,\n",
            "         -6.4900e-01,  1.9794e-01,  4.6836e-01, -7.3740e-01, -5.6883e-01,\n",
            "         -3.6887e-01, -8.6883e-01, -9.0159e-01,  9.1030e-01,  4.2484e-01,\n",
            "          3.0864e-01, -6.4085e-01,  4.7848e-01, -5.1000e-01, -4.2766e-01,\n",
            "         -4.6209e-01, -6.4122e-01,  9.5997e-01,  1.4787e-01,  4.3204e-01,\n",
            "         -1.6563e-01, -8.8306e-01, -7.6829e-01, -7.0191e-01,  5.2914e-01,\n",
            "         -4.3812e-01, -7.4665e-01,  3.8055e-01,  4.7205e-01,  7.3084e-01,\n",
            "          2.0108e-01,  2.2940e-01, -7.6642e-01, -1.8925e-01, -1.4438e-02,\n",
            "          3.4071e-01,  1.1713e-01,  5.4402e-01,  4.9676e-02, -7.4594e-01,\n",
            "          6.0771e-01, -5.1809e-01, -6.4122e-01,  2.9876e-01,  4.6370e-01,\n",
            "          5.8116e-01,  5.1979e-01,  5.4297e-01,  9.9087e-01, -8.6113e-01,\n",
            "          7.7782e-01,  9.7706e-01,  5.0706e-01,  5.2467e-01,  9.9699e-01,\n",
            "         -6.1866e-01,  1.1397e-01,  6.3718e-01,  8.2190e-01, -3.6785e-01,\n",
            "          2.7181e-01,  6.5364e-01,  5.3551e-01,  6.8570e-01,  9.9867e-01,\n",
            "         -3.8761e-01, -8.2885e-01,  1.7581e-01,  9.3361e-01,  8.8096e-01,\n",
            "         -7.0854e-01, -3.0596e-01, -9.6585e-01, -6.9795e-01,  8.5927e-01,\n",
            "         -6.4396e-01, -5.4226e-01,  9.4251e-01, -9.6267e-01,  5.8989e-01,\n",
            "         -5.1154e-01, -8.2993e-01, -4.0829e-01,  8.7382e-01,  1.6395e-01,\n",
            "         -2.4152e-01, -1.7667e-01,  5.1332e-01,  5.1844e-01,  1.2388e-01,\n",
            "          7.8745e-01,  8.5427e-01,  7.7196e-01, -9.5741e-01, -8.7146e-01,\n",
            "         -7.1222e-01,  1.1145e-02, -4.6159e-01,  4.0925e-01,  5.4067e-01,\n",
            "          5.4375e-01,  5.7580e-01,  3.2734e-01, -7.1016e-01,  2.9918e-02,\n",
            "          4.1017e-01,  8.1748e-01, -9.6331e-01,  5.5494e-01,  7.3084e-01,\n",
            "         -7.6116e-01, -8.2277e-01,  1.7597e-01, -7.5253e-01,  5.0141e-03,\n",
            "         -8.0844e-01, -1.5185e-01,  1.4573e-01, -6.6581e-01,  8.5942e-01,\n",
            "          1.1416e-01,  6.1592e-01,  3.6984e-01,  7.0143e-01,  9.0023e-01,\n",
            "          5.1977e-01, -7.6027e-01,  1.1165e-01,  9.6568e-01, -4.7426e-01,\n",
            "          7.9604e-01, -6.6098e-01,  8.5209e-01,  2.7197e-01, -9.8272e-01,\n",
            "          8.2487e-01, -9.5781e-01, -8.2107e-01,  3.6300e-02,  7.5190e-01,\n",
            "         -3.0714e-01, -2.9170e-01,  5.2988e-01,  6.5170e-01,  7.1451e-01,\n",
            "          5.3825e-01,  6.9766e-01, -5.8330e-01, -3.2573e-01,  2.1013e-01,\n",
            "         -1.3651e-01,  6.9316e-02, -9.5305e-01, -9.0019e-01, -6.7989e-01,\n",
            "         -3.5623e-01, -7.5364e-01,  7.3641e-03,  4.5389e-01,  2.0264e-01,\n",
            "          3.1246e-01,  9.4973e-01, -8.3283e-01, -2.3401e-01,  5.6772e-01,\n",
            "         -6.3172e-01, -5.6042e-01,  1.7806e-01, -9.0186e-01,  6.7148e-01,\n",
            "         -9.5890e-01,  9.9172e-01,  7.3730e-01,  4.3865e-01,  9.9510e-02,\n",
            "          1.4690e-01,  1.9528e-01,  9.8955e-01, -5.2045e-01,  6.0655e-01,\n",
            "          2.1411e-01,  7.2228e-01,  9.0288e-01,  2.1607e-01, -8.9280e-01,\n",
            "         -8.5190e-01,  7.3889e-01, -9.3580e-01,  2.0407e-01, -4.3150e-01,\n",
            "          2.7933e-01,  7.9129e-01,  7.7494e-01,  5.9750e-01,  2.2969e-01,\n",
            "          7.0120e-01, -9.8851e-01,  6.4451e-01, -6.6933e-01, -2.6404e-02,\n",
            "          4.1132e-01, -7.5602e-01, -7.9704e-01,  3.5321e-01, -3.2786e-01,\n",
            "         -7.5083e-01, -9.7360e-02,  9.2721e-01,  2.6731e-01,  1.5856e-01,\n",
            "          1.2186e-01,  1.8460e-01, -1.4189e-01, -5.7697e-01, -9.7584e-01,\n",
            "          1.3570e-01,  9.8107e-01, -7.8172e-01, -9.4322e-01,  5.3091e-01,\n",
            "         -2.1350e-01,  8.0005e-01, -3.6638e-01, -7.5426e-01,  5.3248e-01,\n",
            "         -2.2721e-01, -1.1782e-01,  9.7367e-01, -8.4652e-01,  6.0152e-01,\n",
            "          7.5416e-01,  3.5524e-01,  8.2404e-01,  6.7026e-01,  1.1475e-01,\n",
            "         -8.8012e-01,  6.7642e-01, -4.7674e-01,  8.4063e-01, -4.9427e-01,\n",
            "         -5.1475e-01, -4.1503e-02, -8.5041e-01, -9.4896e-01,  7.3546e-01,\n",
            "         -4.7045e-01,  6.4533e-01,  9.5875e-01, -7.4115e-01,  5.9387e-01,\n",
            "         -7.4749e-01,  1.3953e-01,  7.2185e-01, -4.9365e-01,  9.7907e-01,\n",
            "         -6.3460e-01,  3.0898e-01,  1.1543e-01, -9.8400e-01,  8.6612e-01,\n",
            "         -5.7212e-01,  7.4758e-01, -4.9652e-01,  9.1293e-01, -6.8879e-01,\n",
            "         -8.6064e-01, -8.8064e-01,  3.5137e-01,  8.1004e-01,  3.8241e-01,\n",
            "         -3.8515e-01,  3.0320e-01,  4.6455e-01,  3.7384e-01, -9.3043e-01,\n",
            "          3.0689e-01,  6.2511e-01, -8.5460e-01,  7.9153e-01,  2.8048e-01,\n",
            "          3.1963e-01,  3.1022e-01,  6.8242e-02, -9.2348e-01,  4.2715e-01,\n",
            "          8.8760e-01, -3.0714e-01, -3.6468e-01, -3.3840e-01, -5.6148e-01,\n",
            "         -3.4550e-01,  2.1532e-01, -9.1895e-01,  5.5081e-01,  5.7050e-01,\n",
            "         -7.0113e-01, -1.1609e-01, -8.9391e-02,  4.7373e-01, -8.8073e-01,\n",
            "          5.4556e-01,  7.2842e-01,  7.5718e-01,  2.9562e-01, -9.2359e-01,\n",
            "          2.6680e-01, -8.6445e-01, -2.9169e-01, -6.0884e-01, -2.7069e-01,\n",
            "          1.7908e-01, -2.0643e-01, -8.1670e-01, -9.4814e-01,  8.5880e-01,\n",
            "         -4.5014e-01,  8.6762e-01, -7.5702e-01, -6.2031e-01, -6.3195e-01,\n",
            "         -2.0178e-01,  3.1513e-01,  7.2149e-01, -2.6134e-01,  3.6077e-01,\n",
            "         -5.0786e-01,  1.8150e-01,  7.5195e-01,  6.9802e-01,  4.6253e-01,\n",
            "          4.8246e-01,  8.5930e-01,  7.6142e-01, -2.8771e-01,  5.0880e-01,\n",
            "          6.7831e-02, -7.6662e-01, -8.7928e-01,  3.0830e-01,  6.7285e-01,\n",
            "         -6.4655e-02,  8.5232e-01, -6.8362e-01,  7.9548e-02,  6.7982e-01,\n",
            "          3.3653e-01, -3.4263e-01, -1.5848e-01,  9.4763e-01,  2.0086e-01,\n",
            "         -3.8566e-01,  8.5200e-01, -6.3731e-01,  9.4259e-01,  2.4749e-01,\n",
            "         -1.3333e-01,  7.7772e-01,  7.6011e-01, -7.9375e-01, -8.1248e-04,\n",
            "          6.8254e-01,  4.2484e-01,  5.9125e-01, -9.8836e-01, -7.7680e-01,\n",
            "         -1.3036e-01,  1.2081e-02, -8.5756e-01, -4.4330e-01, -9.9873e-01,\n",
            "          8.3701e-01,  6.9984e-01, -8.7396e-01,  6.7179e-01,  7.0044e-02,\n",
            "         -9.7795e-02,  4.3114e-01,  5.5686e-01,  8.8540e-01, -9.1649e-01,\n",
            "         -3.2087e-01, -3.9356e-01,  5.8791e-02,  7.9965e-01,  7.1352e-01,\n",
            "          5.8753e-02, -8.6600e-01, -2.6282e-01,  7.8008e-01,  1.9098e-01,\n",
            "         -5.3723e-01, -7.9151e-01, -2.1669e-01,  5.5725e-01, -7.0302e-01,\n",
            "         -9.3920e-01, -6.3393e-01,  9.9734e-01,  1.8634e-01, -4.7814e-01,\n",
            "          6.4673e-01,  3.3575e-01, -1.0978e-01,  7.7377e-01, -1.9286e-01,\n",
            "          3.7837e-01,  8.0986e-01, -8.6114e-01, -4.7612e-01, -5.0897e-01,\n",
            "          6.0180e-01, -3.6425e-01,  3.1519e-01, -4.5520e-01, -7.8174e-01,\n",
            "         -9.3779e-01, -3.1480e-01,  1.7460e-01, -3.6842e-01,  1.1051e-01,\n",
            "          4.2356e-01,  4.9349e-01,  7.5998e-01, -6.3182e-01, -6.6289e-01,\n",
            "         -9.8846e-01, -4.3495e-01, -4.7484e-01, -4.8250e-01, -6.2055e-01,\n",
            "         -8.6039e-01,  5.1553e-01, -7.1093e-01,  8.7357e-02,  7.5508e-01,\n",
            "          7.0599e-01, -3.5336e-01, -4.2482e-01, -6.3779e-01,  6.2366e-01,\n",
            "          2.4265e-01, -3.1092e-02, -6.5728e-01,  6.9172e-01, -7.3738e-01,\n",
            "         -6.4140e-01, -8.2106e-01, -4.8231e-01, -6.7361e-02,  3.3329e-01,\n",
            "          2.8962e-01,  3.3285e-01,  2.2682e-01, -9.5013e-01,  4.0602e-01,\n",
            "         -4.3081e-01, -2.1321e-01, -5.2348e-01, -7.8794e-01, -9.1644e-01,\n",
            "          8.3325e-01,  9.7121e-01, -5.0795e-01, -8.8904e-01, -1.3546e-01,\n",
            "          5.7096e-01,  4.3437e-01, -6.0019e-01,  7.8923e-01,  9.0674e-01,\n",
            "          7.5468e-01,  6.2877e-01,  5.3349e-01, -4.6999e-01, -8.1153e-01,\n",
            "         -5.6299e-01, -5.1257e-01,  2.6949e-01, -6.2495e-01,  5.6320e-01,\n",
            "          5.3655e-02,  1.7388e-01,  5.1297e-01, -4.7309e-01,  9.4450e-01,\n",
            "          2.9727e-01, -4.3056e-01,  7.5366e-01, -6.2599e-01, -8.1943e-01,\n",
            "          4.2104e-01, -7.6556e-01,  8.8627e-01, -2.5850e-01, -8.7259e-01,\n",
            "          1.4601e-01, -2.0463e-01,  9.3196e-02,  2.5086e-01, -1.7789e-01,\n",
            "          6.5993e-01,  4.4397e-01,  1.7532e-01, -4.2490e-02,  3.9943e-01,\n",
            "          5.3930e-01,  4.6482e-01,  8.8085e-01,  2.3848e-01,  7.5799e-01,\n",
            "         -4.7246e-01,  6.3908e-01,  1.2626e-01,  5.1564e-01,  1.4914e-01,\n",
            "         -6.4412e-01,  3.2700e-02, -9.8733e-01,  5.8044e-01, -2.5262e-01,\n",
            "          4.7738e-01,  8.3384e-01, -5.1839e-01, -4.3836e-01, -5.6128e-01,\n",
            "         -8.2864e-01, -4.6066e-01, -6.7741e-01,  9.7524e-01, -2.5663e-01,\n",
            "         -9.2193e-01,  7.9375e-01,  6.8238e-01,  2.2885e-01,  5.7770e-01,\n",
            "         -8.2318e-01, -2.3566e-01, -4.4343e-01,  9.5819e-01,  5.5629e-01,\n",
            "         -1.9189e-01, -7.8566e-01, -5.5787e-02, -9.1408e-01, -5.8183e-01,\n",
            "          3.0692e-01, -2.4599e-01,  6.2857e-01, -7.1481e-01, -8.7544e-01,\n",
            "          9.2412e-02, -6.9231e-01,  3.6685e-01, -5.1266e-01,  4.3387e-01,\n",
            "          9.3595e-01, -7.2918e-01, -7.7823e-01,  8.8024e-01,  7.4912e-01,\n",
            "         -9.4321e-01,  9.4233e-01, -6.0663e-01, -3.4486e-01,  7.6431e-01,\n",
            "          3.8695e-01, -3.7981e-01,  3.6845e-01, -5.9111e-02,  2.3822e-01,\n",
            "         -1.1435e-02, -5.1915e-01,  9.4722e-01,  2.8984e-01, -2.9206e-01,\n",
            "          6.7717e-01, -2.0436e-01,  4.8024e-01,  3.0258e-01, -6.6775e-01,\n",
            "          5.1135e-01, -9.1304e-01, -5.6271e-01, -3.5859e-01, -4.5053e-01,\n",
            "          7.8481e-01,  9.8768e-01, -6.7019e-01,  3.7454e-01,  4.2312e-01,\n",
            "         -1.7825e-01,  7.7963e-01, -4.1179e-01,  3.8247e-01,  6.6324e-01,\n",
            "          6.9115e-02,  2.5175e-01, -3.6062e-01, -6.6243e-01,  2.6944e-01,\n",
            "          8.7282e-01, -9.6731e-01, -8.3284e-01,  5.1471e-01,  3.6014e-01,\n",
            "         -4.2347e-01, -5.9346e-01,  2.8207e-01,  3.9586e-01, -5.4620e-01,\n",
            "         -4.2240e-01,  5.7759e-01,  3.6955e-01,  9.1679e-01, -8.6434e-01,\n",
            "         -2.5065e-01,  4.2968e-01, -2.9947e-01,  7.3319e-01, -4.1854e-01,\n",
            "          9.8112e-01, -8.0720e-01,  4.8611e-01,  7.7993e-01, -6.3391e-01,\n",
            "         -8.8791e-01, -4.7558e-01,  4.7080e-01,  4.3645e-01, -2.8928e-01,\n",
            "         -8.1201e-01,  7.9132e-01, -8.7136e-01,  4.1390e-01,  1.5949e-01,\n",
            "          1.6704e-01,  3.9364e-01, -3.5927e-01,  2.9873e-01,  2.2269e-01,\n",
            "         -7.5325e-01,  8.6275e-01,  6.9239e-01, -2.0698e-01,  8.0434e-01,\n",
            "         -7.1457e-01,  5.9655e-01, -1.0048e-01, -5.3624e-01,  8.8908e-01,\n",
            "          6.2020e-01,  1.6523e-01, -6.2572e-01, -2.3514e-02,  5.5247e-01,\n",
            "         -8.8752e-01,  2.9997e-01,  5.7388e-01]], device='cuda:0',\n",
            "       grad_fn=<TanhBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluation... :   0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1b622bcbf364de69c9096d57f84dda8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7285,  0.9977,  0.8906,  ...,  0.8699, -0.7901, -0.4029],\n",
            "        [ 0.7440,  1.0000,  0.9566,  ...,  0.8238, -0.1099, -0.9306],\n",
            "        [ 0.8730,  1.0000,  0.5688,  ..., -0.4313,  0.6438, -0.9091],\n",
            "        ...,\n",
            "        [ 0.3713,  0.9998,  0.8018,  ...,  0.7944, -0.7781, -0.2543],\n",
            "        [-0.0739,  0.9696, -0.7419,  ..., -0.8791,  0.5438, -0.1392],\n",
            "        [-0.6764,  0.0041, -0.9110,  ..., -0.7564,  0.2908,  0.5679]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3809,  0.9997, -0.8276,  ..., -0.8893,  0.4923, -0.0364],\n",
            "        [ 0.7118,  1.0000,  0.7495,  ...,  0.4433, -0.7486, -0.4210],\n",
            "        [ 0.3090,  0.9999,  0.3749,  ..., -0.6390,  0.5709, -0.9198],\n",
            "        ...,\n",
            "        [-0.1676,  0.9981, -0.1747,  ..., -0.7044,  0.2387, -0.7704],\n",
            "        [-0.5773,  0.9999, -0.5088,  ..., -0.8635,  0.3327,  0.0366],\n",
            "        [ 0.4875,  1.0000,  0.7097,  ..., -0.6482,  0.6434, -0.9696]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5979,  1.0000,  0.9337,  ...,  0.8638, -0.6720, -0.5670],\n",
            "        [ 0.3168,  1.0000,  0.7996,  ...,  0.4383,  0.6554, -0.8330],\n",
            "        [ 0.5594,  1.0000,  0.8641,  ...,  0.8488, -0.6774, -0.6243],\n",
            "        ...,\n",
            "        [-0.1893,  1.0000,  0.1403,  ..., -0.8762,  0.5938, -0.8667],\n",
            "        [-0.7517,  0.0609, -0.8922,  ..., -0.9225,  0.2617,  0.3860],\n",
            "        [ 0.4931,  1.0000,  0.5254,  ..., -0.2029,  0.3702, -0.9638]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1208,  0.9996,  0.1144,  ..., -0.1464, -0.6090, -0.7321],\n",
            "        [-0.0077,  1.0000,  0.7772,  ..., -0.4948,  0.2989, -0.9614],\n",
            "        [ 0.0106,  0.9999, -0.3682,  ..., -0.8086,  0.3256, -0.8849],\n",
            "        ...,\n",
            "        [ 0.7103,  0.9999,  0.8925,  ...,  0.8781, -0.6612, -0.4867],\n",
            "        [-0.0949,  0.1787, -0.7951,  ..., -0.9087,  0.6572, -0.3124],\n",
            "        [ 0.6390,  0.9994,  0.8843,  ...,  0.8961, -0.8432, -0.3426]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6799,  1.0000,  0.7591,  ...,  0.7164, -0.4410, -0.3685],\n",
            "        [ 0.4242,  1.0000,  0.8398,  ...,  0.8579, -0.4634, -0.5437],\n",
            "        [-0.4524,  0.7837, -0.8611,  ..., -0.7466,  0.3671,  0.3637],\n",
            "        ...,\n",
            "        [ 0.5262,  1.0000,  0.5652,  ...,  0.6840, -0.4267, -0.8514],\n",
            "        [ 0.4998,  1.0000,  0.8727,  ...,  0.2288, -0.4558, -0.6938],\n",
            "        [ 0.7418,  0.9999,  0.9599,  ...,  0.5923, -0.3812, -0.7410]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5424,  0.9998,  0.8825,  ...,  0.8809, -0.7747, -0.4736],\n",
            "        [ 0.6785,  1.0000,  0.5508,  ...,  0.3118, -0.3647, -0.9011],\n",
            "        [-0.2824,  0.2214, -0.9625,  ..., -0.8796,  0.6040,  0.2717],\n",
            "        ...,\n",
            "        [ 0.8381,  1.0000, -0.1112,  ..., -0.5529,  0.7144, -0.8056],\n",
            "        [ 0.3409,  1.0000,  0.1815,  ...,  0.1728, -0.3534, -0.6902],\n",
            "        [-0.2368,  1.0000, -0.1444,  ..., -0.7929,  0.3508, -0.8565]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0431,  0.9839, -0.5934,  ..., -0.8061, -0.2210, -0.6035],\n",
            "        [-0.5377, -0.8094, -0.9461,  ..., -0.9343,  0.0558,  0.6898],\n",
            "        [ 0.6117,  0.9989,  0.8410,  ...,  0.8993, -0.7941, -0.3541],\n",
            "        ...,\n",
            "        [-0.2088,  1.0000, -0.2374,  ..., -0.7887, -0.3674, -0.5696],\n",
            "        [ 0.5871,  0.9992,  0.9076,  ...,  0.9077, -0.8451, -0.3316],\n",
            "        [-0.3676,  0.9733, -0.8117,  ..., -0.8225,  0.1261,  0.2726]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6478,  0.9999,  0.8889,  ...,  0.8825, -0.7674, -0.5132],\n",
            "        [ 0.6768,  0.9998,  0.9253,  ...,  0.9150, -0.7506, -0.5111],\n",
            "        [ 0.7091,  1.0000,  0.9439,  ...,  0.8187,  0.0146, -0.9164],\n",
            "        ...,\n",
            "        [ 0.5969,  0.9982,  0.8920,  ...,  0.8686, -0.8559, -0.2773],\n",
            "        [ 0.4388,  0.9998,  0.8015,  ...,  0.8159, -0.7320, -0.6529],\n",
            "        [ 0.5938,  1.0000,  0.7753,  ...,  0.5871, -0.4830, -0.6810]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7538,  1.0000,  0.9470,  ...,  0.8744, -0.5820, -0.7476],\n",
            "        [-0.1248,  0.9945, -0.8918,  ..., -0.8692,  0.3614, -0.0309],\n",
            "        [-0.8053, -0.8794, -0.8012,  ..., -0.8964,  0.0913,  0.1943],\n",
            "        ...,\n",
            "        [ 0.6680,  0.9999,  0.8865,  ...,  0.8592, -0.7119, -0.4423],\n",
            "        [-0.6522, -0.8266, -0.9249,  ..., -0.9032,  0.2072,  0.7615],\n",
            "        [ 0.5390,  0.9982,  0.8801,  ...,  0.8469, -0.8032, -0.2671]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4725, -0.4763, -0.9530,  ..., -0.8972,  0.1268,  0.4625],\n",
            "        [ 0.1473,  1.0000,  0.2828,  ..., -0.5839,  0.1747, -0.8631],\n",
            "        [ 0.5792,  0.9995,  0.8994,  ...,  0.8780, -0.8222, -0.4119],\n",
            "        ...,\n",
            "        [ 0.6954,  0.9994,  0.8227,  ...,  0.8856, -0.8299, -0.3526],\n",
            "        [ 0.5082,  0.9999,  0.8448,  ...,  0.7378, -0.6026, -0.1960],\n",
            "        [ 0.7077,  1.0000,  0.9313,  ...,  0.7260,  0.2479, -0.9603]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1288,  0.7622, -0.8863,  ..., -0.8652,  0.3518,  0.2328],\n",
            "        [-0.4807, -0.9425, -0.9094,  ..., -0.9390,  0.1475,  0.4494],\n",
            "        [-0.6735,  0.6485, -0.9655,  ..., -0.9471, -0.0755,  0.3593],\n",
            "        ...,\n",
            "        [ 0.6565,  1.0000,  0.8530,  ...,  0.6401, -0.5155, -0.8475],\n",
            "        [ 0.7410,  1.0000, -0.4494,  ..., -0.4918,  0.5275, -0.8535],\n",
            "        [ 0.4919,  0.9995,  0.9057,  ...,  0.8877, -0.8021, -0.2841]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0134,  1.0000,  0.5743,  ...,  0.0211,  0.5957, -0.8037],\n",
            "        [-0.4480, -0.8925, -0.9534,  ..., -0.9113,  0.2279,  0.5635],\n",
            "        [-0.6671,  0.9704, -0.9059,  ..., -0.9024,  0.2180, -0.0078],\n",
            "        ...,\n",
            "        [-0.5248,  0.9769, -0.9335,  ..., -0.9100,  0.3142,  0.4702],\n",
            "        [ 0.2168,  1.0000,  0.3187,  ..., -0.5128, -0.0916, -0.8217],\n",
            "        [-0.2054,  0.9999, -0.6824,  ..., -0.9124,  0.5587, -0.5146]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2667,  0.9987, -0.7180,  ..., -0.4036,  0.7274,  0.1225],\n",
            "        [ 0.3321,  1.0000,  0.6718,  ..., -0.0116, -0.0045, -0.8919],\n",
            "        [-0.6107, -0.9207, -0.8530,  ..., -0.9135,  0.4139,  0.3818],\n",
            "        ...,\n",
            "        [-0.7235,  0.9952, -0.9239,  ..., -0.7218,  0.6139,  0.2865],\n",
            "        [-0.1221,  0.9991, -0.9131,  ..., -0.8694,  0.4981, -0.2358],\n",
            "        [-0.5753,  1.0000, -0.6744,  ..., -0.7980,  0.4462, -0.7186]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7665,  1.0000,  0.9185,  ...,  0.5185, -0.4759, -0.7123],\n",
            "        [ 0.5717,  1.0000,  0.7775,  ...,  0.1268, -0.0937, -0.8708],\n",
            "        [-0.6432, -0.4756, -0.9327,  ..., -0.8517, -0.1446,  0.4962],\n",
            "        ...,\n",
            "        [ 0.4764,  1.0000,  0.5643,  ..., -0.1992, -0.4864, -0.7125],\n",
            "        [ 0.4125,  1.0000,  0.7654,  ...,  0.7504, -0.0792, -0.6754],\n",
            "        [-0.5738,  0.9973, -0.5514,  ..., -0.7586,  0.1344, -0.4776]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4690,  1.0000,  0.6377, -0.9657, -0.3489,  0.9218,  0.7241,  0.7649,\n",
            "         -0.9970, -0.6471,  0.7539, -0.4791,  0.4782,  0.9991,  0.3275,  0.1689,\n",
            "          0.7470, -0.9754,  0.7136, -0.3422,  0.3390, -0.7416,  0.8336, -0.4272,\n",
            "          0.8096,  0.6193, -0.4489,  0.6140, -0.2298,  0.2397, -0.6301, -0.3269,\n",
            "          0.9445,  0.6640,  0.8148, -0.9362, -0.3005, -0.9395, -0.9914, -0.9970,\n",
            "          0.2981, -0.4837,  0.9994, -0.8320,  0.9955, -0.9901,  0.4270, -0.3831,\n",
            "          0.6158,  0.4533, -0.7747,  0.8730,  0.8055,  0.7739, -0.5846, -0.8920,\n",
            "         -0.8524,  0.5556, -0.9067, -0.4642,  0.8218,  0.6971, -0.5483,  0.0034,\n",
            "         -0.8621, -0.3828,  0.6293,  0.4792, -0.6573, -0.9421,  0.8481, -0.9240,\n",
            "          0.7513,  0.1272, -0.2025,  0.8647, -0.8654,  0.8806, -0.7749,  0.9924,\n",
            "          0.5618,  0.4137,  0.7172, -0.9999,  0.6408, -0.9087,  0.9833, -0.9867,\n",
            "         -0.9621,  0.7131,  0.7564,  0.6511,  0.7415, -0.1858, -0.4065, -0.8584,\n",
            "         -0.6132,  0.5553, -0.9988,  0.7942,  0.7316,  0.8509, -0.6836, -0.6549,\n",
            "         -0.9991,  0.3317, -0.7219, -0.5289, -0.9999, -0.7189, -0.8229, -0.8056,\n",
            "         -0.1715,  0.8883,  0.5141,  0.9997,  0.8465,  0.9983, -0.9999, -0.9950,\n",
            "          0.1377,  0.9485, -0.6313, -0.1807,  0.5102, -0.9737,  0.5564, -0.9978,\n",
            "          0.8058, -0.9549, -0.5698,  0.7277,  0.8870,  0.3149, -0.6366,  0.6136,\n",
            "         -0.9996,  0.0877, -0.6599, -0.9914,  0.9938,  0.9054,  0.8118, -0.4014,\n",
            "         -0.3973,  0.8739,  0.8383, -0.6470,  0.0675, -0.3639, -0.8164,  0.8287,\n",
            "          0.3710, -0.5396, -1.0000,  0.5743, -0.6270,  0.9554, -0.9833,  0.9792,\n",
            "         -0.9543, -0.9999,  0.4093,  0.4350, -0.7415,  0.8192, -0.8483,  0.8724,\n",
            "         -0.6105,  0.7426,  0.7028,  0.7152,  0.3977, -0.3278,  0.5132, -0.7845,\n",
            "          0.7721, -0.7442, -0.5313, -0.9650,  0.9654, -0.5100,  0.9736, -0.9514,\n",
            "         -0.6485,  0.3561,  0.1017, -1.0000,  0.8835,  0.5394,  0.4480,  0.3450,\n",
            "          0.2575, -0.4084,  0.0572, -0.0181, -0.6028,  0.7924, -0.2267,  0.9169,\n",
            "          0.5134, -0.9993,  0.8187,  0.9933,  0.1760, -0.5541,  0.0375,  0.9823,\n",
            "         -0.9962, -0.7298,  0.2630, -0.5087,  0.5253,  0.3974, -0.5167, -0.7179,\n",
            "          0.7498,  0.2605,  0.0593, -0.3618,  0.1627,  0.5344, -0.3373,  0.4180,\n",
            "          0.8089,  0.9989, -0.4765, -0.5051,  0.5701, -0.9993,  0.8522,  0.5708,\n",
            "         -0.2737, -0.6932,  0.9913,  0.8371,  0.6513,  0.9883, -0.9357, -0.4062,\n",
            "         -0.5296,  0.8770, -0.2766,  0.0561,  0.9999, -0.9941,  0.9800,  0.9063,\n",
            "         -0.0089, -0.3501,  0.6200,  0.1525, -0.0911,  0.0944, -0.6179,  0.9933,\n",
            "         -0.6487, -0.9884,  0.4638, -0.0925, -0.9324, -0.8168,  0.7070, -0.6142,\n",
            "          0.9713,  0.9999,  0.6805,  0.4629,  0.7243,  0.5990,  0.8048, -0.9789,\n",
            "          0.9740,  1.0000, -0.9338,  0.3397,  0.9999,  0.6645, -0.3684, -0.4705,\n",
            "          0.2664, -0.9725, -0.0459, -0.4400, -0.3684, -0.4865, -0.0232, -0.9447,\n",
            "         -0.9993, -0.9864,  0.9773, -0.7282, -0.4976,  0.6177, -0.8164,  0.2679,\n",
            "         -0.5897,  0.9887, -0.7281,  0.9999,  0.6219, -0.5586, -0.9633, -0.2068,\n",
            "          0.5466,  0.2363,  0.9987,  0.2471, -0.7440,  0.8106,  0.6976,  0.2799,\n",
            "          0.8903, -0.5157,  0.6300,  0.2925,  0.0933, -0.9568, -0.3180, -0.8367,\n",
            "          0.8448,  0.9664,  0.7374, -0.0277,  0.9585,  0.8144, -1.0000,  0.9989,\n",
            "          0.9775, -0.9919,  0.8414, -0.0071,  0.8811, -0.2462,  0.5404, -0.8893,\n",
            "         -0.8325, -0.9707,  0.8043,  0.2889, -0.6607,  0.4790, -0.8895,  0.7886,\n",
            "          0.1227,  0.7463, -0.1918,  0.0120, -0.9958,  0.6850,  0.8894, -0.0788,\n",
            "          0.7105,  0.9841,  0.1212,  1.0000, -0.7529, -0.1322,  0.0676,  0.6505,\n",
            "          0.2448,  0.5743, -0.0561,  0.3871, -1.0000,  0.0970, -0.4507,  0.4084,\n",
            "          0.4738, -0.9816,  0.3522, -0.4966, -0.2046, -0.0310,  0.2607,  0.5533,\n",
            "          0.9986,  0.4451, -0.3979, -0.7204, -0.2131,  0.1000,  0.9233,  0.7871,\n",
            "          0.9928, -0.8304, -0.1441,  0.6772,  0.0027, -0.6531, -0.1010,  0.5794,\n",
            "          0.0719,  0.9187,  0.7713, -0.3757, -0.5913,  0.8264, -0.9983,  0.9999,\n",
            "          0.2522,  0.5073,  0.9511, -0.0953,  0.8239,  0.2703,  0.3649, -0.7537,\n",
            "          0.9744,  0.6739,  0.6161,  0.1547,  0.0429, -0.0705, -0.9302,  0.6353,\n",
            "          0.2267, -0.5306, -0.9848,  0.9878, -0.9857,  0.2233, -0.3775,  0.7660,\n",
            "          0.9672, -0.4304, -0.8231, -0.3478,  0.2083, -0.8144, -0.8526, -0.9936,\n",
            "         -0.0879, -0.9181,  0.9999, -0.9924,  0.5842, -0.9239, -0.8936,  0.7627,\n",
            "         -0.2495, -0.6312, -0.7929,  0.0106, -0.5152,  0.8266, -0.0826,  0.6989,\n",
            "         -0.3524,  0.3563,  0.7564,  0.2606,  0.3277,  0.8987, -0.6534, -0.9568,\n",
            "         -0.7395, -0.6264, -0.6553,  0.9598, -0.9402, -0.7595,  1.0000, -0.9818,\n",
            "          0.2977, -0.3040, -0.9960,  0.5532, -0.5424, -0.9475, -0.5884, -0.8016,\n",
            "          0.7239,  0.9275,  0.9992,  0.0878,  0.1518, -0.9737, -0.6340,  0.9964,\n",
            "         -0.9684, -0.2748,  0.1924, -0.9956,  0.9277,  0.3794, -0.5314,  0.8846,\n",
            "         -0.7093,  0.9623,  0.5918, -0.9964,  0.6871,  0.7680, -0.2437,  0.8704,\n",
            "          0.0556,  0.1672, -0.9527,  0.0652,  0.9994,  0.2682, -0.8505,  0.2941,\n",
            "          0.7840,  0.7501,  1.0000, -0.9478,  0.6314,  0.9996, -0.2991,  0.4546,\n",
            "          0.1969, -0.7521, -0.0319,  0.5633, -0.9800,  0.9998, -0.0882, -0.9878,\n",
            "         -0.9999,  0.3264, -0.7867,  0.7168,  0.9639,  0.4715,  0.8797,  0.2963,\n",
            "         -0.9984,  0.1390, -0.6510, -0.9997, -0.9992,  0.8194, -0.0576,  0.1817,\n",
            "          0.7906, -0.1056, -0.7895,  0.9996,  0.8650, -0.9999, -0.3855,  0.3386,\n",
            "          0.9551, -0.7491,  0.6838,  0.3295,  0.3058, -0.3955, -1.0000, -0.5974,\n",
            "          0.9749, -0.0488, -0.1189,  0.9993,  0.7253,  0.2942, -0.9569,  0.0660,\n",
            "          0.7655, -1.0000, -0.7355,  0.9997, -0.4301, -0.2919, -0.6694,  0.1255,\n",
            "          0.5718,  0.5754,  0.2408, -0.9969,  0.9949,  0.8534, -0.9167,  0.9979,\n",
            "         -0.4870, -0.7056, -0.7803, -0.5952,  0.7906, -0.7318,  0.6120, -0.4031,\n",
            "          0.9843,  0.9052, -0.4976,  0.8058,  0.8954, -0.7988, -0.4846,  0.8385,\n",
            "          0.6608,  0.3935,  0.9847, -0.3525, -0.7566, -0.3091,  0.6164,  0.9187,\n",
            "         -0.9999,  0.9195, -0.4406, -0.9071,  0.6061, -0.4999, -0.7696, -0.2211,\n",
            "         -0.4887, -0.6964,  0.3248,  0.9414,  0.7874,  0.8349, -0.9866, -0.9999,\n",
            "         -0.6225, -0.5252, -0.8343, -0.4640,  0.1361,  0.9584,  0.2886,  0.5503,\n",
            "          0.3939,  0.9998, -0.3872,  0.9881, -0.7584,  0.9401, -0.9870,  0.6735,\n",
            "          0.5517, -0.9747, -0.6639,  0.9443, -0.4913,  0.8433, -0.9683,  0.6899,\n",
            "          1.0000, -0.6994, -0.5047,  0.7066, -0.8752,  0.7801, -0.1002,  0.9951,\n",
            "         -0.9999,  0.9866,  0.0834,  0.4121,  0.6335,  0.5435,  0.5654, -0.6504,\n",
            "         -0.5788, -0.9893,  0.5107,  0.3439, -0.6216,  0.1706,  0.9456, -0.8269,\n",
            "         -0.9987, -0.5706,  0.4140,  0.9605, -0.3932, -0.9906,  0.9613, -0.1686,\n",
            "          0.9760, -0.0107, -0.6712, -0.5505, -0.2049, -0.5374,  0.5216,  0.7005,\n",
            "          0.7939,  0.3116, -0.8186, -0.4302, -0.0703, -0.7600,  0.7512, -0.1975,\n",
            "          0.0363,  0.6641,  0.8434,  0.9805,  0.3982,  0.0755,  0.7446, -0.7015,\n",
            "         -0.4327, -0.9997,  0.9990,  0.8678, -0.8383, -0.9997,  0.9415,  0.3777,\n",
            "         -0.2893,  0.7704, -0.1389, -0.7460,  0.0695,  0.7729, -1.0000, -0.5994,\n",
            "          0.1042, -0.4235, -0.5823, -0.9998, -0.5958,  0.2055, -0.2878,  0.1856,\n",
            "          0.9985, -0.4077, -0.9912, -0.9682, -0.2392,  0.6450,  0.2290, -0.9726,\n",
            "         -0.4717,  0.8703, -0.9979,  0.6243, -0.6130, -0.5261,  0.2046,  0.6645,\n",
            "          0.9179, -0.9999,  0.8851, -0.7512,  0.8782, -0.4379,  0.4747,  0.6426,\n",
            "          0.3946, -0.9984,  0.8624,  0.2750,  0.8645,  0.8026,  0.7489,  0.1371,\n",
            "         -0.8870, -0.7268,  0.9868,  0.9794, -0.6140,  0.7455,  0.9987, -0.5853,\n",
            "          0.5041,  0.5901, -0.1138, -0.9992, -0.8168, -0.3757, -0.5673, -0.8362]],\n",
            "       device='cuda:0')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training... :   0%|          | 0/127 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b701b766409f420f9e4ac66415582b78"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6535, -0.8173, -0.8803,  ..., -0.8442, -0.0167,  0.5881],\n",
            "        [ 0.6122,  1.0000,  0.9276,  ...,  0.8844, -0.0474, -0.8666],\n",
            "        [ 0.6945,  0.9988,  0.8805,  ...,  0.8619, -0.8043, -0.4048],\n",
            "        ...,\n",
            "        [-0.5533,  0.9980, -0.8852,  ..., -0.9308, -0.1406, -0.2682],\n",
            "        [ 0.8272,  1.0000,  0.3707,  ..., -0.3666,  0.6825, -0.8995],\n",
            "        [ 0.6830,  0.9991,  0.8358,  ...,  0.8746, -0.8192, -0.4052]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2743, -0.8631, -0.8904,  ..., -0.8771,  0.4934,  0.3005],\n",
            "        [ 0.6487,  1.0000,  0.9283,  ...,  0.7425, -0.6432, -0.6747],\n",
            "        [-0.3862,  0.9135, -0.8743,  ..., -0.9020,  0.4585,  0.4142],\n",
            "        ...,\n",
            "        [ 0.1084,  0.7311, -0.9094,  ..., -0.8698,  0.6045,  0.0505],\n",
            "        [ 0.8073,  0.9999,  0.8836,  ...,  0.8580, -0.7491, -0.5249],\n",
            "        [ 0.6134,  0.9999,  0.8424,  ...,  0.8421, -0.6265, -0.6433]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2675,  0.9962, -0.9319,  ..., -0.8417,  0.2782,  0.2513],\n",
            "        [ 0.4756,  1.0000,  0.9100,  ...,  0.8432, -0.5971, -0.6667],\n",
            "        [ 0.4992,  1.0000,  0.9655,  ...,  0.8870, -0.7253, -0.6189],\n",
            "        ...,\n",
            "        [ 0.5016,  0.9993,  0.9365,  ...,  0.8859, -0.7375, -0.2898],\n",
            "        [ 0.5933,  0.9986,  0.8931,  ...,  0.9161, -0.8397, -0.2743],\n",
            "        [ 0.5378,  0.9906,  0.7881,  ...,  0.8407, -0.8601, -0.4108]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5282,  0.9990,  0.8069,  ...,  0.8810, -0.8554, -0.5865],\n",
            "        [ 0.7986,  1.0000,  0.9426,  ...,  0.8757, -0.2651, -0.7473],\n",
            "        [ 0.7465,  0.9998,  0.7018,  ...,  0.6611, -0.4948, -0.4924],\n",
            "        ...,\n",
            "        [ 0.2014,  0.9937, -0.9007,  ..., -0.8833,  0.4387, -0.2838],\n",
            "        [ 0.6592,  0.9998,  0.7578,  ...,  0.7813, -0.7877, -0.5490],\n",
            "        [-0.3884, -0.9895, -0.9467,  ..., -0.9379,  0.0196,  0.1464]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3990, -0.5948, -0.9393,  ..., -0.8742,  0.2156,  0.5696],\n",
            "        [ 0.6778,  1.0000,  0.9691,  ...,  0.8679, -0.1372, -0.8929],\n",
            "        [-0.5389,  0.0969, -0.9463,  ..., -0.8751,  0.3452,  0.3249],\n",
            "        ...,\n",
            "        [ 0.4426,  0.9987,  0.8993,  ...,  0.7090, -0.4844, -0.8055],\n",
            "        [ 0.6162,  0.9998,  0.8510,  ...,  0.8319, -0.7400, -0.1674],\n",
            "        [ 0.4806,  1.0000,  0.9473,  ...,  0.8071, -0.2886, -0.5321]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5374,  0.9972,  0.9138,  ...,  0.7360, -0.7054, -0.3698],\n",
            "        [ 0.1765,  0.9996,  0.8735,  ..., -0.6295, -0.3207, -0.5584],\n",
            "        [-0.5125, -0.9440, -0.8463,  ..., -0.8926, -0.2176,  0.0054],\n",
            "        ...,\n",
            "        [ 0.7817,  0.9999,  0.6947,  ...,  0.8526, -0.6828, -0.3084],\n",
            "        [-0.4509,  0.9987, -0.6270,  ..., -0.7817, -0.0428, -0.1356],\n",
            "        [-0.5976, -0.9166, -0.9323,  ..., -0.9236,  0.5299,  0.6523]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5398,  0.8090, -0.9141,  ..., -0.8986,  0.2618,  0.3428],\n",
            "        [ 0.5700,  0.9997,  0.9268,  ...,  0.8621, -0.6826, -0.3927],\n",
            "        [ 0.4951,  0.9986,  0.8519,  ...,  0.8224, -0.8450, -0.2592],\n",
            "        ...,\n",
            "        [ 0.7123,  1.0000,  0.9284,  ...,  0.9023, -0.6075, -0.5345],\n",
            "        [ 0.7719,  0.9997,  0.7930,  ...,  0.9214, -0.6789, -0.1264],\n",
            "        [-0.4791, -0.1948, -0.9533,  ..., -0.8622,  0.4434,  0.5662]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0656,  0.9559, -0.9351,  ..., -0.8792, -0.1760,  0.0756],\n",
            "        [ 0.4286,  0.9996,  0.8373,  ...,  0.8812, -0.8731, -0.3367],\n",
            "        [ 0.3317,  0.9997,  0.8779,  ...,  0.8735, -0.7370, -0.4847],\n",
            "        ...,\n",
            "        [-0.6342, -0.3790, -0.9455,  ..., -0.9033,  0.0066,  0.5220],\n",
            "        [-0.6382,  0.6579, -0.8810,  ..., -0.8273, -0.0491,  0.4372],\n",
            "        [-0.2203, -0.9899, -0.9234,  ..., -0.8607,  0.4067,  0.0391]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5538,  0.9720, -0.8160,  ..., -0.7480, -0.0758, -0.2204],\n",
            "        [ 0.4254,  1.0000,  0.8655,  ...,  0.7064, -0.2457, -0.4988],\n",
            "        [-0.5724,  0.1029, -0.9456,  ..., -0.9137,  0.4578, -0.0884],\n",
            "        ...,\n",
            "        [-0.3890, -0.8868, -0.9702,  ..., -0.8832,  0.2629,  0.4743],\n",
            "        [ 0.7401,  0.9930,  0.8070,  ...,  0.8084, -0.6868, -0.2274],\n",
            "        [-0.5117, -0.0243, -0.9296,  ..., -0.8974, -0.1448,  0.5048]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6304,  0.9998,  0.8635,  ...,  0.8908, -0.7465, -0.4113],\n",
            "        [-0.3653, -0.9108, -0.9183,  ..., -0.8908,  0.3481,  0.2595],\n",
            "        [ 0.6892,  1.0000,  0.9415,  ...,  0.7916, -0.3905, -0.8460],\n",
            "        ...,\n",
            "        [ 0.7147,  0.9992,  0.8946,  ...,  0.8727, -0.6556, -0.5316],\n",
            "        [ 0.5987,  0.9998,  0.8817,  ...,  0.8850, -0.7490, -0.2801],\n",
            "        [ 0.7964,  1.0000,  0.7448,  ...,  0.7480, -0.5116, -0.5034]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5102, -0.9853, -0.9599,  ..., -0.9555,  0.1325,  0.7800],\n",
            "        [ 0.6300,  0.9936,  0.6556,  ...,  0.8869, -0.8451, -0.0880],\n",
            "        [-0.4104,  0.9921, -0.8429,  ..., -0.7484,  0.1008, -0.4994],\n",
            "        ...,\n",
            "        [ 0.6696,  1.0000,  0.9830,  ...,  0.8311,  0.0240, -0.7954],\n",
            "        [ 0.6183,  1.0000,  0.7656,  ...,  0.7727, -0.7277, -0.5603],\n",
            "        [-0.5270,  0.9048, -0.4385,  ..., -0.7939,  0.3406,  0.0652]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3158,  0.9398, -0.9295,  ..., -0.9276,  0.4453, -0.0045],\n",
            "        [-0.4732,  0.0485, -0.5143,  ..., -0.6036,  0.3778,  0.0744],\n",
            "        [ 0.5818,  0.9895, -0.8468,  ..., -0.7713,  0.6983, -0.4355],\n",
            "        ...,\n",
            "        [ 0.6959,  1.0000,  0.9352,  ...,  0.7866, -0.3302, -0.8589],\n",
            "        [ 0.6466,  0.9998,  0.7340,  ...,  0.8520, -0.8400, -0.3258],\n",
            "        [ 0.4198,  1.0000,  0.8608,  ...,  0.8048, -0.5755, -0.4463]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6802,  0.9997,  0.8244,  ...,  0.9013, -0.7455, -0.1960],\n",
            "        [ 0.0326, -0.9232, -0.9144,  ..., -0.8991,  0.2001,  0.5512],\n",
            "        [-0.6536, -0.9966, -0.9385,  ..., -0.8816,  0.1285,  0.6784],\n",
            "        ...,\n",
            "        [ 0.6446,  0.9998,  0.8483,  ...,  0.8423, -0.7720, -0.3443],\n",
            "        [ 0.8124,  0.9998,  0.9059,  ...,  0.7778, -0.7001, -0.6897],\n",
            "        [ 0.5988,  0.9938,  0.8330,  ...,  0.8396, -0.8450, -0.5312]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4954,  1.0000,  0.5466,  ...,  0.7771, -0.8787, -0.5314],\n",
            "        [-0.2264,  0.9999, -0.1882,  ..., -0.8651, -0.0933, -0.2166],\n",
            "        [-0.4804, -0.9989, -0.9376,  ..., -0.9467, -0.2002,  0.6257],\n",
            "        ...,\n",
            "        [ 0.5053,  0.9994,  0.9276,  ...,  0.9253, -0.7059, -0.2677],\n",
            "        [-0.4370,  0.7346, -0.8995,  ..., -0.9297,  0.4696,  0.0402],\n",
            "        [ 0.5486,  0.9976,  0.7880,  ...,  0.7703, -0.6907, -0.1620]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4679,  0.9994,  0.7024,  ...,  0.8619, -0.8871, -0.1778],\n",
            "        [-0.4930, -0.8282, -0.9681,  ..., -0.9146,  0.1321,  0.4302],\n",
            "        [ 0.7547,  0.9996,  0.8310,  ...,  0.8593, -0.7816, -0.2002],\n",
            "        ...,\n",
            "        [-0.3650, -0.6985, -0.9455,  ..., -0.8847,  0.4008,  0.4825],\n",
            "        [ 0.3111,  0.9996, -0.7055,  ..., -0.7093,  0.7378, -0.4566],\n",
            "        [ 0.7883,  0.9990,  0.9311,  ...,  0.8034, -0.7502, -0.6211]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5165,  0.9992,  0.8009,  ...,  0.8322, -0.6930, -0.2417],\n",
            "        [-0.4613, -0.4572, -0.9213,  ..., -0.9357,  0.2367,  0.5074],\n",
            "        [ 0.5086,  0.9978,  0.9020,  ...,  0.7344, -0.7347, -0.5017],\n",
            "        ...,\n",
            "        [-0.5348, -0.7800, -0.9357,  ..., -0.9415,  0.5235,  0.4381],\n",
            "        [-0.5714, -0.9652, -0.9584,  ..., -0.8513, -0.0615,  0.6416],\n",
            "        [-0.0193,  0.8396, -0.9151,  ..., -0.8173,  0.2766, -0.2564]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5723, -0.2992, -0.9110,  ..., -0.8703,  0.3712, -0.0198],\n",
            "        [ 0.6475,  1.0000, -0.6425,  ..., -0.8898,  0.7643, -0.7694],\n",
            "        [ 0.6690,  0.9982,  0.8181,  ...,  0.8781, -0.8937, -0.2467],\n",
            "        ...,\n",
            "        [ 0.7416,  0.9998,  0.9086,  ...,  0.8642, -0.6156, -0.6951],\n",
            "        [ 0.4813,  0.9965,  0.6255,  ...,  0.8807, -0.6974, -0.3559],\n",
            "        [ 0.5427,  1.0000,  0.8531,  ...,  0.5098,  0.6677, -0.8412]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4805,  0.9231, -0.9047,  ..., -0.7408,  0.6448,  0.0042],\n",
            "        [-0.4816, -0.2803, -0.8779,  ..., -0.7529,  0.5403, -0.0538],\n",
            "        [ 0.4553,  0.9967,  0.8368,  ...,  0.7538, -0.7203, -0.4492],\n",
            "        ...,\n",
            "        [-0.0864,  0.9995, -0.5746,  ..., -0.7021,  0.4104, -0.3906],\n",
            "        [ 0.4696,  0.9982,  0.9187,  ...,  0.8676, -0.8433, -0.3944],\n",
            "        [ 0.6104,  0.9989,  0.8753,  ...,  0.6859, -0.6845, -0.5788]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2724,  0.9992,  0.8553,  ...,  0.8300, -0.8128, -0.2242],\n",
            "        [ 0.6326,  0.9979,  0.9007,  ...,  0.9071, -0.8310, -0.3764],\n",
            "        [-0.6350, -0.9832, -0.8949,  ..., -0.9258,  0.1943,  0.7528],\n",
            "        ...,\n",
            "        [-0.1000,  1.0000,  0.7228,  ..., -0.0543, -0.0238, -0.7819],\n",
            "        [ 0.4247,  0.9994,  0.7699,  ...,  0.8135, -0.6953, -0.2087],\n",
            "        [ 0.7381,  0.9999,  0.8380,  ...,  0.8166, -0.4947, -0.5623]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4105, -0.7973, -0.9234,  ..., -0.7897,  0.0402,  0.4289],\n",
            "        [ 0.6401,  0.9999,  0.8897,  ...,  0.8723, -0.7165, -0.4902],\n",
            "        [ 0.6872,  1.0000,  0.9095,  ...,  0.8572, -0.5426, -0.2917],\n",
            "        ...,\n",
            "        [-0.3839, -0.4022, -0.9171,  ..., -0.8027,  0.0574,  0.2067],\n",
            "        [-0.2269, -0.9974, -0.9614,  ..., -0.8740,  0.5680,  0.3431],\n",
            "        [ 0.6315,  0.9998,  0.8478,  ...,  0.8293, -0.5659, -0.7471]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7023,  0.9990,  0.8748,  ...,  0.9159, -0.8335, -0.2272],\n",
            "        [ 0.6846,  0.9905,  0.8214,  ...,  0.8618, -0.8351, -0.1532],\n",
            "        [ 0.1701,  0.9922,  0.8498,  ...,  0.8272, -0.6851, -0.2642],\n",
            "        ...,\n",
            "        [-0.5522, -0.9885, -0.9363,  ..., -0.8844,  0.4353,  0.5751],\n",
            "        [-0.4549, -0.5497, -0.9702,  ..., -0.9271, -0.1063,  0.4772],\n",
            "        [ 0.6072,  1.0000,  0.9418,  ...,  0.8478, -0.2947, -0.8787]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4651,  0.9095, -0.9015,  ..., -0.9159,  0.5466,  0.1079],\n",
            "        [-0.0257,  1.0000, -0.0312,  ..., -0.7972,  0.4345, -0.7734],\n",
            "        [ 0.6621,  0.9993,  0.8815,  ...,  0.8326, -0.7956, -0.6226],\n",
            "        ...,\n",
            "        [-0.0413, -0.8822, -0.9567,  ..., -0.8478,  0.2841,  0.4638],\n",
            "        [ 0.4702,  0.9997,  0.9141,  ...,  0.8962, -0.6597, -0.4311],\n",
            "        [-0.5326,  0.9995, -0.4820,  ..., -0.8588,  0.1072, -0.6104]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4576,  0.9998,  0.7941,  ...,  0.8799, -0.6980, -0.5091],\n",
            "        [ 0.7658,  0.9972,  0.7842,  ...,  0.7435, -0.8726,  0.1164],\n",
            "        [ 0.2336,  1.0000, -0.6541,  ..., -0.8044,  0.8809, -0.7111],\n",
            "        ...,\n",
            "        [ 0.6311,  0.9998,  0.6268,  ...,  0.7265, -0.7220, -0.3344],\n",
            "        [ 0.0194,  0.7187, -0.8809,  ..., -0.8724,  0.2350, -0.1291],\n",
            "        [ 0.6466,  0.9995,  0.9085,  ...,  0.8696, -0.6534, -0.6254]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2403,  0.4230, -0.9033,  ..., -0.9240,  0.4105,  0.5845],\n",
            "        [ 0.3992,  0.9984,  0.8217,  ...,  0.8124, -0.8644, -0.1932],\n",
            "        [ 0.5446,  1.0000,  0.8807,  ...,  0.4596,  0.5155, -0.9695],\n",
            "        ...,\n",
            "        [-0.4066,  0.3887, -0.8847,  ..., -0.8515,  0.4306,  0.0656],\n",
            "        [ 0.3587,  0.9989,  0.7621,  ...,  0.8232, -0.8320,  0.1386],\n",
            "        [ 0.5868,  0.9999,  0.9093,  ...,  0.9317, -0.6481, -0.3876]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3893,  0.9955,  0.8358,  ...,  0.8311, -0.8360, -0.4166],\n",
            "        [ 0.5925,  0.9999,  0.8575,  ...,  0.8196, -0.8438, -0.3676],\n",
            "        [-0.5412, -0.9925, -0.9485,  ..., -0.8834,  0.2246,  0.6226],\n",
            "        ...,\n",
            "        [-0.2366, -0.5694, -0.9040,  ..., -0.8910,  0.5535,  0.6137],\n",
            "        [ 0.7799,  0.9999,  0.8767,  ...,  0.9096, -0.6531, -0.7034],\n",
            "        [ 0.2800,  0.9990,  0.7849,  ...,  0.9276, -0.7445, -0.2769]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2912,  0.8902, -0.9409,  ..., -0.8854,  0.2585,  0.0722],\n",
            "        [ 0.5175,  0.9992,  0.7711,  ...,  0.7588, -0.8393, -0.1760],\n",
            "        [ 0.6465,  0.9986,  0.7655,  ...,  0.8496, -0.8326, -0.1850],\n",
            "        ...,\n",
            "        [-0.5626,  0.2161, -0.8295,  ..., -0.8206,  0.5473, -0.1242],\n",
            "        [ 0.6382,  0.9998,  0.8410,  ...,  0.8519, -0.7990, -0.1023],\n",
            "        [-0.2215,  0.9866, -0.7789,  ..., -0.8897,  0.6070, -0.0142]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5247,  0.5685, -0.9494,  ..., -0.9046,  0.3233,  0.1566],\n",
            "        [ 0.4908,  0.9973,  0.8552,  ...,  0.8252, -0.7993, -0.3773],\n",
            "        [ 0.7244,  1.0000,  0.8746,  ...,  0.7866, -0.7428, -0.6636],\n",
            "        ...,\n",
            "        [-0.1512,  0.9999, -0.6394,  ..., -0.8412,  0.5670, -0.4954],\n",
            "        [-0.7043,  0.6865, -0.9299,  ..., -0.9017,  0.1426,  0.5326],\n",
            "        [-0.4212,  0.9668, -0.8035,  ..., -0.7899,  0.6570, -0.1605]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6200,  0.9968, -0.7392,  ..., -0.7997,  0.5504, -0.7124],\n",
            "        [-0.4896,  0.1705, -0.9098,  ..., -0.8309,  0.2401,  0.2667],\n",
            "        [-0.2639,  0.9789, -0.3516,  ..., -0.7519,  0.2445, -0.1448],\n",
            "        ...,\n",
            "        [ 0.6314,  0.9994,  0.8258,  ...,  0.9150, -0.7988, -0.1356],\n",
            "        [-0.3689,  0.1043, -0.8333,  ..., -0.7837,  0.6169, -0.3015],\n",
            "        [-0.5794,  0.4750, -0.9204,  ..., -0.8711,  0.3539,  0.2996]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0871,  0.9966,  0.8051,  ...,  0.7774, -0.7284,  0.1439],\n",
            "        [ 0.7902,  0.9998,  0.7987,  ...,  0.7066, -0.4025, -0.5034],\n",
            "        [ 0.4943,  0.9984,  0.8258,  ...,  0.8547, -0.8201, -0.4457],\n",
            "        ...,\n",
            "        [-0.3750,  0.8724, -0.9217,  ..., -0.8880,  0.0667,  0.2219],\n",
            "        [ 0.5812,  0.9927,  0.8756,  ...,  0.8426, -0.7604, -0.3605],\n",
            "        [ 0.5416,  0.9999,  0.7693,  ...,  0.7998, -0.7293, -0.5857]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3680,  0.9995,  0.7260,  ...,  0.6149, -0.6675, -0.6830],\n",
            "        [ 0.6352,  0.9937,  0.7873,  ...,  0.7291, -0.7502, -0.1984],\n",
            "        [ 0.4008,  0.9368, -0.9037,  ..., -0.8916,  0.4899, -0.2763],\n",
            "        ...,\n",
            "        [ 0.5485,  0.9969,  0.8915,  ...,  0.9059, -0.8318, -0.2625],\n",
            "        [-0.4803, -0.0524, -0.8283,  ..., -0.9258,  0.1918,  0.3252],\n",
            "        [ 0.6249,  1.0000,  0.9267,  ...,  0.7826, -0.0997, -0.6957]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6808, -0.9576, -0.9315,  ..., -0.9013,  0.1849,  0.5730],\n",
            "        [-0.5271, -0.8621, -0.9150,  ..., -0.9195, -0.1443,  0.1489],\n",
            "        [ 0.7812,  0.9999,  0.8937,  ...,  0.9015, -0.6249, -0.4585],\n",
            "        ...,\n",
            "        [-0.2882, -1.0000, -0.9329,  ..., -0.9201,  0.1159,  0.6617],\n",
            "        [ 0.6104,  0.9996,  0.8452,  ...,  0.8793, -0.8197, -0.4484],\n",
            "        [-0.7156, -0.6965, -0.9272,  ..., -0.8712, -0.1262,  0.6715]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5762,  0.9996,  0.8741,  ...,  0.9260, -0.8581, -0.2998],\n",
            "        [ 0.4427,  0.9994,  0.8619,  ...,  0.8579, -0.7595, -0.3979],\n",
            "        [ 0.0758,  0.4564, -0.9101,  ..., -0.9299,  0.2491,  0.5350],\n",
            "        ...,\n",
            "        [-0.2673,  0.9984, -0.8877,  ..., -0.6716,  0.5649, -0.3137],\n",
            "        [ 0.6940,  0.9979,  0.8801,  ...,  0.8338, -0.8500, -0.4899],\n",
            "        [ 0.7062,  0.9994,  0.9304,  ...,  0.8340, -0.7243, -0.4590]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6397,  0.9999,  0.8871,  ...,  0.8435, -0.7295, -0.4805],\n",
            "        [-0.0704,  0.9971, -0.8879,  ..., -0.7955,  0.2349,  0.2478],\n",
            "        [ 0.4556,  0.9992,  0.8941,  ...,  0.8831, -0.7663, -0.3046],\n",
            "        ...,\n",
            "        [ 0.8248,  1.0000,  0.8589,  ...,  0.8113, -0.6479, -0.2452],\n",
            "        [-0.3413,  0.7350, -0.9267,  ..., -0.9289,  0.2089,  0.5139],\n",
            "        [-0.4983, -0.6725, -0.9306,  ..., -0.9116,  0.2276,  0.4833]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.7237, -0.9965, -0.9106,  ..., -0.9135, -0.2837,  0.7343],\n",
            "        [-0.4144,  0.9407, -0.9014,  ..., -0.9180,  0.3638,  0.5361],\n",
            "        [ 0.4080,  0.9944,  0.8484,  ...,  0.9130, -0.8967, -0.3186],\n",
            "        ...,\n",
            "        [-0.3906, -0.9086, -0.9150,  ..., -0.9009,  0.0733,  0.3666],\n",
            "        [ 0.6370,  0.9982,  0.9290,  ...,  0.8288, -0.7776, -0.5897],\n",
            "        [ 0.3929,  0.9953,  0.7825,  ...,  0.8749, -0.7635,  0.1728]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6081,  0.9997,  0.9383,  ...,  0.8182, -0.5430, -0.4140],\n",
            "        [ 0.6964,  0.9995,  0.7586,  ...,  0.8876, -0.8228, -0.3761],\n",
            "        [ 0.7546,  0.9958,  0.7252,  ...,  0.8629, -0.8525, -0.2401],\n",
            "        ...,\n",
            "        [-0.6749,  0.0674, -0.9373,  ..., -0.9019,  0.3481,  0.7651],\n",
            "        [-0.0296,  0.9894, -0.9216,  ..., -0.8132,  0.5447, -0.0319],\n",
            "        [ 0.7417,  0.9994,  0.9069,  ...,  0.8891, -0.7799, -0.3462]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6440, -0.4468, -0.9691,  ..., -0.8745, -0.0556,  0.6184],\n",
            "        [-0.4056, -0.9325, -0.9589,  ..., -0.8986,  0.3950,  0.6481],\n",
            "        [ 0.6050,  0.9994,  0.8880,  ...,  0.8065, -0.5865, -0.4539],\n",
            "        ...,\n",
            "        [ 0.6970,  0.9993,  0.8451,  ...,  0.9189, -0.7936, -0.2636],\n",
            "        [-0.6285,  0.9861, -0.9124,  ..., -0.8851,  0.0700,  0.6172],\n",
            "        [-0.4398,  0.3958, -0.8874,  ..., -0.8561,  0.5913,  0.5346]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4096,  0.9676, -0.8984,  ..., -0.9394,  0.2511,  0.4742],\n",
            "        [ 0.8420,  0.9999,  0.8189,  ...,  0.7463, -0.4089, -0.6429],\n",
            "        [-0.3247,  0.9988, -0.8582,  ..., -0.8371,  0.6738, -0.0490],\n",
            "        ...,\n",
            "        [ 0.4683,  0.9968,  0.7951,  ...,  0.8000, -0.8600, -0.2703],\n",
            "        [ 0.4062,  0.9996,  0.8676,  ...,  0.8643, -0.5882, -0.7080],\n",
            "        [ 0.5854,  0.9996,  0.8781,  ...,  0.7897, -0.7837, -0.3297]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4289,  0.9979,  0.8438,  ...,  0.8891, -0.8567, -0.2810],\n",
            "        [ 0.5660,  0.9997,  0.7215,  ...,  0.7782, -0.7473, -0.4194],\n",
            "        [ 0.6277,  0.9976,  0.8415,  ...,  0.8449, -0.8931,  0.0336],\n",
            "        ...,\n",
            "        [-0.6595,  0.7685, -0.9260,  ..., -0.8804, -0.0843,  0.4973],\n",
            "        [-0.4395,  0.9763, -0.8458,  ..., -0.8638,  0.5697,  0.0244],\n",
            "        [-0.3437,  0.9992, -0.8830,  ..., -0.9188,  0.5451,  0.0980]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4224, -0.9572, -0.9600,  ..., -0.9266,  0.1986,  0.4096],\n",
            "        [-0.2653,  0.9991, -0.7347,  ..., -0.8527,  0.2171, -0.6021],\n",
            "        [ 0.5703,  0.9911,  0.7707,  ...,  0.8366, -0.8114, -0.3285],\n",
            "        ...,\n",
            "        [ 0.6724,  0.9864,  0.8892,  ...,  0.8947, -0.7473, -0.2677],\n",
            "        [ 0.5094,  0.9988,  0.8146,  ...,  0.8906, -0.7431, -0.2426],\n",
            "        [ 0.2372,  0.9999,  0.9110,  ...,  0.5210, -0.4768, -0.4150]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2958,  0.9999,  0.8447,  ...,  0.2917,  0.1704, -0.8607],\n",
            "        [ 0.7357,  0.9990,  0.8772,  ...,  0.8628, -0.7622, -0.0161],\n",
            "        [ 0.7047,  1.0000,  0.9373,  ...,  0.9199, -0.5423, -0.7978],\n",
            "        ...,\n",
            "        [-0.4630,  0.6000, -0.9172,  ..., -0.9525,  0.2790,  0.1453],\n",
            "        [ 0.3197,  0.9890,  0.7263,  ...,  0.9227, -0.8716, -0.1525],\n",
            "        [-0.4355, -0.9020, -0.9642,  ..., -0.9122,  0.2122,  0.6673]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6166,  0.9982,  0.9192,  ...,  0.9063, -0.8589, -0.2273],\n",
            "        [-0.4209, -0.9797, -0.9473,  ..., -0.8887,  0.1043,  0.3825],\n",
            "        [ 0.5225,  1.0000, -0.7219,  ..., -0.8937,  0.8652, -0.7324],\n",
            "        ...,\n",
            "        [ 0.5544,  1.0000,  0.9353,  ...,  0.6046, -0.4525, -0.8130],\n",
            "        [ 0.6491,  0.9998,  0.9207,  ...,  0.8413, -0.6497, -0.6911],\n",
            "        [ 0.4440,  0.9996,  0.8198,  ...,  0.8843, -0.7026, -0.0885]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.8455,  1.0000,  0.9068,  ...,  0.7399, -0.7521, -0.6233],\n",
            "        [ 0.2614,  0.9999, -0.2139,  ..., -0.4269,  0.3010, -0.3776],\n",
            "        [-0.2489, -0.9674, -0.9190,  ..., -0.8277,  0.4897,  0.2900],\n",
            "        ...,\n",
            "        [ 0.5396,  0.9875,  0.7148,  ...,  0.8627, -0.8294,  0.0636],\n",
            "        [ 0.7706,  0.9989,  0.7853,  ...,  0.8225, -0.8494, -0.7225],\n",
            "        [ 0.7467,  0.9997,  0.9041,  ...,  0.8617, -0.7792, -0.2739]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7070,  0.9996,  0.8669,  ...,  0.8530, -0.7630, -0.4778],\n",
            "        [ 0.5292,  0.9994,  0.7941,  ...,  0.7468, -0.8499, -0.4267],\n",
            "        [ 0.6145,  0.9999,  0.7777,  ...,  0.7714, -0.8524, -0.4584],\n",
            "        ...,\n",
            "        [ 0.4345,  0.9999, -0.7435,  ..., -0.6928,  0.4741, -0.6764],\n",
            "        [-0.4731, -0.9466, -0.9530,  ..., -0.9634,  0.0879,  0.5203],\n",
            "        [-0.3978, -0.9803, -0.9359,  ..., -0.8982,  0.0969,  0.5050]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5868,  1.0000,  0.6813,  ...,  0.7973, -0.4850, -0.5466],\n",
            "        [ 0.5344,  0.9997,  0.9440,  ...,  0.7387, -0.5732, -0.7493],\n",
            "        [ 0.4021,  1.0000,  0.8788,  ...,  0.8258, -0.6381, -0.6867],\n",
            "        ...,\n",
            "        [-0.3321, -0.8537, -0.9377,  ..., -0.8852, -0.1315,  0.5593],\n",
            "        [ 0.5582,  0.9997,  0.4861,  ...,  0.7820, -0.6623, -0.4497],\n",
            "        [-0.5678, -0.9424, -0.9519,  ..., -0.9523,  0.4539,  0.4839]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6815,  0.9995,  0.8863,  ...,  0.8948, -0.7704, -0.4301],\n",
            "        [ 0.8906,  1.0000,  0.9528,  ...,  0.4632,  0.1873, -0.8961],\n",
            "        [-0.5264, -0.9627, -0.9296,  ..., -0.8896,  0.3108,  0.5636],\n",
            "        ...,\n",
            "        [ 0.6179,  0.9998,  0.8463,  ...,  0.8337, -0.8194, -0.2057],\n",
            "        [-0.6243, -0.0061, -0.9276,  ..., -0.9007, -0.2553,  0.4454],\n",
            "        [ 0.4059,  0.9998,  0.7987,  ...,  0.5966, -0.7218, -0.5828]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4902, -0.9807, -0.9390,  ..., -0.7863,  0.2393,  0.5214],\n",
            "        [ 0.5420,  0.9985,  0.7431,  ...,  0.8561, -0.7969, -0.1931],\n",
            "        [ 0.5804,  0.9999,  0.9549,  ...,  0.8036, -0.5043, -0.6324],\n",
            "        ...,\n",
            "        [ 0.5246,  0.9997,  0.6987,  ...,  0.8639, -0.8467, -0.3612],\n",
            "        [-0.5198,  0.5750, -0.6672,  ..., -0.9223,  0.0865,  0.1045],\n",
            "        [-0.5942,  0.7488, -0.9305,  ..., -0.8721,  0.3704,  0.2624]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6331,  0.9992,  0.7926,  ...,  0.8550, -0.8354, -0.2205],\n",
            "        [ 0.5671,  0.9995,  0.8763,  ...,  0.9114, -0.6839, -0.2396],\n",
            "        [-0.4894, -0.9991, -0.9373,  ..., -0.8887,  0.1401,  0.5911],\n",
            "        ...,\n",
            "        [-0.6877, -0.6850, -0.9495,  ..., -0.9171,  0.0791,  0.5459],\n",
            "        [ 0.7096,  1.0000,  0.7805,  ...,  0.7167, -0.7169, -0.7429],\n",
            "        [-0.1580, -0.3554, -0.9005,  ..., -0.8333,  0.3998,  0.5404]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6042, -0.9917, -0.9585,  ..., -0.9381,  0.2017,  0.4868],\n",
            "        [ 0.7096,  0.9879,  0.8478,  ...,  0.8498, -0.8696, -0.2938],\n",
            "        [-0.5130, -0.9818, -0.9352,  ..., -0.8740,  0.3683,  0.5392],\n",
            "        ...,\n",
            "        [ 0.5205,  0.9988,  0.8647,  ...,  0.9008, -0.7921, -0.5440],\n",
            "        [ 0.3356,  0.9998,  0.8607,  ...,  0.8842, -0.8565, -0.4076],\n",
            "        [ 0.5633,  0.9997,  0.8469,  ...,  0.8615, -0.6411, -0.4085]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5378, -0.9222, -0.9326,  ..., -0.8388,  0.2759,  0.5780],\n",
            "        [ 0.6814,  0.9903,  0.8077,  ...,  0.8838, -0.8261, -0.0578],\n",
            "        [ 0.5954,  0.9999,  0.6401,  ...,  0.4044, -0.6132, -0.7865],\n",
            "        ...,\n",
            "        [ 0.5084,  0.9969,  0.8406,  ...,  0.8476, -0.7457, -0.5065],\n",
            "        [-0.3822, -0.9914, -0.8950,  ..., -0.7623,  0.1398,  0.7185],\n",
            "        [-0.3193,  0.2492, -0.9195,  ..., -0.9093,  0.1924,  0.3737]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.8571, -0.9978, -0.8358,  ..., -0.9057,  0.1851,  0.3881],\n",
            "        [ 0.6755,  0.9990,  0.7010,  ...,  0.8621, -0.7803, -0.5619],\n",
            "        [ 0.7416,  1.0000,  0.8356,  ...,  0.7790, -0.7154, -0.5614],\n",
            "        ...,\n",
            "        [ 0.8008,  0.9988,  0.6295,  ...,  0.8005, -0.6859, -0.5037],\n",
            "        [ 0.6022,  0.9990,  0.7453,  ...,  0.8176, -0.8929, -0.3802],\n",
            "        [ 0.6007,  0.9983,  0.9211,  ...,  0.8168, -0.8471, -0.5840]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6888,  0.5363, -0.7649,  ..., -0.7234, -0.0104,  0.7544],\n",
            "        [ 0.3597,  0.9987,  0.7851,  ...,  0.8265, -0.7480,  0.0317],\n",
            "        [-0.3879, -0.6147, -0.9131,  ..., -0.8618,  0.4847, -0.0064],\n",
            "        ...,\n",
            "        [-0.6978,  0.0025, -0.9218,  ..., -0.9094,  0.1802,  0.5500],\n",
            "        [-0.6566, -0.9947, -0.9650,  ..., -0.9142,  0.0263,  0.6159],\n",
            "        [-0.2177,  0.2277, -0.8881,  ..., -0.8487,  0.0186,  0.4581]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6252,  0.9992,  0.6984,  ...,  0.8146, -0.5091, -0.0105],\n",
            "        [-0.6610, -0.9768, -0.9274,  ..., -0.9320,  0.5821,  0.6374],\n",
            "        [-0.7300, -0.3758, -0.9492,  ..., -0.8975,  0.1647,  0.5671],\n",
            "        ...,\n",
            "        [-0.6383, -0.9753, -0.9389,  ..., -0.9207,  0.4493,  0.4643],\n",
            "        [ 0.5323,  0.9947,  0.7487,  ...,  0.8821, -0.8362, -0.0867],\n",
            "        [ 0.7030,  0.9991,  0.7929,  ...,  0.8980, -0.8328,  0.0809]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7964,  0.9992,  0.8728,  ...,  0.8619, -0.8118, -0.3992],\n",
            "        [ 0.4677,  0.9957,  0.7712,  ...,  0.8116, -0.8559, -0.3336],\n",
            "        [-0.4008, -0.7499, -0.8998,  ..., -0.8723,  0.7110,  0.3792],\n",
            "        ...,\n",
            "        [ 0.7743,  0.9970,  0.6279,  ...,  0.8405, -0.7741, -0.3181],\n",
            "        [-0.4875, -0.7273, -0.9453,  ..., -0.9167,  0.1454,  0.7094],\n",
            "        [-0.3877, -0.8352, -0.9126,  ..., -0.8644,  0.4243,  0.3757]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5222, -0.8659, -0.9456,  ..., -0.8998,  0.1798,  0.5528],\n",
            "        [ 0.7095,  0.9916,  0.8409,  ...,  0.8534, -0.7959, -0.1908],\n",
            "        [ 0.2967,  0.9967,  0.6873,  ...,  0.8572, -0.8588, -0.0847],\n",
            "        ...,\n",
            "        [ 0.7812,  1.0000,  0.8330,  ...,  0.8177, -0.5370, -0.7200],\n",
            "        [ 0.5500,  1.0000,  0.8694,  ...,  0.6062, -0.5617, -0.7078],\n",
            "        [-0.5782, -0.9642, -0.9475,  ..., -0.8980,  0.0597,  0.6077]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6203,  0.9936,  0.8108,  ...,  0.8182, -0.5606, -0.1513],\n",
            "        [ 0.4821,  1.0000,  0.9112,  ...,  0.4851, -0.2495, -0.7465],\n",
            "        [-0.2634,  0.9975, -0.9174,  ..., -0.8652,  0.5909,  0.2044],\n",
            "        ...,\n",
            "        [-0.5284, -0.9862, -0.9404,  ..., -0.9044, -0.0475,  0.5779],\n",
            "        [-0.5831, -0.9722, -0.9227,  ..., -0.8834, -0.0934,  0.5038],\n",
            "        [-0.5406, -0.9989, -0.9614,  ..., -0.9594,  0.1227,  0.6029]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6712,  0.9995,  0.9054,  ...,  0.8638, -0.8536, -0.5344],\n",
            "        [-0.3784,  0.1338, -0.9302,  ..., -0.9267,  0.2133,  0.5293],\n",
            "        [ 0.3363,  0.9957,  0.8677,  ...,  0.8135, -0.8250, -0.3717],\n",
            "        ...,\n",
            "        [ 0.7184,  0.9987,  0.7987,  ...,  0.5640, -0.5246, -0.2828],\n",
            "        [-0.6403, -0.9641, -0.9397,  ..., -0.9122, -0.0804,  0.6261],\n",
            "        [ 0.6626,  0.9999,  0.7441,  ...,  0.8883, -0.6940, -0.5079]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6666,  0.9960,  0.7632,  ...,  0.8699, -0.8062, -0.2984],\n",
            "        [ 0.6142,  0.9995,  0.7761,  ...,  0.8369, -0.8356, -0.2664],\n",
            "        [ 0.6856,  0.9999,  0.8907,  ...,  0.8039, -0.8413, -0.4206],\n",
            "        ...,\n",
            "        [ 0.5554,  1.0000,  0.7321,  ...,  0.8334, -0.7903, -0.3864],\n",
            "        [ 0.5317,  0.9946,  0.8152,  ...,  0.8500, -0.8285, -0.1564],\n",
            "        [-0.6306, -0.7069, -0.9542,  ..., -0.8627, -0.1533,  0.7948]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0211,  0.9941, -0.7549,  ..., -0.8008, -0.2534, -0.2160],\n",
            "        [ 0.6552,  0.9997,  0.8783,  ...,  0.8665, -0.7615, -0.4147],\n",
            "        [-0.2930, -0.9828, -0.9575,  ..., -0.9150,  0.1258,  0.4189],\n",
            "        ...,\n",
            "        [-0.6165, -0.7539, -0.9177,  ..., -0.9441, -0.1078,  0.4622],\n",
            "        [ 0.7446,  1.0000,  0.8902,  ...,  0.6677, -0.6467, -0.8242],\n",
            "        [ 0.3227,  1.0000,  0.9137,  ...,  0.1987, -0.1675, -0.9794]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1070, -0.2659, -0.8549,  ..., -0.8633,  0.4585, -0.2377],\n",
            "        [-0.5502, -0.7918, -0.9072,  ..., -0.8556,  0.2262,  0.5187],\n",
            "        [ 0.4791,  0.9957,  0.8991,  ...,  0.8709, -0.8639, -0.2423],\n",
            "        ...,\n",
            "        [-0.5476, -0.9889, -0.9686,  ..., -0.8975,  0.3178,  0.5568],\n",
            "        [ 0.6531,  1.0000,  0.8836,  ...,  0.7347, -0.4529, -0.8150],\n",
            "        [-0.2936, -0.9727, -0.9647,  ..., -0.9167,  0.2266,  0.4128]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3889,  1.0000,  0.8056,  ...,  0.2489,  0.3168, -0.7745],\n",
            "        [-0.2736, -0.1350, -0.8572,  ..., -0.9085,  0.4068,  0.4395],\n",
            "        [ 0.7028,  0.9996,  0.8777,  ...,  0.8387, -0.6771, -0.5221],\n",
            "        ...,\n",
            "        [ 0.5119,  1.0000,  0.8156,  ...,  0.7806, -0.6281, -0.4927],\n",
            "        [ 0.6204,  0.9999,  0.9320,  ...,  0.3613, -0.4559, -0.8391],\n",
            "        [ 0.5106,  0.9999,  0.7846,  ...,  0.5171, -0.8557, -0.7211]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7676,  0.9998,  0.6958,  ...,  0.7194, -0.5033, -0.7293],\n",
            "        [-0.6764, -0.9906, -0.9096,  ..., -0.9000, -0.0066,  0.6782],\n",
            "        [-0.7028,  0.3006, -0.9549,  ..., -0.9185, -0.0384,  0.6913],\n",
            "        ...,\n",
            "        [-0.0885,  0.9990, -0.7962,  ..., -0.7996,  0.5851, -0.1123],\n",
            "        [-0.3152, -0.9799, -0.9166,  ..., -0.8010,  0.1315,  0.6000],\n",
            "        [-0.6108, -0.0816, -0.8902,  ..., -0.9442,  0.2777,  0.1585]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1742,  0.9998, -0.7870,  ..., -0.8012,  0.1614, -0.7040],\n",
            "        [-0.6689, -0.9945, -0.9522,  ..., -0.8754,  0.5153,  0.6792],\n",
            "        [ 0.1858,  0.9994, -0.6291,  ..., -0.8542,  0.4539, -0.0034],\n",
            "        ...,\n",
            "        [ 0.7982,  1.0000,  0.7100,  ...,  0.6896, -0.5364, -0.3026],\n",
            "        [ 0.5000,  0.9985,  0.8112,  ...,  0.7101, -0.7163, -0.1738],\n",
            "        [-0.4071, -0.2446, -0.9315,  ..., -0.9325,  0.0479,  0.3846]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5468,  1.0000,  0.7299,  ...,  0.6730, -0.7393, -0.5372],\n",
            "        [-0.8120, -0.9676, -0.9280,  ..., -0.8570,  0.1705,  0.7956],\n",
            "        [ 0.6781,  0.9976,  0.8691,  ...,  0.5255, -0.5633, -0.6603],\n",
            "        ...,\n",
            "        [ 0.3522,  0.9417,  0.7054,  ...,  0.8569, -0.7848, -0.1555],\n",
            "        [-0.3392, -0.9893, -0.9242,  ..., -0.8658,  0.3897,  0.4455],\n",
            "        [ 0.4772,  0.9954,  0.8744,  ...,  0.8685, -0.6835, -0.3707]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5123,  0.9998,  0.8405,  ...,  0.8247, -0.7142, -0.4173],\n",
            "        [-0.5441, -0.6337, -0.9307,  ..., -0.8840,  0.4857, -0.1487],\n",
            "        [ 0.7975,  0.9999,  0.8470,  ...,  0.8877, -0.6683, -0.2618],\n",
            "        ...,\n",
            "        [ 0.7372,  1.0000,  0.9441,  ...,  0.6563, -0.4692, -0.5227],\n",
            "        [-0.5402, -0.8032, -0.9519,  ..., -0.9226,  0.2069,  0.5557],\n",
            "        [-0.3694, -0.4566, -0.8073,  ..., -0.9078,  0.2453,  0.5601]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5512,  0.9984,  0.7402,  ...,  0.7806, -0.4971, -0.5114],\n",
            "        [ 0.5404,  0.9998,  0.8644,  ...,  0.8707, -0.8492, -0.3034],\n",
            "        [-0.4765, -0.9426, -0.9137,  ..., -0.9264,  0.2595,  0.5611],\n",
            "        ...,\n",
            "        [-0.4600, -0.4418, -0.9659,  ..., -0.9242,  0.2095,  0.4843],\n",
            "        [-0.5946, -0.4445, -0.9274,  ..., -0.7795, -0.0953,  0.7095],\n",
            "        [ 0.6092,  1.0000,  0.7921,  ...,  0.7988, -0.5212, -0.6692]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4757,  0.9999,  0.9442,  ...,  0.9024, -0.5016, -0.4399],\n",
            "        [-0.3542, -0.8949, -0.9369,  ..., -0.9003,  0.3871,  0.5608],\n",
            "        [-0.4779, -0.4497, -0.8805,  ..., -0.9428,  0.3650,  0.7714],\n",
            "        ...,\n",
            "        [ 0.5624,  0.9994,  0.6530,  ...,  0.8259, -0.8273, -0.6165],\n",
            "        [ 0.6743,  0.9999,  0.8862,  ...,  0.7873, -0.4643, -0.6678],\n",
            "        [ 0.5457,  0.9996,  0.8860,  ...,  0.7569, -0.8063, -0.5603]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5924,  0.9984,  0.7972,  ...,  0.9049, -0.8085, -0.4391],\n",
            "        [ 0.3143,  1.0000,  0.7118,  ...,  0.1660, -0.2032, -0.8134],\n",
            "        [-0.7167, -0.9983, -0.9460,  ..., -0.9272,  0.1247,  0.5312],\n",
            "        ...,\n",
            "        [-0.3192,  0.9947, -0.9267,  ..., -0.8859,  0.4725,  0.2105],\n",
            "        [ 0.8223,  0.9998,  0.8361,  ...,  0.9038, -0.7195, -0.4832],\n",
            "        [ 0.5691,  1.0000,  0.8876,  ...,  0.8881, -0.3089, -0.8064]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6083, -0.0304, -0.9083,  ..., -0.9183,  0.3832,  0.2932],\n",
            "        [ 0.8657,  1.0000,  0.8156,  ...,  0.7243, -0.6101, -0.8032],\n",
            "        [-0.6584, -0.9613, -0.9136,  ..., -0.8625,  0.3044,  0.7518],\n",
            "        ...,\n",
            "        [ 0.6252,  1.0000,  0.9086,  ...,  0.8687, -0.5906, -0.6185],\n",
            "        [ 0.5760,  0.9996,  0.8219,  ...,  0.7724, -0.7881, -0.3929],\n",
            "        [ 0.5170,  0.9984,  0.5854,  ...,  0.6731, -0.7496, -0.3226]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4651,  0.6981, -0.7998,  ..., -0.8265,  0.1667, -0.0409],\n",
            "        [ 0.5549,  0.9992,  0.8162,  ...,  0.7641, -0.7472, -0.3658],\n",
            "        [-0.5367, -0.8287, -0.9603,  ..., -0.8409,  0.4388,  0.4164],\n",
            "        ...,\n",
            "        [ 0.7018,  0.9998,  0.8539,  ...,  0.9332, -0.6193, -0.3594],\n",
            "        [ 0.5719,  1.0000,  0.7154,  ...,  0.4928, -0.5548, -0.8514],\n",
            "        [-0.7013, -0.2805, -0.9445,  ..., -0.8872, -0.0754,  0.5226]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7553,  0.9997,  0.9173,  ...,  0.8904, -0.7564, -0.4303],\n",
            "        [ 0.3751,  1.0000,  0.7521,  ...,  0.2672,  0.5618, -0.8508],\n",
            "        [-0.6567,  0.5426, -0.9386,  ..., -0.9239,  0.2927,  0.4188],\n",
            "        ...,\n",
            "        [-0.7104, -0.9988, -0.9308,  ..., -0.8657,  0.2292,  0.7623],\n",
            "        [ 0.6720,  1.0000,  0.8273,  ...,  0.8316, -0.7507, -0.1632],\n",
            "        [-0.4855,  0.2372, -0.9515,  ..., -0.9306,  0.2175,  0.1831]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7872,  0.9995,  0.8756,  ...,  0.9184, -0.7224, -0.4714],\n",
            "        [ 0.6850,  0.9996,  0.8701,  ...,  0.8655, -0.7950, -0.2707],\n",
            "        [ 0.6957,  0.9998,  0.9131,  ...,  0.5807, -0.6909, -0.8188],\n",
            "        ...,\n",
            "        [-0.5581, -0.9921, -0.9197,  ..., -0.8890,  0.5780,  0.4052],\n",
            "        [-0.6047, -0.8576, -0.8865,  ..., -0.9439,  0.2855,  0.2854],\n",
            "        [ 0.6947,  0.9998,  0.8854,  ...,  0.8743, -0.4653, -0.6067]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7824,  1.0000, -0.3217,  ..., -0.8577,  0.5614, -0.7976],\n",
            "        [-0.6071, -0.5236, -0.8965,  ..., -0.9031, -0.0145,  0.5869],\n",
            "        [-0.2725,  0.7888, -0.8834,  ..., -0.8535,  0.1208,  0.0523],\n",
            "        ...,\n",
            "        [-0.5885, -0.9932, -0.9527,  ..., -0.8842,  0.4670,  0.5996],\n",
            "        [ 0.5607,  0.9996,  0.7587,  ...,  0.8441, -0.7134, -0.6824],\n",
            "        [-0.6843, -0.6485, -0.9208,  ..., -0.7736,  0.2628,  0.6806]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6900,  1.0000,  0.8423,  ...,  0.8995, -0.7545, -0.5843],\n",
            "        [ 0.6407,  0.9991,  0.8311,  ...,  0.8008, -0.8119, -0.6094],\n",
            "        [-0.4495,  0.8433, -0.9072,  ..., -0.8582, -0.0514,  0.4004],\n",
            "        ...,\n",
            "        [ 0.6129,  0.9998,  0.9034,  ...,  0.9161, -0.7306, -0.5682],\n",
            "        [ 0.7929,  0.9999,  0.8378,  ...,  0.9106, -0.7527, -0.2726],\n",
            "        [ 0.6483,  0.9998,  0.8751,  ...,  0.8551, -0.8362, -0.4441]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6587,  0.9999,  0.9222,  ...,  0.8833, -0.6595, -0.4402],\n",
            "        [-0.2144,  0.9839, -0.7954,  ..., -0.8420,  0.3092,  0.0381],\n",
            "        [ 0.4718,  0.9994,  0.7588,  ...,  0.9149, -0.6764, -0.2929],\n",
            "        ...,\n",
            "        [ 0.6832,  1.0000,  0.9190,  ...,  0.7743, -0.3701, -0.7807],\n",
            "        [ 0.6693,  1.0000,  0.8828,  ..., -0.0411, -0.4415, -0.8753],\n",
            "        [-0.1744, -0.5264, -0.8827,  ..., -0.8634,  0.3937, -0.0227]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6170, -0.8381, -0.9522,  ..., -0.8390, -0.1246,  0.8279],\n",
            "        [ 0.7072,  1.0000,  0.9001,  ...,  0.7836, -0.4931, -0.4940],\n",
            "        [-0.1802,  1.0000,  0.4997,  ..., -0.3830,  0.1722, -0.9169],\n",
            "        ...,\n",
            "        [ 0.4423,  0.9996,  0.8676,  ...,  0.8521, -0.7848, -0.0552],\n",
            "        [ 0.2571,  1.0000,  0.7061,  ...,  0.3154,  0.7528, -0.7701],\n",
            "        [ 0.6100,  0.9992,  0.8390,  ...,  0.8960, -0.8516, -0.4700]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4678, -0.8657, -0.7400,  ..., -0.5902,  0.5078, -0.4736],\n",
            "        [-0.2448,  0.5008, -0.9193,  ..., -0.9423,  0.4462,  0.5395],\n",
            "        [-0.1852, -0.5902, -0.9596,  ..., -0.9071,  0.3115,  0.5627],\n",
            "        ...,\n",
            "        [-0.2238,  0.9722, -0.8001,  ..., -0.8106,  0.5952,  0.2544],\n",
            "        [-0.4485,  0.0553, -0.9464,  ..., -0.8917,  0.3189,  0.4490],\n",
            "        [-0.3728, -0.9903, -0.9426,  ..., -0.9147,  0.3001,  0.6046]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7370,  0.9926,  0.8796,  ...,  0.7854, -0.7355, -0.5297],\n",
            "        [-0.4228, -0.8089, -0.9493,  ..., -0.9414,  0.4010,  0.4731],\n",
            "        [-0.5778, -0.8487, -0.9167,  ..., -0.8252,  0.5885,  0.4930],\n",
            "        ...,\n",
            "        [ 0.3628,  0.9945,  0.3422,  ..., -0.5051,  0.3815, -0.3298],\n",
            "        [-0.5900, -0.7048, -0.9041,  ..., -0.8010,  0.4990,  0.4187],\n",
            "        [ 0.5398,  1.0000,  0.9258,  ...,  0.7266,  0.7328, -0.8722]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4342,  0.6361, -0.8878,  ..., -0.8176,  0.3038,  0.4982],\n",
            "        [ 0.4485,  0.9994,  0.7571,  ...,  0.8535, -0.7457, -0.3868],\n",
            "        [ 0.6942,  0.9955,  0.7643,  ...,  0.7220, -0.7814, -0.3347],\n",
            "        ...,\n",
            "        [-0.4618, -0.0822, -0.9339,  ..., -0.8965,  0.2699,  0.3999],\n",
            "        [-0.6204, -0.8973, -0.8849,  ..., -0.9173, -0.1260,  0.6838],\n",
            "        [-0.3452, -0.3261, -0.9374,  ..., -0.9039,  0.2656,  0.2898]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7770,  1.0000,  0.9659,  ...,  0.8725, -0.3537, -0.7474],\n",
            "        [ 0.6476,  0.9766,  0.8151,  ...,  0.8354, -0.8004, -0.3931],\n",
            "        [ 0.6396,  0.9999,  0.8266,  ...,  0.8786, -0.6507, -0.4885],\n",
            "        ...,\n",
            "        [-0.7415, -0.5420, -0.8984,  ..., -0.8919,  0.1241,  0.6626],\n",
            "        [ 0.5385,  0.9999,  0.8960,  ...,  0.7388, -0.7379, -0.4904],\n",
            "        [ 0.6181,  0.9953,  0.8735,  ...,  0.8781, -0.8000, -0.2467]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1188,  0.9979, -0.9079,  ..., -0.8308,  0.7083,  0.0231],\n",
            "        [ 0.6460,  0.9983,  0.8782,  ...,  0.8578, -0.7557, -0.1668],\n",
            "        [-0.4929,  0.8656, -0.8927,  ..., -0.9576,  0.2871,  0.4360],\n",
            "        ...,\n",
            "        [ 0.6251,  0.9997,  0.8375,  ...,  0.8019, -0.8110, -0.3219],\n",
            "        [ 0.6059,  0.9988,  0.8334,  ...,  0.6056, -0.8675, -0.4608],\n",
            "        [-0.5455, -0.6362, -0.9371,  ..., -0.7331,  0.0253,  0.5806]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3380,  0.9962,  0.9146,  ...,  0.8404, -0.7681, -0.2202],\n",
            "        [ 0.7758,  0.9994,  0.8734,  ...,  0.8639, -0.6966, -0.7091],\n",
            "        [-0.4347, -0.9857, -0.9402,  ..., -0.9187,  0.0345,  0.5267],\n",
            "        ...,\n",
            "        [-0.4940,  0.2935, -0.8876,  ..., -0.6540,  0.1675,  0.2985],\n",
            "        [ 0.6817,  1.0000,  0.9566,  ...,  0.8294, -0.5890, -0.7467],\n",
            "        [-0.7047,  0.8517, -0.9166,  ..., -0.8907,  0.3994,  0.5581]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6562,  0.8778, -0.8920,  ..., -0.8942, -0.1948,  0.4135],\n",
            "        [-0.6068, -0.8348, -0.9327,  ..., -0.8958,  0.2399,  0.7217],\n",
            "        [-0.7251,  0.9169, -0.9352,  ..., -0.8999,  0.3072,  0.8412],\n",
            "        ...,\n",
            "        [ 0.6103,  0.9977,  0.9037,  ...,  0.8518, -0.8329, -0.3463],\n",
            "        [ 0.5701,  0.9998,  0.8368,  ...,  0.8757, -0.7608, -0.7560],\n",
            "        [ 0.7742,  1.0000,  0.9512,  ...,  0.8805, -0.4728, -0.7347]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6564,  0.5199, -0.9337,  ..., -0.8746,  0.1462,  0.7889],\n",
            "        [-0.3966,  0.7358, -0.8538,  ..., -0.8082,  0.2955,  0.0112],\n",
            "        [ 0.5155,  1.0000,  0.9110,  ...,  0.1753,  0.5976, -0.9738],\n",
            "        ...,\n",
            "        [ 0.4352,  0.9987,  0.7221,  ...,  0.8403, -0.7703, -0.1625],\n",
            "        [-0.4399, -0.8860, -0.9572,  ..., -0.8544,  0.1751,  0.3516],\n",
            "        [ 0.5745,  0.9999,  0.8926,  ...,  0.7863, -0.7341, -0.4042]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5060,  0.9996,  0.7047,  ...,  0.8294, -0.8772, -0.2934],\n",
            "        [ 0.6050,  0.9992,  0.8066,  ...,  0.8146, -0.8147, -0.2951],\n",
            "        [ 0.6000,  0.9999,  0.8869,  ...,  0.7973, -0.3669, -0.7609],\n",
            "        ...,\n",
            "        [-0.6315, -0.0109, -0.8451,  ..., -0.8637,  0.2782,  0.4272],\n",
            "        [ 0.7018,  0.9996,  0.9315,  ...,  0.8912, -0.7388, -0.4735],\n",
            "        [-0.3687, -0.6095, -0.9453,  ..., -0.8843,  0.1734,  0.5732]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.8513,  1.0000,  0.9634,  ...,  0.8450, -0.1659, -0.8774],\n",
            "        [ 0.5033,  1.0000,  0.7815,  ...,  0.7943, -0.6327, -0.5791],\n",
            "        [ 0.7125,  0.9999,  0.9084,  ...,  0.8202, -0.7447, -0.8386],\n",
            "        ...,\n",
            "        [ 0.7416,  0.9991,  0.8344,  ...,  0.8983, -0.8435, -0.4127],\n",
            "        [-0.6041, -0.7213, -0.8855,  ..., -0.8085,  0.0082,  0.7256],\n",
            "        [ 0.2723,  1.0000,  0.9126,  ...,  0.2449,  0.5746, -0.8310]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4669,  0.7292, -0.9378,  ..., -0.8456,  0.5330,  0.2675],\n",
            "        [-0.0782,  0.7191, -0.9030,  ..., -0.8557,  0.5778,  0.0288],\n",
            "        [-0.5707, -0.6713, -0.9057,  ..., -0.8284,  0.2783,  0.6390],\n",
            "        ...,\n",
            "        [ 0.6973,  0.9999,  0.9146,  ...,  0.9139, -0.7998, -0.5966],\n",
            "        [ 0.5436,  0.9990,  0.7096,  ...,  0.7987, -0.8407, -0.2579],\n",
            "        [ 0.8025,  0.9996,  0.9376,  ...,  0.9024, -0.8166, -0.5342]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3447, -0.9674, -0.9140,  ..., -0.6398,  0.1518,  0.6915],\n",
            "        [ 0.7534,  1.0000,  0.9245,  ...,  0.9076, -0.2896, -0.8625],\n",
            "        [-0.5827, -0.5627, -0.9694,  ..., -0.9046,  0.0339,  0.5062],\n",
            "        ...,\n",
            "        [-0.4382,  0.9998, -0.7677,  ..., -0.8950,  0.6297, -0.6126],\n",
            "        [-0.3811, -0.9164, -0.9141,  ..., -0.8107,  0.2565,  0.6151],\n",
            "        [ 0.5611,  0.9997,  0.8289,  ...,  0.9166, -0.7178, -0.1035]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6068,  0.9993,  0.9156,  ...,  0.8901, -0.7482, -0.5518],\n",
            "        [ 0.6193,  0.9998,  0.8543,  ...,  0.9032, -0.7172, -0.2875],\n",
            "        [ 0.8594,  1.0000,  0.8790,  ...,  0.8054, -0.4903, -0.7747],\n",
            "        ...,\n",
            "        [-0.5673, -0.6033, -0.9256,  ..., -0.8964,  0.3386,  0.3923],\n",
            "        [ 0.6708,  0.9995,  0.8570,  ...,  0.8505, -0.8074, -0.3650],\n",
            "        [ 0.6659,  0.9981,  0.8780,  ...,  0.8853, -0.7864, -0.2933]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4122, -0.1487, -0.9547,  ..., -0.8640,  0.2798,  0.6383],\n",
            "        [-0.0549, -0.9622, -0.9270,  ..., -0.8632,  0.2840,  0.5817],\n",
            "        [ 0.0449,  0.9975, -0.8619,  ..., -0.9250,  0.6374, -0.6970],\n",
            "        ...,\n",
            "        [-0.7349, -0.9928, -0.9443,  ..., -0.9015,  0.2114,  0.4937],\n",
            "        [ 0.5612,  0.9983,  0.8675,  ...,  0.8466, -0.7495, -0.4557],\n",
            "        [-0.4060, -0.9965, -0.9334,  ..., -0.9127,  0.2233,  0.6803]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4081,  1.0000, -0.0325,  ..., -0.8358,  0.5675, -0.8464],\n",
            "        [ 0.5278,  0.9990,  0.8582,  ...,  0.8804, -0.7967, -0.2132],\n",
            "        [-0.4460, -0.9475, -0.9529,  ..., -0.8374,  0.2297,  0.5793],\n",
            "        ...,\n",
            "        [ 0.6417,  1.0000,  0.9682,  ...,  0.8406, -0.5584, -0.8136],\n",
            "        [-0.4285,  0.8992, -0.9007,  ..., -0.7733,  0.2527,  0.6765],\n",
            "        [ 0.6249,  0.9996,  0.9298,  ...,  0.9084, -0.6108, -0.6012]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5694,  1.0000,  0.7892,  ..., -0.1834,  0.1966, -0.9057],\n",
            "        [ 0.1789,  0.9999,  0.7067,  ..., -0.5962,  0.4354, -0.8916],\n",
            "        [-0.5589, -0.9758, -0.9360,  ..., -0.8964,  0.1646,  0.4144],\n",
            "        ...,\n",
            "        [ 0.5544,  0.9980,  0.9167,  ...,  0.9087, -0.7592, -0.3454],\n",
            "        [-0.6016,  0.5337, -0.9141,  ..., -0.8994,  0.3001,  0.6219],\n",
            "        [ 0.6341,  0.9999,  0.8404,  ...,  0.9124, -0.7195, -0.6900]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6715,  1.0000,  0.8332,  ...,  0.7229, -0.7273, -0.5954],\n",
            "        [ 0.7162,  0.9998,  0.8848,  ...,  0.8539, -0.9131, -0.4185],\n",
            "        [-0.6063, -0.6318, -0.9205,  ..., -0.9472,  0.0200,  0.7320],\n",
            "        ...,\n",
            "        [ 0.4078,  1.0000,  0.6303,  ...,  0.6032,  0.6844, -0.6595],\n",
            "        [ 0.7239,  0.9989,  0.8748,  ...,  0.9021, -0.8093, -0.6146],\n",
            "        [-0.6876, -0.8465, -0.9441,  ..., -0.8673,  0.4594,  0.6639]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.7433, -0.8223, -0.9379,  ..., -0.9319,  0.1690,  0.7032],\n",
            "        [ 0.4963,  1.0000,  0.8097,  ...,  0.8240, -0.7968, -0.5132],\n",
            "        [ 0.6214,  0.9999,  0.9136,  ...,  0.6518, -0.1568, -0.7475],\n",
            "        ...,\n",
            "        [ 0.5552,  0.9995,  0.8827,  ...,  0.8039, -0.7392, -0.7333],\n",
            "        [ 0.5902,  1.0000,  0.8794,  ...,  0.8971, -0.8707, -0.6082],\n",
            "        [-0.6796,  0.8127, -0.8715,  ..., -0.9055,  0.3160,  0.5269]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4330, -0.9999, -0.9295,  ..., -0.9221,  0.0851,  0.6618],\n",
            "        [-0.7481, -0.9995, -0.9571,  ..., -0.9491,  0.4310,  0.6692],\n",
            "        [-0.5877, -0.8563, -0.9263,  ..., -0.8635,  0.5452,  0.6344],\n",
            "        ...,\n",
            "        [-0.7304,  0.7493, -0.9151,  ..., -0.8498,  0.3509,  0.0831],\n",
            "        [-0.6425, -0.8446, -0.9084,  ..., -0.9075, -0.1152,  0.6534],\n",
            "        [-0.5117, -0.8184, -0.9134,  ..., -0.8549,  0.5500,  0.5490]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4224, -0.8176, -0.8600,  ..., -0.8472, -0.0237,  0.5347],\n",
            "        [-0.4058, -0.6911, -0.9084,  ..., -0.8950,  0.1811, -0.0972],\n",
            "        [-0.3518, -0.9916, -0.9244,  ..., -0.9252,  0.1696,  0.5984],\n",
            "        ...,\n",
            "        [ 0.6871,  1.0000,  0.9340,  ...,  0.2651,  0.3333, -0.9829],\n",
            "        [-0.6106, -0.9932, -0.9411,  ..., -0.9101,  0.0692,  0.6463],\n",
            "        [ 0.5935,  1.0000,  0.8879,  ...,  0.2508,  0.3604, -0.9832]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6524, -0.4142, -0.9514,  ..., -0.8878,  0.2501,  0.4114],\n",
            "        [ 0.6874,  0.9998,  0.9249,  ...,  0.8574, -0.7902, -0.4194],\n",
            "        [-0.5927,  0.7785, -0.8868,  ..., -0.8348,  0.0708,  0.5983],\n",
            "        ...,\n",
            "        [-0.1702, -0.8877, -0.9266,  ..., -0.9154,  0.2518,  0.4406],\n",
            "        [ 0.6939,  0.9999,  0.9204,  ...,  0.8180, -0.6832, -0.6813],\n",
            "        [-0.6237, -0.7024, -0.8988,  ..., -0.8853,  0.3746,  0.3880]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4748,  0.2945, -0.9173,  ..., -0.8584,  0.3456,  0.4376],\n",
            "        [ 0.6482,  0.9999,  0.9343,  ...,  0.8335, -0.8097, -0.3910],\n",
            "        [ 0.6851,  0.9999,  0.9254,  ...,  0.9070, -0.8236, -0.3099],\n",
            "        ...,\n",
            "        [-0.5245, -0.3016, -0.9162,  ..., -0.8865, -0.0625,  0.8571],\n",
            "        [-0.5438, -0.9080, -0.9176,  ..., -0.8771, -0.0407,  0.6120],\n",
            "        [ 0.7000,  0.9987,  0.8678,  ...,  0.8649, -0.8452, -0.5438]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4979,  0.7551, -0.9287,  ..., -0.9467,  0.5118,  0.4537],\n",
            "        [-0.5237, -0.9925, -0.9093,  ..., -0.9296,  0.2329,  0.6961],\n",
            "        [ 0.6651,  1.0000, -0.1664,  ..., -0.8040,  0.7372, -0.9677],\n",
            "        ...,\n",
            "        [-0.5940,  0.9978, -0.6533,  ..., -0.5945,  0.2756, -0.1168],\n",
            "        [ 0.5343,  0.9994,  0.7507,  ...,  0.4482, -0.7316, -0.8235],\n",
            "        [ 0.7185,  0.9998,  0.9121,  ...,  0.8890, -0.6621, -0.5006]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7000,  0.9998,  0.8938,  ...,  0.8525, -0.7447, -0.4515],\n",
            "        [ 0.4719,  1.0000, -0.2840,  ..., -0.3151,  0.1785, -0.6657],\n",
            "        [-0.6083,  0.5584, -0.8540,  ..., -0.9113,  0.2187,  0.5940],\n",
            "        ...,\n",
            "        [-0.6289, -0.9730, -0.9339,  ..., -0.8635,  0.1601,  0.7346],\n",
            "        [-0.6383, -0.0459, -0.9292,  ..., -0.7868,  0.6295,  0.3986],\n",
            "        [ 0.7024,  0.9999,  0.9101,  ...,  0.7988, -0.6122, -0.5703]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7765,  0.9991,  0.8965,  ...,  0.8619, -0.8100, -0.3960],\n",
            "        [ 0.5328,  1.0000,  0.9135,  ...,  0.7806, -0.4975, -0.7697],\n",
            "        [ 0.7817,  1.0000,  0.9608,  ...,  0.8257, -0.4488, -0.7843],\n",
            "        ...,\n",
            "        [ 0.7941,  1.0000,  0.9402,  ...,  0.7684,  0.3957, -0.9703],\n",
            "        [ 0.6874,  0.9999,  0.8265,  ...,  0.8018, -0.6948, -0.2784],\n",
            "        [-0.5855, -0.2412, -0.6417,  ..., -0.7148, -0.1222,  0.5191]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4597,  0.9767, -0.9516,  ..., -0.8497,  0.2865,  0.5927],\n",
            "        [ 0.7458,  1.0000,  0.9364,  ...,  0.7008, -0.1676, -0.9185],\n",
            "        [ 0.5579,  1.0000,  0.9063,  ..., -0.0111, -0.0527, -0.9054],\n",
            "        ...,\n",
            "        [ 0.7233,  0.9978,  0.9048,  ...,  0.7663, -0.7584, -0.4205],\n",
            "        [ 0.7106,  1.0000,  0.9451,  ...,  0.8775, -0.5345, -0.7365],\n",
            "        [-0.2443, -0.8600, -0.9565,  ..., -0.7989,  0.3227,  0.4307]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2644,  1.0000,  0.4764,  ...,  0.1309, -0.1707, -0.8265],\n",
            "        [ 0.6787,  0.9998,  0.8513,  ...,  0.8066, -0.7669, -0.6654],\n",
            "        [-0.2607, -0.2872, -0.9650,  ..., -0.9090,  0.2454,  0.6476],\n",
            "        ...,\n",
            "        [-0.4361,  0.1766, -0.9354,  ..., -0.8706,  0.1583,  0.4641],\n",
            "        [ 0.5042,  0.9992,  0.8907,  ...,  0.9057, -0.6364, -0.4956],\n",
            "        [ 0.8973,  0.9999,  0.9380,  ...,  0.8149, -0.3832, -0.7783]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1962,  0.9984, -0.8441,  ..., -0.8372,  0.3101, -0.4566],\n",
            "        [ 0.7377,  0.9999, -0.7025,  ..., -0.5495,  0.4351, -0.6003],\n",
            "        [ 0.1054,  0.9999,  0.9059,  ...,  0.6417, -0.6061, -0.7647],\n",
            "        ...,\n",
            "        [ 0.7685,  0.9999,  0.8967,  ...,  0.8130, -0.5727, -0.6853],\n",
            "        [-0.5962, -0.9203, -0.9407,  ..., -0.9486, -0.1905,  0.5950],\n",
            "        [-0.2089, -0.7750, -0.9036,  ..., -0.7860,  0.1577,  0.2355]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3936, -0.9807, -0.9294,  ..., -0.8427,  0.1510,  0.5270],\n",
            "        [ 0.6165,  0.9999,  0.9421,  ...,  0.8624, -0.5745, -0.7192],\n",
            "        [-0.4818,  0.5662, -0.9216,  ..., -0.9068, -0.2680,  0.5928],\n",
            "        ...,\n",
            "        [ 0.6651,  0.9992,  0.8403,  ...,  0.8743, -0.7371, -0.5649],\n",
            "        [-0.4824, -0.8820, -0.9329,  ..., -0.8966,  0.1771,  0.5321],\n",
            "        [ 0.8012,  1.0000,  0.9381,  ...,  0.8842, -0.5227, -0.7310]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6478,  0.9986,  0.8347,  ...,  0.8850, -0.8140, -0.2210],\n",
            "        [ 0.5065,  0.9990,  0.8590,  ...,  0.8863, -0.7898, -0.2266],\n",
            "        [-0.7481, -0.9933, -0.9607,  ..., -0.9441,  0.2345,  0.8892],\n",
            "        ...,\n",
            "        [-0.6919, -0.9953, -0.9152,  ..., -0.9507, -0.0742,  0.4922],\n",
            "        [-0.6310,  0.8873, -0.8347,  ..., -0.8130, -0.0225,  0.0374],\n",
            "        [-0.3459, -0.2420, -0.9495,  ..., -0.8668,  0.3586,  0.2398]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6621, -0.9814, -0.9421,  ..., -0.9039,  0.3281,  0.7938],\n",
            "        [ 0.7974,  0.9939,  0.7992,  ...,  0.8102, -0.8396, -0.2851],\n",
            "        [ 0.4368,  0.9993,  0.7924,  ...,  0.8965, -0.7764, -0.0129],\n",
            "        ...,\n",
            "        [ 0.6494,  0.9997,  0.8602,  ...,  0.8579, -0.8062, -0.4070],\n",
            "        [ 0.4716,  0.9999,  0.8546,  ...,  0.7767, -0.7327, -0.7130],\n",
            "        [-0.5573, -0.6066, -0.9408,  ..., -0.9025,  0.2056,  0.7562]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5857,  0.9997,  0.8765,  ...,  0.8802, -0.8324, -0.3067],\n",
            "        [ 0.6412,  1.0000,  0.9145,  ...,  0.7270, -0.2278, -0.7634],\n",
            "        [ 0.7165,  1.0000,  0.9603,  ...,  0.7193,  0.1101, -0.9777],\n",
            "        ...,\n",
            "        [ 0.6548,  1.0000,  0.9205,  ...,  0.7545, -0.7481, -0.5493],\n",
            "        [-0.0097,  0.9805, -0.9375,  ..., -0.8483,  0.3251,  0.2159],\n",
            "        [ 0.7007,  0.9998,  0.9253,  ...,  0.9059, -0.7999, -0.4381]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5750, -0.9248, -0.9211,  ..., -0.9191,  0.5515,  0.5533],\n",
            "        [ 0.7728,  0.9996,  0.8553,  ...,  0.8748, -0.7604, -0.5505],\n",
            "        [ 0.4396,  1.0000,  0.8373,  ...,  0.2545,  0.3976, -0.9565],\n",
            "        ...,\n",
            "        [-0.4763, -0.5017, -0.8677,  ..., -0.9104,  0.1765,  0.4042],\n",
            "        [-0.6837, -0.9468, -0.9596,  ..., -0.7991,  0.1947,  0.6470],\n",
            "        [-0.6390, -0.9358, -0.9548,  ..., -0.9315, -0.2960,  0.5566]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2312, -0.6859, -0.8384,  ..., -0.8707, -0.2445,  0.7261],\n",
            "        [-0.3141, -0.8828, -0.9534,  ..., -0.9231,  0.0447,  0.4748],\n",
            "        [ 0.7145,  0.9975,  0.6169,  ...,  0.8375, -0.7540, -0.7063],\n",
            "        ...,\n",
            "        [-0.4513, -0.7071, -0.8100,  ..., -0.7953,  0.2471,  0.3808],\n",
            "        [-0.3547, -0.5141, -0.9074,  ..., -0.8899,  0.2825,  0.6581],\n",
            "        [ 0.7796,  1.0000,  0.8677,  ...,  0.8871, -0.5308, -0.7442]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6945,  0.0512, -0.8884,  ..., -0.7635, -0.0193,  0.8238],\n",
            "        [-0.7507, -0.9191, -0.9240,  ..., -0.8358,  0.4711,  0.3575],\n",
            "        [ 0.6261,  0.9997,  0.8207,  ...,  0.8328, -0.7222, -0.3503],\n",
            "        ...,\n",
            "        [-0.6496,  0.3292, -0.9306,  ..., -0.8854,  0.1997,  0.6080],\n",
            "        [ 0.7380,  0.9999,  0.9264,  ...,  0.9040, -0.7143, -0.6105],\n",
            "        [-0.6277,  0.4134, -0.9298,  ..., -0.8869,  0.1680,  0.7282]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4337, -0.9796, -0.9117,  ..., -0.8940,  0.2841,  0.6635],\n",
            "        [-0.3748,  0.9995, -0.1833,  ..., -0.5244,  0.6440, -0.5542],\n",
            "        [ 0.1424,  0.9785, -0.8749,  ..., -0.9137,  0.3634, -0.1585],\n",
            "        ...,\n",
            "        [ 0.7412,  1.0000,  0.8551,  ...,  0.8556, -0.6558, -0.6545],\n",
            "        [-0.0199,  0.9755, -0.8787,  ..., -0.7636,  0.6959,  0.2414],\n",
            "        [-0.5641,  0.9637, -0.8305,  ..., -0.8234,  0.6012, -0.1237]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluation... :   0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f267748ea5d4da1917de0ceb1af462f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7573,  0.9944,  0.8929,  ...,  0.8772, -0.8054, -0.4004],\n",
            "        [ 0.7848,  1.0000,  0.9641,  ...,  0.7786,  0.1939, -0.9662],\n",
            "        [ 0.8246,  1.0000, -0.0394,  ..., -0.7077,  0.6683, -0.8578],\n",
            "        ...,\n",
            "        [ 0.3859,  0.9994,  0.7983,  ...,  0.8209, -0.7904, -0.2453],\n",
            "        [-0.0564,  0.9865, -0.7072,  ..., -0.8595,  0.5607, -0.1889],\n",
            "        [-0.6940, -0.2959, -0.9169,  ..., -0.7557,  0.2989,  0.6281]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4222,  0.9960, -0.8678,  ..., -0.8885,  0.3816,  0.1913],\n",
            "        [ 0.7101,  1.0000,  0.7276,  ...,  0.4473, -0.7835, -0.3526],\n",
            "        [ 0.1452,  0.9964, -0.0258,  ..., -0.7270,  0.5894, -0.8234],\n",
            "        ...,\n",
            "        [-0.2664,  0.9927, -0.3662,  ..., -0.7255,  0.1976, -0.6935],\n",
            "        [-0.6129,  0.9999, -0.5320,  ..., -0.8739,  0.3508,  0.0036],\n",
            "        [ 0.4302,  1.0000,  0.5779,  ..., -0.7405,  0.6957, -0.9576]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6761,  1.0000,  0.9404,  ...,  0.8515, -0.5849, -0.7576],\n",
            "        [ 0.3483,  1.0000,  0.8039,  ...,  0.4155,  0.6799, -0.8653],\n",
            "        [ 0.5903,  1.0000,  0.8660,  ...,  0.8661, -0.7171, -0.5982],\n",
            "        ...,\n",
            "        [-0.1652,  1.0000,  0.0310,  ..., -0.8903,  0.5616, -0.8160],\n",
            "        [-0.7750, -0.3878, -0.9067,  ..., -0.9214,  0.2586,  0.4827],\n",
            "        [ 0.4669,  1.0000,  0.5946,  ..., -0.0272,  0.2216, -0.9512]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0587,  0.9988,  0.0145,  ..., -0.2339, -0.6203, -0.6989],\n",
            "        [-0.1352,  1.0000,  0.7420,  ..., -0.4552,  0.1895, -0.9565],\n",
            "        [-0.0799,  0.9999, -0.5036,  ..., -0.8226,  0.3959, -0.8498],\n",
            "        ...,\n",
            "        [ 0.7752,  1.0000,  0.9344,  ...,  0.8695, -0.3792, -0.7458],\n",
            "        [-0.1807, -0.3704, -0.8197,  ..., -0.9111,  0.6452, -0.2011],\n",
            "        [ 0.6602,  0.9987,  0.8878,  ...,  0.9038, -0.8508, -0.3646]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6990,  1.0000,  0.7431,  ...,  0.7209, -0.4320, -0.3428],\n",
            "        [ 0.4614,  1.0000,  0.8539,  ...,  0.8773, -0.4655, -0.5668],\n",
            "        [-0.5346,  0.3871, -0.8805,  ..., -0.7548,  0.3666,  0.4936],\n",
            "        ...,\n",
            "        [ 0.5456,  0.9999,  0.5652,  ...,  0.7110, -0.4646, -0.8431],\n",
            "        [ 0.5010,  1.0000,  0.8905,  ...,  0.3838, -0.5172, -0.6478],\n",
            "        [ 0.7591,  0.9998,  0.9573,  ...,  0.5844, -0.3366, -0.7705]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5642,  0.9995,  0.8928,  ...,  0.8903, -0.7906, -0.4646],\n",
            "        [ 0.7778,  1.0000,  0.6515,  ...,  0.5964, -0.5859, -0.8748],\n",
            "        [-0.0846, -0.0220, -0.9648,  ..., -0.9086,  0.6009,  0.1332],\n",
            "        ...,\n",
            "        [ 0.6960,  0.9994, -0.7415,  ..., -0.7583,  0.7152, -0.4343],\n",
            "        [ 0.3046,  1.0000,  0.1244,  ...,  0.1107, -0.3851, -0.6624],\n",
            "        [ 0.0797,  1.0000,  0.4578,  ..., -0.1273, -0.3730, -0.9019]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0625,  0.9826, -0.5764,  ..., -0.7960, -0.2671, -0.5999],\n",
            "        [-0.5734, -0.8125, -0.9489,  ..., -0.9327,  0.0984,  0.7187],\n",
            "        [ 0.6475,  0.9975,  0.8335,  ...,  0.9041, -0.8038, -0.3893],\n",
            "        ...,\n",
            "        [-0.2494,  1.0000, -0.3400,  ..., -0.8014, -0.3566, -0.5094],\n",
            "        [ 0.6454,  0.9991,  0.9273,  ...,  0.9137, -0.8272, -0.4296],\n",
            "        [-0.4206,  0.9043, -0.8533,  ..., -0.8329,  0.0977,  0.4016]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6616,  0.9998,  0.9010,  ...,  0.8961, -0.7717, -0.5207],\n",
            "        [ 0.7240,  0.9998,  0.9406,  ...,  0.9235, -0.7183, -0.6024],\n",
            "        [ 0.6995,  1.0000,  0.9346,  ...,  0.8159,  0.1226, -0.9410],\n",
            "        ...,\n",
            "        [ 0.6207,  0.9961,  0.8980,  ...,  0.8790, -0.8702, -0.2907],\n",
            "        [ 0.4593,  0.9996,  0.7918,  ...,  0.8362, -0.7776, -0.6311],\n",
            "        [ 0.5846,  1.0000,  0.7949,  ...,  0.6208, -0.5699, -0.6541]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.8161,  1.0000,  0.9589,  ...,  0.8506, -0.2265, -0.9021],\n",
            "        [-0.0866,  0.9961, -0.8839,  ..., -0.8340,  0.2611, -0.1497],\n",
            "        [-0.8301, -0.9743, -0.8297,  ..., -0.9093,  0.1167,  0.3268],\n",
            "        ...,\n",
            "        [ 0.6971,  0.9998,  0.8963,  ...,  0.8768, -0.7452, -0.4230],\n",
            "        [-0.6711, -0.7538, -0.9284,  ..., -0.9017,  0.2459,  0.7846],\n",
            "        [ 0.5592,  0.9971,  0.8887,  ...,  0.8637, -0.8090, -0.3109]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5353, -0.6313, -0.9532,  ..., -0.8866,  0.1492,  0.5139],\n",
            "        [ 0.1005,  1.0000,  0.1656,  ..., -0.5982,  0.1179, -0.8239],\n",
            "        [ 0.6557,  0.9998,  0.9266,  ...,  0.8982, -0.7464, -0.6108],\n",
            "        ...,\n",
            "        [ 0.7199,  0.9986,  0.8285,  ...,  0.8962, -0.8400, -0.3417],\n",
            "        [ 0.4922,  0.9999,  0.8644,  ...,  0.7415, -0.5522, -0.3013],\n",
            "        [ 0.7340,  1.0000,  0.9358,  ...,  0.7552,  0.2408, -0.9603]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2068,  0.4967, -0.9031,  ..., -0.8681,  0.3594,  0.3731],\n",
            "        [-0.5325, -0.9600, -0.9199,  ..., -0.9367,  0.1570,  0.5132],\n",
            "        [-0.6857,  0.7233, -0.9671,  ..., -0.9439, -0.0562,  0.3722],\n",
            "        ...,\n",
            "        [ 0.6761,  1.0000,  0.8567,  ...,  0.6925, -0.5900, -0.8284],\n",
            "        [ 0.7218,  1.0000, -0.5142,  ..., -0.5315,  0.5580, -0.8846],\n",
            "        [ 0.5332,  0.9991,  0.9075,  ...,  0.8932, -0.8056, -0.3255]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3559,  1.0000,  0.7470,  ..., -0.1547,  0.1508, -0.8647],\n",
            "        [-0.5150, -0.9073, -0.9549,  ..., -0.9051,  0.2519,  0.6247],\n",
            "        [-0.7075,  0.9186, -0.9263,  ..., -0.9025,  0.2346,  0.1452],\n",
            "        ...,\n",
            "        [-0.5876,  0.9310, -0.9417,  ..., -0.9094,  0.2735,  0.5790],\n",
            "        [ 0.1135,  1.0000,  0.1338,  ..., -0.6307, -0.0195, -0.8099],\n",
            "        [-0.2966,  0.9997, -0.7394,  ..., -0.9146,  0.5032, -0.3521]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1395,  0.9943, -0.7886,  ..., -0.4334,  0.7085,  0.3247],\n",
            "        [ 0.3564,  1.0000,  0.6758,  ...,  0.0746, -0.0484, -0.8864],\n",
            "        [-0.6428, -0.9454, -0.8694,  ..., -0.9129,  0.4225,  0.4530],\n",
            "        ...,\n",
            "        [-0.7480,  0.9903, -0.9302,  ..., -0.7428,  0.5960,  0.3594],\n",
            "        [-0.0757,  0.9961, -0.9279,  ..., -0.8603,  0.4351, -0.2377],\n",
            "        [-0.6427,  1.0000, -0.7492,  ..., -0.8179,  0.4399, -0.6071]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7831,  1.0000,  0.9216,  ...,  0.4682, -0.3481, -0.7664],\n",
            "        [ 0.5948,  1.0000,  0.8085,  ...,  0.2464, -0.1929, -0.8474],\n",
            "        [-0.6686, -0.4582, -0.9357,  ..., -0.8555, -0.1136,  0.5330],\n",
            "        ...,\n",
            "        [ 0.4399,  1.0000,  0.5565,  ..., -0.2323, -0.4078, -0.7376],\n",
            "        [ 0.5124,  1.0000,  0.7912,  ...,  0.8056, -0.3171, -0.6497],\n",
            "        [-0.5617,  0.9922, -0.6154,  ..., -0.7790,  0.1315, -0.4367]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4720,  1.0000,  0.7426, -0.9575, -0.4396,  0.9323,  0.7107,  0.7927,\n",
            "         -0.9976, -0.6089,  0.8101, -0.5701,  0.4251,  0.9992,  0.3841, -0.1206,\n",
            "          0.7225, -0.9739,  0.6842, -0.2587,  0.3024, -0.7835,  0.8248, -0.3888,\n",
            "          0.8088,  0.7381, -0.4996,  0.5542, -0.1967,  0.2721, -0.6238, -0.2438,\n",
            "          0.9339,  0.6440,  0.8074, -0.9416, -0.3270, -0.9565, -0.9842, -0.9971,\n",
            "          0.2061, -0.4339,  0.9996, -0.8267,  0.9960, -0.9901,  0.5309, -0.3483,\n",
            "          0.6081,  0.4533, -0.7215,  0.9368,  0.7833,  0.8491, -0.6237, -0.8470,\n",
            "         -0.8081,  0.4879, -0.8717, -0.4976,  0.7937,  0.7193, -0.5846, -0.0449,\n",
            "         -0.8746, -0.5146,  0.5788,  0.4752, -0.6918, -0.9388,  0.8469, -0.9285,\n",
            "          0.6660,  0.1618, -0.2790,  0.8310, -0.8712,  0.8951, -0.7839,  0.9917,\n",
            "          0.6695,  0.4334,  0.6550, -1.0000,  0.6796, -0.8960,  0.9856, -0.9839,\n",
            "         -0.9609,  0.7042,  0.7965,  0.6653,  0.7872, -0.1104, -0.4214, -0.9057,\n",
            "         -0.6469,  0.5495, -0.9987,  0.7849,  0.6619,  0.7719, -0.6793, -0.6161,\n",
            "         -0.9992,  0.4886, -0.6140, -0.5296, -0.9999, -0.7269, -0.8244, -0.8180,\n",
            "         -0.3271,  0.8947,  0.5309,  0.9997,  0.8671,  0.9984, -1.0000, -0.9935,\n",
            "          0.0695,  0.9365, -0.6358, -0.0475,  0.5732, -0.9689,  0.6242, -0.9982,\n",
            "          0.7091, -0.9343, -0.5194,  0.8119,  0.8878,  0.4590, -0.6354,  0.5535,\n",
            "         -0.9997,  0.0498, -0.7178, -0.9921,  0.9922,  0.8632,  0.8499, -0.4728,\n",
            "         -0.3718,  0.8509,  0.8545, -0.6828,  0.0897, -0.2349, -0.8187,  0.8117,\n",
            "          0.4265, -0.4619, -1.0000,  0.5075, -0.6795,  0.9469, -0.9871,  0.9753,\n",
            "         -0.9732, -1.0000,  0.4078,  0.3341, -0.7746,  0.7944, -0.8078,  0.8899,\n",
            "         -0.5994,  0.6875,  0.6624,  0.6548,  0.3956, -0.5245,  0.3272, -0.7340,\n",
            "          0.7751, -0.7478, -0.6032, -0.9601,  0.9704, -0.4605,  0.9802, -0.9501,\n",
            "         -0.7471,  0.5234,  0.2231, -1.0000,  0.9228,  0.4965,  0.3992,  0.5550,\n",
            "          0.3102, -0.4717,  0.0556,  0.0337, -0.5395,  0.6899, -0.3052,  0.9077,\n",
            "          0.3375, -0.9995,  0.8223,  0.9928,  0.1972, -0.4387,  0.0710,  0.9806,\n",
            "         -0.9969, -0.6722,  0.1878, -0.5360,  0.4604,  0.4293, -0.4670, -0.7562,\n",
            "          0.6528,  0.3150, -0.0933, -0.4687,  0.3231,  0.6029, -0.3477,  0.4386,\n",
            "          0.7538,  0.9992, -0.5206, -0.5681,  0.6169, -0.9996,  0.8214,  0.5209,\n",
            "         -0.3129, -0.6782,  0.9900,  0.7807,  0.6649,  0.9864, -0.9552, -0.2778,\n",
            "         -0.5995,  0.8553, -0.3929, -0.0736,  1.0000, -0.9939,  0.9850,  0.9091,\n",
            "         -0.0038, -0.4073,  0.6529,  0.3127, -0.2559, -0.0349, -0.6539,  0.9931,\n",
            "         -0.6492, -0.9834,  0.5354, -0.1272, -0.9213, -0.8428,  0.8054, -0.5875,\n",
            "          0.9786,  0.9999,  0.7471,  0.5005,  0.7153,  0.5798,  0.7842, -0.9836,\n",
            "          0.9649,  1.0000, -0.9476,  0.3855,  0.9999,  0.6802, -0.2751, -0.5713,\n",
            "          0.3125, -0.9795, -0.2014, -0.5163, -0.4485, -0.5325,  0.0044, -0.9420,\n",
            "         -0.9993, -0.9851,  0.9723, -0.7008, -0.6271,  0.5694, -0.7479,  0.4161,\n",
            "         -0.6779,  0.9910, -0.7403,  0.9999,  0.6397, -0.6575, -0.9634, -0.3394,\n",
            "          0.5662,  0.1399,  0.9991,  0.0783, -0.6630,  0.7692,  0.6667,  0.2816,\n",
            "          0.9290, -0.6246,  0.6503,  0.3959,  0.0906, -0.9544, -0.3561, -0.8514,\n",
            "          0.8062,  0.9670,  0.7083,  0.1877,  0.9637,  0.8263, -1.0000,  0.9990,\n",
            "          0.9790, -0.9923,  0.8243, -0.1477,  0.8914, -0.1606,  0.4751, -0.8880,\n",
            "         -0.8347, -0.9806,  0.7952,  0.2169, -0.6888,  0.3230, -0.9034,  0.8037,\n",
            "          0.1386,  0.8290, -0.2816,  0.0760, -0.9960,  0.6624,  0.8730, -0.1894,\n",
            "          0.7517,  0.9866,  0.0579,  1.0000, -0.7716, -0.3535,  0.1710,  0.6193,\n",
            "          0.4017,  0.5016, -0.2311,  0.4968, -1.0000,  0.2635, -0.5532,  0.3538,\n",
            "          0.6304, -0.9852,  0.4751, -0.4215, -0.0040, -0.1860,  0.2915,  0.5544,\n",
            "          0.9991,  0.4266, -0.4526, -0.7098, -0.0321,  0.0789,  0.9115,  0.6977,\n",
            "          0.9910, -0.8212, -0.2415,  0.6547,  0.0431, -0.6771, -0.0953,  0.6230,\n",
            "          0.0534,  0.9349,  0.7677, -0.4854, -0.5863,  0.8343, -0.9983,  0.9999,\n",
            "          0.3210,  0.5375,  0.9386, -0.3027,  0.7311,  0.4021,  0.3877, -0.7237,\n",
            "          0.9759,  0.7224,  0.6593,  0.1686, -0.0745, -0.1354, -0.9206,  0.5529,\n",
            "          0.3622, -0.5034, -0.9819,  0.9890, -0.9821,  0.3375, -0.2762,  0.8000,\n",
            "          0.9481, -0.4187, -0.8616, -0.2395,  0.3051, -0.7366, -0.8268, -0.9928,\n",
            "         -0.0882, -0.9115,  0.9999, -0.9914,  0.5573, -0.9194, -0.9023,  0.7574,\n",
            "         -0.4231, -0.6091, -0.8225, -0.1250, -0.5244,  0.7977,  0.0193,  0.7386,\n",
            "         -0.4382,  0.2608,  0.7516,  0.1749,  0.3028,  0.9038, -0.6344, -0.9553,\n",
            "         -0.7110, -0.5994, -0.6904,  0.9617, -0.9315, -0.8168,  1.0000, -0.9847,\n",
            "          0.1655, -0.3265, -0.9971,  0.5838, -0.4107, -0.9450, -0.6148, -0.8084,\n",
            "          0.6920,  0.9375,  0.9992,  0.1934,  0.1447, -0.9647, -0.6439,  0.9974,\n",
            "         -0.9679, -0.3936,  0.3386, -0.9955,  0.9330,  0.3570, -0.4780,  0.8442,\n",
            "         -0.6857,  0.9692,  0.5944, -0.9971,  0.6059,  0.7108, -0.2941,  0.8737,\n",
            "          0.2585,  0.1907, -0.9573,  0.0151,  0.9993,  0.4104, -0.8150,  0.1133,\n",
            "          0.8018,  0.7985,  1.0000, -0.9670,  0.6959,  0.9996, -0.3093,  0.5178,\n",
            "          0.2466, -0.7617,  0.0671,  0.5144, -0.9787,  0.9998, -0.0895, -0.9876,\n",
            "         -1.0000,  0.3256, -0.8268,  0.7751,  0.9711,  0.5955,  0.8753,  0.3315,\n",
            "         -0.9984, -0.0329, -0.5914, -0.9998, -0.9994,  0.8500,  0.1229,  0.1901,\n",
            "          0.7798, -0.1001, -0.7512,  0.9996,  0.9003, -0.9999, -0.2335,  0.3138,\n",
            "          0.9663, -0.7446,  0.6455,  0.3525,  0.3993, -0.3669, -1.0000, -0.5184,\n",
            "          0.9731, -0.0338, -0.0250,  0.9995,  0.7142,  0.3666, -0.9456, -0.0183,\n",
            "          0.7025, -1.0000, -0.7068,  0.9998, -0.3360, -0.1097, -0.5511,  0.3156,\n",
            "          0.6086,  0.6264,  0.1823, -0.9968,  0.9951,  0.8717, -0.9128,  0.9967,\n",
            "         -0.5316, -0.7146, -0.7844, -0.6456,  0.7642, -0.7145,  0.5465, -0.2994,\n",
            "          0.9850,  0.8927, -0.4147,  0.7741,  0.9063, -0.8156, -0.3907,  0.7994,\n",
            "          0.6248,  0.4013,  0.9817, -0.4682, -0.7495, -0.4216,  0.6640,  0.9176,\n",
            "         -0.9999,  0.9221, -0.5015, -0.8950,  0.6656, -0.5216, -0.6553, -0.2799,\n",
            "         -0.4366, -0.6760,  0.1817,  0.9520,  0.7517,  0.7866, -0.9865, -0.9999,\n",
            "         -0.6928, -0.5685, -0.8478, -0.4906,  0.2618,  0.9481,  0.2539,  0.5087,\n",
            "          0.3306,  0.9998, -0.4148,  0.9905, -0.8016,  0.9335, -0.9895,  0.5633,\n",
            "          0.5418, -0.9550, -0.5483,  0.9553, -0.3756,  0.8328, -0.9692,  0.6380,\n",
            "          1.0000, -0.7218, -0.6006,  0.7040, -0.8814,  0.7835, -0.0296,  0.9943,\n",
            "         -1.0000,  0.9892, -0.0582,  0.4099,  0.5832,  0.5766,  0.5539, -0.6532,\n",
            "         -0.5245, -0.9898,  0.6178,  0.4171, -0.6613,  0.2902,  0.9232, -0.7897,\n",
            "         -0.9986, -0.6256,  0.4818,  0.9552, -0.4539, -0.9909,  0.9671, -0.2280,\n",
            "          0.9685,  0.1563, -0.7103, -0.4540, -0.2166, -0.5700,  0.5771,  0.6923,\n",
            "          0.8128,  0.3142, -0.8733, -0.4812, -0.0019, -0.7883,  0.7428, -0.3115,\n",
            "         -0.0307,  0.7363,  0.8378,  0.9783,  0.4099,  0.1848,  0.7521, -0.7476,\n",
            "         -0.5906, -0.9997,  0.9991,  0.8603, -0.8480, -0.9997,  0.9384,  0.2507,\n",
            "         -0.3351,  0.7372, -0.1323, -0.7092,  0.2402,  0.7798, -1.0000, -0.4595,\n",
            "          0.1848, -0.4178, -0.6439, -0.9998, -0.5490,  0.1478, -0.2935,  0.2948,\n",
            "          0.9985, -0.4374, -0.9878, -0.9635, -0.0897,  0.6583,  0.2244, -0.9609,\n",
            "         -0.5349,  0.8563, -0.9985,  0.7224, -0.5698, -0.5143,  0.2555,  0.7145,\n",
            "          0.9211, -0.9999,  0.8780, -0.7123,  0.9097, -0.4850,  0.5419,  0.5278,\n",
            "          0.3476, -0.9977,  0.8325,  0.3344,  0.8207,  0.7489,  0.7781, -0.0442,\n",
            "         -0.8717, -0.6828,  0.9842,  0.9749, -0.6562,  0.6816,  0.9988, -0.6380,\n",
            "          0.5820,  0.6263,  0.0716, -0.9992, -0.8403, -0.2389, -0.5870, -0.8304]],\n",
            "       device='cuda:0')\n",
            "Epoch: 8/10...Step: 1000...Train Loss: 0.031416...Train Acc: 0.989...Valid Loss: 1.250418...Valid Acc: 0.707...\n",
            "Validation loss decreased (inf --> 1.250418).  Saving model ...\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6208, -0.9996, -0.8884,  ..., -0.8948,  0.0962,  0.5808],\n",
            "        [ 0.7163,  0.9984,  0.8591,  ...,  0.8672, -0.7578, -0.3129],\n",
            "        [ 0.6539,  1.0000,  0.9634,  ...,  0.7306, -0.0943, -0.9033],\n",
            "        ...,\n",
            "        [-0.5863, -0.3804, -0.9519,  ..., -0.9401,  0.2398,  0.6426],\n",
            "        [ 0.6379,  0.9931,  0.8553,  ...,  0.8918, -0.7673, -0.1000],\n",
            "        [-0.2799, -0.6936, -0.9370,  ..., -0.8635,  0.2028,  0.4605]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4574,  0.9995, -0.7573,  ..., -0.8127,  0.8075, -0.2388],\n",
            "        [ 0.7035,  0.9998,  0.8262,  ...,  0.8784, -0.7468, -0.4497],\n",
            "        [ 0.8037,  1.0000,  0.9248,  ...,  0.8954, -0.3710, -0.8666],\n",
            "        ...,\n",
            "        [ 0.5797,  0.9999,  0.9180,  ...,  0.8288, -0.7267, -0.5813],\n",
            "        [-0.7197, -0.6719, -0.9268,  ..., -0.8805,  0.2825,  0.7473],\n",
            "        [-0.6378,  0.3295, -0.9356,  ..., -0.8409,  0.0425,  0.6346]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7459,  0.9999,  0.7944,  ...,  0.8766, -0.6787, -0.4513],\n",
            "        [ 0.7749,  1.0000,  0.9722,  ...,  0.7993, -0.3493, -0.6998],\n",
            "        [ 0.6817,  1.0000,  0.9333,  ...,  0.7985,  0.0429, -0.9604],\n",
            "        ...,\n",
            "        [ 0.4796,  0.9996,  0.9222,  ...,  0.8800, -0.7833, -0.5129],\n",
            "        [ 0.6467,  0.9959,  0.7649,  ...,  0.8906, -0.8319, -0.0898],\n",
            "        [ 0.7234,  0.9999,  0.7251,  ...,  0.7842, -0.5630, -0.4388]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6034, -0.8830, -0.9539,  ..., -0.8889,  0.1396,  0.4854],\n",
            "        [ 0.6374,  0.9977,  0.8566,  ...,  0.9052, -0.8386, -0.2973],\n",
            "        [ 0.7779,  0.9995,  0.9284,  ...,  0.9194, -0.7769, -0.5410],\n",
            "        ...,\n",
            "        [ 0.6302,  0.9990,  0.7949,  ...,  0.8224, -0.8140,  0.0386],\n",
            "        [ 0.7175,  1.0000,  0.9445,  ...,  0.8342,  0.1091, -0.9340],\n",
            "        [ 0.6262,  0.9999,  0.9326,  ...,  0.9252, -0.6657, -0.6283]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5802,  1.0000,  0.9362,  ...,  0.3388,  0.4373, -0.9815],\n",
            "        [ 0.6249,  0.9988,  0.8927,  ...,  0.9161, -0.8362, -0.3108],\n",
            "        [-0.4421, -0.3935, -0.9537,  ..., -0.9461,  0.1678,  0.6720],\n",
            "        ...,\n",
            "        [-0.6457, -0.9916, -0.9607,  ..., -0.9312,  0.2126,  0.7145],\n",
            "        [-0.6069, -0.9962, -0.9472,  ..., -0.8886,  0.0299,  0.6719],\n",
            "        [-0.6479, -0.9946, -0.9500,  ..., -0.8771,  0.0948,  0.7307]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-6.1382e-01, -9.9437e-01, -9.4756e-01,  ..., -8.8424e-01,\n",
            "          1.6103e-01,  6.0142e-01],\n",
            "        [ 6.2473e-01,  9.9998e-01,  8.8939e-01,  ...,  8.6515e-01,\n",
            "         -7.1228e-01, -6.4651e-01],\n",
            "        [ 4.9228e-01,  9.7615e-01,  8.1178e-01,  ...,  9.0031e-01,\n",
            "         -8.5153e-01,  5.1053e-05],\n",
            "        ...,\n",
            "        [-5.3751e-01, -9.9928e-01, -9.6782e-01,  ..., -9.0150e-01,\n",
            "          2.5255e-01,  7.9604e-01],\n",
            "        [-7.5905e-01, -2.5935e-01, -8.6407e-01,  ..., -8.8075e-01,\n",
            "          3.9444e-01,  6.0457e-01],\n",
            "        [-6.1354e-01, -8.5492e-01, -9.4964e-01,  ..., -8.8920e-01,\n",
            "          2.2056e-01,  6.0002e-01]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6141,  0.9998,  0.9153,  ...,  0.9083, -0.7625, -0.5574],\n",
            "        [ 0.8165,  1.0000, -0.0287,  ..., -0.7481,  0.6649, -0.9462],\n",
            "        [-0.5353, -0.2839, -0.9548,  ..., -0.9194,  0.2101,  0.5565],\n",
            "        ...,\n",
            "        [ 0.6321,  0.9993,  0.8794,  ...,  0.8807, -0.8324, -0.5885],\n",
            "        [-0.6216,  0.9961, -0.8195,  ..., -0.6748,  0.2662,  0.4064],\n",
            "        [-0.7225,  0.8539, -0.8964,  ..., -0.8672,  0.0383,  0.5623]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5764, -0.9822, -0.9447,  ..., -0.7930,  0.0010,  0.7530],\n",
            "        [ 0.5718,  0.9992,  0.9207,  ...,  0.8721, -0.7040, -0.4024],\n",
            "        [ 0.6394,  0.9994,  0.8987,  ...,  0.9188, -0.7952, -0.5410],\n",
            "        ...,\n",
            "        [ 0.8361,  1.0000,  0.9491,  ...,  0.7653, -0.5495, -0.8972],\n",
            "        [-0.5977, -0.7268, -0.9450,  ..., -0.8964,  0.4417,  0.5397],\n",
            "        [-0.4860,  0.0858, -0.9516,  ..., -0.9068,  0.0882,  0.6642]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5447, -0.9848, -0.8852,  ..., -0.8718,  0.3193,  0.6820],\n",
            "        [ 0.3953,  0.9944,  0.8670,  ...,  0.7840, -0.8366, -0.1703],\n",
            "        [ 0.5471,  0.9985,  0.8218,  ...,  0.9190, -0.8050, -0.2051],\n",
            "        ...,\n",
            "        [ 0.6389,  0.9979,  0.7542,  ...,  0.8389, -0.7286, -0.4238],\n",
            "        [ 0.5539,  0.9958,  0.8159,  ...,  0.9232, -0.8118, -0.1526],\n",
            "        [ 0.5077,  1.0000,  0.8529,  ...,  0.6725, -0.6124, -0.6013]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5243,  0.5201, -0.9167,  ..., -0.7892,  0.4037,  0.7177],\n",
            "        [-0.7084, -0.9465, -0.9405,  ..., -0.8809,  0.4009,  0.6857],\n",
            "        [ 0.6767,  0.9987,  0.8974,  ...,  0.8879, -0.8123, -0.4529],\n",
            "        ...,\n",
            "        [-0.4811,  0.4629, -0.8979,  ..., -0.9097,  0.4080,  0.6010],\n",
            "        [-0.4669, -0.1179, -0.9421,  ..., -0.8800,  0.4698,  0.3310],\n",
            "        [-0.4258, -0.8531, -0.9026,  ..., -0.8885,  0.0704,  0.5498]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5982,  0.6126, -0.9296,  ..., -0.8972,  0.4972,  0.5154],\n",
            "        [ 0.7196,  0.9993,  0.8105,  ...,  0.8564, -0.7326, -0.5743],\n",
            "        [ 0.6943,  1.0000,  0.9490,  ...,  0.9011, -0.7452, -0.6132],\n",
            "        ...,\n",
            "        [-0.7479,  0.9873, -0.7859,  ..., -0.8382,  0.0558,  0.7752],\n",
            "        [-0.4445,  0.5287, -0.9382,  ..., -0.9143,  0.1747,  0.3585],\n",
            "        [ 0.5304,  0.9987,  0.8144,  ...,  0.9031, -0.8250, -0.3297]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2060,  1.0000,  0.4143,  ...,  0.3520,  0.7125, -0.8127],\n",
            "        [-0.6017,  0.9861, -0.8670,  ..., -0.7505,  0.5733,  0.4789],\n",
            "        [-0.6127, -0.9992, -0.9141,  ..., -0.8079,  0.1921,  0.5913],\n",
            "        ...,\n",
            "        [-0.7945, -0.8854, -0.9440,  ..., -0.8975,  0.0102,  0.7275],\n",
            "        [ 0.6556,  0.9992,  0.8768,  ...,  0.9330, -0.8166, -0.4787],\n",
            "        [ 0.2403,  0.9450,  0.7174,  ...,  0.8053, -0.7787, -0.0697]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.7175, -0.8017, -0.9587,  ..., -0.9167,  0.1230,  0.7508],\n",
            "        [-0.7004, -0.8762, -0.8976,  ..., -0.9051,  0.5259,  0.6702],\n",
            "        [-0.4288, -0.0851, -0.9414,  ..., -0.9257,  0.4369,  0.5063],\n",
            "        ...,\n",
            "        [-0.7434, -0.0659, -0.9553,  ..., -0.8832,  0.1605,  0.6420],\n",
            "        [ 0.6558,  0.9999,  0.8220,  ...,  0.7746, -0.6932, -0.6617],\n",
            "        [-0.7135, -0.2603, -0.9480,  ..., -0.9331,  0.1691,  0.6555]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6935,  0.9985,  0.8383,  ...,  0.8972, -0.8125, -0.2857],\n",
            "        [ 0.7500,  0.9999,  0.8759,  ...,  0.8747, -0.7803, -0.5810],\n",
            "        [-0.6598,  0.9376, -0.8595,  ..., -0.9325,  0.2961,  0.3424],\n",
            "        ...,\n",
            "        [-0.6631, -0.9930, -0.9574,  ..., -0.9037,  0.2486,  0.5556],\n",
            "        [ 0.5745,  1.0000,  0.7998,  ...,  0.8234, -0.7501, -0.7316],\n",
            "        [ 0.6672,  0.9964,  0.8376,  ...,  0.8588, -0.8910, -0.0367]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5951, -0.7530, -0.9490,  ..., -0.8659,  0.0088,  0.5483],\n",
            "        [-0.6309, -0.9554, -0.9540,  ..., -0.8945,  0.0604,  0.7246],\n",
            "        [-0.6449, -0.9932, -0.9431,  ..., -0.9260,  0.0972,  0.8020],\n",
            "        ...,\n",
            "        [ 0.4896,  0.9984,  0.8904,  ...,  0.9128, -0.8599, -0.3267],\n",
            "        [-0.6163,  0.5899, -0.9173,  ..., -0.8824,  0.2066,  0.4424],\n",
            "        [-0.6043,  0.5558, -0.9393,  ..., -0.9016,  0.3703,  0.4114]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-7.1663e-01, -3.1424e-01, -9.3246e-01, -2.9357e-01,  2.8162e-02,\n",
            "         -9.1733e-01, -4.5397e-01, -7.3377e-01,  9.2834e-01,  6.8818e-01,\n",
            "         -7.7027e-01,  9.2459e-01, -1.6364e-01, -7.8100e-01,  1.6989e-01,\n",
            "          9.1830e-01, -7.6077e-01,  4.3885e-01,  1.7894e-01,  4.5766e-01,\n",
            "          1.2945e-01,  8.6508e-01, -2.8628e-02,  3.0341e-02, -7.4094e-01,\n",
            "         -8.6114e-01,  4.3839e-01,  1.4550e-01,  1.0558e-01, -5.8434e-01,\n",
            "          4.0600e-02,  7.5770e-01,  4.8132e-01,  2.9689e-01,  1.1977e-01,\n",
            "          5.3171e-01,  7.0640e-01,  6.9153e-01, -5.1753e-01,  1.2613e-01,\n",
            "          9.3234e-01,  4.8150e-01, -3.5703e-01, -8.2004e-01, -8.4647e-01,\n",
            "         -5.1880e-01,  2.3203e-01, -5.6159e-01,  3.2018e-01,  1.2370e-01,\n",
            "          5.4371e-01, -9.9665e-01,  2.7646e-01, -9.6809e-01, -5.4708e-01,\n",
            "         -7.5607e-01, -1.5862e-01,  4.1566e-01,  1.3564e-02,  8.4970e-01,\n",
            "         -4.8772e-01, -4.7925e-01,  9.0823e-01,  3.4066e-01,  9.6959e-01,\n",
            "          2.1202e-01,  4.7463e-01, -2.1027e-01,  9.2038e-01, -6.7751e-01,\n",
            "         -8.6472e-01,  5.5272e-01, -2.9329e-01, -2.4433e-01,  4.3934e-01,\n",
            "         -4.5864e-01,  8.2189e-01, -3.8294e-01, -3.1057e-01, -2.7918e-01,\n",
            "         -8.3240e-01,  4.1394e-01,  7.5301e-01, -1.1210e-01, -8.1769e-01,\n",
            "         -5.2007e-01,  4.7195e-01,  1.1644e-01,  5.3313e-01,  9.1574e-02,\n",
            "         -1.6147e-01, -9.0358e-01, -7.8504e-01,  6.4105e-01,  4.3190e-01,\n",
            "         -5.1467e-01,  4.0743e-01, -8.4384e-01,  6.5739e-01,  9.4209e-02,\n",
            "          6.0855e-01,  5.0485e-01,  5.4737e-01,  2.1339e-01,  3.3182e-02,\n",
            "         -8.6743e-01,  4.4322e-01, -4.4109e-01,  8.2836e-01,  2.1116e-01,\n",
            "         -5.8573e-01,  9.2318e-03,  8.2175e-01, -7.1060e-01, -5.7051e-01,\n",
            "          3.9460e-01, -9.2935e-01, -8.6134e-01,  6.3541e-01,  1.7229e-01,\n",
            "         -1.6885e-01, -6.3418e-01,  4.9712e-01, -4.2671e-01, -4.8738e-01,\n",
            "         -5.7791e-01, -7.0603e-01,  9.0694e-01,  5.2721e-01,  3.1838e-01,\n",
            "         -7.8076e-02, -9.1719e-01, -8.3640e-01, -6.0174e-01,  7.0005e-01,\n",
            "         -3.6163e-01, -9.3910e-01,  4.1353e-01,  7.9422e-01,  7.8068e-01,\n",
            "          7.3670e-01,  8.4217e-02, -6.3199e-01, -1.3485e-01,  6.4237e-02,\n",
            "          3.8983e-01, -3.1018e-02,  6.7938e-01,  5.9491e-02, -8.2727e-01,\n",
            "          5.0070e-01, -6.4584e-01, -7.8139e-01,  1.9289e-01, -4.4889e-01,\n",
            "          4.9840e-01,  5.8537e-01,  5.7394e-01,  9.9243e-01, -8.9727e-01,\n",
            "          7.7171e-01,  9.1040e-01,  4.5768e-01,  3.3237e-01,  9.9881e-01,\n",
            "         -6.7916e-01,  2.0623e-01,  4.2258e-01,  8.9513e-01, -5.5022e-01,\n",
            "         -1.0986e-01,  6.8134e-01,  5.2631e-01,  5.1788e-01,  9.9404e-01,\n",
            "         -5.5252e-01, -7.1542e-01,  1.9797e-01,  9.0781e-01,  8.8622e-01,\n",
            "         -1.6506e-01, -1.1575e-02, -9.2996e-01, -8.0131e-01,  8.5788e-01,\n",
            "         -7.4194e-01, -4.6456e-01,  7.5645e-01, -9.6751e-01,  5.6001e-01,\n",
            "         -7.1114e-01, -8.1377e-01, -5.7364e-01,  8.7243e-01,  5.8248e-02,\n",
            "         -9.5190e-02, -1.5503e-01,  5.2165e-01,  5.7185e-01,  3.4401e-01,\n",
            "          7.0637e-01,  7.4783e-01,  4.9437e-01, -9.5555e-01, -8.6513e-01,\n",
            "         -6.3194e-01,  2.1151e-01,  1.6530e-02, -1.2283e-01,  6.9232e-01,\n",
            "          4.4068e-01,  6.8006e-01,  3.2848e-01, -8.2226e-01,  9.3624e-02,\n",
            "          5.6620e-01,  5.5523e-01, -9.4313e-01,  5.5023e-01,  8.4622e-01,\n",
            "         -8.5318e-01, -8.4309e-01,  4.6545e-01, -8.8701e-01, -1.3758e-01,\n",
            "         -6.7985e-01, -9.9038e-02,  1.2252e-01, -8.1300e-01,  6.2274e-01,\n",
            "          1.7079e-01,  6.5427e-01,  3.3136e-01,  8.5487e-01,  9.5133e-01,\n",
            "          1.7172e-01, -8.9203e-01,  3.4502e-01,  8.1201e-01, -4.8235e-01,\n",
            "          9.1015e-01, -5.9687e-01,  7.5807e-01,  2.7441e-01, -9.4421e-01,\n",
            "          7.1806e-01, -9.3045e-01, -8.0778e-01, -1.4943e-01,  6.5934e-01,\n",
            "         -2.0048e-01, -5.4192e-01,  4.7008e-01,  6.4043e-01,  6.8157e-01,\n",
            "          3.2097e-01,  8.5166e-01, -7.6959e-01, -4.1996e-01,  5.1414e-02,\n",
            "         -3.1312e-01,  2.4238e-01, -9.6932e-01, -8.1812e-01, -6.8946e-01,\n",
            "          5.1180e-01, -6.7885e-01, -2.6011e-01,  3.1030e-01,  2.2751e-01,\n",
            "          3.6977e-01,  8.3202e-01, -7.1622e-01,  6.7003e-01,  3.1292e-01,\n",
            "         -8.0087e-01,  1.7747e-01, -5.6302e-02, -8.5131e-01,  6.5462e-01,\n",
            "         -9.7595e-01,  9.5290e-01,  8.0729e-01,  5.4654e-01,  4.1435e-02,\n",
            "          3.8301e-01, -9.3926e-02,  9.3143e-01, -8.6132e-01,  5.2166e-01,\n",
            "          7.0362e-01,  8.2855e-01,  9.5127e-01,  1.2992e-01, -8.7881e-01,\n",
            "         -8.3242e-01,  7.0294e-01, -8.9304e-01,  2.0204e-01,  4.9624e-01,\n",
            "         -8.5456e-03,  6.9713e-01,  6.1820e-01,  6.3984e-01, -9.1717e-02,\n",
            "          7.4987e-01, -9.5974e-01,  7.0977e-01, -5.8322e-01, -8.6706e-03,\n",
            "          1.3482e-01, -7.1128e-01, -6.1454e-01,  4.8142e-01, -5.8006e-01,\n",
            "         -7.4611e-01, -4.1710e-01,  7.0422e-01,  2.9829e-01,  1.9249e-01,\n",
            "          1.4517e-01,  7.8999e-01, -6.7311e-01, -6.0842e-01, -8.8759e-01,\n",
            "          9.1641e-02,  8.9434e-01, -5.8536e-01, -8.1838e-01,  5.0430e-01,\n",
            "         -1.8309e-01,  8.9630e-01, -4.5223e-01, -7.8411e-01,  2.4197e-01,\n",
            "         -6.2144e-02, -2.9327e-01,  9.6572e-01, -9.3396e-01,  7.4044e-01,\n",
            "          7.9231e-01,  4.1104e-01,  8.6057e-01,  4.2213e-01, -4.3780e-02,\n",
            "         -8.9819e-01,  5.4617e-01, -3.0154e-01,  8.3394e-01, -4.6524e-01,\n",
            "         -3.9061e-01,  1.6063e-01, -8.3241e-01, -8.5781e-01,  7.7451e-01,\n",
            "          4.5900e-01,  6.9359e-01,  9.2252e-01, -6.0790e-01,  3.5637e-01,\n",
            "         -7.0356e-01, -3.3299e-02,  8.1254e-01, -5.3459e-01,  8.9841e-01,\n",
            "         -7.1501e-01,  4.0557e-01,  1.0195e-01, -9.5144e-01,  7.7554e-01,\n",
            "         -5.4024e-01,  7.4370e-01, -1.4170e-01,  9.4021e-01, -5.8230e-01,\n",
            "         -8.4190e-01, -6.5407e-01, -1.1091e-01,  8.6170e-01,  4.7247e-01,\n",
            "         -5.3746e-01,  9.4083e-02,  6.8308e-01,  4.7109e-01, -9.0982e-01,\n",
            "          4.3776e-01,  5.7085e-01, -8.1438e-01,  7.2595e-01,  5.4102e-01,\n",
            "          5.0153e-01,  2.0731e-01, -1.7229e-01, -9.1696e-01,  2.2094e-01,\n",
            "          7.8245e-01, -2.4782e-01, -6.6808e-01, -5.1400e-01,  4.9830e-01,\n",
            "         -7.2500e-01, -1.8439e-01, -7.9851e-01,  6.6899e-01,  5.8639e-01,\n",
            "         -4.5196e-01, -9.2844e-02, -2.8536e-02,  4.9680e-01, -9.2456e-01,\n",
            "          4.8805e-01,  6.5296e-01,  5.1573e-01,  6.4198e-01, -8.9691e-01,\n",
            "          1.2636e-01, -9.0198e-01, -5.4756e-02, -5.3394e-01,  2.8168e-01,\n",
            "         -2.5949e-01, -5.2585e-01, -6.3587e-01, -9.5809e-01,  8.1784e-01,\n",
            "         -3.5345e-01,  9.4059e-01, -6.6908e-01, -6.1190e-01, -4.8786e-01,\n",
            "         -1.5546e-01,  2.1832e-01,  7.5147e-01, -3.8136e-01,  8.6327e-01,\n",
            "         -7.2472e-01,  1.9178e-01,  6.3615e-01,  7.7714e-01,  2.1692e-01,\n",
            "          7.5930e-01,  8.7689e-01,  8.1834e-01, -1.8374e-01,  7.1505e-01,\n",
            "          2.7605e-02, -7.7091e-01, -8.9649e-01,  2.0812e-02,  8.0029e-01,\n",
            "         -1.9135e-01,  8.3088e-01, -7.3972e-01,  5.9424e-01,  7.8427e-01,\n",
            "          9.2787e-02,  7.7945e-02, -2.7753e-01,  9.2787e-01,  5.0331e-01,\n",
            "         -2.4811e-01,  8.9662e-01,  1.5731e-01,  9.2725e-01,  3.0042e-01,\n",
            "          2.0730e-02,  7.2764e-01,  5.4682e-01, -8.1018e-01, -1.9865e-01,\n",
            "          7.0777e-01,  5.2119e-01,  1.9213e-01, -9.6556e-01, -2.5023e-01,\n",
            "         -1.1520e-01, -1.7547e-02, -7.7764e-01, -1.6419e-01, -9.9688e-01,\n",
            "          6.1682e-01,  6.2499e-01, -9.3775e-01,  4.4963e-01,  8.8379e-02,\n",
            "          2.8056e-02,  5.0392e-01,  4.6041e-01,  8.9918e-01, -8.3467e-01,\n",
            "         -6.7218e-02, -1.4049e-01,  8.7323e-02,  6.7090e-01,  5.4679e-01,\n",
            "          9.3571e-02, -6.7564e-01, -2.0938e-01,  5.6011e-01,  1.1236e-01,\n",
            "         -1.0107e-01, -7.7497e-01, -4.2537e-02,  3.1383e-01, -7.5270e-01,\n",
            "         -9.2151e-01,  3.2876e-01,  9.8618e-01,  2.6362e-01,  1.1457e-02,\n",
            "          6.3885e-01,  1.6847e-01,  6.8150e-02,  8.3899e-01, -4.0641e-01,\n",
            "          3.3450e-01,  8.2634e-01, -4.4412e-01, -5.0082e-01, -6.7894e-01,\n",
            "         -2.6282e-01, -3.2173e-01,  5.1806e-01, -6.3668e-01, -8.2829e-01,\n",
            "         -9.2604e-01, -5.7528e-01, -2.5604e-01, -5.0405e-01, -5.0530e-02,\n",
            "          6.9943e-01, -2.2966e-01,  2.4486e-01, -7.7076e-01, -5.2636e-01,\n",
            "         -9.7612e-01, -4.3486e-01, -5.1248e-01, -5.5782e-01, -5.5217e-02,\n",
            "         -9.2118e-01, -2.5778e-01, -3.4760e-01, -1.2462e-01,  6.6902e-01,\n",
            "          7.9299e-01, -4.3318e-01, -3.9636e-01, -6.4827e-01,  7.3791e-01,\n",
            "         -6.6804e-01,  2.1572e-01, -5.8581e-01,  8.3965e-01, -8.2845e-01,\n",
            "         -9.6516e-02, -8.6462e-01, -4.5812e-01, -9.0032e-02,  3.9682e-01,\n",
            "          2.0913e-01, -5.7837e-01,  4.7108e-01, -8.7535e-01,  4.5844e-01,\n",
            "         -3.7179e-01, -4.5285e-01, -6.8958e-01, -8.6562e-01, -9.4589e-01,\n",
            "          8.5862e-01,  9.5672e-01, -4.2403e-04, -8.7731e-01, -4.8707e-01,\n",
            "          5.6456e-01,  7.8367e-02, -5.7872e-01,  8.1975e-01,  9.3028e-01,\n",
            "          6.7416e-01,  7.5287e-01,  2.9150e-01, -4.5423e-02, -8.4583e-01,\n",
            "         -4.6079e-01, -2.6464e-01,  1.3761e-01, -6.7506e-01,  6.3934e-01,\n",
            "          2.1451e-02,  2.1868e-01,  5.6327e-01, -5.0870e-01,  9.2893e-01,\n",
            "          5.2640e-01, -3.2058e-01,  8.9365e-01, -6.8106e-01, -8.5711e-01,\n",
            "         -3.8052e-01, -8.7877e-01,  8.9598e-01, -3.2907e-01, -8.8546e-01,\n",
            "          2.9239e-01, -2.2017e-01,  5.8816e-02,  4.6945e-03,  7.0972e-02,\n",
            "          7.1486e-01,  3.4482e-01,  4.1262e-01, -1.6354e-01, -1.7786e-01,\n",
            "         -1.8144e-01,  5.4869e-01,  8.9723e-01,  1.6879e-01,  6.8413e-01,\n",
            "         -3.4603e-01,  6.1039e-01,  1.9135e-01,  6.6494e-01,  1.1971e-01,\n",
            "         -9.3224e-02,  1.4835e-01, -9.8217e-01,  7.3014e-01, -3.5668e-01,\n",
            "          6.5302e-01,  7.5153e-01, -5.5416e-01, -7.4419e-01, -4.7872e-01,\n",
            "         -8.0136e-01, -3.6606e-01, -7.7751e-01,  9.7121e-01, -1.0183e-01,\n",
            "         -7.6244e-01,  8.4180e-01,  5.6397e-01,  7.6739e-02,  8.1620e-01,\n",
            "         -8.2261e-01, -7.5542e-03, -2.1120e-01,  8.2934e-01,  6.3734e-01,\n",
            "         -2.2883e-01, -7.9340e-01, -3.9124e-01, -9.0044e-01, -5.7487e-01,\n",
            "          2.6680e-01, -3.9599e-02,  4.1359e-01, -7.2254e-01, -9.0959e-01,\n",
            "          2.4008e-01, -8.6449e-01,  4.9862e-01, -4.7733e-01,  9.3463e-03,\n",
            "          9.3200e-01, -7.4173e-01, -4.3845e-01,  9.3463e-01,  7.6599e-01,\n",
            "         -8.8901e-01,  9.3383e-01, -3.3261e-01, -3.0577e-01,  8.5357e-01,\n",
            "          4.8669e-01, -2.6372e-01,  6.4834e-01, -1.1570e-01,  2.3566e-01,\n",
            "         -2.1410e-01, -5.4249e-01,  9.6542e-01,  5.9365e-01, -2.3837e-01,\n",
            "          8.3822e-01, -1.6269e-01,  3.6516e-01,  1.9167e-01, -7.0279e-01,\n",
            "          4.1023e-01, -6.8295e-01, -4.0949e-01, -4.1362e-01, -3.3804e-01,\n",
            "          7.5957e-01,  9.9346e-01, -9.3718e-01,  8.5954e-01,  3.7279e-01,\n",
            "          1.3614e-02,  4.4505e-01, -4.6506e-01,  1.0755e-01,  7.3611e-01,\n",
            "         -1.9132e-01,  5.8166e-01, -2.4483e-01, -6.3675e-01,  1.6140e-02,\n",
            "          6.0595e-01, -9.7239e-01, -8.9142e-01,  5.5911e-01,  3.5581e-01,\n",
            "         -8.0948e-01, -5.5077e-01,  2.2096e-01,  4.9222e-01, -5.7534e-01,\n",
            "         -8.3767e-03,  5.9496e-01, -4.8711e-02,  5.2710e-01, -9.2731e-01,\n",
            "         -2.5914e-01,  3.6286e-01, -2.8192e-01,  8.0041e-01, -6.9470e-01,\n",
            "          9.7793e-01, -7.8024e-01,  6.4822e-01,  8.1395e-01, -8.0244e-01,\n",
            "         -8.8639e-01, -5.8853e-01, -2.3957e-01,  3.5634e-01, -7.3271e-02,\n",
            "         -8.8934e-01,  7.3909e-01, -8.6823e-01,  4.2830e-01,  3.0785e-02,\n",
            "         -5.4289e-01,  5.1449e-01, -2.2131e-01,  2.1628e-01,  2.7134e-01,\n",
            "         -8.4137e-01,  8.6914e-01,  8.2564e-01,  1.3739e-01,  8.4174e-01,\n",
            "         -7.3202e-01,  6.4395e-01, -2.4555e-01,  1.4405e-01,  9.0854e-01,\n",
            "          3.4117e-01, -3.1406e-01, -7.4306e-01, -3.5302e-01,  7.8753e-01,\n",
            "         -8.4483e-01,  4.5091e-02,  7.5469e-01]], device='cuda:0',\n",
            "       grad_fn=<TanhBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluation... :   0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33403fd8abae4e149f34929ea89b70b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7517,  0.9917,  0.8870,  ...,  0.8758, -0.8146, -0.3723],\n",
            "        [ 0.7907,  1.0000,  0.9624,  ...,  0.8061,  0.0895, -0.9579],\n",
            "        [ 0.8411,  1.0000,  0.1219,  ..., -0.6725,  0.6586, -0.8815],\n",
            "        ...,\n",
            "        [ 0.3824,  0.9991,  0.7899,  ...,  0.8224, -0.8022, -0.2053],\n",
            "        [-0.0590,  0.9858, -0.7110,  ..., -0.8601,  0.5605, -0.1761],\n",
            "        [-0.6927, -0.2188, -0.9170,  ..., -0.7550,  0.3039,  0.6249]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4170,  0.9959, -0.8690,  ..., -0.8874,  0.3811,  0.1942],\n",
            "        [ 0.7092,  1.0000,  0.7263,  ...,  0.4637, -0.7920, -0.3276],\n",
            "        [ 0.2082,  0.9983,  0.0589,  ..., -0.7099,  0.5736, -0.8518],\n",
            "        ...,\n",
            "        [-0.2489,  0.9933, -0.3426,  ..., -0.7241,  0.1919, -0.7033],\n",
            "        [-0.6086,  0.9999, -0.5241,  ..., -0.8724,  0.3510, -0.0097],\n",
            "        [ 0.4424,  1.0000,  0.6032,  ..., -0.7272,  0.6799, -0.9599]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6605,  0.9999,  0.9290,  ...,  0.8585, -0.6680, -0.6637],\n",
            "        [ 0.3530,  1.0000,  0.7644,  ...,  0.3970,  0.7247, -0.8630],\n",
            "        [ 0.5828,  1.0000,  0.8596,  ...,  0.8667, -0.7347, -0.5655],\n",
            "        ...,\n",
            "        [-0.1396,  1.0000,  0.0360,  ..., -0.8871,  0.5406, -0.8127],\n",
            "        [-0.7735, -0.3022, -0.9063,  ..., -0.9210,  0.2642,  0.4751],\n",
            "        [ 0.4667,  1.0000,  0.6060,  ...,  0.0230,  0.1765, -0.9455]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0720,  0.9987,  0.0308,  ..., -0.2024, -0.6308, -0.6887],\n",
            "        [-0.0968,  1.0000,  0.7423,  ..., -0.4048,  0.1375, -0.9520],\n",
            "        [-0.0746,  0.9999, -0.4972,  ..., -0.8215,  0.3911, -0.8520],\n",
            "        ...,\n",
            "        [ 0.7642,  1.0000,  0.9261,  ...,  0.8762, -0.4880, -0.6718],\n",
            "        [-0.1778, -0.3339, -0.8210,  ..., -0.9111,  0.6464, -0.2010],\n",
            "        [ 0.6512,  0.9979,  0.8803,  ...,  0.9024, -0.8595, -0.3299]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6977,  0.9999,  0.7364,  ...,  0.7299, -0.4646, -0.3068],\n",
            "        [ 0.4562,  0.9999,  0.8437,  ...,  0.8791, -0.4994, -0.5238],\n",
            "        [-0.5331,  0.4451, -0.8808,  ..., -0.7538,  0.3729,  0.4896],\n",
            "        ...,\n",
            "        [ 0.5475,  0.9999,  0.5568,  ...,  0.7172, -0.4881, -0.8290],\n",
            "        [ 0.4942,  0.9999,  0.8871,  ...,  0.3936, -0.5432, -0.6122],\n",
            "        [ 0.7517,  0.9997,  0.9551,  ...,  0.5834, -0.3979, -0.7464]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5507,  0.9991,  0.8849,  ...,  0.8895, -0.8085, -0.4198],\n",
            "        [ 0.7754,  1.0000,  0.6468,  ...,  0.6040, -0.6084, -0.8670],\n",
            "        [-0.0356,  0.0848, -0.9642,  ..., -0.9114,  0.6227,  0.0869],\n",
            "        ...,\n",
            "        [ 0.7382,  0.9998, -0.6582,  ..., -0.7289,  0.7231, -0.5410],\n",
            "        [ 0.3162,  1.0000,  0.1264,  ...,  0.1314, -0.4045, -0.6488],\n",
            "        [ 0.2490,  1.0000,  0.6415,  ...,  0.2178, -0.5182, -0.8773]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0590,  0.9823, -0.5689,  ..., -0.7948, -0.2779, -0.6023],\n",
            "        [-0.5709, -0.7809, -0.9487,  ..., -0.9320,  0.1019,  0.7168],\n",
            "        [ 0.6383,  0.9961,  0.8226,  ...,  0.9019, -0.8156, -0.3488],\n",
            "        ...,\n",
            "        [-0.2427,  1.0000, -0.3369,  ..., -0.7972, -0.3711, -0.5127],\n",
            "        [ 0.6278,  0.9983,  0.9188,  ...,  0.9122, -0.8448, -0.3698],\n",
            "        [-0.4198,  0.9155, -0.8538,  ..., -0.8315,  0.1008,  0.3993]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6536,  0.9996,  0.8929,  ...,  0.8942, -0.7857, -0.4750],\n",
            "        [ 0.7119,  0.9996,  0.9334,  ...,  0.9229, -0.7457, -0.5457],\n",
            "        [ 0.6981,  1.0000,  0.9370,  ...,  0.8477, -0.0697, -0.9157],\n",
            "        ...,\n",
            "        [ 0.6054,  0.9934,  0.8884,  ...,  0.8749, -0.8796, -0.2362],\n",
            "        [ 0.4522,  0.9995,  0.7855,  ...,  0.8380, -0.7895, -0.6134],\n",
            "        [ 0.5771,  1.0000,  0.7863,  ...,  0.6291, -0.5985, -0.6235]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.8063,  1.0000,  0.9550,  ...,  0.8647, -0.3656, -0.8636],\n",
            "        [-0.0218,  0.9974, -0.8802,  ..., -0.8483,  0.3601, -0.2503],\n",
            "        [-0.8295, -0.9721, -0.8297,  ..., -0.9086,  0.1168,  0.3239],\n",
            "        ...,\n",
            "        [ 0.6975,  0.9997,  0.8915,  ...,  0.8737, -0.7593, -0.3826],\n",
            "        [-0.6692, -0.7070, -0.9285,  ..., -0.9010,  0.2525,  0.7828],\n",
            "        [ 0.5419,  0.9940,  0.8773,  ...,  0.8618, -0.8277, -0.2457]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5275, -0.5547, -0.9531,  ..., -0.8848,  0.1649,  0.5038],\n",
            "        [ 0.0872,  1.0000,  0.1431,  ..., -0.6119,  0.1247, -0.8188],\n",
            "        [ 0.6344,  0.9995,  0.9169,  ...,  0.8951, -0.7849, -0.5401],\n",
            "        ...,\n",
            "        [ 0.7128,  0.9980,  0.8226,  ...,  0.8946, -0.8472, -0.3132],\n",
            "        [ 0.4793,  0.9998,  0.8518,  ...,  0.7371, -0.5873, -0.2260],\n",
            "        [ 0.7458,  1.0000,  0.9383,  ...,  0.8017,  0.0639, -0.9484]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2091,  0.5785, -0.9021,  ..., -0.8658,  0.3605,  0.3814],\n",
            "        [-0.5267, -0.9534, -0.9194,  ..., -0.9360,  0.1690,  0.5051],\n",
            "        [-0.6826,  0.7585, -0.9669,  ..., -0.9431, -0.0537,  0.3656],\n",
            "        ...,\n",
            "        [ 0.6772,  1.0000,  0.8513,  ...,  0.7032, -0.6139, -0.8114],\n",
            "        [ 0.7673,  1.0000, -0.4679,  ..., -0.5728,  0.5034, -0.9097],\n",
            "        [ 0.5132,  0.9985,  0.9017,  ...,  0.8916, -0.8162, -0.2752]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0822,  0.9999,  0.7076,  ..., -0.1864,  0.3536, -0.8351],\n",
            "        [-0.5109, -0.8888, -0.9547,  ..., -0.9042,  0.2652,  0.6201],\n",
            "        [-0.7037,  0.9201, -0.9273,  ..., -0.9023,  0.2464,  0.1348],\n",
            "        ...,\n",
            "        [-0.5898,  0.9350, -0.9415,  ..., -0.9087,  0.2836,  0.5763],\n",
            "        [ 0.1240,  1.0000,  0.1429,  ..., -0.6140, -0.0427, -0.8038],\n",
            "        [-0.2866,  0.9998, -0.7302,  ..., -0.9131,  0.5184, -0.3787]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1206,  0.9932, -0.7977,  ..., -0.4331,  0.6984,  0.3571],\n",
            "        [ 0.3561,  1.0000,  0.6788,  ...,  0.0953, -0.0869, -0.8773],\n",
            "        [-0.6428, -0.9390, -0.8692,  ..., -0.9124,  0.4268,  0.4502],\n",
            "        ...,\n",
            "        [-0.7434,  0.9910, -0.9298,  ..., -0.7378,  0.6023,  0.3492],\n",
            "        [ 0.0819,  0.9973, -0.9113,  ..., -0.8552,  0.4331, -0.4030],\n",
            "        [-0.6413,  1.0000, -0.7492,  ..., -0.8159,  0.4407, -0.6079]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7802,  1.0000,  0.9169,  ...,  0.4881, -0.4168, -0.7339],\n",
            "        [ 0.6029,  1.0000,  0.8157,  ...,  0.2979, -0.2366, -0.8371],\n",
            "        [-0.6678, -0.4217, -0.9360,  ..., -0.8550, -0.1108,  0.5315],\n",
            "        ...,\n",
            "        [ 0.4409,  1.0000,  0.5647,  ..., -0.2044, -0.4460, -0.7213],\n",
            "        [ 0.5156,  1.0000,  0.7857,  ...,  0.8083, -0.3377, -0.6299],\n",
            "        [-0.5562,  0.9935, -0.6079,  ..., -0.7669,  0.1118, -0.4476]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 4.6325e-01,  9.9996e-01,  7.4325e-01, -9.5115e-01, -4.6481e-01,\n",
            "          9.3190e-01,  7.0011e-01,  7.9800e-01, -9.9700e-01, -6.1165e-01,\n",
            "          8.0774e-01, -5.8394e-01,  4.5804e-01,  9.9899e-01,  3.8997e-01,\n",
            "         -1.2163e-01,  7.1828e-01, -9.6940e-01,  6.4890e-01, -2.2678e-01,\n",
            "          3.2252e-01, -7.8622e-01,  8.1199e-01, -3.3234e-01,  8.0302e-01,\n",
            "          7.5694e-01, -4.9904e-01,  5.1565e-01, -1.6140e-01,  2.4769e-01,\n",
            "         -6.1390e-01, -2.4566e-01,  9.1638e-01,  6.3031e-01,  7.9696e-01,\n",
            "         -9.3670e-01, -3.0413e-01, -9.5381e-01, -9.8058e-01, -9.9636e-01,\n",
            "          2.3217e-01, -4.2128e-01,  9.9944e-01, -8.1206e-01,  9.9552e-01,\n",
            "         -9.8825e-01,  5.1855e-01, -3.2467e-01,  5.9170e-01,  4.2522e-01,\n",
            "         -6.9796e-01,  9.3966e-01,  7.7261e-01,  8.4157e-01, -6.0189e-01,\n",
            "         -8.2160e-01, -7.9245e-01,  4.5174e-01, -8.5599e-01, -4.9967e-01,\n",
            "          7.8603e-01,  7.5222e-01, -5.7270e-01, -6.9859e-02, -8.7089e-01,\n",
            "         -5.5659e-01,  5.6446e-01,  4.6507e-01, -6.8876e-01, -9.2947e-01,\n",
            "          8.4952e-01, -9.2720e-01,  6.3772e-01,  1.9831e-01, -3.1366e-01,\n",
            "          8.1551e-01, -8.6950e-01,  9.0400e-01, -7.7735e-01,  9.8973e-01,\n",
            "          6.5622e-01,  4.2796e-01,  6.2986e-01, -9.9994e-01,  6.7291e-01,\n",
            "         -8.8412e-01,  9.8380e-01, -9.7974e-01, -9.5443e-01,  6.9619e-01,\n",
            "          7.8888e-01,  6.5746e-01,  8.0707e-01, -1.2896e-01, -4.3043e-01,\n",
            "         -8.9967e-01, -6.6137e-01,  5.4304e-01, -9.9831e-01,  7.7172e-01,\n",
            "          6.3145e-01,  7.5681e-01, -6.8126e-01, -5.9192e-01, -9.9887e-01,\n",
            "          5.0474e-01, -6.1841e-01, -4.9635e-01, -9.9993e-01, -7.1631e-01,\n",
            "         -8.1418e-01, -8.0510e-01, -3.4050e-01,  8.8512e-01,  5.3595e-01,\n",
            "          9.9965e-01,  8.7057e-01,  9.9799e-01, -9.9994e-01, -9.9206e-01,\n",
            "          4.8276e-02,  9.3393e-01, -6.1993e-01,  1.7829e-02,  5.4379e-01,\n",
            "         -9.6486e-01,  6.7312e-01, -9.9786e-01,  6.6964e-01, -9.2810e-01,\n",
            "         -4.9149e-01,  7.8978e-01,  8.8623e-01,  5.1728e-01, -6.2140e-01,\n",
            "          5.4877e-01, -9.9959e-01,  2.2419e-02, -7.1925e-01, -9.9092e-01,\n",
            "          9.9083e-01,  8.3709e-01,  8.4830e-01, -4.5481e-01, -3.3236e-01,\n",
            "          8.3300e-01,  8.4781e-01, -6.9311e-01,  1.1501e-01, -1.8545e-01,\n",
            "         -8.1225e-01,  8.0096e-01,  4.1843e-01, -4.5735e-01, -9.9993e-01,\n",
            "          4.9494e-01, -6.8335e-01,  9.4012e-01, -9.8689e-01,  9.7256e-01,\n",
            "         -9.7286e-01, -9.9995e-01,  3.5275e-01,  2.9518e-01, -7.7465e-01,\n",
            "          7.9588e-01, -7.9140e-01,  8.7979e-01, -5.9211e-01,  6.8068e-01,\n",
            "          6.3353e-01,  6.4216e-01,  3.7498e-01, -5.5453e-01,  3.1585e-01,\n",
            "         -7.0744e-01,  7.9397e-01, -7.3971e-01, -6.3888e-01, -9.5418e-01,\n",
            "          9.6574e-01, -4.3829e-01,  9.7713e-01, -9.4402e-01, -7.4475e-01,\n",
            "          5.0326e-01,  2.3046e-01, -9.9999e-01,  9.1563e-01,  4.8099e-01,\n",
            "          4.0825e-01,  6.1476e-01,  3.0077e-01, -4.5932e-01,  3.2278e-02,\n",
            "          2.6422e-02, -5.1289e-01,  6.6672e-01, -3.0079e-01,  8.9380e-01,\n",
            "          3.2089e-01, -9.9939e-01,  7.9817e-01,  9.9225e-01,  1.6291e-01,\n",
            "         -4.1816e-01,  8.3198e-02,  9.7669e-01, -9.9617e-01, -6.5009e-01,\n",
            "          1.4750e-01, -5.5527e-01,  4.4702e-01,  4.3490e-01, -4.3752e-01,\n",
            "         -7.4767e-01,  6.1300e-01,  3.6045e-01, -1.6791e-01, -4.9490e-01,\n",
            "          3.0151e-01,  5.9119e-01, -3.0712e-01,  4.3418e-01,  7.4379e-01,\n",
            "          9.9913e-01, -5.0820e-01, -5.9085e-01,  6.2389e-01, -9.9943e-01,\n",
            "          8.1105e-01,  4.9588e-01, -3.5333e-01, -6.8457e-01,  9.8853e-01,\n",
            "          7.6152e-01,  6.7587e-01,  9.8424e-01, -9.4867e-01, -2.4201e-01,\n",
            "         -5.9655e-01,  8.6143e-01, -4.3681e-01, -8.7476e-02,  9.9995e-01,\n",
            "         -9.9257e-01,  9.8273e-01,  9.0545e-01, -1.8539e-02, -4.3269e-01,\n",
            "          6.8452e-01,  2.9704e-01, -2.9684e-01, -6.4877e-02, -6.4739e-01,\n",
            "          9.9224e-01, -6.5498e-01, -9.7899e-01,  5.3162e-01, -1.8159e-01,\n",
            "         -9.0494e-01, -8.4310e-01,  8.1477e-01, -5.4108e-01,  9.7490e-01,\n",
            "          9.9986e-01,  7.6954e-01,  4.7824e-01,  6.8851e-01,  5.4506e-01,\n",
            "          7.5624e-01, -9.8122e-01,  9.6118e-01,  9.9995e-01, -9.4518e-01,\n",
            "          4.4306e-01,  9.9988e-01,  6.6100e-01, -2.2436e-01, -5.8677e-01,\n",
            "          3.1790e-01, -9.7680e-01, -2.0319e-01, -5.0207e-01, -4.6643e-01,\n",
            "         -5.4895e-01,  1.4852e-02, -9.3538e-01, -9.9922e-01, -9.8243e-01,\n",
            "          9.6709e-01, -6.9272e-01, -6.4252e-01,  5.5762e-01, -7.5061e-01,\n",
            "          4.5103e-01, -7.0201e-01,  9.8977e-01, -7.2304e-01,  9.9991e-01,\n",
            "          5.9558e-01, -6.3749e-01, -9.5841e-01, -3.0953e-01,  5.3845e-01,\n",
            "          1.2135e-01,  9.9898e-01,  6.6110e-02, -6.1886e-01,  7.5072e-01,\n",
            "          6.3009e-01,  2.5572e-01,  9.2113e-01, -6.0581e-01,  6.3921e-01,\n",
            "          3.8211e-01,  6.3994e-02, -9.4585e-01, -3.3391e-01, -8.5205e-01,\n",
            "          7.8247e-01,  9.6260e-01,  7.0128e-01,  2.2494e-01,  9.5755e-01,\n",
            "          8.2359e-01, -9.9996e-01,  9.9874e-01,  9.7559e-01, -9.9113e-01,\n",
            "          8.2054e-01, -1.4401e-01,  8.8845e-01, -1.9714e-01,  4.5756e-01,\n",
            "         -8.8317e-01, -8.3010e-01, -9.7794e-01,  7.7279e-01,  2.1177e-01,\n",
            "         -7.0242e-01,  2.8371e-01, -9.0601e-01,  7.9078e-01,  1.4206e-01,\n",
            "          8.2147e-01, -2.9330e-01,  1.5776e-01, -9.9514e-01,  6.6640e-01,\n",
            "          8.6625e-01, -2.2891e-01,  7.6030e-01,  9.8492e-01,  1.2397e-02,\n",
            "          9.9995e-01, -7.5657e-01, -4.3909e-01,  2.1417e-01,  5.8535e-01,\n",
            "          4.1636e-01,  4.6286e-01, -2.4972e-01,  5.3900e-01, -9.9997e-01,\n",
            "          2.9093e-01, -5.3573e-01,  3.0061e-01,  6.5023e-01, -9.8294e-01,\n",
            "          5.0988e-01, -4.3966e-01,  4.0073e-02, -2.0322e-01,  3.1804e-01,\n",
            "          5.7537e-01,  9.9885e-01,  3.9047e-01, -4.7970e-01, -6.8395e-01,\n",
            "          2.2667e-02,  6.6318e-02,  9.0268e-01,  6.7334e-01,  9.8966e-01,\n",
            "         -8.1081e-01, -2.7774e-01,  6.6673e-01,  2.8919e-02, -6.7084e-01,\n",
            "         -1.0019e-01,  6.1569e-01,  5.6727e-02,  9.2400e-01,  7.4733e-01,\n",
            "         -5.5383e-01, -5.5992e-01,  8.3209e-01, -9.9801e-01,  9.9990e-01,\n",
            "          3.0318e-01,  5.2609e-01,  9.3364e-01, -3.0925e-01,  7.0966e-01,\n",
            "          4.3806e-01,  3.6433e-01, -7.0125e-01,  9.7363e-01,  7.3360e-01,\n",
            "          6.3359e-01,  1.4868e-01, -1.1568e-01, -8.4800e-02, -9.1797e-01,\n",
            "          5.3530e-01,  3.7703e-01, -4.7281e-01, -9.7927e-01,  9.8694e-01,\n",
            "         -9.7867e-01,  3.8118e-01, -2.2201e-01,  8.1186e-01,  9.3937e-01,\n",
            "         -3.8134e-01, -8.6818e-01, -2.0066e-01,  3.7834e-01, -7.1581e-01,\n",
            "         -8.1956e-01, -9.9157e-01, -8.9763e-02, -8.9320e-01,  9.9984e-01,\n",
            "         -9.8997e-01,  5.3547e-01, -9.1095e-01, -9.0064e-01,  7.4911e-01,\n",
            "         -4.3489e-01, -5.8093e-01, -8.2237e-01, -1.4492e-01, -5.0940e-01,\n",
            "          7.7270e-01,  2.1855e-02,  7.4315e-01, -4.7054e-01,  2.7788e-01,\n",
            "          7.5233e-01,  1.4970e-01,  2.6622e-01,  9.0050e-01, -6.3052e-01,\n",
            "         -9.5118e-01, -7.0355e-01, -5.8882e-01, -7.0272e-01,  9.5563e-01,\n",
            "         -9.2106e-01, -8.2531e-01,  9.9997e-01, -9.8227e-01,  1.7674e-01,\n",
            "         -3.3133e-01, -9.9657e-01,  5.6743e-01, -3.5556e-01, -9.4055e-01,\n",
            "         -6.1850e-01, -7.9947e-01,  6.7324e-01,  9.3117e-01,  9.9895e-01,\n",
            "          2.2328e-01,  2.0422e-01, -9.5499e-01, -6.3326e-01,  9.9713e-01,\n",
            "         -9.5869e-01, -4.2836e-01,  3.6366e-01, -9.9456e-01,  9.2621e-01,\n",
            "          3.0850e-01, -4.6078e-01,  8.3735e-01, -6.9728e-01,  9.6365e-01,\n",
            "          6.0351e-01, -9.9697e-01,  5.8235e-01,  7.0267e-01, -2.9481e-01,\n",
            "          8.6205e-01,  2.7417e-01,  2.3550e-01, -9.5050e-01, -9.9852e-03,\n",
            "          9.9909e-01,  4.2910e-01, -7.9246e-01,  5.0441e-02,  8.0392e-01,\n",
            "          8.0132e-01,  9.9995e-01, -9.6316e-01,  6.7538e-01,  9.9942e-01,\n",
            "         -2.9673e-01,  4.9495e-01,  2.7555e-01, -7.6467e-01,  6.1305e-02,\n",
            "          5.0735e-01, -9.7683e-01,  9.9980e-01, -4.2464e-02, -9.8650e-01,\n",
            "         -9.9993e-01,  3.2590e-01, -8.1750e-01,  7.6122e-01,  9.7037e-01,\n",
            "          6.1523e-01,  8.6939e-01,  3.1763e-01, -9.9832e-01, -3.9387e-02,\n",
            "         -5.7568e-01, -9.9970e-01, -9.9922e-01,  8.4216e-01,  1.6967e-01,\n",
            "          2.0318e-01,  7.8291e-01, -8.4466e-02, -7.4389e-01,  9.9956e-01,\n",
            "          9.0460e-01, -9.9989e-01, -1.9930e-01,  2.6901e-01,  9.6409e-01,\n",
            "         -7.2786e-01,  6.2521e-01,  3.9646e-01,  4.2518e-01, -3.6701e-01,\n",
            "         -9.9994e-01, -5.0808e-01,  9.6987e-01, -5.9767e-02,  7.1824e-03,\n",
            "          9.9936e-01,  7.0330e-01,  4.0746e-01, -9.4488e-01, -6.0444e-02,\n",
            "          6.8784e-01, -9.9994e-01, -7.0624e-01,  9.9972e-01, -2.7199e-01,\n",
            "         -8.8287e-02, -5.1532e-01,  3.5720e-01,  6.0747e-01,  6.0057e-01,\n",
            "          1.2754e-01, -9.9640e-01,  9.9403e-01,  8.7612e-01, -9.1162e-01,\n",
            "          9.9631e-01, -5.3461e-01, -6.8849e-01, -7.5828e-01, -6.5626e-01,\n",
            "          7.5129e-01, -7.2466e-01,  5.2524e-01, -2.4599e-01,  9.8244e-01,\n",
            "          8.8809e-01, -3.8600e-01,  7.5930e-01,  9.0970e-01, -8.0849e-01,\n",
            "         -3.5777e-01,  7.8568e-01,  6.0335e-01,  4.3253e-01,  9.7828e-01,\n",
            "         -4.4833e-01, -7.3325e-01, -4.4175e-01,  6.5826e-01,  9.1982e-01,\n",
            "         -9.9985e-01,  9.2416e-01, -5.1173e-01, -8.8472e-01,  6.6779e-01,\n",
            "         -5.4486e-01, -6.1307e-01, -2.6004e-01, -5.0494e-01, -6.6979e-01,\n",
            "          1.6188e-01,  9.4624e-01,  7.3144e-01,  7.6537e-01, -9.8414e-01,\n",
            "         -9.9987e-01, -6.9584e-01, -5.7386e-01, -8.2255e-01, -4.9935e-01,\n",
            "          2.8344e-01,  9.4007e-01,  2.2772e-01,  4.8478e-01,  2.8857e-01,\n",
            "          9.9975e-01, -4.1730e-01,  9.9014e-01, -8.0068e-01,  9.3184e-01,\n",
            "         -9.8847e-01,  5.2456e-01,  5.5298e-01, -9.4684e-01, -5.1584e-01,\n",
            "          9.5665e-01, -3.5212e-01,  8.3186e-01, -9.6768e-01,  6.3560e-01,\n",
            "          9.9996e-01, -7.3167e-01, -6.2255e-01,  6.8193e-01, -8.7559e-01,\n",
            "          7.8197e-01,  1.9089e-03,  9.9332e-01, -9.9995e-01,  9.8791e-01,\n",
            "         -8.9602e-02,  4.3755e-01,  5.5762e-01,  5.9613e-01,  5.7099e-01,\n",
            "         -6.2960e-01, -5.0711e-01, -9.8906e-01,  6.3553e-01,  4.1983e-01,\n",
            "         -6.5952e-01,  2.9647e-01,  9.1355e-01, -7.7676e-01, -9.9806e-01,\n",
            "         -6.3466e-01,  4.7963e-01,  9.4579e-01, -4.7625e-01, -9.9010e-01,\n",
            "          9.6030e-01, -2.2614e-01,  9.6638e-01,  2.1523e-01, -7.0550e-01,\n",
            "         -4.3888e-01, -1.8470e-01, -5.8920e-01,  5.5779e-01,  6.8406e-01,\n",
            "          8.1468e-01,  3.2851e-01, -8.7380e-01, -4.8078e-01,  3.0203e-02,\n",
            "         -7.7988e-01,  7.4010e-01, -3.1987e-01, -9.7272e-02,  7.3188e-01,\n",
            "          8.2593e-01,  9.7436e-01,  4.0424e-01,  2.0614e-01,  7.5194e-01,\n",
            "         -7.3709e-01, -5.9697e-01, -9.9963e-01,  9.9890e-01,  8.5599e-01,\n",
            "         -8.4115e-01, -9.9967e-01,  9.3546e-01,  2.3029e-01, -3.4748e-01,\n",
            "          7.2783e-01, -9.3813e-02, -6.8581e-01,  2.6785e-01,  7.6094e-01,\n",
            "         -9.9996e-01, -4.4429e-01,  1.7248e-01, -3.9806e-01, -6.7044e-01,\n",
            "         -9.9972e-01, -5.3791e-01,  1.1638e-01, -2.7282e-01,  3.0108e-01,\n",
            "          9.9802e-01, -4.0686e-01, -9.8621e-01, -9.5739e-01, -6.3622e-02,\n",
            "          6.3673e-01,  2.0747e-01, -9.5419e-01, -5.4263e-01,  8.3691e-01,\n",
            "         -9.9827e-01,  7.2061e-01, -5.7262e-01, -5.1185e-01,  2.5483e-01,\n",
            "          7.2988e-01,  9.1171e-01, -9.9992e-01,  8.7016e-01, -6.8954e-01,\n",
            "          9.0024e-01, -4.9717e-01,  5.3782e-01,  5.0000e-01,  3.1083e-01,\n",
            "         -9.9685e-01,  8.1939e-01,  3.1607e-01,  8.0403e-01,  7.4146e-01,\n",
            "          7.7939e-01,  7.4635e-04, -8.7338e-01, -6.6957e-01,  9.8117e-01,\n",
            "          9.7249e-01, -6.5285e-01,  6.5531e-01,  9.9849e-01, -6.3204e-01,\n",
            "          5.5268e-01,  6.4574e-01,  1.1830e-01, -9.9899e-01, -8.2887e-01,\n",
            "         -2.1791e-01, -6.1376e-01, -8.1695e-01]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training... :   0%|          | 0/127 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "967af0dfa87e4eac911e6f0ab7415312"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5370,  0.3897, -0.9473,  ..., -0.8892,  0.1864,  0.4975],\n",
            "        [ 0.6979,  1.0000,  0.9445,  ...,  0.7215, -0.4887, -0.8946],\n",
            "        [ 0.7789,  0.9976,  0.8937,  ...,  0.7679, -0.8599, -0.4299],\n",
            "        ...,\n",
            "        [-0.6656,  0.9999, -0.8943,  ..., -0.8766,  0.1574, -0.2785],\n",
            "        [ 0.2916,  0.9694, -0.8235,  ..., -0.7666,  0.3746, -0.1648],\n",
            "        [ 0.7410,  0.9943,  0.7442,  ...,  0.8705, -0.6802, -0.4182]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5275, -0.9455, -0.9042,  ..., -0.8812,  0.1350,  0.4963],\n",
            "        [ 0.6322,  1.0000,  0.9801,  ...,  0.7473, -0.2277, -0.8785],\n",
            "        [-0.6006, -0.8679, -0.9497,  ..., -0.9335,  0.1625,  0.7704],\n",
            "        ...,\n",
            "        [-0.0651, -0.1687, -0.9244,  ..., -0.8737,  0.2775,  0.5141],\n",
            "        [ 0.6081,  0.9978,  0.6726,  ...,  0.9143, -0.8014, -0.2878],\n",
            "        [ 0.6186,  0.9995,  0.8483,  ...,  0.9600, -0.7324, -0.4591]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2151,  0.9965, -0.9271,  ..., -0.8771,  0.6528, -0.4290],\n",
            "        [ 0.5801,  0.9997,  0.7670,  ...,  0.8554, -0.7291, -0.7280],\n",
            "        [ 0.6706,  0.9995,  0.9167,  ...,  0.8003, -0.6525, -0.7787],\n",
            "        ...,\n",
            "        [ 0.7000,  1.0000,  0.9688,  ...,  0.8636, -0.2247, -0.8712],\n",
            "        [ 0.6651,  0.9993,  0.9078,  ...,  0.9153, -0.7510, -0.0959],\n",
            "        [ 0.6858,  0.9989,  0.8331,  ...,  0.8360, -0.8258, -0.3051]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5621,  0.9940,  0.7917,  ...,  0.9156, -0.7517, -0.3111],\n",
            "        [ 0.7037,  0.9998,  0.9177,  ...,  0.8240, -0.2756, -0.8080],\n",
            "        [ 0.6471,  0.9944,  0.7422,  ...,  0.8714, -0.6480, -0.2557],\n",
            "        ...,\n",
            "        [-0.1715,  0.9484, -0.9330,  ..., -0.8728,  0.4800, -0.2036],\n",
            "        [ 0.7354,  0.9999,  0.8362,  ...,  0.7240, -0.7281, -0.4872],\n",
            "        [-0.5214, -0.7704, -0.9328,  ..., -0.9403,  0.2280,  0.6264]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4854, -0.9944, -0.9645,  ..., -0.8808,  0.0700,  0.4918],\n",
            "        [ 0.7318,  1.0000,  0.9565,  ...,  0.7498, -0.0663, -0.8923],\n",
            "        [-0.6132, -0.7581, -0.9471,  ..., -0.9313,  0.3065,  0.6528],\n",
            "        ...,\n",
            "        [ 0.5034,  0.9999,  0.9194,  ...,  0.7826, -0.7562, -0.8045],\n",
            "        [ 0.6657,  0.9974,  0.7964,  ...,  0.8801, -0.7046, -0.1208],\n",
            "        [ 0.6113,  0.9999,  0.9179,  ...,  0.8548, -0.4411, -0.7488]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6972,  1.0000,  0.9451,  ...,  0.8089, -0.7076, -0.4937],\n",
            "        [ 0.2550,  0.9690,  0.8701,  ...,  0.6883, -0.7917, -0.1997],\n",
            "        [-0.5532, -0.2068, -0.8037,  ..., -0.9194,  0.2278,  0.2980],\n",
            "        ...,\n",
            "        [ 0.6294,  0.9984,  0.8289,  ...,  0.8452, -0.7887,  0.0109],\n",
            "        [-0.6352,  0.9828, -0.8829,  ..., -0.8638, -0.1111,  0.6316],\n",
            "        [-0.6693, -0.8995, -0.9285,  ..., -0.8814,  0.5998,  0.3045]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4836,  0.7586, -0.9608,  ..., -0.9290,  0.1276,  0.2667],\n",
            "        [ 0.7591,  0.9996,  0.9266,  ...,  0.8919, -0.6511, -0.6385],\n",
            "        [ 0.6858,  0.9992,  0.7764,  ...,  0.8995, -0.8096, -0.2853],\n",
            "        ...,\n",
            "        [ 0.7657,  1.0000,  0.9723,  ...,  0.8565, -0.4803, -0.7395],\n",
            "        [ 0.6463,  0.9971,  0.7679,  ...,  0.8898, -0.7999,  0.1801],\n",
            "        [-0.5302, -0.9625, -0.9538,  ..., -0.9357,  0.5023,  0.3407]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5397,  0.4297, -0.9594,  ..., -0.8532,  0.0061,  0.5066],\n",
            "        [ 0.6260,  0.9999,  0.8786,  ...,  0.8731, -0.8849, -0.4469],\n",
            "        [ 0.7430,  0.9998,  0.9207,  ...,  0.8587, -0.6795, -0.8146],\n",
            "        ...,\n",
            "        [-0.6209, -0.1888, -0.9595,  ..., -0.8726,  0.1597,  0.2449],\n",
            "        [-0.5763, -0.4253, -0.8822,  ..., -0.8660,  0.0866,  0.5639],\n",
            "        [-0.5417, -0.8991, -0.9507,  ..., -0.9069,  0.3693,  0.2749]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.7137, -0.6904, -0.9179,  ..., -0.8303,  0.0041,  0.3599],\n",
            "        [ 0.0270,  0.9993,  0.7524,  ...,  0.4681, -0.6027, -0.4412],\n",
            "        [-0.4046,  0.5730, -0.9017,  ..., -0.9424,  0.3953,  0.3308],\n",
            "        ...,\n",
            "        [-0.3117, -0.9305, -0.9642,  ..., -0.9008,  0.4596,  0.6004],\n",
            "        [ 0.6506,  0.9925,  0.8426,  ...,  0.8208, -0.7576, -0.2009],\n",
            "        [-0.4582, -0.9213, -0.9427,  ..., -0.8840,  0.2143,  0.4192]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7166,  0.9999,  0.8330,  ...,  0.7535, -0.6746, -0.6231],\n",
            "        [-0.1983,  0.8235, -0.9304,  ..., -0.7787,  0.5078,  0.3340],\n",
            "        [ 0.6585,  1.0000,  0.9432,  ...,  0.8265, -0.2739, -0.8225],\n",
            "        ...,\n",
            "        [ 0.6919,  0.9993,  0.8438,  ...,  0.7948, -0.5283, -0.6906],\n",
            "        [ 0.5450,  0.9983,  0.9121,  ...,  0.8710, -0.8659, -0.3552],\n",
            "        [ 0.8173,  1.0000,  0.8876,  ...,  0.8730, -0.6675, -0.5087]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5229, -1.0000, -0.9098,  ..., -0.8818,  0.1272,  0.7240],\n",
            "        [ 0.5592,  0.9985,  0.7600,  ...,  0.8458, -0.8282, -0.0851],\n",
            "        [-0.2446, -0.6428, -0.7500,  ..., -0.7535, -0.1686, -0.1831],\n",
            "        ...,\n",
            "        [ 0.7982,  1.0000,  0.9512,  ...,  0.8464,  0.2275, -0.9409],\n",
            "        [ 0.7620,  0.9998,  0.8466,  ...,  0.8727, -0.6772, -0.5270],\n",
            "        [-0.6681, -0.8556, -0.7549,  ..., -0.8248,  0.4100,  0.0355]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5634,  0.7417, -0.9150,  ..., -0.9265,  0.3271, -0.0651],\n",
            "        [-0.5044,  0.9991, -0.5866,  ..., -0.6919,  0.4524,  0.0421],\n",
            "        [-0.0522,  0.9257, -0.9008,  ..., -0.7130,  0.4355, -0.3633],\n",
            "        ...,\n",
            "        [ 0.4749,  1.0000,  0.8984,  ...,  0.6692, -0.2141, -0.7719],\n",
            "        [ 0.6758,  0.9993,  0.7286,  ...,  0.8467, -0.8403, -0.2698],\n",
            "        [ 0.7926,  0.9999,  0.8591,  ...,  0.8965, -0.6875, -0.3574]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6280,  0.9918,  0.7494,  ...,  0.9085, -0.8746, -0.0036],\n",
            "        [-0.0907,  0.6356, -0.9065,  ..., -0.8524,  0.1353,  0.4631],\n",
            "        [-0.5264, -0.2413, -0.9031,  ..., -0.8494,  0.3481,  0.6966],\n",
            "        ...,\n",
            "        [ 0.6969,  0.9999,  0.9192,  ...,  0.8894, -0.5886, -0.5554],\n",
            "        [ 0.8067,  0.9988,  0.8922,  ...,  0.8856, -0.7977, -0.6182],\n",
            "        [ 0.7214,  0.9844,  0.8906,  ...,  0.8832, -0.8058, -0.5796]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4689,  0.9998,  0.7004,  ...,  0.8492, -0.7910, -0.2209],\n",
            "        [ 0.1361,  0.9999, -0.6776,  ..., -0.8991,  0.4985, -0.3824],\n",
            "        [-0.4623, -0.9958, -0.9613,  ..., -0.9188,  0.0435,  0.5307],\n",
            "        ...,\n",
            "        [ 0.7657,  0.9982,  0.8525,  ...,  0.8821, -0.7574, -0.2362],\n",
            "        [-0.4388, -0.4543, -0.9496,  ..., -0.9188,  0.4763,  0.4736],\n",
            "        [ 0.8128,  0.9984,  0.8556,  ...,  0.7767, -0.5317, -0.3181]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6637,  0.9982,  0.7707,  ...,  0.8879, -0.7722, -0.2601],\n",
            "        [-0.2638, -0.9386, -0.9423,  ..., -0.8944,  0.2679,  0.5420],\n",
            "        [ 0.5774,  0.9978,  0.8399,  ...,  0.8605, -0.9256, -0.1320],\n",
            "        ...,\n",
            "        [-0.5600, -0.9731, -0.9251,  ..., -0.8777,  0.3397,  0.4731],\n",
            "        [-0.0771,  0.9936, -0.8377,  ..., -0.8174,  0.7562, -0.2799],\n",
            "        [ 0.5593,  0.9995,  0.9471,  ...,  0.8549, -0.7954, -0.7201]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5296,  0.9993,  0.8869,  ...,  0.8849, -0.7008, -0.3873],\n",
            "        [-0.4309,  0.9777, -0.9547,  ..., -0.8678,  0.1802,  0.5498],\n",
            "        [ 0.6427,  1.0000,  0.9609,  ...,  0.7582, -0.5929, -0.7790],\n",
            "        ...,\n",
            "        [-0.6238, -0.9966, -0.9604,  ..., -0.8904,  0.4319,  0.5735],\n",
            "        [-0.4042, -0.7381, -0.9411,  ..., -0.8695,  0.2230,  0.6757],\n",
            "        [-0.6841, -0.0919, -0.8736,  ..., -0.8147,  0.1723,  0.3559]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6758,  0.2692, -0.9147,  ..., -0.8108,  0.1595,  0.4000],\n",
            "        [ 0.7846,  0.9999, -0.6546,  ..., -0.5721,  0.6644, -0.7312],\n",
            "        [ 0.5951,  0.9818,  0.8592,  ...,  0.9451, -0.8145, -0.4527],\n",
            "        ...,\n",
            "        [ 0.7907,  0.9978,  0.8962,  ...,  0.8466, -0.7919, -0.4562],\n",
            "        [ 0.5250,  0.9852,  0.6775,  ...,  0.8522, -0.7068, -0.5517],\n",
            "        [ 0.0883,  1.0000,  0.5743,  ...,  0.1194,  0.6008, -0.7947]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4555,  0.9999, -0.7877,  ..., -0.7633,  0.6941, -0.5625],\n",
            "        [-0.6320, -0.9469, -0.9127,  ..., -0.8651,  0.5095,  0.2019],\n",
            "        [ 0.5220,  0.9955,  0.8805,  ...,  0.8858, -0.7136, -0.2146],\n",
            "        ...,\n",
            "        [-0.3489,  1.0000, -0.3617,  ..., -0.7280,  0.5676, -0.8753],\n",
            "        [ 0.3109,  0.9924,  0.9389,  ...,  0.8563, -0.8286, -0.1909],\n",
            "        [ 0.5866,  0.9989,  0.8867,  ...,  0.8775, -0.7985, -0.4479]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4032,  0.9947,  0.9098,  ...,  0.8572, -0.8196, -0.0128],\n",
            "        [ 0.6589,  0.9905,  0.8868,  ...,  0.8420, -0.8054, -0.1341],\n",
            "        [-0.4751, -0.4992, -0.8715,  ..., -0.9341, -0.0357,  0.6570],\n",
            "        ...,\n",
            "        [-0.4972,  0.9998,  0.1969,  ..., -0.7731,  0.1819, -0.8245],\n",
            "        [ 0.6799,  0.9996,  0.8593,  ...,  0.9115, -0.8089, -0.3233],\n",
            "        [ 0.8022,  0.9999,  0.6903,  ...,  0.7939, -0.6252, -0.7285]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6752, -0.3746, -0.9332,  ..., -0.8118,  0.1432,  0.4882],\n",
            "        [ 0.6463,  0.9976,  0.8662,  ...,  0.8577, -0.7841, -0.1464],\n",
            "        [ 0.5757,  0.9990,  0.8441,  ...,  0.8421, -0.8101, -0.3151],\n",
            "        ...,\n",
            "        [-0.3676, -0.0792, -0.8797,  ..., -0.7890,  0.4589,  0.4088],\n",
            "        [-0.3951,  0.9695, -0.9227,  ..., -0.6176,  0.2440,  0.3709],\n",
            "        [ 0.6292,  0.9852,  0.8894,  ...,  0.8773, -0.6936, -0.6088]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5997,  0.9963,  0.9022,  ...,  0.8953, -0.7984, -0.0806],\n",
            "        [ 0.4489,  0.9991,  0.8327,  ...,  0.8550, -0.8140, -0.3282],\n",
            "        [ 0.5371,  0.9958,  0.7737,  ...,  0.8637, -0.6443, -0.1235],\n",
            "        ...,\n",
            "        [-0.5330, -0.9935, -0.9299,  ..., -0.9170,  0.2769,  0.6807],\n",
            "        [-0.4893, -0.1598, -0.9605,  ..., -0.9530,  0.1409,  0.7020],\n",
            "        [ 0.8103,  1.0000,  0.9309,  ...,  0.8734, -0.4322, -0.8511]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5573,  0.2183, -0.9471,  ..., -0.8036,  0.4397,  0.5724],\n",
            "        [-0.5951,  0.9918, -0.9092,  ..., -0.8354,  0.6033, -0.2814],\n",
            "        [ 0.7096,  0.9996,  0.9257,  ...,  0.8492, -0.6998, -0.2399],\n",
            "        ...,\n",
            "        [-0.4059,  0.7773, -0.9067,  ..., -0.8740,  0.5155,  0.0284],\n",
            "        [ 0.5777,  0.9979,  0.8644,  ...,  0.8746, -0.7433, -0.1721],\n",
            "        [-0.5336,  0.1977, -0.8063,  ..., -0.8181,  0.2731, -0.1400]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7428,  0.9997,  0.8250,  ...,  0.8141, -0.7530, -0.3780],\n",
            "        [ 0.8176,  0.9946,  0.8558,  ...,  0.7937, -0.7025,  0.0524],\n",
            "        [ 0.7289,  1.0000, -0.2397,  ..., -0.6453,  0.7158, -0.5003],\n",
            "        ...,\n",
            "        [ 0.7321,  0.9998,  0.7843,  ...,  0.7308, -0.8544, -0.2598],\n",
            "        [-0.3232, -0.9202, -0.8924,  ..., -0.8354,  0.3183, -0.1855],\n",
            "        [ 0.4244,  0.9997,  0.7882,  ...,  0.8330, -0.7802, -0.5495]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2504,  0.0275, -0.9026,  ..., -0.8921,  0.2696,  0.4335],\n",
            "        [ 0.4591,  0.9967,  0.8449,  ...,  0.8487, -0.8111, -0.2756],\n",
            "        [ 0.5970,  1.0000,  0.9154,  ...,  0.2344,  0.4026, -0.9791],\n",
            "        ...,\n",
            "        [-0.3953, -0.6487, -0.8749,  ..., -0.7614,  0.4463,  0.1642],\n",
            "        [ 0.4879,  0.9985,  0.8845,  ...,  0.8344, -0.7842, -0.2520],\n",
            "        [ 0.5909,  0.9988,  0.9002,  ...,  0.9152, -0.7173, -0.4600]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1761,  0.9413,  0.8211,  ...,  0.7727, -0.8482, -0.2010],\n",
            "        [ 0.6951,  0.9995,  0.9427,  ...,  0.8715, -0.6050, -0.4963],\n",
            "        [-0.6505, -0.9853, -0.9478,  ..., -0.8865,  0.0630,  0.6810],\n",
            "        ...,\n",
            "        [-0.2520, -0.7260, -0.6445,  ..., -0.8789,  0.5589,  0.0886],\n",
            "        [ 0.7366,  0.9996,  0.8579,  ...,  0.8452, -0.7757, -0.2625],\n",
            "        [ 0.5144,  0.9978,  0.8310,  ...,  0.9234, -0.8498, -0.2326]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6044,  0.9196, -0.9388,  ..., -0.9293,  0.0883,  0.2584],\n",
            "        [ 0.6927,  0.9992,  0.8555,  ...,  0.8988, -0.8068, -0.2258],\n",
            "        [ 0.5833,  0.9988,  0.7805,  ...,  0.8284, -0.7679, -0.3577],\n",
            "        ...,\n",
            "        [-0.6793,  0.3172, -0.8095,  ..., -0.6605,  0.0147, -0.4111],\n",
            "        [ 0.5674,  0.9996,  0.9251,  ...,  0.8428, -0.7903, -0.4883],\n",
            "        [-0.1687,  0.9021, -0.8414,  ..., -0.8873,  0.5957,  0.4344]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4920, -0.8963, -0.9627,  ..., -0.9212,  0.2078,  0.6291],\n",
            "        [ 0.5240,  0.9881,  0.8331,  ...,  0.9008, -0.8655, -0.2167],\n",
            "        [ 0.6572,  0.9999,  0.8741,  ...,  0.7202, -0.7446, -0.3227],\n",
            "        ...,\n",
            "        [-0.0362,  0.9996, -0.6843,  ..., -0.5472,  0.2419, -0.4430],\n",
            "        [-0.7452,  0.0125, -0.9358,  ..., -0.9413,  0.2843,  0.4569],\n",
            "        [-0.6402,  0.9933, -0.8673,  ..., -0.8420,  0.3949,  0.5719]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6406,  0.4597, -0.8344,  ..., -0.7879,  0.2318,  0.1684],\n",
            "        [-0.6910, -0.9715, -0.9415,  ..., -0.9042,  0.3679,  0.4284],\n",
            "        [ 0.1065,  0.9883, -0.4242,  ..., -0.8067,  0.4030, -0.6907],\n",
            "        ...,\n",
            "        [ 0.4002,  0.9756,  0.8379,  ...,  0.8941, -0.8012,  0.0257],\n",
            "        [-0.3498, -0.9415, -0.8533,  ..., -0.8222,  0.6842,  0.2976],\n",
            "        [-0.4810,  0.9347, -0.9025,  ..., -0.8415,  0.1198,  0.5214]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4995,  0.9934,  0.8155,  ...,  0.8546, -0.6401, -0.0515],\n",
            "        [ 0.5979,  0.9981,  0.8540,  ...,  0.7959, -0.7820, -0.2834],\n",
            "        [ 0.5181,  0.9964,  0.8501,  ...,  0.8585, -0.8465, -0.3172],\n",
            "        ...,\n",
            "        [-0.7584, -0.7690, -0.9260,  ..., -0.9289,  0.2146,  0.7173],\n",
            "        [ 0.4642,  0.9986,  0.9014,  ...,  0.9167, -0.7941, -0.5111],\n",
            "        [ 0.5188,  0.9992,  0.8824,  ...,  0.9007, -0.6075, -0.2527]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6147,  0.9998,  0.8051,  ...,  0.8560, -0.8006, -0.3728],\n",
            "        [ 0.6179,  0.9984,  0.8020,  ...,  0.7780, -0.8605, -0.2817],\n",
            "        [ 0.2570,  0.9977, -0.8662,  ..., -0.9210,  0.5092, -0.4219],\n",
            "        ...,\n",
            "        [ 0.7467,  0.9996,  0.9110,  ...,  0.8965, -0.7889, -0.6240],\n",
            "        [-0.6194, -0.9736, -0.9247,  ..., -0.9065,  0.3194,  0.4199],\n",
            "        [ 0.7852,  1.0000,  0.9096,  ...,  0.8492, -0.0440, -0.9074]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5832, -0.9947, -0.9572,  ..., -0.9290,  0.2830,  0.6273],\n",
            "        [-0.2906, -0.3825, -0.8857,  ..., -0.8047,  0.0126,  0.3244],\n",
            "        [ 0.7883,  0.9999,  0.8640,  ...,  0.9170, -0.6283, -0.5293],\n",
            "        ...,\n",
            "        [-0.6255, -0.9969, -0.9187,  ..., -0.9405,  0.2008,  0.7403],\n",
            "        [ 0.7928,  0.9979,  0.9238,  ...,  0.9186, -0.7017, -0.5152],\n",
            "        [-0.7217, -0.6001, -0.9260,  ..., -0.9170,  0.1923,  0.5959]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4621,  0.9949,  0.8510,  ...,  0.8999, -0.8843, -0.1192],\n",
            "        [ 0.6034,  0.9991,  0.9072,  ...,  0.8948, -0.6961, -0.2756],\n",
            "        [-0.1355,  0.9238, -0.8325,  ..., -0.9176,  0.5211,  0.2774],\n",
            "        ...,\n",
            "        [-0.5585,  0.9976, -0.8780,  ..., -0.6028,  0.4352,  0.1158],\n",
            "        [ 0.3886,  0.9965,  0.8606,  ...,  0.8335, -0.7793, -0.3003],\n",
            "        [ 0.7618,  0.9984,  0.9317,  ...,  0.8800, -0.6972, -0.5751]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6708,  0.9997,  0.8766,  ...,  0.8526, -0.7461, -0.3332],\n",
            "        [-0.4207,  0.8895, -0.9472,  ..., -0.8644,  0.3272,  0.5132],\n",
            "        [ 0.5961,  0.9988,  0.9259,  ...,  0.8842, -0.7676, -0.3975],\n",
            "        ...,\n",
            "        [ 0.8010,  0.9999,  0.8468,  ...,  0.8912, -0.6655, -0.5256],\n",
            "        [-0.2018,  0.4186, -0.9165,  ..., -0.8821,  0.2469,  0.1975],\n",
            "        [-0.5042, -0.1870, -0.9641,  ..., -0.9013,  0.2654,  0.6347]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3545, -0.8112, -0.9528,  ..., -0.8796, -0.1948,  0.7880],\n",
            "        [-0.7065, -0.9631, -0.9173,  ..., -0.8328,  0.1035,  0.6914],\n",
            "        [ 0.6732,  0.9982,  0.8143,  ...,  0.9115, -0.7749, -0.3524],\n",
            "        ...,\n",
            "        [-0.5345,  0.2216, -0.8573,  ..., -0.9142,  0.5034,  0.1952],\n",
            "        [ 0.7747,  0.9999,  0.9408,  ...,  0.8816, -0.7617, -0.6467],\n",
            "        [ 0.4143,  0.9923,  0.8155,  ...,  0.8331, -0.8702, -0.0808]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5361,  0.9985,  0.9018,  ...,  0.8746, -0.8465, -0.6108],\n",
            "        [ 0.6854,  0.9997,  0.8687,  ...,  0.8659, -0.7704, -0.3325],\n",
            "        [ 0.8105,  0.9988,  0.7875,  ...,  0.9179, -0.8333, -0.4583],\n",
            "        ...,\n",
            "        [-0.6628, -0.9895, -0.9558,  ..., -0.8982, -0.0129,  0.8007],\n",
            "        [-0.0979,  0.9990, -0.7604,  ..., -0.8066,  0.7634, -0.0526],\n",
            "        [ 0.7895,  0.9999,  0.9218,  ...,  0.8514, -0.6212, -0.6189]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4780, -0.7773, -0.9429,  ..., -0.8655,  0.1067,  0.4970],\n",
            "        [-0.4041, -0.4520, -0.9282,  ..., -0.8842,  0.4819,  0.7291],\n",
            "        [ 0.6978,  0.9973,  0.8450,  ...,  0.8135, -0.8148, -0.5187],\n",
            "        ...,\n",
            "        [ 0.7677,  0.9972,  0.9014,  ...,  0.8883, -0.7452, -0.0734],\n",
            "        [-0.5575,  0.9909, -0.9439,  ..., -0.9181, -0.0951,  0.6388],\n",
            "        [-0.6477, -0.9455, -0.9683,  ..., -0.8588,  0.4994,  0.5243]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6270,  0.9689, -0.8304,  ..., -0.8568,  0.4703,  0.4957],\n",
            "        [ 0.7523,  0.9969,  0.8422,  ...,  0.9118, -0.8311, -0.4657],\n",
            "        [-0.6052,  0.9998, -0.7696,  ..., -0.7476,  0.4310,  0.0137],\n",
            "        ...,\n",
            "        [ 0.7279,  0.9992,  0.8717,  ...,  0.9326, -0.7489, -0.3711],\n",
            "        [ 0.6535,  0.9985,  0.8490,  ...,  0.8148, -0.8229, -0.4660],\n",
            "        [ 0.7541,  0.9995,  0.8442,  ...,  0.8608, -0.4784, -0.4033]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6389,  0.9640,  0.8780,  ...,  0.8245, -0.8782, -0.0705],\n",
            "        [ 0.5581,  0.9996,  0.7644,  ...,  0.8547, -0.7973, -0.1804],\n",
            "        [ 0.6412,  0.9994,  0.8458,  ...,  0.8340, -0.7981, -0.4646],\n",
            "        ...,\n",
            "        [-0.6128, -0.9381, -0.9349,  ..., -0.9189,  0.1352,  0.6236],\n",
            "        [ 0.3509,  0.9797, -0.8674,  ..., -0.9136,  0.7887, -0.1298],\n",
            "        [-0.2564,  0.9972, -0.9195,  ..., -0.9372,  0.1590, -0.0786]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2863, -0.8083, -0.9630,  ..., -0.9227,  0.4556, -0.0717],\n",
            "        [-0.3054,  0.9999, -0.4004,  ..., -0.8213, -0.0649, -0.4307],\n",
            "        [ 0.5646,  0.9904,  0.8986,  ...,  0.9106, -0.8150, -0.2948],\n",
            "        ...,\n",
            "        [ 0.7318,  0.9988,  0.8996,  ...,  0.8720, -0.7785, -0.3560],\n",
            "        [ 0.6521,  0.9990,  0.8474,  ...,  0.8801, -0.8232, -0.2968],\n",
            "        [ 0.3282,  0.9982,  0.8990,  ...,  0.8166, -0.8023, -0.3922]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7769,  1.0000,  0.9351,  ...,  0.7448, -0.1931, -0.9102],\n",
            "        [ 0.5727,  0.9919,  0.8984,  ...,  0.8329, -0.8487,  0.0790],\n",
            "        [ 0.4324,  0.9796,  0.9260,  ...,  0.8503, -0.7283, -0.3150],\n",
            "        ...,\n",
            "        [-0.5622,  0.6405, -0.9466,  ..., -0.9321,  0.3180,  0.0740],\n",
            "        [ 0.7125,  0.9982,  0.8791,  ...,  0.9017, -0.7705, -0.2688],\n",
            "        [-0.3487, -0.8870, -0.9697,  ..., -0.9189,  0.2817,  0.4717]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5863,  0.9997,  0.9058,  ...,  0.8921, -0.6162, -0.6602],\n",
            "        [-0.2718, -0.9384, -0.9603,  ..., -0.8712,  0.3569,  0.4061],\n",
            "        [ 0.6806,  0.9995, -0.7896,  ..., -0.8834,  0.8287, -0.5768],\n",
            "        ...,\n",
            "        [ 0.6962,  0.9999,  0.9441,  ...,  0.7870, -0.6419, -0.5946],\n",
            "        [ 0.4638,  0.9988,  0.9148,  ...,  0.9265, -0.6771, -0.4050],\n",
            "        [ 0.3866,  0.9990,  0.8061,  ...,  0.8846, -0.7209, -0.0361]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7210,  0.9999,  0.9525,  ...,  0.8527, -0.6157, -0.6034],\n",
            "        [ 0.2055,  0.9999, -0.3973,  ..., -0.3471,  0.3805, -0.4354],\n",
            "        [-0.3006, -0.9878, -0.8945,  ..., -0.8553,  0.4710,  0.2035],\n",
            "        ...,\n",
            "        [ 0.6688,  0.9632,  0.7640,  ...,  0.8734, -0.8617, -0.1943],\n",
            "        [ 0.5807,  0.9939,  0.7786,  ...,  0.8660, -0.9056, -0.2196],\n",
            "        [ 0.6278,  0.9998,  0.9285,  ...,  0.8151, -0.8358, -0.3960]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6373,  0.9988,  0.8468,  ...,  0.8499, -0.8105, -0.3904],\n",
            "        [ 0.5279,  0.9943,  0.8612,  ...,  0.8266, -0.8733, -0.5149],\n",
            "        [ 0.5521,  0.9979,  0.8759,  ...,  0.7180, -0.6807, -0.3481],\n",
            "        ...,\n",
            "        [ 0.5640,  0.9990, -0.6243,  ..., -0.6344,  0.7095, -0.3899],\n",
            "        [-0.5892, -0.9277, -0.9490,  ..., -0.9172,  0.0885,  0.6151],\n",
            "        [-0.5267, -0.9969, -0.9425,  ..., -0.8532,  0.2459,  0.6809]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5425,  0.9993,  0.7246,  ...,  0.7722, -0.7048, -0.3801],\n",
            "        [ 0.7514,  0.9991,  0.9201,  ...,  0.8027, -0.7757, -0.6834],\n",
            "        [ 0.5397,  0.9992,  0.8747,  ...,  0.8302, -0.6532, -0.5724],\n",
            "        ...,\n",
            "        [-0.6430, -0.1457, -0.9140,  ..., -0.8661,  0.3331,  0.4338],\n",
            "        [ 0.6958,  0.9989,  0.7115,  ...,  0.8514, -0.8218, -0.1616],\n",
            "        [-0.4726, -0.2783, -0.8966,  ..., -0.8939,  0.2749,  0.3843]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6932,  0.9996,  0.9218,  ...,  0.9102, -0.7414, -0.3882],\n",
            "        [ 0.8644,  1.0000,  0.9459,  ...,  0.5212,  0.2428, -0.8467],\n",
            "        [-0.4720, -0.9541, -0.9288,  ..., -0.9257,  0.4282,  0.4130],\n",
            "        ...,\n",
            "        [ 0.5880,  0.9962,  0.7795,  ...,  0.8555, -0.8377, -0.3389],\n",
            "        [-0.6494, -0.3542, -0.9555,  ..., -0.9215, -0.0819,  0.5552],\n",
            "        [ 0.5736,  0.9947,  0.8383,  ...,  0.8760, -0.7013, -0.2424]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6110, -0.9397, -0.9484,  ..., -0.8677,  0.2364,  0.5776],\n",
            "        [ 0.5372,  0.9523,  0.7641,  ...,  0.8395, -0.8765, -0.2766],\n",
            "        [ 0.5036,  0.9999,  0.9225,  ...,  0.6067, -0.6686, -0.0505],\n",
            "        ...,\n",
            "        [ 0.5504,  0.9997,  0.7911,  ...,  0.8168, -0.6291, -0.6569],\n",
            "        [-0.6187,  0.8055, -0.8425,  ..., -0.9174,  0.0564, -0.0037],\n",
            "        [-0.1844,  0.9808, -0.9443,  ..., -0.7626,  0.4163, -0.0100]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5564,  0.9916,  0.8549,  ...,  0.7961, -0.8438,  0.1472],\n",
            "        [ 0.5603,  0.9980,  0.8625,  ...,  0.8909, -0.8784, -0.1092],\n",
            "        [-0.6494, -0.9984, -0.9642,  ..., -0.9098,  0.0103,  0.7328],\n",
            "        ...,\n",
            "        [-0.6456, -0.6856, -0.8958,  ..., -0.9247,  0.2529,  0.5055],\n",
            "        [ 0.5713,  0.9977,  0.8442,  ...,  0.8448, -0.8630, -0.3507],\n",
            "        [-0.1316, -0.0873, -0.8886,  ..., -0.8317,  0.2655,  0.3043]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4605, -0.9973, -0.9298,  ..., -0.9458,  0.1232,  0.5140],\n",
            "        [ 0.6724,  0.8952,  0.8403,  ...,  0.8805, -0.8601, -0.3576],\n",
            "        [-0.4001, -0.9231, -0.9484,  ..., -0.9080,  0.2888,  0.5428],\n",
            "        ...,\n",
            "        [ 0.4989,  0.9962,  0.8196,  ...,  0.9005, -0.8836, -0.4170],\n",
            "        [ 0.6113,  0.9989,  0.8621,  ...,  0.8667, -0.7827, -0.5063],\n",
            "        [ 0.5976,  0.9997,  0.9071,  ...,  0.9070, -0.8051, -0.3987]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6442, -0.9055, -0.9317,  ..., -0.8539,  0.1585,  0.7246],\n",
            "        [ 0.6651,  0.9579,  0.7658,  ...,  0.9236, -0.8647, -0.1745],\n",
            "        [ 0.6025,  0.9977,  0.8110,  ...,  0.7941, -0.8260, -0.4117],\n",
            "        ...,\n",
            "        [ 0.6166,  0.9643,  0.8914,  ...,  0.8308, -0.7931, -0.3482],\n",
            "        [-0.7496, -0.9133, -0.9113,  ..., -0.7639,  0.1708,  0.7687],\n",
            "        [-0.4576,  0.9502, -0.9058,  ..., -0.9305,  0.3885,  0.5585]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.8287, -0.5456, -0.8808,  ..., -0.8985,  0.2177,  0.5101],\n",
            "        [ 0.4707,  0.9768,  0.7311,  ...,  0.8983, -0.8635, -0.2438],\n",
            "        [ 0.7198,  0.9997,  0.8266,  ...,  0.8397, -0.7153, -0.1829],\n",
            "        ...,\n",
            "        [ 0.7542,  0.9987,  0.9092,  ...,  0.9269, -0.7558, -0.4243],\n",
            "        [ 0.7425,  0.9986,  0.6971,  ...,  0.8510, -0.8816, -0.5466],\n",
            "        [ 0.6414,  0.9984,  0.8898,  ...,  0.9004, -0.7856, -0.5087]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.8417,  0.5280, -0.7959,  ..., -0.7276,  0.1505,  0.8513],\n",
            "        [ 0.2528,  0.9985,  0.7097,  ...,  0.7863, -0.8641, -0.1932],\n",
            "        [-0.5692,  0.9012, -0.9071,  ..., -0.8824,  0.3726,  0.2262],\n",
            "        ...,\n",
            "        [-0.5153, -0.3862, -0.9203,  ..., -0.8746,  0.3385,  0.4715],\n",
            "        [-0.4480, -0.9005, -0.9651,  ..., -0.9070,  0.2283,  0.6573],\n",
            "        [-0.5143, -0.9485, -0.9187,  ..., -0.8289,  0.0804,  0.5802]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7525,  0.9965,  0.7245,  ...,  0.8185, -0.6473, -0.4535],\n",
            "        [-0.5875, -0.9994, -0.9565,  ..., -0.8884,  0.3746,  0.6353],\n",
            "        [-0.6791,  0.3912, -0.9324,  ..., -0.8729,  0.2338,  0.5221],\n",
            "        ...,\n",
            "        [-0.7015, -0.9623, -0.9273,  ..., -0.8819,  0.3855,  0.6738],\n",
            "        [ 0.6523,  0.9939,  0.8334,  ...,  0.9136, -0.8108, -0.0990],\n",
            "        [ 0.4491,  0.9983,  0.8942,  ...,  0.9200, -0.7791, -0.1213]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6111,  0.9910,  0.8719,  ...,  0.9164, -0.7665, -0.2494],\n",
            "        [ 0.6535,  0.9995,  0.8463,  ...,  0.9353, -0.8251, -0.2293],\n",
            "        [ 0.0634,  0.9659, -0.9001,  ..., -0.8591,  0.5442,  0.0581],\n",
            "        ...,\n",
            "        [ 0.6714,  0.9810,  0.8594,  ...,  0.8994, -0.8340, -0.3932],\n",
            "        [-0.5360, -0.1599, -0.9066,  ..., -0.8568,  0.3744,  0.7219],\n",
            "        [-0.6351, -0.4422, -0.9370,  ..., -0.8655,  0.2760,  0.5497]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6029, -0.5510, -0.9533,  ..., -0.8992,  0.0738,  0.6573],\n",
            "        [ 0.6499,  0.9941,  0.8341,  ...,  0.9078, -0.8195, -0.3343],\n",
            "        [ 0.5886,  0.9934,  0.7561,  ...,  0.8496, -0.8383, -0.2104],\n",
            "        ...,\n",
            "        [ 0.4584,  0.9999,  0.7967,  ...,  0.6020, -0.8864, -0.5254],\n",
            "        [ 0.6747,  0.9887,  0.8641,  ...,  0.8407, -0.7546, -0.2467],\n",
            "        [-0.6061, -0.8888, -0.9489,  ..., -0.8939,  0.1859,  0.6446]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6499,  0.9988,  0.8544,  ...,  0.7815, -0.8216, -0.6069],\n",
            "        [ 0.6734,  0.9705,  0.7728,  ...,  0.8729, -0.8130, -0.3792],\n",
            "        [-0.6679, -0.7381, -0.9534,  ..., -0.8753,  0.1973,  0.6999],\n",
            "        ...,\n",
            "        [-0.3831, -0.9565, -0.9377,  ..., -0.8349,  0.0425,  0.6049],\n",
            "        [-0.7137, -0.9910, -0.8875,  ..., -0.8978,  0.0835,  0.6050],\n",
            "        [-0.4984, -0.9983, -0.9504,  ..., -0.8743,  0.2145,  0.6688]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6002,  0.9753,  0.8984,  ...,  0.8259, -0.8371, -0.3166],\n",
            "        [-0.5519,  0.1898, -0.8878,  ..., -0.9361,  0.2399,  0.2977],\n",
            "        [ 0.4052,  0.9864,  0.8072,  ...,  0.8589, -0.8666, -0.1388],\n",
            "        ...,\n",
            "        [ 0.6511,  0.9992,  0.8139,  ...,  0.7400, -0.7927, -0.5563],\n",
            "        [-0.7174, -0.8981, -0.9043,  ..., -0.8776,  0.1262,  0.6757],\n",
            "        [ 0.5300,  0.9976,  0.7239,  ...,  0.8883, -0.8054, -0.3969]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6076,  0.9969,  0.7849,  ...,  0.8761, -0.9011, -0.1763],\n",
            "        [ 0.7301,  0.9980,  0.7094,  ...,  0.9201, -0.8597, -0.2638],\n",
            "        [ 0.5194,  0.9971,  0.8627,  ...,  0.8727, -0.8137, -0.3897],\n",
            "        ...,\n",
            "        [ 0.4851,  1.0000,  0.8940,  ...,  0.8504, -0.7010, -0.5037],\n",
            "        [ 0.6391,  0.9919,  0.7797,  ...,  0.9193, -0.8249, -0.1383],\n",
            "        [-0.5173,  0.5067, -0.9488,  ..., -0.8638,  0.2548,  0.3609]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0623,  0.9967, -0.8398,  ..., -0.8649,  0.1092, -0.1018],\n",
            "        [ 0.6462,  0.9962,  0.9259,  ...,  0.9007, -0.8197, -0.5226],\n",
            "        [-0.5234, -0.7450, -0.9604,  ..., -0.8434,  0.2237,  0.6410],\n",
            "        ...,\n",
            "        [-0.6496,  0.6514, -0.9503,  ..., -0.9079, -0.1985,  0.6854],\n",
            "        [ 0.7164,  0.9974,  0.8305,  ...,  0.6285, -0.8657, -0.4866],\n",
            "        [ 0.5850,  1.0000,  0.9389,  ...,  0.4802, -0.0405, -0.9747]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0747,  0.2861, -0.7502,  ..., -0.7369,  0.6045,  0.1695],\n",
            "        [-0.4047,  0.8597, -0.9312,  ..., -0.8755,  0.0563,  0.5631],\n",
            "        [ 0.4217,  0.9865,  0.7453,  ...,  0.8923, -0.9166, -0.0502],\n",
            "        ...,\n",
            "        [-0.6034, -0.8898, -0.9190,  ..., -0.9067,  0.0411,  0.5454],\n",
            "        [ 0.6880,  0.9998,  0.8380,  ...,  0.7954, -0.6537, -0.2624],\n",
            "        [-0.3441, -0.5196, -0.9377,  ..., -0.9041,  0.3972,  0.4313]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3918,  1.0000,  0.8844,  ...,  0.7942, -0.4869, -0.5006],\n",
            "        [-0.5062, -0.4336, -0.9025,  ..., -0.9254, -0.1889,  0.5395],\n",
            "        [ 0.3785,  0.9999,  0.7710,  ...,  0.8406, -0.7556, -0.4924],\n",
            "        ...,\n",
            "        [ 0.6890,  0.9927,  0.7483,  ...,  0.8972, -0.8166, -0.2230],\n",
            "        [ 0.6150,  0.9999,  0.8947,  ...,  0.8374, -0.5128, -0.5724],\n",
            "        [ 0.7099,  0.9995,  0.9127,  ...,  0.7800, -0.7922, -0.6664]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.8544,  0.9987,  0.6788,  ...,  0.9197, -0.7249, -0.6134],\n",
            "        [-0.7718, -0.8996, -0.8693,  ..., -0.8264, -0.0509,  0.6820],\n",
            "        [-0.7878, -0.7268, -0.9275,  ..., -0.9099, -0.0792,  0.6705],\n",
            "        ...,\n",
            "        [-0.2489,  0.9057, -0.8459,  ..., -0.8851,  0.1923,  0.1930],\n",
            "        [-0.5298, -0.9397, -0.9603,  ..., -0.8071,  0.1688,  0.6710],\n",
            "        [-0.6175,  0.2385, -0.9307,  ..., -0.9258,  0.2188,  0.6726]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5257,  0.9757, -0.6336,  ..., -0.8749,  0.1501, -0.6283],\n",
            "        [-0.6788, -0.9996, -0.9279,  ..., -0.8506,  0.2173,  0.7839],\n",
            "        [-0.4335,  0.8235, -0.9331,  ..., -0.9074,  0.0605,  0.4189],\n",
            "        ...,\n",
            "        [ 0.7531,  0.9985,  0.8393,  ...,  0.8203, -0.8196, -0.1443],\n",
            "        [ 0.5356,  0.9991,  0.8382,  ...,  0.8652, -0.8604, -0.3977],\n",
            "        [-0.4097, -0.7264, -0.9623,  ..., -0.9181, -0.2110,  0.3311]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4993,  0.9941,  0.8580,  ...,  0.8873, -0.8685, -0.1091],\n",
            "        [-0.6001, -0.8115, -0.9380,  ..., -0.9006,  0.3041,  0.6708],\n",
            "        [ 0.6521,  0.9894,  0.7820,  ...,  0.8556, -0.7659, -0.3141],\n",
            "        ...,\n",
            "        [ 0.6142,  0.9964,  0.8721,  ...,  0.8728, -0.7472, -0.2652],\n",
            "        [-0.5319, -0.9231, -0.9032,  ..., -0.7897,  0.3092,  0.4695],\n",
            "        [ 0.6818,  0.9893,  0.9084,  ...,  0.8825, -0.8033, -0.2117]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6098,  1.0000,  0.9421,  ...,  0.9076, -0.5276, -0.6408],\n",
            "        [-0.5416,  0.4027, -0.9282,  ..., -0.7436,  0.5631, -0.1726],\n",
            "        [ 0.7059,  0.9984,  0.8564,  ...,  0.8828, -0.7497, -0.3583],\n",
            "        ...,\n",
            "        [ 0.7195,  0.9998,  0.9503,  ...,  0.8430, -0.6254, -0.6774],\n",
            "        [-0.3491, -0.0923, -0.9532,  ..., -0.8867,  0.4411,  0.4703],\n",
            "        [ 0.1834, -0.1834, -0.7642,  ..., -0.8463,  0.3992,  0.2062]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5738,  0.9989,  0.8080,  ...,  0.8621, -0.7576, -0.6717],\n",
            "        [ 0.6858,  0.9994,  0.8795,  ...,  0.8954, -0.8562, -0.3543],\n",
            "        [-0.7580, -0.7727, -0.9348,  ..., -0.9005,  0.1433,  0.5390],\n",
            "        ...,\n",
            "        [-0.6109, -0.6188, -0.9540,  ..., -0.9118,  0.0906,  0.5801],\n",
            "        [-0.4140, -0.6481, -0.9382,  ..., -0.8749,  0.2785,  0.5933],\n",
            "        [ 0.6567,  1.0000,  0.7555,  ...,  0.3888, -0.3460, -0.7956]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6604,  0.9979,  0.8799,  ...,  0.9295, -0.7401, -0.4132],\n",
            "        [-0.5518,  0.5689, -0.9228,  ..., -0.8914, -0.1207,  0.6248],\n",
            "        [-0.6150, -0.9598, -0.9106,  ..., -0.9445,  0.3188,  0.8394],\n",
            "        ...,\n",
            "        [ 0.5653,  0.9901,  0.8151,  ...,  0.7719, -0.7763, -0.4317],\n",
            "        [ 0.7474,  0.9996,  0.8882,  ...,  0.9243, -0.6572, -0.6459],\n",
            "        [ 0.7404,  0.9976,  0.8523,  ...,  0.8452, -0.6909, -0.5194]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5639,  0.9905,  0.8138,  ...,  0.8871, -0.8484, -0.1848],\n",
            "        [ 0.3609,  0.9994,  0.8647,  ...,  0.8875, -0.6732, -0.4699],\n",
            "        [-0.7284,  0.4323, -0.9212,  ..., -0.9181,  0.4336,  0.4020],\n",
            "        ...,\n",
            "        [-0.4939,  0.9114, -0.9095,  ..., -0.7660,  0.2976,  0.6499],\n",
            "        [ 0.7800,  0.9983,  0.7012,  ...,  0.8726, -0.6526, -0.2717],\n",
            "        [ 0.7193,  1.0000,  0.9098,  ...,  0.9211, -0.3982, -0.8655]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.7079,  0.9782, -0.9237,  ..., -0.9299,  0.4017,  0.1638],\n",
            "        [ 0.7825,  1.0000,  0.7319,  ...,  0.8374, -0.7293, -0.4240],\n",
            "        [-0.6318, -0.9876, -0.9178,  ..., -0.8716,  0.0817,  0.8017],\n",
            "        ...,\n",
            "        [ 0.7128,  0.9997,  0.9106,  ...,  0.8800, -0.7471, -0.5809],\n",
            "        [ 0.6415,  0.9998,  0.7929,  ...,  0.8093, -0.7816, -0.5720],\n",
            "        [ 0.5438,  0.9898,  0.7651,  ...,  0.8587, -0.8341, -0.1459]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5322, -0.4283, -0.8746,  ..., -0.8812,  0.2448,  0.2954],\n",
            "        [ 0.5182,  0.9978,  0.7617,  ...,  0.7888, -0.8387, -0.5184],\n",
            "        [-0.7109, -0.0228, -0.8946,  ..., -0.8382,  0.5471,  0.6284],\n",
            "        ...,\n",
            "        [ 0.4719,  0.9997,  0.9124,  ...,  0.8506, -0.8114, -0.4242],\n",
            "        [ 0.5546,  0.9999,  0.7556,  ...,  0.6096, -0.5037, -0.7965],\n",
            "        [-0.6213, -0.0541, -0.9472,  ..., -0.9105,  0.2960,  0.4992]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7362,  0.9724,  0.8912,  ...,  0.9290, -0.7794, -0.2989],\n",
            "        [ 0.6884,  1.0000,  0.9612,  ...,  0.7756, -0.3279, -0.8789],\n",
            "        [-0.5835,  0.5765, -0.9246,  ..., -0.8889,  0.5082,  0.4925],\n",
            "        ...,\n",
            "        [-0.5326, -0.5844, -0.9189,  ..., -0.7914,  0.1160,  0.7676],\n",
            "        [ 0.5971,  0.9924,  0.5642,  ...,  0.7482, -0.8455,  0.1245],\n",
            "        [-0.6479, -0.4228, -0.9294,  ..., -0.8469,  0.1228,  0.4879]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7464,  0.9861,  0.9109,  ...,  0.7744, -0.7523, -0.6583],\n",
            "        [ 0.7413,  0.9969,  0.8725,  ...,  0.9242, -0.8206, -0.2382],\n",
            "        [ 0.5815,  0.9999,  0.9430,  ...,  0.7613, -0.5471, -0.6552],\n",
            "        ...,\n",
            "        [-0.4218, -0.9848, -0.8868,  ..., -0.8400,  0.6667,  0.1985],\n",
            "        [-0.5101,  0.8098, -0.9310,  ..., -0.9057,  0.3893,  0.2083],\n",
            "        [ 0.6342,  0.9985,  0.8392,  ...,  0.8186, -0.7222, -0.5906]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6866,  1.0000, -0.7640,  ..., -0.7002,  0.7905, -0.7842],\n",
            "        [-0.7448, -0.5023, -0.9374,  ..., -0.8833,  0.1695,  0.8395],\n",
            "        [-0.4194,  0.6551, -0.8908,  ..., -0.9019,  0.4343,  0.4742],\n",
            "        ...,\n",
            "        [-0.1425, -0.6784, -0.9420,  ..., -0.8813,  0.5687,  0.4973],\n",
            "        [ 0.4041,  0.9746,  0.8041,  ...,  0.8018, -0.8540, -0.2956],\n",
            "        [-0.7990, -0.7596, -0.9173,  ..., -0.8926, -0.0968,  0.8442]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7183,  0.9942,  0.8661,  ...,  0.8831, -0.8193, -0.2402],\n",
            "        [ 0.6407,  0.9974,  0.7985,  ...,  0.9071, -0.8260, -0.1970],\n",
            "        [-0.3324,  0.1275, -0.9017,  ..., -0.8665,  0.1042,  0.7107],\n",
            "        ...,\n",
            "        [ 0.6924,  0.9998,  0.8581,  ...,  0.8051, -0.6405, -0.2705],\n",
            "        [ 0.5367,  0.9995,  0.7923,  ...,  0.8738, -0.8100, -0.2265],\n",
            "        [ 0.5439,  0.9973,  0.8351,  ...,  0.8214, -0.7675, -0.3008]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7773,  0.9977,  0.9119,  ...,  0.8723, -0.7383, -0.2627],\n",
            "        [-0.1944,  0.9977, -0.7789,  ..., -0.8663,  0.3642, -0.4956],\n",
            "        [ 0.6693,  0.9975,  0.7794,  ...,  0.9053, -0.8711, -0.0782],\n",
            "        ...,\n",
            "        [ 0.5348,  1.0000,  0.9172,  ...,  0.8871, -0.4975, -0.7824],\n",
            "        [ 0.6150,  0.9997,  0.7591,  ...,  0.5862, -0.6289, -0.6546],\n",
            "        [-0.4064, -0.4815, -0.8556,  ..., -0.7637,  0.3539,  0.1894]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4940, -0.8793, -0.9346,  ..., -0.8166,  0.1536,  0.7446],\n",
            "        [ 0.4792,  0.9996,  0.8710,  ...,  0.7969, -0.7780, -0.5972],\n",
            "        [ 0.5406,  0.9988,  0.7837,  ...,  0.8797, -0.7693, -0.5218],\n",
            "        ...,\n",
            "        [ 0.4528,  0.9882,  0.8652,  ...,  0.9170, -0.8388,  0.0476],\n",
            "        [ 0.5548,  1.0000,  0.8777,  ...,  0.5555,  0.1603, -0.8361],\n",
            "        [ 0.5385,  0.9942,  0.8881,  ...,  0.8701, -0.8666, -0.6015]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0370, -0.8892, -0.7692,  ..., -0.6023,  0.3211,  0.0077],\n",
            "        [-0.2714, -0.7900, -0.9067,  ..., -0.9405,  0.3608,  0.3936],\n",
            "        [-0.4605, -0.9256, -0.9300,  ..., -0.9214,  0.3433,  0.5637],\n",
            "        ...,\n",
            "        [-0.3393,  0.6569, -0.7915,  ..., -0.6463,  0.4344,  0.4480],\n",
            "        [-0.6658,  0.8783, -0.9325,  ..., -0.8109,  0.4165,  0.6280],\n",
            "        [-0.3468, -0.6411, -0.9428,  ..., -0.8982,  0.5467,  0.1194]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7495,  0.9965,  0.8322,  ...,  0.8700, -0.7308, -0.5701],\n",
            "        [-0.4440, -0.4111, -0.9177,  ..., -0.8425,  0.4016,  0.2643],\n",
            "        [-0.3205, -0.1697, -0.9291,  ..., -0.8607,  0.6570,  0.4483],\n",
            "        ...,\n",
            "        [ 0.6271,  0.9998, -0.0412,  ..., -0.4589,  0.7326, -0.6859],\n",
            "        [-0.6239,  0.8329, -0.8623,  ..., -0.8520,  0.1644,  0.1654],\n",
            "        [ 0.7826,  0.9979,  0.9345,  ...,  0.5653, -0.6037, -0.7885]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2254,  0.6451, -0.9162,  ..., -0.8842,  0.2342,  0.3509],\n",
            "        [ 0.5710,  0.9997,  0.8609,  ...,  0.7736, -0.5520, -0.3850],\n",
            "        [ 0.5872,  0.9947,  0.7617,  ...,  0.7235, -0.7829, -0.1909],\n",
            "        ...,\n",
            "        [-0.5087, -0.9760, -0.9533,  ..., -0.8736,  0.1408,  0.6374],\n",
            "        [-0.4481, -0.9298, -0.9267,  ..., -0.8510,  0.2856,  0.5556],\n",
            "        [-0.5826, -0.2079, -0.9513,  ..., -0.9235,  0.1367,  0.2993]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7422,  0.9999,  0.9301,  ...,  0.9042, -0.5704, -0.7309],\n",
            "        [ 0.2113,  0.9792,  0.8385,  ...,  0.8774, -0.8203, -0.2984],\n",
            "        [ 0.6526,  0.9999,  0.8476,  ...,  0.8821, -0.8010, -0.3279],\n",
            "        ...,\n",
            "        [-0.5926, -0.1849, -0.9125,  ..., -0.8883,  0.1781,  0.7406],\n",
            "        [ 0.5040,  1.0000,  0.8935,  ...,  0.8523, -0.4647, -0.7863],\n",
            "        [ 0.4980,  0.9828,  0.8108,  ...,  0.9131, -0.8178, -0.1863]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3878,  0.9987, -0.8886,  ..., -0.7736,  0.3745, -0.0818],\n",
            "        [ 0.6020,  0.9706,  0.8051,  ...,  0.8955, -0.8255, -0.1931],\n",
            "        [-0.3196,  0.9383, -0.7076,  ..., -0.9103,  0.6025, -0.0951],\n",
            "        ...,\n",
            "        [ 0.4360,  0.9977,  0.8167,  ...,  0.8386, -0.8432, -0.3629],\n",
            "        [ 0.6064,  0.9967,  0.8085,  ...,  0.7256, -0.7483, -0.6147],\n",
            "        [-0.4669,  0.4369, -0.8852,  ..., -0.8423,  0.1505,  0.5688]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6467,  0.9960,  0.8512,  ...,  0.8811, -0.7844, -0.2818],\n",
            "        [ 0.8266,  0.9995,  0.8571,  ...,  0.8603, -0.8635, -0.4046],\n",
            "        [-0.6998, -0.9322, -0.9189,  ..., -0.9007,  0.1123,  0.5241],\n",
            "        ...,\n",
            "        [-0.7330, -0.8031, -0.9139,  ..., -0.9172,  0.0129,  0.6947],\n",
            "        [ 0.7124,  0.9998,  0.9580,  ...,  0.8699, -0.5646, -0.7237],\n",
            "        [-0.7886,  0.1748, -0.9218,  ..., -0.8864,  0.4204,  0.8059]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5502, -0.9740, -0.9039,  ..., -0.9059,  0.3971,  0.2997],\n",
            "        [-0.6186, -0.9928, -0.9512,  ..., -0.9443,  0.1489,  0.6958],\n",
            "        [-0.3603,  0.9340, -0.9362,  ..., -0.8964,  0.2497,  0.5221],\n",
            "        ...,\n",
            "        [ 0.7028,  0.9998,  0.9252,  ...,  0.8423, -0.7544, -0.5695],\n",
            "        [ 0.6584,  0.9970,  0.8663,  ...,  0.8827, -0.8254, -0.4340],\n",
            "        [ 0.6998,  1.0000,  0.9559,  ...,  0.8450, -0.3834, -0.8632]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5484,  0.7115, -0.9720,  ..., -0.9137,  0.4951,  0.5026],\n",
            "        [-0.7858, -0.0898, -0.9361,  ..., -0.8280,  0.0402,  0.5889],\n",
            "        [ 0.6142,  1.0000,  0.8689,  ...,  0.0792,  0.4581, -0.9745],\n",
            "        ...,\n",
            "        [ 0.5553,  0.9993,  0.6673,  ...,  0.7681, -0.7649, -0.2504],\n",
            "        [-0.5725, -0.6301, -0.9376,  ..., -0.8834,  0.1729,  0.4190],\n",
            "        [ 0.7293,  0.9987,  0.7354,  ...,  0.8773, -0.6549, -0.1465]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6485,  0.9983,  0.8042,  ...,  0.9008, -0.8373, -0.5810],\n",
            "        [ 0.4439,  0.9968,  0.8377,  ...,  0.7425, -0.8051, -0.1575],\n",
            "        [ 0.4686,  0.9981,  0.8373,  ...,  0.8852, -0.7715, -0.5302],\n",
            "        ...,\n",
            "        [-0.4642,  0.7551, -0.8810,  ..., -0.8031, -0.1189,  0.6158],\n",
            "        [ 0.4334,  0.9990,  0.9101,  ...,  0.8609, -0.7750, -0.4342],\n",
            "        [-0.0913, -0.7547, -0.9303,  ..., -0.9070,  0.0809,  0.6397]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.8172,  1.0000,  0.9532,  ...,  0.7855, -0.2573, -0.9105],\n",
            "        [ 0.5598,  1.0000,  0.8656,  ...,  0.8900, -0.5855, -0.5063],\n",
            "        [ 0.6587,  1.0000,  0.9137,  ...,  0.8495, -0.8436, -0.5011],\n",
            "        ...,\n",
            "        [ 0.4711,  0.9985,  0.8649,  ...,  0.9307, -0.8215, -0.0373],\n",
            "        [-0.4183, -0.5458, -0.9189,  ..., -0.7833,  0.0181,  0.5714],\n",
            "        [ 0.5886,  0.9999,  0.9186,  ...,  0.8164, -0.7281, -0.5966]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4301,  0.4558, -0.9395,  ..., -0.8795,  0.2853,  0.2617],\n",
            "        [-0.5486,  0.1263, -0.9087,  ..., -0.8980,  0.1407,  0.2789],\n",
            "        [-0.5327, -0.9774, -0.9130,  ..., -0.8699,  0.1485,  0.7057],\n",
            "        ...,\n",
            "        [ 0.5985,  0.9992,  0.9245,  ...,  0.9475, -0.8320, -0.4972],\n",
            "        [ 0.5774,  0.9933,  0.6951,  ...,  0.8705, -0.7666, -0.3374],\n",
            "        [ 0.4617,  0.9986,  0.8123,  ...,  0.8784, -0.7986, -0.2923]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5014, -0.9904, -0.9100,  ..., -0.9078, -0.0879,  0.6463],\n",
            "        [ 0.6363,  1.0000,  0.9302,  ...,  0.8873, -0.4951, -0.8084],\n",
            "        [-0.5723, -0.6263, -0.8543,  ..., -0.8395,  0.0334,  0.6817],\n",
            "        ...,\n",
            "        [-0.4620,  0.9991, -0.8352,  ..., -0.8991,  0.4745, -0.5789],\n",
            "        [-0.2756, -0.9813, -0.9388,  ..., -0.7799,  0.4480,  0.5324],\n",
            "        [ 0.7363,  0.9917,  0.8106,  ...,  0.9108, -0.7917, -0.1603]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6106,  0.9960,  0.9110,  ...,  0.8055, -0.8092, -0.5970],\n",
            "        [ 0.7694,  0.9995,  0.8497,  ...,  0.9079, -0.8198, -0.3081],\n",
            "        [ 0.6985,  1.0000,  0.9251,  ...,  0.5270,  0.4389, -0.9565],\n",
            "        ...,\n",
            "        [-0.5253, -0.4342, -0.8627,  ..., -0.9348,  0.2550,  0.3451],\n",
            "        [ 0.5975,  0.9993,  0.7609,  ...,  0.8730, -0.8254, -0.2629],\n",
            "        [ 0.6808,  0.9886,  0.7376,  ...,  0.8126, -0.8095, -0.2331]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5686, -0.8390, -0.9529,  ..., -0.8562,  0.4249,  0.5532],\n",
            "        [-0.4073, -0.9675, -0.9455,  ..., -0.8636,  0.3032,  0.6374],\n",
            "        [-0.1126,  0.8843, -0.7819,  ..., -0.8840,  0.6507, -0.4914],\n",
            "        ...,\n",
            "        [-0.7250, -0.9840, -0.9405,  ..., -0.8537,  0.3457,  0.6407],\n",
            "        [ 0.6714,  0.9989,  0.7679,  ...,  0.8831, -0.8366, -0.2057],\n",
            "        [-0.6452, -0.9869, -0.9013,  ..., -0.8789,  0.3946,  0.7608]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.7908,  0.9997, -0.0872,  ..., -0.6694,  0.4362, -0.4290],\n",
            "        [ 0.6347,  0.9629,  0.8664,  ...,  0.8841, -0.8708, -0.0726],\n",
            "        [-0.4669, -0.9602, -0.9639,  ..., -0.8987,  0.2701,  0.6103],\n",
            "        ...,\n",
            "        [ 0.7901,  1.0000,  0.9645,  ...,  0.6856, -0.1657, -0.9392],\n",
            "        [-0.4876,  0.8968, -0.7835,  ..., -0.6471,  0.5909,  0.1278],\n",
            "        [ 0.6655,  0.9996,  0.9400,  ...,  0.8435, -0.6396, -0.5645]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6821,  1.0000,  0.8055,  ..., -0.0448,  0.4236, -0.9385],\n",
            "        [-0.2924,  0.9991,  0.0468,  ..., -0.7142,  0.3370, -0.8174],\n",
            "        [-0.5576, -0.9655, -0.9651,  ..., -0.9131,  0.1799,  0.4991],\n",
            "        ...,\n",
            "        [ 0.5572,  0.9971,  0.9128,  ...,  0.9291, -0.8104, -0.5689],\n",
            "        [-0.2772,  0.2120, -0.9622,  ..., -0.8190,  0.2759,  0.4898],\n",
            "        [ 0.5571,  0.9991,  0.8029,  ...,  0.8920, -0.7137, -0.2578]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6341,  0.9998,  0.8243,  ...,  0.8337, -0.7589, -0.1548],\n",
            "        [ 0.5787,  0.9980,  0.8320,  ...,  0.8923, -0.8764, -0.3676],\n",
            "        [-0.6368,  0.6750, -0.9468,  ..., -0.9405,  0.1455,  0.8329],\n",
            "        ...,\n",
            "        [ 0.0696,  1.0000,  0.4464,  ...,  0.4089,  0.8023, -0.7525],\n",
            "        [ 0.6557,  0.9632,  0.8223,  ...,  0.9075, -0.8844, -0.3954],\n",
            "        [-0.7641,  0.7089, -0.9275,  ..., -0.8279,  0.4883,  0.3970]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4908,  0.9649, -0.9323,  ..., -0.9009,  0.3999,  0.4930],\n",
            "        [ 0.6394,  0.9999,  0.8358,  ...,  0.8753, -0.8550, -0.6863],\n",
            "        [ 0.3504,  1.0000,  0.9487,  ...,  0.3129, -0.0697, -0.9139],\n",
            "        ...,\n",
            "        [ 0.1475,  0.9743,  0.8695,  ...,  0.7136, -0.6236, -0.7327],\n",
            "        [ 0.6869,  0.9991,  0.8105,  ...,  0.8491, -0.8313, -0.4146],\n",
            "        [-0.7336,  0.9691, -0.9082,  ..., -0.9245,  0.2075,  0.4843]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6464, -0.9993, -0.9068,  ..., -0.7722,  0.3637,  0.7185],\n",
            "        [-0.5590, -0.9792, -0.9572,  ..., -0.8876,  0.4430,  0.6227],\n",
            "        [-0.7372, -0.8572, -0.9360,  ..., -0.8941,  0.2504,  0.8056],\n",
            "        ...,\n",
            "        [-0.6792,  0.9092, -0.9164,  ..., -0.8454,  0.3518,  0.1184],\n",
            "        [-0.3936,  0.0655, -0.8453,  ..., -0.9382,  0.1608,  0.4617],\n",
            "        [-0.5748, -0.6820, -0.9174,  ..., -0.8472,  0.6615,  0.4715]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.7559, -0.9902, -0.9301,  ..., -0.9044,  0.4276,  0.7346],\n",
            "        [-0.1763,  0.8831, -0.8102,  ..., -0.8684,  0.2048, -0.4374],\n",
            "        [-0.5300, -0.9860, -0.8885,  ..., -0.8124,  0.0498,  0.6916],\n",
            "        ...,\n",
            "        [ 0.4825,  1.0000,  0.9337,  ...,  0.2389,  0.6226, -0.9725],\n",
            "        [-0.5431, -0.9613, -0.9344,  ..., -0.9023,  0.2287,  0.6605],\n",
            "        [ 0.4648,  1.0000,  0.9358,  ...,  0.3641,  0.4806, -0.9791]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2681,  0.2178, -0.9429,  ..., -0.8866,  0.4859,  0.4525],\n",
            "        [ 0.8505,  0.9999,  0.8668,  ...,  0.8937, -0.6655, -0.6627],\n",
            "        [-0.5722, -0.0647, -0.8921,  ..., -0.7356,  0.3300,  0.5571],\n",
            "        ...,\n",
            "        [-0.3712, -0.8234, -0.8948,  ..., -0.8168,  0.3928, -0.0303],\n",
            "        [ 0.7210,  0.9999,  0.9260,  ...,  0.8662, -0.8042, -0.8157],\n",
            "        [-0.6848, -0.6574, -0.9114,  ..., -0.8695,  0.2278,  0.4535]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5308,  0.0193, -0.9439,  ..., -0.8628,  0.1059,  0.6578],\n",
            "        [ 0.6505,  0.9996,  0.7935,  ...,  0.7041, -0.7367, -0.0857],\n",
            "        [ 0.6983,  0.9986,  0.7858,  ...,  0.8706, -0.8261, -0.4049],\n",
            "        ...,\n",
            "        [-0.5642, -0.5907, -0.8935,  ..., -0.9108,  0.3378,  0.7996],\n",
            "        [-0.5774, -0.6091, -0.9347,  ..., -0.9169,  0.2305,  0.6831],\n",
            "        [ 0.5056,  0.9875,  0.8448,  ...,  0.8963, -0.8916, -0.1858]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2345, -0.2142, -0.9451,  ..., -0.8886,  0.2201,  0.3357],\n",
            "        [-0.3459, -0.9876, -0.9273,  ..., -0.9292,  0.2859,  0.6300],\n",
            "        [ 0.8027,  1.0000,  0.3836,  ..., -0.7492,  0.7192, -0.9762],\n",
            "        ...,\n",
            "        [-0.4987,  0.9890, -0.7513,  ..., -0.7490,  0.3189, -0.1701],\n",
            "        [ 0.4241,  0.9992,  0.7504,  ...,  0.6984, -0.6833, -0.5160],\n",
            "        [ 0.5999,  0.9978,  0.9001,  ...,  0.9307, -0.7466, -0.4991]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3517,  0.9975,  0.8448,  ...,  0.8540, -0.8255, -0.3782],\n",
            "        [ 0.8089,  1.0000,  0.3088,  ..., -0.5032,  0.6307, -0.9462],\n",
            "        [-0.4798,  0.9014, -0.9337,  ..., -0.8803, -0.0336,  0.6419],\n",
            "        ...,\n",
            "        [-0.6370, -0.6942, -0.9312,  ..., -0.9005,  0.1437,  0.6082],\n",
            "        [-0.3884,  0.9421, -0.8852,  ..., -0.6414,  0.6502,  0.1369],\n",
            "        [ 0.6533,  0.9999,  0.8921,  ...,  0.8429, -0.6974, -0.5881]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5257,  0.9985,  0.8644,  ...,  0.8742, -0.7852, -0.0746],\n",
            "        [ 0.6862,  1.0000,  0.8721,  ...,  0.8718, -0.6242, -0.6140],\n",
            "        [ 0.7287,  0.9999,  0.9511,  ...,  0.8829, -0.5472, -0.6921],\n",
            "        ...,\n",
            "        [ 0.6207,  1.0000,  0.9311,  ...,  0.7845,  0.3182, -0.9615],\n",
            "        [ 0.6671,  0.9999,  0.9391,  ...,  0.8733, -0.6654, -0.6596],\n",
            "        [-0.4913,  0.9998, -0.8156,  ..., -0.7879,  0.0291,  0.3412]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4240,  0.8174, -0.9781,  ..., -0.8679,  0.3783,  0.5802],\n",
            "        [ 0.5604,  1.0000,  0.9301,  ...,  0.7566,  0.1655, -0.9127],\n",
            "        [ 0.6192,  1.0000,  0.8376,  ...,  0.2140, -0.3142, -0.9354],\n",
            "        ...,\n",
            "        [ 0.6459,  0.9964,  0.8428,  ...,  0.8444, -0.6527, -0.2991],\n",
            "        [ 0.7071,  1.0000,  0.9605,  ...,  0.8771, -0.4451, -0.8489],\n",
            "        [ 0.0119,  0.9450, -0.9399,  ..., -0.8253,  0.1053,  0.2945]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5743,  1.0000,  0.7374,  ...,  0.0090,  0.0354, -0.8861],\n",
            "        [ 0.5787,  0.9996,  0.8167,  ...,  0.7981, -0.8474, -0.5219],\n",
            "        [-0.6468, -0.9860, -0.9206,  ..., -0.9076,  0.2047,  0.7585],\n",
            "        ...,\n",
            "        [-0.0574,  0.9848, -0.9464,  ..., -0.8791,  0.0702,  0.4686],\n",
            "        [ 0.5147,  0.9987,  0.9275,  ...,  0.7765, -0.5712, -0.6609],\n",
            "        [ 0.7636,  0.9940,  0.8772,  ...,  0.7463, -0.6832, -0.4942]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2847,  0.9654, -0.9011,  ..., -0.9056,  0.6685, -0.1140],\n",
            "        [ 0.1348,  0.8874, -0.9475,  ..., -0.9383,  0.6026,  0.5784],\n",
            "        [ 0.4921,  0.9997,  0.8704,  ...,  0.8728, -0.7062, -0.6914],\n",
            "        ...,\n",
            "        [ 0.6044,  0.9999,  0.8992,  ...,  0.5709, -0.6568, -0.7237],\n",
            "        [-0.5088, -0.8190, -0.9109,  ..., -0.9285, -0.0954,  0.4344],\n",
            "        [-0.2500,  0.2297, -0.8866,  ..., -0.8189,  0.4394,  0.4232]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4055, -0.7916, -0.9469,  ..., -0.9180,  0.3829,  0.6303],\n",
            "        [ 0.7526,  0.9999,  0.9309,  ...,  0.8650, -0.7684, -0.6012],\n",
            "        [-0.5349,  0.3520, -0.9468,  ..., -0.8932,  0.2832,  0.3731],\n",
            "        ...,\n",
            "        [ 0.5473,  0.9819,  0.8901,  ...,  0.8566, -0.8882, -0.4098],\n",
            "        [-0.5234, -0.4864, -0.9357,  ..., -0.8949,  0.2863,  0.5982],\n",
            "        [ 0.5621,  0.9964,  0.8880,  ...,  0.9099, -0.8441, -0.3631]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5083,  0.9972,  0.9061,  ...,  0.8686, -0.8000, -0.2570],\n",
            "        [ 0.5852,  0.9973,  0.9094,  ...,  0.9182, -0.7960, -0.4363],\n",
            "        [-0.6433, -0.8978, -0.9422,  ..., -0.9080,  0.2081,  0.7548],\n",
            "        ...,\n",
            "        [-0.5505, -0.7986, -0.8054,  ..., -0.8612,  0.4719,  0.4540],\n",
            "        [-0.4715,  0.9992, -0.8496,  ..., -0.7829,  0.6373,  0.0787],\n",
            "        [-0.2327, -0.9827, -0.9283,  ..., -0.9097,  0.3078,  0.0609]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6774, -0.9371, -0.9481,  ..., -0.9005,  0.2265,  0.7663],\n",
            "        [ 0.6553,  0.9944,  0.7111,  ...,  0.9136, -0.7710, -0.3026],\n",
            "        [ 0.7078,  0.9904,  0.8451,  ...,  0.9271, -0.8341, -0.3036],\n",
            "        ...,\n",
            "        [ 0.6564,  0.9999,  0.9071,  ...,  0.9006, -0.7573, -0.5516],\n",
            "        [ 0.6588,  0.9995,  0.8894,  ...,  0.8538, -0.7937, -0.4512],\n",
            "        [-0.7843, -0.9972, -0.9426,  ..., -0.8868, -0.1138,  0.6990]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4909,  0.9991,  0.7922,  ...,  0.8278, -0.8467, -0.1236],\n",
            "        [ 0.8578,  1.0000,  0.8696,  ...,  0.8853, -0.4550, -0.7769],\n",
            "        [ 0.7664,  1.0000,  0.9723,  ...,  0.8390,  0.0666, -0.9034],\n",
            "        ...,\n",
            "        [ 0.5328,  1.0000,  0.8381,  ...,  0.8075, -0.5970, -0.4913],\n",
            "        [ 0.0371,  0.9814, -0.8804,  ..., -0.7595,  0.5273,  0.2075],\n",
            "        [ 0.7490,  0.9975,  0.8833,  ...,  0.8836, -0.8982, -0.5259]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5435,  0.1024, -0.8723,  ..., -0.8476,  0.7142,  0.6342],\n",
            "        [ 0.5183,  0.9992,  0.9339,  ...,  0.7004, -0.8308, -0.6854],\n",
            "        [ 0.0326,  1.0000,  0.8311,  ..., -0.0984,  0.3648, -0.8511],\n",
            "        ...,\n",
            "        [-0.4769,  0.7605, -0.8892,  ..., -0.8922,  0.3578,  0.4369],\n",
            "        [-0.6782, -0.9414, -0.9495,  ..., -0.8992, -0.1349,  0.7036],\n",
            "        [-0.5370,  0.3230, -0.9226,  ..., -0.8543,  0.0181,  0.5274]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5914, -0.8956, -0.7064,  ..., -0.8081,  0.2994,  0.5040],\n",
            "        [-0.3275, -0.9988, -0.9033,  ..., -0.9141,  0.2408,  0.6014],\n",
            "        [ 0.7644,  0.9989,  0.8764,  ...,  0.8096, -0.7064, -0.5414],\n",
            "        ...,\n",
            "        [-0.5968, -0.8723, -0.8892,  ..., -0.8532,  0.3435,  0.4258],\n",
            "        [-0.7114, -0.7229, -0.9260,  ..., -0.9171,  0.2405,  0.7992],\n",
            "        [ 0.7106,  1.0000,  0.8946,  ...,  0.7838, -0.4995, -0.6694]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.7499,  0.7551, -0.9089,  ..., -0.7768,  0.1582,  0.7544],\n",
            "        [-0.4836, -0.5079, -0.8846,  ..., -0.9011,  0.2130,  0.3155],\n",
            "        [ 0.4225,  0.9985,  0.7803,  ...,  0.7609, -0.7988, -0.2006],\n",
            "        ...,\n",
            "        [-0.3369,  0.8850, -0.8889,  ..., -0.8778,  0.4974,  0.6041],\n",
            "        [ 0.6880,  0.9998,  0.8742,  ...,  0.8932, -0.8419, -0.4707],\n",
            "        [-0.4558,  0.0099, -0.9000,  ..., -0.9251,  0.5174,  0.6297]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4401, -0.5972, -0.8595,  ..., -0.7330,  0.6010,  0.5343],\n",
            "        [-0.5209,  0.0395, -0.8823,  ..., -0.9271,  0.6157,  0.2824],\n",
            "        [-0.0420,  0.9628, -0.8377,  ..., -0.8756,  0.5529,  0.0670],\n",
            "        ...,\n",
            "        [ 0.6029,  0.9998,  0.8578,  ...,  0.8856, -0.5117, -0.3877],\n",
            "        [-0.4148,  0.9062, -0.9383,  ..., -0.7094,  0.5601,  0.4908],\n",
            "        [-0.6915,  0.0026, -0.8905,  ..., -0.8893,  0.0424,  0.2797]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5948, -0.9877, -0.7658,  ..., -0.8106,  0.3685,  0.3694],\n",
            "        [ 0.8183,  0.9974,  0.8029,  ...,  0.8826, -0.7483, -0.5417],\n",
            "        [ 0.2826,  1.0000,  0.9560,  ...,  0.8473, -0.4588, -0.8180],\n",
            "        ...,\n",
            "        [-0.6238,  0.7036, -0.9582,  ..., -0.9440,  0.1411,  0.6260],\n",
            "        [ 0.6145,  0.9923,  0.8556,  ...,  0.8562, -0.6780, -0.2322],\n",
            "        [-0.2284, -0.9693, -0.9333,  ..., -0.8470,  0.3318,  0.4228]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5530,  0.9996, -0.7286,  ..., -0.7804,  0.9144, -0.7615],\n",
            "        [ 0.5472,  0.9999,  0.7377,  ...,  0.7920, -0.6867, -0.4053],\n",
            "        [ 0.7115,  1.0000,  0.9311,  ...,  0.8048, -0.2018, -0.9494],\n",
            "        ...,\n",
            "        [ 0.5937,  0.9998,  0.9131,  ...,  0.8268, -0.7319, -0.7960],\n",
            "        [-0.5932, -0.1319, -0.8896,  ..., -0.8124,  0.4192,  0.6454],\n",
            "        [-0.5629, -0.0977, -0.9252,  ..., -0.7395,  0.2901,  0.5062]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6692,  0.9998,  0.7380,  ...,  0.7533, -0.4459, -0.4216],\n",
            "        [ 0.6950,  1.0000,  0.9767,  ...,  0.8240, -0.5710, -0.5900],\n",
            "        [ 0.6207,  1.0000,  0.9492,  ...,  0.7035, -0.1425, -0.9686],\n",
            "        ...,\n",
            "        [ 0.6114,  1.0000,  0.9522,  ...,  0.8463, -0.5791, -0.6843],\n",
            "        [ 0.7301,  0.9953,  0.7086,  ...,  0.9200, -0.8275, -0.1953],\n",
            "        [ 0.8080,  0.9999,  0.7668,  ...,  0.8282, -0.5345, -0.4109]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2515,  0.0300, -0.9486,  ..., -0.8204,  0.2699,  0.3796],\n",
            "        [ 0.6746,  0.9865,  0.7978,  ...,  0.8338, -0.8356, -0.1938],\n",
            "        [ 0.6755,  0.9947,  0.8385,  ...,  0.8762, -0.8532, -0.5512],\n",
            "        ...,\n",
            "        [ 0.6367,  0.9989,  0.7548,  ...,  0.8121, -0.8705,  0.0559],\n",
            "        [ 0.7351,  1.0000,  0.9245,  ...,  0.8216, -0.4058, -0.7808],\n",
            "        [ 0.6838,  1.0000,  0.9385,  ...,  0.8918, -0.5308, -0.6944]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5211,  1.0000,  0.8702,  ...,  0.0232,  0.3870, -0.9752],\n",
            "        [ 0.7428,  0.9971,  0.8728,  ...,  0.9127, -0.6921, -0.5317],\n",
            "        [-0.5011,  0.7746, -0.9502,  ..., -0.9344,  0.2186,  0.4999],\n",
            "        ...,\n",
            "        [-0.5419, -0.9995, -0.9371,  ..., -0.8972, -0.0271,  0.7038],\n",
            "        [-0.5581, -0.9551, -0.9368,  ..., -0.8489, -0.0351,  0.6850],\n",
            "        [-0.6537, -0.9911, -0.9499,  ..., -0.8352,  0.1275,  0.8240]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5084, -0.9274, -0.9451,  ..., -0.8557,  0.1630,  0.3947],\n",
            "        [ 0.7233,  1.0000,  0.7442,  ...,  0.7467, -0.7520, -0.6537],\n",
            "        [ 0.5870,  0.9264,  0.8065,  ...,  0.8668, -0.8048,  0.0955],\n",
            "        ...,\n",
            "        [-0.4478, -0.9990, -0.9489,  ..., -0.8752,  0.2368,  0.6872],\n",
            "        [-0.6579,  0.9697, -0.8762,  ..., -0.9139,  0.1772,  0.2502],\n",
            "        [-0.6125, -0.7669, -0.9369,  ..., -0.8774,  0.2315,  0.6777]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6225,  0.9997,  0.8502,  ...,  0.8503, -0.7101, -0.6912],\n",
            "        [ 0.5349,  1.0000, -0.4612,  ..., -0.4920,  0.5846, -0.8494],\n",
            "        [-0.4633, -0.2063, -0.9358,  ..., -0.9123,  0.1994,  0.5896],\n",
            "        ...,\n",
            "        [ 0.6585,  0.9982,  0.9418,  ...,  0.8735, -0.8618, -0.5351],\n",
            "        [-0.7674,  0.9995, -0.8455,  ..., -0.6234,  0.1975, -0.2965],\n",
            "        [-0.7275,  0.9594, -0.8352,  ..., -0.8925,  0.2491,  0.2460]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6198,  0.7588, -0.9186,  ..., -0.8192, -0.0339,  0.6393],\n",
            "        [ 0.6046,  0.9986,  0.8962,  ...,  0.8113, -0.7753, -0.4146],\n",
            "        [ 0.6563,  0.9995,  0.8654,  ...,  0.8659, -0.6650, -0.7581],\n",
            "        ...,\n",
            "        [ 0.8158,  1.0000,  0.9016,  ...,  0.7986, -0.5441, -0.9424],\n",
            "        [-0.6483, -0.2757, -0.9365,  ..., -0.8955,  0.3801,  0.4911],\n",
            "        [-0.6490,  0.6279, -0.9517,  ..., -0.9413,  0.2689,  0.6824]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6696, -0.2592, -0.7760,  ..., -0.8667,  0.3991,  0.3745],\n",
            "        [ 0.3259,  0.9896,  0.8687,  ...,  0.7246, -0.7944, -0.3484],\n",
            "        [ 0.3014,  0.9664,  0.7673,  ...,  0.8974, -0.8775,  0.0900],\n",
            "        ...,\n",
            "        [ 0.5888,  0.9995,  0.8790,  ...,  0.8441, -0.6173, -0.6099],\n",
            "        [ 0.6388,  0.9945,  0.8981,  ...,  0.9489, -0.7342, -0.1341],\n",
            "        [ 0.2042,  0.9999,  0.8079,  ..., -0.0504, -0.2152, -0.7897]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5249,  0.9734, -0.8207,  ..., -0.8195,  0.3893,  0.5987],\n",
            "        [-0.5817,  0.0998, -0.9341,  ..., -0.8999,  0.3639,  0.3471],\n",
            "        [ 0.7593,  0.9993,  0.9089,  ...,  0.8996, -0.7663, -0.5557],\n",
            "        ...,\n",
            "        [-0.4339,  0.8421, -0.8468,  ..., -0.9067,  0.1767,  0.3993],\n",
            "        [-0.4656,  0.3516, -0.9378,  ..., -0.8853,  0.3216,  0.2747],\n",
            "        [-0.4638, -0.4549, -0.9434,  ..., -0.9038,  0.1762,  0.5215]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4780,  0.7030, -0.9115,  ..., -0.8227,  0.4103,  0.5587],\n",
            "        [ 0.6234,  0.9999,  0.8422,  ...,  0.8355, -0.6859, -0.7304],\n",
            "        [ 0.5869,  0.9982,  0.9059,  ...,  0.8576, -0.8315, -0.2405],\n",
            "        ...,\n",
            "        [-0.6696,  0.9944, -0.8210,  ..., -0.7241, -0.1708,  0.5003],\n",
            "        [-0.3560,  0.9136, -0.9435,  ..., -0.9161,  0.3157,  0.1989],\n",
            "        [ 0.5854,  0.9927,  0.8050,  ...,  0.8731, -0.8497, -0.2301]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1381,  0.9997,  0.3998,  ..., -0.1817,  0.1857, -0.6649],\n",
            "        [-0.6690,  0.9991, -0.9284,  ..., -0.8345,  0.4961,  0.2644],\n",
            "        [-0.6126, -0.9581, -0.8579,  ..., -0.6129,  0.3074,  0.4224],\n",
            "        ...,\n",
            "        [-0.7191, -0.8018, -0.9136,  ..., -0.8810,  0.1015,  0.6694],\n",
            "        [ 0.6909,  0.9946,  0.8568,  ...,  0.8909, -0.8360, -0.3889],\n",
            "        [ 0.5855,  0.9895,  0.6365,  ...,  0.7795, -0.7746, -0.5414]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6739,  0.4789, -0.9561,  ..., -0.9352,  0.1209,  0.5747],\n",
            "        [-0.7307, -0.8136, -0.8222,  ..., -0.8875,  0.5944,  0.5753],\n",
            "        [-0.3231,  0.1817, -0.9204,  ..., -0.9206,  0.4781,  0.4016],\n",
            "        ...,\n",
            "        [-0.6985,  0.9740, -0.9367,  ..., -0.7784,  0.3622,  0.4942],\n",
            "        [ 0.7809,  0.9999,  0.8328,  ...,  0.8396, -0.6754, -0.5914],\n",
            "        [-0.7584,  0.9722, -0.9064,  ..., -0.9161,  0.0129,  0.4245]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7250,  0.9999,  0.8770,  ...,  0.8914, -0.6853, -0.4197],\n",
            "        [ 0.6358,  1.0000,  0.8849,  ...,  0.7885, -0.5724, -0.7048],\n",
            "        [-0.6719,  0.8917, -0.8289,  ..., -0.9576,  0.4423,  0.3755],\n",
            "        ...,\n",
            "        [-0.6602, -0.7902, -0.9512,  ..., -0.8231,  0.5084,  0.2038],\n",
            "        [ 0.5720,  1.0000,  0.8490,  ...,  0.6190, -0.6676, -0.6825],\n",
            "        [ 0.5340,  0.9680,  0.7577,  ...,  0.8601, -0.9072,  0.0420]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4007, -0.8431, -0.9317,  ..., -0.8034,  0.5055, -0.0166],\n",
            "        [-0.4555, -0.8413, -0.9580,  ..., -0.8927,  0.0404,  0.6848],\n",
            "        [-0.4550, -0.9855, -0.9588,  ..., -0.9382,  0.0462,  0.7080],\n",
            "        ...,\n",
            "        [ 0.5346,  0.9996,  0.7960,  ...,  0.8996, -0.8611, -0.2623],\n",
            "        [-0.6199,  0.5452, -0.9035,  ..., -0.9117,  0.2426,  0.4040],\n",
            "        [-0.6531,  0.9613, -0.9436,  ..., -0.9092,  0.4000,  0.5970]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-6.2036e-01,  7.2709e-01, -8.9400e-01, -4.6706e-01,  1.1492e-01,\n",
            "         -9.0317e-01, -4.1001e-01, -7.3791e-01,  8.4599e-01,  6.0540e-01,\n",
            "         -6.3578e-01,  8.8565e-01, -1.1049e-01, -8.5248e-02,  2.1874e-01,\n",
            "          9.7445e-01, -7.3529e-01, -1.5939e-01,  1.7606e-01,  5.4367e-01,\n",
            "         -9.2898e-02,  8.8982e-01, -3.7205e-01,  1.0282e-02, -7.3271e-01,\n",
            "         -8.7145e-01,  3.3355e-01, -3.8752e-04, -8.7681e-03, -6.9994e-01,\n",
            "         -5.1900e-03,  8.6183e-01,  7.5650e-01,  1.2760e-01,  6.0206e-02,\n",
            "          2.4901e-01,  6.8628e-01,  4.2298e-01, -6.0472e-01, -5.1704e-01,\n",
            "          9.7584e-01,  5.6888e-01,  4.5870e-01, -8.5090e-01, -3.9591e-01,\n",
            "         -6.3264e-01,  4.9420e-02, -4.1204e-01, -1.0669e-01,  1.6185e-01,\n",
            "          6.6767e-01, -9.9748e-01,  4.6559e-01, -8.9570e-01, -3.9390e-01,\n",
            "         -8.2432e-01, -1.9918e-01,  4.4894e-01,  3.9791e-02,  8.5010e-01,\n",
            "         -5.2850e-01, -3.1151e-01,  8.5984e-01,  1.3304e-01,  9.7593e-01,\n",
            "         -6.2390e-02,  4.6208e-01, -2.8788e-01,  9.2136e-01, -6.4093e-01,\n",
            "         -9.1145e-01,  5.7409e-01, -3.5542e-01,  8.4940e-03,  5.0819e-01,\n",
            "         -4.8879e-01,  9.0190e-01, -1.5655e-01, -1.8970e-01,  3.4787e-01,\n",
            "         -8.6459e-01,  4.0557e-01,  7.2728e-01, -8.6475e-01, -7.7916e-01,\n",
            "         -1.8446e-01,  6.6531e-01, -3.6452e-01,  3.9103e-01,  2.1319e-02,\n",
            "         -3.1082e-01, -9.1599e-01, -6.5125e-01,  6.7289e-01,  2.4329e-01,\n",
            "         -5.1543e-01,  2.9221e-01, -7.5467e-01,  9.9042e-03, -2.0144e-01,\n",
            "          5.5646e-01,  4.8963e-01,  5.8208e-01,  5.3453e-02, -6.7688e-01,\n",
            "         -8.2232e-01,  4.9374e-01, -2.9948e-01, -2.7620e-02,  3.9087e-01,\n",
            "         -5.3802e-01,  1.3358e-01,  8.0461e-01, -2.5188e-01, -4.3055e-01,\n",
            "          8.1269e-01, -9.4401e-01, -7.5229e-01, -4.2656e-01,  5.0466e-02,\n",
            "         -3.5946e-01, -5.7126e-01,  5.5536e-01, -5.3539e-01, -3.8965e-01,\n",
            "         -7.0114e-01, -2.7877e-01,  7.1232e-01,  3.1762e-01,  4.1231e-01,\n",
            "          2.3714e-01, -8.5568e-01, -7.6147e-01, -5.1233e-01,  8.0450e-01,\n",
            "         -4.0411e-01, -9.8356e-01,  5.6790e-01,  7.5192e-01,  5.8392e-01,\n",
            "          9.1906e-01,  5.3295e-01, -6.8881e-01,  3.1243e-01,  1.4979e-01,\n",
            "          6.2810e-01,  3.7278e-02,  7.9626e-01, -1.6220e-01, -7.6432e-01,\n",
            "          4.4151e-01, -6.6774e-01, -8.1625e-01,  2.8826e-01, -9.4942e-01,\n",
            "          3.2391e-01,  7.2687e-01,  6.1114e-01,  9.7807e-01, -8.8383e-01,\n",
            "          4.5539e-01,  4.3712e-01,  2.8777e-01,  3.2454e-01,  9.9267e-01,\n",
            "         -7.8959e-01,  2.4892e-01,  6.7037e-01,  8.9113e-01, -3.4870e-01,\n",
            "         -1.0891e-01,  6.9915e-01,  4.4485e-01,  4.9131e-01,  9.8039e-01,\n",
            "         -6.8852e-01, -5.0524e-01,  1.4795e-01,  8.7469e-01,  5.6921e-01,\n",
            "          2.4266e-01,  1.6553e-01, -8.1543e-01, -8.7478e-01,  7.3837e-01,\n",
            "         -7.7083e-01, -4.6055e-01, -1.6535e-01, -9.4904e-01,  4.8640e-01,\n",
            "         -7.8331e-01, -7.5185e-01, -7.1646e-01,  8.6166e-01, -1.8329e-01,\n",
            "         -2.5620e-01, -2.3876e-01,  1.1267e-01,  6.8038e-01,  5.3469e-01,\n",
            "          7.7277e-01,  4.0292e-01,  5.1869e-01, -9.7021e-01, -8.8926e-01,\n",
            "         -4.2128e-01,  3.7758e-01,  4.4983e-01, -6.8995e-01,  6.3379e-01,\n",
            "          4.5290e-01,  6.9328e-01,  3.3264e-01, -8.2975e-01,  1.7699e-01,\n",
            "          4.4842e-01,  6.0111e-01, -9.3591e-01,  4.8648e-01,  8.4545e-01,\n",
            "         -8.6548e-01, -7.5076e-01,  5.6605e-01, -9.0108e-01, -2.6735e-01,\n",
            "         -1.9098e-01, -1.7639e-01,  2.5235e-01, -7.4086e-01, -1.7662e-01,\n",
            "          9.2003e-02,  5.3836e-01,  3.3635e-01,  8.3976e-01,  8.9272e-01,\n",
            "          1.6342e-01, -8.9838e-01,  4.2616e-01,  5.1889e-01, -2.8345e-01,\n",
            "          9.0909e-01, -7.2998e-01,  6.0299e-01,  2.2706e-01, -3.2882e-01,\n",
            "          1.2156e-01, -7.2401e-01, -7.5933e-01, -2.5209e-01,  5.2344e-01,\n",
            "         -1.2080e-01, -4.8313e-01,  3.0359e-01,  7.2178e-01,  6.7580e-01,\n",
            "          4.0818e-01,  8.7874e-01, -8.7019e-01, -4.4488e-01,  1.3707e-01,\n",
            "         -4.2947e-01,  1.0596e-01, -9.7213e-01, -6.7656e-01,  7.0111e-03,\n",
            "          9.4509e-01, -6.6720e-01, -5.8425e-01,  2.5925e-01,  4.0213e-02,\n",
            "          2.8144e-01,  5.5810e-01, -5.7774e-01,  9.7713e-01,  4.0032e-02,\n",
            "         -7.7331e-01,  8.4836e-01,  1.9722e-02, -7.9493e-01,  7.5401e-01,\n",
            "         -9.7447e-01,  8.2209e-01,  8.0537e-01,  6.4144e-01,  1.0260e-01,\n",
            "          3.7652e-01, -2.0204e-01,  7.6324e-01, -9.5314e-01,  9.6114e-02,\n",
            "          7.2368e-01,  8.0845e-01,  9.6715e-01,  3.5881e-01, -6.1942e-01,\n",
            "         -7.7118e-01,  6.2898e-01, -7.0618e-01, -1.7231e-01,  9.3741e-01,\n",
            "         -2.8112e-01,  7.2519e-01,  4.2592e-01,  6.0386e-01, -2.2637e-01,\n",
            "          7.4121e-01, -7.3578e-01,  7.0960e-01, -5.5891e-01, -9.2199e-03,\n",
            "          1.3902e-01, -6.0666e-01, -4.0993e-01,  4.9118e-01, -7.0949e-01,\n",
            "         -8.0276e-01, -5.5388e-01,  3.1693e-01,  5.3203e-01,  1.5163e-01,\n",
            "          1.8161e-01,  8.1647e-01, -7.2307e-01, -4.0656e-01, -4.7566e-01,\n",
            "          2.2934e-01,  2.8428e-01,  2.9547e-02, -3.5982e-01,  3.2731e-02,\n",
            "         -3.5409e-01,  9.2052e-01, -5.0506e-01, -6.4075e-01,  1.2515e-01,\n",
            "         -1.0336e-01, -1.9623e-01,  9.5848e-01, -8.7405e-01,  5.9844e-01,\n",
            "          8.0774e-01,  3.9240e-01,  8.5597e-01,  2.8889e-01, -2.1025e-01,\n",
            "         -8.5710e-01,  4.5301e-01, -1.2669e-01,  2.9621e-01, -5.0190e-01,\n",
            "         -4.5498e-01,  4.2295e-02, -7.7671e-01, -6.1772e-01,  6.9115e-01,\n",
            "          9.3947e-01,  7.0919e-01,  9.2670e-01, -4.1273e-01,  1.9477e-01,\n",
            "         -6.8916e-01, -2.4224e-01,  7.4670e-01, -5.3757e-01,  3.1239e-01,\n",
            "         -5.9760e-01,  3.9551e-01,  1.1996e-01, -8.8292e-01,  4.6790e-01,\n",
            "         -4.9970e-01,  6.6311e-01,  1.4337e-01,  9.0046e-01, -5.4054e-01,\n",
            "         -8.2187e-01,  2.0858e-02, -2.7275e-01,  8.7696e-01,  4.6532e-01,\n",
            "         -5.0403e-01, -1.7409e-01,  8.7904e-01,  4.5257e-01, -5.9047e-01,\n",
            "          5.6256e-01,  5.4740e-01, -7.9799e-01,  5.7220e-01,  7.0983e-01,\n",
            "          5.1632e-01,  1.0911e-01, -2.9465e-01, -8.0478e-01,  1.6406e-01,\n",
            "          6.2810e-01, -8.9871e-02, -7.3228e-01, -1.7486e-01,  9.4525e-01,\n",
            "         -7.5876e-01, -4.7133e-01, -4.8007e-01,  6.0062e-01,  5.5428e-01,\n",
            "         -4.6230e-01, -9.2562e-02,  6.0539e-02,  4.2252e-01, -9.0355e-01,\n",
            "          4.2019e-01,  5.4874e-01,  5.2651e-01,  7.4607e-01, -9.3523e-01,\n",
            "         -7.1909e-02, -9.0494e-01,  4.0574e-02, -7.7164e-01,  5.5314e-01,\n",
            "         -5.9570e-01, -1.9736e-01, -6.3476e-01, -9.4746e-01,  8.7730e-01,\n",
            "         -3.8075e-01,  9.3906e-01, -5.9050e-01, -5.2463e-01, -2.7223e-01,\n",
            "          3.2891e-02, -2.5711e-01,  7.8459e-01, -6.9136e-01,  9.5865e-01,\n",
            "         -8.3592e-01,  8.0003e-02,  1.4920e-01,  7.6257e-01,  3.9460e-01,\n",
            "          7.7861e-01,  9.1360e-01,  8.2172e-01, -1.8601e-01,  7.1367e-01,\n",
            "         -6.9225e-02, -7.6730e-01, -8.8512e-01, -4.8760e-02,  8.1058e-01,\n",
            "         -3.1695e-01,  7.2102e-01, -6.7839e-01,  8.3752e-01,  8.2786e-01,\n",
            "         -4.0580e-02,  1.4410e-01, -2.4162e-01,  9.1514e-01,  6.4476e-01,\n",
            "         -2.3762e-01,  8.3377e-01,  8.9439e-01,  7.5909e-01,  2.8318e-01,\n",
            "         -6.5057e-02,  1.9250e-01,  4.5207e-01, -7.5249e-01, -5.4379e-01,\n",
            "          7.8910e-01,  5.1832e-01,  8.5838e-02, -8.3051e-01,  3.4841e-01,\n",
            "         -3.2322e-02, -7.9956e-03, -8.7600e-01, -1.0835e-01, -9.9144e-01,\n",
            "          7.4197e-02,  7.1618e-01, -9.1263e-01, -2.4355e-01,  3.6333e-01,\n",
            "          1.5991e-01,  6.2534e-01,  3.5825e-01,  9.1086e-01, -8.8859e-02,\n",
            "         -1.0560e-01, -1.4238e-01,  1.3362e-01,  4.6050e-01,  4.7220e-01,\n",
            "          8.1288e-02, -7.1480e-01, -3.7842e-01,  3.3248e-01,  1.1598e-01,\n",
            "          6.6245e-01, -7.9648e-01,  1.6184e-01,  1.5478e-01, -8.1340e-01,\n",
            "         -8.5326e-01,  9.1268e-01,  9.1226e-01,  1.1400e-01,  7.4156e-01,\n",
            "          7.1773e-01,  1.7492e-01,  2.0966e-01,  6.8165e-01, -3.8825e-01,\n",
            "         -3.8668e-02,  3.9809e-01,  3.5612e-01, -4.9960e-01, -8.5633e-01,\n",
            "         -9.1609e-01, -4.3917e-01,  6.5632e-01, -6.4342e-01, -8.4699e-01,\n",
            "         -9.4739e-01, -4.8999e-01, -2.0971e-01, -6.8875e-01,  6.6522e-02,\n",
            "          7.6231e-01, -7.4491e-01, -6.5997e-01, -8.5239e-01, -3.1131e-01,\n",
            "         -9.8396e-01, -4.9307e-01, -5.4032e-01, -4.0346e-01,  6.8055e-01,\n",
            "         -9.3016e-01, -8.9120e-01, -3.6931e-01,  1.4717e-01,  7.2933e-01,\n",
            "          8.8718e-01, -1.7912e-01, -3.1768e-01, -5.1575e-01,  7.5388e-01,\n",
            "         -9.7141e-01,  4.3644e-01, -1.1248e-01,  7.6504e-01, -8.7610e-01,\n",
            "          5.8189e-01, -8.8246e-01, -2.3706e-01, -7.9353e-02,  3.9407e-01,\n",
            "         -1.2523e-01, -9.5119e-01,  3.0861e-01, -4.6498e-01,  4.7007e-01,\n",
            "         -5.0084e-01, -7.1692e-01, -5.3017e-01, -9.0953e-01, -9.4338e-01,\n",
            "          7.2462e-01,  9.6143e-01,  4.9670e-01, -8.7420e-01, -6.9850e-01,\n",
            "          6.2526e-01,  1.6182e-01, -2.4064e-01,  8.8558e-01,  9.3060e-01,\n",
            "          4.6624e-01,  7.0646e-01,  2.0871e-01,  8.0430e-02, -7.2498e-01,\n",
            "         -3.0211e-01,  1.9303e-01, -1.1105e-01, -6.9992e-01,  6.0126e-01,\n",
            "         -1.7077e-01,  4.6057e-01,  4.6444e-01, -2.8926e-01,  9.7999e-01,\n",
            "          5.1894e-01, -1.5439e-01,  8.7222e-01, -7.1865e-01, -8.9861e-01,\n",
            "         -9.1840e-01, -9.1582e-01,  8.4479e-01,  8.2155e-02, -8.7840e-01,\n",
            "          4.5959e-01,  2.2556e-02,  2.6050e-01, -1.7551e-01,  2.4856e-01,\n",
            "          7.2170e-01,  6.4424e-01,  3.3360e-01,  5.7134e-02, -6.4022e-01,\n",
            "         -8.1604e-01,  6.1071e-01,  9.1523e-01, -2.6994e-01,  7.1776e-01,\n",
            "         -3.4085e-01,  7.4413e-01,  8.9470e-02,  7.1021e-01,  1.4933e-01,\n",
            "          7.4840e-01,  4.2603e-01, -9.2029e-01,  7.2220e-01, -3.6204e-01,\n",
            "          7.1353e-01,  7.0193e-01, -6.2408e-01, -6.5219e-01, -5.1893e-01,\n",
            "         -7.0597e-01, -4.3183e-01, -6.9964e-01,  9.1825e-01, -1.7689e-01,\n",
            "          2.2900e-01,  9.0779e-01,  4.2301e-01,  1.8059e-01,  7.7989e-01,\n",
            "         -8.7136e-01,  1.9058e-01,  5.4797e-01,  2.1181e-01,  4.2421e-01,\n",
            "         -2.8446e-01, -6.4088e-01, -4.5530e-01, -9.2318e-01, -5.6407e-01,\n",
            "          3.7886e-01,  1.3715e-01,  1.0556e-01, -7.1878e-01, -8.5671e-01,\n",
            "          2.8905e-01, -8.6839e-01,  2.6588e-01, -5.0383e-01, -7.3191e-01,\n",
            "          9.4298e-01, -6.5463e-01, -1.7020e-01,  9.0452e-01,  2.3158e-01,\n",
            "         -6.8602e-01,  9.0494e-01,  6.0452e-02, -4.0854e-01,  8.2445e-01,\n",
            "          5.1680e-01, -1.9503e-01,  7.5795e-01,  2.5841e-01,  1.1214e-01,\n",
            "         -2.3750e-01, -3.1934e-01,  9.6957e-01,  7.3448e-01, -4.2579e-01,\n",
            "          8.6627e-01, -3.2670e-01,  4.0886e-01,  6.8499e-02, -7.6191e-01,\n",
            "          5.0978e-01, -2.3192e-01, -4.2473e-01, -2.5696e-01, -2.7309e-01,\n",
            "          7.8952e-01,  9.5041e-01, -9.8209e-01,  9.4982e-01,  4.1172e-01,\n",
            "         -3.5807e-02, -2.8833e-01, -3.2704e-01,  2.3685e-01,  8.6239e-01,\n",
            "         -2.0351e-01,  6.6008e-01, -1.2866e-01, -5.9548e-01,  3.0764e-01,\n",
            "         -3.8548e-01, -9.8817e-01, -8.8285e-01,  7.4273e-01,  4.8853e-01,\n",
            "         -9.6975e-01, -4.1928e-01,  3.1138e-01,  6.5370e-01, -5.9919e-01,\n",
            "          6.4541e-01,  5.3178e-01, -3.1308e-01, -1.1022e-01, -8.9149e-01,\n",
            "         -1.0587e-01,  3.7972e-01, -6.5726e-01,  7.0786e-01, -2.8029e-01,\n",
            "          8.8183e-01, -7.9503e-01,  6.1045e-01,  8.1947e-01, -8.4650e-01,\n",
            "         -8.4679e-01, -6.5217e-01, -9.0594e-01, -8.3325e-03,  1.9046e-01,\n",
            "         -8.8250e-01,  6.2331e-01, -8.2976e-01,  1.7721e-01, -9.2903e-02,\n",
            "         -9.0665e-01,  5.9260e-01,  4.1739e-02,  2.3324e-01,  2.4455e-01,\n",
            "         -8.6704e-01,  8.5698e-01,  8.6013e-01,  9.4168e-02,  9.0674e-01,\n",
            "         -5.6926e-01,  6.9634e-01, -2.3412e-01,  5.8006e-01,  9.0176e-01,\n",
            "          3.1547e-01, -2.1996e-01, -7.5503e-01, -4.8466e-01,  6.5480e-01,\n",
            "         -7.7477e-01,  1.7570e-01,  7.9876e-01]], device='cuda:0',\n",
            "       grad_fn=<TanhBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluation... :   0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "699381678de5446392cd7d2b13d3c83e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7478,  0.9743,  0.8809,  ...,  0.8767, -0.8303, -0.3323],\n",
            "        [ 0.8070,  1.0000,  0.9637,  ...,  0.7609,  0.3263, -0.9726],\n",
            "        [ 0.6447,  0.9998, -0.7743,  ..., -0.8431,  0.7137, -0.5891],\n",
            "        ...,\n",
            "        [ 0.4062,  0.9978,  0.7878,  ...,  0.8337, -0.8111, -0.1877],\n",
            "        [-0.0765,  0.9870, -0.7108,  ..., -0.8566,  0.5708, -0.1543],\n",
            "        [-0.7061, -0.1952, -0.9168,  ..., -0.7489,  0.3124,  0.6542]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4327,  0.9975, -0.8679,  ..., -0.8847,  0.4075,  0.2111],\n",
            "        [ 0.6982,  0.9999,  0.7310,  ...,  0.5270, -0.8144, -0.2510],\n",
            "        [ 0.2358,  0.9970,  0.0657,  ..., -0.6837,  0.5087, -0.8525],\n",
            "        ...,\n",
            "        [-0.2273,  0.9943, -0.2855,  ..., -0.7211,  0.2010, -0.7153],\n",
            "        [-0.6256,  0.9999, -0.5580,  ..., -0.8731,  0.3467,  0.0684],\n",
            "        [ 0.4565,  1.0000,  0.6523,  ..., -0.6769,  0.6395, -0.9634]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6669,  1.0000,  0.9415,  ...,  0.8271, -0.5067, -0.8245],\n",
            "        [ 0.3647,  1.0000,  0.7374,  ...,  0.3656,  0.7647, -0.8666],\n",
            "        [ 0.5912,  0.9999,  0.8546,  ...,  0.8708, -0.7599, -0.5309],\n",
            "        ...,\n",
            "        [-0.1681,  1.0000,  0.0316,  ..., -0.8817,  0.5201, -0.8110],\n",
            "        [-0.7891, -0.3132, -0.9108,  ..., -0.9220,  0.2705,  0.5238],\n",
            "        [ 0.4813,  1.0000,  0.6538,  ...,  0.1839,  0.0510, -0.9295]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1066,  0.9975,  0.0830,  ..., -0.0730, -0.6691, -0.6399],\n",
            "        [-0.0102,  1.0000,  0.7329,  ..., -0.2818, -0.0081, -0.9399],\n",
            "        [-0.1038,  0.9998, -0.4979,  ..., -0.8184,  0.3824, -0.8446],\n",
            "        ...,\n",
            "        [ 0.7972,  1.0000,  0.9318,  ...,  0.8560, -0.3211, -0.7628],\n",
            "        [-0.1880, -0.3814, -0.8265,  ..., -0.9094,  0.6551, -0.1807],\n",
            "        [ 0.6512,  0.9942,  0.8739,  ...,  0.9037, -0.8699, -0.3114]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7092,  0.9999,  0.7304,  ...,  0.7538, -0.5234, -0.2410],\n",
            "        [ 0.4758,  0.9998,  0.8330,  ...,  0.8939, -0.5497, -0.4565],\n",
            "        [-0.5640,  0.3146, -0.8897,  ..., -0.7608,  0.3777,  0.5335],\n",
            "        ...,\n",
            "        [ 0.5739,  0.9999,  0.5702,  ...,  0.7564, -0.5486, -0.7937],\n",
            "        [ 0.4881,  0.9999,  0.8873,  ...,  0.4220, -0.5710, -0.5630],\n",
            "        [ 0.7400,  0.9996,  0.9459,  ...,  0.4391, -0.3136, -0.7386]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5446,  0.9972,  0.8767,  ...,  0.8897, -0.8291, -0.3755],\n",
            "        [ 0.7962,  1.0000,  0.6649,  ...,  0.6864, -0.6745, -0.8425],\n",
            "        [-0.3332, -0.4021, -0.9661,  ..., -0.8799,  0.5456,  0.3938],\n",
            "        ...,\n",
            "        [ 0.3760,  0.9512, -0.9108,  ..., -0.8352,  0.6929,  0.1513],\n",
            "        [ 0.3564,  1.0000,  0.1078,  ...,  0.2114, -0.4523, -0.6049],\n",
            "        [ 0.4423,  1.0000,  0.7593,  ...,  0.5896, -0.6901, -0.7908]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0358,  0.9834, -0.5480,  ..., -0.7961, -0.2963, -0.6173],\n",
            "        [-0.5867, -0.7299, -0.9487,  ..., -0.9287,  0.1273,  0.7289],\n",
            "        [ 0.6338,  0.9903,  0.8194,  ...,  0.9029, -0.8292, -0.3051],\n",
            "        ...,\n",
            "        [-0.2573,  1.0000, -0.3754,  ..., -0.7962, -0.3797, -0.4803],\n",
            "        [ 0.6456,  0.9973,  0.9234,  ...,  0.9089, -0.8357, -0.3978],\n",
            "        [-0.4417,  0.9153, -0.8609,  ..., -0.8311,  0.0990,  0.4237]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6500,  0.9990,  0.8866,  ...,  0.8956, -0.8044, -0.4341],\n",
            "        [ 0.7144,  0.9993,  0.9331,  ...,  0.9244, -0.7507, -0.5460],\n",
            "        [ 0.6733,  1.0000,  0.9302,  ...,  0.8300,  0.0608, -0.9166],\n",
            "        ...,\n",
            "        [ 0.6003,  0.9798,  0.8774,  ...,  0.8744, -0.8917, -0.1775],\n",
            "        [ 0.4701,  0.9983,  0.7738,  ...,  0.8497, -0.8145, -0.5778],\n",
            "        [ 0.5640,  1.0000,  0.7742,  ...,  0.6386, -0.6234, -0.6108]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.8197,  1.0000,  0.9570,  ...,  0.8214, -0.0177, -0.9305],\n",
            "        [-0.2973,  0.9781, -0.9090,  ..., -0.8471,  0.2124,  0.1680],\n",
            "        [-0.8354, -0.9631, -0.8407,  ..., -0.9097,  0.1204,  0.3685],\n",
            "        ...,\n",
            "        [ 0.7050,  0.9994,  0.8843,  ...,  0.8743, -0.7845, -0.3389],\n",
            "        [-0.6851, -0.6800, -0.9302,  ..., -0.8991,  0.2643,  0.7969],\n",
            "        [ 0.5262,  0.9860,  0.8693,  ...,  0.8606, -0.8366, -0.2137]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5865, -0.6625, -0.9516,  ..., -0.8795,  0.1436,  0.5659],\n",
            "        [ 0.0911,  1.0000,  0.1720,  ..., -0.5830,  0.0368, -0.8000],\n",
            "        [ 0.6651,  0.9995,  0.9240,  ...,  0.8910, -0.7448, -0.5998],\n",
            "        ...,\n",
            "        [ 0.7081,  0.9936,  0.8133,  ...,  0.8942, -0.8615, -0.2691],\n",
            "        [ 0.4846,  0.9998,  0.8513,  ...,  0.7336, -0.5766, -0.2534],\n",
            "        [ 0.7256,  1.0000,  0.9294,  ...,  0.7700,  0.1522, -0.9537]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2510,  0.4934, -0.9075,  ..., -0.8635,  0.3508,  0.4342],\n",
            "        [-0.5626, -0.9536, -0.9212,  ..., -0.9345,  0.1531,  0.5502],\n",
            "        [-0.7028,  0.7515, -0.9670,  ..., -0.9418, -0.0416,  0.3932],\n",
            "        ...,\n",
            "        [ 0.6822,  1.0000,  0.8493,  ...,  0.7216, -0.6446, -0.7885],\n",
            "        [ 0.5969,  1.0000, -0.6445,  ..., -0.7696,  0.6049, -0.8584],\n",
            "        [ 0.4990,  0.9965,  0.9007,  ...,  0.8932, -0.8283, -0.2474]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1702,  0.9999,  0.6586,  ..., -0.3328,  0.2606, -0.8359],\n",
            "        [-0.5527, -0.8965, -0.9561,  ..., -0.8997,  0.2678,  0.6642],\n",
            "        [-0.7171,  0.9141, -0.9302,  ..., -0.9006,  0.2432,  0.1982],\n",
            "        ...,\n",
            "        [-0.6361,  0.8977, -0.9433,  ..., -0.9073,  0.2720,  0.6379],\n",
            "        [ 0.1741,  1.0000,  0.1825,  ..., -0.5248, -0.1140, -0.7821],\n",
            "        [-0.3931,  0.9994, -0.7444,  ..., -0.9146,  0.4829, -0.2488]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0677,  0.9907, -0.8074,  ..., -0.4533,  0.6921,  0.4011],\n",
            "        [ 0.3369,  1.0000,  0.6587,  ...,  0.0900, -0.1078, -0.8674],\n",
            "        [-0.6636, -0.9384, -0.8741,  ..., -0.9119,  0.4269,  0.4866],\n",
            "        ...,\n",
            "        [-0.7402,  0.9912, -0.9290,  ..., -0.7367,  0.6106,  0.3425],\n",
            "        [-0.3350,  0.9761, -0.9392,  ..., -0.8784,  0.4078,  0.1170],\n",
            "        [-0.6568,  1.0000, -0.7474,  ..., -0.8144,  0.4437, -0.5827]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7973,  1.0000,  0.9145,  ...,  0.4812, -0.4395, -0.7149],\n",
            "        [ 0.6186,  1.0000,  0.8288,  ...,  0.4100, -0.3210, -0.8136],\n",
            "        [-0.6801, -0.3396, -0.9354,  ..., -0.8549, -0.0924,  0.5484],\n",
            "        ...,\n",
            "        [ 0.4635,  1.0000,  0.5603,  ..., -0.1695, -0.4697, -0.6980],\n",
            "        [ 0.5006,  1.0000,  0.7783,  ...,  0.8103, -0.3773, -0.6213],\n",
            "        [-0.5247,  0.9947, -0.5990,  ..., -0.7529,  0.1080, -0.4749]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 4.7261e-01,  9.9994e-01,  7.4043e-01, -9.4355e-01, -4.7757e-01,\n",
            "          9.3322e-01,  6.8218e-01,  7.8296e-01, -9.9627e-01, -5.8649e-01,\n",
            "          7.9439e-01, -5.7601e-01,  4.8598e-01,  9.9872e-01,  4.1817e-01,\n",
            "         -1.0248e-01,  6.9686e-01, -9.6031e-01,  5.9779e-01, -1.6998e-01,\n",
            "          3.0671e-01, -7.8580e-01,  7.8909e-01, -2.9007e-01,  7.9638e-01,\n",
            "          7.5065e-01, -5.0592e-01,  4.6583e-01, -1.2240e-01,  2.1105e-01,\n",
            "         -5.8468e-01, -1.8461e-01,  8.9451e-01,  6.0737e-01,  7.6234e-01,\n",
            "         -9.2200e-01, -2.6497e-01, -9.5013e-01, -9.7655e-01, -9.9472e-01,\n",
            "          2.8953e-01, -3.8575e-01,  9.9929e-01, -7.9938e-01,  9.9472e-01,\n",
            "         -9.8639e-01,  5.2647e-01, -3.0159e-01,  5.3552e-01,  4.0845e-01,\n",
            "         -6.7001e-01,  9.4277e-01,  7.5545e-01,  8.2118e-01, -6.0190e-01,\n",
            "         -7.5948e-01, -7.7051e-01,  4.3117e-01, -8.3294e-01, -5.0889e-01,\n",
            "          7.7152e-01,  7.7410e-01, -5.6457e-01, -9.5389e-02, -8.5963e-01,\n",
            "         -5.7596e-01,  5.6216e-01,  4.3086e-01, -6.6877e-01, -9.1093e-01,\n",
            "          8.3707e-01, -9.2642e-01,  5.9401e-01,  2.5982e-01, -3.2078e-01,\n",
            "          7.8579e-01, -8.6614e-01,  9.1048e-01, -7.6186e-01,  9.8667e-01,\n",
            "          6.3732e-01,  3.9959e-01,  6.0190e-01, -9.9990e-01,  6.4714e-01,\n",
            "         -8.7153e-01,  9.8034e-01, -9.7094e-01, -9.3719e-01,  6.6592e-01,\n",
            "          7.7286e-01,  6.2594e-01,  8.0045e-01, -1.0999e-01, -4.0174e-01,\n",
            "         -8.9714e-01, -6.6291e-01,  5.2660e-01, -9.9781e-01,  7.4626e-01,\n",
            "          5.8506e-01,  7.2560e-01, -6.8914e-01, -5.5773e-01, -9.9850e-01,\n",
            "          5.0808e-01, -6.2108e-01, -4.5987e-01, -9.9990e-01, -6.9988e-01,\n",
            "         -8.1112e-01, -7.7879e-01, -3.1398e-01,  8.5692e-01,  5.4797e-01,\n",
            "          9.9950e-01,  8.6308e-01,  9.9749e-01, -9.9992e-01, -9.9015e-01,\n",
            "          1.8574e-02,  9.2341e-01, -5.9476e-01,  8.8125e-02,  5.2863e-01,\n",
            "         -9.5623e-01,  7.2789e-01, -9.9739e-01,  6.2696e-01, -9.1707e-01,\n",
            "         -4.2911e-01,  7.6370e-01,  8.7824e-01,  5.5909e-01, -6.1495e-01,\n",
            "          5.4767e-01, -9.9944e-01, -7.0372e-03, -6.7876e-01, -9.8947e-01,\n",
            "          9.8931e-01,  7.8445e-01,  8.4466e-01, -4.0759e-01, -2.8306e-01,\n",
            "          7.9632e-01,  8.3033e-01, -6.8488e-01,  1.6753e-01, -1.7009e-01,\n",
            "         -8.0049e-01,  7.9127e-01,  3.8231e-01, -4.3462e-01, -9.9989e-01,\n",
            "          4.9338e-01, -7.1773e-01,  9.2467e-01, -9.8665e-01,  9.6608e-01,\n",
            "         -9.7289e-01, -9.9993e-01,  3.1228e-01,  2.6238e-01, -7.7506e-01,\n",
            "          7.8754e-01, -7.7176e-01,  8.5923e-01, -5.6801e-01,  6.7474e-01,\n",
            "          5.8117e-01,  6.0810e-01,  3.4737e-01, -5.6039e-01,  2.9207e-01,\n",
            "         -6.5830e-01,  8.0190e-01, -7.2512e-01, -6.4799e-01, -9.3857e-01,\n",
            "          9.5876e-01, -3.7818e-01,  9.7260e-01, -9.3745e-01, -7.2905e-01,\n",
            "          4.9593e-01,  2.4775e-01, -9.9998e-01,  8.9982e-01,  4.7725e-01,\n",
            "          3.6653e-01,  6.4887e-01,  2.6405e-01, -4.5069e-01, -4.8835e-02,\n",
            "          4.1834e-02, -4.8272e-01,  6.2776e-01, -2.5886e-01,  8.5579e-01,\n",
            "          2.9485e-01, -9.9928e-01,  7.4393e-01,  9.9139e-01,  1.2843e-01,\n",
            "         -3.7487e-01,  9.0123e-02,  9.7019e-01, -9.9497e-01, -5.8433e-01,\n",
            "          1.4114e-01, -5.2977e-01,  4.2894e-01,  4.1958e-01, -3.9006e-01,\n",
            "         -7.4749e-01,  5.6284e-01,  3.3615e-01, -2.4928e-01, -5.0048e-01,\n",
            "          2.4111e-01,  5.4383e-01, -2.4388e-01,  4.0221e-01,  7.1511e-01,\n",
            "          9.9896e-01, -4.5143e-01, -5.9775e-01,  6.1959e-01, -9.9923e-01,\n",
            "          7.8377e-01,  4.8619e-01, -3.8917e-01, -6.7536e-01,  9.8694e-01,\n",
            "          7.1964e-01,  6.5640e-01,  9.8142e-01, -9.4379e-01, -1.8191e-01,\n",
            "         -5.8409e-01,  8.7541e-01, -4.5942e-01, -9.9618e-02,  9.9993e-01,\n",
            "         -9.9085e-01,  9.8005e-01,  9.0318e-01, -4.7249e-02, -4.6202e-01,\n",
            "          7.1848e-01,  3.1064e-01, -3.3730e-01, -9.5232e-02, -6.2851e-01,\n",
            "          9.9087e-01, -6.3538e-01, -9.7460e-01,  5.2020e-01, -2.3308e-01,\n",
            "         -8.8089e-01, -8.2764e-01,  8.0750e-01, -4.8363e-01,  9.6763e-01,\n",
            "          9.9978e-01,  7.7498e-01,  4.7279e-01,  6.5965e-01,  5.1020e-01,\n",
            "          7.2253e-01, -9.7847e-01,  9.5835e-01,  9.9993e-01, -9.3706e-01,\n",
            "          4.7240e-01,  9.9981e-01,  6.2450e-01, -1.8596e-01, -5.9254e-01,\n",
            "          3.0358e-01, -9.7411e-01, -1.6149e-01, -4.9915e-01, -4.7170e-01,\n",
            "         -5.5056e-01,  2.3369e-04, -9.2700e-01, -9.9906e-01, -9.7683e-01,\n",
            "          9.6028e-01, -6.5162e-01, -6.3006e-01,  5.0747e-01, -7.4318e-01,\n",
            "          5.0955e-01, -7.1836e-01,  9.8822e-01, -6.8005e-01,  9.9986e-01,\n",
            "          5.5192e-01, -5.9563e-01, -9.5079e-01, -2.7486e-01,  4.7514e-01,\n",
            "          9.4638e-02,  9.9881e-01,  4.9422e-02, -5.7663e-01,  7.1369e-01,\n",
            "          5.9679e-01,  2.3072e-01,  9.1189e-01, -5.8589e-01,  6.1566e-01,\n",
            "          3.7521e-01,  3.9302e-02, -9.3405e-01, -3.0689e-01, -8.3895e-01,\n",
            "          7.4137e-01,  9.5281e-01,  6.8151e-01,  3.1604e-01,  9.5049e-01,\n",
            "          8.0552e-01, -9.9995e-01,  9.9835e-01,  9.7317e-01, -9.8881e-01,\n",
            "          8.0507e-01, -1.2433e-01,  8.7962e-01, -2.1942e-01,  4.1349e-01,\n",
            "         -8.7130e-01, -8.0553e-01, -9.7147e-01,  7.5035e-01,  1.8264e-01,\n",
            "         -7.0195e-01,  2.4712e-01, -8.9971e-01,  7.7182e-01,  1.1831e-01,\n",
            "          8.1519e-01, -3.1514e-01,  2.1641e-01, -9.9365e-01,  6.5229e-01,\n",
            "          8.5989e-01, -2.4646e-01,  7.4322e-01,  9.8286e-01,  7.3883e-04,\n",
            "          9.9993e-01, -7.3414e-01, -5.4252e-01,  2.1559e-01,  5.4374e-01,\n",
            "          3.8904e-01,  4.3567e-01, -2.8474e-01,  5.7850e-01, -9.9996e-01,\n",
            "          2.9347e-01, -5.0950e-01,  2.5852e-01,  6.7417e-01, -9.8027e-01,\n",
            "          5.5228e-01, -4.4316e-01,  7.8106e-02, -2.0686e-01,  3.0465e-01,\n",
            "          5.6190e-01,  9.9842e-01,  3.5024e-01, -4.7536e-01, -6.5695e-01,\n",
            "          6.3726e-02,  1.6997e-02,  8.8884e-01,  6.1654e-01,  9.8684e-01,\n",
            "         -7.9998e-01, -3.2079e-01,  6.3948e-01,  1.1214e-02, -6.4881e-01,\n",
            "         -1.1722e-01,  6.1000e-01,  2.1283e-02,  9.0694e-01,  7.2808e-01,\n",
            "         -5.7801e-01, -5.3803e-01,  8.2629e-01, -9.9767e-01,  9.9984e-01,\n",
            "          2.6038e-01,  4.9828e-01,  9.2118e-01, -2.8828e-01,  6.7181e-01,\n",
            "          4.8489e-01,  3.0160e-01, -6.8107e-01,  9.6970e-01,  7.2137e-01,\n",
            "          5.9895e-01,  1.0460e-01, -1.6091e-01, -3.3352e-02, -9.2051e-01,\n",
            "          4.9631e-01,  3.7809e-01, -4.1101e-01, -9.7323e-01,  9.8372e-01,\n",
            "         -9.7479e-01,  4.0588e-01, -1.7507e-01,  8.0101e-01,  9.2096e-01,\n",
            "         -2.8864e-01, -8.6239e-01, -1.4254e-01,  4.5124e-01, -6.6349e-01,\n",
            "         -7.9460e-01, -9.8953e-01, -8.2049e-02, -8.6278e-01,  9.9978e-01,\n",
            "         -9.8645e-01,  5.0360e-01, -8.9247e-01, -8.9967e-01,  7.3026e-01,\n",
            "         -4.6160e-01, -5.5703e-01, -8.1929e-01, -1.4253e-01, -4.7874e-01,\n",
            "          7.4178e-01,  1.9313e-02,  7.2322e-01, -4.7167e-01,  2.8211e-01,\n",
            "          7.3565e-01,  1.5179e-01,  2.4365e-01,  9.0405e-01, -6.1203e-01,\n",
            "         -9.4053e-01, -6.7303e-01, -5.4305e-01, -7.0743e-01,  9.4885e-01,\n",
            "         -9.0873e-01, -8.2646e-01,  9.9996e-01, -9.7867e-01,  1.8594e-01,\n",
            "         -3.5437e-01, -9.9559e-01,  5.6625e-01, -2.7463e-01, -9.3038e-01,\n",
            "         -6.1901e-01, -7.9923e-01,  6.3967e-01,  9.2039e-01,  9.9869e-01,\n",
            "          2.3760e-01,  2.6597e-01, -9.3846e-01, -6.3629e-01,  9.9678e-01,\n",
            "         -9.4381e-01, -4.4642e-01,  3.5891e-01, -9.9301e-01,  9.2233e-01,\n",
            "          2.5370e-01, -4.5245e-01,  8.2270e-01, -6.8292e-01,  9.5797e-01,\n",
            "          6.2427e-01, -9.9665e-01,  5.6074e-01,  6.6644e-01, -3.2676e-01,\n",
            "          8.4652e-01,  2.9479e-01,  2.6446e-01, -9.4273e-01, -6.0343e-02,\n",
            "          9.9866e-01,  4.2664e-01, -7.6401e-01, -1.4735e-02,  7.9020e-01,\n",
            "          7.7230e-01,  9.9992e-01, -9.5747e-01,  6.4892e-01,  9.9920e-01,\n",
            "         -2.7466e-01,  4.4836e-01,  3.0314e-01, -7.4714e-01,  7.4231e-02,\n",
            "          4.6690e-01, -9.7386e-01,  9.9972e-01,  3.1964e-02, -9.8620e-01,\n",
            "         -9.9988e-01,  2.7911e-01, -8.0426e-01,  7.5702e-01,  9.6785e-01,\n",
            "          6.1130e-01,  8.6147e-01,  2.5340e-01, -9.9824e-01, -7.2256e-02,\n",
            "         -5.4478e-01, -9.9959e-01, -9.9890e-01,  8.3065e-01,  1.7731e-01,\n",
            "          1.7836e-01,  7.7010e-01, -2.9439e-02, -7.3985e-01,  9.9941e-01,\n",
            "          9.0011e-01, -9.9984e-01, -1.2131e-01,  2.2313e-01,  9.6122e-01,\n",
            "         -7.0715e-01,  5.7873e-01,  4.2281e-01,  4.0845e-01, -3.7201e-01,\n",
            "         -9.9991e-01, -4.5825e-01,  9.6335e-01, -1.4013e-02, -1.6942e-02,\n",
            "          9.9908e-01,  6.7378e-01,  4.4004e-01, -9.3608e-01, -1.2752e-01,\n",
            "          6.4073e-01, -9.9991e-01, -7.0770e-01,  9.9962e-01, -1.8979e-01,\n",
            "         -1.9191e-02, -4.7641e-01,  3.4130e-01,  5.7211e-01,  5.9144e-01,\n",
            "          3.8332e-02, -9.9548e-01,  9.9283e-01,  8.6785e-01, -9.1745e-01,\n",
            "          9.9590e-01, -5.5083e-01, -6.8359e-01, -7.3714e-01, -6.5193e-01,\n",
            "          7.1237e-01, -7.2200e-01,  4.7711e-01, -2.0061e-01,  9.7753e-01,\n",
            "          8.7439e-01, -3.6056e-01,  7.3130e-01,  9.0739e-01, -7.8657e-01,\n",
            "         -2.9736e-01,  7.3927e-01,  5.7955e-01,  4.4139e-01,  9.7642e-01,\n",
            "         -4.3327e-01, -7.0940e-01, -4.3040e-01,  6.2356e-01,  9.1769e-01,\n",
            "         -9.9978e-01,  9.1783e-01, -4.8238e-01, -8.6726e-01,  6.3506e-01,\n",
            "         -5.4287e-01, -5.6807e-01, -2.3853e-01, -5.8673e-01, -6.3828e-01,\n",
            "          1.4194e-01,  9.4102e-01,  7.0616e-01,  7.3113e-01, -9.8167e-01,\n",
            "         -9.9981e-01, -6.8812e-01, -5.6243e-01, -7.9296e-01, -5.1031e-01,\n",
            "          3.0331e-01,  9.3002e-01,  1.8297e-01,  4.7623e-01,  2.2843e-01,\n",
            "          9.9964e-01, -4.0166e-01,  9.8973e-01, -7.8241e-01,  9.2462e-01,\n",
            "         -9.8666e-01,  4.8373e-01,  5.4115e-01, -9.2689e-01, -4.5715e-01,\n",
            "          9.5196e-01, -3.0058e-01,  8.1676e-01, -9.6498e-01,  6.1138e-01,\n",
            "          9.9994e-01, -7.1196e-01, -6.4835e-01,  6.4139e-01, -8.6439e-01,\n",
            "          7.5104e-01,  3.2810e-02,  9.9137e-01, -9.9992e-01,  9.8700e-01,\n",
            "         -1.5012e-01,  4.3237e-01,  5.4413e-01,  5.7631e-01,  5.9343e-01,\n",
            "         -5.9193e-01, -4.7221e-01, -9.8651e-01,  6.4524e-01,  3.7315e-01,\n",
            "         -6.4624e-01,  2.7494e-01,  9.0311e-01, -7.5458e-01, -9.9684e-01,\n",
            "         -5.9401e-01,  4.7177e-01,  9.3451e-01, -4.7129e-01, -9.8869e-01,\n",
            "          9.5173e-01, -1.8587e-01,  9.6360e-01,  2.4864e-01, -7.0269e-01,\n",
            "         -4.4153e-01, -1.1882e-01, -5.7789e-01,  5.2852e-01,  6.7922e-01,\n",
            "          7.9422e-01,  3.0424e-01, -8.7264e-01, -4.7856e-01,  1.0447e-01,\n",
            "         -7.5603e-01,  7.1169e-01, -3.6212e-01, -1.8261e-01,  7.2362e-01,\n",
            "          8.2394e-01,  9.6938e-01,  3.8906e-01,  2.0759e-01,  7.4169e-01,\n",
            "         -7.2725e-01, -6.2328e-01, -9.9951e-01,  9.9856e-01,  8.4134e-01,\n",
            "         -8.3141e-01, -9.9956e-01,  9.2747e-01,  1.6642e-01, -3.2134e-01,\n",
            "          7.0544e-01, -2.2227e-02, -6.5300e-01,  3.2338e-01,  7.0392e-01,\n",
            "         -9.9994e-01, -4.3879e-01,  1.4222e-01, -3.8053e-01, -6.9283e-01,\n",
            "         -9.9966e-01, -5.6093e-01,  7.2067e-02, -2.5457e-01,  2.7474e-01,\n",
            "          9.9737e-01, -3.9358e-01, -9.8487e-01, -9.4774e-01, -8.3131e-02,\n",
            "          6.0320e-01,  1.6480e-01, -9.3894e-01, -5.4692e-01,  8.0390e-01,\n",
            "         -9.9783e-01,  7.0519e-01, -5.5182e-01, -5.0000e-01,  2.0700e-01,\n",
            "          7.1960e-01,  8.9781e-01, -9.9988e-01,  8.5524e-01, -6.4054e-01,\n",
            "          8.9081e-01, -4.9517e-01,  5.2264e-01,  4.3705e-01,  2.3700e-01,\n",
            "         -9.9516e-01,  7.9200e-01,  2.9624e-01,  7.8375e-01,  7.3540e-01,\n",
            "          7.6820e-01,  3.3546e-02, -8.5844e-01, -6.4866e-01,  9.7795e-01,\n",
            "          9.6690e-01, -6.3113e-01,  6.2995e-01,  9.9796e-01, -6.0320e-01,\n",
            "          5.1353e-01,  6.4023e-01,  1.4416e-01, -9.9873e-01, -8.2406e-01,\n",
            "         -1.7917e-01, -6.3300e-01, -8.0789e-01]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training... :   0%|          | 0/127 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f3243dfd90014c449a91e5e3826c00a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.8346,  0.9570, -0.8885,  ..., -0.9063, -0.1653,  0.6487],\n",
            "        [ 0.8393,  1.0000,  0.9727,  ...,  0.8009, -0.1464, -0.9095],\n",
            "        [ 0.6321,  0.9884,  0.8732,  ...,  0.7666, -0.8030, -0.4701],\n",
            "        ...,\n",
            "        [-0.4189,  1.0000, -0.5436,  ..., -0.7384, -0.0113, -0.7250],\n",
            "        [-0.0257,  0.9251, -0.8862,  ..., -0.8306,  0.5875,  0.0625],\n",
            "        [ 0.6647,  0.9409,  0.7963,  ...,  0.8454, -0.8301, -0.3942]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4462, -0.2235, -0.9075,  ..., -0.8832,  0.3004,  0.3871],\n",
            "        [ 0.7688,  1.0000,  0.9661,  ...,  0.6445, -0.6540, -0.8041],\n",
            "        [-0.6591, -0.8556, -0.9174,  ..., -0.9101,  0.1681,  0.5977],\n",
            "        ...,\n",
            "        [ 0.1276,  0.9991, -0.8902,  ..., -0.9089,  0.6450, -0.0875],\n",
            "        [ 0.7395,  0.9973,  0.8198,  ...,  0.9128, -0.8174, -0.3475],\n",
            "        [ 0.4415,  0.9993,  0.8086,  ...,  0.8365, -0.7663, -0.2545]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1474,  0.9817, -0.8428,  ..., -0.8955,  0.7440,  0.2241],\n",
            "        [ 0.5587,  0.9993,  0.9247,  ...,  0.6735, -0.4397, -0.6279],\n",
            "        [ 0.7348,  1.0000,  0.9453,  ...,  0.9061, -0.5636, -0.8274],\n",
            "        ...,\n",
            "        [ 0.6861,  0.9998,  0.9130,  ...,  0.8536, -0.5565, -0.6146],\n",
            "        [ 0.6151,  0.9987,  0.8709,  ...,  0.8477, -0.8743, -0.5346],\n",
            "        [ 0.7221,  0.9934,  0.8601,  ...,  0.9164, -0.8727, -0.2172]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7501,  0.9881,  0.8372,  ...,  0.9072, -0.7963, -0.5904],\n",
            "        [ 0.4002,  0.9998,  0.9218,  ...,  0.5711, -0.2342, -0.8456],\n",
            "        [ 0.4610,  0.9947,  0.7908,  ...,  0.7147, -0.6741, -0.1240],\n",
            "        ...,\n",
            "        [-0.4116,  0.7331, -0.9127,  ..., -0.7919,  0.4713, -0.0146],\n",
            "        [ 0.7149,  0.9998,  0.8160,  ...,  0.8543, -0.7384, -0.4144],\n",
            "        [-0.3225, -0.9606, -0.9575,  ..., -0.9400,  0.1451,  0.2682]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3424, -0.2938, -0.9471,  ..., -0.8845,  0.2544,  0.5754],\n",
            "        [ 0.6708,  1.0000,  0.9436,  ...,  0.7888, -0.0313, -0.9204],\n",
            "        [-0.5785, -0.8445, -0.9270,  ..., -0.8721,  0.2019,  0.7229],\n",
            "        ...,\n",
            "        [ 0.3953,  0.9999,  0.9472,  ...,  0.8343, -0.6520, -0.7903],\n",
            "        [ 0.6961,  0.9926,  0.8105,  ...,  0.8666, -0.8558, -0.1106],\n",
            "        [ 0.7344,  0.9999,  0.9309,  ...,  0.8525, -0.3513, -0.7176]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6073,  0.9975,  0.9485,  ...,  0.8292, -0.7524, -0.1354],\n",
            "        [ 0.2891,  0.9553,  0.8744,  ...,  0.5872, -0.8652, -0.2855],\n",
            "        [-0.6125, -0.9518, -0.8656,  ..., -0.8725, -0.1368,  0.4948],\n",
            "        ...,\n",
            "        [ 0.6436,  0.9906,  0.7391,  ...,  0.8578, -0.7504,  0.0076],\n",
            "        [-0.3241,  0.9922, -0.7523,  ..., -0.6977,  0.3437, -0.1338],\n",
            "        [-0.6614, -0.9223, -0.9357,  ..., -0.8580,  0.4947,  0.4957]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6357, -0.8313, -0.9196,  ..., -0.9250,  0.0504,  0.8260],\n",
            "        [ 0.6572,  0.9998,  0.9043,  ...,  0.8778, -0.4396, -0.7111],\n",
            "        [ 0.6771,  0.9986,  0.8765,  ...,  0.8615, -0.8417, -0.3452],\n",
            "        ...,\n",
            "        [ 0.7389,  1.0000,  0.9361,  ...,  0.9182, -0.5156, -0.6427],\n",
            "        [ 0.7253,  0.9983,  0.8368,  ...,  0.9202, -0.6930, -0.2330],\n",
            "        [-0.6537,  0.9157, -0.9175,  ..., -0.9268,  0.3620,  0.0107]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2614,  0.6029, -0.9198,  ..., -0.7910,  0.3592,  0.2061],\n",
            "        [ 0.7124,  0.9998,  0.8393,  ...,  0.9109, -0.7602, -0.4721],\n",
            "        [ 0.7699,  0.9999,  0.8713,  ...,  0.9197, -0.7373, -0.6370],\n",
            "        ...,\n",
            "        [-0.7392,  0.1837, -0.9437,  ..., -0.9004,  0.0855,  0.4781],\n",
            "        [-0.7220, -0.9220, -0.9314,  ..., -0.8689,  0.2386,  0.5994],\n",
            "        [-0.3177, -0.9598, -0.9399,  ..., -0.8672,  0.5864,  0.2986]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.7085,  0.4856, -0.8906,  ..., -0.8489,  0.0290,  0.5281],\n",
            "        [ 0.6758,  0.9899,  0.6265,  ...,  0.8050, -0.7830, -0.4501],\n",
            "        [-0.5101, -0.1637, -0.9010,  ..., -0.8852,  0.5659,  0.5367],\n",
            "        ...,\n",
            "        [-0.5239, -0.3408, -0.9545,  ..., -0.8847,  0.4188,  0.6141],\n",
            "        [ 0.3496,  0.9844,  0.7701,  ...,  0.8567, -0.7251, -0.1290],\n",
            "        [-0.4740, -0.5400, -0.9497,  ..., -0.8727,  0.1262,  0.5205]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6739,  1.0000,  0.8598,  ...,  0.7452, -0.5279, -0.7094],\n",
            "        [-0.4772, -0.0099, -0.9405,  ..., -0.8836,  0.2533,  0.3842],\n",
            "        [ 0.7160,  1.0000,  0.9434,  ...,  0.7054, -0.2893, -0.8505],\n",
            "        ...,\n",
            "        [ 0.6733,  1.0000,  0.8969,  ...,  0.9284, -0.3920, -0.6939],\n",
            "        [ 0.4306,  0.9939,  0.8927,  ...,  0.8558, -0.8547, -0.5234],\n",
            "        [ 0.7811,  0.9999,  0.8278,  ...,  0.9248, -0.7171, -0.5246]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4402, -0.9997, -0.9484,  ..., -0.8507,  0.2433,  0.7037],\n",
            "        [ 0.6699,  0.9991,  0.7662,  ...,  0.8297, -0.7816, -0.0337],\n",
            "        [-0.4133, -0.5805, -0.8405,  ..., -0.7865,  0.2196, -0.2394],\n",
            "        ...,\n",
            "        [ 0.8339,  1.0000,  0.9691,  ...,  0.6573,  0.0481, -0.9169],\n",
            "        [ 0.5573,  0.9998,  0.8773,  ...,  0.8112, -0.7801, -0.4482],\n",
            "        [-0.5653,  0.9966, -0.7389,  ..., -0.8833,  0.1151, -0.1948]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4480,  0.7559, -0.9291,  ..., -0.9395,  0.1009,  0.0429],\n",
            "        [-0.6988,  0.9814, -0.8073,  ..., -0.5783,  0.2603,  0.5193],\n",
            "        [ 0.0017,  0.9070, -0.8981,  ..., -0.8638,  0.4583,  0.0081],\n",
            "        ...,\n",
            "        [ 0.5119,  1.0000,  0.9263,  ...,  0.7400, -0.1078, -0.8922],\n",
            "        [ 0.7490,  0.9994,  0.8177,  ...,  0.7964, -0.7572, -0.5105],\n",
            "        [ 0.5430,  1.0000,  0.7908,  ...,  0.6972, -0.4892, -0.4222]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7675,  0.9961,  0.8375,  ...,  0.9140, -0.7809, -0.3417],\n",
            "        [-0.3091, -0.5925, -0.8789,  ..., -0.9425,  0.3788,  0.2604],\n",
            "        [-0.4513,  0.3376, -0.9587,  ..., -0.8148,  0.4285,  0.6557],\n",
            "        ...,\n",
            "        [ 0.3792,  0.9969,  0.8834,  ...,  0.8597, -0.7926, -0.3057],\n",
            "        [ 0.7582,  0.9978,  0.6853,  ...,  0.8443, -0.5466, -0.6674],\n",
            "        [ 0.7368,  0.9977,  0.8493,  ...,  0.8417, -0.8176, -0.5403]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6481,  0.9957,  0.5795,  ...,  0.9077, -0.8849, -0.4794],\n",
            "        [-0.1216,  0.9998, -0.6199,  ..., -0.8456,  0.2727, -0.4615],\n",
            "        [-0.5102, -0.9923, -0.9353,  ..., -0.9209,  0.1552,  0.5814],\n",
            "        ...,\n",
            "        [ 0.7575,  0.9994,  0.9339,  ...,  0.8549, -0.6217, -0.5687],\n",
            "        [-0.3008, -0.7576, -0.9544,  ..., -0.9119,  0.3487,  0.4459],\n",
            "        [ 0.6191,  0.9856,  0.7622,  ...,  0.7163, -0.7498, -0.2976]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5873,  0.9913,  0.6693,  ...,  0.8710, -0.8287, -0.1108],\n",
            "        [-0.4802, -0.9517, -0.9069,  ..., -0.8648,  0.3356,  0.3617],\n",
            "        [ 0.5481,  0.9690,  0.8790,  ...,  0.8874, -0.8829, -0.1834],\n",
            "        ...,\n",
            "        [-0.6195, -0.8775, -0.9368,  ..., -0.8956,  0.4577,  0.4941],\n",
            "        [-0.2962,  0.9999, -0.7660,  ..., -0.8232,  0.7777, -0.5591],\n",
            "        [ 0.5889,  0.9997,  0.9628,  ...,  0.7687, -0.6582, -0.5864]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6693,  0.9974,  0.8739,  ...,  0.9274, -0.7289, -0.2941],\n",
            "        [-0.3848, -0.4243, -0.9146,  ..., -0.8461,  0.1430,  0.4121],\n",
            "        [ 0.7468,  1.0000,  0.9762,  ...,  0.8292, -0.5625, -0.8304],\n",
            "        ...,\n",
            "        [-0.5650, -0.9884, -0.9258,  ..., -0.8965,  0.6733,  0.4403],\n",
            "        [-0.4519, -0.9415, -0.9372,  ..., -0.8971,  0.2313,  0.6115],\n",
            "        [-0.7114,  0.1757, -0.9267,  ..., -0.7480, -0.0459,  0.5801]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.7903,  0.5218, -0.9417,  ..., -0.8393,  0.2896,  0.4350],\n",
            "        [ 0.3503,  0.9897, -0.9076,  ..., -0.8292,  0.6684, -0.1586],\n",
            "        [ 0.3482,  0.9978,  0.8394,  ...,  0.8193, -0.9104, -0.2874],\n",
            "        ...,\n",
            "        [ 0.5700,  0.9976,  0.8807,  ...,  0.7724, -0.8534, -0.3775],\n",
            "        [ 0.7617,  0.9993,  0.7417,  ...,  0.9174, -0.8388, -0.4137],\n",
            "        [ 0.0068,  0.9997,  0.7466,  ...,  0.0897,  0.4109, -0.8010]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4213,  0.9883, -0.8620,  ..., -0.8918,  0.6121,  0.2247],\n",
            "        [-0.5634, -0.9192, -0.8744,  ..., -0.8680,  0.4275,  0.2518],\n",
            "        [ 0.4894,  0.9989,  0.8867,  ...,  0.8190, -0.8237, -0.4246],\n",
            "        ...,\n",
            "        [-0.1994,  0.9972, -0.6783,  ..., -0.6890,  0.5609, -0.4038],\n",
            "        [ 0.5363,  0.9700,  0.9195,  ...,  0.8897, -0.7958, -0.1632],\n",
            "        [ 0.6980,  0.9738,  0.8848,  ...,  0.8198, -0.7670, -0.5301]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6178,  0.9957,  0.8128,  ...,  0.8950, -0.8478, -0.2198],\n",
            "        [ 0.6357,  0.9934,  0.9135,  ...,  0.8948, -0.8372, -0.3672],\n",
            "        [-0.7340, -0.4586, -0.9270,  ..., -0.9142, -0.0601,  0.6269],\n",
            "        ...,\n",
            "        [-0.3170,  0.9962,  0.2523,  ..., -0.3685,  0.2572, -0.6864],\n",
            "        [ 0.7239,  0.9914,  0.7657,  ...,  0.8973, -0.7680, -0.3774],\n",
            "        [ 0.8286,  1.0000,  0.5222,  ...,  0.7291, -0.5471, -0.3776]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5060, -0.7041, -0.9253,  ..., -0.8369,  0.4474,  0.5320],\n",
            "        [ 0.6600,  0.9998,  0.9402,  ...,  0.8799, -0.5097, -0.7218],\n",
            "        [ 0.7435,  0.9991,  0.9439,  ...,  0.8659, -0.7347, -0.3374],\n",
            "        ...,\n",
            "        [-0.2893,  0.8156, -0.7956,  ..., -0.8132,  0.5278,  0.3581],\n",
            "        [-0.2315, -0.9985, -0.9146,  ..., -0.8233,  0.3954,  0.0189],\n",
            "        [ 0.6994,  0.9971,  0.9115,  ...,  0.9020, -0.7386, -0.5363]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7916,  0.9999,  0.9359,  ...,  0.9221, -0.6447, -0.5355],\n",
            "        [ 0.6172,  0.9990,  0.9053,  ...,  0.8926, -0.6592, -0.5604],\n",
            "        [ 0.3441,  0.9998,  0.6901,  ...,  0.7365, -0.5602, -0.3664],\n",
            "        ...,\n",
            "        [-0.5702, -0.9372, -0.9511,  ..., -0.8547,  0.2801,  0.4215],\n",
            "        [-0.4883, -0.7244, -0.9484,  ..., -0.9506, -0.2468,  0.5446],\n",
            "        [ 0.7554,  1.0000,  0.9412,  ...,  0.6564,  0.2143, -0.9025]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5595,  0.9880, -0.9445,  ..., -0.8979,  0.3624,  0.5002],\n",
            "        [-0.8259,  0.9097, -0.8756,  ..., -0.8982,  0.0530,  0.3524],\n",
            "        [ 0.7579,  0.9999,  0.9333,  ...,  0.8701, -0.7113, -0.6104],\n",
            "        ...,\n",
            "        [-0.2717, -0.4876, -0.9314,  ..., -0.8316,  0.5415,  0.3111],\n",
            "        [ 0.6374,  0.9998,  0.8653,  ...,  0.8594, -0.5793, -0.7086],\n",
            "        [-0.6097,  0.4182, -0.9151,  ..., -0.6387,  0.1303,  0.3675]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7278,  0.9989,  0.8234,  ...,  0.8569, -0.7607, -0.3741],\n",
            "        [ 0.7017,  0.9406,  0.7764,  ...,  0.8686, -0.8583,  0.0451],\n",
            "        [ 0.1845,  0.9875, -0.7935,  ..., -0.9240,  0.5879, -0.3814],\n",
            "        ...,\n",
            "        [ 0.4880,  0.9996,  0.8257,  ...,  0.8221, -0.6606, -0.3148],\n",
            "        [-0.2491, -0.7516, -0.8390,  ..., -0.8555,  0.4931, -0.2146],\n",
            "        [ 0.8101,  1.0000,  0.9285,  ...,  0.7512, -0.5494, -0.8807]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3391, -0.9196, -0.8958,  ..., -0.8880,  0.3554,  0.6254],\n",
            "        [ 0.5464,  0.9864,  0.8209,  ...,  0.8601, -0.8405, -0.0954],\n",
            "        [ 0.7157,  1.0000,  0.9355,  ...,  0.3515,  0.4919, -0.9826],\n",
            "        ...,\n",
            "        [-0.2494,  0.9866, -0.8727,  ..., -0.9250,  0.1006, -0.0860],\n",
            "        [ 0.6090,  0.9968,  0.8939,  ...,  0.8627, -0.8179, -0.1344],\n",
            "        [ 0.7438,  0.9998,  0.8496,  ...,  0.9327, -0.7631, -0.5358]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5262,  0.9999,  0.9073,  ...,  0.7869, -0.4932, -0.8035],\n",
            "        [ 0.6241,  0.9990,  0.9205,  ...,  0.8833, -0.7901, -0.5261],\n",
            "        [-0.6655, -0.9852, -0.9417,  ..., -0.9254,  0.0253,  0.8229],\n",
            "        ...,\n",
            "        [-0.6643, -0.6251, -0.8732,  ..., -0.8795,  0.5441,  0.5906],\n",
            "        [ 0.6830,  0.9990,  0.7738,  ...,  0.7703, -0.5508, -0.4294],\n",
            "        [ 0.2029,  0.9976,  0.8745,  ...,  0.8726, -0.7973, -0.3730]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4542,  0.0353, -0.9109,  ..., -0.8712,  0.3176,  0.5521],\n",
            "        [ 0.5911,  0.9948,  0.8252,  ...,  0.7869, -0.7875, -0.2815],\n",
            "        [ 0.7309,  0.9969,  0.8357,  ...,  0.8350, -0.8900, -0.0783],\n",
            "        ...,\n",
            "        [-0.7175, -0.9998, -0.8417,  ..., -0.8211,  0.2042,  0.0104],\n",
            "        [ 0.6682,  0.9981,  0.9125,  ...,  0.8692, -0.7465, -0.6166],\n",
            "        [-0.3092,  0.9504, -0.7840,  ..., -0.8331,  0.7085,  0.1488]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6438, -0.8677, -0.9408,  ..., -0.9126,  0.2115,  0.6145],\n",
            "        [ 0.6316,  0.9978,  0.9118,  ...,  0.9133, -0.8080, -0.5103],\n",
            "        [ 0.4985,  1.0000,  0.9006,  ...,  0.7659, -0.5679, -0.7261],\n",
            "        ...,\n",
            "        [-0.4737,  0.9839, -0.8376,  ..., -0.8598,  0.4625, -0.3210],\n",
            "        [-0.5613, -0.9412, -0.9551,  ..., -0.9249,  0.1395,  0.8091],\n",
            "        [-0.3574,  0.9828, -0.8905,  ..., -0.8284,  0.3846,  0.3705]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6536,  0.6916, -0.7035,  ..., -0.8580,  0.3476, -0.2145],\n",
            "        [-0.5493, -0.8889, -0.9358,  ..., -0.9181,  0.0843,  0.6355],\n",
            "        [-0.0074,  0.9921, -0.6452,  ..., -0.7456,  0.3035, -0.3663],\n",
            "        ...,\n",
            "        [ 0.7734,  0.9998,  0.9013,  ...,  0.9244, -0.7253, -0.3467],\n",
            "        [-0.5508, -0.9311, -0.8660,  ..., -0.7829,  0.2912,  0.2635],\n",
            "        [-0.3329, -0.6510, -0.9243,  ..., -0.8516,  0.1647,  0.6088]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2636,  0.9758,  0.7515,  ...,  0.8299, -0.7577,  0.0559],\n",
            "        [ 0.5688,  0.9946,  0.8496,  ...,  0.6676, -0.5749, -0.2923],\n",
            "        [ 0.6902,  0.9959,  0.8330,  ...,  0.9134, -0.7442, -0.4475],\n",
            "        ...,\n",
            "        [-0.5904, -0.9458, -0.9479,  ..., -0.8252,  0.0895,  0.6468],\n",
            "        [ 0.6752,  0.9927,  0.8824,  ...,  0.8793, -0.8537, -0.4723],\n",
            "        [ 0.6707,  0.9983,  0.8501,  ...,  0.8068, -0.7038, -0.1430]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6259,  0.9997,  0.8843,  ...,  0.8787, -0.7493, -0.2716],\n",
            "        [ 0.7322,  0.9975,  0.7906,  ...,  0.8635, -0.8955, -0.3921],\n",
            "        [ 0.0161,  0.8371, -0.9540,  ..., -0.9056,  0.3353,  0.0335],\n",
            "        ...,\n",
            "        [ 0.6725,  0.9941,  0.8572,  ...,  0.8528, -0.8057, -0.4364],\n",
            "        [-0.6122, -0.7663, -0.9087,  ..., -0.9249,  0.3184,  0.4766],\n",
            "        [ 0.4661,  1.0000,  0.9472,  ...,  0.1835,  0.2456, -0.9630]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6997, -0.9701, -0.9452,  ..., -0.9158,  0.1969,  0.8412],\n",
            "        [-0.5668, -0.9972, -0.9372,  ..., -0.9008,  0.2003,  0.2902],\n",
            "        [ 0.7794,  0.9998,  0.8844,  ...,  0.8894, -0.6650, -0.3427],\n",
            "        ...,\n",
            "        [-0.5695,  0.5199, -0.9215,  ..., -0.8896,  0.3861,  0.7113],\n",
            "        [ 0.6460,  0.9969,  0.8699,  ...,  0.8860, -0.7995, -0.3463],\n",
            "        [-0.7662, -0.2371, -0.9390,  ..., -0.9288,  0.1036,  0.5035]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5188,  0.9988,  0.8232,  ...,  0.8626, -0.8540, -0.1048],\n",
            "        [ 0.6433,  0.9880,  0.8860,  ...,  0.9005, -0.8286, -0.1351],\n",
            "        [-0.5107,  0.2963, -0.7673,  ..., -0.9029,  0.4053,  0.0904],\n",
            "        ...,\n",
            "        [-0.3017,  0.9952, -0.8102,  ..., -0.8255,  0.2827, -0.2110],\n",
            "        [ 0.7623,  0.9902,  0.9234,  ...,  0.8612, -0.7592, -0.2643],\n",
            "        [ 0.8164,  1.0000,  0.9427,  ...,  0.7280, -0.1983, -0.8970]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6940,  1.0000,  0.8949,  ...,  0.9184, -0.7032, -0.7155],\n",
            "        [-0.2646,  0.8489, -0.9283,  ..., -0.7805,  0.4618,  0.1309],\n",
            "        [ 0.4184,  0.9992,  0.8459,  ...,  0.8580, -0.7718, -0.2656],\n",
            "        ...,\n",
            "        [ 0.8509,  1.0000,  0.7052,  ...,  0.8548, -0.8212, -0.7195],\n",
            "        [-0.5193, -0.9263, -0.9279,  ..., -0.8944,  0.3342,  0.5943],\n",
            "        [-0.5487, -0.8210, -0.9490,  ..., -0.8623,  0.2545,  0.6305]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2847, -0.3339, -0.7004,  ..., -0.8386, -0.5258,  0.6209],\n",
            "        [-0.3979, -0.2956, -0.9228,  ..., -0.7891,  0.5903,  0.4933],\n",
            "        [ 0.5770,  0.9938,  0.8128,  ...,  0.8643, -0.8810, -0.4248],\n",
            "        ...,\n",
            "        [-0.2317,  0.9525, -0.9123,  ..., -0.8227,  0.3547,  0.0872],\n",
            "        [ 0.6335,  0.9867,  0.8730,  ...,  0.8461, -0.8346, -0.4797],\n",
            "        [ 0.5970,  0.9888,  0.8317,  ...,  0.9124, -0.8799, -0.2513]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6586,  0.9990,  0.8906,  ...,  0.8580, -0.8285, -0.3366],\n",
            "        [ 0.4997,  0.9997,  0.8495,  ...,  0.9052, -0.8195, -0.5069],\n",
            "        [ 0.4220,  0.9937,  0.7743,  ...,  0.9120, -0.8255, -0.2151],\n",
            "        ...,\n",
            "        [-0.7035, -0.9377, -0.8875,  ..., -0.8153,  0.2053,  0.7709],\n",
            "        [-0.4300,  0.9575, -0.9004,  ..., -0.8030,  0.5371,  0.1838],\n",
            "        [ 0.7626,  1.0000,  0.9578,  ...,  0.8950, -0.4537, -0.7862]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6061, -0.8624, -0.9626,  ..., -0.9087,  0.3090,  0.7204],\n",
            "        [-0.4505, -0.4965, -0.9593,  ..., -0.9180,  0.3114,  0.5249],\n",
            "        [ 0.6566,  0.9230,  0.8698,  ...,  0.8853, -0.8070, -0.2412],\n",
            "        ...,\n",
            "        [ 0.6558,  0.9998,  0.8752,  ...,  0.8845, -0.6400, -0.3374],\n",
            "        [-0.5118,  0.9816, -0.8935,  ..., -0.8127, -0.1003,  0.6152],\n",
            "        [-0.7638, -0.8410, -0.9523,  ..., -0.9153,  0.5596,  0.6029]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5653, -0.0124, -0.9324,  ..., -0.9082,  0.4072,  0.0121],\n",
            "        [ 0.6523,  0.9936,  0.8466,  ...,  0.8661, -0.7768, -0.3756],\n",
            "        [ 0.0645,  0.9951, -0.7806,  ..., -0.5271,  0.5834, -0.3057],\n",
            "        ...,\n",
            "        [ 0.6890,  0.9993,  0.9473,  ...,  0.8872, -0.7829, -0.6978],\n",
            "        [ 0.6118,  0.9992,  0.8416,  ...,  0.7698, -0.7022, -0.6196],\n",
            "        [ 0.7930,  0.9945,  0.9002,  ...,  0.8876, -0.7478, -0.4109]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5075,  0.9872,  0.8936,  ...,  0.8458, -0.8227, -0.2779],\n",
            "        [ 0.2095,  0.9997,  0.7921,  ...,  0.8085, -0.5206, -0.4691],\n",
            "        [ 0.6439,  0.9992,  0.8929,  ...,  0.8576, -0.8172, -0.4569],\n",
            "        ...,\n",
            "        [-0.7777, -0.0229, -0.9461,  ..., -0.8356,  0.4312,  0.6990],\n",
            "        [-0.3396,  0.9722, -0.8723,  ..., -0.8743,  0.7283,  0.1219],\n",
            "        [-0.3218,  0.9759, -0.8927,  ..., -0.8820,  0.3893,  0.1052]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4653, -0.9167, -0.9433,  ..., -0.8896,  0.3420,  0.2803],\n",
            "        [-0.1226,  0.9985, -0.7481,  ..., -0.7816,  0.5681, -0.6623],\n",
            "        [ 0.8092,  0.9975,  0.8935,  ...,  0.8981, -0.7605, -0.5045],\n",
            "        ...,\n",
            "        [ 0.7252,  0.9925,  0.9232,  ...,  0.9246, -0.7929, -0.2787],\n",
            "        [ 0.5828,  0.9898,  0.7577,  ...,  0.8055, -0.8342, -0.3374],\n",
            "        [ 0.6610,  0.9948,  0.9567,  ...,  0.8595, -0.6934, -0.5535]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5834,  1.0000,  0.9470,  ...,  0.4635,  0.5712, -0.9552],\n",
            "        [ 0.6840,  0.9891,  0.8316,  ...,  0.8702, -0.8331, -0.0378],\n",
            "        [ 0.6831,  0.9864,  0.9152,  ...,  0.8931, -0.7135, -0.3521],\n",
            "        ...,\n",
            "        [-0.6288, -0.8856, -0.9551,  ..., -0.9451, -0.0041,  0.6296],\n",
            "        [ 0.3211,  0.9878,  0.7966,  ...,  0.9181, -0.8226, -0.3303],\n",
            "        [-0.4793, -0.9904, -0.9625,  ..., -0.9091,  0.2200,  0.6148]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6968,  0.9951,  0.9020,  ...,  0.8588, -0.7956, -0.4366],\n",
            "        [-0.5260, -0.6300, -0.9578,  ..., -0.8541,  0.1940,  0.5844],\n",
            "        [ 0.6178,  0.9985, -0.6994,  ..., -0.8648,  0.8978, -0.7305],\n",
            "        ...,\n",
            "        [ 0.6263,  0.9999,  0.9407,  ...,  0.8495, -0.4524, -0.7357],\n",
            "        [ 0.6098,  0.9986,  0.9333,  ...,  0.9151, -0.6700, -0.5310],\n",
            "        [ 0.5341,  0.9970,  0.6845,  ...,  0.8842, -0.8264, -0.3085]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.9193,  1.0000,  0.9307,  ...,  0.7494, -0.5037, -0.8590],\n",
            "        [ 0.1174,  1.0000, -0.3280,  ..., -0.2778,  0.2786, -0.6637],\n",
            "        [-0.3424, -0.6696, -0.9049,  ..., -0.8829,  0.4903,  0.3563],\n",
            "        ...,\n",
            "        [ 0.7750,  0.9832,  0.8203,  ...,  0.9083, -0.8491, -0.0184],\n",
            "        [ 0.6010,  0.9496,  0.8541,  ...,  0.7133, -0.9053, -0.1807],\n",
            "        [ 0.7360,  0.9998,  0.9105,  ...,  0.8147, -0.8646, -0.3682]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7616,  0.9985,  0.8361,  ...,  0.7972, -0.8384, -0.4216],\n",
            "        [ 0.5194,  0.9939,  0.8438,  ...,  0.8442, -0.8306, -0.3600],\n",
            "        [ 0.6100,  0.9998,  0.8744,  ...,  0.8510, -0.8408, -0.4416],\n",
            "        ...,\n",
            "        [-0.0551,  0.9864, -0.8740,  ..., -0.8352,  0.3417,  0.0593],\n",
            "        [-0.5094, -0.9582, -0.9412,  ..., -0.9195,  0.1028,  0.7436],\n",
            "        [-0.4808, -0.9679, -0.9337,  ..., -0.7911,  0.4585,  0.5711]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6671,  0.9999,  0.8650,  ...,  0.8441, -0.6940, -0.3275],\n",
            "        [ 0.6236,  1.0000,  0.9067,  ...,  0.7820, -0.7082, -0.8042],\n",
            "        [ 0.1955,  0.9954,  0.7838,  ...,  0.8542, -0.8822, -0.1558],\n",
            "        ...,\n",
            "        [-0.6130, -0.9736, -0.9600,  ..., -0.9273,  0.0185,  0.6700],\n",
            "        [ 0.8406,  1.0000,  0.6733,  ...,  0.8248, -0.5394, -0.7684],\n",
            "        [-0.6544, -0.7751, -0.9507,  ..., -0.9449,  0.2945,  0.3538]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6837,  0.9999,  0.9432,  ...,  0.8966, -0.7487, -0.5397],\n",
            "        [ 0.7988,  1.0000,  0.8959,  ...,  0.1387,  0.0953, -0.8336],\n",
            "        [-0.6179, -0.6095, -0.9225,  ..., -0.8610,  0.3328,  0.4301],\n",
            "        ...,\n",
            "        [ 0.7519,  0.9647,  0.8136,  ...,  0.8902, -0.8481,  0.0066],\n",
            "        [-0.6132,  0.7790, -0.9509,  ..., -0.8415,  0.3390,  0.4752],\n",
            "        [ 0.5904,  0.9902,  0.8365,  ...,  0.8604, -0.7856, -0.2896]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5480, -0.6853, -0.9060,  ..., -0.8415,  0.3272,  0.6194],\n",
            "        [ 0.7703,  0.9388,  0.8773,  ...,  0.8018, -0.8108, -0.3724],\n",
            "        [ 0.7567,  0.9999,  0.8916,  ...,  0.7859, -0.6393, -0.5846],\n",
            "        ...,\n",
            "        [ 0.5235,  0.9968,  0.7474,  ...,  0.8152, -0.8084, -0.1698],\n",
            "        [-0.7822, -0.7777, -0.8228,  ..., -0.9318, -0.0408,  0.2284],\n",
            "        [-0.6030,  0.4279, -0.9247,  ..., -0.8424,  0.4097,  0.6313]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6607,  0.9835,  0.8258,  ...,  0.8743, -0.8323, -0.0095],\n",
            "        [ 0.6448,  0.9994,  0.8290,  ...,  0.9158, -0.8416, -0.5922],\n",
            "        [-0.5735, -0.9778, -0.9367,  ..., -0.9255,  0.0494,  0.6484],\n",
            "        ...,\n",
            "        [-0.6679,  0.8325, -0.9182,  ..., -0.9026,  0.5666,  0.2904],\n",
            "        [ 0.5091,  0.9996,  0.7902,  ...,  0.8096, -0.8977, -0.5261],\n",
            "        [-0.1830, -0.9586, -0.8654,  ..., -0.8501,  0.1624,  0.5047]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6362, -0.8710, -0.9591,  ..., -0.9051,  0.2210,  0.5694],\n",
            "        [ 0.6180,  0.9932,  0.9172,  ...,  0.8992, -0.8734, -0.4270],\n",
            "        [-0.1613,  0.9611, -0.9408,  ..., -0.8455,  0.6440,  0.2984],\n",
            "        ...,\n",
            "        [ 0.7162,  0.9989,  0.8913,  ...,  0.8903, -0.8133, -0.5436],\n",
            "        [ 0.7267,  0.9994,  0.8485,  ...,  0.8548, -0.8230, -0.5841],\n",
            "        [ 0.6979,  0.9992,  0.9155,  ...,  0.9276, -0.6412, -0.6053]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6214, -0.4867, -0.9126,  ..., -0.7971,  0.2095,  0.7335],\n",
            "        [ 0.5808,  0.9946,  0.7944,  ...,  0.9000, -0.8525, -0.3696],\n",
            "        [ 0.6536,  0.9961,  0.7503,  ...,  0.7434, -0.8384, -0.1699],\n",
            "        ...,\n",
            "        [ 0.4347,  0.9907,  0.8626,  ...,  0.8590, -0.8250, -0.5298],\n",
            "        [-0.6341, -0.9646, -0.9055,  ..., -0.7992, -0.0189,  0.6472],\n",
            "        [-0.5683,  0.0808, -0.8578,  ..., -0.8954,  0.4688,  0.1731]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6716, -0.9655, -0.8903,  ..., -0.8604,  0.2525,  0.5270],\n",
            "        [ 0.8115,  1.0000,  0.4415,  ...,  0.5898, -0.7563, -0.8244],\n",
            "        [ 0.4827,  0.9897,  0.8966,  ...,  0.8353, -0.7732, -0.5413],\n",
            "        ...,\n",
            "        [ 0.3627,  0.9982,  0.7070,  ...,  0.8500, -0.8708, -0.1854],\n",
            "        [ 0.7456,  0.9848,  0.8570,  ...,  0.8529, -0.8636, -0.3726],\n",
            "        [ 0.7053,  0.9950,  0.9290,  ...,  0.8944, -0.6231, -0.5672]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.8210,  0.7893, -0.7365,  ..., -0.7302,  0.1280,  0.8157],\n",
            "        [ 0.4531,  0.9791,  0.5114,  ...,  0.7079, -0.7227,  0.2355],\n",
            "        [-0.7394, -0.7900, -0.9244,  ..., -0.8797,  0.2917,  0.5765],\n",
            "        ...,\n",
            "        [-0.6259,  0.8955, -0.9262,  ..., -0.9274,  0.1521,  0.3643],\n",
            "        [-0.5056, -0.9418, -0.9567,  ..., -0.9161,  0.1397,  0.6162],\n",
            "        [-0.5109,  0.8449, -0.9174,  ..., -0.8393,  0.0881,  0.4602]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7754,  0.9799,  0.7247,  ...,  0.9245, -0.7555, -0.5140],\n",
            "        [-0.4518, -0.9989, -0.9555,  ..., -0.8982,  0.4237,  0.7421],\n",
            "        [-0.7765, -0.8063, -0.9591,  ..., -0.9009,  0.1345,  0.7365],\n",
            "        ...,\n",
            "        [-0.8013, -0.8061, -0.9625,  ..., -0.9108,  0.3396,  0.7438],\n",
            "        [ 0.3449,  0.9911,  0.8127,  ...,  0.8675, -0.8794,  0.2243],\n",
            "        [ 0.6800,  0.9996,  0.9081,  ...,  0.8938, -0.7551, -0.2634]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7600,  0.9790,  0.8462,  ...,  0.8958, -0.8126, -0.2999],\n",
            "        [ 0.6388,  0.9897,  0.6841,  ...,  0.8716, -0.8747, -0.2549],\n",
            "        [-0.4728,  0.6288, -0.9343,  ..., -0.6388,  0.4857,  0.5684],\n",
            "        ...,\n",
            "        [ 0.6459,  0.9542,  0.8469,  ...,  0.8823, -0.7704, -0.2071],\n",
            "        [-0.4564, -0.7713, -0.9032,  ..., -0.9038,  0.2247,  0.6409],\n",
            "        [-0.2786, -0.8236, -0.9496,  ..., -0.8379,  0.4204,  0.5209]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4730, -0.9016, -0.9365,  ..., -0.9232,  0.2907,  0.6251],\n",
            "        [ 0.7537,  0.9970,  0.8628,  ...,  0.9081, -0.8155, -0.2507],\n",
            "        [ 0.4604,  0.9855,  0.6830,  ...,  0.7981, -0.9009,  0.0567],\n",
            "        ...,\n",
            "        [ 0.4823,  0.9994,  0.8295,  ...,  0.9124, -0.9011, -0.4339],\n",
            "        [ 0.7209,  0.9992,  0.8505,  ...,  0.9101, -0.7819, -0.5455],\n",
            "        [-0.6482, -0.9348, -0.9531,  ..., -0.9299,  0.1344,  0.5160]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4575,  0.9955,  0.8501,  ...,  0.7485, -0.7727, -0.3313],\n",
            "        [ 0.7462,  0.9994,  0.8895,  ...,  0.8683, -0.4030, -0.7317],\n",
            "        [-0.6567, -0.2588, -0.9301,  ..., -0.8368,  0.2840,  0.7340],\n",
            "        ...,\n",
            "        [-0.5929, -0.8457, -0.9433,  ..., -0.8821,  0.3441,  0.6833],\n",
            "        [-0.7889, -0.9442, -0.9152,  ..., -0.8735,  0.1968,  0.7166],\n",
            "        [-0.5510, -0.9972, -0.9466,  ..., -0.9138,  0.3984,  0.5857]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.8165,  0.9991,  0.9443,  ...,  0.8037, -0.6244, -0.5777],\n",
            "        [-0.4617,  0.2716, -0.9259,  ..., -0.9428,  0.3013,  0.1369],\n",
            "        [ 0.1614,  0.8664,  0.7857,  ...,  0.8627, -0.8211,  0.0373],\n",
            "        ...,\n",
            "        [ 0.6581,  0.9745,  0.7586,  ...,  0.7452, -0.8276, -0.4447],\n",
            "        [-0.6898, -0.9804, -0.9236,  ..., -0.8970,  0.3969,  0.7460],\n",
            "        [ 0.5085,  0.9901,  0.6495,  ...,  0.8756, -0.7648, -0.2679]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 4.1612e-01,  9.9069e-01,  8.2587e-01,  ...,  8.7055e-01,\n",
            "         -8.6552e-01, -1.0144e-04],\n",
            "        [ 6.9561e-01,  9.9788e-01,  7.4154e-01,  ...,  9.1221e-01,\n",
            "         -7.7192e-01, -3.6059e-01],\n",
            "        [ 6.2651e-01,  9.9767e-01,  8.8371e-01,  ...,  8.6148e-01,\n",
            "         -7.8981e-01, -2.8959e-01],\n",
            "        ...,\n",
            "        [ 4.5235e-01,  9.9920e-01,  7.8865e-01,  ...,  7.3101e-01,\n",
            "         -7.6843e-01, -5.4078e-01],\n",
            "        [ 5.9588e-01,  9.9801e-01,  8.7666e-01,  ...,  8.8159e-01,\n",
            "         -7.9292e-01, -1.2420e-01],\n",
            "        [-5.3820e-01, -2.2919e-01, -9.5537e-01,  ..., -7.5603e-01,\n",
            "          3.2823e-01,  4.8032e-01]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5942,  0.9997, -0.5358,  ..., -0.6763,  0.1587, -0.5280],\n",
            "        [ 0.6179,  0.9998,  0.9264,  ...,  0.8482, -0.7233, -0.5549],\n",
            "        [-0.2991, -0.7599, -0.9196,  ..., -0.8823,  0.2512,  0.6867],\n",
            "        ...,\n",
            "        [-0.5967,  0.9170, -0.8618,  ..., -0.9047,  0.2521,  0.4657],\n",
            "        [ 0.5022,  0.9951,  0.8444,  ...,  0.8076, -0.8300, -0.3074],\n",
            "        [ 0.4042,  1.0000,  0.9400,  ...,  0.1707,  0.1988, -0.9869]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1995,  0.7800, -0.8214,  ..., -0.7731,  0.6628,  0.0512],\n",
            "        [-0.4823,  0.1382, -0.9353,  ..., -0.9012,  0.3170,  0.3873],\n",
            "        [ 0.6044,  0.9580,  0.8460,  ...,  0.9015, -0.8685, -0.0897],\n",
            "        ...,\n",
            "        [-0.5298, -0.9194, -0.9526,  ..., -0.9215,  0.2787,  0.4907],\n",
            "        [ 0.5349,  0.9998,  0.7955,  ...,  0.7592, -0.8291, -0.0182],\n",
            "        [-0.3371, -0.2229, -0.9200,  ..., -0.9096,  0.3033,  0.3307]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1131,  1.0000,  0.8942,  ...,  0.6798, -0.2047, -0.7404],\n",
            "        [-0.4253, -0.3857, -0.9084,  ..., -0.8996,  0.0869,  0.4050],\n",
            "        [ 0.5746,  0.9987,  0.8192,  ...,  0.8584, -0.7589, -0.3290],\n",
            "        ...,\n",
            "        [ 0.5768,  0.9991,  0.8728,  ...,  0.8792, -0.8462, -0.4494],\n",
            "        [ 0.7338,  0.9999,  0.9396,  ...,  0.7328, -0.6018, -0.8508],\n",
            "        [ 0.6379,  1.0000,  0.9534,  ...,  0.8321, -0.7798, -0.8389]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.8341,  0.9982,  0.7142,  ...,  0.8421, -0.6948, -0.6047],\n",
            "        [-0.7895, -0.9861, -0.9585,  ..., -0.9197,  0.2947,  0.6642],\n",
            "        [-0.6278, -0.6840, -0.9460,  ..., -0.9270,  0.1857,  0.5903],\n",
            "        ...,\n",
            "        [-0.1353,  0.9608, -0.8477,  ..., -0.9126,  0.5378,  0.4216],\n",
            "        [-0.3525, -0.9619, -0.9264,  ..., -0.8260,  0.3165,  0.6946],\n",
            "        [-0.6228, -0.7938, -0.9311,  ..., -0.9347,  0.4607,  0.1888]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0989,  0.9973, -0.7135,  ..., -0.8711,  0.4057, -0.6654],\n",
            "        [-0.7125, -0.9856, -0.9450,  ..., -0.8966,  0.1685,  0.7570],\n",
            "        [-0.2812,  0.9891, -0.8256,  ..., -0.9150,  0.1805,  0.0813],\n",
            "        ...,\n",
            "        [ 0.8019,  1.0000,  0.6374,  ...,  0.7744, -0.7817, -0.0671],\n",
            "        [ 0.6284,  0.9928,  0.8500,  ...,  0.8343, -0.8795, -0.3146],\n",
            "        [-0.4447, -0.9510, -0.9337,  ..., -0.8609, -0.1188,  0.7088]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5628,  0.9999,  0.8590,  ...,  0.9035, -0.7756, -0.4934],\n",
            "        [-0.6721, -0.9763, -0.9623,  ..., -0.9207,  0.3262,  0.7905],\n",
            "        [ 0.3001,  0.9776,  0.7994,  ...,  0.7609, -0.8908, -0.5222],\n",
            "        ...,\n",
            "        [ 0.5520,  0.9937,  0.9296,  ...,  0.8168, -0.7359, -0.4612],\n",
            "        [-0.4597, -0.9726, -0.8835,  ..., -0.8169,  0.3173,  0.3959],\n",
            "        [ 0.5377,  0.9421,  0.8270,  ...,  0.8880, -0.7587, -0.2836]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7350,  0.9999,  0.9244,  ...,  0.8644, -0.4673, -0.5996],\n",
            "        [-0.5789,  0.4639, -0.9124,  ..., -0.6995,  0.4003,  0.2518],\n",
            "        [ 0.6864,  0.8827,  0.7953,  ...,  0.7937, -0.8555, -0.2128],\n",
            "        ...,\n",
            "        [ 0.6276,  0.9991,  0.9058,  ...,  0.8549, -0.7030, -0.4909],\n",
            "        [-0.5786, -0.6890, -0.9355,  ..., -0.8362,  0.3092,  0.6439],\n",
            "        [-0.1758, -0.8987, -0.8801,  ..., -0.8121,  0.3766,  0.2264]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7089,  0.9698,  0.8634,  ...,  0.9097, -0.7066, -0.0366],\n",
            "        [ 0.6905,  0.9912,  0.8222,  ...,  0.9083, -0.8768, -0.3403],\n",
            "        [-0.5052, -0.8596, -0.9594,  ..., -0.9070,  0.3187,  0.4158],\n",
            "        ...,\n",
            "        [-0.5712, -0.6199, -0.9573,  ..., -0.8436,  0.1125,  0.6908],\n",
            "        [-0.6145, -0.9375, -0.9387,  ..., -0.8730,  0.1229,  0.4493],\n",
            "        [ 0.8005,  1.0000,  0.8685,  ...,  0.7973, -0.6371, -0.6173]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3990,  0.9967,  0.8906,  ...,  0.8814, -0.7559, -0.1065],\n",
            "        [-0.4082, -0.9878, -0.9267,  ..., -0.8704,  0.2334,  0.5921],\n",
            "        [-0.6500, -0.9970, -0.9242,  ..., -0.9207,  0.0914,  0.7419],\n",
            "        ...,\n",
            "        [ 0.6179,  0.9936,  0.7413,  ...,  0.8978, -0.8253, -0.5237],\n",
            "        [ 0.6428,  0.9999,  0.8664,  ...,  0.7236, -0.6553, -0.6341],\n",
            "        [ 0.6837,  0.9957,  0.8930,  ...,  0.8634, -0.8025, -0.4980]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5044,  0.9609,  0.7763,  ...,  0.8840, -0.8709, -0.2001],\n",
            "        [ 0.4124,  0.9995,  0.8377,  ...,  0.8627, -0.7960, -0.4915],\n",
            "        [-0.6504, -0.3249, -0.8764,  ..., -0.8059,  0.5688,  0.2362],\n",
            "        ...,\n",
            "        [-0.4200,  0.9064, -0.9244,  ..., -0.8395,  0.2432,  0.1902],\n",
            "        [ 0.7057,  0.9991,  0.8740,  ...,  0.8728, -0.7769, -0.2055],\n",
            "        [ 0.5797,  1.0000,  0.9391,  ...,  0.8914, -0.5692, -0.8029]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4976,  0.9636, -0.9045,  ..., -0.8710,  0.4585, -0.2857],\n",
            "        [ 0.8622,  1.0000,  0.8589,  ...,  0.7383, -0.4195, -0.8253],\n",
            "        [-0.6827, -0.9878, -0.9476,  ..., -0.9023,  0.2689,  0.6361],\n",
            "        ...,\n",
            "        [ 0.6863,  0.9989,  0.8719,  ...,  0.8819, -0.5679, -0.4176],\n",
            "        [ 0.7604,  0.9997,  0.7289,  ...,  0.8595, -0.7975, -0.5329],\n",
            "        [ 0.6215,  0.9884,  0.7145,  ...,  0.8650, -0.8350, -0.1668]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2538,  0.1593, -0.8255,  ..., -0.9232,  0.2890, -0.1047],\n",
            "        [ 0.5784,  0.9955,  0.7264,  ...,  0.9052, -0.8710, -0.0776],\n",
            "        [-0.5200, -0.9978, -0.9577,  ..., -0.8258,  0.1002,  0.5861],\n",
            "        ...,\n",
            "        [ 0.7691,  0.9997,  0.8944,  ...,  0.8530, -0.5684, -0.6497],\n",
            "        [ 0.5625,  0.9953,  0.6737,  ...,  0.7404, -0.8184, -0.3538],\n",
            "        [-0.7800,  0.5143, -0.9169,  ..., -0.8711, -0.1927,  0.3841]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5748,  0.9859,  0.8901,  ...,  0.8838, -0.8648, -0.0749],\n",
            "        [ 0.2058,  1.0000,  0.8874,  ...,  0.3594, -0.3563, -0.9276],\n",
            "        [-0.5684,  0.3988, -0.9272,  ..., -0.8746,  0.5366,  0.3679],\n",
            "        ...,\n",
            "        [-0.7788, -0.7154, -0.9378,  ..., -0.8782,  0.4813,  0.6233],\n",
            "        [ 0.5715,  0.9142,  0.7496,  ...,  0.8226, -0.8958,  0.2336],\n",
            "        [-0.5232,  0.8333, -0.9310,  ..., -0.8668,  0.6177,  0.1745]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7535,  0.9923,  0.8321,  ...,  0.9277, -0.8429, -0.5714],\n",
            "        [ 0.6601,  0.9926,  0.7731,  ...,  0.8638, -0.8614,  0.1013],\n",
            "        [ 0.5555,  0.9976,  0.7939,  ...,  0.8518, -0.8557, -0.5547],\n",
            "        ...,\n",
            "        [-0.4288, -0.0521, -0.9050,  ..., -0.8044,  0.6734,  0.1415],\n",
            "        [-0.2855,  0.5671, -0.8901,  ..., -0.9243,  0.2343,  0.3618],\n",
            "        [ 0.5112,  0.9902,  0.7108,  ...,  0.8308, -0.8344, -0.2610]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1230,  0.9740, -0.8789,  ..., -0.8215,  0.6708, -0.2732],\n",
            "        [-0.6655,  0.9765, -0.8729,  ..., -0.9185,  0.2498,  0.6637],\n",
            "        [-0.4389,  0.7421, -0.8532,  ..., -0.9153,  0.6586, -0.0038],\n",
            "        ...,\n",
            "        [-0.4093, -0.9769, -0.9356,  ..., -0.8873,  0.4140,  0.5384],\n",
            "        [ 0.4074,  0.9851,  0.8914,  ...,  0.8234, -0.9034, -0.1885],\n",
            "        [-0.6508, -0.9099, -0.9188,  ..., -0.7389,  0.1249,  0.7917]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5068,  0.9975,  0.8097,  ...,  0.8403, -0.8191, -0.1684],\n",
            "        [ 0.5673,  0.9509,  0.6574,  ...,  0.8812, -0.8906, -0.1683],\n",
            "        [-0.4550,  0.9009, -0.9598,  ..., -0.9103,  0.3037,  0.6350],\n",
            "        ...,\n",
            "        [ 0.6933,  1.0000,  0.8062,  ...,  0.7080, -0.7033, -0.8031],\n",
            "        [ 0.6961,  0.9983,  0.8595,  ...,  0.9285, -0.8353, -0.0827],\n",
            "        [ 0.6159,  0.9954,  0.8636,  ...,  0.8949, -0.7343, -0.1095]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7510,  0.9965,  0.8039,  ...,  0.8634, -0.8089, -0.2892],\n",
            "        [ 0.4008,  0.9991, -0.6192,  ..., -0.8790,  0.5130, -0.6616],\n",
            "        [ 0.6718,  0.9881,  0.7332,  ...,  0.8653, -0.7533, -0.2115],\n",
            "        ...,\n",
            "        [ 0.5202,  0.9999,  0.9006,  ...,  0.8243, -0.5788, -0.7077],\n",
            "        [ 0.7937,  1.0000,  0.6630,  ...,  0.4993, -0.4658, -0.7425],\n",
            "        [-0.4236,  0.9086, -0.7843,  ..., -0.8283,  0.5239,  0.3505]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5337, -0.9072, -0.9371,  ..., -0.8818,  0.1356,  0.7848],\n",
            "        [ 0.4284,  0.8976,  0.8477,  ...,  0.7825, -0.7587,  0.1500],\n",
            "        [ 0.7533,  0.9995,  0.8138,  ...,  0.8442, -0.8200, -0.6004],\n",
            "        ...,\n",
            "        [ 0.4643,  0.9034,  0.8834,  ...,  0.8660, -0.8482, -0.2063],\n",
            "        [ 0.5975,  1.0000,  0.9478,  ...,  0.1873,  0.1723, -0.8490],\n",
            "        [ 0.5010,  0.9901,  0.8628,  ...,  0.8809, -0.8908, -0.4113]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0485, -0.9274, -0.5707,  ..., -0.5571,  0.5236, -0.2968],\n",
            "        [ 0.1058,  0.9931, -0.8449,  ..., -0.8900,  0.6046,  0.1858],\n",
            "        [-0.5253, -0.9889, -0.9355,  ..., -0.9153,  0.3311,  0.6754],\n",
            "        ...,\n",
            "        [-0.0884,  0.9929, -0.4139,  ..., -0.6193,  0.7874, -0.2155],\n",
            "        [-0.5680,  0.9657, -0.9157,  ..., -0.8757,  0.4300,  0.7332],\n",
            "        [-0.1674,  0.0536, -0.9040,  ..., -0.8692,  0.2927,  0.7183]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6173,  0.9905,  0.8715,  ...,  0.8364, -0.7596, -0.3661],\n",
            "        [-0.3607, -0.1115, -0.9458,  ..., -0.9102,  0.4460,  0.3751],\n",
            "        [-0.5099, -0.0591, -0.9043,  ..., -0.8799,  0.7278,  0.2485],\n",
            "        ...,\n",
            "        [ 0.1751,  1.0000,  0.4411,  ..., -0.5421,  0.3936, -0.8575],\n",
            "        [-0.7340, -0.9526, -0.9364,  ..., -0.8360,  0.5125,  0.4257],\n",
            "        [ 0.8708,  0.9999,  0.9421,  ...,  0.8897, -0.5934, -0.8129]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6101, -0.9717, -0.9256,  ..., -0.8962,  0.3122,  0.3018],\n",
            "        [ 0.5610,  0.9973,  0.8320,  ...,  0.8167, -0.8359, -0.5129],\n",
            "        [ 0.6671,  0.9665,  0.7933,  ...,  0.7898, -0.7518,  0.1517],\n",
            "        ...,\n",
            "        [-0.4979,  0.2668, -0.9068,  ..., -0.8562,  0.0379,  0.4686],\n",
            "        [-0.4120, -0.9321, -0.9359,  ..., -0.8986,  0.1122,  0.4639],\n",
            "        [-0.5296, -0.2352, -0.9185,  ..., -0.8178,  0.0164,  0.5798]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6639,  0.9999,  0.9122,  ...,  0.8460, -0.5052, -0.5813],\n",
            "        [ 0.5480,  0.9750,  0.8764,  ...,  0.8322, -0.8142, -0.4909],\n",
            "        [ 0.6977,  0.9996,  0.8859,  ...,  0.9197, -0.7566, -0.2445],\n",
            "        ...,\n",
            "        [-0.7007,  0.9486, -0.8678,  ..., -0.7535,  0.2700,  0.7418],\n",
            "        [ 0.6002,  0.9965,  0.8537,  ...,  0.8951, -0.7561, -0.2847],\n",
            "        [ 0.4822,  0.9065,  0.7210,  ...,  0.9152, -0.8235, -0.2972]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1739,  0.7322, -0.9472,  ..., -0.8362,  0.6175,  0.2123],\n",
            "        [ 0.6112,  0.9834,  0.8058,  ...,  0.8885, -0.8158, -0.1659],\n",
            "        [-0.6703,  0.9606, -0.7713,  ..., -0.8203,  0.3537,  0.2038],\n",
            "        ...,\n",
            "        [ 0.5214,  0.9766,  0.8539,  ...,  0.6994, -0.8868, -0.2385],\n",
            "        [ 0.8063,  0.9922,  0.8426,  ...,  0.8499, -0.8561, -0.5631],\n",
            "        [-0.6065, -0.7965, -0.9141,  ..., -0.8462,  0.4083,  0.6775]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5803,  0.9955,  0.8964,  ...,  0.8897, -0.7886, -0.2063],\n",
            "        [ 0.7788,  0.9947,  0.8790,  ...,  0.8555, -0.8263, -0.3680],\n",
            "        [-0.6647, -0.3792, -0.9052,  ..., -0.8568,  0.4433,  0.6567],\n",
            "        ...,\n",
            "        [-0.5538,  0.4663, -0.8959,  ..., -0.8277,  0.2856,  0.5488],\n",
            "        [ 0.5237,  0.9998,  0.9132,  ...,  0.7849, -0.6931, -0.7881],\n",
            "        [-0.7905, -0.5568, -0.9390,  ..., -0.8861,  0.1794,  0.7194]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.7747, -0.7737, -0.9309,  ..., -0.9265,  0.0270,  0.5337],\n",
            "        [-0.5744, -0.9248, -0.9387,  ..., -0.9159,  0.2995,  0.6172],\n",
            "        [-0.6829,  0.6979, -0.9272,  ..., -0.9407,  0.2738,  0.7264],\n",
            "        ...,\n",
            "        [ 0.7135,  0.9876,  0.9179,  ...,  0.8763, -0.8410, -0.3078],\n",
            "        [ 0.5042,  0.9969,  0.8125,  ...,  0.8743, -0.8054, -0.3304],\n",
            "        [ 0.8657,  0.9999,  0.9556,  ...,  0.8302, -0.4291, -0.8223]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-6.1757e-01,  4.9727e-05, -9.6236e-01,  ..., -8.8404e-01,\n",
            "          2.1352e-01,  5.0119e-01],\n",
            "        [-6.2679e-01,  4.3269e-01, -9.3601e-01,  ..., -8.3214e-01,\n",
            "          2.5699e-01,  4.1265e-01],\n",
            "        [ 2.7540e-01,  1.0000e+00,  9.3150e-01,  ..., -1.8288e-01,\n",
            "          1.5877e-01, -9.5885e-01],\n",
            "        ...,\n",
            "        [ 5.8264e-01,  9.6923e-01,  8.5797e-01,  ...,  8.5607e-01,\n",
            "         -8.4724e-01,  6.9535e-02],\n",
            "        [-4.0807e-01, -4.9222e-01, -9.2524e-01,  ..., -8.5542e-01,\n",
            "          1.2453e-01,  4.8311e-01],\n",
            "        [ 5.6761e-01,  9.8835e-01,  7.4529e-01,  ...,  8.7091e-01,\n",
            "         -7.5142e-01, -3.4457e-02]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6774,  0.9827,  0.8303,  ...,  0.8859, -0.8785, -0.3475],\n",
            "        [ 0.6184,  0.9969,  0.8803,  ...,  0.9142, -0.8142,  0.0035],\n",
            "        [ 0.6549,  0.9927,  0.8299,  ...,  0.8915, -0.7875, -0.2563],\n",
            "        ...,\n",
            "        [-0.6672, -0.4212, -0.9217,  ..., -0.8741,  0.1122,  0.5288],\n",
            "        [ 0.5069,  0.9985,  0.8480,  ...,  0.7495, -0.7401, -0.2360],\n",
            "        [-0.4212, -0.6519, -0.9440,  ..., -0.9098,  0.0161,  0.5805]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7148,  1.0000,  0.9490,  ...,  0.8258, -0.4054, -0.7490],\n",
            "        [ 0.6464,  0.9939,  0.7944,  ...,  0.8758, -0.8449, -0.3950],\n",
            "        [ 0.6794,  0.9992,  0.8907,  ...,  0.7985, -0.8075, -0.3787],\n",
            "        ...,\n",
            "        [ 0.5308,  0.8951,  0.8183,  ...,  0.8843, -0.8740, -0.1239],\n",
            "        [-0.5483, -0.9064, -0.9298,  ..., -0.8714,  0.0651,  0.4433],\n",
            "        [ 0.6850,  0.9997,  0.9327,  ...,  0.8116, -0.7603, -0.4459]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3977,  0.6679, -0.9282,  ..., -0.8794,  0.3802,  0.2559],\n",
            "        [-0.5705,  0.2287, -0.9089,  ..., -0.8086,  0.2566,  0.5253],\n",
            "        [-0.7042, -0.9721, -0.9069,  ..., -0.8531,  0.3041,  0.8079],\n",
            "        ...,\n",
            "        [ 0.6905,  0.9983,  0.9285,  ...,  0.8909, -0.7737, -0.5244],\n",
            "        [ 0.4487,  0.9128,  0.6943,  ...,  0.7968, -0.8801,  0.1509],\n",
            "        [ 0.7126,  0.9932,  0.8960,  ...,  0.8557, -0.8532, -0.2825]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5698, -0.9916, -0.9454,  ..., -0.7838,  0.0663,  0.7050],\n",
            "        [ 0.7235,  1.0000,  0.8790,  ...,  0.8209, -0.7694, -0.5626],\n",
            "        [-0.7958, -0.7009, -0.9571,  ..., -0.8932, -0.0760,  0.5590],\n",
            "        ...,\n",
            "        [-0.0884,  0.9997, -0.6544,  ..., -0.9132,  0.6482, -0.6280],\n",
            "        [-0.4053, -0.4786, -0.8651,  ..., -0.8554,  0.4385,  0.5466],\n",
            "        [ 0.6746,  0.9969,  0.7477,  ...,  0.9092, -0.7793, -0.0530]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6969,  0.9997,  0.8924,  ...,  0.7852, -0.4803, -0.7044],\n",
            "        [ 0.7772,  0.9916,  0.8777,  ...,  0.9021, -0.8442, -0.1281],\n",
            "        [ 0.6586,  0.9991,  0.9122,  ...,  0.8418, -0.6994, -0.3988],\n",
            "        ...,\n",
            "        [-0.6605, -0.8699, -0.9343,  ..., -0.9055,  0.5243,  0.6834],\n",
            "        [ 0.6374,  0.9782,  0.8418,  ...,  0.9145, -0.7932, -0.2943],\n",
            "        [ 0.7182,  0.9497,  0.8647,  ...,  0.8853, -0.7709, -0.0444]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4572, -0.5764, -0.9500,  ..., -0.8497,  0.0674,  0.4433],\n",
            "        [-0.4704, -0.8419, -0.9382,  ..., -0.9117,  0.3084,  0.5691],\n",
            "        [ 0.2116,  0.9914, -0.6577,  ..., -0.9067,  0.7518, -0.8288],\n",
            "        ...,\n",
            "        [-0.6164,  0.9562, -0.8249,  ..., -0.8343,  0.3406,  0.3556],\n",
            "        [ 0.5853,  0.9935,  0.8453,  ...,  0.9219, -0.8200, -0.1725],\n",
            "        [-0.5559, -0.9946, -0.9306,  ..., -0.8768,  0.4394,  0.6534]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5269,  0.9999, -0.4801,  ..., -0.8777,  0.6472, -0.6312],\n",
            "        [ 0.2688,  0.9884,  0.8738,  ...,  0.8689, -0.8813, -0.0668],\n",
            "        [-0.6152, -0.9819, -0.9455,  ..., -0.7704,  0.4150,  0.5464],\n",
            "        ...,\n",
            "        [ 0.8046,  0.9966,  0.9160,  ...,  0.8259, -0.7596, -0.4085],\n",
            "        [-0.6054, -0.5900, -0.9098,  ..., -0.6903,  0.4429,  0.5808],\n",
            "        [ 0.7631,  0.9942,  0.8949,  ...,  0.8653, -0.6834, -0.5495]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6232,  0.9994,  0.7034,  ...,  0.0869,  0.2126, -0.8586],\n",
            "        [-0.2610,  0.9998,  0.4660,  ..., -0.5673,  0.6258, -0.6233],\n",
            "        [-0.4963, -0.8978, -0.9577,  ..., -0.8856,  0.2893,  0.4329],\n",
            "        ...,\n",
            "        [ 0.6286,  0.9969,  0.8059,  ...,  0.9155, -0.7356, -0.6014],\n",
            "        [-0.4791,  0.4220, -0.9197,  ..., -0.8958,  0.1064,  0.4586],\n",
            "        [ 0.6415,  0.9988,  0.8459,  ...,  0.9355, -0.7974, -0.3635]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7790,  0.9998,  0.7798,  ...,  0.7671, -0.7375, -0.2060],\n",
            "        [ 0.5891,  0.9973,  0.8427,  ...,  0.8525, -0.8433, -0.1484],\n",
            "        [-0.7411, -0.9578, -0.9536,  ..., -0.9477,  0.1683,  0.7727],\n",
            "        ...,\n",
            "        [ 0.3057,  1.0000,  0.3428,  ..., -0.0124,  0.6622, -0.7170],\n",
            "        [ 0.6381,  0.9969,  0.8885,  ...,  0.8944, -0.7514, -0.3190],\n",
            "        [-0.5303,  0.2420, -0.8837,  ..., -0.8256,  0.6263,  0.3378]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.7149,  0.4158, -0.9226,  ..., -0.8956,  0.1121,  0.7450],\n",
            "        [ 0.5651,  0.9985,  0.8596,  ...,  0.7840, -0.8612, -0.3185],\n",
            "        [ 0.1724,  1.0000,  0.7028,  ...,  0.2222,  0.5076, -0.7534],\n",
            "        ...,\n",
            "        [ 0.4664,  0.9652,  0.8295,  ...,  0.8220, -0.7635, -0.2797],\n",
            "        [ 0.6699,  0.9997,  0.7879,  ...,  0.8347, -0.8505, -0.5093],\n",
            "        [-0.7684,  0.4022, -0.9126,  ..., -0.9338,  0.1504,  0.7058]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6321, -0.9999, -0.9616,  ..., -0.8221,  0.2933,  0.7684],\n",
            "        [-0.4852, -0.7496, -0.9808,  ..., -0.9212,  0.4291,  0.5644],\n",
            "        [-0.6283, -0.7932, -0.9184,  ..., -0.8508,  0.2378,  0.6484],\n",
            "        ...,\n",
            "        [-0.6234,  0.9134, -0.8682,  ..., -0.8393,  0.0951, -0.0467],\n",
            "        [-0.4395,  0.2668, -0.8927,  ..., -0.9323, -0.0605,  0.5891],\n",
            "        [-0.5411,  0.7586, -0.9293,  ..., -0.9251,  0.5104,  0.5372]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5959, -0.9992, -0.9096,  ..., -0.8786,  0.1467,  0.5535],\n",
            "        [-0.4230,  0.2298, -0.9009,  ..., -0.9022,  0.2532, -0.1841],\n",
            "        [-0.6599, -0.8316, -0.9401,  ..., -0.8602,  0.2291,  0.5381],\n",
            "        ...,\n",
            "        [ 0.6300,  1.0000,  0.9347,  ...,  0.3729,  0.4472, -0.9595],\n",
            "        [-0.6096, -0.9370, -0.9261,  ..., -0.9030,  0.0224,  0.5832],\n",
            "        [ 0.5438,  1.0000,  0.9070,  ...,  0.1461,  0.3817, -0.9550]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4916, -0.3585, -0.9615,  ..., -0.8779,  0.3159,  0.5692],\n",
            "        [ 0.5879,  0.9891,  0.6746,  ...,  0.8835, -0.9087, -0.2250],\n",
            "        [-0.4242, -0.9077, -0.9405,  ..., -0.6268,  0.3640,  0.5037],\n",
            "        ...,\n",
            "        [-0.1211, -0.3516, -0.9136,  ..., -0.8868,  0.5967,  0.1984],\n",
            "        [ 0.6966,  0.9989,  0.8841,  ...,  0.8400, -0.7916, -0.4622],\n",
            "        [-0.7304,  0.2498, -0.8762,  ..., -0.8274,  0.5703,  0.5684]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5484, -0.0469, -0.8901,  ..., -0.8657,  0.4404,  0.4897],\n",
            "        [ 0.4685,  0.9457,  0.8212,  ...,  0.8306, -0.8841, -0.1733],\n",
            "        [ 0.6251,  0.9965,  0.8519,  ...,  0.8611, -0.7874, -0.3791],\n",
            "        ...,\n",
            "        [-0.5911,  0.8141, -0.9535,  ..., -0.9378,  0.6015,  0.6861],\n",
            "        [-0.5957, -0.9437, -0.9277,  ..., -0.8901,  0.1052,  0.7046],\n",
            "        [ 0.5722,  0.9976,  0.8088,  ...,  0.9407, -0.8585, -0.5550]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1917,  0.8380, -0.9041,  ..., -0.8973,  0.3827,  0.2727],\n",
            "        [-0.5202, -0.9977, -0.9098,  ..., -0.8851,  0.1088,  0.5660],\n",
            "        [ 0.7963,  1.0000,  0.2734,  ..., -0.7662,  0.6322, -0.9676],\n",
            "        ...,\n",
            "        [-0.6307,  0.9978, -0.6907,  ..., -0.6761,  0.3317,  0.1386],\n",
            "        [ 0.4158,  0.9945,  0.6837,  ...,  0.7345, -0.8297, -0.1016],\n",
            "        [ 0.7067,  0.9907,  0.8532,  ...,  0.9085, -0.7130, -0.1724]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5540,  0.8267,  0.8340,  ...,  0.8336, -0.7195,  0.1244],\n",
            "        [ 0.7683,  1.0000,  0.8935,  ...,  0.0916,  0.5998, -0.8852],\n",
            "        [-0.2800,  0.9490, -0.9341,  ..., -0.8519,  0.4289,  0.6780],\n",
            "        ...,\n",
            "        [-0.4531, -0.9794, -0.9377,  ..., -0.9038,  0.0858,  0.7744],\n",
            "        [-0.4364, -0.8589, -0.9456,  ..., -0.8632,  0.5092, -0.0394],\n",
            "        [ 0.6633,  0.9918,  0.8504,  ...,  0.9071, -0.8835, -0.5389]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5942,  0.9896,  0.8003,  ...,  0.8230, -0.7476, -0.0667],\n",
            "        [ 0.6800,  0.9981,  0.8833,  ...,  0.7314, -0.6899, -0.3968],\n",
            "        [ 0.8473,  0.9999,  0.9508,  ...,  0.9160, -0.4596, -0.7652],\n",
            "        ...,\n",
            "        [ 0.7370,  1.0000,  0.9264,  ...,  0.8107,  0.0152, -0.9619],\n",
            "        [ 0.6759,  0.9983,  0.8678,  ...,  0.9030, -0.7902, -0.2529],\n",
            "        [-0.3671,  0.9826, -0.6657,  ..., -0.7919,  0.0881,  0.5346]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3558, -0.4747, -0.9084,  ..., -0.7810,  0.3924,  0.7139],\n",
            "        [ 0.7304,  1.0000,  0.9449,  ...,  0.6848, -0.1536, -0.8676],\n",
            "        [ 0.7001,  0.9996,  0.7997,  ...,  0.5299, -0.6212, -0.7675],\n",
            "        ...,\n",
            "        [ 0.5439,  0.9719,  0.8407,  ...,  0.8764, -0.8560, -0.2965],\n",
            "        [ 0.6190,  0.9946,  0.8662,  ...,  0.8923, -0.8682, -0.3941],\n",
            "        [-0.5914, -0.5228, -0.9463,  ..., -0.8567,  0.5777,  0.6279]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1867,  1.0000,  0.7355,  ...,  0.2588,  0.0920, -0.7448],\n",
            "        [ 0.6220,  0.9997,  0.7609,  ...,  0.6648, -0.6285, -0.3948],\n",
            "        [-0.6058, -0.8232, -0.9446,  ..., -0.8413,  0.3599,  0.5684],\n",
            "        ...,\n",
            "        [-0.2884,  0.9624, -0.9404,  ..., -0.8525,  0.3077,  0.5110],\n",
            "        [ 0.5125,  0.9620,  0.9164,  ...,  0.9026, -0.7882, -0.1833],\n",
            "        [ 0.7411,  0.9994,  0.9215,  ...,  0.6748, -0.8014, -0.5534]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1932,  0.9991, -0.6957,  ..., -0.9263,  0.6846, -0.4280],\n",
            "        [-0.0446,  0.9929, -0.9344,  ..., -0.8831,  0.4862,  0.1808],\n",
            "        [ 0.4751,  0.9999,  0.8789,  ...,  0.7324, -0.5578, -0.6382],\n",
            "        ...,\n",
            "        [ 0.5809,  0.9998,  0.8535,  ...,  0.8414, -0.7847, -0.3776],\n",
            "        [-0.6108, -0.9809, -0.9418,  ..., -0.9374,  0.1307,  0.6397],\n",
            "        [-0.2380, -0.9844, -0.9283,  ..., -0.8805,  0.3019,  0.2271]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.1454, -0.9931, -0.9355,  ..., -0.8931,  0.3018,  0.4506],\n",
            "        [ 0.6721,  0.9981,  0.9174,  ...,  0.8806, -0.8000, -0.2462],\n",
            "        [-0.5684, -0.5474, -0.9344,  ..., -0.9100,  0.3433,  0.4185],\n",
            "        ...,\n",
            "        [ 0.6751,  0.9935,  0.8860,  ...,  0.8228, -0.8238, -0.2137],\n",
            "        [-0.5794, -0.9409, -0.8850,  ..., -0.8648,  0.2814,  0.4209],\n",
            "        [ 0.7308,  0.9920,  0.8288,  ...,  0.8948, -0.8103, -0.5437]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5470,  0.9919,  0.8491,  ...,  0.8996, -0.8342, -0.2764],\n",
            "        [ 0.6747,  0.9912,  0.8802,  ...,  0.8807, -0.8138, -0.1960],\n",
            "        [-0.6412, -0.9628, -0.9457,  ..., -0.8998,  0.3163,  0.7631],\n",
            "        ...,\n",
            "        [-0.7546, -0.8826, -0.9014,  ..., -0.9149,  0.2013,  0.4584],\n",
            "        [-0.5459,  0.9291, -0.8929,  ..., -0.7564,  0.1626,  0.5929],\n",
            "        [-0.2714, -0.8848, -0.9179,  ..., -0.8699,  0.3973,  0.3341]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5054, -0.9104, -0.9286,  ..., -0.8480,  0.4439,  0.5899],\n",
            "        [ 0.7298,  0.9664,  0.6868,  ...,  0.9130, -0.6977, -0.4884],\n",
            "        [ 0.3970,  0.9879,  0.7696,  ...,  0.8884, -0.7613, -0.0340],\n",
            "        ...,\n",
            "        [ 0.4249,  0.9997,  0.8963,  ...,  0.8413, -0.7689, -0.4460],\n",
            "        [ 0.3974,  0.9837,  0.8652,  ...,  0.8754, -0.7558, -0.1503],\n",
            "        [-0.4678, -0.9779, -0.9635,  ..., -0.8536,  0.0413,  0.6801]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5909,  0.9988,  0.8914,  ...,  0.9174, -0.8331, -0.2902],\n",
            "        [ 0.7693,  0.9999,  0.7368,  ...,  0.7491, -0.6733, -0.6431],\n",
            "        [ 0.5938,  1.0000,  0.9264,  ...,  0.8305, -0.4298, -0.8714],\n",
            "        ...,\n",
            "        [ 0.5516,  0.9996,  0.8887,  ...,  0.8527, -0.7815, -0.5118],\n",
            "        [-0.3060,  0.3097, -0.9556,  ..., -0.7311,  0.6786, -0.1475],\n",
            "        [ 0.6813,  0.9990,  0.8792,  ...,  0.8487, -0.7817, -0.4434]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4968, -0.9795, -0.9195,  ..., -0.8246,  0.4541,  0.6770],\n",
            "        [ 0.7332,  0.9978,  0.9004,  ...,  0.8445, -0.8168, -0.5157],\n",
            "        [ 0.0942,  1.0000,  0.3356,  ..., -0.1151,  0.7144, -0.8376],\n",
            "        ...,\n",
            "        [-0.4871,  0.6977, -0.9071,  ..., -0.8913,  0.0477,  0.5206],\n",
            "        [-0.6258, -0.9894, -0.9184,  ..., -0.8595,  0.1898,  0.6701],\n",
            "        [-0.6410, -0.8475, -0.9404,  ..., -0.8619, -0.1967,  0.6125]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5817,  0.8977, -0.8888,  ..., -0.9265,  0.3215,  0.4767],\n",
            "        [-0.5044, -0.9926, -0.9373,  ..., -0.9018,  0.2429,  0.6098],\n",
            "        [ 0.4990,  0.9398,  0.7406,  ...,  0.8386, -0.8473, -0.4015],\n",
            "        ...,\n",
            "        [-0.6756, -0.5356, -0.8949,  ..., -0.7627,  0.2131,  0.6079],\n",
            "        [-0.5598,  0.8915, -0.9061,  ..., -0.9147,  0.2866,  0.6334],\n",
            "        [ 0.7514,  0.9998,  0.8790,  ...,  0.8441, -0.6861, -0.6996]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6926,  0.9482, -0.8985,  ..., -0.8268,  0.1416,  0.7086],\n",
            "        [-0.4758, -0.9931, -0.9283,  ..., -0.9386,  0.2195,  0.2132],\n",
            "        [ 0.5483,  0.9939,  0.8491,  ...,  0.7601, -0.7892, -0.2197],\n",
            "        ...,\n",
            "        [-0.6611, -0.8931, -0.9278,  ..., -0.8689,  0.1624,  0.6622],\n",
            "        [ 0.6559,  0.9975,  0.8364,  ...,  0.8600, -0.7621, -0.3554],\n",
            "        [-0.5979, -0.0824, -0.8812,  ..., -0.8851,  0.2919,  0.5558]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5286, -0.3223, -0.8373,  ..., -0.8017,  0.4568,  0.6825],\n",
            "        [-0.4523,  0.9575, -0.8118,  ..., -0.8323,  0.8031,  0.2277],\n",
            "        [-0.4646,  0.4070, -0.8827,  ..., -0.8252,  0.5278,  0.3451],\n",
            "        ...,\n",
            "        [ 0.6000,  0.9977,  0.6968,  ...,  0.8657, -0.8805, -0.2784],\n",
            "        [-0.4450, -0.5181, -0.9317,  ..., -0.8054,  0.5547,  0.4940],\n",
            "        [-0.4061, -0.0040, -0.8507,  ..., -0.7771,  0.4065,  0.4681]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5932, -0.9999, -0.8386,  ..., -0.9010, -0.1504,  0.3108],\n",
            "        [ 0.7573,  0.9871,  0.8039,  ...,  0.9059, -0.7636, -0.2543],\n",
            "        [ 0.5709,  0.9998,  0.8956,  ...,  0.8127, -0.6174, -0.5814],\n",
            "        ...,\n",
            "        [-0.6777,  0.3871, -0.9498,  ..., -0.9253,  0.2986,  0.6265],\n",
            "        [ 0.6861,  0.9578,  0.8326,  ...,  0.8464, -0.7228, -0.0943],\n",
            "        [-0.5054, -0.7504, -0.9530,  ..., -0.9147,  0.1623,  0.4326]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.3317,  0.9958, -0.8069,  ..., -0.8184,  0.7717, -0.1766],\n",
            "        [ 0.6928,  0.9987,  0.8369,  ...,  0.8693, -0.8400, -0.1608],\n",
            "        [ 0.7186,  0.9997,  0.8826,  ...,  0.8125, -0.5395, -0.7724],\n",
            "        ...,\n",
            "        [ 0.5321,  0.9997,  0.7073,  ...,  0.7448, -0.7187, -0.4336],\n",
            "        [-0.6405,  0.5828, -0.9317,  ..., -0.8580,  0.2791,  0.7111],\n",
            "        [-0.6294,  0.9657, -0.9262,  ..., -0.8712, -0.0020,  0.6299]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6235,  0.9998,  0.6986,  ...,  0.7773, -0.7811, -0.2566],\n",
            "        [ 0.5613,  0.9996,  0.9738,  ...,  0.8385, -0.6489, -0.4289],\n",
            "        [ 0.7430,  1.0000,  0.9411,  ...,  0.8262, -0.1484, -0.9206],\n",
            "        ...,\n",
            "        [ 0.2979,  0.9862,  0.8647,  ...,  0.8205, -0.7722, -0.2827],\n",
            "        [ 0.5652,  0.9944,  0.7959,  ...,  0.8913, -0.8059, -0.0921],\n",
            "        [ 0.7031,  0.9996,  0.7046,  ...,  0.7993, -0.7020, -0.3849]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5136, -0.8787, -0.9478,  ..., -0.8647,  0.2744,  0.4384],\n",
            "        [ 0.5269,  0.9944,  0.8305,  ...,  0.7820, -0.8294,  0.0282],\n",
            "        [ 0.8034,  0.9987,  0.9387,  ...,  0.8444, -0.6826, -0.7847],\n",
            "        ...,\n",
            "        [ 0.6581,  0.9944,  0.8283,  ...,  0.7630, -0.8045,  0.0022],\n",
            "        [ 0.8031,  0.9999,  0.9294,  ...,  0.8055, -0.4767, -0.8531],\n",
            "        [ 0.5283,  0.9990,  0.8898,  ...,  0.9159, -0.6909, -0.5032]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6474,  1.0000,  0.9291,  ...,  0.3941,  0.5050, -0.9702],\n",
            "        [ 0.6312,  0.9957,  0.9256,  ...,  0.8724, -0.7934, -0.3146],\n",
            "        [-0.3256,  0.3764, -0.9100,  ..., -0.9047,  0.3545,  0.6175],\n",
            "        ...,\n",
            "        [-0.5526, -0.9749, -0.9375,  ..., -0.8817,  0.5928,  0.5809],\n",
            "        [-0.5696, -0.9716, -0.9478,  ..., -0.9060,  0.1141,  0.4488],\n",
            "        [-0.7235, -0.9651, -0.9472,  ..., -0.8954,  0.1102,  0.5933]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6510, -0.9994, -0.9502,  ..., -0.8659,  0.2210,  0.7042],\n",
            "        [ 0.6483,  1.0000,  0.9134,  ...,  0.7787, -0.4790, -0.8966],\n",
            "        [ 0.4954,  0.9396,  0.7477,  ...,  0.8667, -0.7706, -0.0139],\n",
            "        ...,\n",
            "        [-0.5169, -0.9979, -0.9669,  ..., -0.8399,  0.3593,  0.6640],\n",
            "        [-0.7608,  0.5645, -0.8554,  ..., -0.8628,  0.0119,  0.2018],\n",
            "        [-0.6668, -0.4157, -0.9560,  ..., -0.8378,  0.3867,  0.5979]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6689,  0.9988,  0.8214,  ...,  0.9062, -0.7212, -0.5398],\n",
            "        [ 0.6266,  1.0000, -0.5824,  ..., -0.7175,  0.6125, -0.8611],\n",
            "        [-0.4183, -0.2560, -0.9566,  ..., -0.8944,  0.1953,  0.4924],\n",
            "        ...,\n",
            "        [ 0.5035,  0.9558,  0.8836,  ...,  0.8465, -0.8986, -0.0317],\n",
            "        [-0.5855,  0.9959, -0.7918,  ..., -0.6458,  0.0249, -0.0312],\n",
            "        [-0.6393,  0.9855, -0.7985,  ..., -0.8453,  0.3376,  0.2871]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6339, -0.9938, -0.9021,  ..., -0.7791,  0.2929,  0.6287],\n",
            "        [ 0.3513,  0.9987,  0.8904,  ...,  0.8442, -0.6943, -0.4436],\n",
            "        [ 0.5970,  1.0000,  0.9580,  ...,  0.8882, -0.4486, -0.7085],\n",
            "        ...,\n",
            "        [ 0.7674,  1.0000,  0.9341,  ...,  0.6957, -0.5834, -0.8357],\n",
            "        [-0.6850,  0.5129, -0.9360,  ..., -0.9058,  0.5145,  0.3805],\n",
            "        [-0.5691, -0.4679, -0.9091,  ..., -0.9377,  0.0461,  0.5687]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6073, -0.9972, -0.9083,  ..., -0.8857,  0.3316,  0.6505],\n",
            "        [ 0.4037,  0.9529,  0.8815,  ...,  0.8276, -0.8703,  0.0593],\n",
            "        [ 0.4596,  0.9844,  0.8020,  ...,  0.8957, -0.8554,  0.0168],\n",
            "        ...,\n",
            "        [ 0.4823,  0.9641,  0.7241,  ...,  0.8791, -0.8920, -0.4647],\n",
            "        [ 0.4831,  0.9796,  0.7995,  ...,  0.8917, -0.8151,  0.0242],\n",
            "        [ 0.4412,  1.0000,  0.8458,  ...,  0.2859, -0.5523, -0.6556]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1595,  0.9993, -0.7075,  ..., -0.6238,  0.7692, -0.5085],\n",
            "        [-0.7755, -0.9839, -0.9576,  ..., -0.9085,  0.5448,  0.3868],\n",
            "        [ 0.4563,  0.9906,  0.8321,  ...,  0.8164, -0.8409, -0.4313],\n",
            "        ...,\n",
            "        [-0.4391,  0.5654, -0.8820,  ..., -0.9240,  0.1467,  0.5030],\n",
            "        [-0.5084,  0.9044, -0.8609,  ..., -0.7798,  0.6854,  0.0139],\n",
            "        [-0.4131, -0.9967, -0.9022,  ..., -0.9116,  0.1991,  0.5538]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5170,  0.9642, -0.8813,  ..., -0.8205,  0.6373,  0.4367],\n",
            "        [ 0.8632,  0.9971,  0.8322,  ...,  0.9296, -0.4752, -0.6505],\n",
            "        [ 0.7550,  1.0000,  0.9229,  ...,  0.8199, -0.6841, -0.7063],\n",
            "        ...,\n",
            "        [-0.6747,  0.9939, -0.7506,  ..., -0.7840,  0.2819,  0.7729],\n",
            "        [-0.1293,  0.9729, -0.9407,  ..., -0.9396,  0.6455,  0.0766],\n",
            "        [ 0.4658,  0.9938,  0.7863,  ...,  0.9011, -0.8707, -0.3655]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 2.3286e-01,  9.9988e-01,  2.9940e-01,  ...,  1.0978e-01,\n",
            "          5.4538e-01, -7.2549e-01],\n",
            "        [-4.2109e-01,  9.9750e-01, -7.9453e-01,  ..., -7.5837e-01,\n",
            "          7.3258e-01,  5.8657e-04],\n",
            "        [-5.9010e-01, -9.9999e-01, -9.1917e-01,  ..., -7.9677e-01,\n",
            "          4.3118e-01,  4.8878e-01],\n",
            "        ...,\n",
            "        [-6.9917e-01, -9.6679e-01, -9.3252e-01,  ..., -9.0402e-01,\n",
            "         -7.7240e-02,  6.4058e-01],\n",
            "        [ 5.6247e-01,  9.9343e-01,  8.2145e-01,  ...,  9.1634e-01,\n",
            "         -8.8966e-01, -4.7480e-01],\n",
            "        [ 2.3767e-01,  9.5789e-01,  7.0639e-01,  ...,  8.6181e-01,\n",
            "         -8.3650e-01, -8.2763e-02]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6749, -0.5884, -0.9542,  ..., -0.9383, -0.0081,  0.7173],\n",
            "        [-0.7027, -0.9854, -0.8921,  ..., -0.9355,  0.5524,  0.6607],\n",
            "        [-0.6342, -0.5760, -0.9362,  ..., -0.9021,  0.2398,  0.6901],\n",
            "        ...,\n",
            "        [-0.7161,  0.7206, -0.9473,  ..., -0.8634,  0.1601,  0.5922],\n",
            "        [ 0.7256,  0.9998,  0.8192,  ...,  0.6679, -0.3752, -0.7395],\n",
            "        [-0.5450, -0.1646, -0.9544,  ..., -0.8893,  0.3599,  0.6541]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6620,  0.9934,  0.8289,  ...,  0.8669, -0.7815, -0.2879],\n",
            "        [ 0.7931,  1.0000,  0.8774,  ...,  0.8112, -0.6818, -0.7401],\n",
            "        [-0.6112,  0.9997, -0.6225,  ..., -0.8551,  0.0985, -0.4122],\n",
            "        ...,\n",
            "        [-0.5469, -0.9612, -0.9514,  ..., -0.9152,  0.3256,  0.5783],\n",
            "        [ 0.5511,  1.0000,  0.6873,  ...,  0.3021, -0.6029, -0.8797],\n",
            "        [ 0.6523,  0.9632,  0.8044,  ...,  0.8294, -0.7791, -0.1333]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4849,  0.9432, -0.8733,  ..., -0.8551,  0.2889,  0.4043],\n",
            "        [-0.6624,  0.2774, -0.9094,  ..., -0.8638,  0.0494,  0.5199],\n",
            "        [-0.7311, -0.9797, -0.9391,  ..., -0.9199,  0.0727,  0.7376],\n",
            "        ...,\n",
            "        [ 0.5704,  0.9976,  0.8706,  ...,  0.8999, -0.8621, -0.3847],\n",
            "        [-0.5490,  0.8431, -0.9092,  ..., -0.9297,  0.1354,  0.3097],\n",
            "        [-0.5827,  0.3779, -0.9203,  ..., -0.8968,  0.4987,  0.4901]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6451,  0.2128, -0.9385, -0.5130,  0.0088, -0.9171, -0.5244, -0.7710,\n",
            "          0.8316,  0.6362, -0.7008,  0.8766, -0.2146, -0.4909,  0.1861,  0.8858,\n",
            "         -0.6897,  0.1350,  0.4551,  0.4946, -0.0270,  0.8531,  0.1660, -0.2204,\n",
            "         -0.7410, -0.8668,  0.4049,  0.3016,  0.2472, -0.5416,  0.0921,  0.8486,\n",
            "          0.6478,  0.2023,  0.2933,  0.3569,  0.6216,  0.3848, -0.7552, -0.2316,\n",
            "          0.9380,  0.3844, -0.0431, -0.7573, -0.6913, -0.3796,  0.0920, -0.5861,\n",
            "          0.2306,  0.3993,  0.3758, -0.9948,  0.2694, -0.9355, -0.6591, -0.8622,\n",
            "         -0.3983,  0.4181,  0.0965,  0.7580, -0.4786, -0.5332,  0.8729,  0.3024,\n",
            "          0.9704,  0.2271,  0.5611, -0.2706,  0.9246, -0.6664, -0.8795,  0.8244,\n",
            "         -0.1744, -0.2708,  0.5081, -0.4231,  0.8585, -0.7255, -0.3211,  0.3445,\n",
            "         -0.7656,  0.4775,  0.8186, -0.6180, -0.7042, -0.5027,  0.6844, -0.3910,\n",
            "          0.3254, -0.2687, -0.1704, -0.8902, -0.6964,  0.7615,  0.5533, -0.3331,\n",
            "          0.3934, -0.8848,  0.4201,  0.0799,  0.6934,  0.5566,  0.5693,  0.1247,\n",
            "         -0.2687, -0.8798,  0.5264, -0.5487,  0.5239,  0.2464, -0.6071, -0.1593,\n",
            "          0.8911, -0.6792, -0.4869,  0.7727, -0.9142, -0.6457,  0.2351,  0.1754,\n",
            "         -0.2510, -0.6302,  0.5118, -0.5296, -0.5605, -0.8024, -0.7511,  0.8436,\n",
            "          0.4480,  0.1572, -0.0777, -0.9257, -0.8217, -0.7986,  0.5958, -0.4588,\n",
            "         -0.9659,  0.2186,  0.7068,  0.6522,  0.8223,  0.5946, -0.5157,  0.1315,\n",
            "          0.1216,  0.5062, -0.0382,  0.6016, -0.0910, -0.8552,  0.2782, -0.5530,\n",
            "         -0.7790,  0.1405, -0.8110,  0.5340,  0.6028,  0.4539,  0.9741, -0.9089,\n",
            "          0.7326,  0.7344,  0.4283,  0.1911,  0.9974, -0.6849,  0.2718,  0.7019,\n",
            "          0.8765, -0.4479, -0.0613,  0.6781,  0.3505,  0.6648,  0.9913, -0.7515,\n",
            "         -0.6804,  0.2381,  0.9134,  0.7619,  0.0417,  0.1005, -0.8629, -0.8722,\n",
            "          0.7543, -0.6054, -0.5350,  0.3739, -0.9319,  0.5628, -0.6771, -0.7956,\n",
            "         -0.6662,  0.8387,  0.2048, -0.2498, -0.2971,  0.5742,  0.6782,  0.3937,\n",
            "          0.6923,  0.2900,  0.5892, -0.9496, -0.8536, -0.6501,  0.2359,  0.0209,\n",
            "         -0.4926,  0.5921,  0.4245,  0.7074,  0.2172, -0.8136, -0.1161,  0.6056,\n",
            "          0.6796, -0.9437,  0.7068,  0.8834, -0.7645, -0.7899,  0.5033, -0.8871,\n",
            "         -0.2091, -0.5669, -0.1882,  0.3679, -0.8310,  0.3414,  0.2244,  0.6789,\n",
            "          0.3905,  0.8565,  0.9517,  0.2585, -0.9023,  0.2948,  0.6985, -0.4849,\n",
            "          0.8956, -0.3895,  0.8607,  0.2567, -0.8552,  0.3353, -0.8110, -0.7371,\n",
            "         -0.1538,  0.7622, -0.1918, -0.4122,  0.6075,  0.6658,  0.6572,  0.3785,\n",
            "          0.9014, -0.9344, -0.6668,  0.0370, -0.5631,  0.2501, -0.9513, -0.8388,\n",
            "         -0.4712,  0.8642, -0.7666, -0.2972,  0.4886,  0.4169,  0.3850,  0.7257,\n",
            "         -0.3532,  0.8916,  0.3193, -0.7767,  0.7111,  0.0705, -0.8228,  0.6655,\n",
            "         -0.9830,  0.9142,  0.7191,  0.6130,  0.0066,  0.5761, -0.2282,  0.8009,\n",
            "         -0.9289,  0.0966,  0.7792,  0.8227,  0.9574,  0.1479, -0.8514, -0.8075,\n",
            "          0.6987, -0.7365,  0.2212,  0.8113,  0.1423,  0.6081,  0.4398,  0.7031,\n",
            "         -0.0153,  0.7441, -0.9307,  0.6563, -0.6749,  0.1948,  0.1312, -0.6231,\n",
            "         -0.6295,  0.4277, -0.4729, -0.7158, -0.4927,  0.4839,  0.2578,  0.0933,\n",
            "          0.2359,  0.8376, -0.5553, -0.6498, -0.7131, -0.0963,  0.7228, -0.3338,\n",
            "         -0.6820,  0.4054, -0.0469,  0.9055, -0.4235, -0.7859, -0.1413, -0.4144,\n",
            "         -0.2763,  0.9550, -0.8844,  0.6487,  0.8342,  0.4978,  0.8610,  0.4858,\n",
            "         -0.2469, -0.7856,  0.4787, -0.2762,  0.7470, -0.3702, -0.4506,  0.2871,\n",
            "         -0.8979, -0.6931,  0.7969,  0.7484,  0.7620,  0.9146, -0.7641,  0.4668,\n",
            "         -0.6553, -0.0504,  0.8054, -0.6485,  0.7642, -0.7393,  0.4397,  0.3568,\n",
            "         -0.9404,  0.5920, -0.7039,  0.6906, -0.3481,  0.9409, -0.6299, -0.8429,\n",
            "         -0.4976,  0.0971,  0.8212,  0.2690, -0.5615, -0.0384,  0.7622,  0.3238,\n",
            "         -0.5917,  0.5104,  0.6423, -0.8737,  0.7213,  0.7010,  0.5214, -0.0089,\n",
            "         -0.2402, -0.8383,  0.2878,  0.8010, -0.2920, -0.5325, -0.4345,  0.8343,\n",
            "         -0.7581, -0.0237, -0.5326,  0.4720,  0.6350, -0.5314,  0.1202, -0.1290,\n",
            "          0.1300, -0.9380,  0.6439,  0.5803,  0.4346,  0.3776, -0.8767,  0.0467,\n",
            "         -0.8908, -0.2113, -0.7261,  0.4685, -0.3576, -0.6416, -0.7099, -0.9678,\n",
            "          0.9064, -0.1562,  0.9483, -0.5869, -0.7370, -0.3639, -0.2317, -0.1322,\n",
            "          0.7249, -0.5372,  0.9600, -0.7258,  0.0911,  0.4174,  0.6674,  0.2052,\n",
            "          0.7318,  0.8212,  0.7551,  0.1072,  0.6218,  0.0011, -0.8059, -0.9065,\n",
            "          0.3896,  0.6747, -0.1328,  0.8357, -0.6030,  0.7395,  0.8553, -0.0486,\n",
            "          0.0387, -0.3433,  0.9464,  0.6285, -0.1812,  0.8649,  0.7285,  0.8679,\n",
            "          0.2223,  0.0469,  0.5160,  0.5534, -0.8237, -0.3040,  0.7649,  0.5080,\n",
            "          0.2381, -0.9241,  0.2928, -0.3481, -0.2656, -0.8840, -0.1783, -0.9890,\n",
            "          0.3334,  0.6335, -0.9062,  0.1104,  0.0829,  0.1363,  0.2049,  0.4084,\n",
            "          0.9146, -0.6711,  0.1129, -0.1467,  0.0997,  0.5232,  0.3943,  0.1896,\n",
            "         -0.7057, -0.3739,  0.1993,  0.3230,  0.3863, -0.8160, -0.2071,  0.4758,\n",
            "         -0.8242, -0.8981,  0.7292,  0.9678,  0.3677,  0.6511,  0.5175,  0.0822,\n",
            "         -0.1609,  0.8751, -0.3048,  0.3173,  0.8332,  0.0342, -0.5708, -0.5212,\n",
            "         -0.7373, -0.4058,  0.3677, -0.3714, -0.8478, -0.9359, -0.5002, -0.4266,\n",
            "         -0.4476, -0.0842,  0.6815, -0.6331,  0.0426, -0.7680, -0.5330, -0.9669,\n",
            "         -0.5091, -0.4176, -0.6447,  0.2980, -0.9335, -0.7617, -0.5625,  0.0082,\n",
            "          0.5929,  0.8598, -0.3764, -0.4287, -0.6555,  0.7189, -0.8934,  0.3615,\n",
            "         -0.4784,  0.8308, -0.9180,  0.3530, -0.8421, -0.5188, -0.0828,  0.3649,\n",
            "          0.1463, -0.9138,  0.3667, -0.6852,  0.1984, -0.2424, -0.5409, -0.6935,\n",
            "         -0.8840, -0.9268,  0.7851,  0.9490,  0.1958, -0.8276, -0.6532,  0.6230,\n",
            "          0.2144, -0.6500,  0.7753,  0.8957,  0.7237,  0.7666,  0.2718, -0.2409,\n",
            "         -0.7377, -0.2503, -0.2887, -0.0368, -0.5950,  0.5329, -0.1854,  0.4180,\n",
            "          0.6692, -0.5663,  0.9319,  0.5317, -0.3450,  0.8928, -0.7427, -0.8561,\n",
            "         -0.7871, -0.9040,  0.9027, -0.3503, -0.8807,  0.3191, -0.3220, -0.0861,\n",
            "         -0.0460,  0.1830,  0.6618,  0.5328,  0.4130,  0.1074, -0.4540, -0.5724,\n",
            "          0.5390,  0.8518, -0.1233,  0.6800, -0.3605,  0.7678,  0.1140,  0.6555,\n",
            "          0.3868,  0.4920,  0.1960, -0.9566,  0.7144, -0.3398,  0.6020,  0.8414,\n",
            "         -0.4490, -0.8426, -0.4446, -0.8196, -0.2745, -0.8173,  0.9442, -0.1627,\n",
            "         -0.4783,  0.8669,  0.7192,  0.3007,  0.7953, -0.7801, -0.3076,  0.1674,\n",
            "          0.5514,  0.8112, -0.2759, -0.8566, -0.1028, -0.9190, -0.5817, -0.0828,\n",
            "         -0.0417,  0.2986, -0.5005, -0.9251,  0.1609, -0.8811,  0.5627, -0.4385,\n",
            "         -0.4991,  0.9074, -0.6071, -0.1722,  0.9428,  0.7164, -0.8231,  0.9417,\n",
            "         -0.2252, -0.3199,  0.7840,  0.4340, -0.4424,  0.6513,  0.2141,  0.1589,\n",
            "         -0.3060, -0.7417,  0.9458,  0.6402, -0.3176,  0.8120, -0.0377,  0.2665,\n",
            "          0.5286, -0.7583,  0.5132, -0.3419, -0.2742, -0.5630, -0.4646,  0.7630,\n",
            "          0.9896, -0.9769,  0.9327,  0.2453, -0.1252,  0.0510, -0.3972,  0.0012,\n",
            "          0.8280,  0.1481,  0.5549, -0.4592, -0.5682, -0.1790,  0.1224, -0.9368,\n",
            "         -0.8790,  0.6222,  0.4630, -0.9417, -0.4636,  0.4149,  0.5509, -0.5895,\n",
            "          0.2035,  0.5841, -0.4095,  0.2032, -0.9153, -0.0784,  0.4742, -0.2906,\n",
            "          0.8641, -0.5337,  0.9441, -0.6600,  0.6994,  0.7558, -0.7179, -0.8838,\n",
            "         -0.2810, -0.7330,  0.2327, -0.1315, -0.7804,  0.7066, -0.8438,  0.2653,\n",
            "         -0.3182, -0.8139,  0.3754, -0.3833,  0.4114,  0.2811, -0.8137,  0.7933,\n",
            "          0.8550,  0.1148,  0.9200, -0.6530,  0.6329,  0.0644,  0.5046,  0.7951,\n",
            "          0.5222, -0.1988, -0.8532, -0.4653,  0.6633, -0.7754,  0.2238,  0.6651]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluation... :   0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aeebdb00c47c4e588897f4853757d9e5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7346,  0.9386,  0.8684,  ...,  0.8738, -0.8459, -0.2806],\n",
            "        [ 0.8268,  1.0000,  0.9613,  ...,  0.8307,  0.1113, -0.9526],\n",
            "        [ 0.6059,  0.9996, -0.8182,  ..., -0.8513,  0.7073, -0.5245],\n",
            "        ...,\n",
            "        [ 0.4170,  0.9943,  0.7714,  ...,  0.8391, -0.8297, -0.1261],\n",
            "        [-0.1091,  0.9793, -0.7369,  ..., -0.8616,  0.5627, -0.1041],\n",
            "        [-0.7109, -0.1942, -0.9178,  ..., -0.7500,  0.3131,  0.6596]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.4312,  0.9983, -0.8670,  ..., -0.8851,  0.4213,  0.2098],\n",
            "        [ 0.6995,  0.9997,  0.7264,  ...,  0.5648, -0.8303, -0.2063],\n",
            "        [ 0.3261,  0.9993,  0.2494,  ..., -0.6160,  0.3847, -0.8948],\n",
            "        ...,\n",
            "        [-0.2294,  0.9930, -0.2964,  ..., -0.7273,  0.1948, -0.7123],\n",
            "        [-0.6244,  0.9999, -0.5537,  ..., -0.8736,  0.3399,  0.0659],\n",
            "        [ 0.4842,  1.0000,  0.7003,  ..., -0.6341,  0.5965, -0.9662]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6488,  0.9999,  0.9260,  ...,  0.8548, -0.6765, -0.6765],\n",
            "        [ 0.3602,  1.0000,  0.6908,  ...,  0.3312,  0.7634, -0.8405],\n",
            "        [ 0.5880,  0.9998,  0.8428,  ...,  0.8713, -0.7800, -0.4780],\n",
            "        ...,\n",
            "        [-0.1427,  1.0000,  0.0708,  ..., -0.8762,  0.4886, -0.8169],\n",
            "        [-0.7915, -0.3247, -0.9113,  ..., -0.9233,  0.2732,  0.5295],\n",
            "        [ 0.4819,  1.0000,  0.6575,  ...,  0.2269, -0.0167, -0.9170]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1519,  0.9966,  0.1570,  ...,  0.0476, -0.7056, -0.6008],\n",
            "        [ 0.0288,  1.0000,  0.7252,  ..., -0.2459, -0.0702, -0.9317],\n",
            "        [-0.1015,  0.9998, -0.4927,  ..., -0.8156,  0.3628, -0.8435],\n",
            "        ...,\n",
            "        [ 0.7799,  0.9999,  0.9136,  ...,  0.8745, -0.5582, -0.6081],\n",
            "        [-0.1712, -0.3560, -0.8246,  ..., -0.9101,  0.6572, -0.1842],\n",
            "        [ 0.6350,  0.9824,  0.8574,  ...,  0.9011, -0.8831, -0.2428]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7040,  0.9997,  0.7105,  ...,  0.7691, -0.5716, -0.1692],\n",
            "        [ 0.4619,  0.9993,  0.8132,  ...,  0.8931, -0.5994, -0.3774],\n",
            "        [-0.5643,  0.2805, -0.8910,  ..., -0.7616,  0.3772,  0.5396],\n",
            "        ...,\n",
            "        [ 0.5742,  0.9997,  0.5576,  ...,  0.7628, -0.5904, -0.7593],\n",
            "        [ 0.5063,  0.9995,  0.8862,  ...,  0.4909, -0.6186, -0.4620],\n",
            "        [ 0.7434,  0.9989,  0.9453,  ...,  0.4739, -0.4202, -0.6892]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5245,  0.9913,  0.8615,  ...,  0.8882, -0.8484, -0.2994],\n",
            "        [ 0.8003,  1.0000,  0.6697,  ...,  0.7389, -0.7263, -0.8101],\n",
            "        [-0.4182, -0.4504, -0.9677,  ..., -0.8715,  0.5467,  0.4583],\n",
            "        ...,\n",
            "        [ 0.3140,  0.9106, -0.9208,  ..., -0.8428,  0.6793,  0.2314],\n",
            "        [ 0.3867,  1.0000,  0.1210,  ...,  0.2808, -0.5077, -0.5599],\n",
            "        [ 0.4903,  0.9998,  0.7655,  ...,  0.7251, -0.7767, -0.6674]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.0220,  0.9793, -0.5437,  ..., -0.7940, -0.3262, -0.6162],\n",
            "        [-0.5887, -0.7176, -0.9489,  ..., -0.9281,  0.1327,  0.7322],\n",
            "        [ 0.6189,  0.9760,  0.8007,  ...,  0.8989, -0.8471, -0.2352],\n",
            "        ...,\n",
            "        [-0.2548,  1.0000, -0.3706,  ..., -0.7895, -0.4075, -0.4770],\n",
            "        [ 0.6068,  0.9870,  0.9027,  ...,  0.9067, -0.8683, -0.2763],\n",
            "        [-0.4426,  0.9250, -0.8609,  ..., -0.8300,  0.0993,  0.4206]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.6463,  0.9969,  0.8704,  ...,  0.8935, -0.8245, -0.3534],\n",
            "        [ 0.6904,  0.9964,  0.9142,  ...,  0.9205, -0.8038, -0.4240],\n",
            "        [ 0.7574,  1.0000,  0.9367,  ...,  0.8635, -0.4312, -0.7603],\n",
            "        ...,\n",
            "        [ 0.5821,  0.9508,  0.8600,  ...,  0.8685, -0.9013, -0.1087],\n",
            "        [ 0.4705,  0.9954,  0.7574,  ...,  0.8530, -0.8344, -0.5355],\n",
            "        [ 0.5500,  1.0000,  0.7563,  ...,  0.6609, -0.6668, -0.5497]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.8230,  1.0000,  0.9546,  ...,  0.8505, -0.3244, -0.8719],\n",
            "        [-0.3350,  0.9667, -0.9129,  ..., -0.8535,  0.2330,  0.2369],\n",
            "        [-0.8333, -0.9647, -0.8389,  ..., -0.9080,  0.1112,  0.3655],\n",
            "        ...,\n",
            "        [ 0.6850,  0.9972,  0.8683,  ...,  0.8767, -0.8213, -0.2511],\n",
            "        [-0.6828, -0.6119, -0.9299,  ..., -0.8990,  0.2701,  0.7945],\n",
            "        [ 0.4907,  0.9362,  0.8460,  ...,  0.8617, -0.8670, -0.1077]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5963, -0.6783, -0.9515,  ..., -0.8794,  0.1433,  0.5784],\n",
            "        [ 0.1591,  1.0000,  0.3074,  ..., -0.5003, -0.1483, -0.7954],\n",
            "        [ 0.6204,  0.9967,  0.9030,  ...,  0.8876, -0.8231, -0.4505],\n",
            "        ...,\n",
            "        [ 0.6912,  0.9843,  0.7983,  ...,  0.8888, -0.8738, -0.2090],\n",
            "        [ 0.4823,  0.9990,  0.8278,  ...,  0.7593, -0.6595, -0.1259],\n",
            "        [ 0.7366,  1.0000,  0.9307,  ...,  0.8266, -0.0796, -0.9327]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.2704,  0.5440, -0.9078,  ..., -0.8641,  0.3358,  0.4652],\n",
            "        [-0.5704, -0.9554, -0.9212,  ..., -0.9344,  0.1453,  0.5619],\n",
            "        [-0.7065,  0.7401, -0.9674,  ..., -0.9423, -0.0426,  0.4136],\n",
            "        ...,\n",
            "        [ 0.6823,  1.0000,  0.8389,  ...,  0.7306, -0.6767, -0.7574],\n",
            "        [ 0.5466,  1.0000, -0.6533,  ..., -0.8159,  0.5960, -0.8506],\n",
            "        [ 0.4841,  0.9900,  0.8881,  ...,  0.8924, -0.8503, -0.1683]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0519,  0.9999,  0.6095,  ..., -0.1650,  0.5093, -0.8233],\n",
            "        [-0.5590, -0.8966, -0.9569,  ..., -0.8988,  0.2697,  0.6727],\n",
            "        [-0.7108,  0.9196, -0.9301,  ..., -0.9010,  0.2398,  0.1935],\n",
            "        ...,\n",
            "        [-0.6475,  0.8834, -0.9449,  ..., -0.9081,  0.2698,  0.6494],\n",
            "        [ 0.2025,  1.0000,  0.2061,  ..., -0.4594, -0.1782, -0.7611],\n",
            "        [-0.4114,  0.9993, -0.7443,  ..., -0.9150,  0.4787, -0.2261]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.0392,  0.9875, -0.8162,  ..., -0.4670,  0.6761,  0.4328],\n",
            "        [ 0.3325,  1.0000,  0.6491,  ...,  0.0868, -0.1612, -0.8533],\n",
            "        [-0.6657, -0.9471, -0.8743,  ..., -0.9128,  0.4267,  0.4964],\n",
            "        ...,\n",
            "        [-0.7343,  0.9913, -0.9291,  ..., -0.7372,  0.6088,  0.3330],\n",
            "        [-0.4095,  0.9579, -0.9410,  ..., -0.8821,  0.3930,  0.2544],\n",
            "        [-0.6602,  1.0000, -0.7497,  ..., -0.8138,  0.4384, -0.5668]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7816,  0.9999,  0.9098,  ...,  0.5398, -0.5645, -0.6410],\n",
            "        [ 0.6195,  1.0000,  0.8276,  ...,  0.4597, -0.3929, -0.7879],\n",
            "        [-0.6838, -0.3657, -0.9371,  ..., -0.8557, -0.0900,  0.5592],\n",
            "        ...,\n",
            "        [ 0.4827,  1.0000,  0.6082,  ..., -0.0798, -0.5628, -0.6571],\n",
            "        [ 0.5079,  1.0000,  0.7639,  ...,  0.8134, -0.4200, -0.5856],\n",
            "        [-0.3975,  0.9995, -0.4735,  ..., -0.5852, -0.0917, -0.6373]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.4681,  0.9999,  0.7399, -0.9221, -0.5180,  0.9327,  0.6469,  0.7940,\n",
            "         -0.9941, -0.5832,  0.7812, -0.5990,  0.5436,  0.9977,  0.4372, -0.1140,\n",
            "          0.6987, -0.9408,  0.5161, -0.1406,  0.3267, -0.7871,  0.7575, -0.1907,\n",
            "          0.7895,  0.7748, -0.5150,  0.3854, -0.0572,  0.1918, -0.5591, -0.1895,\n",
            "          0.8364,  0.5767,  0.7365, -0.9012, -0.2302, -0.9376, -0.9634, -0.9907,\n",
            "          0.2975, -0.3724,  0.9987, -0.7626,  0.9927, -0.9796,  0.5076, -0.2526,\n",
            "          0.5170,  0.3658, -0.6262,  0.9461,  0.7371,  0.7960, -0.5647, -0.6831,\n",
            "         -0.7381,  0.3733, -0.7962, -0.5170,  0.7654,  0.8196, -0.5540, -0.1372,\n",
            "         -0.8567, -0.6397,  0.5388,  0.4212, -0.6711, -0.8906,  0.8460, -0.9263,\n",
            "          0.5354,  0.2971, -0.3829,  0.7547, -0.8670,  0.9259, -0.7499,  0.9793,\n",
            "          0.6109,  0.3931,  0.5569, -0.9998,  0.6371, -0.8460,  0.9737, -0.9522,\n",
            "         -0.9049,  0.6559,  0.7565,  0.6154,  0.8273, -0.1385, -0.4214, -0.8890,\n",
            "         -0.6823,  0.5260, -0.9963,  0.7164,  0.5160,  0.6822, -0.6957, -0.5061,\n",
            "         -0.9972,  0.5308, -0.6212, -0.3928, -0.9998, -0.6844, -0.7928, -0.7569,\n",
            "         -0.3520,  0.8236,  0.5565,  0.9990,  0.8721,  0.9958, -0.9998, -0.9846,\n",
            "          0.0065,  0.9173, -0.5662,  0.1978,  0.4883, -0.9399,  0.7804, -0.9959,\n",
            "          0.5393, -0.9059, -0.3770,  0.7080,  0.8775,  0.6295, -0.6011,  0.5384,\n",
            "         -0.9991, -0.0558, -0.6770, -0.9849,  0.9844,  0.6900,  0.8449, -0.3817,\n",
            "         -0.2109,  0.7308,  0.8213, -0.7101,  0.2011, -0.0941, -0.7833,  0.7742,\n",
            "          0.3622, -0.4301, -0.9997,  0.4496, -0.7282,  0.9113, -0.9854,  0.9573,\n",
            "         -0.9712, -0.9999,  0.2258,  0.1966, -0.7711,  0.7917, -0.7364,  0.8383,\n",
            "         -0.5577,  0.6615,  0.5266,  0.5819,  0.3248, -0.6153,  0.3039, -0.5841,\n",
            "          0.8307, -0.7054, -0.7038, -0.9138,  0.9418, -0.3624,  0.9631, -0.9229,\n",
            "         -0.7133,  0.4606,  0.2547, -1.0000,  0.8755,  0.4376,  0.3932,  0.7289,\n",
            "          0.2482, -0.4294, -0.0776,  0.0382, -0.4298,  0.5866, -0.2610,  0.8047,\n",
            "          0.2745, -0.9990,  0.6827,  0.9895,  0.0911, -0.3015,  0.1184,  0.9564,\n",
            "         -0.9917, -0.5251,  0.0798, -0.5566,  0.4118,  0.4476, -0.3380, -0.7397,\n",
            "          0.4761,  0.4146, -0.3624, -0.5517,  0.2208,  0.5121, -0.1814,  0.4056,\n",
            "          0.6933,  0.9988, -0.4245, -0.6302,  0.6438, -0.9985,  0.7674,  0.4508,\n",
            "         -0.4545, -0.6896,  0.9823,  0.6763,  0.6794,  0.9735, -0.9233, -0.1095,\n",
            "         -0.5933,  0.8767, -0.5349, -0.1158,  0.9999, -0.9852,  0.9719,  0.8956,\n",
            "         -0.0644, -0.4996,  0.7591,  0.2924, -0.4170, -0.1489, -0.6241,  0.9888,\n",
            "         -0.6489, -0.9592,  0.5251, -0.3231, -0.8262, -0.8263,  0.8276, -0.3978,\n",
            "          0.9511,  0.9995,  0.8010,  0.4258,  0.6155,  0.4507,  0.6574, -0.9702,\n",
            "          0.9499,  0.9998, -0.9289,  0.5510,  0.9996,  0.5834, -0.0974, -0.6233,\n",
            "          0.3316, -0.9635, -0.1637, -0.4801, -0.5025, -0.5804,  0.0211, -0.9032,\n",
            "         -0.9986, -0.9637,  0.9423, -0.6369, -0.6723,  0.4864, -0.7580,  0.5562,\n",
            "         -0.7506,  0.9847, -0.6214,  0.9997,  0.4710, -0.5285, -0.9321, -0.2360,\n",
            "          0.4213,  0.0616,  0.9983,  0.0246, -0.4921,  0.6706,  0.5131,  0.2020,\n",
            "          0.8858, -0.5565,  0.6096,  0.3581,  0.0052, -0.9030, -0.2518, -0.8366,\n",
            "          0.6813,  0.9352,  0.6734,  0.3677,  0.9304,  0.8020, -0.9999,  0.9973,\n",
            "          0.9618, -0.9843,  0.7946, -0.1437,  0.8738, -0.2751,  0.3899, -0.8639,\n",
            "         -0.7938, -0.9612,  0.6821,  0.1563, -0.7273,  0.1759, -0.9055,  0.7463,\n",
            "          0.1379,  0.8028, -0.3258,  0.3372, -0.9898,  0.6567,  0.8452, -0.3023,\n",
            "          0.7561,  0.9783, -0.0635,  0.9998, -0.7183, -0.6455,  0.2818,  0.4675,\n",
            "          0.4155,  0.3635, -0.3235,  0.6371, -0.9999,  0.3611, -0.4794,  0.1703,\n",
            "          0.6824, -0.9729,  0.6172, -0.4794,  0.1479, -0.2376,  0.3357,  0.5934,\n",
            "          0.9973,  0.2802, -0.5190, -0.6088,  0.1440, -0.0132,  0.8648,  0.5560,\n",
            "          0.9813, -0.7824, -0.3823,  0.6476, -0.0269, -0.6374, -0.1126,  0.5825,\n",
            "          0.0347,  0.8754,  0.6906, -0.6651, -0.4784,  0.8239, -0.9966,  0.9996,\n",
            "          0.2334,  0.4777,  0.8988, -0.3056,  0.6339,  0.5274,  0.2647, -0.6384,\n",
            "          0.9655,  0.7480,  0.5337,  0.0718, -0.2132,  0.0479, -0.9195,  0.4632,\n",
            "          0.4118, -0.3472, -0.9651,  0.9783, -0.9628,  0.4810, -0.0684,  0.8223,\n",
            "          0.8972, -0.2012, -0.8728, -0.0878,  0.5507, -0.6106, -0.7825, -0.9846,\n",
            "         -0.0925, -0.7924,  0.9996, -0.9813,  0.4607, -0.8666, -0.8957,  0.7120,\n",
            "         -0.4826, -0.5102, -0.8196, -0.1776, -0.4673,  0.6806,  0.0499,  0.7312,\n",
            "         -0.5269,  0.2966,  0.7376,  0.0954,  0.2051,  0.8961, -0.6182, -0.9308,\n",
            "         -0.6560, -0.5317, -0.7326,  0.9276, -0.8796, -0.8418,  0.9999, -0.9707,\n",
            "          0.1899, -0.3594, -0.9932,  0.5369, -0.1752, -0.9147, -0.6376, -0.7871,\n",
            "          0.6080,  0.8953,  0.9978,  0.2843,  0.3511, -0.8965, -0.6226,  0.9959,\n",
            "         -0.9070, -0.4992,  0.4078, -0.9887,  0.9078,  0.1619, -0.4276,  0.8076,\n",
            "         -0.7102,  0.9366,  0.6305, -0.9964,  0.5212,  0.6474, -0.3255,  0.8208,\n",
            "          0.3169,  0.3326, -0.9245, -0.1007,  0.9972,  0.4581, -0.7131, -0.1326,\n",
            "          0.8017,  0.7629,  0.9998, -0.9436,  0.6149,  0.9984, -0.2601,  0.4355,\n",
            "          0.3376, -0.7541,  0.0529,  0.4496, -0.9702,  0.9995,  0.1134, -0.9830,\n",
            "         -0.9997,  0.2807, -0.7870,  0.7367,  0.9673,  0.6488,  0.8500,  0.2418,\n",
            "         -0.9978, -0.0794, -0.5306, -0.9992, -0.9980,  0.8227,  0.2575,  0.1660,\n",
            "          0.7754, -0.0068, -0.7191,  0.9989,  0.9086, -0.9996, -0.0647,  0.1286,\n",
            "          0.9584, -0.6815,  0.5541,  0.4768,  0.4471, -0.3835, -0.9998, -0.4507,\n",
            "          0.9501, -0.0474,  0.0411,  0.9983,  0.6675,  0.4960, -0.9313, -0.1856,\n",
            "          0.6162, -0.9998, -0.7035,  0.9993, -0.0840,  0.0116, -0.4132,  0.4079,\n",
            "          0.5782,  0.5544, -0.0119, -0.9938,  0.9887,  0.8800, -0.9186,  0.9947,\n",
            "         -0.5489, -0.6400, -0.6857, -0.6782,  0.6718, -0.7436,  0.4385, -0.1033,\n",
            "          0.9680,  0.8650, -0.3146,  0.6982,  0.9105, -0.7708, -0.2266,  0.7019,\n",
            "          0.5290,  0.4763,  0.9659, -0.4040, -0.6755, -0.4694,  0.6169,  0.9219,\n",
            "         -0.9995,  0.9226, -0.5048, -0.8518,  0.6346, -0.5747, -0.4857, -0.2190,\n",
            "         -0.6929, -0.6333,  0.1019,  0.9259,  0.6737,  0.6894, -0.9738, -0.9996,\n",
            "         -0.6934, -0.5914, -0.7477, -0.5258,  0.3455,  0.9024,  0.1404,  0.4146,\n",
            "          0.1495,  0.9993, -0.4051,  0.9873, -0.7830,  0.9219, -0.9851,  0.3919,\n",
            "          0.5616, -0.8911, -0.3864,  0.9550, -0.2704,  0.8179, -0.9604,  0.5990,\n",
            "          0.9999, -0.7328, -0.6768,  0.5955, -0.8514,  0.7565,  0.0842,  0.9873,\n",
            "         -0.9998,  0.9838, -0.2103,  0.4830,  0.5038,  0.6091,  0.6246, -0.5457,\n",
            "         -0.4504, -0.9838,  0.6598,  0.3904, -0.6418,  0.3057,  0.8813, -0.7254,\n",
            "         -0.9934, -0.6141,  0.4694,  0.9061, -0.5227, -0.9870,  0.9334, -0.2040,\n",
            "          0.9583,  0.3420, -0.6966, -0.4450, -0.0672, -0.6143,  0.4806,  0.6582,\n",
            "          0.7986,  0.3173, -0.8769, -0.4927,  0.1458, -0.7416,  0.7137, -0.3689,\n",
            "         -0.3038,  0.7308,  0.8068,  0.9563,  0.3866,  0.2407,  0.7449, -0.7066,\n",
            "         -0.6206, -0.9992,  0.9977,  0.8365, -0.8195, -0.9992,  0.9203,  0.1286,\n",
            "         -0.3380,  0.6791,  0.0286, -0.6091,  0.3484,  0.6358, -0.9999, -0.4340,\n",
            "          0.1443, -0.3527, -0.7255, -0.9995, -0.5388,  0.0135, -0.2177,  0.2897,\n",
            "          0.9954, -0.3377, -0.9806, -0.9253, -0.0403,  0.5585,  0.1208, -0.9157,\n",
            "         -0.5615,  0.7472, -0.9967,  0.6959, -0.5544, -0.5168,  0.2176,  0.7492,\n",
            "          0.8665, -0.9997,  0.8408, -0.5970,  0.8762, -0.5153,  0.5189,  0.3912,\n",
            "          0.1730, -0.9902,  0.7601,  0.2680,  0.7506,  0.7237,  0.7743,  0.0847,\n",
            "         -0.8625, -0.6262,  0.9695,  0.9574, -0.6262,  0.5790,  0.9962, -0.6027,\n",
            "          0.4491,  0.6646,  0.2213, -0.9981, -0.8017, -0.1401, -0.6707, -0.7850]],\n",
            "       device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "for epoch in tqdm(range(1, EPOCHS + 1), desc=\"Epochs... \"):\n",
        "\n",
        "    # Define train_y, train_loss, step, eval_loss_min using train_op\n",
        "    ##############################################################################################\n",
        "    #                                       Your Code                                            #\n",
        "    ##############################################################################################\n",
        "    train_y, train_loss, step, eval_loss_min = train_op(\n",
        "        model=pt_model, \n",
        "        data_loader=train_data_loader, \n",
        "        loss_fn=loss_fn, \n",
        "        optimizer=optimizer, \n",
        "        scheduler=scheduler, \n",
        "        step=step, \n",
        "        print_every_step=EEVERY_EPOCH, \n",
        "        eval=True,\n",
        "        eval_cb=eval_callback(epoch, EPOCHS, OUTPUT_PATH),\n",
        "        eval_loss_min=eval_loss_min,\n",
        "        eval_data_loader=valid_data_loader, \n",
        "        clip=CLIP)    \n",
        "    \n",
        "    # Define train_score using acc_and_f1\n",
        "    ##############################################################################################\n",
        "    #                                       Your Code                                            #\n",
        "    ##############################################################################################\n",
        "    train_score = acc_and_f1(train_y[0], train_y[1], average='weighted')\n",
        "\n",
        "    # Define eval_y, eval_loss using eval_op\n",
        "    ##############################################################################################\n",
        "    #                                       Your Code                                            #\n",
        "    ##############################################################################################\n",
        "    eval_y, eval_loss = eval_op(\n",
        "        model=pt_model, \n",
        "        data_loader=valid_data_loader, \n",
        "        loss_fn=loss_fn)\n",
        "    \n",
        "    # Define eval_score using acc_and_f1\n",
        "    ##############################################################################################\n",
        "    #                                       Your Code                                            #\n",
        "    ##############################################################################################\n",
        "    eval_score = acc_and_f1(eval_y[0], eval_y[1], average='weighted')\n",
        "\n",
        "    # Save Accuracy and Loss values\n",
        "    ##############################################################################################\n",
        "    #                                       Your Code                                            #\n",
        "    ##############################################################################################\n",
        "    history['train_acc'].append(train_score['acc'])\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['val_acc'].append(eval_score['acc'])\n",
        "    history['val_loss'].append(eval_loss)\n",
        "\n",
        "# Diagram\n",
        "##############################################################################################\n",
        "#                                       Your Code                                            #\n",
        "##############################################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-ZvVuRsoYRK"
      },
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "iterarions = [i for i in range(10)]\n",
        "xpoints = np.array(iterarions)\n",
        "train_ypoints = np.array(history[\"train_loss\"])\n",
        "val_ypoints = np.array(history[\"val_loss\"])\n",
        "\n",
        "plt.plot(iterarions, train_ypoints, label = \"train loss\")\n",
        "plt.plot(iterarions, val_ypoints, label = \"validation loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "tzVjE3tnH4iK",
        "outputId": "28af1ba4-3bfb-4874-d255-4bbca72de49e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD5CAYAAAA3Os7hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xUZdr/8c81k0mFhNAhhYCiJECkBGQpAou6lBWwAmLBFXFZ67ZncZv9edx9+PkgiiIiuq4iiwjIWndRFF2KBJCOFGmhhkASQnrm/v1xhhRIGcgkZya53q/XvDJzzplzLobkmzv3Oee+xRiDUkqpwOewuwCllFK+oYGulFINhAa6Uko1EBroSinVQGigK6VUA6GBrpRSDURQTRuIyDzgp8AJY0y3arbrA6wGxhtjFtW035YtW5qEhISLKFUppdT69etPGmNaVbauxkAH3gReAt6qagMRcQJ/Af7lbVEJCQmkpqZ6u7lSSilARA5Uta7GLhdjzErgVA2bPQS8D5y4uNKUUkr5Sq370EUkBrgReKX25SillLpUvjgpOgP4nTHGXdOGIjJFRFJFJDU9Pd0Hh1ZKKXWON33oNUkBFogIQEtgpIgUG2OWnr+hMWYOMAcgJSXlgkFkioqKSEtLIz8/3wdlqboUGhpKbGwsLpfL7lKUUh61DnRjTMdzz0XkTeDDysLcG2lpaTRt2pSEhAQ8vyCUHzLGkJGRQVpaGh07dqz5DUqpeuHNZYvvAkOAliKSBjwOuACMMbN9WUx+fr6GeQAQEVq0aIF2mynlX2oMdGPMBG93ZoyZVKtqQMM8QOj/k1L+xxd96EoppapjDGQfgePb4PhWaN8TLhvq88NooJeTmZnJ/Pnz+cUvfnHR7x05ciTz58+nWbNmXm3/xBNP0KRJE37zm99c9LGUUn6sIAfSd1rBfXxbWYjnZ5VtM/CXGuh1LTMzk5dffrnSQC8uLiYoqOqP6+OPP67L0pRS/sbthtP7Kob28W1wej/guYgvuAm0ToKuN0GbrtCmG7ROhDDvGn4XSwO9nGnTprF371569OjBddddx6hRo/jTn/5EdHQ0O3fuZNeuXYwdO5ZDhw6Rn5/PI488wpQpU4CyoQxycnIYMWIEAwcOZNWqVcTExPDBBx8QFhZW5XG/++47fv7zn5Obm8tll13GvHnziI6OZubMmcyePZugoCCSkpJYsGABX331FY888ghg9WOvXLmSpk2b1svno1SjlXsKTmyvGNwndkBRrmcDgRaXQbtk6HG7J7y7QlQ8OOpvDES/DfQn/7mN7UeyfbrPpPaRPH5D1yrXP/fcc2zdupXvvvsOgC+//JINGzawdevW0svz5s2bR/PmzcnLy6NPnz7cfPPNtGjRosJ+du/ezbvvvstrr73Gbbfdxvvvv88dd9xR5XHvuusuXnzxRQYPHsyf//xnnnzySWbMmMFzzz3Hvn37CAkJITMzE4Dp06cza9YsBgwYQE5ODqGhobX9WJRS55QUwcndFYP7+DY4c6Rsm7DmVlj3urssuFt1geBw++r28NtA9xd9+/atcK31zJkzWbJkCQCHDh1i9+7dFwR6x44d6dGjBwC9e/dm//79Ve4/KyuLzMxMBg8eDMDdd9/NrbfeCkBycjITJ05k7NixjB07FoABAwbwq1/9iokTJ3LTTTcRGxvrs3+rUo2GMZBz/Lx+7m2Q/j24i6xtHC5odSV0HFQW3G26QZM24KdXefltoFfXkq5PERERpc+//PJLli9fzurVqwkPD2fIkCGV3tUaEhJS+tzpdJKXl3dJx/7oo49YuXIl//znP3n22WfZsmUL06ZNY9SoUXz88ccMGDCAzz77jC5dulzS/pVqFNwlcHIXHN4Ax7ZYIX5iO+RmlG0TGWP1dV9+rRXabbpCy87gDKw7of020O3QtGlTzpw5U+X6rKwsoqOjCQ8PZ+fOnaxZs6bWx4yKiiI6Opqvv/6aQYMG8fe//53Bgwfjdrs5dOgQQ4cOZeDAgSxYsICcnBwyMjLo3r073bt3Z926dezcuVMDXalzjIFTP8CRjdbj8AY4ugmKzlrrXeHWSckuo8qCu3UShDe3t24f0UAvp0WLFgwYMIBu3boxYsQIRo0aVWH98OHDmT17NomJiVx55ZX069fPJ8f929/+VnpStFOnTrzxxhuUlJRwxx13kJWVhTGGhx9+mGbNmvGnP/2JFStW4HA46Nq1KyNGjPBJDUoFnHPXdh/ZUBbeRzZCvnW+CWeIdZKy5x3Wdd8xvaDF5eBw2lt3HRJjLhgjq16kpKSY8ye42LFjB4mJibbUoy6e/n+penU2wwrvwxvKQjznuLVOnNAmCdr3soK7fU+r5R1gXSbeEJH1xpiUytZpC10p5X/ys6yukvLhnXnQs1Kg5RXQaagnvHtB227gqvrS4MZCA10pZa+iPDi62dPv7WmBZ+wuW9+sgxXafSZbX9tdBaGR9tXrxzTQlVL1p6TIujywtN97o3XFiSmx1jdpa7W6k2+zwrt9T4hoUf0+VSkNdKVU3TqwCrYutgL82BYoKbCWhzazwvuKX5adtIxsb2+tAU4DXSlVN45vg+VPwu7PwBUB7XtA3/vKTlpGd/TbG3QClQa6Usq3Mg/Civ+GTQusvu5rn4C+9/vFrfENXf2NGtNANWnSBIAjR45wyy23VLrNkCFDOP8SzfPNmDGD3Nzc0tcjR44sHb+lNp544gmmT59e6/0oVaOzGfDp7+HF3lYXS/+H4OHvrKFiNczrhbbQfaR9+/YsWrTokt8/Y8YM7rjjDsLDrW98HY5XBYzCs7DmFfjPC1CYY402OOQxiNJxhuqbttDLmTZtGrNmzSp9fa51m5OTw7Bhw+jVqxfdu3fngw8+uOC9+/fvp1u3bgDk5eUxfvx4EhMTufHGGyuM5TJ16lRSUlLo2rUrjz/+OGAN+HXkyBGGDh3K0KHWoPcJCQmcPHkSgOeff55u3brRrVs3ZsyYUXq8xMRE7rvvPrp27cr1119f45gx3333Hf369SM5OZkbb7yR06dPlx4/KSmJ5ORkxo8fD8BXX31Fjx496NGjBz179qx2SATVSJUUQeo8mNkTvngaEgbC1FUwZpaGuU38t4X+yTTrjLgvte0OI56rcvW4ceN49NFHeeCBBwBYuHAhn332GaGhoSxZsoTIyEhOnjxJv379GD16dJXzar7yyiuEh4ezY8cONm/eTK9evUrXPfvsszRv3pySkhKGDRvG5s2befjhh3n++edZsWIFLVu2rLCv9evX88Ybb7B27VqMMVx99dUMHjyY6OhoHaZX2cMY2LEMPn8KMvZAXD+47S2I981QGOrSaQu9nJ49e3LixAmOHDnCpk2biI6OJi4uDmMMv//970lOTubaa6/l8OHDHD9+vMr9rFy5sjRYk5OTSU5OLl23cOFCevXqRc+ePdm2bRvbt2+vtqZvvvmGG2+8kYiICJo0acJNN93E119/DdR+mN6VK1eW1jhx4kTefvvt0lmZzg3TO3PmTDIzM6udrUk1Ivu+hrnDYOFd4AiC8e/Czz7VMPcTNf6Uisg84KfACWNMt0rWTwR+BwhwBphqjNlU68qqaUnXpVtvvZVFixZx7Ngxxo0bB8A777xDeno669evx+VykZCQUOmwuTXZt28f06dPZ926dURHRzNp0qRL2s85OkyvqjfHtliXIO75tzXU7JhZcNWEBj3QVSDypoX+JjC8mvX7gMHGmO7A08AcH9Rlm3HjxrFgwQIWLVpUOtFEVlYWrVu3xuVysWLFCg4cOFDtPq655hrmz58PwNatW9m8eTMA2dnZREREEBUVxfHjx/nkk09K31PV0L2DBg1i6dKl5ObmcvbsWZYsWcKgQYMu+t9VfpheoNJhev/yl7+QlZVFTk4Oe/fupXv37vzud7+jT58+7Ny586KPqRqA0wdg8RSYPQjS1sF1T8ND660RDDXM/U6NLXRjzEoRSahm/apyL9cAAX02pGvXrpw5c4aYmBjatWsHwMSJE7nhhhvo3r07KSkpNbZUp06dyj333ENiYiKJiYn07t0bgKuuuoqePXvSpUsX4uLiGDBgQOl7pkyZwvDhw2nfvj0rVqwoXd6rVy8mTZpE3759AZg8eTI9e/astnulKjpMr/La2ZOwcjqkvg7igAGPwMBHISza7spUNbwaPtcT6B9W1uVy3na/AboYYyZXsX4KMAUgPj6+9/ktXR2ONbDo/1cDVHgWVr9sXYJYdNZqiQ+eBlExdlemPOpl+FwRGQrcCwysahtjzBw8XTIpKSn2DMSulLpQSRFs+Bt8+Rc4ewK6/BSG/dmaU1MFDJ8EuogkA3OBEcaYjJq2V0r5CWNg2xLrOvJTP0B8fxj/DsT1tbsydQlqHegiEg8sBu40xuyq7f6MMVVe3638h10zXSkf+uErWP64NQpi6yS4fSF0vl4HzApg3ly2+C4wBGgpImnA44ALwBgzG/gz0AJ42RPExVX179QkNDSUjIwMWrRooaHux4wxZGRk6M1GgeroJlj+BOz9AqLiYOxsa/xxvWol4HlzlcuEGtZPBio9CXqxYmNjSUtLIz093Re7U3UoNDSU2NiAvqCp8Tm1D1Y8C1ves65Wuf5ZaxYgl/5ibij86vY/l8tFx44d7S5DqYYlJx1W/q817oojCAb92roMMTTK7sqUj/lVoCulfKgwF1a9CKtmWvN29roLBv8OItvZXZmqIxroSjVEZ47Bu+OtE56Jo61LEFt2trsqVcc00JVqaI5tgfnjIC/TGjyry0i7K1L1RANdqYZk12ew6GcQEmmNgtguueb3qAZDh89VqiEwxpo16N3x0OJyuO8LDfNGSFvoSgW6kmL49Hewbq51y/5NcyA4wu6qlA000JUKZPlZ8N49sPdz61LEYU+AQ//wbqw00JUKVKcPWCc/M3bDDTOh9912V6RspoGuVCA6tA4WTICSQrhjMXQabHdFyg/o32ZKBZqt78OboyC4Cdy7XMNcldIWulKBwhhrFqEVz0D8j2DcOxDRwu6qlB/RQFcqEBQXwLKHYfMCSB4Ho1+EoJCa36caFQ10pfzd2Qz4xx1wcBUM/SNc8xsds1xVSgNdKX+Wvgvm3wbZR+CWedDtZrsrUn5MA10pf/XDV7DwTnC4YNKHOi2cqpFe5aKUP9rwFrx9EzRtb93Gr2GuvKAtdKX8idsNnz8B/3kBLvsx3PqmTkShvKaBrpS/KDwLi6fAzg8h5V4Y8Vdw6o+o8p5+tyjlD7KPWiMlHt0Ew5+Dq3+uV7Koi1ZjH7qIzBOREyKytYr1IiIzRWSPiGwWkV6+L1OpBuzYFpg7DE7uhgkLoN9UDXN1Sbw5KfomMLya9SOAzp7HFOCV2pelVCPx/afw+k+s5/d+BldW96OmVPVqDHRjzErgVDWbjAHeMpY1QDMR0VlolaqOMbD6ZWuArZadrStZ2na3uyoV4HzRhx4DHCr3Os2z7KgP9q1Uw1NSDJ/8F6S+rhNSKJ+q15OiIjIFq1uG+Pj4+jy0Uv4hPwvemwR7v4ABj8Kwx3VCCuUzvgj0w0BcudexnmUXMMbMAeYApKSkGB8cW6nAcfqAdRt/xh4Y/RL0utPuilQD44umwTLgLs/VLv2ALGOMdrcoVd6hb60rWc4chTuXaJirOlFjC11E3gWGAC1FJA14HHABGGNmAx8DI4E9QC5wT10Vq1RA2rIIlv4CItvDxPesk6BK1YEaA90YM6GG9QZ4wGcVKdVQGAMr/xdWPAvx/WHc2zohhapTeqeoUnWhuACWPQSb/wHJ42H0TJ2QQtU5DXSlfO3MMetKloOr4cd/hEE6IYWqHxroSvnSzo+slnlhrk5IoeqdBrpSvlB4Fj77A6x/A9omw82vQ6sr7K5KNTIa6ErV1pGN8P5kyNgLAx6x5v0MCra7KtUIaaArdancJbBqJnzxDES0hruXQcdr7K5KNWIa6Epdiqw0WHw/HPgGksbCT/8PwpvbXZVq5DTQlbpYW9+HD39ptdDHvgJXTdCrWJRf0EBXylv52dYoiZvehdg+1iiJzTvZXZVSpTTQlfLGwbWw+D7IOgSDp8E1v9X5PpXf0e9IpapTUmzdvr/yrxAVC/d8AvH97K5KqUppoCtVlVP7YPEUSPvW6icf8VcIjbS7KqWqpIGu1PmMsfrJP/4tiFPv+FQBQwNdqfLyTsM/H4XtS6HDALjxVWgWV/P7lPIDGuhKnbPva1hyP+Qct6aGG/AIOJx2V6WU1zTQlSoutMYs/88L0OIyuPffENPL7qqUumga6KpxS98FiyfD0U3QexL85L8hOMLuqpS6JBroqnEyBlLnWSMkusJg/HzoMsruqpSqFQ101ficPQkfPAi7PoHLfgxjXobIdnZXpVStaaCrxmX3clg6FfIz4Sf/A1f/HBwOu6tSyic00FXjUJQPyx+HtbOhdRLcuQTadrO7KqV8yqumiYgMF5HvRWSPiEyrZH28iKwQkY0isllERvq+VKUu0fFt8NpQK8yvngr3rdAwVw1SjS10EXECs4DrgDRgnYgsM8ZsL7fZH4GFxphXRCQJ+BhIqIN6lfKe222F+PLHIbQZTHwfOl9rd1VK1Rlvulz6AnuMMT8AiMgCYAxQPtANcG6QiyjgiC+LVOqiZR+1+sp/WAFXjIAxL0FES7urUqpOeRPoMcChcq/TgKvP2+YJ4F8i8hAQAVTaDBKRKcAUgPj4+IutVSnv7PgQlj0ERXnWTEK979EJKFSj4KvT+xOAN40xscBI4O8icsG+jTFzjDEpxpiUVq1a+ejQSmHNHnRwDSyZCv+YaI2/cv9KSPmZhrlqNLxpoR8Gyo9OFOtZVt69wHAAY8xqEQkFWgInfFGkUpUqyoMfvoKdH8KuT+FsOjhcMOBRGPoHCAq2u0Kl6pU3gb4O6CwiHbGCfDxw+3nbHASGAW+KSCIQCqT7slClAMg9Bbs+s0J87xdQlAshkdD5OrhypPU1NMruKpWyRY2BbowpFpEHgc8AJzDPGLNNRJ4CUo0xy4BfA6+JyC+xTpBOMsaYuixcNSKn98POj+H7j+HAKjAl0LS9NelEl1GQMEhb40oBYlfupqSkmNTUVFuOrfycMdZgWTs/skL8+FZreatEK8C7jIR2PfUOT9Uoich6Y0xKZev0TlHlH0qKYP83VoDv/Biy00AcENcPrn/G6k5pcZndVSrl1zTQlX0KzsCe5VZLfPe/ID8LgsKsAbOGPgZXDNdrx5W6CBroqn6dOVbWCt/3FZQUQlhz6PJTqzul01AIDre7SqUCkga6qlvGwMld1lUpOz+Gw57zJtEJ0HeK1ZUSdzU49VtRqdrSnyLle+4SSFtndaXs/AhO7bWWt+8JP/4jXDkKWifqDT9K+ZgGuvKNqm7y6TgI+k21WuJRMXZXqVSDpoGuLl5JEZzYAUc2wJGNcHgDnNgO7mK9yUcpG2mgq+q5S+Dk7rLwPrIRjm2B4nxrfUgUtO8B/R+ChIGQcI3e5KOUTTTQVRlj4NQPZcF9ZKN1g09hjrXeFWGFd5/JVn94+57QvJP2hSvlJzTQGytjICvNE9zlWt/5WdZ6Zwi0S4Yet3vCuxe07AwOp711K6WqpIHeWJw5fmF4n/WMn+YIsubZ7HpjWXi3TgSny96alVIXRQO9Ico9VS68v7OeZ3tGPBYHtOoCna8vC+82XcEVam/NSqla00APdEV5kJZaseV9en/Z+uaXQYf+ZeHdtjuENLGtXKVU3dFAD1RuN2z+B3z+JJw5ai2LioeYntB7khXe7a6CsGa2lqmUqj8a6IHo4Fr4dJrVKo/pDaOeh7i+OpCVUo2cBnogyTwIy5+Are9bEzzcOAe636rjgiulAA30wFCQA/+ZAateBAQGT4MBD0NwhN2VKaX8iAa6P3O7YfMCWP4k5ByzWuPXPgFRsXZXppTyQwH3t/rhzDweWbCRM/lFdpdStw6ugbk/hqVTrUGt7v033DxXw1wpVaWAa6HvOJLNR5uPsj8jl7fu6UtUeAO7+SXzIPz7cdi22Oonv+k16HaL9pMrpWoUcClxbVIbXrmjNzuOZDPhtTVk5BTYXZJvFOTAF8/AS33g+0+sfvKHUiH5Ng1zpZRXvEoKERkuIt+LyB4RmVbFNreJyHYR2SYi831bZkXXJbVh7t0p/HAyh/Fz1nAiO78uD1e33G74bj682BtW/i8kjraCfOhjetJTKXVRagx0EXECs4ARQBIwQUSSztumM/AYMMAY0xV4tA5qreCaK1rx5j19OZyZx7g5aziSmVfXh/S9A6vhtaGefvJYuHc53Pya9pMrpS6JNy30vsAeY8wPxphCYAEw5rxt7gNmGWNOAxhjTvi2zMr169SCv997NSfPFHDbq6s5mJFbH4etvcyD8N4keGM45Jyw+snv/TfE9bG7MqVUAPMm0GOAQ+Vep3mWlXcFcIWI/EdE1ojI8Mp2JCJTRCRVRFLT09MvreLz9O4Qzfz7+pFTUMxtr65mb3qOT/ZbJwpy4POn4cUU+P5TGPKY9pMrpXzGVykSBHQGhgATgNdE5IJBRIwxc4wxKcaYlFatWvno0NA9NooFU/pR7HYz7tU1fH/sjM/27RNuN2x8B17sBV9Ph6Qx8NB6GDJN+8mVUj7jTaAfBuLKvY71LCsvDVhmjCkyxuwDdmEFfL3p0jaSBVN+hNMB4+esZuvhrPo8fNXO9ZN/8AuIiivXT64TJiulfMubQF8HdBaRjiISDIwHlp23zVKs1jki0hKrC+YHH9ZZZs/nMLMXvHMbfPp7WPe6Ndt81mEubxXBwvt/RHhwEBNeW8OGg6frpASvnD5Q1k9+Nh1umqv95EqpOlXjjUXGmGIReRD4DHAC84wx20TkKSDVGLPMs+56EdkOlAC/NcZk1EnFIU2tqdEy9sD+r6Go3IlQVzgdml/Gv+MSeH9/KO/N/ZLgUdfSLbkXhEXXSTkXKDgD3/wfrHrJmkxiyGPQ/2EIDq+f4yulGi0xxthy4JSUFJOamlq7nRhjjQWesceamT5jr/U8Yw/m9H7ElJRtG94CWlzueVxW9rx5J3CF1a4OsPrJN82Hz5+CnOOQPA6GPa5dK0opnxKR9caYlMrWBdyt/xWIQGR769HxmoqrSoo4dXg3L/zjE0Kz93Fn2yJi3Ydh7wr47p2K+4mKqxjy5x7N4r2bFPnAKmt88qObILYPjJ8PsZV+3kopVWcCu4XuhczcQu6e9y3bjmQzc0JPRnZvZ10+eOoHyKjYqufkHigodzLVGQzRHS9s1be4HJq0hswD1rgr25dCZAxc9xR0u9n6RaOUUnWguhZ6gw90gOz8In72xjo2HDzN/7vtKm7sWcWdmMZAbkZZwJc+9lqPknLjxgQ3tV47gmDAo9D/Ie0nV0rVuYbb5eKlyFAXf/tZX+57K5VfLdxEQZGb8X3jL9xQxJrGLaIlxPeruM5dAllp5QJ+j3XSs/9D2k+ulPILjSLQASJCgpg3qQ8/f3s90xZvoaDYzd39E7zfgcMJ0R2sx+XD6qxOpZS6VI3qfvNQl5NX7+zN9UlteHzZNl79aq/dJSmllM80qkAHCAlyMmtiL264qj3/88lOZizfhV3nEZRSypcaTZdLeS6ngxnjehAS5GDG8t3kF7n53fArEb06RSkVwBploAM4HcJfb04m1OVg9ld7yS8q4fEbkjTUlVIBq9EGOoDDITw9phshQU5e/2YfBcUlPDu2Ow6HhrpSKvA06kAHEBH+OCqRMJeTl1bsoaDIzV9vSSbI2ehOLyilAlyjD3SwQv03P7mSUJeD6f/aRUGxmxnje+DSUFdKBRAN9HIe/HFnQl1OnvloBwXFJbx0ey9CXV6M5aKUUn5Am6DnmTyoE0+P7cbyHSe4761U8gpLan6TUkr5AQ30StzZrwN/vSWZb/acZNIb35JTUGx3SUopVSMN9CrclhLHjHE9SD1wmrteX0tWXpHdJSmlVLU00KsxpkcMs27vxZbDWUycu4bTZwvtLkkppaqkgV6D4d3aMufOFHYdz2H8nDWknymo+U1KKWUDDXQvDO3Smjcm9eHgqVzGzVnNsax8u0tSSqkLaKB7acDlLXnr3r6cyC7gtldXc+hUbs1vUkqpeuRVoIvIcBH5XkT2iMi0ara7WUSMiDTICTX7JDTn7clXk5lbyLhXV7Pv5Fm7S1JKqVI1BrqIOIFZwAggCZggIkmVbNcUeARY6+si/UmPuGa8O6Uf+cVubp29mvUHTtldklJKAd610PsCe4wxPxhjCoEFwJhKtnsa+AvQ4DuYu7aPYuH9/YgIcTJ+zhoWfHvQ7pKUUsqrQI8BDpV7neZZVkpEegFxxpiPfFibX7u8dVOWPTCQfp1aMG3xFv64dAuFxW67y1JKNWK1PikqIg7geeDXXmw7RURSRSQ1PT29toe2XVS4izfv6cv913Ti7TUHuWPuWr2sUSllG28C/TAQV+51rGfZOU2BbsCXIrIf6Acsq+zEqDFmjjEmxRiT0qpVq0uv2o84HcJjIxN5YXwPNqVlMvqlb9iSlmV3WUqpRsibQF8HdBaRjiISDIwHlp1baYzJMsa0NMYkGGMSgDXAaGNMap1U7KfG9Ijh/an9cYhwy+xVLNmYZndJSqlGpsZAN8YUAw8CnwE7gIXGmG0i8pSIjK7rAgNJt5golj04gB5xzfjlPzbxzIfbKS7RfnWlVP0Qu2a8T0lJMampDbMRX1Ti5pkPt/O31QcYeHlLXpzQk+iIYLvLUko1ACKy3hhT6b0+eqdoHXA5HTw5pht/vTmZb/edYvSsb9h5LNvuspRSDZwGeh26rU8cC+7vR0GRm5teXsUnW47aXZJSqgHTQK9jveKj+fChgVzZtilT39nA9M++x+22p5tLKdWwaaDXg9aRoSyY0o9xKXG8tGIPk99KJTtfJ8xQSvmWBno9CQly8tzN3Xl6TFdW7kpn7Kz/sDc9x+6ylFINiAZ6PRIR7vxRAm9Pvpqs3CLGvvQfPt9x3O6ylFINhAa6Dfp1asGyhwYS3yKcyW+l8tIXu7Hr8lGlVMOhgW6TmGZhLPp5f0Zf1Z7p/9rFA/M3cLag2O6ylFIBTAPdRmHBTmaM68EfRiby6dZj3PzKKg5m6ExISqlLo4FuMxHhvms68eY9fTmalZ0cDcoAAAx+SURBVM8NL33DN7tP2l2WUioAaaD7iWuuaMWyBwfQNjKUu+atZe7XP2i/ulLqomig+5EOLSJY/Iv+XJ/Ulmc+2sGvFm4iv6jE7rKUUgFCA93PRIQE8fLEXvz6uitYsvEwt8xexeHMPLvLUkoFAA10P+RwCA8N68zcu1LYfzKX0S9+w7f7dDJqpVT1NND92LVJbVj6QH8iw1zc/toa/r7mgParK6WqpIHu5y5v3ZSlDwxgUOeW/GnpVn6/ZAsFxdqvrpS6kAZ6AIgKczH37j48MPQy3v32ELe/tpYT2fl2l6WU8jMa6AHC6RB++5MuzLq9F9uPZHPDS9+w8eBpu8tSSvkRDfQAMyq5He9P7Y/L6WDcq2t4L/WQ3SUppfyEBnoASmofyT8fHEhKQjS/XbSZX/3jO7YezrK7LKWUzYLsLkBdmuiIYN76WV+m/2sXb67ax+KNh0mOjWJC33huuKo9TUL0v1apxka8uQxORIYDLwBOYK4x5rnz1v8KmAwUA+nAz4wxB6rbZ0pKiklNTb3UulU5WXlFLN14mPlrD/L98TNEBDsZ0zOG2/vG0y0myu7ylFI+JCLrjTEpla6rKdBFxAnsAq4D0oB1wARjzPZy2wwF1hpjckVkKjDEGDOuuv1qoPueMYYNBzN599uDfLj5CPlFbm21K9XA1DbQfwQ8YYz5ief1YwDGmP+pYvuewEvGmAHV7VcDvW5pq12phqm6QPemyRYDlL+UIg24uprt7wU+qaKQKcAUgPj4eC8OrS5VVJiLu/sncNePOpS22hdvSGP+2oPaaleqgfKmhX4LMNwYM9nz+k7gamPMg5VsewfwIDDYGFNQ3X61hV7/tNWuVOCrbQv9MBBX7nWsZ9n5B7kW+ANehLmyh7balWrYvGmhB2GdFB2GFeTrgNuNMdvKbdMTWITVkt/tzYG1he4ftNWuVGCp1UlRzw5GAjOwLlucZ4x5VkSeAlKNMctEZDnQHTjqectBY8zo6vapge5fKrtCpntMFLdfra12pfxJrQO9Lmig+6/KWu2je8Qw8WpttStlNw10dUm01a6U/9FAV7WmrXal/IMGuvKZqlrtE/rGM+TKVrSNDMXhELvLVKrB0kBXdeL8VjtAsNNBbPMw4puHlz7imofToUU4cdHhRGg3jVK1ooGu6pQxhs1pWWw7ks2BU2c5dCqXg6dyOZCRy5n84grbtmwSTJwn6Dt4wj6+eTjxLcJp01Rb90rVpLY3FilVLRHhqrhmXBXX7IJ1mbmFHPQE/MFTuRzMsL6uP3Caf246grtceyI4yEFcdNh5LfsIz/MwwoP121Wp6uhPiKpTzcKDaRYeTHLshWFfVOLm8Om80rAv37Jft/80OQXnt+5DiG8eRocWEWUte8+jddMQbd2rRk8DXdnG5XSQ0DKChJYRF6wzxpCZW2QF/Lmw97Tuv913iqXfHaZ8b2FIkKM05Du3aUJSu0gS20XSqWUEQU6dmEs1Dhroyi+JCNERwURHBFfalVNY7OZwZl65rpyzpa37r3enU1RipX1wkIMr2jQhsa0V8IntIklqF0lUuKu+/0lK1TkNdBWQgoMcdGwZQcdKWveFxW72puew42i253GGL3ae4L31aaXbxDQLI7Fd09KQT2wXSYfm4dptowKaBrpqcIKDHKUhfY4xhvQzBWz3BPy5sP9i54nSE7PhwU66tK0Y8l3aNtVLLVXA0MsWVaOWX1TCruNnSlvy2z1Bf+5ySxHo0Dy8QsgntY+kfVQoItqaV/VPL1tUqgqhLifJsc0qXIVjjOFwZl6Flvz2o9l8svVY6TaRoUEV+uQT20XSuU0TQl1OO/4ZSgEa6EpdQESIjQ4nNjqc65LalC7PKSjm+2PZbC8X9AtTD5FbWAKA0yF0ahlhddW0a0psdDjtokJpGxlK68gQQoI07FXd0kBXyktNQoLo3aE5vTs0L13mdhsOnMotdwI2m9T9p1i26cgF72/ZJJi2noBvGxVKu6iw0ufW61C9eUrVin73KFULDoeUXm0zsnu70uVn8os4lpXP0ax8jmXlcyz73PM80k7nsf7AaU7nFl2wv8jQIE/Ah9GuXNifC/x2kWFEhgVp/72qlAa6UnWgaaiLpqEuOrdpWuU2+UUlpaF/vFzgn3u982g26TkFnH/dQqjLUdq6bxcVShtP2Fuvw2gTFULLCL1ztjHSQFfKJqEuZ5V3yp5TVOLmxJkCjmXlcSyrgKNZedYvgex8jmfls3bfKY5n51Psrpj6LqfQumkorZqGEBHiJMwVRHiwk/BgJ6EuZ+nzsGBreZjLSVhwueWuoNLXYcFOwl1OveM2AGigK+XHXE4HMc3CiGkWVuU2brfh5NkCjp8LfE9r/3hWPuk5BeQWlnDqbB55hcXkFpaQV1RCXmHJBb8EahLsdBDqchB+7pfABb8ggkrDP6zcL4Lw4CBCXA5CghwEBzkIdjpxOcV6HuRZ7nTiChKCnY7S5cFOh3YtXSQNdKUCnMNhtcZbNw2le6z3s0cVFrvJKywht8gT9J6wt55XDP/cwrLlZdtYX7PzizmenV9h27yikgu6ii6Fy1kW8q7zwj6kkmWuIAchlSwr/UXhdOB0CC6nEFT+ucOByyk4HQ6CnILLUXG7IIcQVGE7wVW6vGy9y+GwtavLq0AXkeHAC4ATmGuMee689SHAW0BvIAMYZ4zZ79tSlVK+dC70ovD9uDbGGPKL3J7wLya/qITCYkNhiZvCYjdFnq8FxW4KS9wUeb4WFnseJRW/FpVbV3De9kUlbs4WFJftq/x+it0UlVjHrS8i4PL8Yigf+C7PL5AgpzChTzz3XdPJ58euMdBFxAnMAq4D0oB1IrLMGLO93Gb3AqeNMZeLyHjgL8A4n1erlAoIIlLa7dI8ItjucjDGeMLeUFJiKHK7KS4xFJf7WlRiKHEbikrcFHu+lrgNxSVly4rdhuIS6z1Fbrdne88yz7bn9lW6zHMMa/9uityGVk1D6uTf6U0LvS+wxxjzA4CILADGAOUDfQzwhOf5IuAlERFj17gCSilVjogQEuSkoQ/L481p6xjgULnXaZ5llW5jjCkGsoAWvihQKaWUd+r1OiQRmSIiqSKSmp6eXp+HVkqpBs+bQD8MxJV7HetZVuk2IhIERGGdHK3AGDPHGJNijElp1arVpVWslFKqUt4E+jqgs4h0FJFgYDyw7LxtlgF3e57fAnyh/edKKVW/ajxFYIwpFpEHgc+wLlucZ4zZJiJPAanGmGXA68DfRWQPcAor9JVSStUjr875GmM+Bj4+b9mfyz3PB271bWlKKaUuhg7OoJRSDYQGulJKNRC2zSkqIunAgUt8e0vgpA/LCXT6eVSkn0cZ/SwqagifRwdjTKWXCdoW6LUhIqlVTZLaGOnnUZF+HmX0s6iooX8e2uWilFINhAa6Uko1EIEa6HPsLsDP6OdRkX4eZfSzqKhBfx4B2YeulFLqQoHaQldKKXWegAt0ERkuIt+LyB4RmWZ3PXYSkTgRWSEi20Vkm4g8YndNdhMRp4hsFJEP7a7FbiLSTEQWichOEdkhIj+yuya7iMgvPT8jW0XkXREJtbumuhBQgV5u9qQRQBIwQUSS7K3KVsXAr40xSUA/4IFG/nkAPALssLsIP/EC8KkxpgtwFY30cxGRGOBhIMUY0w1rTKoGOd5UQAU65WZPMsYUAudmT2qUjDFHjTEbPM/PYP3Anj/5SKMhIrHAKGCu3bXYTUSigGuwBs7DGFNojMm0typbBQFhnuG9w4EjNtdTJwIt0L2ZPalREpEEoCew1t5KbDUD+C+g/mYE9l8dgXTgDU8X1FwRibC7KDsYYw4D04GDwFEgyxjzL3urqhuBFuiqEiLSBHgfeNQYk213PXYQkZ8CJ4wx6+2uxU8EAb2AV4wxPYGzQKM85yQi0Vh/yXcE2gMRInKHvVXVjUALdG9mT2pURMSFFebvGGMW212PjQYAo0VkP1ZX3I9F5G17S7JVGpBmjDn3F9sirIBvjK4F9hlj0o0xRcBioL/NNdWJQAt0b2ZPajRERLD6SHcYY563ux47GWMeM8bEGmMSsL4vvjDGNMhWmDeMMceAQyJypWfRMGC7jSXZ6SDQT0TCPT8zw2igJ4i9muDCX1Q1e5LNZdlpAHAnsEVEvvMs+71nQhKlHgLe8TR+fgDusbkeWxhj1orIImAD1pVhG2mgd4zqnaJKKdVABFqXi1JKqSpooCulVAOhga6UUg2EBrpSSjUQGuhKKdVAaKArpVQDoYGulFINhAa6Uko1EP8fA9qmf9RLRA0AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "iterarions = [i for i in range(10)]\n",
        "xpoints = np.array(iterarions)\n",
        "train_ypoints = np.array(history[\"train_acc\"])\n",
        "val_ypoints = np.array(history[\"val_acc\"])\n",
        "\n",
        "plt.plot(iterarions, train_ypoints, label = \"train acc\")\n",
        "plt.plot(iterarions, val_ypoints, label = \"validation acc\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "reFsi7a6VARq",
        "outputId": "d6cc410e-76e0-4ceb-e262-12c4d39a2bed"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXyU9b33/9cne0JCyEbAJJCAQVZliUiLC9aCoFasS13vY9vT8muPS5dzem7auhX1V4+/tsd6H9tTammPva0cb3qr2LLUBUVbrQQVGMIelgQSCCSQBLJN5vP745okkxDIJEy4JpPP8/G4HjPXNvOZQd9z5Xtd1/crqooxxpjIFeV2AcYYY/qXBb0xxkQ4C3pjjIlwFvTGGBPhLOiNMSbCxbhdQFeZmZman5/vdhnGGDOgbNy48aiqZnW3LuyCPj8/n+LiYrfLMMaYAUVE9p9pXY9NNyKyTESOiIjnDOtFRJ4Vkd0isllEpgesu1dEdvmne/tWvjHGmHMRTBv974D5Z1m/ACj0T4uAXwKISDrwKHAZMBN4VETSzqVYY4wxvddj0KvqeqD6LJssBF5Qx4fAMBEZCVwLvKGq1apaA7zB2X8wjDHG9INQXHWTA5QFzJf7l51p+WlEZJGIFItIcVVVVQhKMsYY0yYsLq9U1aWqWqSqRVlZ3Z40NsYY00ehCPqDQF7AfK5/2ZmWG2OMOY9CEfQrgX/wX30zCzihqhXAWmCeiKT5T8LO8y8zxhhzHvV4Hb2IvATMATJFpBznSppYAFX9T2AVcB2wGzgFfMW/rlpEHgc2+F9qiaqe7aSuMcb0qNWntLT6aG710eL10dKqNHv98wFTs1cDtmlb72zbvk2rjxav0urzISJEiRAlEBUliNAxf9q6wOV03lcC9w1c7yyLjjrz+uSEGCZdkBry76zHoFfVO3tYr8B9Z1i3DFjWt9KMMf2hsaWVw7WNNHl9eFsVr8+H16e0+hRvq//R5/M/asCjr319i09pbfV1WR+wnU9pbQ1c7gt47c7LOgLaH+DeziHcEdLONq2+yB1DY2reMF69b3bIXzfs7ow1xpwbb6uPihONlNWcory6gfKaU5TVNFBWfYqymlMcrm3q1/ePiXKOWtsfo6M6zccGzEeJEBcTRVx0FImx0QxNiCE2OopY/7LYaGd9bHTbvP95TOd1sf5t4zvNRxEXI8RFRxMbI11eo/O+0VGCqqIKPlV8/se2+VZV1Ne2zlmvAdv5ut03YH2XfTut93W83pD4/olkC3pjBhhVpaquibKaU5RVdwR4eU0DZTWnOHS8sdNRb5TAyNREctMSuaIwi7y0JHLSEkmMje4I4Ojug9h57DIf3Xl5bMB8WzPEQCRtTS4MzPrPxoLemDCjqpxoaHFCvOZUe5CX+Y/Oy2saaPL6Ou2TlRJPXloi0/LSuPGSRPLSkshLTyIvLYmRwxKIjQ6LK6mNSyzojXHBySZve9NK+5G5P9TLaxqob/J22j41MZa89ETGZafwufHD20M8Lz2R3LQkEmKjXfokZiCwoDemn6gqlbWN7Dxcz67Ddew8XMfOw/UcqD5F9cnmTtsmxkaTl+4cic8ak0FumhPgeemJ5KUnMTQh1qVPYSKBBb0x56itzXyHP8jbQn3XkXrqGjuOzDOT4ygcnsK1k0a0h3pumhPkGUPiBmzbtgl/FvTGBElVOVrf3HF0fqQt1Os50dDSvl1aUizjslO4aWoO47KTKcxOYVx2CulD4lys3gxmFvTGdKP6ZLNzVO4P8p3+cK851RHoqYmxjMtO5vqLRzJueDLjslMozE4hM9mOzk14saA3g9qJUy3sPFLHjsqOUN91pI6j9R1t6CnxMRRmJzN/8ggKhztH5+Oyk8lKibdANwOCBb0ZFGobWzodne/yPx6p67h5aEhcNIX+q1rajs7HZSczYmiCBboZ0CzoTURpafVRWnWS7ZW17KisY3ulc7R+8HhD+zaJsdEUZidzRWEW47KdJpdxI1K4INUC3UQmC3ozIKkqFSca2VFZxzZ/qO+orGNPVT0trc5doTFRwtisZGaMTuPuWaO4yH9SNGdYIlFRFuhm8LCgN2GvtrGFnZV1bKusY0fAkXrgpYsXpCZw0YgUrh4/nPEjUrhoRApjMpOJi7E7Qo2xoDdho9nro/Rofacml67NLinxMVw0IoWFUy/gohFDGT/COUpPTbQbiow5Ewt6c96pKodONLKjsrZToJ+t2cU5Sh9q7ejG9IEFvelXTd5WNpef8Ae6NbsY4wYLetNv3tlxhIdf81BW7TS9WLOLMe6woDchV3mikcf/VMKft1QwNmsIv7h7OpfkDbNmF2NcElTQi8h84OdANPC8qj7VZf1onCEDs4Bq4B5VLfevawW2+Dc9oKo3hqh2E2a8rT5+/+F+fvqXnbS0+viXeeNYdOVYa4IxxmXBDA4eDTwHzAXKgQ0islJVSwI2+wnwgqr+l4h8Dvgx8D/86xpUdWqI6zZhZlPZcX746hY8B2u5alwWSxZOYnTGELfLMsYQ3BH9TGC3qpYCiMhyYCEQGPQTge/6n68DXg1lkSZ81Ta28JO1O/j9h/vJSo7nubumc92UEdZEY0wYCSboc4CygPly4LIu22wCbsZp3vkikCIiGap6DEgQkWLACzylqqf9CIjIImARwKhRo3r9Icz5p6q8vrmCx/9UwrH6Ju79TD7/PG8cKTZAhjFhJ1QnY/8F+A8R+TKwHjgItPrXjVbVgyIyBnhbRLao6p7AnVV1KbAUoKioSDFhbd/Rkzz8mof3dh3l4txUlt17KVNyU90uyxhzBsEE/UEgL2A+17+snaoewjmiR0SSgVtU9bh/3UH/Y6mIvANMAzoFvRkYmryt/Oc7pTz3zm7io6NYsnASd182mmjrN8aYsBZM0G8ACkWkACfg7wDuCtxARDKBalX1Ad/HuQIHEUkDTqlqk3+b2cDTIazfnCd/3X2Uh1/1UHr0JF+45AIevn4Cw4cmuF2WMSYIPQa9qnpF5H5gLc7llctUdauILAGKVXUlMAf4sYgoTtPNff7dJwC/EhEfEIXTRl9y2puYsFVV18STfy7h1U8PMTojiRe+OpMrx2W5XZYxphdENbyaxIuKirS4uNjtMgY9n0/5w0cHeHrNdhpbfHxjzlj+ac5YEmKj3S7NGNMNEdmoqkXdrbM7Y81pth46wQ9f8fBp2XE+OzaDx2+azNisZLfLMsb0kQW9aVff5OXf39jJb/+6l/QhcTxz+1QWTr3Arok3ZoCzoDeoKmu3HuZHr2+lsraRu2aO4l+vHU9qkl0Tb0wksKAf5MqqT/HYyq28tf0IE0YO5bm7pzN9VJrbZRljQsiCfpBq9vp4/v1Snn1rF1EiPHT9BL782Xxioq0DMmMijQX9IPTR3moeenULOw/XM3/SCB75wkQuGJbodlnGmH5iQT+IVJ9s5qnV23i5uJycYYn85t4irpmQ7XZZxph+ZkE/CPh8yoqPy/nxqm3UNXr5xlVjefCaC0mKs39+YwYD+z89wu08XMdDr3j4aF81l+an8cRNU7hoRIrbZRljziML+gjV2NLKz9/axa/Xl5KcEMPTt1zMrTNyibIOyIwZdCzoI9Tjfyrhxb8f4LYZuXz/ugmkD4lzuyRjjEss6CPQJwdq+MNHB/jq7AIe+cJEt8sxxrjMLpqOMN5WHw+96mF4SjzfmVvodjnGmDBgQR9h/veH+9l6qJaHb5how/oZYwAL+ohypLaRn/5lJ1cUZnL9lJFul2OMCRMW9BHkiT9vo6nVx5KFk63HSWNMOwv6CPH+rqOs3HSIb141loLMIW6XY4wJIxb0EaDJ28ojr3kYnZHEN+eMdbscY0yYCSroRWS+iOwQkd0isrib9aNF5C0R2Swi74hIbsC6e0Vkl3+6N5TFG8fSd0spPXqSJQsn21B/xpjT9Bj0IhINPAcsACYCd4pI14uzfwK8oKoXA0uAH/v3TQceBS4DZgKPioh1dh5CB46d4j/W7eb6KSO5ygbtNsZ0I5gj+pnAblUtVdVmYDmwsMs2E4G3/c/XBay/FnhDVatVtQZ4A5h/7mUbcEaGenSlh5go4eEb7MYoY0z3ggn6HKAsYL7cvyzQJuBm//MvAikikhHkvqaP1m49zLodVXxn7jhGpCa4XY4xJkyF6mTsvwBXicgnwFXAQaA12J1FZJGIFItIcVVVVYhKimwnm7z86PWtjB+Rwpc/m+92OcaYMBZM0B8E8gLmc/3L2qnqIVW9WVWnAT/0LzsezL7+bZeqapGqFmVlWTtzMJ59axcVJxp58ouTbfg/Y8xZBZMQG4BCESkQkTjgDmBl4AYikikiba/1fWCZ//laYJ6IpPlPws7zLzPnYEdlHb95fy+3F+UxY3S62+UYY8Jcj0Gvql7gfpyA3ga8rKpbRWSJiNzo32wOsENEdgLZwJP+fauBx3F+LDYAS/zLTB+pKg+9uoWUhBgWLxjvdjnGmAEgqG6KVXUVsKrLskcCnq8AVpxh32V0HOGbc7RiYzkb9tXwb7dMIc36mDfGBMEadweQ46ea+fHq7cwYncZtM/J63sEYY7CgH1D+bc0OTjS08MRNk21IQGNM0CzoB4iPD9SwfMMBvvLZfCaMHOp2OcaYAcSCfgDwtvp46BUP2SkJfHvuOLfLMcYMMBb0A8DvP9xPSUUtj3xhIsnxNsyvMaZ3LOjD3GH/qFFXjstiweQRbpdjjBmALOjD3BN/3kZzq48lN06yUaOMMX1iQR/G3ttVxeubDvFPc8aSb6NGGWP6yII+TDmjRm0lPyOJb1xlo0YZY/rOzuyFqV+9W8reoyd54aszbdQoY8w5sSP6MLT/2Eln1KiLR3KljRpljDlHFvRhxhk1aiuxUcLD19uoUcaYc2dBH2bWbq3knR1VfHfeRTZqlDEmJCzow4gzalQJE0YO5d7PjHa7HGNMhLCgDyM/948a9cRNNmqUMSZ0LE3CxPbKWn7z/l7uuDSPGaPT3C7HGBNBLOjDgM+nPPSKh6EJMfzP+TZqlDEmtCzow8CKj8sp3l/D9xdMsFGjjDEhZ0HvspqTzfx41TaKRqdx64xct8sxxkSgoIJeROaLyA4R2S0ii7tZP0pE1onIJyKyWUSu8y/PF5EGEfnUP/1nqD/AQPf02u3UNnp53EaNMsb0kx67QBCRaOA5YC5QDmwQkZWqWhKw2UPAy6r6SxGZiDOQeL5/3R5VnRrasiPDxwdqeOmjMr5+RYGNGmWM6TfBHNHPBHaraqmqNgPLgYVdtlGgLalSgUOhKzEyeVt9/PAVDyOGJvCtz9uoUcaY/hNM0OcAZQHz5f5lgR4D7hGRcpyj+QcC1hX4m3TeFZErunsDEVkkIsUiUlxVVRV89QPYCx/sZ1tFLY/aqFHGmH4WqpOxdwK/U9Vc4Drg9yISBVQAo1R1GvBd4A8iclobhaouVdUiVS3Kyor8TrwO1zbyszd2ctW4LObbqFHGmH4WTNAfBPIC5nP9ywL9I/AygKp+ACQAmarapKrH/Ms3AnuAQd9O8fifSpxRoxbaqFHGmP4XTNBvAApFpEBE4oA7gJVdtjkAXAMgIhNwgr5KRLL8J3MRkTFAIVAaquIHovd2VfGnzRXcN+dCRmfYqFHGmP7XY+OwqnpF5H5gLRANLFPVrSKyBChW1ZXAPwO/FpHv4JyY/bKqqohcCSwRkRbAB3xDVav77dOEucaWVh5+1UNB5hD+n6vGuF2OMWaQCOosoKquwjnJGrjskYDnJcDsbvb7I/DHc6wxYvzq3VL2HTvF7//RRo0yxpw/dmfsebL/2Emee2c3N1w8kisKI/+EszEmfFjQnweqyiOvbSUuOoqHb7BRo4wx55cF/XmwxlPJuzur+O7ccWQPtVGjjDHnlwV9P6v3jxo1ceRQ/sFGjTLGuMBuyexnP39zJ5W1jfzinuk2apQxxhWWPP1oW0Uty/66jztn5jF9lI0aZYxxhwV9P/H5lIde9ZCaGMu/XmujRhlj3GNB309WbCxn4/4aFi8Yb6NGGWNcZUHfD2pONvPj1du4ND+NW6fbqFHGGHdZ0PeDf1tjo0YZY8KHBX2IlRyqZfmGMv7x8gLGj7BRo4wx7rOgD7HXNh0kJkr4pzlj3S7FGGMAC/qQUlXWeCr57IWZDEuyE7DGmPBgQR9C2yrq2H/sFAts1ChjTBixoA+hNZ4KogTmTcx2uxRjjGlnQR9Cqz2VzCxIJyM53u1SjDGmnQV9iOw+UseuI/UsmDzS7VKMMaYTC/oQWb2lEoBrJ1n7vDEmvAQV9CIyX0R2iMhuEVnczfpRIrJORD4Rkc0icl3Auu/799shIteGsvhwstpTyYzRaYxItf7mjTHhpcegF5Fo4DlgATARuFNEug6T9BDwsqpOA+4AfuHfd6J/fhIwH/iF//UiyoFjpyipqLWrbYwxYSmYI/qZwG5VLVXVZmA5sLDLNgq03QaaChzyP18ILFfVJlXdC+z2v15EWe2pAKzZxhgTnoIJ+hygLGC+3L8s0GPAPSJSDqwCHujFvojIIhEpFpHiqqqqIEsPH6s9lUzJSSUvPcntUowx5jShOhl7J/A7Vc0FrgN+LyJBv7aqLlXVIlUtysrKClFJ58eh4w18Wnac+dZsY4wJU8EMJXgQyAuYz/UvC/SPOG3wqOoHIpIAZAa574C2xuNcbWPt88aYcBXMUfcGoFBECkQkDufk6sou2xwArgEQkQlAAlDl3+4OEYkXkQKgEPgoVMWHgzWeSi7KTmFMVrLbpRhjTLd6DHpV9QL3A2uBbThX12wVkSUicqN/s38Gvi4im4CXgC+rYyvwMlACrAHuU9XW/vggbjhS18iG/dUsmGJH88aY8BVM0w2qugrnJGvgskcCnpcAs8+w75PAk+dQY9j6y9bDqGJ3wxpjwprdGXsO1ngqGZM5hHHZ1mxjjAlfFvR9VHOymQ9KjzF/8ghEbLhAY0z4sqDvozdKDtPqU2u2McaEPQv6PlrtqSA3LZHJOTYurDEmvFnQ90FtYwvv7z7K/EnWbGOMCX8W9H3w9rYjtLQqC6ZYs40xJvxZ0PfBak8F2UPjmZY3zO1SjDGmRxb0vXSq2cu7O6uYP2kEUVHWbGOMCX8W9L30zo4qGlt8zLerbYwxA4QFfS+t2lJBxpA4Zhaku12KMcYExYK+FxpbWlm3/QjzJmUTbc02xpgBwoK+F97bdZSTza12k5QxZkCxoO+F1Z4KUhNj+czYDLdLMcaYoFnQB6nZ6+PNksN8fkI2sdH2tRljBg5LrCB9UHqM2kavjSRljBlwLOiDtMZTwZC4aC4vzHS7FGOM6RUL+iB4W32s3XqYz03IJiE22u1yjDGmVyzog/DRvmqqTzZbs40xZkAKKuhFZL6I7BCR3SKyuJv1/y4in/qnnSJyPGBda8C6roOKDwhrPJUkxEYx56Ist0sxxphe63HMWBGJBp4D5gLlwAYRWekfJxYAVf1OwPYPANMCXqJBVaeGruTzy+dT1ngqmTNuOElxQQ2xa4wxYSWY5JoJ7FbVUgARWQ4sBErOsP2dwKOhKc99n5TVcKSuiesmpUPdYWiohoYaOOV/bKg5fVnjCUDdLh2i4yEtHzLGQvpY/+MYSIrw7huaT0L1XqjeA8f2OI/VeyEuGXKLIGeGMyVa76NmcAgm6HOAsoD5cuCy7jYUkdFAAfB2wOIEESkGvMBTqvpqH2sNjdaWgIAODOzqbpddWF2FJ/44ySsbz/yaUTGQmA6JaU6IpoyEqDA4adt8Eso/As8f6fTDkzCsS/j7fwAyxjifYSBoaYDqUn+Ql/pD3f9YV9F52yHDnc93/ADs+gvt30VGoRP8uUWQUwTZkyA69rx/FGP6W6jbIu4AVqhqa8Cy0ap6UETGAG+LyBZV3RO4k4gsAhYBjBo1qm/v3HwSSlb2cMRdA811Z34Nie4I68Q0dOgF/PVIJtGp6VxbNMFZl5jWOdQT05wjxXAeacrbBDX7AoLRf6R74APY8n/o9COQmN4l/AMeE1LPb90tjVCzt3PN1aXOVHuw87ZJmU6NY652frDa6k8fAwkBwz021sKhj6G8GA5uhN1vwaaXnHUxCTByaufwT80N739bY4IgqmdvYhCRzwCPqeq1/vnvA6jqj7vZ9hPgPlX92xle63fAn1R1xZner6ioSIuLi4P+AO1OHoP/b4z/jaKco9a2IG4L5sBwDpzalsUP7fQ/9eby49z4H3/l6Vsv5ktFeb2vaSBoafT/COzpEqh7oba887ZJmQHhP7ZzoCb0cezcth+hTu/tf/8T5XT6EUrK8If32M4/QOlj+v4jpOoc6R8shvKNzuOhT6G1yVmfnO0Efu4MyL0ULpgG8Sl9ey9j+pGIbFTVou7WBXNEvwEoFJEC4CDOUftd3bzJeCAN+CBgWRpwSlWbRCQTmA083fuPEITENHjwE39gp0LUuV85utpTSXSUMHdCdggKDFOxCTB8vDN11dLQpa3bfzRd+m7HUXCbIVndB3D6WIiO6/gx6fRXRSmcKKPzXxRpzj6jPxsQ6v4j8/5oVhKBtNHONPkWZ5m3GQ57nCP+8mIo3wA7/ty2Awyf4LTxtx31D58QHk11xpxBj0Gvql4RuR9YC0QDy1R1q4gsAYpVte2SyTuA5dr5T4QJwK9ExIdzKedTgVfrhFRUlBMGIaLqXG3z2bEZpA2JC9nrDiixiZA90Zm6aj/hWdr5h2D3W1D/YudtJQrU1zGfkOoE+KjLIP2ugB+FMDlRHBMHOdOdaebXnWWnquHgx/4j/2LY/if45PfOurhk50g/MPyHWg+nJnz02HRzvvW56SbEtlfWMv+Z93jyi5O5+7LRbpczsDTVd25b9zZ1bnJJTBv47d6qzg9beXFH+FduAV+Ls35ortPck+Nv7x85FeKS3K3ZRLRzbboZlFZvqUQE5k20u2F7LT4ZRkxxpkgl4vxoZYyFS253lrU0QuXmgPDfACWv+bePdq7qyS2C/Ctg7Ofs8k5z3ljQn8EaTyWX5qeTlRLvdilmoIhNgLyZztSm/khHW//BYtj8f6B4mRP8eZdB4eehcB5kTx74f+WYsGVB3409VfXsOFzHo1/opm3amN5IHg4XLXAmgFavE/i73nCu6X9riTOljIQL/aE/Zk7fr2IyphsW9N1Y46kEYL51YmZCLToGRs1ypmsehrpK2P2mE/olK50TvFExMOozUDgXLpzrXNVjR/vmHNjJ2G7c8L/eIyYqilfvm+1qHWaQaW2Bso9g9xvOEf9hj7N8aG5HE0/BVc45EGO6sJOxvVBWfQrPwVp+cF0315Ub05+iYyF/tjN9/jE4cbDjaH/LH2Hj7yAq1rnHoHCec8SfOc6O9k2PLOi7aGu2WTDZroM2LkvNgRn3OpO3Gco+dEJ/15vwlx8607BRTvNO4TwouALihrhdtQlDFvRdrPZUMOmCoeSl2zXPJozExEHBlc407wmn24bdbzpNPJteguLfOL2V5s/2H+3Pcy79NAYL+k4qTzTy8YHj/Mu8cW6XYszZDRsFRV91Jm8T7P+bE/q734A1i50praCjiSf/cudOZzMoWdAHWONxuredb802ZiCJiYexVzsT/6/TNUXb0f7HL8BHv3J65sy/oiP40wvcrtqcRxb0AVZ7KikcnsyFw+2qBjOApRc4ffTM/LrTMd3+v3Zct7/6e7AapzuK7Emnj0uQPNxO7kYgC3q/o/VNbNhXzf2fK3S7FGNCJzbRuRHrws/Dgn9z+h/a9QbsfReOlMCOVeDzdmwfl+z8UJw2KM1Yp4dS+xEYkCzo/f6y9TA+hQV2k5SJZG3988z6hjPf6oUTB/zdRwf0RFq5Gba9DoFjCMWldIxBENgNdcZYZ6yAgfIj4G06fXQ5b1OP41MMZBb0fqs9FeRnJDF+hA0qYQaR6JiOLqIv7LKutcW5uidwDIHqUjj0idNZW+CPQHxqx7gBgX8N9Gdvpd7m00eRO+PwoAHbtZwK7vXbRpzrNGBR4CBGad0PbBSGI85Z0APHTzXzwZ5jfO2KMUiY/QMZ45ro2I6/AArndl7nbfb/COzpPG5veTFsfaX78Qe6DlLfNv5Aaws0HO8y7Gd3Q4G2LTvuLGuuP3PtUTGdQzg1F0ZefObR5aLjofH42ceQrj0Ih7c6z8/63rHdv0e3ywLWxQ3ptx8IC3rgjZLDeH1qzTbGBCsmDjIvdKauvE1Qs7/LoDR74MDfYcsKOo0oFpMI3oYzv0/Xo+qhFzgnkdvHbQ4M0PTzd1Ttber4wTnrXxLVcLwMKjY582f7ayI6zrnr+R9eC3m5FvQ4d8PmDEvk4tzzPPi1MZEoJh6yxjlTV13HCK6rdI74gxzHOWzExENKtjP1Rkvj2ZubhmT1T7n98qoDSF1jC+/tOso9s0Zbs40x/S0mHrIucqbBKDYBYkee96Emz30E7QHu7e1HaG71cd0Ua7YxxkSmoIJeROaLyA4R2S0ii7tZ/+8i8ql/2ikixwPW3Ssiu/zTvaEsPhTWeCoZnhLP9FFpbpdijDH9osemGxGJBp4D5gLlwAYRWamqJW3bqOp3ArZ/AJjmf54OPAoU4ZyB2ejftyakn6KPGppbeWdHFbfOyCUqypptjDGRKZgj+pnAblUtVdVmYDmw8Czb3wm85H9+LfCGqlb7w/0NYP65FBxK7+48QkNLq11tY4yJaMEEfQ5QFjBf7l92GhEZDRQAb/dmXxFZJCLFIlJcVVUVTN0hsWpLJWlJscwsSD9v72mMMedbqE/G3gGsUA28Za5nqrpUVYtUtSgrq38uL+qqydvK29uPMG/iCGKiB/05aWNMBAsm4Q4CeQHzuf5l3bmDjmab3u57Xr2/6yj1TV7m29U2xpgIF0zQbwAKRaRAROJwwnxl141EZDyQBnwQsHgtME9E0kQkDZjnX+a61Z5KUhJimD020+1SjDGmX/V41Y2qekXkfpyAjgaWqepWEVkCFKtqW+jfASxXVQ3Yt1pEHsf5sQBYoqrVof0IvdfS6uONksPMnZBNXIw12xhjIltQd8aq6ipgVZdlj3SZf+wM+y4DlvWxvn7xYekxTjS0MN+utjHGDAKD8nB2taeSpLhorhx3fk78GmOMmwZd0Lf6lL9sreTq8cNJiI12uxxjjOl3g7PtQNYAAA0MSURBVC7oN+yr5mh9s90kZYwZNAZd0K/xVBIfE8XVFw13uxRjjDkvBlXQ+3zKGk8lV43LYkj8oO+h2RgzSAyqtPu0/DiVtY38zymDtC9sY4LQ0tJCeXk5jY2NbpdiupGQkEBubi6xsbFB7zOogn6Np5LYaOFz43s5Kowxg0h5eTkpKSnk5+fbYDxhRlU5duwY5eXlFBQUBL3foGm6UVVWeyqYfWEmqYnB/xIaM9g0NjaSkZFhIR+GRISMjIxe/7U1aIJ+66Fayqob7GobY4JgIR+++vJvM2iCfrWngugoYe5EC3pjzOAyKILeabap5LKCdNKHxLldjjHmLI4fP84vfvGLPu173XXXcfz48Z43HGQGRdDvOlJPadVJFkw5vyOvG2N672xB7/V6z7rvqlWrGDZsWH+UNaANiqtuVm+pRASunWRX2xjTGz96fSslh2pD+poTLxjKo1+YdMb1ixcvZs+ePUydOpW5c+dy/fXX8/DDD5OWlsb27dvZuXMnN910E2VlZTQ2NvKtb32LRYsWAZCfn09xcTH19fUsWLCAyy+/nL/97W/k5OTw2muvkZiY2Om9Xn/9dZ544gmam5vJyMjgxRdfJDs7m/r6eh544AGKi4sRER599FFuueUW1qxZww9+8ANaW1vJzMzkrbfeCul3018GR9B7KigancbwlAS3SzHG9OCpp57C4/Hw6aefAvDOO+/w8ccf4/F42i8pXLZsGenp6TQ0NHDppZdyyy23kJGR0el1du3axUsvvcSvf/1rvvSlL/HHP/6Re+65p9M2l19+OR9++CEiwvPPP8/TTz/NT3/6Ux5//HFSU1PZsmULADU1NVRVVfH1r3+d9evXU1BQQHW16z2uBy3ig37v0ZNsr6zj4Rsmul2KMQPO2Y68z6eZM2d2um782Wef5ZVXXgGgrKyMXbt2nRb0BQUFTJ06FYAZM2awb9++0163vLyc22+/nYqKCpqbm9vf480332T58uXt26WlpfH6669z5ZVXtm+Tnj5wxpqO+Db61Z4KAOt73pgBbMiQIe3P33nnHd58800++OADNm3axLRp07q9rjw+Pr79eXR0dLft+w888AD3338/W7Zs4Ve/+lXE3g0c8UG/xlPJJbmp5AxL7HljY4zrUlJSqKurO+P6EydOkJaWRlJSEtu3b+fDDz/s83udOHGCnJwcAP7rv/6rffncuXN57rnn2udramqYNWsW69evZ+/evQADqukmooO+vOYUm8tP2NU2xgwgGRkZzJ49m8mTJ/O9733vtPXz58/H6/UyYcIEFi9ezKxZs/r8Xo899hi33XYbM2bMIDOzY/zohx56iJqaGiZPnswll1zCunXryMrKYunSpdx8881ccskl3H777X1+3/NNAoZ4PfNGIvOBn+OMGfu8qj7VzTZfAh4DFNikqnf5l7cCW/ybHVDVG8/2XkVFRVpcXNybz3BGz79XyhN/3sa735vD6IwhPe9gjGHbtm1MmDDB7TLMWXT3byQiG1W1qLvtezwZKyLRwHPAXKAc2CAiK1W1JGCbQuD7wGxVrRGRwM7eG1R1au8/yrlb46lkwsihFvLGmEEtmKabmcBuVS1V1WZgObCwyzZfB55T1RoAVT0S2jJ773BtIxsP1FjfNsaYQS+YoM8BygLmy/3LAo0DxonIX0XkQ39TT5sEESn2L7+puzcQkUX+bYqrqqp69QHOZO3WSlSxoDfGDHqhuo4+BigE5gC5wHoRmaKqx4HRqnpQRMYAb4vIFlXdE7izqi4FloLTRh+KglZvqWRs1hAKs1NC8XLGGDNgBXNEfxDIC5jP9S8LVA6sVNUWVd0L7MQJflT1oP+xFHgHmHaONffoWH0Tf997jAWT7WobY4wJJug3AIUiUiAiccAdwMou27yKczSPiGTiNOWUikiaiMQHLJ8NlNDP3ig5jE9hwRRrtjHGmB6DXlW9wP3AWmAb8LKqbhWRJSLSdqnkWuCYiJQA64DvqeoxYAJQLCKb/MufCrxap7+s9lQyKj2JiSOH9vdbGWPCQHJyMgCHDh3i1ltv7XabOXPm0NOl28888wynTp1qn4+Ubo+DaqNX1VXAqi7LHgl4rsB3/VPgNn8Dppx7mcE70dDC3/Yc5auzC2yUHGMGmQsuuIAVK1b0ef9nnnmGe+65h6SkJMDp9jgSRFynZm9tO0xLq1rfNsaEwurFULml5+16Y8QUWHDaPZftFi9eTF5eHvfddx/g3L2anJzMN77xDRYuXEhNTQ0tLS088cQTLFzY+Urvffv2ccMNN+DxeGhoaOArX/kKmzZtYvz48TQ0NLRv981vfpMNGzbQ0NDArbfeyo9+9COeffZZDh06xNVXX01mZibr1q1r7/Y4MzOTn/3sZyxbtgyAr33ta3z7299m3759A6I75IgL+lVbKhmZmsAluTb4gDED0e233863v/3t9qB/+eWXWbt2LQkJCbzyyisMHTqUo0ePMmvWLG688cYz/uX+y1/+kqSkJLZt28bmzZuZPn16+7onn3yS9PR0Wltbueaaa9i8eTMPPvggP/vZz1i3bl2n7hAANm7cyG9/+1v+/ve/o6pcdtllXHXVVaSlpQ2I7pAjKujrm7ys31XFXTNHERVlzTbGnLOzHHn3l2nTpnHkyBEOHTpEVVUVaWlp5OXl0dLSwg9+8APWr19PVFQUBw8e5PDhw4wY0f1f7+vXr+fBBx8E4OKLL+biiy9uX/fyyy+zdOlSvF4vFRUVlJSUdFrf1fvvv88Xv/jF9l40b775Zt577z1uvPHGAdEdckR1arZu+xGavT67ScqYAe62225jxYoV/Pd//3d752EvvvgiVVVVbNy4kU8//ZTs7Ow+dSu8d+9efvKTn/DWW2+xefNmrr/++nPqnnggdIccUUG/xlNJZnI8RfkDZ0AAY8zpbr/9dpYvX86KFSu47bbbAKdL4eHDhxMbG8u6devYv3//WV/jyiuv5A9/+AMAHo+HzZs3A1BbW8uQIUNITU3l8OHDrF69un2fM3WRfMUVV/Dqq69y6tQpTp48ySuvvMIVV1wR9OdxuzvkiAn6xpZW1u04wrWTsom2ZhtjBrRJkyZRV1dHTk4OI0c6Nz7efffdFBcXM2XKFF544QXGjx9/1tf45je/SX19PRMmTOCRRx5hxowZAFxyySVMmzaN8ePHc9dddzF79uz2fRYtWsT8+fO5+uqrO73W9OnT+fKXv8zMmTO57LLL+NrXvsa0acHf++l2d8hBdVN8PvW1m+IjtY08/udt3H3ZKGaNyeh5B2NMt6yb4vAX8m6KB4rhQxP4X3f2e+8Kxhgz4ERM040xxpjuWdAbY04Tbk26pkNf/m0s6I0xnSQkJHDs2DEL+zCkqhw7doyEhIRe7RcxbfTGmNDIzc2lvLycUA0CZEIrISGB3NzcXu1jQW+M6SQ2Nrb9rkwTGazpxhhjIpwFvTHGRDgLemOMiXBhd2esiFQBZ+/E4uwygaMhKmegs++iM/s+OrPvo0MkfBejVTWruxVhF/TnSkSKz3Qb8GBj30Vn9n10Zt9Hh0j/LqzpxhhjIpwFvTHGRLhIDPqlbhcQRuy76My+j87s++gQ0d9FxLXRG2OM6SwSj+iNMcYEsKA3xpgIFzFBLyLzRWSHiOwWkcVu1+MmEckTkXUiUiIiW0XkW27X5DYRiRaRT0TkT27X4jYRGSYiK0Rku4hsE5HPuF2Tm0TkO/7/Tzwi8pKI9K5ryAEgIoJeRKKB54AFwETgThGZ6G5VrvIC/6yqE4FZwH2D/PsA+Bawze0iwsTPgTWqOh64hEH8vYhIDvAgUKSqk4Fo4A53qwq9iAh6YCawW1VLVbUZWA4sdLkm16hqhap+7H9eh/M/co67VblHRHKB64Hn3a7FbSKSClwJ/AZAVZtV9bi7VbkuBkgUkRggCTjkcj0hFylBnwOUBcyXM4iDLZCI5APTgL+7W4mrngH+FfC5XUgYKACqgN/6m7KeF5EhbhflFlU9CPwEOABUACdU9S/uVhV6kRL0phsikgz8Efi2qta6XY8bROQG4IiqbnS7ljARA0wHfqmq04CTwKA9pyUiaTh//RcAFwBDROQed6sKvUgJ+oNAXsB8rn/ZoCUisTgh/6Kq/l+363HRbOBGEdmH06T3ORH53+6W5KpyoFxV2/7CW4ET/IPV54G9qlqlqi3A/wU+63JNIRcpQb8BKBSRAhGJwzmZstLlmlwjIoLTBrtNVX/mdj1uUtXvq2ququbj/HfxtqpG3BFbsFS1EigTkYv8i64BSlwsyW0HgFkikuT//+YaIvDkdEQMJaiqXhG5H1iLc9Z8mapudbksN80G/gewRUQ+9S/7gaqucrEmEz4eAF70HxSVAl9xuR7XqOrfRWQF8DHO1WqfEIHdIVgXCMYYE+EipenGGGPMGVjQG2NMhLOgN8aYCGdBb4wxEc6C3hhjIpwFvTHGRDgLemOMiXD/PxffbCyFucdjAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4rSonLZjzrL"
      },
      "source": [
        "\n",
        "**<font color=red> Complete function</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "dlpDbg0wDqKP"
      },
      "outputs": [],
      "source": [
        "def predict(model, comments, tokenizer, max_len=128, batch_size=32):\n",
        "    data_loader = create_data_loader(comments, None, tokenizer, max_len, batch_size, None)\n",
        "    \n",
        "    predictions = []\n",
        "    prediction_probs = []\n",
        "\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for dl in tqdm(data_loader, position=0):\n",
        "\n",
        "            # Define input_ids, attention_mask, token_type_ids\n",
        "            ##############################################################################################\n",
        "            #                                       Your Code                                            #\n",
        "            ##############################################################################################\n",
        "            input_ids = dl['input_ids']\n",
        "            attention_mask = dl['attention_mask']\n",
        "            token_type_ids = dl['token_type_ids']\n",
        "            \n",
        "            # move tensors to GPU if CUDA is available\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            token_type_ids = token_type_ids.to(device)\n",
        "            \n",
        "            # compute predicted outputs by passing inputs to the model\n",
        "            ##############################################################################################\n",
        "            #                                       Your Code                                            #\n",
        "            ##############################################################################################\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                token_type_ids=token_type_ids)\n",
        "            # convert output probabilities to predicted class\n",
        "            ##############################################################################################\n",
        "            #                                       Your Code                                            #\n",
        "            ##############################################################################################\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "            predictions.extend(preds)\n",
        "            prediction_probs.extend(F.softmax(outputs, dim=1))\n",
        "\n",
        "    predictions = torch.stack(predictions).cpu().detach().numpy()\n",
        "    prediction_probs = torch.stack(prediction_probs).cpu().detach().numpy()\n",
        "\n",
        "    return predictions, prediction_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "RRpWTfwdoWoS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f9214e44a5aa4fb5ac252acb463925f1",
            "72b3e66d4c8b4421b4ee464af1f7d1f9",
            "e6e21363e9a444a6ab31fdd94a8922e5",
            "3da2a692295c4c4b95d604aaae8ad0b7",
            "e5743cd6e7e04deab6c06e228cd12553",
            "4b0fb2d13901413eac9efffecfd5b35e",
            "47d78132d74a4361be7784661e75ffae",
            "7b8304c29b2a457fb2fa9ac164e88d1e",
            "4da9adc5d47d4be8976fc76faf06f53f",
            "9b02b589e30d416e941abf0cf4642e58",
            "e9c919e53a984340a6cf47a594d64eeb"
          ]
        },
        "outputId": "48ea5a65-0bdc-4b5e-ba8c-cc012ab40c20"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/8 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f9214e44a5aa4fb5ac252acb463925f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.5397,  0.9971, -0.8262,  ..., -0.9400,  0.6882, -0.3887],\n",
            "        [-0.7155,  0.9767, -0.8576,  ..., -0.7841,  0.5919,  0.7095],\n",
            "        [ 0.4905,  0.9273,  0.8241,  ...,  0.9015, -0.7864, -0.0895],\n",
            "        ...,\n",
            "        [-0.4293,  0.8832, -0.9012,  ..., -0.8577,  0.5271, -0.0243],\n",
            "        [-0.3067,  1.0000, -0.3072,  ..., -0.7203,  0.4499, -0.7601],\n",
            "        [-0.5749, -0.8885, -0.9168,  ..., -0.8994,  0.3939,  0.6602]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.5766,  0.9697,  0.7474,  ...,  0.8574, -0.8210, -0.0675],\n",
            "        [ 0.6546,  1.0000,  0.9599,  ...,  0.8036, -0.4736, -0.8428],\n",
            "        [-0.0221,  1.0000, -0.3561,  ..., -0.4641,  0.4911, -0.6556],\n",
            "        ...,\n",
            "        [-0.5436,  0.9486, -0.9064,  ..., -0.9188,  0.1940,  0.0546],\n",
            "        [ 0.6469,  0.9855,  0.7892,  ...,  0.8926, -0.8726, -0.1249],\n",
            "        [ 0.0672,  0.8829, -0.5460,  ..., -0.5072,  0.0400, -0.2964]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.6566,  0.1393, -0.9669,  ..., -0.8987,  0.1618,  0.6743],\n",
            "        [-0.7139, -0.1553, -0.9182,  ..., -0.9361,  0.1219,  0.3830],\n",
            "        [-0.1865,  0.9683, -0.6402,  ..., -0.4915,  0.6467, -0.3909],\n",
            "        ...,\n",
            "        [ 0.1351,  1.0000,  0.4008,  ..., -0.6264,  0.2274, -0.6943],\n",
            "        [ 0.1256,  1.0000, -0.2499,  ..., -0.7332, -0.0479, -0.6575],\n",
            "        [ 0.5326,  0.9989,  0.8703,  ...,  0.8499, -0.7738, -0.4856]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3144,  0.9999,  0.1953,  ..., -0.3952, -0.1964, -0.5735],\n",
            "        [ 0.5596,  0.9981,  0.8792,  ...,  0.8867, -0.8222, -0.2135],\n",
            "        [-0.5222,  0.9583, -0.9409,  ..., -0.8674,  0.2637, -0.0490],\n",
            "        ...,\n",
            "        [-0.2706,  0.6369, -0.9375,  ..., -0.7407,  0.2341,  0.3835],\n",
            "        [ 0.6354,  0.9964,  0.6126,  ...,  0.8334, -0.8282, -0.4855],\n",
            "        [-0.7303, -0.7213, -0.9308,  ..., -0.8912,  0.1862,  0.7535]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.7907,  0.0095, -0.9632,  ..., -0.9007,  0.2741,  0.7188],\n",
            "        [ 0.5473,  1.0000,  0.7878,  ...,  0.4029, -0.5866, -0.8898],\n",
            "        [-0.3890,  0.9995, -0.8203,  ..., -0.7898,  0.4756,  0.0988],\n",
            "        ...,\n",
            "        [ 0.6317,  0.9826,  0.8640,  ...,  0.8682, -0.8779, -0.2708],\n",
            "        [ 0.5286,  0.9188,  0.8444,  ...,  0.9163, -0.8577, -0.1242],\n",
            "        [ 0.7908,  0.9997,  0.8034,  ...,  0.8092, -0.8343, -0.3355]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.7608,  0.9996,  0.9174,  ...,  0.8884, -0.6542, -0.5975],\n",
            "        [-0.7214,  0.8767, -0.9153,  ..., -0.8968,  0.2652,  0.6245],\n",
            "        [ 0.5677,  0.9963,  0.6478,  ...,  0.7623, -0.8079, -0.1168],\n",
            "        ...,\n",
            "        [ 0.6705,  0.9887,  0.7450,  ...,  0.8821, -0.8502, -0.3566],\n",
            "        [ 0.6785,  0.9976, -0.2001,  ...,  0.2878, -0.5548, -0.6418],\n",
            "        [ 0.5891,  1.0000,  0.8747,  ...,  0.5052, -0.4287, -0.6177]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.1696,  0.9987, -0.8603,  ..., -0.9320,  0.5765, -0.6073],\n",
            "        [ 0.4588,  0.8609,  0.8003,  ...,  0.8852, -0.8965, -0.1702],\n",
            "        [ 0.5143,  0.9990,  0.7198,  ...,  0.5875, -0.7492, -0.2430],\n",
            "        ...,\n",
            "        [-0.4486,  1.0000, -0.4990,  ..., -0.8831,  0.7567, -0.5737],\n",
            "        [-0.2432,  0.9978, -0.5342,  ..., -0.5214,  0.4936,  0.1037],\n",
            "        [ 0.6099,  0.9973,  0.8534,  ...,  0.8872, -0.8521, -0.3552]],\n",
            "       device='cuda:0')\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[ 0.2094,  0.9995, -0.7758,  ..., -0.8072,  0.4128, -0.5068],\n",
            "        [ 0.0327,  1.0000,  0.4060,  ..., -0.7778,  0.0462, -0.7141],\n",
            "        [-0.7134,  0.9985, -0.3804,  ..., -0.8037,  0.2955,  0.0632],\n",
            "        ...,\n",
            "        [-0.6921, -0.9355, -0.9427,  ..., -0.9132,  0.2240,  0.6744],\n",
            "        [ 0.4857,  0.9995,  0.8913,  ...,  0.8253, -0.7444, -0.3217],\n",
            "        [ 0.5250,  0.9999,  0.4121,  ...,  0.4299, -0.3904, -0.7184]],\n",
            "       device='cuda:0')\n",
            "(250,) (250, 2)\n"
          ]
        }
      ],
      "source": [
        "test_comments = test['comment'].to_numpy()\n",
        "preds, probs = predict(pt_model, test_comments, tokenizer, max_len=128)\n",
        "\n",
        "print(preds.shape, probs.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJ_GfqNck5he"
      },
      "source": [
        "**<font color=red> Evaluate Your Model using f1-score & Precision & Recall</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "ZRL2bgDDpUG0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23da443c-5712-4043-c04f-7c741892deb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1: 0.7358478483606556\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.71      0.73       125\n",
            "           1       0.73      0.76      0.74       125\n",
            "\n",
            "    accuracy                           0.74       250\n",
            "   macro avg       0.74      0.74      0.74       250\n",
            "weighted avg       0.74      0.74      0.74       250\n",
            "\n"
          ]
        }
      ],
      "source": [
        "##############################################################################################\n",
        "#                                       Your Code                                            #\n",
        "##############################################################################################\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_test, y_pred = [label_list.index(label) for label in test['label'].values], preds\n",
        "\n",
        "print(f'F1: {f1_score(y_test, y_pred, average=\"weighted\")}')\n",
        "print()\n",
        "print(classification_report(y_test, y_pred, target_names=label_list))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Obt_Bt3vUqyc"
      },
      "execution_count": 37,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "assignment3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "499f74de07764d43a4164df19b1a0ccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f125474f707f48a589eb3d21da4a95f2",
              "IPY_MODEL_43eff8ce43dd4056b7898a22179aa812",
              "IPY_MODEL_e6bc9ed89a274f88bdbf192d3e2eaddb"
            ],
            "layout": "IPY_MODEL_04e5a3fce56b4ca09f3e2b3af8067623"
          }
        },
        "f125474f707f48a589eb3d21da4a95f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a5bb13585944ef69718c9f3b7fad322",
            "placeholder": "โ",
            "style": "IPY_MODEL_c942290c8bd14ec6b8644a83504b2aa2",
            "value": "Downloading: 100%"
          }
        },
        "43eff8ce43dd4056b7898a22179aa812": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12a3210bbb864414ae7cb9d3361351e3",
            "max": 1198122,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_42cc91115efa47e6bf6121e1e1550731",
            "value": 1198122
          }
        },
        "e6bc9ed89a274f88bdbf192d3e2eaddb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a4d0d26defe40f5b06ee4f901289647",
            "placeholder": "โ",
            "style": "IPY_MODEL_bd891371cd304c81a62be55c2f388a6c",
            "value": " 1.14M/1.14M [00:00&lt;00:00, 4.07MB/s]"
          }
        },
        "04e5a3fce56b4ca09f3e2b3af8067623": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a5bb13585944ef69718c9f3b7fad322": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c942290c8bd14ec6b8644a83504b2aa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12a3210bbb864414ae7cb9d3361351e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42cc91115efa47e6bf6121e1e1550731": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a4d0d26defe40f5b06ee4f901289647": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd891371cd304c81a62be55c2f388a6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ff4ae5966814bc89dc823fdda0f7ce6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d8080f487384783a2aec63391331610",
              "IPY_MODEL_09f8f12214bb4675800dbfee6cd2038c",
              "IPY_MODEL_33ec7bccf44d40e195b90861f561bd4b"
            ],
            "layout": "IPY_MODEL_b6da6ffdece54ea69fff9929fdf467ad"
          }
        },
        "1d8080f487384783a2aec63391331610": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf2995046fad4709ac48cbcc42d1c394",
            "placeholder": "โ",
            "style": "IPY_MODEL_7d87c212aa1c48c3b666af39e794547c",
            "value": "Downloading: 100%"
          }
        },
        "09f8f12214bb4675800dbfee6cd2038c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2939d19010ba4caeb56e973373bfc80f",
            "max": 440,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a61c30e0a3a64185939b9fa537355712",
            "value": 440
          }
        },
        "33ec7bccf44d40e195b90861f561bd4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36bc92e1736a48faa3174c5ba6994c10",
            "placeholder": "โ",
            "style": "IPY_MODEL_a44e0a294e7648fa995c326f66950342",
            "value": " 440/440 [00:00&lt;00:00, 5.16kB/s]"
          }
        },
        "b6da6ffdece54ea69fff9929fdf467ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf2995046fad4709ac48cbcc42d1c394": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d87c212aa1c48c3b666af39e794547c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2939d19010ba4caeb56e973373bfc80f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a61c30e0a3a64185939b9fa537355712": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "36bc92e1736a48faa3174c5ba6994c10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a44e0a294e7648fa995c326f66950342": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b37ce85d0ba4f74a75d65deb066614a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_999dd428264d447093b79a430cf006a9",
              "IPY_MODEL_fa84b3deee9a449499955067e565cf48",
              "IPY_MODEL_376d97cf555949e2847ba49c741aff5d"
            ],
            "layout": "IPY_MODEL_1ee8ce0c6edd402f8b0d4a96fe8466e9"
          }
        },
        "999dd428264d447093b79a430cf006a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d894ebbcafd14e2a957365a250eb6a54",
            "placeholder": "โ",
            "style": "IPY_MODEL_73f690b312e142a9ba59fff9adefc5b7",
            "value": "Downloading: 100%"
          }
        },
        "fa84b3deee9a449499955067e565cf48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1258cddfc7244ad8b472519a1518ed5c",
            "max": 654226731,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_09839934638340d09ffaa0e1876b7656",
            "value": 654226731
          }
        },
        "376d97cf555949e2847ba49c741aff5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67b127d30cc843bf9274617c948e3d3f",
            "placeholder": "โ",
            "style": "IPY_MODEL_ad4641dc3143436cbdd6f64bfe65626a",
            "value": " 624M/624M [00:11&lt;00:00, 59.3MB/s]"
          }
        },
        "1ee8ce0c6edd402f8b0d4a96fe8466e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d894ebbcafd14e2a957365a250eb6a54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73f690b312e142a9ba59fff9adefc5b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1258cddfc7244ad8b472519a1518ed5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09839934638340d09ffaa0e1876b7656": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "67b127d30cc843bf9274617c948e3d3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad4641dc3143436cbdd6f64bfe65626a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "849a0c5397714e728f4a0feb8abcaf18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a47c8af7a843479c8abd62902ab6ff1f",
              "IPY_MODEL_9ba1f0d92cfb4520aebd5c2fb02c575d",
              "IPY_MODEL_162d8d89f37e48b9ad775a6e88e66cca"
            ],
            "layout": "IPY_MODEL_a456d87324ed4acd9f5c70f27719fa88"
          }
        },
        "a47c8af7a843479c8abd62902ab6ff1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1c14ec7f1f74963a3d766611d3a615d",
            "placeholder": "โ",
            "style": "IPY_MODEL_a130a78d20434c2898297db8835ae3f0",
            "value": "Epochs... : 100%"
          }
        },
        "9ba1f0d92cfb4520aebd5c2fb02c575d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74e68e302692433eb0f3735b78adfeb4",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed05b03884a942ccb7800218093cce49",
            "value": 10
          }
        },
        "162d8d89f37e48b9ad775a6e88e66cca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b9c9c3bb07a4ca692149936f3c688ea",
            "placeholder": "โ",
            "style": "IPY_MODEL_51b0ffdbd4484d6db43405b57b042c50",
            "value": " 10/10 [08:53&lt;00:00, 53.76s/it]"
          }
        },
        "a456d87324ed4acd9f5c70f27719fa88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1c14ec7f1f74963a3d766611d3a615d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a130a78d20434c2898297db8835ae3f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74e68e302692433eb0f3735b78adfeb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed05b03884a942ccb7800218093cce49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b9c9c3bb07a4ca692149936f3c688ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51b0ffdbd4484d6db43405b57b042c50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5c90b77d0b442f380d7c3d183a5300c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c2926082540d4dfc90cf557cf6db1144",
              "IPY_MODEL_109267bf737e431884382b7d31fd7852",
              "IPY_MODEL_8601eb8ad82545abaf747999a1a8f657"
            ],
            "layout": "IPY_MODEL_ba841ab64e6f4c66ac56ea5a715a679d"
          }
        },
        "c2926082540d4dfc90cf557cf6db1144": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff2338148b274857bc23c13145e0c906",
            "placeholder": "โ",
            "style": "IPY_MODEL_9a8013942fe24daf9b0e4df1f1f33981",
            "value": "Training... : 100%"
          }
        },
        "109267bf737e431884382b7d31fd7852": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1ca07b00b0446e2a553925a7950fe32",
            "max": 127,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf09c769b2254724a902808b07eed392",
            "value": 127
          }
        },
        "8601eb8ad82545abaf747999a1a8f657": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32ac88fd5ad942b19740d67d74915362",
            "placeholder": "โ",
            "style": "IPY_MODEL_2aadadb679b64dc7b951a63de7e0466f",
            "value": " 127/127 [00:49&lt;00:00,  3.08it/s]"
          }
        },
        "ba841ab64e6f4c66ac56ea5a715a679d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff2338148b274857bc23c13145e0c906": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a8013942fe24daf9b0e4df1f1f33981": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1ca07b00b0446e2a553925a7950fe32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf09c769b2254724a902808b07eed392": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "32ac88fd5ad942b19740d67d74915362": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2aadadb679b64dc7b951a63de7e0466f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f4f054c4ceb4eb4b22900a1439698fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a99a0c08e9db47d7990e7bcc00d83df6",
              "IPY_MODEL_b53c5194051c4ff981d924ab0a3a8efc",
              "IPY_MODEL_57bb996901ef458e94496afa5f16bbbb"
            ],
            "layout": "IPY_MODEL_0c6081ba8ca6434d858b85fb6efd325a"
          }
        },
        "a99a0c08e9db47d7990e7bcc00d83df6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24a1ca4632b7490097060ed08b08cc99",
            "placeholder": "โ",
            "style": "IPY_MODEL_19bf4ef60dce4fbe93dffcb6bdc9a929",
            "value": "Evaluation... : 100%"
          }
        },
        "b53c5194051c4ff981d924ab0a3a8efc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_659f3f0df94d46f6ac775ff04d21f84c",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f7fb1d381cff47ae8eee16df8d1208dd",
            "value": 15
          }
        },
        "57bb996901ef458e94496afa5f16bbbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f207df9a1384cf1ad4b36645946aa6e",
            "placeholder": "โ",
            "style": "IPY_MODEL_e96d3c3ed39d4897ad3a9d617a7bbe6a",
            "value": " 15/15 [00:02&lt;00:00,  7.04it/s]"
          }
        },
        "0c6081ba8ca6434d858b85fb6efd325a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24a1ca4632b7490097060ed08b08cc99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19bf4ef60dce4fbe93dffcb6bdc9a929": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "659f3f0df94d46f6ac775ff04d21f84c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7fb1d381cff47ae8eee16df8d1208dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8f207df9a1384cf1ad4b36645946aa6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e96d3c3ed39d4897ad3a9d617a7bbe6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82592d0ddb6f4667848b15d4ddf63edb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_02ce970aebf74b179f170ff8c20b2bc1",
              "IPY_MODEL_a5266057ae3342a0a9b3ac78a4f9c236",
              "IPY_MODEL_c5061ba32c754d82a42c9fffaeef3b1a"
            ],
            "layout": "IPY_MODEL_cc82c3ab83a34da3a89a672757bfb3d2"
          }
        },
        "02ce970aebf74b179f170ff8c20b2bc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edefb16f58bf44bfbd549e9696798074",
            "placeholder": "โ",
            "style": "IPY_MODEL_f47e3e38804e4555811860c0293e956a",
            "value": "Training... : 100%"
          }
        },
        "a5266057ae3342a0a9b3ac78a4f9c236": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67840bd1888941f891211ea901ad00f5",
            "max": 127,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06955744027840e8bce23fea9c1c26ff",
            "value": 127
          }
        },
        "c5061ba32c754d82a42c9fffaeef3b1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcbdc9cc99e14477ad7463d13a594a44",
            "placeholder": "โ",
            "style": "IPY_MODEL_1a002b68a0fc42e49f86d517175b421b",
            "value": " 127/127 [00:50&lt;00:00,  3.23it/s]"
          }
        },
        "cc82c3ab83a34da3a89a672757bfb3d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edefb16f58bf44bfbd549e9696798074": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f47e3e38804e4555811860c0293e956a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67840bd1888941f891211ea901ad00f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06955744027840e8bce23fea9c1c26ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dcbdc9cc99e14477ad7463d13a594a44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a002b68a0fc42e49f86d517175b421b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "893286436692404194cfef6c856cdc67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eda97d34774b432d9204c3729f7e1d9a",
              "IPY_MODEL_825a285ac309419f97b9a2bcef4f7751",
              "IPY_MODEL_ce3fe39bef414eafab7d1a89280b0c86"
            ],
            "layout": "IPY_MODEL_40ba3eb4005f4f80ab0529d13d2aeb2a"
          }
        },
        "eda97d34774b432d9204c3729f7e1d9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17ac8f3fe5524703be485d2524772a14",
            "placeholder": "โ",
            "style": "IPY_MODEL_004e35587f8747acbaa4719545a49d5a",
            "value": "Evaluation... : 100%"
          }
        },
        "825a285ac309419f97b9a2bcef4f7751": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a4e3283bbf2426cb9ae5ea0db7a1f3a",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_adc152c76b2841b185988d26eb7fd58b",
            "value": 15
          }
        },
        "ce3fe39bef414eafab7d1a89280b0c86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8eafef2060da49cbad827c9f1b072f5e",
            "placeholder": "โ",
            "style": "IPY_MODEL_6ef7e897435642dda7bc0ad1b71d9e12",
            "value": " 15/15 [00:01&lt;00:00,  7.37it/s]"
          }
        },
        "40ba3eb4005f4f80ab0529d13d2aeb2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17ac8f3fe5524703be485d2524772a14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "004e35587f8747acbaa4719545a49d5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a4e3283bbf2426cb9ae5ea0db7a1f3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adc152c76b2841b185988d26eb7fd58b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8eafef2060da49cbad827c9f1b072f5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ef7e897435642dda7bc0ad1b71d9e12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d4d8827789e41f8be80a443f1a15bdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8fd982099f054498b548e70ba915952d",
              "IPY_MODEL_6442cf2047d14730b6679df5acb66860",
              "IPY_MODEL_a04497d7247b402f926ab46dedec7b45"
            ],
            "layout": "IPY_MODEL_66f6ebb3a25143bcb40bc3ee9fa10c09"
          }
        },
        "8fd982099f054498b548e70ba915952d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_580b60de18404ed3a6cb53bce4f8f710",
            "placeholder": "โ",
            "style": "IPY_MODEL_df24d290e37b41a4bb02a774cbd86697",
            "value": "Training... : 100%"
          }
        },
        "6442cf2047d14730b6679df5acb66860": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2a50148d417445e859d6f184af3d560",
            "max": 127,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d54d3d1c36cb4d058d90f29fde59eced",
            "value": 127
          }
        },
        "a04497d7247b402f926ab46dedec7b45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b91117a0c541458cbf5eb53c646f3a8b",
            "placeholder": "โ",
            "style": "IPY_MODEL_c7034328b49b4211a0f02a2211cbbda9",
            "value": " 127/127 [00:50&lt;00:00,  3.15it/s]"
          }
        },
        "66f6ebb3a25143bcb40bc3ee9fa10c09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "580b60de18404ed3a6cb53bce4f8f710": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df24d290e37b41a4bb02a774cbd86697": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2a50148d417445e859d6f184af3d560": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d54d3d1c36cb4d058d90f29fde59eced": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b91117a0c541458cbf5eb53c646f3a8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7034328b49b4211a0f02a2211cbbda9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "270a2e26ad054a649f5169562e1326a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2a6b2cd2d54a4bc59a0da8a5bc629eea",
              "IPY_MODEL_bb949fc263ff406cbfe018fcfdd37085",
              "IPY_MODEL_89323f4b0f014299a98393ab07512664"
            ],
            "layout": "IPY_MODEL_b2dc9a16147b4a28a5c90557119f7962"
          }
        },
        "2a6b2cd2d54a4bc59a0da8a5bc629eea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b518b3e487db4191aac7a08f533cec28",
            "placeholder": "โ",
            "style": "IPY_MODEL_df334dc9cb7041388b1450d44e0618a2",
            "value": "Evaluation... : 100%"
          }
        },
        "bb949fc263ff406cbfe018fcfdd37085": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f3a1158935745a8a9483afe4726546b",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_905b216e2e584e1cb904ba72aa8a3477",
            "value": 15
          }
        },
        "89323f4b0f014299a98393ab07512664": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de357ed73f024a6a8971b0f3e266f9d0",
            "placeholder": "โ",
            "style": "IPY_MODEL_ed863aedc9f94162a64653b76f15450f",
            "value": " 15/15 [00:02&lt;00:00,  7.15it/s]"
          }
        },
        "b2dc9a16147b4a28a5c90557119f7962": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b518b3e487db4191aac7a08f533cec28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df334dc9cb7041388b1450d44e0618a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f3a1158935745a8a9483afe4726546b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "905b216e2e584e1cb904ba72aa8a3477": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de357ed73f024a6a8971b0f3e266f9d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed863aedc9f94162a64653b76f15450f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9210640196204e76b9afb46e09bc612e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c64014fae4041ebbc3220d8f14e19c1",
              "IPY_MODEL_5db0bae4bd0e4b49a6d492cdac896ebe",
              "IPY_MODEL_689889ea9ee744bbade7c64ce451e1b6"
            ],
            "layout": "IPY_MODEL_b350843193504592a810440cddd04c22"
          }
        },
        "7c64014fae4041ebbc3220d8f14e19c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_871ab8105fd247a1ab25eda16976b5b1",
            "placeholder": "โ",
            "style": "IPY_MODEL_d4bb601e87d54588b920a1d6ada019af",
            "value": "Training... : 100%"
          }
        },
        "5db0bae4bd0e4b49a6d492cdac896ebe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ed7b6c303824311b481ae3d6b47f252",
            "max": 127,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c786b8ae89a4cfdb949a77339d8048a",
            "value": 127
          }
        },
        "689889ea9ee744bbade7c64ce451e1b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73c8bb0f9b474300b6caf8db7627b3df",
            "placeholder": "โ",
            "style": "IPY_MODEL_008fcaf16170441db8d07fcad4f8f039",
            "value": " 127/127 [00:51&lt;00:00,  2.67it/s]"
          }
        },
        "b350843193504592a810440cddd04c22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "871ab8105fd247a1ab25eda16976b5b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4bb601e87d54588b920a1d6ada019af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ed7b6c303824311b481ae3d6b47f252": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c786b8ae89a4cfdb949a77339d8048a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "73c8bb0f9b474300b6caf8db7627b3df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "008fcaf16170441db8d07fcad4f8f039": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0811f59155e945598ab2daf8db337ea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4bde0af3b5f2479f80374035ef7e945e",
              "IPY_MODEL_17d4a00ab6934a35aa628aa059eea6e5",
              "IPY_MODEL_68ece3a48eb84cfba024bdc49760582c"
            ],
            "layout": "IPY_MODEL_7c137e0929d0476585ac3f2af2f3180b"
          }
        },
        "4bde0af3b5f2479f80374035ef7e945e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4c799a68343416cbfbc57be1de6f8a4",
            "placeholder": "โ",
            "style": "IPY_MODEL_baee5ef17b8540cb9b67bd7adb737d5c",
            "value": "Evaluation... : 100%"
          }
        },
        "17d4a00ab6934a35aa628aa059eea6e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5a300352c7a44f0bcd173fe4b507862",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f7803fadc58e486a8457d2f238f16f98",
            "value": 15
          }
        },
        "68ece3a48eb84cfba024bdc49760582c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba1f8ed4c2d748ad80233229b45d768e",
            "placeholder": "โ",
            "style": "IPY_MODEL_d22725e0be734a57af5fe276c88a4945",
            "value": " 15/15 [00:02&lt;00:00,  7.02it/s]"
          }
        },
        "7c137e0929d0476585ac3f2af2f3180b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4c799a68343416cbfbc57be1de6f8a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baee5ef17b8540cb9b67bd7adb737d5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5a300352c7a44f0bcd173fe4b507862": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7803fadc58e486a8457d2f238f16f98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba1f8ed4c2d748ad80233229b45d768e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d22725e0be734a57af5fe276c88a4945": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9aed995118b443409667bc495b4e25df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_292ef6272db9499696072df7e307ea90",
              "IPY_MODEL_07a0d2af5bff44f486dd2e3621184b67",
              "IPY_MODEL_7a220e989fb64beca2d5abdecbb30c07"
            ],
            "layout": "IPY_MODEL_132edba0bbdd49a686439c5c42668973"
          }
        },
        "292ef6272db9499696072df7e307ea90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9db67726b5054c0fa4bfeb168ad8cebf",
            "placeholder": "โ",
            "style": "IPY_MODEL_12477f9b808f44ae807ba8e35921b14f",
            "value": "Training... : 100%"
          }
        },
        "07a0d2af5bff44f486dd2e3621184b67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd6e2f37e195447a9af47be38f9bd3d4",
            "max": 127,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_16727ff7d8f649b59503d5b314cf84e8",
            "value": 127
          }
        },
        "7a220e989fb64beca2d5abdecbb30c07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8ee4f6383eb400197d522480a82c033",
            "placeholder": "โ",
            "style": "IPY_MODEL_5d28acfb8458487c986b4c9dc4d511d2",
            "value": " 127/127 [00:50&lt;00:00,  3.15it/s]"
          }
        },
        "132edba0bbdd49a686439c5c42668973": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9db67726b5054c0fa4bfeb168ad8cebf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12477f9b808f44ae807ba8e35921b14f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd6e2f37e195447a9af47be38f9bd3d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16727ff7d8f649b59503d5b314cf84e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a8ee4f6383eb400197d522480a82c033": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d28acfb8458487c986b4c9dc4d511d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02f80e5f64814c3082ae935a9072716c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e693d92fe71742d09397264c4d99001b",
              "IPY_MODEL_b8ec11b81aaa4247b30d6250a83ccc94",
              "IPY_MODEL_d2d03889b7aa46888abdac0edc526ad4"
            ],
            "layout": "IPY_MODEL_596bd130a9cf4693b6977d7bc4839af6"
          }
        },
        "e693d92fe71742d09397264c4d99001b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96c5531de4764a05873f69da3847b853",
            "placeholder": "โ",
            "style": "IPY_MODEL_1c137234cdea4bd5a34b2cff9c5e1f47",
            "value": "Evaluation... : 100%"
          }
        },
        "b8ec11b81aaa4247b30d6250a83ccc94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_748c02a6382743e88f79ddea63b34c16",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_17494a17b06547ddaa03d72ef8782044",
            "value": 15
          }
        },
        "d2d03889b7aa46888abdac0edc526ad4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_270f3ad8f39e4c1583546cbedd4644f1",
            "placeholder": "โ",
            "style": "IPY_MODEL_d887b730ae944f3bbaf310183d2bc40b",
            "value": " 15/15 [00:02&lt;00:00,  7.04it/s]"
          }
        },
        "596bd130a9cf4693b6977d7bc4839af6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96c5531de4764a05873f69da3847b853": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c137234cdea4bd5a34b2cff9c5e1f47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "748c02a6382743e88f79ddea63b34c16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17494a17b06547ddaa03d72ef8782044": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "270f3ad8f39e4c1583546cbedd4644f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d887b730ae944f3bbaf310183d2bc40b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86e0e04f92c34c38b98de2716e28e376": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1450abf5cd1549709badb72b0bac9728",
              "IPY_MODEL_e2946ebcb3244438a391aba94cb44e21",
              "IPY_MODEL_0adbf2ac679e45a0bda05b679d0e830c"
            ],
            "layout": "IPY_MODEL_177cee6c3eda4b4eab4a2529cfdc7b7c"
          }
        },
        "1450abf5cd1549709badb72b0bac9728": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ff4520a721445cfaf5cc20fe279468d",
            "placeholder": "โ",
            "style": "IPY_MODEL_19bb820d169a4de1936e49e7f08df1a1",
            "value": "Training... : 100%"
          }
        },
        "e2946ebcb3244438a391aba94cb44e21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79637fbcc5444cfd825373e0ee4780d5",
            "max": 127,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c9a8966752c94e1e909f77aa4425aeef",
            "value": 127
          }
        },
        "0adbf2ac679e45a0bda05b679d0e830c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cc5c9813d80411fa37dff15005ecb6d",
            "placeholder": "โ",
            "style": "IPY_MODEL_a4c9df2b59f445cf8a4e5809c2b3a431",
            "value": " 127/127 [00:50&lt;00:00,  3.12it/s]"
          }
        },
        "177cee6c3eda4b4eab4a2529cfdc7b7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ff4520a721445cfaf5cc20fe279468d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19bb820d169a4de1936e49e7f08df1a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79637fbcc5444cfd825373e0ee4780d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9a8966752c94e1e909f77aa4425aeef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5cc5c9813d80411fa37dff15005ecb6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4c9df2b59f445cf8a4e5809c2b3a431": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7f309d5689f49c39dbc1e9cd8f6d6a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bc12ea29b25646ef8a580244d08bddee",
              "IPY_MODEL_70c8ae9dd3064c2098f0e60f8777f147",
              "IPY_MODEL_ce3460e415dc4e64ab47124646438448"
            ],
            "layout": "IPY_MODEL_f93eae4aed3b4761b65ad6e82512b5cf"
          }
        },
        "bc12ea29b25646ef8a580244d08bddee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bd127bfc7f04f0a8f5f22eaed5eb1fe",
            "placeholder": "โ",
            "style": "IPY_MODEL_b420d0c66c1b492a85b11cc48c655dcb",
            "value": "Evaluation... : 100%"
          }
        },
        "70c8ae9dd3064c2098f0e60f8777f147": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47504834cd7f40fa95815e7db77c595a",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_62d34ee221184081ba83758c7cf83168",
            "value": 15
          }
        },
        "ce3460e415dc4e64ab47124646438448": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90a14ef808df4a6980416bdc0a061137",
            "placeholder": "โ",
            "style": "IPY_MODEL_efd6d60eb98b47d2a81a0599a316035d",
            "value": " 15/15 [00:02&lt;00:00,  6.95it/s]"
          }
        },
        "f93eae4aed3b4761b65ad6e82512b5cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bd127bfc7f04f0a8f5f22eaed5eb1fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b420d0c66c1b492a85b11cc48c655dcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47504834cd7f40fa95815e7db77c595a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62d34ee221184081ba83758c7cf83168": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "90a14ef808df4a6980416bdc0a061137": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efd6d60eb98b47d2a81a0599a316035d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb70fdbcdc9d4d36a8aa15a5047d5374": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_097eb548449d407480c1d6a2bee7b729",
              "IPY_MODEL_da0faebd99384bb19ac94167f625a43b",
              "IPY_MODEL_5a3dc56a790a4768a1d4e106a1f7c230"
            ],
            "layout": "IPY_MODEL_ccd0898d21c147dca8b93213f288ecbb"
          }
        },
        "097eb548449d407480c1d6a2bee7b729": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b80fa8fa8b264cd09b72597bf9d40963",
            "placeholder": "โ",
            "style": "IPY_MODEL_657ca5ecd14d4b8c984c8ac1d628e827",
            "value": "Training... : 100%"
          }
        },
        "da0faebd99384bb19ac94167f625a43b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cea64c8c4b2f44919e653bb78d637478",
            "max": 127,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39ae8603d3a6414a987a669bf1e71d5d",
            "value": 127
          }
        },
        "5a3dc56a790a4768a1d4e106a1f7c230": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a07341aa17841a7884cc2f77a229c73",
            "placeholder": "โ",
            "style": "IPY_MODEL_7fc9045d679d4187b005ba5e9f47c564",
            "value": " 127/127 [00:51&lt;00:00,  3.11it/s]"
          }
        },
        "ccd0898d21c147dca8b93213f288ecbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b80fa8fa8b264cd09b72597bf9d40963": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "657ca5ecd14d4b8c984c8ac1d628e827": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cea64c8c4b2f44919e653bb78d637478": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39ae8603d3a6414a987a669bf1e71d5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a07341aa17841a7884cc2f77a229c73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fc9045d679d4187b005ba5e9f47c564": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1b622bcbf364de69c9096d57f84dda8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e06275da28e04b73a5b2a4d65f6ced24",
              "IPY_MODEL_8eb45b00a6634c69ae88d3d5cf727ecf",
              "IPY_MODEL_8a47a54439c64ef5bf8a1b32265ffde5"
            ],
            "layout": "IPY_MODEL_670f02ea804446d984e0b1b060104cf2"
          }
        },
        "e06275da28e04b73a5b2a4d65f6ced24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24cf6bdc462d43ed8cd930fec703c5ad",
            "placeholder": "โ",
            "style": "IPY_MODEL_23f5f89e1db0434e95c4e41643e5117c",
            "value": "Evaluation... : 100%"
          }
        },
        "8eb45b00a6634c69ae88d3d5cf727ecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_084d2597c7524dc786dfb87b858c4b82",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bcb1bb491e40493380fd038a9ef77401",
            "value": 15
          }
        },
        "8a47a54439c64ef5bf8a1b32265ffde5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a82aae66f2b4303a8a7405cbc96bdf5",
            "placeholder": "โ",
            "style": "IPY_MODEL_2ef6fdeeb916463b930433fda0f70ccc",
            "value": " 15/15 [00:02&lt;00:00,  7.07it/s]"
          }
        },
        "670f02ea804446d984e0b1b060104cf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24cf6bdc462d43ed8cd930fec703c5ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23f5f89e1db0434e95c4e41643e5117c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "084d2597c7524dc786dfb87b858c4b82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcb1bb491e40493380fd038a9ef77401": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a82aae66f2b4303a8a7405cbc96bdf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ef6fdeeb916463b930433fda0f70ccc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b701b766409f420f9e4ac66415582b78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_046f059594864439b2178641641e51e5",
              "IPY_MODEL_0e605e2232bd4dd9b97367e2da30e923",
              "IPY_MODEL_02631f3903bf4ece8764b84baf7ce838"
            ],
            "layout": "IPY_MODEL_44cad2dff63543c88ee1d8e6ee8f4073"
          }
        },
        "046f059594864439b2178641641e51e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d95c58e9fd84a7c8c0bdbf91e5784b8",
            "placeholder": "โ",
            "style": "IPY_MODEL_ac77bddf75d44950b932c408535dc2a6",
            "value": "Training... : 100%"
          }
        },
        "0e605e2232bd4dd9b97367e2da30e923": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28b51df6499d4bde8cecaa88d223c980",
            "max": 127,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc33e0ded05d42978be7facb9a67d482",
            "value": 127
          }
        },
        "02631f3903bf4ece8764b84baf7ce838": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_907a5e1e362c4731857e10ee22b52c35",
            "placeholder": "โ",
            "style": "IPY_MODEL_cd1d10c42bb9446191e247c271fc9c17",
            "value": " 127/127 [00:55&lt;00:00,  3.09it/s]"
          }
        },
        "44cad2dff63543c88ee1d8e6ee8f4073": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d95c58e9fd84a7c8c0bdbf91e5784b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac77bddf75d44950b932c408535dc2a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28b51df6499d4bde8cecaa88d223c980": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc33e0ded05d42978be7facb9a67d482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "907a5e1e362c4731857e10ee22b52c35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd1d10c42bb9446191e247c271fc9c17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f267748ea5d4da1917de0ceb1af462f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_82f505c824364c7c997c5bc5cf174183",
              "IPY_MODEL_9c0363e2117245c9a22fb4de2f35e6db",
              "IPY_MODEL_2616c8c2e7b24d6abe73144f07575842"
            ],
            "layout": "IPY_MODEL_ac6c266425a24051a80c1a6a112a83da"
          }
        },
        "82f505c824364c7c997c5bc5cf174183": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e4b9c15d1dc44cf9290527e69983ae5",
            "placeholder": "โ",
            "style": "IPY_MODEL_e3f46ed90b4942759a68a499c18b6b97",
            "value": "Evaluation... : 100%"
          }
        },
        "9c0363e2117245c9a22fb4de2f35e6db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb12f34dca574a1da206cf71d055785e",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e72082b305dc4ad7a794fb439cbd7fcd",
            "value": 15
          }
        },
        "2616c8c2e7b24d6abe73144f07575842": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e95fb3fd5c04c4f975be892a81b238f",
            "placeholder": "โ",
            "style": "IPY_MODEL_f6a07473f1e8475a8fae818c29f4ba08",
            "value": " 15/15 [00:02&lt;00:00,  7.12it/s]"
          }
        },
        "ac6c266425a24051a80c1a6a112a83da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e4b9c15d1dc44cf9290527e69983ae5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3f46ed90b4942759a68a499c18b6b97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb12f34dca574a1da206cf71d055785e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e72082b305dc4ad7a794fb439cbd7fcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e95fb3fd5c04c4f975be892a81b238f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6a07473f1e8475a8fae818c29f4ba08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33403fd8abae4e149f34929ea89b70b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a202287e0714bc49148cbf81739bb6f",
              "IPY_MODEL_f08f3bc8fc234b809b02978b477f54cd",
              "IPY_MODEL_091f3c7c1ce7486aacdef75f3c414725"
            ],
            "layout": "IPY_MODEL_71ed124f595d482eb95d9ee172a29e39"
          }
        },
        "5a202287e0714bc49148cbf81739bb6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d41d51bf67c46ffb50b443821473a1b",
            "placeholder": "โ",
            "style": "IPY_MODEL_e30d4bd707234b8b8ca501989e358b16",
            "value": "Evaluation... : 100%"
          }
        },
        "f08f3bc8fc234b809b02978b477f54cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d95a46f733264b428619021b72614002",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_74b60563e7c742f7adb8487a409cb6d3",
            "value": 15
          }
        },
        "091f3c7c1ce7486aacdef75f3c414725": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b2835053b7842cfa5e2dca6a8bf9726",
            "placeholder": "โ",
            "style": "IPY_MODEL_0bb9ff8bf78b4c89b371bf45ebf83753",
            "value": " 15/15 [00:02&lt;00:00,  7.00it/s]"
          }
        },
        "71ed124f595d482eb95d9ee172a29e39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d41d51bf67c46ffb50b443821473a1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e30d4bd707234b8b8ca501989e358b16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d95a46f733264b428619021b72614002": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74b60563e7c742f7adb8487a409cb6d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b2835053b7842cfa5e2dca6a8bf9726": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bb9ff8bf78b4c89b371bf45ebf83753": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "967af0dfa87e4eac911e6f0ab7415312": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f9dbc51c012f4708bfc4ba68621e2505",
              "IPY_MODEL_b95e26d3560f433db8c77db9e1d27616",
              "IPY_MODEL_40d5010dbed2473dbe7e0429b41b5461"
            ],
            "layout": "IPY_MODEL_029183ecdc644903996e50d665ce198f"
          }
        },
        "f9dbc51c012f4708bfc4ba68621e2505": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ad6d9c69a0b46e6b8e5876df0b26f81",
            "placeholder": "โ",
            "style": "IPY_MODEL_aa16ace50b74488d9559b0dba579ca4a",
            "value": "Training... : 100%"
          }
        },
        "b95e26d3560f433db8c77db9e1d27616": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96a851951e7c4e6e96dc9e10f99b6f22",
            "max": 127,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6ceb86f21f864739a0fa111259e41b7e",
            "value": 127
          }
        },
        "40d5010dbed2473dbe7e0429b41b5461": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e6b0bd439894917b0d56c4b61733766",
            "placeholder": "โ",
            "style": "IPY_MODEL_5baf55b049bb4725aaced06f75e30136",
            "value": " 127/127 [00:50&lt;00:00,  3.09it/s]"
          }
        },
        "029183ecdc644903996e50d665ce198f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ad6d9c69a0b46e6b8e5876df0b26f81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa16ace50b74488d9559b0dba579ca4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96a851951e7c4e6e96dc9e10f99b6f22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ceb86f21f864739a0fa111259e41b7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7e6b0bd439894917b0d56c4b61733766": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5baf55b049bb4725aaced06f75e30136": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "699381678de5446392cd7d2b13d3c83e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5b18a0216274ec3a8df4273d47d732f",
              "IPY_MODEL_7f6f7e2499b84b8ca5456e2827a3e807",
              "IPY_MODEL_af2bdf284b4c4a8aa950f64867445823"
            ],
            "layout": "IPY_MODEL_b9a37eaa91984bb9ad78cda52cab0557"
          }
        },
        "c5b18a0216274ec3a8df4273d47d732f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b136c6ff6204661a50531262017e0e4",
            "placeholder": "โ",
            "style": "IPY_MODEL_fef5fee962c64e358ec02dc84ad9e690",
            "value": "Evaluation... : 100%"
          }
        },
        "7f6f7e2499b84b8ca5456e2827a3e807": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f5d9efbf78a495d8fd20a879bf344c5",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fb777dbe75334091a0477971da471c04",
            "value": 15
          }
        },
        "af2bdf284b4c4a8aa950f64867445823": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19ac036ed63643509d0c2f337468860d",
            "placeholder": "โ",
            "style": "IPY_MODEL_9b471f92f09f4ee69b900ee0ba59170f",
            "value": " 15/15 [00:02&lt;00:00,  6.48it/s]"
          }
        },
        "b9a37eaa91984bb9ad78cda52cab0557": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b136c6ff6204661a50531262017e0e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fef5fee962c64e358ec02dc84ad9e690": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f5d9efbf78a495d8fd20a879bf344c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb777dbe75334091a0477971da471c04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "19ac036ed63643509d0c2f337468860d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b471f92f09f4ee69b900ee0ba59170f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3243dfd90014c449a91e5e3826c00a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_555bcd7ed31f4aa7951e6f6c4d987a30",
              "IPY_MODEL_3e90e7ec33c34861837d8be88aebadd1",
              "IPY_MODEL_6981b6c5ecee4c5fbae1bafe68d6ae45"
            ],
            "layout": "IPY_MODEL_dbf683a521624767830719b3b9422220"
          }
        },
        "555bcd7ed31f4aa7951e6f6c4d987a30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86edd78334fb44e69dd9028957d6b856",
            "placeholder": "โ",
            "style": "IPY_MODEL_5a9f098974fb494da092cc4e99e7fd63",
            "value": "Training... : 100%"
          }
        },
        "3e90e7ec33c34861837d8be88aebadd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bbdd0af72984ed285a3250ed217f558",
            "max": 127,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1f76220efd04b2c81bd385b404c0752",
            "value": 127
          }
        },
        "6981b6c5ecee4c5fbae1bafe68d6ae45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e88156e2b0e460a84448b21a691e65a",
            "placeholder": "โ",
            "style": "IPY_MODEL_17d796277d014aca97f7b5ffcddbc01b",
            "value": " 127/127 [00:50&lt;00:00,  3.12it/s]"
          }
        },
        "dbf683a521624767830719b3b9422220": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86edd78334fb44e69dd9028957d6b856": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a9f098974fb494da092cc4e99e7fd63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0bbdd0af72984ed285a3250ed217f558": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1f76220efd04b2c81bd385b404c0752": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8e88156e2b0e460a84448b21a691e65a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17d796277d014aca97f7b5ffcddbc01b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aeebdb00c47c4e588897f4853757d9e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7bbe10ca6ad44295bcc215443725d29d",
              "IPY_MODEL_320f2ab606874d3782b9e247049ec017",
              "IPY_MODEL_dbe505d579f34f5f8cc1b1b6fb35562e"
            ],
            "layout": "IPY_MODEL_c84ed20948244c48b74bba18edd4a7f4"
          }
        },
        "7bbe10ca6ad44295bcc215443725d29d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b21338a7b4544cd3a01e2ab686fc5ee4",
            "placeholder": "โ",
            "style": "IPY_MODEL_b852f703a61845efbe2df771a49eca88",
            "value": "Evaluation... : 100%"
          }
        },
        "320f2ab606874d3782b9e247049ec017": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7598a304ccb94c42b623936c8f28769b",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2acd1337f8904501afda98640be3ffc5",
            "value": 15
          }
        },
        "dbe505d579f34f5f8cc1b1b6fb35562e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29d3f41ab12544efb7088dff79d3a732",
            "placeholder": "โ",
            "style": "IPY_MODEL_1210392c1a894b1ea96e22ab6339926a",
            "value": " 15/15 [00:02&lt;00:00,  7.11it/s]"
          }
        },
        "c84ed20948244c48b74bba18edd4a7f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b21338a7b4544cd3a01e2ab686fc5ee4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b852f703a61845efbe2df771a49eca88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7598a304ccb94c42b623936c8f28769b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2acd1337f8904501afda98640be3ffc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "29d3f41ab12544efb7088dff79d3a732": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1210392c1a894b1ea96e22ab6339926a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9214e44a5aa4fb5ac252acb463925f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_72b3e66d4c8b4421b4ee464af1f7d1f9",
              "IPY_MODEL_e6e21363e9a444a6ab31fdd94a8922e5",
              "IPY_MODEL_3da2a692295c4c4b95d604aaae8ad0b7"
            ],
            "layout": "IPY_MODEL_e5743cd6e7e04deab6c06e228cd12553"
          }
        },
        "72b3e66d4c8b4421b4ee464af1f7d1f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b0fb2d13901413eac9efffecfd5b35e",
            "placeholder": "โ",
            "style": "IPY_MODEL_47d78132d74a4361be7784661e75ffae",
            "value": "100%"
          }
        },
        "e6e21363e9a444a6ab31fdd94a8922e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b8304c29b2a457fb2fa9ac164e88d1e",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4da9adc5d47d4be8976fc76faf06f53f",
            "value": 8
          }
        },
        "3da2a692295c4c4b95d604aaae8ad0b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b02b589e30d416e941abf0cf4642e58",
            "placeholder": "โ",
            "style": "IPY_MODEL_e9c919e53a984340a6cf47a594d64eeb",
            "value": " 8/8 [00:02&lt;00:00,  3.75it/s]"
          }
        },
        "e5743cd6e7e04deab6c06e228cd12553": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b0fb2d13901413eac9efffecfd5b35e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47d78132d74a4361be7784661e75ffae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b8304c29b2a457fb2fa9ac164e88d1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4da9adc5d47d4be8976fc76faf06f53f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9b02b589e30d416e941abf0cf4642e58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9c919e53a984340a6cf47a594d64eeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}